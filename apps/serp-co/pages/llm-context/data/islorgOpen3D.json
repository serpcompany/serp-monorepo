[
  {
    "owner": "isl-org",
    "repo": "open3d",
    "content": "TITLE: Computing Convex Hull of Point Cloud in Open3D\nDESCRIPTION: Samples points from a mesh, computes the convex hull of the point cloud, and visualizes the result. The convex hull is the smallest convex set containing all points, implemented using the Qhull algorithm.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(bunny.path)\nmesh.compute_vertex_normals()\n\npcl = mesh.sample_points_poisson_disk(number_of_points=2000)\nhull, _ = pcl.compute_convex_hull()\nhull_ls = o3d.geometry.LineSet.create_from_triangle_mesh(hull)\nhull_ls.paint_uniform_color((1, 0, 0))\no3d.visualization.draw_geometries([pcl, hull_ls])\n```\n\n----------------------------------------\n\nTITLE: Performing Plane Segmentation on Point Cloud Data with Open3D in Python\nDESCRIPTION: This snippet shows how to use RANSAC-based plane segmentation on a point cloud. It finds the plane with the largest support, extracts inlier points, and visualizes the results by coloring the inlier points red.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npcd_point_cloud = o3d.data.PCDPointCloud()\npcd = o3d.io.read_point_cloud(pcd_point_cloud.path)\n\nplane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n                                         ransac_n=3,\n                                         num_iterations=1000)\n[a, b, c, d] = plane_model\nprint(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n\ninlier_cloud = pcd.select_by_index(inliers)\ninlier_cloud.paint_uniform_color([1.0, 0, 0])\noutlier_cloud = pcd.select_by_index(inliers, invert=True)\no3d.visualization.draw_geometries([inlier_cloud, outlier_cloud],\n                                  zoom=0.8,\n                                  front=[-0.4999, -0.1659, -0.8499],\n                                  lookat=[2.1813, 2.0619, 2.0999],\n                                  up=[0.1204, -0.9852, 0.1215])\n```\n\n----------------------------------------\n\nTITLE: Displaying Axis-Aligned and Oriented Bounding Boxes - Open3D - Python\nDESCRIPTION: This snippet generates both axis-aligned and oriented bounding boxes around a point cloud, sets their colors, and renders them along with the original point cloud. Axis-aligned boxes are aligned to coordinate axes, while oriented boxes fit tightly at arbitrary orientations. Dependencies: Open3D; inputs: point cloud, desired colors; outputs: colored bounding boxes visualized with the input point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\naabb = pcd.get_axis_aligned_bounding_box()\\naabb.set_color(o3c.Tensor([1, 0, 0], o3c.float32))\\nobb = pcd.get_oriented_bounding_box()\\nobb.set_color(o3c.Tensor([0, 1, 0], o3c.float32))\\no3d.visualization.draw_geometries(\\n    [pcd.to_legacy(), aabb.to_legacy(),\\n     obb.to_legacy()],\\n    zoom=0.7,\\n    front=[0.5439, -0.2333, -0.8060],\\n    lookat=[2.4615, 2.1331, 1.338],\\n    up=[-0.1781, -0.9708, 0.1608])\n```\n\n----------------------------------------\n\nTITLE: Installing and Verifying Open3D with Python\nDESCRIPTION: Commands for installing Open3D via pip and verifying the installation by checking the version. Includes both standard installation and CPU-only options for x86_64 Linux systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Install\npip install open3d       # or\npip install open3d-cpu   # Smaller CPU only wheel on x86_64 Linux (v0.17+)\n\n# Verify installation\npython -c \"import open3d as o3d; print(o3d.__version__)\"\n```\n\n----------------------------------------\n\nTITLE: Colored ICP Registration Implementation\nDESCRIPTION: Implements color-aware ICP registration that uses both geometry and color information for more accurate and robust alignment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndemo_cicp_pcds = o3d.data.DemoColoredICPPointClouds()\nsource = o3d.t.io.read_point_cloud(demo_cicp_pcds.paths[0])\ntarget = o3d.t.io.read_point_cloud(demo_cicp_pcds.paths[1])\n\nsource.point[\"colors\"] = source.point[\"colors\"].to(\n    o3d.core.Dtype.Float32) / 255.0\ntarget.point[\"colors\"] = target.point[\"colors\"].to(\n    o3d.core.Dtype.Float32) / 255.0\n\ncurrent_transformation = np.identity(4)\ndraw_registration_result(source, target, current_transformation)\n```\n\n----------------------------------------\n\nTITLE: Declaring the Open3D Project with Metadata - CMake - CMake\nDESCRIPTION: The snippet formally declares the Open3D project in CMake, injecting version numbers and project metadata such as description and homepage URL. It supports C and C++ languages and emits the finalized project version to the build log. No additional dependencies beyond earlier variable setup are required. Output is CMake's internal project configuration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_15\n\nLANGUAGE: CMake\nCODE:\n```\nproject(Open3D\n    VERSION ${OPEN3D_VERSION}\n    # Set PROJECT_DESCRIPTION\n    DESCRIPTION \"Open3D: A Modern Library for 3D Data Processing.\"\n    # Set PROJECT_HOMEPAGE_URL\n    HOMEPAGE_URL \"https://www.open3d.org\"\n    LANGUAGES C CXX)\nmessage(STATUS \"Open3D ${OPEN3D_VERSION_FULL}\")\n```\n\n----------------------------------------\n\nTITLE: Segmenting Planes in Point Clouds using Open3D RANSAC in Python\nDESCRIPTION: This snippet demonstrates how to segment the largest plane from a point cloud using the RANSAC algorithm implemented in Open3D's `segment_plane` function. It requires a distance threshold, the number of points for plane estimation (`ransac_n`), the number of iterations, and the desired probability. The function returns the plane model coefficients (a, b, c, d) and the indices of the inlier points. The code then separates inliers and outliers, colors them differently, and visualizes the result.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n```python\nsample_pcd_data = o3d.data.PCDPointCloud()\npcd = o3d.t.io.read_point_cloud(sample_pcd_data.path)\nplane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n                                            ransac_n=3,\n                                            num_iterations=1000, \n                                            probability=0.9999)\n[a, b, c, d] = plane_model.numpy().tolist()\nprint(f\"Plane equation: {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\")\n\ninlier_cloud = pcd.select_by_index(inliers)\ninlier_cloud = inlier_cloud.paint_uniform_color([1.0, 0, 0])\noutlier_cloud = pcd.select_by_index(inliers, invert=True)\no3d.visualization.draw_geometries([inlier_cloud.to_legacy(), outlier_cloud.to_legacy()],\n                                  zoom=0.8,\n                                  front=[-0.4999, -0.1659, -0.8499],\n                                  lookat=[2.1813, 2.0619, 2.0999],\n                                  up=[0.1204, -0.9852, 0.1215])\n```\n```\n\n----------------------------------------\n\nTITLE: Performing Point-to-Plane ICP Registration with Open3D\nDESCRIPTION: This code demonstrates point-to-plane ICP registration using Open3D. It applies the ICP algorithm with point-to-plane estimation, which typically converges faster than point-to-point ICP.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/icp_registration.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Apply point-to-plane ICP\")\nreg_p2l = o3d.pipelines.registration.registration_icp(\n    source, target, threshold, trans_init,\n    o3d.pipelines.registration.TransformationEstimationPointToPlane())\nprint(reg_p2l)\nprint(\"Transformation is:\")\nprint(reg_p2l.transformation)\ndraw_registration_result(source, target, reg_p2l.transformation)\n```\n\n----------------------------------------\n\nTITLE: Cropping Point Clouds with Selection Polygon Volume - Open3D - Python\nDESCRIPTION: This snippet demonstrates how to crop a point cloud using a polygon volume defined in a JSON file with Open3D. It loads the point cloud and the polygon selection, crops the original cloud to retain only the geometry within the polygon, then renders the result. Dependencies: Open3D, demo point cloud and crop JSON files. Inputs include file paths for the point cloud and the selection area; outputs are the cropped point cloud and a displayed visualization. Only the part of the object (chair) inside the selection remains after cropping.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Load a polygon volume and use it to crop the original point cloud\")\\ndemo_crop_data = o3d.data.DemoCropPointCloud()\\npcd = o3d.t.io.read_point_cloud(demo_crop_data.point_cloud_path)\\nvol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)\\nchair = vol.crop_point_cloud(pcd.to_legacy())\\no3d.visualization.draw_geometries([chair],\\n                                  zoom=0.7,\\n                                  front=[0.5439, -0.2333, -0.8060],\\n                                  lookat=[2.4615, 2.1331, 1.338],\\n                                  up=[-0.1781, -0.9708, 0.1608])\n```\n\n----------------------------------------\n\nTITLE: Reading Sample RGBD Images and Camera Poses in Python with Open3D\nDESCRIPTION: This snippet demonstrates how to read sample RGBD images and camera poses using Open3D's data module and the previously defined read_trajectory function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_integration.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nredwood_rgbd = o3d.data.SampleRedwoodRGBDImages()\ncamera_poses = read_trajectory(redwood_rgbd.odometry_log_path)\n```\n\n----------------------------------------\n\nTITLE: Setting and Getting Point Cloud Attributes\nDESCRIPTION: Demonstrates how to set and get point cloud attributes like normals, colors, and custom properties. Shows setting attributes using Open3D tensors, NumPy arrays, and Python lists, and retrieving those attributes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32))\n# Set attributes.\npcd.point.normals = o3c.Tensor([[0, 0, 1], [0, 0, 1]], o3c.float32)\npcd.point.colors = o3c.Tensor([[1, 0, 0], [0, 1, 0]], o3c.float32)\npcd.point.labels = o3c.Tensor([0, 1], o3c.int64)\nprint(pcd, \"\\n\")\n\n# Set by numpy array or python list.\npcd.point.normals = np.array([[0, 0, 1], [0, 0, 1]], dtype=np.float32)\npcd.point.intensity = [0.4, 0.4]\nprint(pcd, \"\\n\")\n\n# Get attributes.\nposisions = pcd.point.positions\nprint(\"posisions: \")\nprint(posisions, \"\\n\")\nlabels = pcd.point.labels\nprint(\"labels: \")\nprint(labels, \"\")\n```\n\n----------------------------------------\n\nTITLE: Statistical Outlier Removal from Point Clouds - Open3D - Python\nDESCRIPTION: Applies statistical_outlier_removal to a downsampled point cloud to remove noisy points based on neighborhood statistics. Takes number of neighbors and standard deviation ratio as parameters and uses the earlier display_inlier_outlier function for visualization. Dependencies: Open3D; inputs: point cloud, neighborhood parameters; outputs: filtered cloud and visual display of inliers/outliers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Statistical oulier removal\")\\ncl, ind = voxel_down_pcd.remove_statistical_outliers(nb_neighbors=20,\\n                                                     std_ratio=2.0)\\ndisplay_inlier_outlier(voxel_down_pcd, ind)\n```\n\n----------------------------------------\n\nTITLE: Detecting Planar Patches in Point Cloud Data with Open3D in Python\nDESCRIPTION: This snippet demonstrates the use of a robust statistics-based approach for planar patch detection in a point cloud. It applies the algorithm with customizable parameters and visualizes the detected planar patches as flattened bounding boxes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.PCDPointCloud()\npcd = o3d.io.read_point_cloud(dataset.path)\nassert (pcd.has_normals())\n\n# using all defaults\noboxes = pcd.detect_planar_patches(\n    normal_variance_threshold_deg=60,\n    coplanarity_deg=75,\n    outlier_ratio=0.75,\n    min_plane_edge_length=0,\n    min_num_points=0,\n    search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n\nprint(\"Detected {} patches\".format(len(oboxes)))\n\ngeometries = []\nfor obox in oboxes:\n    mesh = o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(obox, scale=[1, 1, 0.0001])\n    mesh.paint_uniform_color(obox.color)\n    geometries.append(mesh)\n    geometries.append(obox)\ngeometries.append(pcd)\n\no3d.visualization.draw_geometries(geometries,\n                                  zoom=0.62,\n                                  front=[0.4361, -0.2632, -0.8605],\n                                  lookat=[2.4947, 1.7728, 1.5541],\n                                  up=[-0.1726, -0.9630, 0.2071])\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Point Clouds for Feature Extraction in Open3D\nDESCRIPTION: Implements a function to preprocess point clouds by downsampling, estimating normals, and computing FPFH features. These steps are crucial for the subsequent global registration process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_point_cloud(pcd, voxel_size):\n    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n    pcd_down = pcd.voxel_down_sample(voxel_size)\n\n    radius_normal = voxel_size * 2\n    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n    pcd_down.estimate_normals(\n        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n\n    radius_feature = voxel_size * 5\n    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n        pcd_down,\n        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n    return pcd_down, pcd_fpfh\n```\n\n----------------------------------------\n\nTITLE: Mesh Subdivision using Midpoint Method in Python with Open3D\nDESCRIPTION: This snippet demonstrates mesh subdivision using the midpoint method in Open3D. It creates a box mesh, applies subdivision, and visualizes the results, showing the increase in vertices and triangles.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_box()\nmesh.compute_vertex_normals()\nprint(\n    f'The mesh has {len(mesh.vertices)} vertices and {len(mesh.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh], zoom=0.8, mesh_show_wireframe=True)\nmesh = mesh.subdivide_midpoint(number_of_iterations=1)\nprint(\n    f'After subdivision it has {len(mesh.vertices)} vertices and {len(mesh.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh], zoom=0.8, mesh_show_wireframe=True)\n```\n\n----------------------------------------\n\nTITLE: Converting TUM RGBD Image to Point Cloud\nDESCRIPTION: Creates and visualizes a 3D point cloud from the TUM dataset RGBD image using default camera parameters with specified zoom level.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\npcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n    rgbd_image,\n    o3d.camera.PinholeCameraIntrinsic(\n        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n# Flip it, otherwise the pointcloud will be upside down\npcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\no3d.visualization.draw_geometries([pcd], zoom=0.35)\n```\n\n----------------------------------------\n\nTITLE: Implementing Frame-to-Model Tracking Loop\nDESCRIPTION: Main tracking loop that performs frame-to-model alignment using ray-casting and RGB-D odometry. Updates camera poses and maintains the reconstructed model through iterative refinement.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/dense_slam.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwhile True:\n    # Process RGB-D frame\n    rgbd = process_rgbd(color_source[i], depth_source[i], intrinsic,\n                       config)\n    input_frame = frame\n    input_frame.load_rgbd_frame(rgbd)\n\n    # Switch rgbd input to GPU\n    input_frame.compute_normals(intrinsic)\n    result = model.track_frame_to_model(input_frame,\n                                       raycast_frame,\n                                       intrinsic,\n                                       T_frame_to_model,\n                                       config)\n    T_frame_to_model = T_frame_to_model @ result.transformation\n\n    # Update model after tracking\n    model.update_frame_pose(i, T_frame_to_model)\n    model.integrate(input_frame,\n                   intrinsic,\n                   T_frame_to_model,\n                   config)\n\n```\n\n----------------------------------------\n\nTITLE: Configuring C++ Standard and Compatibility Flags - CMake - CMake\nDESCRIPTION: This snippet sets the project's C++ standard to C++17 and disables compiler-specific extensions for improved cross-compiler compatibility. It suppresses certain deprecation warnings for specific CUDA/MSVC cases using add_compile_definitions. There are no required inputs, and effects are limited to build compilation flags and definitions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_17\n\nLANGUAGE: CMake\nCODE:\n```\n# Global flag to set CXX standard.\n# This does not affect 3rd party libraries.\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_EXTENSIONS OFF)   # Improved compatibility\n\n# Suppress warnings for deprecated C++17 functions (stdgpu->thrust with CUDA 11 for MSVC).\nadd_compile_definitions($<$<COMPILE_LANGUAGE:CUDA>:_SILENCE_CXX17_RESULT_OF_DEPRECATION_WARNING>)\n```\n\n----------------------------------------\n\nTITLE: Implementing Colored Point Cloud Registration with Open3D\nDESCRIPTION: Performs colored point cloud registration using a multi-scale approach. It iterates through different voxel sizes, downsampling the point clouds, estimating normals, and applying colored ICP registration at each scale.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/colored_pointcloud_registration.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# colored pointcloud registration\n# This is implementation of following paper\n# J. Park, Q.-Y. Zhou, V. Koltun,\n# Colored Point Cloud Registration Revisited, ICCV 2017\nvoxel_radius = [0.04, 0.02, 0.01]\nmax_iter = [50, 30, 14]\ncurrent_transformation = np.identity(4)\nprint(\"3. Colored point cloud registration\")\nfor scale in range(3):\n    iter = max_iter[scale]\n    radius = voxel_radius[scale]\n    print([iter, radius, scale])\n\n    print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n    source_down = source.voxel_down_sample(radius)\n    target_down = target.voxel_down_sample(radius)\n\n    print(\"3-2. Estimate normal.\")\n    source_down.estimate_normals(\n        o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n    target_down.estimate_normals(\n        o3d.geometry.KDTreeSearchParamHybrid(radius=radius * 2, max_nn=30))\n\n    print(\"3-3. Applying colored point cloud registration\")\n    result_icp = o3d.pipelines.registration.registration_colored_icp(\n        source_down, target_down, radius, current_transformation,\n        o3d.pipelines.registration.TransformationEstimationForColoredICP(),\n        o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-6,\n                                                          relative_rmse=1e-6,\n                                                          max_iteration=iter))\n    current_transformation = result_icp.transformation\n    print(result_icp)\ndraw_registration_result_original_color(source, target,\n                                        result_icp.transformation)\n```\n\n----------------------------------------\n\nTITLE: Radius Outlier Removal from Point Clouds - Open3D - Python\nDESCRIPTION: This snippet performs radius-based outlier removal, eliminating points that lack sufficient neighbors within a certain radius. The minimum neighbor count and search radius are parameters; display_inlier_outlier is used to show results. Dependencies: Open3D; inputs: point cloud, nb_points, search_radius; outputs: cleaned inlier set, outlier visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Radius oulier removal\")\\ncl, ind = voxel_down_pcd.remove_radius_outliers(nb_points=16, search_radius=0.05)\\ndisplay_inlier_outlier(voxel_down_pcd, ind)\n```\n\n----------------------------------------\n\nTITLE: Performing DBSCAN Clustering on Point Cloud Data with Open3D in Python\nDESCRIPTION: This snippet demonstrates how to use DBSCAN clustering on a point cloud loaded from a PLY file. It sets clustering parameters, applies the algorithm, and visualizes the results by coloring each cluster differently.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nply_point_cloud = o3d.data.PLYPointCloud()\npcd = o3d.io.read_point_cloud(ply_point_cloud.path)\n\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    labels = np.array(\n        pcd.cluster_dbscan(eps=0.02, min_points=10, print_progress=True))\n\nmax_label = labels.max()\nprint(f\"point cloud has {max_label + 1} clusters\")\ncolors = plt.get_cmap(\"tab20\")(labels / (max_label if max_label > 0 else 1))\ncolors[labels < 0] = 0\npcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\no3d.visualization.draw_geometries([pcd],\n                                  zoom=0.455,\n                                  front=[-0.4999, -0.1659, -0.8499],\n                                  lookat=[2.1813, 2.0619, 2.0999],\n                                  up=[0.1204, -0.9852, 0.1215])\n```\n\n----------------------------------------\n\nTITLE: Implementing Pairwise and Full Registration for Point Clouds in Open3D\nDESCRIPTION: Defines functions for pairwise registration using point-to-plane ICP and full registration to build a pose graph. The pose graph includes odometry edges (between consecutive point clouds) and loop closure edges (between non-consecutive clouds) with appropriate information matrices.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef pairwise_registration(source, target):\n    print(\"Apply point-to-plane ICP\")\n    icp_coarse = o3d.pipelines.registration.registration_icp(\n        source, target, max_correspondence_distance_coarse, np.identity(4),\n        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n    icp_fine = o3d.pipelines.registration.registration_icp(\n        source, target, max_correspondence_distance_fine,\n        icp_coarse.transformation,\n        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n    transformation_icp = icp_fine.transformation\n    information_icp = o3d.pipelines.registration.get_information_matrix_from_point_clouds(\n        source, target, max_correspondence_distance_fine,\n        icp_fine.transformation)\n    return transformation_icp, information_icp\n\n\ndef full_registration(pcds, max_correspondence_distance_coarse,\n                      max_correspondence_distance_fine):\n    pose_graph = o3d.pipelines.registration.PoseGraph()\n    odometry = np.identity(4)\n    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n    n_pcds = len(pcds)\n    for source_id in range(n_pcds):\n        for target_id in range(source_id + 1, n_pcds):\n            transformation_icp, information_icp = pairwise_registration(\n                pcds[source_id], pcds[target_id])\n            print(\"Build o3d.pipelines.registration.PoseGraph\")\n            if target_id == source_id + 1:  # odometry case\n                odometry = np.dot(transformation_icp, odometry)\n                pose_graph.nodes.append(\n                    o3d.pipelines.registration.PoseGraphNode(\n                        np.linalg.inv(odometry)))\n                pose_graph.edges.append(\n                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n                                                             target_id,\n                                                             transformation_icp,\n                                                             information_icp,\n                                                             uncertain=False))\n            else:  # loop closure case\n                pose_graph.edges.append(\n                    o3d.pipelines.registration.PoseGraphEdge(source_id,\n                                                             target_id,\n                                                             transformation_icp,\n                                                             information_icp,\n                                                             uncertain=True))\n    return pose_graph\n```\n\n----------------------------------------\n\nTITLE: Normal Estimation for Point Cloud in Open3D\nDESCRIPTION: Estimates normal vectors for each point in the downsampled point cloud using KDTree neighborhood search. The algorithm uses covariance analysis with a 10cm search radius and a maximum of 30 neighbors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Recompute the normal of the downsampled point cloud\")\ndownpcd.estimate_normals(\n    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\no3d.visualization.draw_geometries([downpcd],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024],\n                                  point_show_normal=True)\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing Geometric Primitives with Open3D in Python\nDESCRIPTION: Demonstrates the creation of geometric primitives (box, sphere, cylinder) using Open3D. Each primitive is assigned a different color, and normals are computed for Phong shading. A coordinate frame is also created for reference.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/visualization.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Let's define some primitives\")\nmesh_box = o3d.geometry.TriangleMesh.create_box(width=1.0,\n                                                height=1.0,\n                                                depth=1.0)\nmesh_box.compute_vertex_normals()\nmesh_box.paint_uniform_color([0.9, 0.1, 0.1])\nmesh_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=1.0)\nmesh_sphere.compute_vertex_normals()\nmesh_sphere.paint_uniform_color([0.1, 0.1, 0.7])\nmesh_cylinder = o3d.geometry.TriangleMesh.create_cylinder(radius=0.3,\n                                                          height=4.0)\nmesh_cylinder.compute_vertex_normals()\nmesh_cylinder.paint_uniform_color([0.1, 0.9, 0.1])\nmesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(\n    size=0.6, origin=[-2, -2, -2])\n```\n\n----------------------------------------\n\nTITLE: Preparing Dataset for Global Registration in Open3D\nDESCRIPTION: Loads source and target point clouds, applies initial transformation, and prepares the dataset for global registration by downsampling and computing features.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_dataset(voxel_size):\n    print(\":: Load two point clouds and disturb initial pose.\")\n\n    demo_icp_pcds = o3d.data.DemoICPPointClouds()\n    source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n    target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n    source.transform(trans_init)\n    draw_registration_result(source, target, np.identity(4))\n\n    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n    return source, target, source_down, target_down, source_fpfh, target_fpfh\n```\n\n----------------------------------------\n\nTITLE: Loading Point Cloud Data and Initial Transformation\nDESCRIPTION: Loads source and target point clouds from demo data files and defines an initial transformation matrix for registration. Then calls the visualization function to display the point clouds with the initial transformation applied.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/robust_kernels.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndemo_icp_pcds = o3d.data.DemoICPPointClouds()\nsource = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\ntarget = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\ntrans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n                         [-0.139, 0.967, -0.215, 0.7],\n                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\ndraw_registration_result(source, target, trans_init)\n```\n\n----------------------------------------\n\nTITLE: Implementing Voxel Carving in Open3D\nDESCRIPTION: This extensive code snippet implements voxel carving in Open3D. It includes helper functions for camera positioning, preprocessing, and the main voxel carving function that uses depth maps or silhouettes to carve a voxel grid.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/voxelization.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef xyz_spherical(xyz):\n    x = xyz[0]\n    y = xyz[1]\n    z = xyz[2]\n    r = np.sqrt(x * x + y * y + z * z)\n    r_x = np.arccos(y / r)\n    r_y = np.arctan2(z, x)\n    return [r, r_x, r_y]\n\n\ndef get_rotation_matrix(r_x, r_y):\n    rot_x = np.asarray([[1, 0, 0], [0, np.cos(r_x), -np.sin(r_x)],\n                        [0, np.sin(r_x), np.cos(r_x)]])\n    rot_y = np.asarray([[np.cos(r_y), 0, np.sin(r_y)], [0, 1, 0],\n                        [-np.sin(r_y), 0, np.cos(r_y)]])\n    return rot_y.dot(rot_x)\n\n\ndef get_extrinsic(xyz):\n    rvec = xyz_spherical(xyz)\n    r = get_rotation_matrix(rvec[1], rvec[2])\n    t = np.asarray([0, 0, 2]).transpose()\n    trans = np.eye(4)\n    trans[:3, :3] = r\n    trans[:3, 3] = t\n    return trans\n\n\ndef preprocess(model):\n    min_bound = model.get_min_bound()\n    max_bound = model.get_max_bound()\n    center = min_bound + (max_bound - min_bound) / 2.0\n    scale = np.linalg.norm(max_bound - min_bound) / 2.0\n    vertices = np.asarray(model.vertices)\n    vertices -= center\n    model.vertices = o3d.utility.Vector3dVector(vertices / scale)\n    return model\n\n\ndef voxel_carving(mesh,\n                  cubic_size,\n                  voxel_resolution,\n                  w=300,\n                  h=300,\n                  use_depth=True,\n                  surface_method='pointcloud'):\n    mesh.compute_vertex_normals()\n    camera_sphere = o3d.geometry.TriangleMesh.create_sphere()\n\n    # setup dense voxel grid\n    voxel_carving = o3d.geometry.VoxelGrid.create_dense(\n        width=cubic_size,\n        height=cubic_size,\n        depth=cubic_size,\n        voxel_size=cubic_size / voxel_resolution,\n        origin=[-cubic_size / 2.0, -cubic_size / 2.0, -cubic_size / 2.0],\n        color=[1.0, 0.7, 0.0])\n\n    # rescale geometry\n    camera_sphere = preprocess(camera_sphere)\n    mesh = preprocess(mesh)\n\n    # setup visualizer to render depthmaps\n    vis = o3d.visualization.Visualizer()\n    vis.create_window(width=w, height=h, visible=False)\n    vis.add_geometry(mesh)\n    vis.get_render_option().mesh_show_back_face = True\n    ctr = vis.get_view_control()\n    param = ctr.convert_to_pinhole_camera_parameters()\n\n    # carve voxel grid\n    pcd_agg = o3d.geometry.PointCloud()\n    centers_pts = np.zeros((len(camera_sphere.vertices), 3))\n    for cid, xyz in enumerate(camera_sphere.vertices):\n        # get new camera pose\n        trans = get_extrinsic(xyz)\n        param.extrinsic = trans\n        c = np.linalg.inv(trans).dot(np.asarray([0, 0, 0, 1]).transpose())\n        centers_pts[cid, :] = c[:3]\n        ctr.convert_from_pinhole_camera_parameters(param)\n\n        # capture depth image and make a point cloud\n        vis.poll_events()\n        vis.update_renderer()\n        depth = vis.capture_depth_float_buffer(False)\n        pcd_agg += o3d.geometry.PointCloud.create_from_depth_image(\n            o3d.geometry.Image(depth),\n            param.intrinsic,\n            param.extrinsic,\n            depth_scale=1)\n\n        # depth map carving method\n        if use_depth:\n            voxel_carving.carve_depth_map(o3d.geometry.Image(depth), param)\n        else:\n            voxel_carving.carve_silhouette(o3d.geometry.Image(depth), param)\n        print(\"Carve view %03d/%03d\" % (cid + 1, len(camera_sphere.vertices)))\n    vis.destroy_window()\n\n    # add voxel grid survace\n    print('Surface voxel grid from %s' % surface_method)\n    if surface_method == 'pointcloud':\n        voxel_surface = o3d.geometry.VoxelGrid.create_from_point_cloud_within_bounds(\n            pcd_agg,\n            voxel_size=cubic_size / voxel_resolution,\n            min_bound=(-cubic_size / 2, -cubic_size / 2, -cubic_size / 2),\n            max_bound=(cubic_size / 2, cubic_size / 2, cubic_size / 2))\n    elif surface_method == 'mesh':\n        voxel_surface = o3d.geometry.VoxelGrid.create_from_triangle_mesh_within_bounds(\n            mesh,\n            voxel_size=cubic_size / voxel_resolution,\n            min_bound=(-cubic_size / 2, -cubic_size / 2, -cubic_size / 2),\n            max_bound=(cubic_size / 2, cubic_size / 2, cubic_size / 2))\n    else:\n        raise Exception('invalid surface method')\n    voxel_carving_surface = voxel_surface + voxel_carving\n\n    return voxel_carving_surface, voxel_carving, voxel_surface\n```\n\n----------------------------------------\n\nTITLE: Executing RANSAC-based Global Registration in Open3D\nDESCRIPTION: Implements RANSAC-based global registration using Open3D. It sets up correspondence checkers, transformation estimation, and RANSAC convergence criteria for robust point cloud alignment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef execute_global_registration(source_down, target_down, source_fpfh,\n                                target_fpfh, voxel_size):\n    distance_threshold = voxel_size * 1.5\n    print(\":: RANSAC registration on downsampled point clouds.\")\n    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n        source_down, target_down, source_fpfh, target_fpfh, True,\n        distance_threshold,\n        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n        3, [\n            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n                0.9),\n            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n                distance_threshold)\n        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n    return result\n```\n\n----------------------------------------\n\nTITLE: Checking Mesh Properties in Open3D\nDESCRIPTION: This function checks various properties of a mesh, including edge manifold, vertex manifold, self-intersection, watertightness, and orientability. It visualizes non-manifold edges, boundary edges, and self-intersecting triangles.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef check_properties(name, mesh):\n    mesh.compute_vertex_normals()\n\n    edge_manifold = mesh.is_edge_manifold(allow_boundary_edges=True)\n    edge_manifold_boundary = mesh.is_edge_manifold(allow_boundary_edges=False)\n    vertex_manifold = mesh.is_vertex_manifold()\n    self_intersecting = mesh.is_self_intersecting()\n    watertight = mesh.is_watertight()\n    orientable = mesh.is_orientable()\n\n    print(name)\n    print(f\"  edge_manifold:          {edge_manifold}\")\n    print(f\"  edge_manifold_boundary: {edge_manifold_boundary}\")\n    print(f\"  vertex_manifold:        {vertex_manifold}\")\n    print(f\"  self_intersecting:      {self_intersecting}\")\n    print(f\"  watertight:             {watertight}\")\n    print(f\"  orientable:             {orientable}\")\n\n    geoms = [mesh]\n    if not edge_manifold:\n        edges = mesh.get_non_manifold_edges(allow_boundary_edges=True)\n        geoms.append(o3dtut.edges_to_lineset(mesh, edges, (1, 0, 0)))\n    if not edge_manifold_boundary:\n        edges = mesh.get_non_manifold_edges(allow_boundary_edges=False)\n        geoms.append(o3dtut.edges_to_lineset(mesh, edges, (0, 1, 0)))\n    if not vertex_manifold:\n        verts = np.asarray(mesh.get_non_manifold_vertices())\n        pcl = o3d.geometry.PointCloud(\n            points=o3d.utility.Vector3dVector(np.asarray(mesh.vertices)[verts]))\n        pcl.paint_uniform_color((0, 0, 1))\n        geoms.append(pcl)\n    if self_intersecting:\n        intersecting_triangles = np.asarray(\n            mesh.get_self_intersecting_triangles())\n        intersecting_triangles = intersecting_triangles[0:1]\n        intersecting_triangles = np.unique(intersecting_triangles)\n        print(\"  # visualize self-intersecting triangles\")\n        triangles = np.asarray(mesh.triangles)[intersecting_triangles]\n        edges = [\n            np.vstack((triangles[:, i], triangles[:, j]))\n            for i, j in [(0, 1), (1, 2), (2, 0)]\n        ]\n        edges = np.hstack(edges).T\n        edges = o3d.utility.Vector2iVector(edges)\n        geoms.append(o3dtut.edges_to_lineset(mesh, edges, (1, 0, 1)))\n    o3d.visualization.draw_geometries(geoms, mesh_show_back_face=True)\n```\n\n----------------------------------------\n\nTITLE: Mesh Simplification using Vertex Clustering in Python with Open3D\nDESCRIPTION: This snippet shows mesh simplification using vertex clustering in Open3D. It loads a bunny mesh, applies simplification with different voxel sizes, and visualizes the results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\nmesh_in = o3d.io.read_triangle_mesh(bunny.path)\nmesh_in.compute_vertex_normals()\n\nprint(\n    f'Input mesh has {len(mesh_in.vertices)} vertices and {len(mesh_in.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh_in])\n\nvoxel_size = max(mesh_in.get_max_bound() - mesh_in.get_min_bound()) / 32\nprint(f'voxel_size = {voxel_size:e}')\nmesh_smp = mesh_in.simplify_vertex_clustering(\n    voxel_size=voxel_size,\n    contraction=o3d.geometry.SimplificationContraction.Average)\nprint(\n    f'Simplified mesh has {len(mesh_smp.vertices)} vertices and {len(mesh_smp.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh_smp])\n\nvoxel_size = max(mesh_in.get_max_bound() - mesh_in.get_min_bound()) / 16\nprint(f'voxel_size = {voxel_size:e}')\nmesh_smp = mesh_in.simplify_vertex_clustering(\n    voxel_size=voxel_size,\n    contraction=o3d.geometry.SimplificationContraction.Average)\nprint(\n    f'Simplified mesh has {len(mesh_smp.vertices)} vertices and {len(mesh_smp.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh_smp])\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Module with Architecture Detection in CMake\nDESCRIPTION: Configures CUDA build options with architecture detection based on CUDA toolkit version. It supports user-provided architectures, common architectures for previous GPU generations, or native architecture detection via nvidia-smi.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_24\n\nLANGUAGE: CMake\nCODE:\n```\n# Build CUDA module by default if CUDA is available\nif(BUILD_CUDA_MODULE)\n    # Suppress nvcc unsupported compiler error for MSVC 2022 with CUDA 11.7 to 12.4\n    # https://forums.developer.nvidia.com/t/problems-with-latest-vs2022-update/294150/12\n    if (MSVC AND MSVC_VERSION VERSION_LESS_EQUAL \"1949\")\n        # Set this before any CUDA checks\n        set(CMAKE_CUDA_FLAGS \"--allow-unsupported-compiler\" CACHE STRING \"Additional flags for nvcc\" FORCE)\n        message(WARNING \"Using --allow-unsupported-compiler flag for nvcc with MSVC 2022. \"\n        \"Set $Env:NVCC_PREPEND_FLAGS='--allow-unsupported-compiler' if nvcc still fails.\")\n    endif()\n    if (CMAKE_CUDA_ARCHITECTURES)\n        message(STATUS \"Building with user-provided CUDA architectures: ${CMAKE_CUDA_ARCHITECTURES}\")\n    else()\n        if(BUILD_COMMON_CUDA_ARCHS)\n            # Build with all supported architectures for previous 2 generations and\n            # M0 (minor=0) architectures for previous generations (including\n            # deprecated). Note that cubin for M0 runs on GPUs with architecture Mx.\n            # This is a tradeoff between binary size / build time and runtime on\n            # older architectures. See:\n            # https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#building-for-maximum-compatibility\n            # https://docs.nvidia.com/cuda/ampere-compatibility-guide/index.html#application-compatibility-on-ampere\n            # https://en.wikipedia.org/wiki/CUDA#GPUs_supported\n            find_package(CUDAToolkit REQUIRED)\n            if(CUDAToolkit_VERSION VERSION_GREATER_EQUAL \"11.8\")\n                set(CMAKE_CUDA_ARCHITECTURES 75-real 80-real 86-real 89-real 90)    # Turing, Ampere, Ada Lovelace, Hopper\n            elseif(CUDAToolkit_VERSION VERSION_GREATER_EQUAL \"11.1\")\n                set(CMAKE_CUDA_ARCHITECTURES 70-real 75-real 80-real 86)            # Volta, Turing, Ampere\n            elseif(CUDAToolkit_VERSION VERSION_GREATER_EQUAL \"11.0\")\n                set(CMAKE_CUDA_ARCHITECTURES 60-real 70-real 72-real 75-real 80)    # Pascal, Volta, Turing, Ampere\n            else()\n                set(CMAKE_CUDA_ARCHITECTURES 30-real 50-real 60-real 70-real 75)    # Kepler, Maxwell, Pascal, Turing\n            endif()\n            message(STATUS \"Using CUDA architectures: ${CMAKE_CUDA_ARCHITECTURES}\")\n        else()\n            execute_process(COMMAND nvidia-smi RESULT_VARIABLE NVIDIA_CHECK OUTPUT_QUIET)\n            if (NVIDIA_CHECK EQUAL 0)\n                message(STATUS \"Building with native CUDA architecture.\")\n                set(CMAKE_CUDA_ARCHITECTURES native)\n            else()\n                message(WARNING \"No CUDA GPU detected. Building with CMake default CUDA architecture.\")\n            endif()\n        endif()\n    endif()\n    enable_language(CUDA)\n    set(CMAKE_CUDA_STANDARD 17)\n    if (CMAKE_CUDA_COMPILER_ID STREQUAL \"NVIDIA\" AND CMAKE_CUDA_COMPILER_VERSION VERSION_LESS \"11.5\")\n        message(FATAL_ERROR \"CUDA 11.4 and older are not supported. Please upgrade to CUDA 11.5 or newer.\")\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: DBSCAN Clustering of Point Cloud Data - Open3D - Python\nDESCRIPTION: Executes DBSCAN clustering on a point cloud to identify density-based clusters, colors each cluster using a matplotlib colormap, and visualizes the result. Parameters eps and min_points control cluster formation. Noise points are indicated by a -1 label. Dependencies: Open3D, matplotlib. Inputs: point cloud, clustering parameters; outputs: labeled and colored point cloud visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nply_point_cloud = o3d.data.PLYPointCloud()\\npcd = o3d.t.io.read_point_cloud(ply_point_cloud.path)\\n\\nwith o3d.utility.VerbosityContextManager(\\n        o3d.utility.VerbosityLevel.Debug) as cm:\\n    labels = pcd.cluster_dbscan(eps=0.02, min_points=10, print_progress=True)\\n\\nmax_label = labels.max().item()\\nprint(f\"point cloud has {max_label + 1} clusters\")\\ncolors = plt.get_cmap(\"tab20\")(\\n        labels.numpy() / (max_label if max_label > 0 else 1))\\ncolors = o3c.Tensor(colors[:, :3], o3c.float32)\\ncolors[labels < 0] = 0\\npcd.point.colors = colors\\no3d.visualization.draw_geometries([pcd.to_legacy()],\\n                                  zoom=0.455,\\n                                  front=[-0.4999, -0.1659, -0.8499],\\n                                  lookat=[2.1813, 2.0619, 2.0999],\\n                                  up=[0.1204, -0.9852, 0.1215])\n```\n\n----------------------------------------\n\nTITLE: Configuring Robust Kernel for ICP Registration in Open3D\nDESCRIPTION: Sets up a robust kernel using TukeyLoss method for point-to-plane ICP registration. Uses standard deviation (sigma) as the kernel parameter to discriminate between inliers and outliers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmu, sigma = 0, 0.1  # mean and standard deviation\nestimation = treg.TransformationEstimationPointToPlane(\n    treg.robust_kernel.RobustKernel(\n        treg.robust_kernel.RobustKernelMethod.TukeyLoss, sigma))\n```\n\n----------------------------------------\n\nTITLE: Integrating RGBD Images into a Scalable TSDF Volume using Open3D in Python\nDESCRIPTION: This code creates a ScalableTSDFVolume and integrates a series of RGBD images into it. It demonstrates setting volume parameters and iterating through camera poses to integrate color and depth data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_integration.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvolume = o3d.pipelines.integration.ScalableTSDFVolume(\n    voxel_length=4.0 / 512.0,\n    sdf_trunc=0.04,\n    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n\nfor i in range(len(camera_poses)):\n    print(\"Integrate {:d}-th image into the volume.\".format(i))\n    color = o3d.io.read_image(redwood_rgbd.color_paths[i])\n    depth = o3d.io.read_image(redwood_rgbd.depth_paths[i])\n    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        color, depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n    volume.integrate(\n        rgbd,\n        o3d.camera.PinholeCameraIntrinsic(\n            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault),\n        np.linalg.inv(camera_poses[i].pose))\n```\n\n----------------------------------------\n\nTITLE: Processing Sample Fountain RGBD Images using Open3D Python\nDESCRIPTION: This Python snippet loads the Sample Fountain RGBD dataset (`o3d.data.SampleFountainRGBDImages`). It reads pairs of color and depth images, creates `o3d.geometry.RGBDImage` objects, reads the camera trajectory log using `o3d.io.read_pinhole_camera_trajectory`, and loads the reconstructed mesh using `o3d.io.read_triangle_mesh`.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_46\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.SampleFountainRGBDImages()\n\nrgbd_images = []\nfor i in range(len(dataset.depth_paths)):\n    depth = o3d.io.read_image(dataset.depth_paths[i])\n    color = o3d.io.read_image(dataset.color_paths[i])\n    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n                       color, depth, convert_rgb_to_intensity=False)\n    rgbd_images.append(rgbd_image)\n\ncamera_trajectory = o3d.io.read_pinhole_camera_trajectory(\n                          dataset.keyframe_poses_log_path)\nmesh = o3d.io.read_triangle_mesh(dataset.reconstruction_path)\n```\n\n----------------------------------------\n\nTITLE: Optimizing Pose Graph for Scene Registration in Python with Open3D\nDESCRIPTION: This function performs global optimization on the pose graph to achieve multiway registration of all fragments. It uses robust kernel for outlier rejection and iterative optimization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/register_fragments.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef optimize_posegraph_for_scene(pose_graph, config):\n    # to align with fragments 1-n\n    pose_graph_new = o3d.pipelines.registration.PoseGraph()\n    pose_graph_new.nodes.append(pose_graph.nodes[0])\n    for edge in pose_graph.edges:\n        if edge.source_node_id != 0:\n            pose_graph_new.edges.append(edge)\n    for node in pose_graph.nodes[1:]:\n        pose_graph_new.nodes.append(\n            o3d.pipelines.registration.PoseGraphNode(\n                np.dot(node.pose, pose_graph.nodes[0].pose)))\n    option = o3d.pipelines.registration.GlobalOptimizationOption(\n        max_correspondence_distance=config[\"voxel_size\"] * 1.4,\n        edge_prune_threshold=0.25,\n        reference_node=0)\n    o3d.pipelines.registration.global_optimization(\n        pose_graph_new,\n        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n        option)\n    return pose_graph_new\n```\n\n----------------------------------------\n\nTITLE: Memory Sharing Between PyTorch and Open3D using DLPack\nDESCRIPTION: Demonstrates how to convert PyTorch tensors to Open3D tensors with memory sharing using DLPack, allowing changes in one to affect the other.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.utils.dlpack\n\n# From PyTorch\nth_a = torch.ones((5,)).cuda(0)\no3_a = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(th_a))\nprint(f\"th_a: {th_a}\")\nprint(f\"o3_a: {o3_a}\")\nprint(\"\")\n\n# Changes to PyTorch array reflects on open3d Tensor and vice versa\nth_a[0] = 100\no3_a[1] = 200\nprint(f\"th_a: {th_a}\")\nprint(f\"o3_a: {o3_a}\")\n```\n\n----------------------------------------\n\nTITLE: Poisson Surface Reconstruction\nDESCRIPTION: Implements Poisson surface reconstruction on the eagle point cloud dataset.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/surface_reconstruction.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint('run Poisson surface reconstruction')\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n        pcd, depth=9)\nprint(mesh)\no3d.visualization.draw_geometries([mesh],\n                                  zoom=0.664,\n                                  front=[-0.4761, -0.4698, -0.7434],\n                                  lookat=[1.8900, 3.2596, 0.9284],\n                                  up=[0.2304, -0.8825, 0.4101])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Registration Results in Open3D\nDESCRIPTION: This function visualizes the alignment of source and target point clouds after registration. It creates copies of the point clouds, colors them differently, applies the transformation, and displays the result using Open3D's visualization tools.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/icp_registration.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef draw_registration_result(source, target, transformation):\n    source_temp = copy.deepcopy(source)\n    target_temp = copy.deepcopy(target)\n    source_temp.paint_uniform_color([1, 0.706, 0])\n    target_temp.paint_uniform_color([0, 0.651, 0.929])\n    source_temp.transform(transformation)\n    o3d.visualization.draw_geometries([source_temp, target_temp],\n                                      zoom=0.4459,\n                                      front=[0.9288, -0.2951, -0.2242],\n                                      lookat=[1.6784, 2.0612, 1.4451],\n                                      up=[-0.3402, -0.9189, -0.1996])\n```\n\n----------------------------------------\n\nTITLE: Integrating RGBD Frames in Open3D Reconstruction System (Python)\nDESCRIPTION: This function reads alignment results, computes pose of each RGBD image in global space, and integrates RGBD images using Open3D's RGBD integration. It processes fragments and frames, updating a TSDF volume and extracting a mesh.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/integrate_scene.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef scalable_integrate_rgb_frames(path_dataset, intrinsic, config):\n    poses = []\n    [color_files, depth_files] = get_rgbd_file_lists(path_dataset)\n    n_files = len(color_files)\n    n_fragments = int(math.ceil(float(n_files) / \n            config['n_frames_per_fragment']))\n    volume = o3d.pipelines.integration.ScalableTSDFVolume(\n        voxel_length=config[\"tsdf_cubic_size\"] / 512.0,\n        sdf_trunc=0.04,\n        color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n\n    pose_graph_fragment = o3d.io.read_pose_graph(\n        join(path_dataset, config[\"template_fragment_posegraph\"] % n_fragments))\n\n    for fragment_id in range(len(pose_graph_fragment.nodes)):\n        pose_graph_rgbd = o3d.io.read_pose_graph(\n            join(path_dataset,\n                 config[\"template_fragment_posegraph_optimized\"] % fragment_id))\n\n        for frame_id in range(len(pose_graph_rgbd.nodes)):\n            frame_id_abs = fragment_id * config['n_frames_per_fragment'] \\\n                    + frame_id\n            print(\"Fragment %03d / %03d :: integrate rgbd frame %d (%d of %d).\" %\n                  (fragment_id, n_fragments - 1, frame_id_abs, frame_id + 1,\n                   len(pose_graph_rgbd.nodes)))\n            color = o3d.io.read_image(color_files[frame_id_abs])\n            depth = o3d.io.read_image(depth_files[frame_id_abs])\n            rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n                color, depth, convert_rgb_to_intensity=False)\n            pose = np.dot(pose_graph_fragment.nodes[fragment_id].pose,\n                          pose_graph_rgbd.nodes[frame_id].pose)\n            volume.integrate(rgbd, intrinsic, np.linalg.inv(pose))\n            poses.append(pose)\n\n    mesh = volume.extract_triangle_mesh()\n    mesh.compute_vertex_normals()\n    if config[\"debug_mode\"]:\n        o3d.visualization.draw_geometries([mesh])\n```\n\n----------------------------------------\n\nTITLE: Removing Small Clusters from Mesh in Python using Open3D\nDESCRIPTION: This snippet shows how to remove small clusters of triangles from a mesh based on the results of connected components analysis in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Show mesh with small clusters removed\")\nmesh_0 = copy.deepcopy(mesh)\ntriangles_to_remove = cluster_n_triangles[triangle_clusters] < 100\nmesh_0.remove_triangles_by_mask(triangles_to_remove)\no3d.visualization.draw_geometries([mesh_0])\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Setting Up Environment for Open3D\nDESCRIPTION: Imports necessary libraries including Open3D, NumPy, and custom modules. Sets up the environment for visualization and tutorial helpers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/colored_pointcloud_registration.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport copy\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Loading Point Clouds and Setting Up Initial Transformation for ICP\nDESCRIPTION: Loads demo point clouds from Open3D data, normalizes color values to float range, and sets up an initial transformation matrix for alignment. This provides the starting point for ICP registration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndemo_icp_pcds = o3d.data.DemoICPPointClouds()\nsource = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[0])\ntarget = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[1])\n\n# For Colored-ICP `colors` attribute must be of the same dtype as `positions` and `normals` attribute.\nsource.point[\"colors\"] = source.point[\"colors\"].to(\n    o3d.core.Dtype.Float32) / 255.0\ntarget.point[\"colors\"] = target.point[\"colors\"].to(\n    o3d.core.Dtype.Float32) / 255.0\n\n# Initial guess transform between the two point-cloud.\n# ICP algorithm requires a good initial alignment to converge efficiently.\ntrans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n                         [-0.139, 0.967, -0.215, 0.7],\n                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n\ndraw_registration_result(source, target, trans_init)\n```\n\n----------------------------------------\n\nTITLE: Creating Tensors from Various Data Sources\nDESCRIPTION: Demonstrates multiple ways to create Open3D tensors from lists, NumPy arrays, and with specific data types and devices.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Tensor from list.\na = o3c.Tensor([0, 1, 2])\nprint(\"Created from list:\\n{}\".format(a))\n\n# Tensor from Numpy.\na = o3c.Tensor(np.array([0, 1, 2]))\nprint(\"\\nCreated from numpy array:\\n{}\".format(a))\n\n# Dtype and inferred from list.\na_float = o3c.Tensor([0.0, 1.0, 2.0])\nprint(\"\\nDefault dtype and device:\\n{}\".format(a_float))\n\n# Specify dtype.\na = o3c.Tensor(np.array([0, 1, 2]), dtype=o3c.Dtype.Float64)\nprint(\"\\nSpecified data type:\\n{}\".format(a))\n\n# Specify device.\na = o3c.Tensor(np.array([0, 1, 2]), device=o3c.Device(\"CUDA:0\"))\nprint(\"\\nSpecified device:\\n{}\".format(a))\n```\n\n----------------------------------------\n\nTITLE: Setting up Multi-scale ICP Parameters\nDESCRIPTION: Configures convergence criteria, correspondence distances, and voxel sizes for multi-scale registration. Includes three levels of refinement with progressively stricter parameters.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ncurrent_transformation = np.identity(4)\n\ncriteria_list = [\n    treg.ICPConvergenceCriteria(relative_fitness=0.0001,\n                                relative_rmse=0.0001,\n                                max_iteration=50),\n    treg.ICPConvergenceCriteria(0.00001, 0.00001, 30),\n    treg.ICPConvergenceCriteria(0.000001, 0.000001, 14)\n]\n\nmax_correspondence_distances = o3d.utility.DoubleVector([0.08, 0.04, 0.02])\n\nvoxel_sizes = o3d.utility.DoubleVector([0.04, 0.02, 0.01])\n```\n\n----------------------------------------\n\nTITLE: Correspondence-based Fast Global Registration in Python\nDESCRIPTION: This code snippet demonstrates how to perform Fast Global Registration using a set of putative correspondences instead of FPFH features. It's useful when a different correspondence frontend is used but FGR is still desired for registration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\no3d.pipelines.registration.registration_fgr_based_on_correspondence(\n        source_down, target_down, correspondence_set,\n        o3d.pipelines.registration.FastGlobalRegistrationOption())\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Open3D Multiway Registration\nDESCRIPTION: Imports necessary libraries and sets up the environment for the tutorial. It includes Open3D for 3D data processing, NumPy for numerical operations, and imports a helper module for visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Transforming and Visualizing Aligned Point Clouds in Open3D\nDESCRIPTION: Applies the optimized transformations to the point clouds and visualizes the result. Each point cloud is transformed using the corresponding pose from the optimized pose graph, resulting in a globally aligned set of point clouds.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Transform points and display\")\nfor point_id in range(len(pcds_down)):\n    print(pose_graph.nodes[point_id].pose)\n    pcds_down[point_id].transform(pose_graph.nodes[point_id].pose)\no3d.visualization.draw_geometries(pcds_down,\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Loading and Displaying a Point Cloud with Open3D\nDESCRIPTION: Demonstrates how to load a sample point cloud using Open3D's data module and the io.read_point_cloud function, then print basic information about it.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/python_interface.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nsample_pcd_data = o3d.data.PCDPointCloud()\npcd = o3d.io.read_point_cloud(sample_pcd_data.path)\nprint(pcd)\n```\n\n----------------------------------------\n\nTITLE: Uniform Downsampling of Point Clouds - Open3D - Python\nDESCRIPTION: This snippet demonstrates uniform downsampling by selecting every nth point from a given point cloud. This can be used for rapid reduction of data size at the expense of structural detail. Dependencies: Open3D; input: point cloud, sampling interval (every_k_points); output: downsampled cloud visualized.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Every 5th points are selected\")\\nuni_down_pcd = pcd.uniform_down_sample(every_k_points=5)\\no3d.visualization.draw_geometries([uni_down_pcd.to_legacy()],\\n                                  zoom=0.3412,\\n                                  front=[0.4257, -0.2125, -0.8795],\\n                                  lookat=[2.6172, 2.0475, 1.532],\\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Reconstruction System\nDESCRIPTION: This JSON snippet provides an example configuration file for the Open3D reconstruction system. It includes various parameters such as dataset path, depth and color image scales, voxel size, and multi-threading options.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/system_overview.rst#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"Open3D reconstruction system tutorial\",\n    \"path_dataset\": \"dataset/tutorial/\",\n    \"path_intrinsic\": \"\",\n    \"n_frames_per_fragment\": 100,\n    \"n_keyframes_per_n_frame\": 5,\n    \"min_depth\": 0.3,\n    \"max_depth\": 3.0,\n    \"voxel_size\": 0.05,\n    \"max_depth_diff\": 0.07,\n    \"depth_scale\": 1000.0,\n    \"depth_max\": 3.0,\n    \"preference_loop_closure_odometry\": 0.1,\n    \"preference_loop_closure_registration\": 5.0,\n    \"tsdf_cubic_size\": 3.0,\n    \"icp_method\": \"color\",\n    \"global_registration\": \"ransac\",\n    \"python_multi_threading\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Alpha Shape Surface Reconstruction\nDESCRIPTION: Demonstrates alpha shape surface reconstruction from a point cloud using the bunny mesh dataset.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/surface_reconstruction.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(bunny.path)\nmesh.compute_vertex_normals()\n\npcd = mesh.sample_points_poisson_disk(750)\no3d.visualization.draw_geometries([pcd])\nalpha = 0.03\nprint(f\"alpha={alpha:.3f}\")\nmesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha)\nmesh.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh], mesh_show_back_face=True)\n```\n\n----------------------------------------\n\nTITLE: Performing Point-to-Plane ICP Registration with Open3D\nDESCRIPTION: Applies point-to-plane ICP registration as a baseline approach. It uses a distance threshold of 0.02 and visualizes the result, showing potential misalignment in planar surfaces.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/colored_pointcloud_registration.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# point to plane ICP\ncurrent_transformation = np.identity(4)\nprint(\"2. Point-to-plane ICP registration is applied on original point\")\nprint(\"   clouds to refine the alignment. Distance threshold 0.02.\")\nresult_icp = o3d.pipelines.registration.registration_icp(\n    source, target, 0.02, current_transformation,\n    o3d.pipelines.registration.TransformationEstimationPointToPlane())\nprint(result_icp)\ndraw_registration_result_original_color(source, target,\n                                        result_icp.transformation)\n```\n\n----------------------------------------\n\nTITLE: Applying Taubin Filter to Smooth Mesh in Open3D\nDESCRIPTION: This code applies the Taubin filter to smooth a mesh while preventing shrinkage. It demonstrates the effect of different numbers of iterations on the smoothing result.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprint('filter with Taubin with 10 iterations')\nmesh_out = mesh_in.filter_smooth_taubin(number_of_iterations=10)\nmesh_out.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh_out])\n\nprint('filter with Taubin with 100 iterations')\nmesh_out = mesh_in.filter_smooth_taubin(number_of_iterations=100)\nmesh_out.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh_out])\n```\n\n----------------------------------------\n\nTITLE: Radius Outlier Removal from Point Cloud\nDESCRIPTION: Applies radius-based outlier removal to the downsampled point cloud. This method removes points that have fewer than a specified number of neighbors within a given radius, using parameters for minimum number of points and search radius.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud_outlier_removal.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Radius oulier removal\")\ncl, ind = voxel_down_pcd.remove_radius_outlier(nb_points=16, radius=0.05)\ndisplay_inlier_outlier(voxel_down_pcd, ind)\n```\n\n----------------------------------------\n\nTITLE: Registering Point Clouds via User Correspondences in Open3D (Python)\nDESCRIPTION: This function performs point cloud registration using user-selected correspondences. It computes an initial transformation based on the correspondences and refines it using ICP (Iterative Closest Point) algorithm.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/interactive_visualization.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef register_via_correspondences(source, target, source_picked_points,\n                                 target_picked_points):\n    corr = np.zeros((len(source_picked_points), 2))\n    corr[:, 0] = source_picked_points\n    corr[:, 1] = target_picked_points\n    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n    trans_init = p2p.compute_transformation(source, target,\n                                            o3d.utility.Vector2iVector(corr))\n    result = o3d.pipelines.registration.registration_icp(\n        source, target, 0.05, trans_init,\n        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n    return result\n```\n\n----------------------------------------\n\nTITLE: Converting Open3D Tensor to PyTorch with DLPack Memory Sharing\nDESCRIPTION: Shows how to convert an Open3D tensor to a PyTorch tensor and back using DLPack, maintaining memory sharing between the tensors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# To PyTorch\no3_a = o3c.Tensor([1, 1, 1, 1, 1], device=o3c.Device(\"CUDA:0\"))\nth_a = torch.utils.dlpack.from_dlpack(o3_a.to_dlpack())\no3_a = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(th_a))\nprint(f\"th_a: {th_a}\")\nprint(f\"o3_a: {o3_a}\")\nprint(\"\")\n\n# Changes to PyTorch array reflects on open3d Tensor and vice versa\nth_a[0] = 100\no3_a[1] = 200\nprint(f\"th_a: {th_a}\")\nprint(f\"o3_a: {o3_a}\")\n```\n\n----------------------------------------\n\nTITLE: Merging and Downsampling Point Clouds with Open3D in Python\nDESCRIPTION: This code snippet demonstrates how to load multiple point clouds, merge them using the '+' operator, apply transformations based on a pose graph, downsample the combined cloud, save it to a file, and visualize the result. It uses Open3D's geometry and visualization modules.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\npcds = load_point_clouds(voxel_size)\npcd_combined = o3d.geometry.PointCloud()\nfor point_id in range(len(pcds)):\n    pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n    pcd_combined += pcds[point_id]\npcd_combined_down = pcd_combined.voxel_down_sample(voxel_size=voxel_size)\no3d.io.write_point_cloud(\"multiway_registration.pcd\", pcd_combined_down)\no3d.visualization.draw_geometries([pcd_combined_down],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Creating Point Clouds in Open3D\nDESCRIPTION: Demonstrates various ways to create point clouds in Open3D, including empty point clouds, from Open3D tensors with different data types, from NumPy arrays, and from Python lists. Also shows error handling for incorrect shapes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Create a empty point cloud on CPU.\npcd = o3d.t.geometry.PointCloud()\nprint(pcd, \"\\n\")\n\n# To create a point cloud on CUDA, specify the device.\n# pcd = o3d.t.geometry.PointCloud(o3c.Device(\"cuda:0\"))\n\n# Create a point cloud from open3d tensor with dtype of float32.\npcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32))\nprint(pcd, \"\\n\")\n\n# Create a point cloud from open3d tensor with dtype of float64.\npcd = o3d.t.geometry.PointCloud(o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float64))\nprint(pcd, \"\\n\")\n\n# Create a point cloud from numpy array. The array will be copied.\npcd = o3d.t.geometry.PointCloud(\n    np.array([[0, 0, 0], [1, 1, 1]], dtype=np.float32))\nprint(pcd, \"\\n\")\n\n# Create a point cloud from python list.\npcd = o3d.t.geometry.PointCloud([[0., 0., 0.], [1., 1., 1.]])\nprint(pcd, \"\\n\")\n\n# Error creation. The point cloud must have shape of (N, 3).\ntry:\n    pcd = o3d.t.geometry.PointCloud(o3c.Tensor([0, 0, 0, 0], o3c.float32))\nexcept:\n    print(f\"Error creation. The point cloud must have shape of (N, 3).\")\n\n```\n\n----------------------------------------\n\nTITLE: Refining Registration with ICP in Open3D\nDESCRIPTION: Implements a function to refine the global registration result using point-to-plane ICP (Iterative Closest Point) algorithm. It applies a stricter distance threshold for fine-tuning the alignment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n    distance_threshold = voxel_size * 0.4\n    print(\":: Point-to-plane ICP registration is applied on original point\")\n    print(\"   clouds to refine the alignment. This time we use a strict\")\n    print(\"   distance threshold %.3f.\" % distance_threshold)\n    result = o3d.pipelines.registration.registration_icp(\n        source, target, distance_threshold, result_ransac.transformation,\n        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n    return result\n```\n\n----------------------------------------\n\nTITLE: Transforming Geometry and Visualizing ICP Iterations in Python\nDESCRIPTION: This code snippet performs ICP registration iterations, updates the geometry, and renders new frames without blocking. It demonstrates the core concept of non-blocking visualization in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/non_blocking_visualization.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor i in range(icp_iteration):\n    reg_p2p = o3d.pipelines.registration.registration_icp(\n        source_down, target_down, threshold, np.identity(4),\n        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=1))\n    source.transform(reg_p2p.transformation)\n    vis.update_geometry(source)\n    vis.poll_events()\n    vis.update_renderer()\n    if save_image:\n        vis.capture_screen_image(\"temp_%04d.jpg\" % i)\n    print(\"ICP iteration #%d\" % (i + 1))\nvis.destroy_window()\n```\n\n----------------------------------------\n\nTITLE: Ball Pivoting Surface Reconstruction Setup\nDESCRIPTION: Prepares point cloud data for ball pivoting algorithm reconstruction.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/surface_reconstruction.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\ngt_mesh = o3d.io.read_triangle_mesh(bunny.path)\ngt_mesh.compute_vertex_normals()\n\npcd = gt_mesh.sample_points_poisson_disk(3000)\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: TSDF Integration with Color Support\nDESCRIPTION: Shows how to perform TSDF integration with optional color information using optimized functions and raw depth images.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/integration.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvoxel_grid.integrate(depth, intrinsic, extrinsic, depth_scale,\n                  depth_max, color, depth_stride)\n\n# Alternatively with default parameters\nvoxel_grid.integrate(depth, intrinsic, extrinsic,\n                  depth_scale=depth_scale,\n                  depth_max=depth_max)\n```\n\n----------------------------------------\n\nTITLE: Memory Sharing Between NumPy and Open3D using from_numpy\nDESCRIPTION: Demonstrates how to create a tensor that shares memory with a NumPy array using from_numpy, so changes in one affect the other.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# From numpy.\nnp_a = np.ones((5,), dtype=np.int32)\no3_a = o3c.Tensor.from_numpy(np_a)\n\n# Changes to numpy array reflects on open3d Tensor and vice versa.\nnp_a[0] += 100\no3_a[1] += 200\nprint(f\"np_a: {np_a}\")\nprint(f\"o3_a: {o3_a}\")\n```\n\n----------------------------------------\n\nTITLE: Estimating and Visualizing Point Cloud Normals\nDESCRIPTION: Demonstrates how to estimate surface normals for a point cloud using nearest neighbor search with specified parameters for radius and maximum neighbors. Shows how to visualize the calculated normals.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Recompute the normal of the downsampled point cloud using hybrid nearest neighbor search with 30 max_nn and radius of 0.1m.\")\ndownpcd.estimate_normals(max_nn=30, radius=0.1)\no3d.visualization.draw_geometries([downpcd.to_legacy()],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024],\n                                  point_show_normal=True)\n```\n\n----------------------------------------\n\nTITLE: Computing RGBD Odometry Using Different Jacobian Terms\nDESCRIPTION: Calculates camera motion between two RGBD image pairs using two different methods: color-based term (Steinbrucker2011) and hybrid term (Park2017). The function returns success status, transformation matrix, and additional information.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_odometry.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\noption = o3d.pipelines.odometry.OdometryOption()\nodo_init = np.identity(4)\nprint(option)\n\n[success_color_term, trans_color_term,\n info] = o3d.pipelines.odometry.compute_rgbd_odometry(\n     source_rgbd_image, target_rgbd_image, pinhole_camera_intrinsic, odo_init,\n     o3d.pipelines.odometry.RGBDOdometryJacobianFromColorTerm(), option)\n[success_hybrid_term, trans_hybrid_term,\n info] = o3d.pipelines.odometry.compute_rgbd_odometry(\n     source_rgbd_image, target_rgbd_image, pinhole_camera_intrinsic, odo_init,\n     o3d.pipelines.odometry.RGBDOdometryJacobianFromHybridTerm(), option)\n```\n\n----------------------------------------\n\nTITLE: Computing and Visualizing Surface Normals in Open3D\nDESCRIPTION: This code computes vertex normals for a mesh and visualizes the result. It uses the compute_vertex_normals() method to calculate normals.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Computing normal and rendering it.\")\nmesh.compute_vertex_normals()\nprint(np.asarray(mesh.triangle_normals))\no3d.visualization.draw_geometries([mesh])\n```\n\n----------------------------------------\n\nTITLE: Voxel Downsampling a Point Cloud\nDESCRIPTION: Demonstrates how to use voxel downsampling to create a uniformly downsampled point cloud. This technique averages points within each voxel grid cell to produce a single representative point per occupied voxel.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Downsample the point cloud with a voxel of 0.03\")\ndownpcd = pcd.voxel_down_sample(voxel_size=0.03)\no3d.visualization.draw_geometries([downpcd.to_legacy()],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Cropping a Mesh in Open3D\nDESCRIPTION: This snippet demonstrates how to crop a mesh by directly manipulating its triangles and triangle normals. It creates a partial mesh containing only the first half of the triangles.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"We make a partial mesh of only the first half triangles.\")\nmesh1 = copy.deepcopy(mesh)\nmesh1.triangles = o3d.utility.Vector3iVector(\n    np.asarray(mesh1.triangles)[:len(mesh1.triangles) // 2, :])\nmesh1.triangle_normals = o3d.utility.Vector3dVector(\n    np.asarray(mesh1.triangle_normals)[:len(mesh1.triangle_normals) // 2, :])\nprint(mesh1.triangles)\no3d.visualization.draw_geometries([mesh1])\n```\n\n----------------------------------------\n\nTITLE: Visualizing PLY Point Cloud with Open3D in Python\nDESCRIPTION: Loads a PLY point cloud file, prints its information, and renders it using Open3D's draw_geometries function. The visualization includes custom zoom, viewpoint, and camera orientation settings.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/visualization.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Load a ply point cloud, print it, and render it\")\nsample_ply_data = o3d.data.PLYPointCloud()\npcd = o3d.io.read_point_cloud(sample_ply_data.path)\no3d.visualization.draw_geometries([pcd],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Scaling 3D Meshes in Open3D\nDESCRIPTION: Demonstrates mesh scaling around its center point. Translates the mesh and then applies scaling relative to its center.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_coordinate_frame()\nmesh_s = copy.deepcopy(mesh).translate((2, 0, 0))\nmesh_s.scale(0.5, center=mesh_s.get_center())\no3d.visualization.draw_geometries([mesh, mesh_s])\n```\n\n----------------------------------------\n\nTITLE: Statistical Outlier Removal from Point Cloud\nDESCRIPTION: Applies statistical outlier removal to the downsampled point cloud. This method removes points that are further away from their neighbors than the average for the point cloud, using parameters for number of neighbors and standard deviation ratio.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud_outlier_removal.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Statistical oulier removal\")\ncl, ind = voxel_down_pcd.remove_statistical_outlier(nb_neighbors=20,\n                                                    std_ratio=2.0)\ndisplay_inlier_outlier(voxel_down_pcd, ind)\n```\n\n----------------------------------------\n\nTITLE: Extracting and Visualizing a Mesh from TSDF Volume using Open3D in Python\nDESCRIPTION: This snippet extracts a triangle mesh from the integrated TSDF volume, computes vertex normals, and visualizes the result using Open3D's visualization module.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_integration.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Extract a triangle mesh from the volume and visualize it.\")\nmesh = volume.extract_triangle_mesh()\nmesh.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh],\n                                  front=[0.5297, -0.1873, -0.8272],\n                                  lookat=[2.0712, 2.0312, 1.7251],\n                                  up=[-0.0558, -0.9809, 0.1864],\n                                  zoom=0.47)\n```\n\n----------------------------------------\n\nTITLE: Applying Average Filter to Smooth Noisy Mesh in Open3D\nDESCRIPTION: This code demonstrates the use of the average filter to smooth a noisy mesh. It applies the filter with different numbers of iterations and visualizes the results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint('create noisy mesh')\nknot_mesh = o3d.data.KnotMesh()\nmesh_in = o3d.io.read_triangle_mesh(knot_mesh.path)\nvertices = np.asarray(mesh_in.vertices)\nnoise = 5\nvertices += np.random.uniform(0, noise, size=vertices.shape)\nmesh_in.vertices = o3d.utility.Vector3dVector(vertices)\nmesh_in.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh_in])\n\nprint('filter with average with 1 iteration')\nmesh_out = mesh_in.filter_smooth_simple(number_of_iterations=1)\nmesh_out.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh_out])\n\nprint('filter with average with 5 iterations')\nmesh_out = mesh_in.filter_smooth_simple(number_of_iterations=5)\nmesh_out.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh_out])\n```\n\n----------------------------------------\n\nTITLE: Optimizing the Pose Graph with Levenberg-Marquardt in Open3D\nDESCRIPTION: Optimizes the pose graph using the Levenberg-Marquardt method. The optimization adjusts the transformations to minimize the overall alignment error while considering the reliability of different edges (odometry vs. loop closure).\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Optimizing PoseGraph ...\")\noption = o3d.pipelines.registration.GlobalOptimizationOption(\n    max_correspondence_distance=max_correspondence_distance_fine,\n    edge_prune_threshold=0.25,\n    reference_node=0)\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    o3d.pipelines.registration.global_optimization(\n        pose_graph,\n        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n        option)\n```\n\n----------------------------------------\n\nTITLE: Main Registration Loop for Scene Fragments in Python with Open3D\nDESCRIPTION: This function orchestrates the entire registration process for scene fragments. It performs pairwise global registration followed by multiway registration using the functions defined earlier.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/register_fragments.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef make_posegraph_for_scene(ply_file_names, config):\n    pose_graph = o3d.pipelines.registration.PoseGraph()\n    odometry = np.identity(4)\n    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n    n_files = len(ply_file_names)\n    for s in range(n_files):\n        for t in range(s + 1, n_files):\n            # odometry\n            if t == s + 1:\n                print(\"Fragment %d - %d\" % (s, t))\n                source = o3d.io.read_point_cloud(ply_file_names[s])\n                target = o3d.io.read_point_cloud(ply_file_names[t])\n                trans_init = np.identity(4)\n                trans_init = compute_initial_registration(s, t, trans_init, config)\n\n                if config[\"python_multi_threading\"] is True:\n                    success = register_point_cloud_pair(\n                        s, t, ply_file_names, pose_graph, config)\n                else:\n                    success = register_point_cloud_pair_single_process(\n                        s, t, ply_file_names, pose_graph, config)\n                if success:\n                    o3d.io.write_pose_graph(\n                        join(config[\"path_dataset\"], config[\"template_global_posegraph\"]),\n                        pose_graph)\n            # loop closure\n            if s + config[\"min_num_loop_closure_edges\"] <= t < s + config[\n                    \"max_num_loop_closure_edges\"]:\n                print(\"Loop closure %d - %d\" % (s, t))\n                if config[\"python_multi_threading\"] is True:\n                    success = register_point_cloud_pair(\n                        s, t, ply_file_names, pose_graph, config)\n                else:\n                    success = register_point_cloud_pair_single_process(\n                        s, t, ply_file_names, pose_graph, config)\n                if success:\n                    o3d.io.write_pose_graph(\n                        join(config[\"path_dataset\"], config[\"template_global_posegraph\"]),\n                        pose_graph)\n    o3d.io.write_pose_graph(\n        join(config[\"path_dataset\"], config[\"template_global_posegraph\"]),\n        pose_graph)\n    return pose_graph\n```\n\n----------------------------------------\n\nTITLE: Performing Hidden Point Removal on Point Cloud Data with Open3D in Python\nDESCRIPTION: This snippet illustrates the hidden point removal algorithm in Open3D. It converts a mesh to a point cloud, estimates dimensions, and applies the algorithm to determine visible points from a given viewpoint without surface reconstruction or normal estimation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Convert mesh to a point cloud and estimate dimensions\")\narmadillo = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo.path)\nmesh.compute_vertex_normals()\n\npcd = mesh.sample_points_poisson_disk(5000)\ndiameter = np.linalg.norm(\n    np.asarray(pcd.get_max_bound()) - np.asarray(pcd.get_min_bound()))\no3d.visualization.draw_geometries([pcd])\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Define parameters used for hidden_point_removal\")\ncamera = [0, 0, diameter]\nradius = diameter * 100\n\nprint(\"Get all points that are visible from given view point\")\n_, pt_map = pcd.hidden_point_removal(camera, radius)\n\nprint(\"Visualize result\")\npcd = pcd.select_by_index(pt_map)\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Computing ISS Keypoints on Armadillo Mesh with Open3D\nDESCRIPTION: Loads an Armadillo mesh, converts it to a point cloud, and computes ISS keypoints using Open3D's built-in function. The code measures and displays the computation time and visualizes both the mesh and detected keypoints.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/iss_keypoint_detector.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Compute ISS Keypoints on ArmadilloMesh\narmadillo = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo.path)\nmesh.compute_vertex_normals()\n\npcd = o3d.geometry.PointCloud()\npcd.points = mesh.vertices\n\ntic = time.time()\nkeypoints = o3d.geometry.keypoint.compute_iss_keypoints(pcd)\ntoc = 1000 * (time.time() - tic)\nprint(\"ISS Computation took {:.0f} [ms]\".format(toc))\n\nmesh.compute_vertex_normals()\nmesh.paint_uniform_color([0.5, 0.5, 0.5])\nkeypoints.paint_uniform_color([1.0, 0.75, 0.0])\no3d.visualization.draw_geometries([keypoints, mesh], front=[0, 0, -1.0])\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D and Setting Up Environment for ICP Registration\nDESCRIPTION: Imports necessary modules from Open3D and sets up the environment for ICP registration. Conditionally imports CUDA or CPU implementation based on device API availability.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport open3d.core as o3c\n\nif o3d.__DEVICE_API__ == 'cuda':\n    import open3d.cuda.pybind.t.pipelines.registration as treg\nelse:\n    import open3d.cpu.pybind.t.pipelines.registration as treg\n\nimport numpy as np\nimport sys\nimport os\nimport time\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Timing and Visualizing Fast Global Registration Results in Python\nDESCRIPTION: This snippet executes the Fast Global Registration function, measures its execution time, prints the result, and visualizes the registration outcome. It uses previously defined source and target point clouds and their FPFH features.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nstart = time.time()\nresult_fast = execute_fast_global_registration(source_down, target_down,\n                                               source_fpfh, target_fpfh,\n                                               voxel_size)\nprint(\"Fast global registration took %.3f sec.\\n\" % (time.time() - start))\nprint(result_fast)\ndraw_registration_result(source_down, target_down, result_fast.transformation)\n```\n\n----------------------------------------\n\nTITLE: Creating Point Cloud with Multiple Attributes using Dictionary\nDESCRIPTION: Shows how to create a point cloud with multiple attributes by using a Python dictionary to map attribute names to tensors. This includes required position data and optional attributes like normals and custom labels.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmap_to_tensors = {}\n\n# - The \"positions\" attribute must be specified.\n# - Common attributes include \"colors\" and \"normals\". \n# - You may also use custom attributes, such as \"labels\".\n# - The value of an attribute could be of any shape and dtype. Its correctness\n#   will only be checked when the attribute is used by some algorithms.\nmap_to_tensors[\"positions\"] = o3c.Tensor([[0, 0, 0], [1, 1, 1]], o3c.float32)\nmap_to_tensors[\"normals\"] = o3c.Tensor([[0, 0, 1], [0, 0, 1]], o3c.float32)\nmap_to_tensors[\"labels\"] = o3c.Tensor([0, 1], o3c.int64)\n\npcd = o3d.t.geometry.PointCloud(map_to_tensors)\nprint(pcd)\n```\n\n----------------------------------------\n\nTITLE: RealSense Camera Capture and Recording (Python)\nDESCRIPTION: Shows how to configure a RealSense camera, capture live RGBD video, and record it to a bag file using the Open3D Python API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nimport json\nimport open3d as o3d\nwith open(config_filename) as cf:\n    rs_cfg = o3d.t.io.RealSenseSensorConfig(json.load(cf))\n\nrs = o3d.t.io.RealSenseSensor()\nrs.init_sensor(rs_cfg, 0, bag_filename)\nrs.start_capture(True)  # true: start recording with capture\nfor fid in range(150):\n    im_rgbd = rs.capture_frame(True, True)  # wait for frames and align them\n    # process im_rgbd.depth and im_rgbd.color\n\nrs.stop_capture()\n```\n\n----------------------------------------\n\nTITLE: Creating Voxel Grid from Point Cloud in Open3D\nDESCRIPTION: This snippet shows how to create a voxel grid from a point cloud using Open3D. It samples points from an Armadillo mesh, scales them, assigns random colors, and creates a voxel grid.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/voxelization.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint('input')\narmadillo = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo.path)\n\nN = 2000\npcd = mesh.sample_points_poisson_disk(N)\n# fit to unit cube\npcd.scale(1 / np.max(pcd.get_max_bound() - pcd.get_min_bound()),\n          center=pcd.get_center())\npcd.colors = o3d.utility.Vector3dVector(np.random.uniform(0, 1, size=(N, 3)))\no3d.visualization.draw_geometries([pcd])\n\nprint('voxelization')\nvoxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd,\n                                                            voxel_size=0.05)\no3d.visualization.draw_geometries([voxel_grid])\n```\n\n----------------------------------------\n\nTITLE: Radius-Based Neighbor Search Using KDTree in Open3D\nDESCRIPTION: Shows how to use search_radius_vector_3d function to find all points within a specified radius (0.2) from the anchor point. These points are colored green for visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/kdtree.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Find its neighbors with distance less than 0.2, and paint them green.\")\n[k, idx, _] = pcd_tree.search_radius_vector_3d(pcd.points[1500], 0.2)\nnp.asarray(pcd.colors)[idx[1:], :] = [0, 1, 0]\n```\n\n----------------------------------------\n\nTITLE: Loading Point Clouds and Initializing Registration in Open3D\nDESCRIPTION: Loads source and target point clouds from files and initializes the registration process with an identity matrix. Visualizes the initial alignment of the point clouds.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/colored_pointcloud_registration.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"1. Load two point clouds and show initial pose\")\ndemo_colored_icp_pcds = o3d.data.DemoColoredICPPointClouds()\nsource = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[0])\ntarget = o3d.io.read_point_cloud(demo_colored_icp_pcds.paths[1])\n\n# draw initial alignment\ncurrent_transformation = np.identity(4)\ndraw_registration_result_original_color(source, target, current_transformation)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Cropped Indices from Cropped Polygon - Open3D - Python\nDESCRIPTION: This snippet retrieves the indices of points in the original point cloud that remain after cropping by a selection polygon volume. The indices are computed using crop_in_polygon and printed. The approach enables further downstream processing of the selected region. Dependencies: Open3D. Inputs include the point cloud and selection polygon volume object; outputs are a tensor of valid indices and a printed summary.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nindices = vol.crop_in_polygon(pcd.to_legacy())\\nprint(f\"Cropped indices length: {len(indices)}\") \n```\n\n----------------------------------------\n\nTITLE: Poisson Disk Sampling on Sphere Mesh in Python using Open3D\nDESCRIPTION: This snippet demonstrates Poisson disk sampling on a sphere mesh using Open3D. It shows two methods: using an initial factor and using a pre-sampled point cloud for elimination.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_sphere()\npcd = mesh.sample_points_poisson_disk(number_of_points=500, init_factor=5)\no3d.visualization.draw_geometries([pcd])\n\npcd = mesh.sample_points_uniformly(number_of_points=2500)\npcd = mesh.sample_points_poisson_disk(number_of_points=500, pcl=pcd)\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Loading Open3D Point Cloud from File and Converting to NumPy\nDESCRIPTION: Shows how to load a point cloud from a PLY file, convert the Open3D PointCloud object back to a NumPy array using np.asarray, and visualize the point cloud using Open3D's visualization tools.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/working_with_numpy.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Load saved point cloud and visualize it\npcd_load = o3d.io.read_point_cloud(\"sync.ply\")\n\n# Convert Open3D.o3d.geometry.PointCloud to numpy array\nxyz_load = np.asarray(pcd_load.points)\nprint('xyz_load')\nprint(xyz_load)\no3d.visualization.draw_geometries([pcd_load])\n```\n\n----------------------------------------\n\nTITLE: Loading Point Clouds and Initial Transformation for ICP\nDESCRIPTION: This snippet loads source and target point clouds from files and sets up an initial transformation matrix. It also defines a threshold for the ICP algorithm and visualizes the initial alignment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/icp_registration.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndemo_icp_pcds = o3d.data.DemoICPPointClouds()\nsource = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\ntarget = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\nthreshold = 0.02\ntrans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n                         [-0.139, 0.967, -0.215, 0.7],\n                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\ndraw_registration_result(source, target, trans_init)\n```\n\n----------------------------------------\n\nTITLE: Extracting Largest Cluster from Mesh in Python using Open3D\nDESCRIPTION: This snippet demonstrates how to extract and visualize the largest connected component from a mesh using the results of connected components analysis in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Show largest cluster\")\nmesh_1 = copy.deepcopy(mesh)\nlargest_cluster_idx = cluster_n_triangles.argmax()\ntriangles_to_remove = triangle_clusters != largest_cluster_idx\nmesh_1.remove_triangles_by_mask(triangles_to_remove)\no3d.visualization.draw_geometries([mesh_1])\n```\n\n----------------------------------------\n\nTITLE: Voxel Downsampling of Point Cloud in Open3D\nDESCRIPTION: Performs uniform downsampling of a point cloud using a voxel grid approach with a voxel size of 0.05. The algorithm buckets points into voxels and generates one point per occupied voxel by averaging.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Downsample the point cloud with a voxel of 0.05\")\ndownpcd = pcd.voxel_down_sample(voxel_size=0.05)\no3d.visualization.draw_geometries([downpcd],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Point-to-Point ICP Registration Implementation\nDESCRIPTION: Implements point-to-point ICP algorithm with configurable parameters including estimation method, convergence criteria, and voxel size for registration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nestimation = treg.TransformationEstimationPointToPoint()\n\nmax_correspondence_distance = 0.02\ninit_source_to_target = trans_init\ncriteria = treg.ICPConvergenceCriteria(relative_fitness=0.0000001,\n                                       relative_rmse=0.0000001,\n                                       max_iteration=30)\nvoxel_size = -1\nsave_loss_log = True\n\nreg_point_to_point = treg.icp(source, target, max_correspondence_distance,\n                              init_source_to_target, estimation, criteria,\n                              voxel_size)\n```\n\n----------------------------------------\n\nTITLE: Visualizing ICP Registration Results with Open3D\nDESCRIPTION: Helper function to visualize the alignment of source and target point clouds. The function clones the input geometries, applies the transformation to the source, and renders them with different colors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef draw_registration_result(source, target, transformation):\n    source_temp = source.clone()\n    target_temp = target.clone()\n\n    source_temp.transform(transformation)\n\n    # This is patched version for tutorial rendering.\n    # Use `draw` function for you application.\n    o3d.visualization.draw_geometries(\n        [source_temp.to_legacy(),\n         target_temp.to_legacy()],\n        zoom=0.4459,\n        front=[0.9288, -0.2951, -0.2242],\n        lookat=[1.6784, 2.0612, 1.4451],\n        up=[-0.3402, -0.9189, -0.1996])\n```\n\n----------------------------------------\n\nTITLE: Setting Up ICP Parameters and Running Vanilla ICP\nDESCRIPTION: Sets up parameters for ICP registration including initial alignment, convergence criteria, and transformation estimation method. Then runs vanilla point-to-plane ICP on the noisy source point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ninit_source_to_target = np.asarray([[0.862, 0.011, -0.507, 0.5],\n                                    [-0.139, 0.967, -0.215, 0.7],\n                                    [0.487, 0.255, 0.835, -1.4],\n                                    [0.0, 0.0, 0.0, 1.0]])\n\ncriteria = treg.ICPConvergenceCriteria(relative_fitness=0.000001,\n                                       relative_rmse=0.000001,\n                                       max_iteration=50)\n\nestimation = treg.TransformationEstimationPointToPlane()\n\nmax_correspondence_distance = 0.02\n\nprint(\"Vanilla point-to-plane ICP, max_correspondence_distance={}:\".format(\n    max_correspondence_distance))\ns = time.time()\n\nreg_point_to_plane = treg.icp(source_noisy, target, max_correspondence_distance,\n                              init_source_to_target, estimation)\n\nicp_time = time.time() - s\n\nprint(\"Time taken by Point-To-Plane ICP: \", icp_time)\nprint(\"Fitness: \", reg_point_to_plane.fitness)\nprint(\"Inlier RMSE: \", reg_point_to_plane.inlier_rmse)\n\ndraw_registration_result(source, target, reg_point_to_plane.transformation)\n```\n\n----------------------------------------\n\nTITLE: Setting Correspondence Distance for Vanilla ICP\nDESCRIPTION: Defines the maximum correspondence distance parameter for vanilla ICP. This is the radius within which the algorithm searches for corresponding points between source and target point clouds.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# For Vanilla ICP (double)\n\n# Search distance for Nearest Neighbour Search [Hybrid-Search is used].\nmax_correspondence_distance = 0.07\n```\n\n----------------------------------------\n\nTITLE: Computing and Visualizing a Distance Field Grid in Open3D\nDESCRIPTION: This snippet demonstrates how to compute a signed distance field for a grid of points and visualize a slice of it using matplotlib.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nxyz_range = np.linspace(min_bound, max_bound, num=32)\n\n# query_points is a [32,32,32,3] array ..\nquery_points = np.stack(np.meshgrid(*xyz_range.T), axis=-1).astype(np.float32)\n\n# signed distance is a [32,32,32] array\nsigned_distance = scene.compute_signed_distance(query_points)\n\n# We can visualize a slice of the distance field directly with matplotlib\nplt.imshow(signed_distance.numpy()[:, :, 15])\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Geometry Cropping in Open3D (Python)\nDESCRIPTION: This function reads a point cloud and demonstrates the interactive cropping feature using draw_geometries_with_editing. It allows users to select and crop regions of the point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/interactive_visualization.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef demo_crop_geometry():\n    print(\"Demo for manual geometry cropping\")\n    print(\"1) Press 'Y' twice to align geometry with negative direction of y-axis\")\n    print(\"2) Press 'K' to lock screen and to switch to selection mode\")\n    print(\"3) Drag for rectangle selection,\")\n    print(\"   or use ctrl + left click for polygon selection\")\n    print(\"4) Press 'C' to get a selected geometry and to save it\")\n    print(\"5) Press 'F' to switch to freeview mode\")\n    pcd = o3d.io.read_point_cloud(\"../../test_data/ICP/cloud_bin_0.pcd\")\n    o3d.visualization.draw_geometries_with_editing([pcd])\n```\n\n----------------------------------------\n\nTITLE: Cropping Point Cloud Using Polygon Volume in Open3D\nDESCRIPTION: Loads a point cloud and a selection polygon volume from a JSON file, then uses the volume to crop the point cloud. This technique allows extracting specific parts of a point cloud based on a predefined region.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Load a polygon volume and use it to crop the original point cloud\")\ndemo_crop_data = o3d.data.DemoCropPointCloud()\npcd = o3d.io.read_point_cloud(demo_crop_data.point_cloud_path)\nvol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)\nchair = vol.crop_point_cloud(pcd)\no3d.visualization.draw_geometries([chair],\n                                  zoom=0.7,\n                                  front=[0.5439, -0.2333, -0.8060],\n                                  lookat=[2.4615, 2.1331, 1.338],\n                                  up=[-0.1781, -0.9708, 0.1608])\n```\n\n----------------------------------------\n\nTITLE: Rigid Color Map Optimization\nDESCRIPTION: Performs rigid optimization of camera poses to improve color mapping quality, with configurable maximum iterations based on CI environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/color_map_optimization.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Run rigid optimization.\nmaximum_iteration = 100 if is_ci else 300\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    mesh, camera_trajectory = o3d.pipelines.color_map.run_rigid_optimizer(\n        mesh, rgbd_images, camera_trajectory,\n        o3d.pipelines.color_map.RigidOptimizerOption(\n            maximum_iteration=maximum_iteration))\n\no3d.visualization.draw_geometries([mesh],\n                                  zoom=0.5399,\n                                  front=[0.0665, -0.1107, -0.9916],\n                                  lookat=[0.7353, 0.6537, 1.0521],\n                                  up=[0.0136, -0.9936, 0.1118])\n```\n\n----------------------------------------\n\nTITLE: Rendering Multiple Geometries with Open3D in Python\nDESCRIPTION: Shows two methods of rendering multiple geometries together: using a list of geometries and using the + operator to combine meshes. Both approaches are demonstrated with the previously created primitives.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/visualization.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(\"We draw a few primitives using collection.\")\no3d.visualization.draw_geometries(\n    [mesh_box, mesh_sphere, mesh_cylinder, mesh_frame])\n\nprint(\"We draw a few primitives using + operator of mesh.\")\no3d.visualization.draw_geometries(\n    [mesh_box + mesh_sphere + mesh_cylinder + mesh_frame])\n```\n\n----------------------------------------\n\nTITLE: Querying Multi-valued Hash Map in Open3D\nDESCRIPTION: Shows how to query specific coordinates from the hash map and access their corresponding color and weight values. Includes handling of valid results using masks.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nquery_coords = o3c.Tensor([[0, 1, 0]], dtype=o3c.int32, device=device)\nbuf_indices, masks = mhashmap.find(query_coords)\n\nvalid_keys = query_coords[masks]\nbuf_indices = buf_indices[masks].to(o3c.int64)\nvalid_colors = mhashmap.value_tensor(0)[buf_indices]\nvalid_weights = mhashmap.value_tensor(1)[buf_indices]\nprint('found coordinates:\\n', valid_keys)\nprint('found colors:\\n', valid_colors)\nprint('found weights:\\n', valid_weights)\n```\n\n----------------------------------------\n\nTITLE: Casting Rays in Open3D RaycastingScene\nDESCRIPTION: Creates and casts two rays in the scene: one that will hit the cube mesh and one that will miss. The rays are defined by 6D vectors with origin and direction.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# We create two rays:\n# The first ray starts at (0.5,0.5,10) and has direction (0,0,-1).\n# The second ray start at (-1,-1,-1) and has direction (0,0,-1).\nrays = o3d.core.Tensor([[0.5, 0.5, 10, 0, 0, -1], [-1, -1, -1, 0, 0, -1]],\n                       dtype=o3d.core.Dtype.Float32)\n\nans = scene.cast_rays(rays)\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Visualization Function for ICP Results\nDESCRIPTION: Defines a custom function to visualize the registration results, overriding the default visualization for better camera positioning.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef draw_registration_result(source, target, transformation):\n    source_temp = source.clone()\n    target_temp = target.clone()\n\n    source_temp.transform(transformation)\n\n    # This is patched version for tutorial rendering.\n    # Use `draw` function for you application.\n    o3d.visualization.draw_geometries(\n        [source_temp.to_legacy(),\n         target_temp.to_legacy()],\n        zoom=0.4459,\n        front=[0.9288, -0.2951, -0.2242],\n        lookat=[1.6784, 2.0612, 1.4451],\n        up=[-0.3402, -0.9189, -0.1996])\n```\n\n----------------------------------------\n\nTITLE: Rotating 3D Meshes in Open3D\nDESCRIPTION: Demonstrates mesh rotation using Euler angles. Creates a rotation matrix and applies it to rotate the mesh around a specified center point.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_coordinate_frame()\nmesh_r = copy.deepcopy(mesh)\nR = mesh.get_rotation_matrix_from_xyz((np.pi / 2, 0, np.pi / 4))\nmesh_r.rotate(R, center=(0, 0, 0))\no3d.visualization.draw_geometries([mesh, mesh_r])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Registration Results with Original Colors in Open3D\nDESCRIPTION: Defines a helper function to visualize the alignment of colored point clouds using their original colors. It creates a copy of the source, applies the transformation, and renders both point clouds.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/colored_pointcloud_registration.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef draw_registration_result_original_color(source, target, transformation):\n    source_temp = copy.deepcopy(source)\n    source_temp.transform(transformation)\n    o3d.visualization.draw_geometries([source_temp, target],\n                                      zoom=0.5,\n                                      front=[-0.2458, -0.8088, 0.5342],\n                                      lookat=[1.7745, 2.2305, 0.9787],\n                                      up=[0.3109, -0.5878, -0.7468])\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Open3D Point Cloud Processing\nDESCRIPTION: Sets up the environment by importing necessary libraries for Open3D point cloud processing, including Open3D, NumPy, Matplotlib, and custom tutorial utilities.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\nimport os\nimport sys\n\n# only needed for tutorial, monkey patches visualization\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Building KDTree from Point Cloud in Open3D\nDESCRIPTION: Loads a sample point cloud, paints it gray, and constructs a KDTree using FLANN implementation to enable efficient nearest neighbor queries for subsequent operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/kdtree.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Testing kdtree in Open3D...\")\nprint(\"Load a point cloud and paint it gray.\")\n\nsample_pcd_data = o3d.data.PCDPointCloud()\npcd = o3d.io.read_point_cloud(sample_pcd_data.path)\npcd.paint_uniform_color([0.5, 0.5, 0.5])\npcd_tree = o3d.geometry.KDTreeFlann(pcd)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Point Cloud Registration Results\nDESCRIPTION: Defines a function to visualize the results of point cloud registration. It creates copies of the source and target point clouds, applies different colors to them, transforms the source cloud, and displays both clouds together.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/robust_kernels.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef draw_registration_result(source, target, transformation):\n    source_temp = copy.deepcopy(source)\n    target_temp = copy.deepcopy(target)\n    source_temp.paint_uniform_color([1, 0.706, 0])\n    target_temp.paint_uniform_color([0, 0.651, 0.929])\n    source_temp.transform(transformation)\n    o3d.visualization.draw_geometries([source_temp, target_temp],\n                                      zoom=0.4459,\n                                      front=[0.9288, -0.2951, -0.2242],\n                                      lookat=[1.6784, 2.0612, 1.4451],\n                                      up=[-0.3402, -0.9189, -0.1996])\n```\n\n----------------------------------------\n\nTITLE: Tensor Views and Memory Sharing through Slicing\nDESCRIPTION: Demonstrates how sliced tensors create views that share memory with the original tensor, so changes in the slice affect the original.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nvals = np.array(range(24)).reshape((2, 3, 4))\na = o3c.Tensor(vals)\n\n# Changes get reflected.\nb = a[:-1, 0:3:2, 2]\nb[0] += 100\nprint(\"b = {}\\n\".format(b))\nprint(\"a = \\n{}\".format(a))\n```\n\n----------------------------------------\n\nTITLE: Converting RGBD Image to Point Cloud with Open3D\nDESCRIPTION: Creates a 3D point cloud from the RGBD image using PrimeSense default camera intrinsic parameters. The point cloud is flipped for better visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n    rgbd_image,\n    o3d.camera.PinholeCameraIntrinsic(\n        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n# Flip it, otherwise the pointcloud will be upside down\npcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Active Entries in an Open3D Hash Map\nDESCRIPTION: A utility function to retrieve and display all active key-value pairs in the hash map using the active buffer indices.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef print_active_entries(hashmap):\n    active_buf_indices = hashmap.active_buf_indices().to(o3c.int64)\n\n    active_keys = hashmap.key_tensor()[active_buf_indices]\n    print('all active keys:\\n', active_keys)\n\n    active_vals = hashmap.value_tensor()[active_buf_indices]\n    print('all active values:\\n', active_vals)\n```\n\n----------------------------------------\n\nTITLE: Processing Lounge RGBD Images using Open3D Python\nDESCRIPTION: This Python snippet loads the Lounge RGBD dataset (`o3d.data.LoungeRGBDImages`). It iterates through the color and depth image paths, reads them, creates `o3d.geometry.RGBDImage` objects for each pair using `create_from_color_and_depth`, and loads the associated reconstructed mesh.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_53\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.LoungeRGBDImages()\n\nrgbd_images = []\nfor i in range(len(dataset.depth_paths)):\n    color_raw = o3d.io.read_image(dataset.color_paths[i])\n    depth_raw = o3d.io.read_image(dataset.depth_paths[i])\n    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n                                               color_raw, depth_raw)\n    rgbd_images.append(rgbd_image)\n\nmesh = o3d.io.read_triangle_mesh(dataset.reconstruction_path)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Voxel Carving Results in Open3D\nDESCRIPTION: This code visualizes the results of voxel carving, showing surface voxels, carved voxels, and the combined voxel grid. It uses Open3D's visualization capabilities.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/voxelization.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"surface voxels\")\nprint(voxel_surface)\no3d.visualization.draw_geometries([voxel_surface])\n\nprint(\"carved voxels\")\nprint(voxel_carving)\no3d.visualization.draw_geometries([voxel_carving])\n\nprint(\"combined voxels (carved + surface)\")\nprint(voxel_grid)\no3d.visualization.draw_geometries([voxel_grid])\n```\n\n----------------------------------------\n\nTITLE: Executing Full Registration to Build a Pose Graph in Open3D\nDESCRIPTION: Performs full registration on the downsampled point clouds using the defined parameters for correspondence distances. The function builds a pose graph with nodes representing point clouds and edges representing transformations between them.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Full registration ...\")\nmax_correspondence_distance_coarse = voxel_size * 15\nmax_correspondence_distance_fine = voxel_size * 1.5\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    pose_graph = full_registration(pcds_down,\n                                   max_correspondence_distance_coarse,\n                                   max_correspondence_distance_fine)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ray Hit Distance as Depth Map\nDESCRIPTION: Uses matplotlib to visualize the ray hit distances as a depth map, displaying the scene from the camera's perspective.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nplt.imshow(ans['t_hit'].numpy())\n```\n\n----------------------------------------\n\nTITLE: Inserting Key-Value Pairs into an Open3D Hash Map\nDESCRIPTION: Shows how to insert a batch of key-value pairs into a hash map. Returns buffer indices and masks indicating successful insertions, handling duplicated keys by inserting only one of them.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Prepare a batch of 7 key/values, each a int64 element\nkeys = o3c.Tensor([[100], [200], [400], [800], [300], [200], [100]],\n                  dtype=o3c.int64,\n                  device=device)\nvals = o3c.Tensor([[1], [2], [4], [8], [3], [2], [1]],\n                  dtype=o3c.int64,\n                  device=device)\nbuf_indices, masks = hashmap.insert(keys, vals)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Point Cloud with Default Parameters\nDESCRIPTION: Demonstrates loading a PLY point cloud dataset and visualizing it using Open3D's Plotly renderer with default parameters.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/draw_plotly.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#draw a point cloud with default parameter\ndataset = o3d.data.PLYPointCloud()\noffice = o3d.io.read_point_cloud(dataset.path)\no3d.visualization.draw_plotly([office])\n```\n\n----------------------------------------\n\nTITLE: Point Cloud Cropping Demo\nDESCRIPTION: Demonstrates point cloud cropping using a selection polygon volume loaded from a JSON file.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_59\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.DemoCropPointCloud()\npcd = o3d.io.read_point_cloud(dataset.point_cloud_path)\nvol = o3d.visualization.read_selection_polygon_volume(dataset.cropped_json_path)\nchair = vol.crop_point_cloud(pcd)\n```\n\n----------------------------------------\n\nTITLE: Reading and Creating RGBD Image from Redwood Dataset\nDESCRIPTION: Loads color and depth images from the Redwood dataset and creates an RGBD image using Open3D. The depth values are stored in millimeters and converted to meters in the resulting RGBD image.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Read Redwood dataset\")\nredwood_rgbd = o3d.data.SampleRedwoodRGBDImages()\ncolor_raw = o3d.io.read_image(redwood_rgbd.color_paths[0])\ndepth_raw = o3d.io.read_image(redwood_rgbd.depth_paths[0])\nrgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n    color_raw, depth_raw)\nprint(rgbd_image)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Primitive Normals from Ray Casting\nDESCRIPTION: Creates a visualization of the primitive normals returned from ray casting, showing the surface orientation at each hit point.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# use abs to avoid negative values\nplt.imshow(np.abs(ans['primitive_normals'].numpy()))\n```\n\n----------------------------------------\n\nTITLE: Visualizing Downsampled Point Clouds in Open3D\nDESCRIPTION: Loads the point clouds with a specified voxel size for downsampling and visualizes them. The visualization displays all point clouds together to show their initial misalignment before registration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nvoxel_size = 0.02\npcds_down = load_point_clouds(voxel_size)\no3d.visualization.draw_geometries(pcds_down,\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Translating 3D Meshes in Open3D\nDESCRIPTION: Demonstrates mesh translation along different axes using the translate() method. Creates copies of a coordinate frame mesh and translates them in x and y directions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_coordinate_frame()\nmesh_tx = copy.deepcopy(mesh).translate((1.3, 0, 0))\nmesh_ty = copy.deepcopy(mesh).translate((0, 1.3, 0))\nprint(f'Center of mesh: {mesh.get_center()}')\nprint(f'Center of mesh tx: {mesh_tx.get_center()}')\nprint(f'Center of mesh ty: {mesh_ty.get_center()}')\no3d.visualization.draw_geometries([mesh, mesh_tx, mesh_ty])\n```\n\n----------------------------------------\n\nTITLE: Robust ICP with TukeyLoss Kernel\nDESCRIPTION: Implements point-to-plane ICP registration with a robust Tukey loss function to handle outliers. The robust kernel's parameter k is set to match the standard deviation of the noise model, effectively distinguishing between inliers and outliers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/robust_kernels.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Robust point-to-plane ICP, threshold={}:\".format(threshold))\nloss = o3d.pipelines.registration.TukeyLoss(k=sigma)\nprint(\"Using robust loss:\", loss)\np2l = o3d.pipelines.registration.TransformationEstimationPointToPlane(loss)\nreg_p2l = o3d.pipelines.registration.registration_icp(source_noisy, target,\n                                                      threshold, trans_init,\n                                                      p2l)\nprint(reg_p2l)\nprint(\"Transformation is:\")\nprint(reg_p2l.transformation)\ndraw_registration_result(source, target, reg_p2l.transformation)\n```\n\n----------------------------------------\n\nTITLE: Computing ISS Keypoints on Stanford Bunny Mesh with Custom Parameters\nDESCRIPTION: Demonstrates computing ISS keypoints on the Stanford Bunny mesh with customized parameters. The code modifies salient_radius, non_max_radius, gamma_21, and gamma_32 to adjust the keypoint detection behavior and uses the helper function to visualize keypoints as spheres.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/iss_keypoint_detector.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Compute ISS Keypoints on Standford BunnyMesh, changing the default parameters\nbunny = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(bunny.path)\nmesh.compute_vertex_normals()\n\npcd = o3d.geometry.PointCloud()\npcd.points = mesh.vertices\n\ntic = time.time()\nkeypoints = o3d.geometry.keypoint.compute_iss_keypoints(pcd,\n                                                        salient_radius=0.005,\n                                                        non_max_radius=0.005,\n                                                        gamma_21=0.5,\n                                                        gamma_32=0.5)\ntoc = 1000 * (time.time() - tic)\nprint(\"ISS Computation took {:.0f} [ms]\".format(toc))\n\nmesh.compute_vertex_normals()\nmesh.paint_uniform_color([0.5, 0.5, 0.5])\no3d.visualization.draw_geometries([keypoints_to_spheres(keypoints), mesh])\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Point Cloud from Ray Casting\nDESCRIPTION: Generates a point cloud from ray casting results by calculating the 3D coordinates of intersection points. This represents what a virtual 3D sensor would capture from the origin of the rays.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nhit = ans['t_hit'].isfinite()\npoints = rays[hit][:,:3] + rays[hit][:,3:]*ans['t_hit'][hit].reshape((-1,1))\npcd = o3d.t.geometry.PointCloud(points)\n# Press Ctrl/Cmd-C in the visualization window to copy the current viewpoint\no3d.visualization.draw_geometries([pcd.to_legacy()], \n                                  front=[0.5, 0.86, 0.125],\n                                  lookat=[0.23, 0.5, 2],\n                                  up=[-0.63, 0.45, -0.63],\n                                  zoom=0.7)\n# o3d.visualization.draw([pcd]) # new API\n```\n\n----------------------------------------\n\nTITLE: Initializing and Inserting Data into Multi-valued Hash Map in Open3D\nDESCRIPTION: Creates a multi-valued hash map to store voxel coordinates mapped to their colors and weights. Demonstrates initialization with multiple value types and insertion of coordinate-color-weight triplets.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmhashmap = o3c.HashMap(capacity,\n                       key_dtype=o3c.int32,\n                       key_element_shape=(3,),\n                       value_dtypes=(o3c.uint8, o3c.float32),\n                       value_element_shapes=((3,), (1,)),\n                       device=device)\nvoxel_coords = o3c.Tensor([[0, 1, 0], [-1, 2, 3], [3, 4, 1]],\n                          dtype=o3c.int32,\n                          device=device)\nvoxel_colors = o3c.Tensor([[0, 255, 0], [255, 255, 0], [255, 0, 0]],\n                          dtype=o3c.uint8,\n                          device=device)\nvoxel_weights = o3c.Tensor([[0.9], [0.1], [0.3]],\n                           dtype=o3c.float32,\n                           device=device)\nmhashmap.insert(voxel_coords, (voxel_colors, voxel_weights))\n```\n\n----------------------------------------\n\nTITLE: Computing Point Cloud Distance and Filtering in Open3D\nDESCRIPTION: Computes distances between two point clouds and uses the distances to filter points. This technique allows removing specific objects from a scene by calculating point distances and applying a threshold-based filter.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Load data\ndemo_crop_data = o3d.data.DemoCropPointCloud()\npcd = o3d.io.read_point_cloud(demo_crop_data.point_cloud_path)\nvol = o3d.visualization.read_selection_polygon_volume(demo_crop_data.cropped_json_path)\nchair = vol.crop_point_cloud(pcd)\n\ndists = pcd.compute_point_cloud_distance(chair)\ndists = np.asarray(dists)\nind = np.where(dists > 0.01)[0]\npcd_without_chair = pcd.select_by_index(ind)\no3d.visualization.draw_geometries([pcd_without_chair],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Sampling Points from Bunny Mesh in Python using Open3D\nDESCRIPTION: This snippet shows how to load a bunny mesh, compute vertex normals, and sample points uniformly from the mesh surface using Open3D. It demonstrates loading external mesh data and visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(bunny.path)\nmesh.compute_vertex_normals()\n\no3d.visualization.draw_geometries([mesh])\npcd = mesh.sample_points_uniformly(number_of_points=500)\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Redwood RGBD Image Components\nDESCRIPTION: Displays the color and depth components of the RGBD image using Matplotlib. The color image is shown as grayscale and the depth image with depth values in meters.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nplt.subplot(1, 2, 1)\nplt.title('Redwood grayscale image')\nplt.imshow(rgbd_image.color)\nplt.subplot(1, 2, 2)\nplt.title('Redwood depth image')\nplt.imshow(rgbd_image.depth)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Configuring Convergence Criteria for Multi-Scale ICP\nDESCRIPTION: Creates a list of convergence criteria for multi-scale ICP. Different criteria are used for each scale, with more permissive thresholds for coarser scales and stricter thresholds for finer scales to optimize performance.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# List of Convergence-Criteria for Multi-Scale ICP:\n\n# We can control `ConvergenceCriteria` of each `scale` individually.\n# We want to keep `relative_fitness` and `relative_rmse` high (more error tolerance)\n# for initial scales, i.e. we will be happy to consider ICP converged, when difference\n# between 2 successive iterations for that scale is smaller than this value.\n# We expect less accuracy (more error tolerance) initial coarse-scale iteration,\n# and want our later scale convergence to be more accurate (less error tolerance).\ncriteria_list = [\n    treg.ICPConvergenceCriteria(relative_fitness=0.0001,\n                                relative_rmse=0.0001,\n                                max_iteration=20),\n    treg.ICPConvergenceCriteria(0.00001, 0.00001, 15),\n    treg.ICPConvergenceCriteria(0.000001, 0.000001, 10)\n]\n```\n\n----------------------------------------\n\nTITLE: Painting Point Clouds Uniformly - Open3D - Python\nDESCRIPTION: This snippet colors all points in a point cloud with a uniform RGB value using Open3D's paint_uniform_color function. The painted cloud is visualized, making it easier to highlight or differentiate point cloud groups visually. Required dependency: Open3D; input: point cloud, RGB color as a 3-element list in range [0,1]; output: colored point cloud and a rendered scene.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Paint point cloud.\")\\npcd.paint_uniform_color([1, 0.706, 0])\\no3d.visualization.draw_geometries([pcd.to_legacy()],\\n                                  zoom=0.7,\\n                                  front=[0.5439, -0.2333, -0.8060],\\n                                  lookat=[2.4615, 2.1331, 1.338],\\n                                  up=[-0.1781, -0.9708, 0.1608])\n```\n\n----------------------------------------\n\nTITLE: Visualizing Registration Results in Open3D\nDESCRIPTION: Defines a helper function to visualize the transformed source point cloud alongside the target point cloud. It applies color coding and sets specific view parameters for consistent visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef draw_registration_result(source, target, transformation):\n    source_temp = copy.deepcopy(source)\n    target_temp = copy.deepcopy(target)\n    source_temp.paint_uniform_color([1, 0.706, 0])\n    target_temp.paint_uniform_color([0, 0.651, 0.929])\n    source_temp.transform(transformation)\n    o3d.visualization.draw_geometries([source_temp, target_temp],\n                                      zoom=0.4559,\n                                      front=[0.6452, -0.3036, -0.7011],\n                                      lookat=[1.9892, 2.0208, 1.8945],\n                                      up=[-0.2779, -0.9482, 0.1556])\n```\n\n----------------------------------------\n\nTITLE: Creating an Integer-to-Integer Hash Map in Open3D\nDESCRIPTION: Demonstrates how to create a simple hash map that maps integers to integers, specifying the data types and element shapes for both keys and values.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nhashmap = o3c.HashMap(capacity,\n                      key_dtype=o3c.int64,\n                      key_element_shape=(1,),\n                      value_dtype=o3c.int64,\n                      value_element_shape=(1,),\n                      device=device)\n```\n\n----------------------------------------\n\nTITLE: Creating Bounding Volumes for Point Clouds in Open3D\nDESCRIPTION: Demonstrates how to create axis-aligned and oriented bounding boxes for a point cloud. These bounding volumes are useful for spatial analysis, collision detection, and visualizing the extent of point cloud objects.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\naabb = chair.get_axis_aligned_bounding_box()\naabb.color = (1, 0, 0)\nobb = chair.get_oriented_bounding_box()\nobb.color = (0, 1, 0)\no3d.visualization.draw_geometries([chair, aabb, obb],\n                                  zoom=0.7,\n                                  front=[0.5439, -0.2333, -0.8060],\n                                  lookat=[2.4615, 2.1331, 1.338],\n                                  up=[-0.1781, -0.9708, 0.1608])\n```\n\n----------------------------------------\n\nTITLE: Creating Spheres to Visualize Keypoints in Open3D\nDESCRIPTION: Defines a helper function that converts keypoints to sphere meshes for better visualization. Each keypoint is represented as a small sphere with uniform color, improving the visual representation in 3D space.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/iss_keypoint_detector.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# This function is only used to make the keypoints look better on the rendering\ndef keypoints_to_spheres(keypoints):\n    spheres = o3d.geometry.TriangleMesh()\n    for keypoint in keypoints.points:\n        sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.001)\n        sphere.translate(keypoint)\n        spheres += sphere\n    spheres.paint_uniform_color([1.0, 0.75, 0.0])\n    return spheres\n```\n\n----------------------------------------\n\nTITLE: Detecting Boundary Points in Point Clouds using Open3D in Python\nDESCRIPTION: This snippet illustrates boundary detection in an unordered point cloud using Open3D's `compute_boundary_points` function, inspired by PCL's algorithm. It analyzes the angles between the normals of a point and its neighbors within a specified hybrid search radius (`radius`) and maximum neighbor count (`max_nn`). Points where the maximum angle exceeds `angle_threshold` are considered boundary points. The function returns a new point cloud containing only the boundary points and a boolean mask indicating boundary points in the original cloud. The code then visualizes the original cloud with the detected boundary points highlighted.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n```python\nply_point_cloud = o3d.data.DemoCropPointCloud()\npcd = o3d.t.io.read_point_cloud(ply_point_cloud.point_cloud_path)\n\nboundarys, mask = pcd.compute_boundary_points(0.02, 30)\n# TODO: not good to get size of points.\nprint(f\"Detect {boundarys.point.positions.shape[0]} bnoundary points from {pcd.point.positions.shape[0]} points.\")\n\nboundarys = boundarys.paint_uniform_color([1.0, 0.0, 0.0])\npcd = pcd.paint_uniform_color([0.6, 0.6, 0.6])\no3d.visualization.draw_geometries([pcd.to_legacy(), boundarys.to_legacy()],\n                                      zoom=0.3412,\n                                      front=[0.3257, -0.2125, -0.8795],\n                                      lookat=[2.6172, 2.0475, 1.532],\n                                      up=[-0.0694, -0.9768, 0.2024])\n```\n```\n\n----------------------------------------\n\nTITLE: Loading Eagle Point Cloud Dataset in Python\nDESCRIPTION: Demonstrates how to load the Eagle colored point cloud dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.EaglePointCloud()\npcd = o3d.io.read_point_cloud(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Creating and Converting Mesh for RaycastingScene\nDESCRIPTION: Loads a box mesh and converts it from legacy Open3D geometry to tensor-based triangle mesh format for use with RaycastingScene.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Load mesh and convert to open3d.t.geometry.TriangleMesh\ncube = o3d.geometry.TriangleMesh.create_box().translate([0, 0, 0])\ncube = o3d.t.geometry.TriangleMesh.from_legacy(cube)\n```\n\n----------------------------------------\n\nTITLE: Loading and Downsampling Point Clouds with Voxel Filter - Open3D - Python\nDESCRIPTION: This snippet demonstrates loading a ply-format point cloud, rendering it, and then performing voxel-based downsampling with a specified voxel size. Downsampling helps reduce point count while preserving structure. Dependencies: Open3D; inputs: path to the .ply file, voxel size parameter; outputs: original and downsampled point clouds visualized for comparison.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Load a ply point cloud, print it, and render it\")\\nsample_pcd_data = o3d.data.PCDPointCloud()\\npcd = o3d.t.io.read_point_cloud(sample_pcd_data.path)\\no3d.visualization.draw_geometries([pcd.to_legacy()],\\n                                  zoom=0.3412,\\n                                  front=[0.4257, -0.2125, -0.8795],\\n                                  lookat=[2.6172, 2.0475, 1.532],\\n                                  up=[-0.0694, -0.9768, 0.2024])\\n\\nprint(\"Downsample the point cloud with a voxel of 0.02\")\\nvoxel_down_pcd = pcd.voxel_down_sample(voxel_size=0.02)\\no3d.visualization.draw_geometries([voxel_down_pcd.to_legacy()],\\n                                  zoom=0.3412,\\n                                  front=[0.4257, -0.2125, -0.8795],\\n                                  lookat=[2.6172, 2.0475, 1.532],\\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: RealSense Camera Capture and Recording (C++)\nDESCRIPTION: Demonstrates how to configure a RealSense camera, capture live RGBD video, and record it to a bag file using the Open3D C++ API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_7\n\nLANGUAGE: C++\nCODE:\n```\n#include <open3d/open3d.hpp>\nopen3d::t::io::RealSenseSensorConfig rs_cfg;\nopen3d::io::ReadIJsonConvertible(config_filename, rs_cfg);\nRealSenseSensor rs;\nrs.InitSensor(rs_cfg, 0, bag_filename);\nrs.StartCapture(true);  // true: start recording with capture\nfor(size_t fid = 0; fid<150; ++fid) {\n    im_rgbd = rs.CaptureFrame(true, true);  // wait for frames and align them\n    // process im_rgbd.depth_ and im_rgbd.color_\n}\nrs.StopCapture();\n```\n\n----------------------------------------\n\nTITLE: Running Open3D Reconstruction System with Default Dataset\nDESCRIPTION: This snippet demonstrates how to run the Open3D reconstruction system using the default 'lounge' dataset from Stanford. It includes flags for making fragments, registering, refining, and integrating the RGBD sequence.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/system_overview.rst#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npython run_system.py --make --register --refine --integrate\n```\n\n----------------------------------------\n\nTITLE: Mesh Subdivision on Knot Mesh in Python using Open3D\nDESCRIPTION: This snippet demonstrates applying Loop subdivision on a knot mesh using Open3D. It loads an external knot mesh, applies subdivision, and visualizes the results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nknot_mesh = o3d.data.KnotMesh()\nmesh = o3d.io.read_triangle_mesh(knot_mesh.path)\nmesh.compute_vertex_normals()\nprint(\n    f'The mesh has {len(mesh.vertices)} vertices and {len(mesh.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh], zoom=0.8, mesh_show_wireframe=True)\nmesh = mesh.subdivide_loop(number_of_iterations=1)\nprint(\n    f'After subdivision it has {len(mesh.vertices)} vertices and {len(mesh.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh], zoom=0.8, mesh_show_wireframe=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Rays for Pinhole Camera Model\nDESCRIPTION: Generates rays for a pinhole camera model to create an image of the scene. The resulting ray tensor has dimensions [height, width, 6] for an image with heightwidth pixels.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nrays = o3d.t.geometry.RaycastingScene.create_rays_pinhole(\n    fov_deg=90,\n    center=[0, 0, 2],\n    eye=[2, 3, 0],\n    up=[0, 1, 0],\n    width_px=640,\n    height_px=480,\n)\n# We can directly pass the rays tensor to the cast_rays function.\nans = scene.cast_rays(rays)\n```\n\n----------------------------------------\n\nTITLE: General Transformation Matrix in Open3D\nDESCRIPTION: Demonstrates using a 4x4 homogeneous transformation matrix to combine rotation and translation in a single operation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_coordinate_frame()\nT = np.eye(4)\nT[:3, :3] = mesh.get_rotation_matrix_from_xyz((0, np.pi / 3, np.pi / 2))\nT[0, 3] = 1\nT[1, 3] = 1.3\nprint(T)\nmesh_t = copy.deepcopy(mesh).transform(T)\no3d.visualization.draw_geometries([mesh, mesh_t])\n```\n\n----------------------------------------\n\nTITLE: Registering RGBD Image Pairs in Python using Open3D\nDESCRIPTION: This function reads a pair of RGBD images and registers the source image to the target image using Open3D's compute_rgbd_odometry function. It handles both adjacent and non-adjacent image pairs, using different initialization methods.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/make_fragments.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef register_one_rgbd_pair(source_rgbd_image, target_rgbd_image,\n                             odo_init=np.identity(4),\n                             method=\"color\"):\n    option = OdometryOption()\n    option.max_depth_diff = config[\"max_depth_diff\"]\n    if method == \"hybrid\":\n        option.depth_diff_max_depth = config[\"odometry_max_depth\"]\n    cur_odo = np.identity(4)\n    for level in range(2):\n        if level == 2:\n            source_rgbd_image = source_rgbd_image.create_pyramid_level(level)\n            target_rgbd_image = target_rgbd_image.create_pyramid_level(level)\n        success_w, trans_w, info = compute_rgbd_odometry(\n            source_rgbd_image, target_rgbd_image, odo_init,\n            RGBDOdometryJacobianFromHybridTerm(), option)\n        success_c, trans_c, info = compute_rgbd_odometry(\n            source_rgbd_image, target_rgbd_image, odo_init,\n            RGBDOdometryJacobianFromColorTerm(), option)\n        if success_w and success_c:\n            if info[\"rmse_w\"] < info[\"rmse_c\"]:\n                if method == \"hybrid\":\n                    cur_odo = trans_w\n                else:\n                    cur_odo = trans_c\n            else:\n                cur_odo = trans_c\n        elif success_w:\n            cur_odo = trans_w\n        elif success_c:\n            cur_odo = trans_c\n        else:\n            return (False, np.identity(4))\n        odo_init = cur_odo\n    return (True, cur_odo)\n```\n\n----------------------------------------\n\nTITLE: Mesh Subdivision using Loop Method in Python with Open3D\nDESCRIPTION: This snippet shows mesh subdivision using the Loop method in Open3D. It creates a sphere mesh, applies Loop subdivision, and visualizes the results, demonstrating smoother surfaces.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_sphere()\nmesh.compute_vertex_normals()\nprint(\n    f'The mesh has {len(mesh.vertices)} vertices and {len(mesh.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh], zoom=0.8, mesh_show_wireframe=True)\nmesh = mesh.subdivide_loop(number_of_iterations=2)\nprint(\n    f'After subdivision it has {len(mesh.vertices)} vertices and {len(mesh.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh], zoom=0.8, mesh_show_wireframe=True)\n```\n\n----------------------------------------\n\nTITLE: Converting SUN RGBD Image to Point Cloud\nDESCRIPTION: Creates and visualizes a 3D point cloud from the SUN dataset RGBD image using default camera parameters.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\npcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n    rgbd_image,\n    o3d.camera.PinholeCameraIntrinsic(\n        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n# Flip it, otherwise the pointcloud will be upside down\npcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Computing Initial Registration between Fragments in Python for Open3D\nDESCRIPTION: This function computes a rough alignment between two fragments. It uses either aggregated RGBD odometry for neighboring fragments or global registration for non-neighboring fragments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/register_fragments.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef compute_initial_registration(s, t, trans_init, config):\n    if t == s + 1:  # odometry case\n        print(\"Using RGBD odometry\")\n        pose_graph_frag = o3d.io.read_pose_graph(\n            join(config[\"path_dataset\"],\n                 config[\"template_fragment_posegraph_optimized\"] % s))\n        n_nodes = len(pose_graph_frag.nodes)\n        trans_init = np.linalg.inv(pose_graph_frag.nodes[n_nodes -\n                                                        1].pose.to_dict())\n        trans_init = np.matmul(pose_graph_frag.nodes[0].pose.to_dict(),\n                               trans_init)\n        trans_init = np.matmul(trans_init, trans_source_to_target)\n    else:  # loop closure case\n        print(\"Using feature matching\")\n        source_down, source_fpfh = preprocess_point_cloud(\n            source, config[\"voxel_size\"])\n        target_down, target_fpfh = preprocess_point_cloud(\n            target, config[\"voxel_size\"])\n        result = register_point_cloud_fpfh(source_down, target_down,\n                                           source_fpfh, target_fpfh, config)\n        trans_init = result.transformation\n    return trans_init\n```\n\n----------------------------------------\n\nTITLE: Converting Open3D Tensor to NumPy with Memory Sharing\nDESCRIPTION: Shows how to convert a tensor to a NumPy array with shared memory using the numpy method, and how to handle CUDA tensors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# To numpy.\no3_a = o3c.Tensor([1, 1, 1, 1, 1], dtype=o3c.Dtype.Int32)\nnp_a = o3_a.numpy()\n\n# Changes to numpy array reflects on open3d Tensor and vice versa.\nnp_a[0] += 100\no3_a[1] += 200\nprint(f\"np_a: {np_a}\")\nprint(f\"o3_a: {o3_a}\")\n\n# For CUDA Tensor, call cpu() before calling numpy().\no3_a = o3c.Tensor([1, 1, 1, 1, 1], device=o3c.Device(\"CUDA:0\"))\nprint(f\"\\no3_a.cpu().numpy(): {o3_a.cpu().numpy()}\")\n```\n\n----------------------------------------\n\nTITLE: Computing the Convex Hull of a Point Cloud - Open3D - Python\nDESCRIPTION: Calculates the convex hull of a given point cloud, returning a triangle mesh. The mesh is converted to a red LineSet and visualized with the original cloud. This operation is based on the Qhull library. Dependencies: Open3D, point cloud mesh input. Outputs: convex hull mesh, red wireframe overlay plot.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\\npcd = o3d.t.io.read_point_cloud(bunny.path)\\n\\nhull = pcd.compute_convex_hull()\\nhull_ls = o3d.geometry.LineSet.create_from_triangle_mesh(hull.to_legacy())\\nhull_ls.paint_uniform_color((1, 0, 0))\\no3d.visualization.draw_geometries([pcd.to_legacy(), hull_ls])\n```\n\n----------------------------------------\n\nTITLE: Creating Voxel Grid from Triangle Mesh in Open3D\nDESCRIPTION: This code demonstrates how to create a voxel grid from a triangle mesh using Open3D. It loads a bunny mesh, scales it, and creates a voxel grid with a specified voxel size.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/voxelization.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint('input')\nbunny = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(bunny.path)\n\n# fit to unit cube\nmesh.scale(1 / np.max(mesh.get_max_bound() - mesh.get_min_bound()),\n           center=mesh.get_center())\no3d.visualization.draw_geometries([mesh])\n\nprint('voxelization')\nvoxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh,\n                                                              voxel_size=0.05)\no3d.visualization.draw_geometries([voxel_grid])\n```\n\n----------------------------------------\n\nTITLE: Printing Active Multi-value Entries in Open3D Hash Map\nDESCRIPTION: Utility function to display all active entries in a multi-valued hash map, including keys and their corresponding values from all value buffers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndef print_active_multivalue_entries(mhashmap):\n    active_buf_indices = mhashmap.active_buf_indices().to(o3c.int64)\n\n    active_keys = mhashmap.key_tensor()[active_buf_indices]\n    print('all active keys:\\n', active_keys)\n\n    n_buffers = len(mhashmap.value_tensors())\n    for i in range(n_buffers):\n        active_val_i = mhashmap.value_tensor(i)[active_buf_indices]\n        print('active value {}\\n:'.format(i), active_val_i)\n\n\nprint_active_multivalue_entries(mhashmap)\n```\n\n----------------------------------------\n\nTITLE: Erasing Keys from an Open3D Hash Map\nDESCRIPTION: Shows how to remove keys from the hash map using the erase operation, which returns masks indicating which keys were successfully erased.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nerase_keys = o3c.Tensor([[100], [1000], [100]], dtype=o3c.int64, device=device)\nmasks = hashmap.erase(erase_keys)\nprint('erase masks:\\n', masks)\nprint('erased keys:\\n', erase_keys[masks])\n```\n\n----------------------------------------\n\nTITLE: Performing Point-to-Point ICP Registration with Open3D\nDESCRIPTION: This snippet demonstrates point-to-point ICP registration using Open3D. It applies the ICP algorithm with default settings and then with a higher number of maximum iterations, showing the improvement in alignment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/icp_registration.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Apply point-to-point ICP\")\nreg_p2p = o3d.pipelines.registration.registration_icp(\n    source, target, threshold, trans_init,\n    o3d.pipelines.registration.TransformationEstimationPointToPoint())\nprint(reg_p2p)\nprint(\"Transformation is:\")\nprint(reg_p2p.transformation)\ndraw_registration_result(source, target, reg_p2p.transformation)\n\nreg_p2p = o3d.pipelines.registration.registration_icp(\n    source, target, threshold, trans_init,\n    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\nprint(reg_p2p)\nprint(\"Transformation is:\")\nprint(reg_p2p.transformation)\ndraw_registration_result(source, target, reg_p2p.transformation)\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Sample NYU RGBD Image using Open3D Python\nDESCRIPTION: This Python snippet loads the Sample NYU RGBD Image dataset (`o3d.data.SampleNYURGBDImage`). It includes a custom function `read_nyu_pgm` to parse the specific PGM format used for NYU depth images. It then uses `matplotlib.image.mpimg` to read the color image, converts both to `o3d.geometry.Image`, and finally creates an `o3d.geometry.RGBDImage` using `create_from_nyu_format`.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_48\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.image as mpimg\nimport re\nimport numpy as np\n\ndef read_nyu_pgm(filename, byteorder='>'):\n    with open(filename, 'rb') as f:\n        buffer = f.read()\n    try:\n        header, width, height, maxval = re.search(\n            b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n    except AttributeError:\n        raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n    img = np.frombuffer(buffer,\n                        dtype=byteorder + 'u2',\n                        count=int(width) * int(height),\n                        offset=len(header)).reshape((int(height), int(width)))\n    img_out = img.astype('u2')\n    return img_out\n\ndataset = o3d.data.SampleNYURGBDImage()\ncolor_raw = mpimg.imread(dataset.color_path)\ndepth_raw = read_nyu_pgm(dataset.depth_path)\ncolor = o3d.geometry.Image(color_raw)\ndepth = o3d.geometry.Image(depth_raw)\nrgbd_image = o3d.geometry.RGBDImage.create_from_nyu_format(\n    color, depth, convert_rgb_to_intensity=False)\n```\n\n----------------------------------------\n\nTITLE: Initializing RaycastingScene with Triangle Mesh\nDESCRIPTION: Creates a RaycastingScene and adds a triangle mesh to it, returning an ID that can be used to identify which mesh is hit by a ray.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create a scene and add the triangle mesh\nscene = o3d.t.geometry.RaycastingScene()\ncube_id = scene.add_triangles(cube)\n```\n\n----------------------------------------\n\nTITLE: Optimizing PoseGraph for Scene Registration\nDESCRIPTION: Performs global optimization of the pose graph using Levenberg-Marquardt optimization. Includes line process weight calculation and edge pruning for robust registration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/refine_registration.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef optimize_posegraph_for_scene(pose_graph, max_correspondence_distance):\n    # to prevent having too many fragments\n    option = o3d.pipelines.registration.GlobalOptimizationOption(\n        max_correspondence_distance=max_correspondence_distance,\n        edge_prune_threshold=0.25,\n        preference_loop_closure=preference_loop_closure,\n        reference_node=0)\n    o3d.pipelines.registration.global_optimization(\n        pose_graph,\n        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n        o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n        option)\n```\n\n----------------------------------------\n\nTITLE: Performing Binary Element-wise Operations on Tensors\nDESCRIPTION: Demonstrates basic arithmetic operations between tensors, including addition, subtraction, multiplication, and division.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\na = o3c.Tensor([1, 1, 1], dtype=o3c.Dtype.Float32)\nb = o3c.Tensor([2, 2, 2], dtype=o3c.Dtype.Float32)\nprint(\"a + b = {}\".format(a + b))\nprint(\"a - b = {}\".format(a - b))\nprint(\"a * b = {}\".format(a * b))\nprint(\"a / b = {}\".format(a / b))\n```\n\n----------------------------------------\n\nTITLE: Sampling Points from Mesh in Python using Open3D\nDESCRIPTION: This snippet demonstrates uniform and Poisson disk sampling of points from a triangle mesh using Open3D. It shows how to create a sphere mesh, sample points uniformly, and visualize the results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_sphere()\nmesh.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh])\npcd = mesh.sample_points_uniformly(number_of_points=500)\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Open3D Global Registration\nDESCRIPTION: Imports necessary libraries and sets up the environment for Open3D global registration examples. It includes monkey patching for visualization and helper functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport copy\nimport time\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Ball Pivoting Algorithm Implementation\nDESCRIPTION: Performs surface reconstruction using the ball pivoting algorithm with multiple radii.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/surface_reconstruction.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nradii = [0.005, 0.01, 0.02, 0.04]\nrec_mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n    pcd, o3d.utility.DoubleVector(radii))\no3d.visualization.draw_geometries([pcd, rec_mesh])\n```\n\n----------------------------------------\n\nTITLE: Implementing Multiscale ICP Registration in Python\nDESCRIPTION: Performs iterative closest point registration at multiple scales using both point geometry and color information to prevent drift. Takes source and target point clouds as input and returns the transformation matrix.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/refine_registration.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef multiscale_icp(source, target, voxel_size, max_iter, config):\n    current_transformation = np.identity(4)\n    for i, scale in enumerate(range(len(max_iter))):  # multi-scale approach\n        iter = max_iter[scale]\n        distance_threshold = config[\"voxel_size\"] * 1.4\n        if config[\"icp_method\"] == \"point_to_point\":\n            result_icp = o3d.pipelines.registration.registration_icp(\n                source, target, distance_threshold, current_transformation,\n                o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n                o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=iter))\n        else:\n            if i == 0:\n                sigma = 1.0\n            elif i == 1:\n                sigma = 2.0\n            else:\n                sigma = 4.0\n            result_icp = o3d.pipelines.registration.registration_colored_icp(\n                source, target, distance_threshold, current_transformation,\n                o3d.pipelines.registration.TransformationEstimationForColoredICP(\n                    lambda_geometric=0.968),\n                o3d.pipelines.registration.ICPConvergenceCriteria(\n                    relative_fitness=1e-6,\n                    relative_rmse=1e-6,\n                    max_iteration=iter))\n        current_transformation = result_icp.transformation\n    return result_icp.transformation\n```\n\n----------------------------------------\n\nTITLE: Visualizing a 3D Mesh in Open3D\nDESCRIPTION: This snippet demonstrates how to visualize a 3D mesh using Open3D's visualization tools. It checks for the presence of vertex normals and colors before rendering.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Try to render a mesh with normals (exist: \" +\n      str(mesh.has_vertex_normals()) + \") and colors (exist: \" +\n      str(mesh.has_vertex_colors()) + \")\")\no3d.visualization.draw_geometries([mesh])\nprint(\"A mesh with no normals and no colors does not look good.\")\n```\n\n----------------------------------------\n\nTITLE: Converting NYU RGBD Image to Point Cloud\nDESCRIPTION: Creates and visualizes a 3D point cloud from the NYU dataset RGBD image using default camera parameters.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n    rgbd_image,\n    o3d.camera.PinholeCameraIntrinsic(\n        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n# Flip it, otherwise the pointcloud will be upside down\npcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Mesh Decimation in Python using Open3D\nDESCRIPTION: This snippet demonstrates mesh decimation using quadric error metrics in Open3D. It simplifies a mesh to a target number of triangles and visualizes the results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nmesh_smp = mesh_in.simplify_quadric_decimation(target_number_of_triangles=6500)\nprint(\n    f'Simplified mesh has {len(mesh_smp.vertices)} vertices and {len(mesh_smp.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh_smp])\n\nmesh_smp = mesh_in.simplify_quadric_decimation(target_number_of_triangles=1700)\nprint(\n    f'Simplified mesh has {len(mesh_smp.vertices)} vertices and {len(mesh_smp.triangles)} triangles'\n)\no3d.visualization.draw_geometries([mesh_smp])\n```\n\n----------------------------------------\n\nTITLE: Converting Voxel Grid to Octree\nDESCRIPTION: Shows the process of creating an octree from a voxel grid representation of point cloud data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/octree.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint('voxelization')\nvoxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd,\n                                                            voxel_size=0.05)\no3d.visualization.draw_geometries([voxel_grid])\n\nprint('octree division')\noctree = o3d.geometry.Octree(max_depth=4)\noctree.create_from_voxel_grid(voxel_grid)\no3d.visualization.draw_geometries([octree])\n```\n\n----------------------------------------\n\nTITLE: Accessing Point Cloud Normal Vectors in Open3D\nDESCRIPTION: Demonstrates how to access the estimated normal vectors from a point cloud object. The normals can be accessed directly from the point cloud object or converted to a NumPy array.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Print a normal vector of the 0th point\")\nprint(downpcd.normals[0])\n```\n\n----------------------------------------\n\nTITLE: Performing Inclusion Test on Voxel Grid in Open3D\nDESCRIPTION: This code demonstrates how to perform an inclusion test on a voxel grid in Open3D. It checks if points from the point cloud are included in the voxel grid.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/voxelization.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nqueries = np.asarray(pcd.points)\noutput = voxel_grid.check_if_included(o3d.utility.Vector3dVector(queries))\nprint(output[:10])\n```\n\n----------------------------------------\n\nTITLE: Processing Sample Fountain RGBD Images using Open3D C++\nDESCRIPTION: This C++ code loads the Sample Fountain RGBD dataset (`open3d::data::SampleFountainRGBDImages`). It iterates through color/depth pairs, creates `geometry::RGBDImage` objects specifying scale and truncation, reads the camera trajectory using `io::ReadPinholeCameraTrajectory`, and loads the reconstructed mesh using `io::CreateMeshFromFile`.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_47\n\nLANGUAGE: cpp\nCODE:\n```\ndata::SampleFountainRGBDImages dataset;\n\nstd::vector<std::shared_ptr<geometry::RGBDImage>> rgbd_images;\nfor(size_t i = 0; i < dataset.GetDepthPaths().size(); ++i) {\n    auto color_raw = io::CreateImageFromFile(dataset.GetColorPaths()[i]);\n    auto depth_raw = io::CreateImageFromFile(dataset.GetDepthPaths()[i]);\n\n    auto rgbd_image = geometry::RGBDImage::CreateFromColorAndDepth(\n            *color_raw, *depth_raw,\n            /*depth_scale =*/1000.0,\n            /*depth_trunc =*/3.0,\n            /*convert_rgb_to_intensity =*/false);\n    rgbd_images.push_back(rgbd_image);\n}\n\ncamera::PinholeCameraTrajectory camera_trajectory;\nio::ReadPinholeCameraTrajectory(dataset.GetKeyframePosesLogPath(),\n                                camera_trajectory);\nauto mesh = io::CreateMeshFromFile(dataset.GetReconstructionPath());\n```\n\n----------------------------------------\n\nTITLE: Reading Camera Intrinsic Parameters from JSON\nDESCRIPTION: Loads camera intrinsic parameters from a JSON file using Open3D's I/O capabilities and displays the intrinsic matrix.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_odometry.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nredwood_rgbd = o3d.data.SampleRedwoodRGBDImages()\n\npinhole_camera_intrinsic = o3d.io.read_pinhole_camera_intrinsic(\n    redwood_rgbd.camera_intrinsic_path)\nprint(pinhole_camera_intrinsic.intrinsic_matrix)\n```\n\n----------------------------------------\n\nTITLE: Viewing Active Entries After Erasure in Open3D Hash Map\nDESCRIPTION: Demonstrates how to check the active entries in the hash map after performing erase operations to verify the changes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint_active_entries(hashmap)\n```\n\n----------------------------------------\n\nTITLE: Getting Help for read_point_cloud Function in Open3D\nDESCRIPTION: Shows how to get detailed documentation about the read_point_cloud function in Open3D's io module, including argument descriptions and return type.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/python_interface.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nhelp(o3d.io.read_point_cloud)\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D and Required Libraries in Python\nDESCRIPTION: This snippet imports Open3D, NumPy, and other necessary libraries for 3D mesh processing. It also sets up the environment for visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport copy\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Processing Sample Redwood RGBD Images using Open3D Python\nDESCRIPTION: This Python code loads the Sample Redwood RGBD dataset using `o3d.data.SampleRedwoodRGBDImages()`. It iterates through the provided color and depth image paths, reads them using `o3d.io.read_image`, creates `o3d.geometry.RGBDImage` objects for each pair, and also loads the pre-computed point cloud reconstruction.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_44\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.SampleRedwoodRGBDImages()\n\nrgbd_images = []\nfor i in range(len(dataset.depth_paths)):\n    color_raw = o3d.io.read_image(dataset.color_paths[i])\n    depth_raw = o3d.io.read_image(dataset.depth_paths[i])\n    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n                                               color_raw, depth_raw)\n    rgbd_images.append(rgbd_image)\n\npcd = o3d.io.read_point_cloud(dataset.reconstruction_path)\n```\n\n----------------------------------------\n\nTITLE: Computing Distance and Occupancy for a Single Point in Open3D\nDESCRIPTION: This snippet demonstrates how to compute unsigned distance, signed distance, and occupancy for a single query point using RaycastingScene.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nquery_point = o3d.core.Tensor([[10, 10, 10]], dtype=o3d.core.Dtype.Float32)\n\n# Compute distance of the query point from the surface\nunsigned_distance = scene.compute_distance(query_point)\nsigned_distance = scene.compute_signed_distance(query_point)\noccupancy = scene.compute_occupancy(query_point)\n\nprint(\"unsigned distance\", unsigned_distance.numpy())\nprint(\"signed_distance\", signed_distance.numpy())\nprint(\"occupancy\", occupancy.numpy())\n```\n\n----------------------------------------\n\nTITLE: Reading and Printing Mesh Information in Open3D\nDESCRIPTION: This code reads a triangle mesh from a PLY file using Open3D, and prints information about its vertices and triangles.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Testing mesh in Open3D...\")\narmadillo_mesh = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo_mesh.path)\n\nknot_mesh = o3d.data.KnotMesh()\nmesh = o3d.io.read_triangle_mesh(knot_mesh.path)\nprint(mesh)\nprint('Vertices:')\nprint(np.asarray(mesh.vertices))\nprint('Triangles:')\nprint(np.asarray(mesh.triangles))\n```\n\n----------------------------------------\n\nTITLE: Generating 3D Point Data Using NumPy and Sinc Function\nDESCRIPTION: Creates a 3D point cloud dataset using NumPy by computing a variant of the sinc function. The code generates a grid of x, y coordinates and calculates z values using the sinc function, normalizes them to the [0,1] range, and combines them into a single array of 3D points.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/working_with_numpy.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Generate some neat n times 3 matrix using a variant of sync function\nx = np.linspace(-3, 3, 401)\nmesh_x, mesh_y = np.meshgrid(x, x)\nz = np.sinc((np.power(mesh_x, 2) + np.power(mesh_y, 2)))\nz_norm = (z - z.min()) / (z.max() - z.min())\nxyz = np.zeros((np.size(mesh_x), 3))\nxyz[:, 0] = np.reshape(mesh_x, -1)\nxyz[:, 1] = np.reshape(mesh_y, -1)\nxyz[:, 2] = np.reshape(z_norm, -1)\nprint('xyz')\nprint(xyz)\n```\n\n----------------------------------------\n\nTITLE: Loading and Downsampling Point Cloud with Voxel Method\nDESCRIPTION: Loads a point cloud from a PCD file, visualizes it, and then downsamples it using the voxel downsample method. The visualization parameters are set to provide a specific view of the point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud_outlier_removal.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Load a ply point cloud, print it, and render it\")\nsample_pcd_data = o3d.data.PCDPointCloud()\npcd = o3d.io.read_point_cloud(sample_pcd_data.path)\no3d.visualization.draw_geometries([pcd],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n\nprint(\"Downsample the point cloud with a voxel of 0.02\")\nvoxel_down_pcd = pcd.voxel_down_sample(voxel_size=0.02)\no3d.visualization.draw_geometries([voxel_down_pcd],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Applying Mesh Properties Check to Various Meshes in Open3D\nDESCRIPTION: This code applies the check_properties function to different types of meshes, including a knot mesh, Mobius strip, and meshes with non-manifold edges and vertices.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nknot_mesh_data = o3d.data.KnotMesh()\nknot_mesh = o3d.io.read_triangle_mesh(knot_mesh_data.path)\ncheck_properties('KnotMesh', knot_mesh)\ncheck_properties('Mobius', o3d.geometry.TriangleMesh.create_mobius(twists=1))\ncheck_properties(\"non-manifold edge\", o3dtut.get_non_manifold_edge_mesh())\ncheck_properties(\"non-manifold vertex\", o3dtut.get_non_manifold_vertex_mesh())\ncheck_properties(\"open box\", o3dtut.get_open_box_mesh())\ncheck_properties(\"intersecting_boxes\", o3dtut.get_intersecting_boxes_mesh())\n```\n\n----------------------------------------\n\nTITLE: Creating a PoseGraph for Fragment Registration in Python using Open3D\nDESCRIPTION: This function builds a pose graph for multiway registration of all RGBD images in a sequence. It creates graph nodes for key frames and adds odometry and loop closure edges to the graph.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/make_fragments.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef make_posegraph_for_fragment(path_dataset, sid, eid, color_files,\n                                depth_files, fragment_id, n_fragments,\n                                intrinsic, with_opencv):\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Error)\n    pose_graph = o3d.pipelines.registration.PoseGraph()\n    trans_odometry = np.identity(4)\n    pose_graph.nodes.append(\n        o3d.pipelines.registration.PoseGraphNode(trans_odometry))\n    for s in range(sid, eid):\n        for t in range(s + 1, eid):\n            # odometry\n            if t == s + 1:\n                print(\n                    \"Fragment %03d / %03d :: RGBD matching between frame : %d and %d\"\n                    % (fragment_id, n_fragments - 1, s, t))\n                [success, trans, info] = register_one_rgbd_pair(\n                    s, t, color_files, depth_files, intrinsic, with_opencv)\n                trans_odometry = np.dot(trans, trans_odometry)\n                trans = trans_odometry\n                pose_graph.nodes.append(\n                    o3d.pipelines.registration.PoseGraphNode(trans))\n                pose_graph.edges.append(\n                    o3d.pipelines.registration.PoseGraphEdge(s - sid,\n                                                             t - sid,\n                                                             trans,\n                                                             info,\n                                                             uncertain=False))\n\n            # keyframe loop closure\n            if s % config['n_keyframes_per_n_frame'] == 0 \\\n                    and t % config['n_keyframes_per_n_frame'] == 0:\n                print(\n                    \"Fragment %03d / %03d :: RGBD matching between frame : %d and %d\"\n                    % (fragment_id, n_fragments - 1, s, t))\n                [success, trans, info] = register_one_rgbd_pair(\n                    s, t, color_files, depth_files, intrinsic, with_opencv)\n                if success:\n                    pose_graph.edges.append(\n                        o3d.pipelines.registration.PoseGraphEdge(\n                            s - sid, t - sid, trans, info, uncertain=True))\n    o3d.io.write_pose_graph(\n        join(path_dataset, config[\"template_fragment_posegraph\"] % fragment_id),\n        pose_graph)\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Info)\n```\n\n----------------------------------------\n\nTITLE: Creating a Complex Scene with Multiple Meshes\nDESCRIPTION: Sets up a more complex scene with multiple objects (cube, torus, sphere) for ray casting, demonstrating how to add multiple meshes to a RaycastingScene.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Create meshes and convert to open3d.t.geometry.TriangleMesh\ncube = o3d.geometry.TriangleMesh.create_box().translate([0, 0, 0])\ncube = o3d.t.geometry.TriangleMesh.from_legacy(cube)\ntorus = o3d.geometry.TriangleMesh.create_torus().translate([0, 0, 2])\ntorus = o3d.t.geometry.TriangleMesh.from_legacy(torus)\nsphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.5).translate(\n    [1, 2, 3])\nsphere = o3d.t.geometry.TriangleMesh.from_legacy(sphere)\n\nscene = o3d.t.geometry.RaycastingScene()\nscene.add_triangles(cube)\nscene.add_triangles(torus)\n_ = scene.add_triangles(sphere)\n```\n\n----------------------------------------\n\nTITLE: K-Nearest Neighbor Search Using KDTree in Open3D\nDESCRIPTION: Demonstrates the use of search_knn_vector_3d function to find the 200 nearest neighbors of the anchor point. The function returns indices of neighboring points which are then colored blue for visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/kdtree.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Find its 200 nearest neighbors, and paint them blue.\")\n[k, idx, _] = pcd_tree.search_knn_vector_3d(pcd.points[1500], 200)\nnp.asarray(pcd.colors)[idx[1:], :] = [0, 0, 1]\n```\n\n----------------------------------------\n\nTITLE: Implementing Octree Traversal Function\nDESCRIPTION: Defines a traversal function for octree nodes with early stopping capability based on point count thresholds.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/octree.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef f_traverse(node, node_info):\n    early_stop = False\n\n    if isinstance(node, o3d.geometry.OctreeInternalNode):\n        if isinstance(node, o3d.geometry.OctreeInternalPointNode):\n            n = 0\n            for child in node.children:\n                if child is not None:\n                    n += 1\n            print(\n                \"{}{}: Internal node at depth {} has {} children and {} points ({})\"\n                .format('    ' * node_info.depth,\n                        node_info.child_index, node_info.depth, n,\n                        len(node.indices), node_info.origin))\n\n            # we only want to process nodes / spatial regions with enough points\n            early_stop = len(node.indices) < 250\n    elif isinstance(node, o3d.geometry.OctreeLeafNode):\n        if isinstance(node, o3d.geometry.OctreePointColorLeafNode):\n            print(\"{}{}: Leaf node at depth {} has {} points with origin {}\"\n                  .format('    ' * node_info.depth, node_info.child_index,\n                         node_info.depth, len(node.indices), node_info.origin))\n    else:\n        raise NotImplementedError('Node type not recognized!')\n\n    # early stopping: if True, traversal of children of the current node will be skipped\n    return early_stop\n```\n\n----------------------------------------\n\nTITLE: Normal Estimation Implementation\nDESCRIPTION: Demonstrates normal estimation and orientation for point clouds without pre-existing normals.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/surface_reconstruction.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\ngt_mesh = o3d.io.read_triangle_mesh(bunny.path)\n\npcd = gt_mesh.sample_points_poisson_disk(5000)\npcd.normals = o3d.utility.Vector3dVector(np.zeros(\n    (1, 3)))  # invalidate existing normals\n\npcd.estimate_normals()\no3d.visualization.draw_geometries([pcd], point_show_normal=True)\n```\n\n----------------------------------------\n\nTITLE: Tensor Slicing and Indexing Operations\nDESCRIPTION: Shows basic slicing and indexing operations on tensors using integer indices, slice objects, and combinations of both.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nvals = np.array(range(24)).reshape((2, 3, 4))\na = o3c.Tensor(vals)\nprint(\"a = \\n{}\\n\".format(a))\n\n# Indexing __getitem__.\nprint(\"a[1, 2] = {}\\n\".format(a[1, 2]))\n\n# Slicing __getitem__.\nprint(\"a[1:] = \\n{}\\n\".format(a[1:]))\n\n# slice object.\nprint(\"a[:, 0:3:2, :] = \\n{}\\n\".format(a[:, 0:3:2, :]))\n\n# Combined __getitem__\nprint(\"a[:-1, 0:3:2, 2] = \\n{}\\n\".format(a[:-1, 0:3:2, 2]))\n```\n\n----------------------------------------\n\nTITLE: Initializing RaycastingScene with a Triangle Mesh in Open3D\nDESCRIPTION: This code loads an Armadillo mesh, converts it to a tensor-based TriangleMesh, and adds it to a RaycastingScene for distance queries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Load mesh and convert to open3d.t.geometry.TriangleMesh\narmadillo_data = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo_data.path)\nmesh = o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n\n# Create a scene and add the triangle mesh\nscene = o3d.t.geometry.RaycastingScene()\n_ = scene.add_triangles(mesh)  # we do not need the geometry ID for mesh\n```\n\n----------------------------------------\n\nTITLE: Reading and Creating RGBD Image from NYU Dataset\nDESCRIPTION: Loads and processes NYU dataset images using custom methods due to non-standard image formats. Uses the NYU format parser to create an RGBD image.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Read NYU dataset\")\n# Open3D does not support ppm/pgm file yet. Not using o3d.io.read_image here.\n# MathplotImage having some ISSUE with NYU pgm file. Not using imread for pgm.\nnyu_rgbd = o3d.data.SampleNYURGBDImage()\ncolor_raw = mpimg.imread(nyu_rgbd.color_path)\ndepth_raw = read_nyu_pgm(nyu_rgbd.depth_path)\ncolor = o3d.geometry.Image(color_raw)\ndepth = o3d.geometry.Image(depth_raw)\nrgbd_image = o3d.geometry.RGBDImage.create_from_nyu_format(color, depth)\nprint(rgbd_image)\n```\n\n----------------------------------------\n\nTITLE: Processing Bedroom RGBD Images using Open3D Python\nDESCRIPTION: This Python snippet demonstrates loading the Bedroom RGBD dataset using `o3d.data.BedroomRGBDImages()`. It initializes an empty list and starts iterating through the color and depth image paths, reading each pair using `o3d.io.read_image`. The loop body for creating `RGBDImage` objects is incomplete in the source.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_55\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.BedroomRGBDImages()\n\nrgbd_images = []\nfor i in range(len(dataset.depth_paths)):\n    color_raw = o3d.io.read_image(dataset.color_paths[i])\n    depth_raw = o3d.io.read_image(dataset.depth_paths[i])\n```\n\n----------------------------------------\n\nTITLE: Mimicking draw_geometries() with Visualizer Class in Python\nDESCRIPTION: This function demonstrates how to use the Visualizer class to replicate the functionality of draw_geometries(). It creates a visualizer, adds geometry, and runs the visualization loop.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/customized_visualization.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef custom_draw_geometry(pcd):\n    vis = o3d.visualization.Visualizer()\n    vis.create_window()\n    vis.add_geometry(pcd)\n    vis.run()\n    vis.destroy_window()\n```\n\n----------------------------------------\n\nTITLE: Loading Sample TUM RGBD Image using Open3D Python\nDESCRIPTION: This Python snippet loads the Sample TUM RGBD Image dataset with `o3d.data.SampleTUMRGBDImage()`. It reads the color and depth images using `o3d.io.read_image` and creates an `o3d.geometry.RGBDImage` object using the TUM-specific function `create_from_tum_format`.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_51\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.SampleTUMRGBDImage()\ncolor_raw = o3d.io.read_image(dataset.color_path)\ndepth_raw = o3d.io.read_image(dataset.depth_path)\nrgbd_image = o3d.geometry.RGBDImage.create_from_tum_format(\n    color_raw, depth_raw, convert_rgb_to_intensity=False)\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing RGBD Image Pairs\nDESCRIPTION: Reads color and depth image pairs from the Redwood dataset, creates RGBD image objects, and generates a point cloud from the target image using camera intrinsics.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_odometry.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nsource_color = o3d.io.read_image(redwood_rgbd.color_paths[0])\nsource_depth = o3d.io.read_image(redwood_rgbd.depth_paths[0])\ntarget_color = o3d.io.read_image(redwood_rgbd.color_paths[1])\ntarget_depth = o3d.io.read_image(redwood_rgbd.depth_paths[1])\nsource_rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n    source_color, source_depth)\ntarget_rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n    target_color, target_depth)\ntarget_pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n    target_rgbd_image, pinhole_camera_intrinsic)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Setting Up Environment for Open3D\nDESCRIPTION: Sets up the Python environment by importing Open3D, NumPy, and other required libraries, along with adding the tutorial module to the path for visualization helpers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_odometry.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Drawing Line Set with Open3D in Python\nDESCRIPTION: Illustrates how to create and visualize a line set using Open3D. A custom box is drawn by defining points and edges, with each edge colored red. The LineSet is then rendered using draw_geometries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/visualization.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Let's draw a box using o3d.geometry.LineSet.\")\npoints = [\n    [0, 0, 0],\n    [1, 0, 0],\n    [0, 1, 0],\n    [1, 1, 0],\n    [0, 0, 1],\n    [1, 0, 1],\n    [0, 1, 1],\n    [1, 1, 1],\n]\nlines = [\n    [0, 1],\n    [0, 2],\n    [1, 3],\n    [2, 3],\n    [4, 5],\n    [4, 6],\n    [5, 7],\n    [6, 7],\n    [0, 4],\n    [1, 5],\n    [2, 6],\n    [3, 7],\n]\ncolors = [[1, 0, 0] for i in range(len(lines))]\nline_set = o3d.geometry.LineSet(\n    points=o3d.utility.Vector3dVector(points),\n    lines=o3d.utility.Vector2iVector(lines),\n)\nline_set.colors = o3d.utility.Vector3dVector(colors)\no3d.visualization.draw_geometries([line_set])\n```\n\n----------------------------------------\n\nTITLE: Constructing a Voxel Block Grid in Python using Open3D\nDESCRIPTION: This snippet demonstrates how to create a Voxel Block Grid using Open3D's TSDFVoxelGrid class. It sets up the voxel size, block resolution, and block count, and initializes the grid with TSDF, weight, and color properties.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/voxel_block_grid.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvoxel_grid = o3d.t.geometry.TSDFVoxelGrid(\n    voxel_size=3.0 / 512,\n    sdf_trunc=0.04,\n    color_type=o3d.t.geometry.TSDFVoxelGrid.ColorType.RGB8,\n    # (3,) coordinate key -> (16, 16, 16, 1) tsdf, (16, 16, 16, 1) weight, (16, 16, 16, 3) color\n    block_resolution=16,\n    block_count=50000,\n    device=device)\n\n# Voxel size: 3.0 / 512 == 3 (meter) / 512 ~= 5.9mm\n# Block resolution: 16 -> block size ~= 9.4cm\n# Number of block: 50000 -> Up to 50000 * 16^3 ~= 2 billion voxels\n```\n\n----------------------------------------\n\nTITLE: Multiple Alpha Shapes Computation\nDESCRIPTION: Creates multiple alpha shapes from a point cloud using different alpha values and a pre-computed convex hull.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/surface_reconstruction.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntetra_mesh, pt_map = o3d.geometry.TetraMesh.create_from_point_cloud(pcd)\nfor alpha in np.logspace(np.log10(0.5), np.log10(0.01), num=4):\n    print(f\"alpha={alpha:.3f}\")\n    mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(\n        pcd, alpha, tetra_mesh, pt_map)\n    mesh.compute_vertex_normals()\n    o3d.visualization.draw_geometries([mesh], mesh_show_back_face=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Octree from Point Cloud\nDESCRIPTION: Demonstrates creating an octree from a point cloud using the Armadillo mesh sample, including point cloud generation, scaling, and octree conversion.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/octree.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint('input')\nN = 2000\n\narmadillo = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo.path)\npcd = mesh.sample_points_poisson_disk(N)\n# fit to unit cube\npcd.scale(1 / np.max(pcd.get_max_bound() - pcd.get_min_bound()),\n          center=pcd.get_center())\npcd.colors = o3d.utility.Vector3dVector(np.random.uniform(0, 1, size=(N, 3)))\no3d.visualization.draw_geometries([pcd])\n\nprint('octree division')\noctree = o3d.geometry.Octree(max_depth=4)\noctree.convert_from_point_cloud(pcd, size_expand=0.01)\no3d.visualization.draw_geometries([octree])\n```\n\n----------------------------------------\n\nTITLE: Accessing Hash Map Entries Using Buffer Indices\nDESCRIPTION: Shows how to access the inserted key-value pairs using buffer indices, requiring conversion from int32 to int64 for advanced indexing operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbuf_keys = hashmap.key_tensor()\nbuf_vals = hashmap.value_tensor()\nbuf_indices = buf_indices[masks].to(o3c.int64)\nprint('buffer indices: \\n', buf_indices)\n\ninserted_keys = buf_keys[buf_indices]\ninserted_vals = buf_vals[buf_indices]\nprint('inserted keys: \\n', inserted_keys)\nprint('inserted values: \\n', inserted_vals)\n```\n\n----------------------------------------\n\nTITLE: Integrating RGB Frames for Fragment Creation in Python using Open3D\nDESCRIPTION: This function integrates RGB frames to create a colored fragment from an RGBD sequence. It uses Open3D's TSDF volume integration and marching cubes to generate a mesh.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/make_fragments.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef integrate_rgb_frames_for_fragment(color_files, depth_files, fragment_id,\n                                    n_fragments, pose_graph_name, intrinsic,\n                                    config):\n    pose_graph = o3d.io.read_pose_graph(pose_graph_name)\n    volume = o3d.pipelines.integration.ScalableTSDFVolume(\n        voxel_length=config[\"tsdf_cubic_size\"] / 512.0,\n        sdf_trunc=0.04,\n        color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)\n    for i in range(len(pose_graph.nodes)):\n        i_abs = fragment_id * config['n_frames_per_fragment'] + i\n        print(\n            \"Fragment %03d / %03d :: integrate rgbd frame %d (%d of %d).\" %\n            (fragment_id, n_fragments - 1, i_abs, i + 1, len(pose_graph.nodes)))\n        rgbd = read_rgbd_image(color_files[i_abs], depth_files[i_abs], False,\n                               config)\n        pose = pose_graph.nodes[i].pose\n        volume.integrate(rgbd, intrinsic, np.linalg.inv(pose))\n    mesh = volume.extract_triangle_mesh()\n    mesh.compute_vertex_normals()\n    return mesh\n```\n\n----------------------------------------\n\nTITLE: Surface Extraction from TSDF\nDESCRIPTION: Shows how to extract surface points and triangle meshes from the voxel grid using marching cubes algorithm.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/integration.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npcd = voxel_grid.extract_point_cloud()\nmesh = voxel_grid.extract_triangle_mesh()\n\n# Estimate point cloud normals for better visualization\npcd.estimate_normals()\n```\n\n----------------------------------------\n\nTITLE: Activating Keys and Modifying Values In-Place in Open3D Hash Map\nDESCRIPTION: Shows how to activate keys without knowing their values initially, then modify the values in-place afterwards using buffer indices.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nactivate_keys = o3c.Tensor([[1000], [0]], dtype=o3c.int64, device=device)\nbuf_indices, masks = hashmap.activate(activate_keys)\n\nbuf_vals = hashmap.value_tensor()\n# Note the assigned tensor has to be strictly in the shape of (N, 1) due to broadcasting\nbuf_vals[buf_indices[masks].to(o3c.int64)] \\\n    = o3c.Tensor([[10], [0]],\n                 dtype=o3c.int64,\n                 device=device)\n\nprint_active_entries(hashmap)\n```\n\n----------------------------------------\n\nTITLE: Visualizing RGBD Odometry Results with Point Cloud Alignment\nDESCRIPTION: Transforms the source point cloud using the estimated transformation matrices from both odometry methods and visualizes the alignment with the target point cloud. This demonstrates the accuracy of the computed camera motion.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_odometry.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif success_color_term:\n    print(\"Using RGB-D Odometry\")\n    print(trans_color_term)\n    source_pcd_color_term = o3d.geometry.PointCloud.create_from_rgbd_image(\n        source_rgbd_image, pinhole_camera_intrinsic)\n    source_pcd_color_term.transform(trans_color_term)\n    o3d.visualization.draw_geometries([target_pcd, source_pcd_color_term],\n                                      zoom=0.48,\n                                      front=[0.0999, -0.1787, -0.9788],\n                                      lookat=[0.0345, -0.0937, 1.8033],\n                                      up=[-0.0067, -0.9838, 0.1790])\nif success_hybrid_term:\n    print(\"Using Hybrid RGB-D Odometry\")\n    print(trans_hybrid_term)\n    source_pcd_hybrid_term = o3d.geometry.PointCloud.create_from_rgbd_image(\n        source_rgbd_image, pinhole_camera_intrinsic)\n    source_pcd_hybrid_term.transform(trans_hybrid_term)\n    o3d.visualization.draw_geometries([target_pcd, source_pcd_hybrid_term],\n                                      zoom=0.48,\n                                      front=[0.0999, -0.1787, -0.9788],\n                                      lookat=[0.0345, -0.0937, 1.8033],\n                                      up=[-0.0067, -0.9838, 0.1790])\n```\n\n----------------------------------------\n\nTITLE: Nonzero Operations in Open3D Tensors (Python)\nDESCRIPTION: Explains and demonstrates the nonzero operation in Open3D tensors. It shows how to retrieve indices of non-zero elements in both tuple and tensor formats.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\na = o3c.Tensor([[3, 0, 0], [0, 4, 0], [5, 6, 0]])\n\nprint(\"a = \\n{}\\n\".format(a))\nprint(\"a.nonzero() = \\n{}\\n\".format(a.nonzero()))\nprint(\"a.nonzero(as_tuple = 1) = \\n{}\".format(a.nonzero(as_tuple=1)))\n```\n\n----------------------------------------\n\nTITLE: Executing Multi-scale Colored Point Cloud Registration\nDESCRIPTION: Performs the actual colored point cloud registration using multi-scale ICP approach. Includes timing measurement and result visualization. Implementation based on Park et al. ICCV 2017 paper.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# colored pointcloud registration\n# This is implementation of following paper\n# J. Park, Q.-Y. Zhou, V. Koltun,\n# Colored Point Cloud Registration Revisited, ICCV 2017\n\nprint(\"Colored point cloud registration\")\ns = time.time()\n\nreg_multiscale_icp = treg.multi_scale_icp(source, target, voxel_sizes,\n                                          criteria_list,\n                                          max_correspondence_distances,\n                                          init_source_to_target, estimation)\n\nicp_time = time.time() - s\nprint(\"Time taken by Colored ICP: \", icp_time)\nprint(\"Fitness: \", reg_point_to_plane.fitness)\nprint(\"Inlier RMSE: \", reg_point_to_plane.inlier_rmse)\n\ndraw_registration_result(source, target, reg_multiscale_icp.transformation)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Original and Deformed Meshes\nDESCRIPTION: Renders both the original and deformed meshes for comparison. Applies rotation transformation and computes vertex normals for proper visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh_deformation.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint('Original Mesh')\nR = mesh.get_rotation_matrix_from_xyz((0, np.pi, 0))\no3d.visualization.draw_geometries([mesh.rotate(R, center=mesh.get_center())])\nprint('Deformed Mesh')\nmesh_prime.compute_vertex_normals()\no3d.visualization.draw_geometries(\n    [mesh_prime.rotate(R, center=mesh_prime.get_center())])\n```\n\n----------------------------------------\n\nTITLE: Converting Between Integer and Float Types\nDESCRIPTION: Demonstrates type conversion from integer to floating-point types using the 'to' method.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# E.g. int -> float\na = o3c.Tensor([1, 2, 3])\nb = a.to(o3c.Dtype.Float32)\nprint(a)\nprint(b)\n```\n\n----------------------------------------\n\nTITLE: Preparing Data for Manual Registration in Open3D (Python)\nDESCRIPTION: This function prepares data for manual registration by reading two point clouds and visualizing them before alignment. It's part of the manual registration demo in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/interactive_visualization.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_data():\n    print(\"Load two point clouds and show initial pose\")\n    source = o3d.io.read_point_cloud(\"../../test_data/ICP/cloud_bin_0.pcd\")\n    target = o3d.io.read_point_cloud(\"../../test_data/ICP/cloud_bin_2.pcd\")\n    source.paint_uniform_color([1, 0.706, 0])\n    target.paint_uniform_color([0, 0.651, 0.929])\n    o3d.visualization.draw_geometries([source, target])\n    return source, target\n```\n\n----------------------------------------\n\nTITLE: Loading Sword Model with PBR Texture in C++\nDESCRIPTION: Shows how to load the Sword model with PBR texture in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_21\n\nLANGUAGE: cpp\nCODE:\n```\ndata::SwordModel dataset;\nvisualization::rendering::TriangleMeshModel model;\nio::ReadTriangleModel(dataset.GetPath(), model);\n```\n\n----------------------------------------\n\nTITLE: Setting Correspondence Distances for Multi-Scale ICP\nDESCRIPTION: Defines multiple correspondence distances for multi-scale ICP using a vector of values. Each distance corresponds to a different resolution level in the multi-scale approach, with larger distances for coarser scales.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# For Multi-Scale ICP (o3d.utility.DoubleVector):\n\n# `max_correspondence_distances` is proportional to the resolution or the `voxel_sizes`.\n# In general it is recommended to use values between 1x - 3x of the corresponding `voxel_sizes`.\n# We may have a higher value of the `max_correspondence_distances` for the first coarse\n# scale, as it is not much expensive, and gives us more tolerance to initial alignment.\nmax_correspondence_distances = o3d.utility.DoubleVector([0.3, 0.14, 0.07])\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset Objects\nDESCRIPTION: Loads the fountain dataset by calling the load_fountain_dataset function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/color_map_optimization.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Load dataset\nmesh, rgbd_images, camera_trajectory = load_fountain_dataset()\n```\n\n----------------------------------------\n\nTITLE: Coloring Point Cloud with Uniform Color in Open3D\nDESCRIPTION: Applies a uniform color to all points in a point cloud. The color is specified in RGB format with values in the range [0, 1], creating a visual enhancement for the point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Paint chair\")\nchair.paint_uniform_color([1, 0.706, 0])\no3d.visualization.draw_geometries([chair],\n                                  zoom=0.7,\n                                  front=[0.5439, -0.2333, -0.8060],\n                                  lookat=[2.4615, 2.1331, 1.338],\n                                  up=[-0.1781, -0.9708, 0.1608])\n```\n\n----------------------------------------\n\nTITLE: Uniform Downsampling of Point Cloud\nDESCRIPTION: Demonstrates an alternative downsampling method using uniform_down_sample, which selects every nth point (in this case, every 5th point) from the original point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud_outlier_removal.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Every 5th points are selected\")\nuni_down_pcd = pcd.uniform_down_sample(every_k_points=5)\no3d.visualization.draw_geometries([uni_down_pcd],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Absolute Scaling in Open3D\nDESCRIPTION: Shows scaling relative to the coordinate origin instead of the mesh center. Demonstrates how the mesh center can move during scaling.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_coordinate_frame()\nmesh_s = copy.deepcopy(mesh).translate((2, 1, 0))\nmesh_s.scale(0.5, center=(0, 0, 0))\no3d.visualization.draw_geometries([mesh, mesh_s])\n```\n\n----------------------------------------\n\nTITLE: Setting Convergence Criteria for Vanilla ICP\nDESCRIPTION: Defines convergence criteria for vanilla ICP algorithm, including maximum iterations and thresholds for relative fitness and RMSE. These parameters determine when the algorithm considers the alignment to be satisfactory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Convergence-Criteria for Vanilla ICP:\n\ncriteria = treg.ICPConvergenceCriteria(relative_fitness=0.000001,\n                                       relative_rmse=0.000001,\n                                       max_iteration=50)\n```\n\n----------------------------------------\n\nTITLE: Viewing Inserted Keys Using Masks in Open3D\nDESCRIPTION: Demonstrates how to use the masks returned from the insert operation to identify which keys were successfully inserted into the hash map.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint('masks: \\n', masks)\nprint('inserted keys: \\n', keys[masks])\n```\n\n----------------------------------------\n\nTITLE: Performing Hidden Point Removal on Point Clouds using Open3D in Python\nDESCRIPTION: This code demonstrates the hidden point removal feature in Open3D, based on the method by Katz et al. (2007). It loads a mesh, samples it into a point cloud, defines a camera viewpoint and a radius, and then uses `pcd.hidden_point_removal(camera, radius)` to identify points visible from that camera position. The resulting visible points are then visualized. Note that the input point cloud needs to be converted to a Tensor-based PointCloud (`o3d.t.geometry.PointCloud`).\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n```python\nprint(\"Convert mesh to a point cloud and estimate dimensions\")\narmadillo = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo.path)\n# Tensor TriangleMesh not supported this function yet.\nmesh.compute_vertex_normals()\n\npcd = mesh.sample_points_poisson_disk(5000)\ndiameter = np.linalg.norm(\n    np.asarray(pcd.get_max_bound()) - np.asarray(pcd.get_min_bound()))\no3d.visualization.draw_geometries([pcd])\n\nprint(\"Define parameters used for hidden_point_removal\")\ncamera = o3d.core.Tensor([0, 0, diameter], o3d.core.float32)\nradius = diameter * 100\n\nprint(\"Get all points that are visible from given view point\")\npcd = o3d.t.geometry.PointCloud.from_legacy(pcd)\n_, pt_map = pcd.hidden_point_removal(camera, radius)\npcd = pcd.select_by_index(pt_map)\n\nprint(\"Visualize result\")\no3d.visualization.draw_geometries([pcd.to_legacy()])\n```\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Hash Map Parameters\nDESCRIPTION: Sets up basic parameters for an Open3D hash map, including capacity and device configuration. These parameters are required before creating a hash map instance.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport open3d.core as o3c\nimport numpy as np\n\ncapacity = 10\ndevice = o3c.Device('cpu:0')\n```\n\n----------------------------------------\n\nTITLE: Accessing Estimated Point Cloud Normals\nDESCRIPTION: Shows how to access the estimated normal vectors from a point cloud and convert them to a NumPy array for further processing or analysis.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nnormals = downpcd.point.normals\nprint(\"Print first 5 normals of the downsampled point cloud.\")\nprint(normals[:5], \"\\n\")\nprint(\"Convert normals tensor into numpy array.\")\nnormals_np = normals.numpy()\nprint(normals_np[:5])\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Tetrahedron with UV Mapping in Open3D\nDESCRIPTION: Illustrates the creation and visualization of a tetrahedron with UV mapping using Open3D's TriangleMesh class.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntetra = o3d.geometry.TriangleMesh.create_tetrahedron(create_uv_map=True)\no3d.visualization.draw({'name': 'tetrahedron', 'geometry': tetra, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Comparing RANSAC and Fast Global Registration in Open3D\nDESCRIPTION: Demonstrates the usage of RANSAC-based global registration and compares its execution time with a faster global registration approach. It prepares the dataset, executes the registration, and visualizes the results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nvoxel_size = 0.05  # means 5cm for the dataset\nsource, target, source_down, target_down, source_fpfh, target_fpfh = \\\n        prepare_dataset(voxel_size)\n\nstart = time.time()\nresult_ransac = execute_global_registration(source_down, target_down,\n                                            source_fpfh, target_fpfh,\n                                            voxel_size)\nprint(\"Global registration took %.3f sec.\\n\" % (time.time() - start))\nprint(result_ransac)\ndraw_registration_result(source_down, target_down, result_ransac.transformation)\n```\n\n----------------------------------------\n\nTITLE: Loading Sample SUN RGBD Image using Open3D Python\nDESCRIPTION: This Python snippet demonstrates loading the Sample SUN RGBD Image dataset using `o3d.data.SampleSUNRGBDImage()`. It reads the color and depth images using `o3d.io.read_image` and combines them into an `o3d.geometry.RGBDImage` specifically using `create_from_sun_format`.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_49\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.SampleSUNRGBDImage()\ncolor_raw = o3d.io.read_image(dataset.color_path)\ndepth_raw = o3d.io.read_image(dataset.depth_path)\nrgbd_image = o3d.geometry.RGBDImage.create_from_sun_format(\n    color_raw, depth_raw, convert_rgb_to_intensity=False)\n```\n\n----------------------------------------\n\nTITLE: Initializing RaycastingScene with Multiple Meshes in Open3D\nDESCRIPTION: This code creates a RaycastingScene with two non-intersecting watertight meshes (a cube and a sphere) for demonstrating closest point queries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncube = o3d.t.geometry.TriangleMesh.from_legacy(\n    o3d.geometry.TriangleMesh.create_box().translate([-1.2, -1.2, 0]))\nsphere = o3d.t.geometry.TriangleMesh.from_legacy(\n    o3d.geometry.TriangleMesh.create_sphere(0.5).translate([0.7, 0.8, 0]))\n\nscene = o3d.t.geometry.RaycastingScene()\n# Add triangle meshes and remember ids\nmesh_ids = {}\nmesh_ids[scene.add_triangles(cube)] = 'cube'\nmesh_ids[scene.add_triangles(sphere)] = 'sphere'\n```\n\n----------------------------------------\n\nTITLE: Performing Reduction Operations on Tensors\nDESCRIPTION: Shows various reduction operations like sum, min, and argmax that can be performed on tensors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nvals = np.array(range(24)).reshape((2, 3, 4))\na = o3c.Tensor(vals)\nprint(\"a.sum = {}\\n\".format(a.sum()))\nprint(\"a.min = {}\\n\".format(a.min()))\nprint(\"a.ArgMax = {}\\n\".format(a.argmax()))\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Open3D Registration\nDESCRIPTION: Imports the necessary Python libraries for working with 3D point clouds, including Open3D, NumPy, and standard Python modules. It also sets up the tutorial environment by importing helpers from open3d_tutorial.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/robust_kernels.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport copy\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Preparing Example Data for ICP Visualization in Python\nDESCRIPTION: This function prepares two point clouds for ICP visualization. It reads, downsamples, and transforms the point clouds to create an initial misalignment for demonstration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/non_blocking_visualization.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_data():\n    demo_icp_pcds = o3d.data.DemoICPPointClouds()\n    source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n    target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n    threshold = 0.02\n    trans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n                             [-0.139, 0.967, -0.215, 0.7],\n                             [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n    source.transform(trans_init)\n    flip_transform = [[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]\n    source.transform(flip_transform)\n    target.transform(flip_transform)\n    source_down = source.voxel_down_sample(voxel_size=threshold)\n    target_down = target.voxel_down_sample(voxel_size=threshold)\n    return source, target, source_down, target_down\n```\n\n----------------------------------------\n\nTITLE: Loading Avocado Model with Embedded Textures in C++\nDESCRIPTION: Shows how to load the Avocado GLB model with PNG format embedded textures in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_27\n\nLANGUAGE: cpp\nCODE:\n```\ndata::AvocadoModel dataset;\nvisualization::rendering::TriangleMeshModel model;\nio::ReadTriangleModel(dataset.GetPath(), model);\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Environment with Required Imports\nDESCRIPTION: Sets up the Python environment with necessary imports for Open3D operations and visualization configurations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/octree.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\nimport os\nimport sys\n\n# only needed for tutorial, monkey patches visualization\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Red Cube\nDESCRIPTION: This code creates a red cube using Open3D's TriangleMesh, computes its vertex normals, paints it red, and visualizes it using the web visualizer.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/jupyter_visualization.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ncube_red = o3d.geometry.TriangleMesh.create_box(1, 2, 4)\ncube_red.compute_vertex_normals()\ncube_red.paint_uniform_color((1.0, 0.0, 0.0))\ndraw(cube_red)\n```\n\n----------------------------------------\n\nTITLE: Integer Array Indexing in Open3D Tensors (Python)\nDESCRIPTION: Demonstrates integer array indexing for selecting arbitrary items in Open3D tensors based on their dimensional index. It shows how to select specific elements along each dimension and explains that changes to the indexed copy are not reflected in the original tensor.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nvals = np.array(range(24)).reshape((2, 3, 4))\na = o3c.Tensor(vals)\n\n# Along each dimension, a specific element is selected.\nprint(\"a[[0, 1], [1, 2], [1, 0]] = {}\\n\".format(a[[0, 1], [1, 2], [1, 0]]))\n\n# Changes not reflected as it is a copy.\nb = a[[0, 0], [0, 1], [1, 1]]\nb[0] += 100\nprint(\"b = {}\\n\".format(b))\nprint(\"a[[0, 0], [0, 1], [1, 1]] = {}\".format(a[[0, 0], [0, 1], [1, 1]]))\n```\n\n----------------------------------------\n\nTITLE: Poisson Disk Sampling on Bunny Mesh in Python using Open3D\nDESCRIPTION: This snippet shows Poisson disk sampling on a bunny mesh using Open3D. It demonstrates loading an external mesh and applying Poisson disk sampling with different methods.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nbunny = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(bunny.path)\nmesh.compute_vertex_normals()\n\npcd = mesh.sample_points_poisson_disk(number_of_points=500, init_factor=5)\no3d.visualization.draw_geometries([pcd])\n\npcd = mesh.sample_points_uniformly(number_of_points=2500)\npcd = mesh.sample_points_poisson_disk(number_of_points=500, pcl=pcd)\no3d.visualization.draw_geometries([pcd])\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Environment\nDESCRIPTION: Sets up the Open3D environment with necessary imports and visualization helpers. Includes configuration for interactive visualization based on CI environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh_deformation.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Generating Mesh with Noise for Connected Components Analysis in Python using Open3D\nDESCRIPTION: This snippet creates a bunny mesh, subdivides it, and adds small cube meshes as noise. It prepares the mesh for connected components analysis.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Generate data\")\nbunny = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(bunny.path)\nmesh.compute_vertex_normals()\n\nmesh = mesh.subdivide_midpoint(number_of_iterations=2)\nvert = np.asarray(mesh.vertices)\nmin_vert, max_vert = vert.min(axis=0), vert.max(axis=0)\nfor _ in range(30):\n    cube = o3d.geometry.TriangleMesh.create_box()\n    cube.scale(0.005, center=cube.get_center())\n    cube.translate(\n        (\n            np.random.uniform(min_vert[0], max_vert[0]),\n            np.random.uniform(min_vert[1], max_vert[1]),\n            np.random.uniform(min_vert[2], max_vert[2]),\n        ),\n        relative=False,\n    )\n    mesh += cube\nmesh.compute_vertex_normals()\nprint(\"Show input mesh\")\no3d.visualization.draw_geometries([mesh])\n```\n\n----------------------------------------\n\nTITLE: Logical Operations on Open3D Tensors (Python)\nDESCRIPTION: Illustrates various logical operations supported by Open3D, including AND, OR, XOR, NOT, and functions like any() and all(). It also demonstrates how these operations work with boolean and non-boolean tensors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\na = o3c.Tensor(np.array([True, False, True, False]))\nb = o3c.Tensor(np.array([True, True, False, False]))\n\nprint(\"a AND b = {}\".format(a.logical_and(b)))\nprint(\"a OR b = {}\".format(a.logical_or(b)))\nprint(\"a XOR b = {}\".format(a.logical_xor(b)))\nprint(\"NOT a = {}\\n\".format(a.logical_not()))\n\n# Only works for boolean tensors.\nprint(\"a.any = {}\".format(a.any()))\nprint(\"a.all = {}\\n\".format(a.all()))\n\n# If tensor is not boolean, 0 will be treated as False, while non-zero as true.\n# The tensor will be filled with 0 or 1 casted to tensor's dtype.\nc = o3c.Tensor(np.array([2.0, 0.0, 3.5, 0.0]))\nd = o3c.Tensor(np.array([0.0, 3.0, 1.5, 0.0]))\nprint(\"c AND d = {}\".format(c.logical_and(d)))\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Box with UV Mapping for Each Face in Open3D\nDESCRIPTION: Shows how to create a box with UV mapping applied to each face individually. The 'map_texture_to_each_face' parameter is set to True for this purpose.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbox = o3d.geometry.TriangleMesh.create_box(create_uv_map=True, map_texture_to_each_face=True)\no3d.visualization.draw({'name': 'box', 'geometry': box, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing an Icosahedron with UV Mapping in Open3D\nDESCRIPTION: Shows how to create an icosahedron with UV mapping and visualize it using Open3D. The 'create_uv_map' parameter ensures UV coordinates are generated.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nico = o3d.geometry.TriangleMesh.create_icosahedron(create_uv_map=True)\no3d.visualization.draw({'name': 'icosahedron', 'geometry': ico, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Loading and Visualizing a Point Cloud from File\nDESCRIPTION: Demonstrates loading a point cloud from a PLY file using Open3D's IO functions and visualizing it with the built-in visualization tools. Shows how to configure viewing parameters like zoom, camera position, and viewpoint.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Load a ply point cloud, print it, and render it\")\nply_point_cloud = o3d.data.PLYPointCloud()\npcd = o3d.t.io.read_point_cloud(ply_point_cloud.path)\nprint(pcd)\no3d.visualization.draw_geometries([pcd.to_legacy()],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Accessing Mesh ID in RaycastingScene\nDESCRIPTION: Displays the ID returned when adding the cube mesh to the scene, which can be used to identify the mesh when a ray hits it.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(cube_id)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Setting Up Environment for Open3D RGBD Integration\nDESCRIPTION: This snippet imports necessary libraries and sets up the environment for RGBD integration using Open3D. It includes monkey patching for visualization and helper functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_integration.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Unary Element-wise Operations on Tensors\nDESCRIPTION: Demonstrates various unary operations like square root, sine, cosine, and inplace operations on tensors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\na = o3c.Tensor([4, 9, 16], dtype=o3c.Dtype.Float32)\nprint(\"a = {}\\n\".format(a))\nprint(\"a.sqrt = {}\\n\".format(a.sqrt()))\nprint(\"a.sin = {}\\n\".format(a.sin()))\nprint(\"a.cos = {}\\n\".format(a.cos()))\n\n# Inplace operation\na.sqrt_()\nprint(a)\n```\n\n----------------------------------------\n\nTITLE: Loading PLY Point Cloud Dataset in C++\nDESCRIPTION: Shows how to load a PLY format point cloud dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_5\n\nLANGUAGE: cpp\nCODE:\n```\ndata::PLYPointCloud dataset;\nauto pcd = io::CreatePointCloudFromFile(dataset.GetPath());\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ray Casting Results in Open3D Python\nDESCRIPTION: This snippet shows how to obtain and visualize the results of ray casting. It extracts depth, color, and normal information from the results and creates corresponding Open3D images for visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/ray_casting.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndepth = results['depth'].numpy()\ncolor = results['color'].numpy()\nnormal = results['normal'].numpy()\n\ndepth_image = o3d.geometry.Image(depth)\ncolor_image = o3d.geometry.Image(color.astype(np.uint8))\nnormal_image = o3d.geometry.Image((normal * 128 + 128).astype(np.uint8))\n\no3d.visualization.draw_geometries([depth_image])\no3d.visualization.draw_geometries([color_image])\no3d.visualization.draw_geometries([normal_image])\n```\n\n----------------------------------------\n\nTITLE: Initializing Visualizer for Non-blocking Visualization in Python\nDESCRIPTION: This code initializes the Visualizer class, creates a window, and adds geometries to it. It sets up the environment for non-blocking visualization of ICP iterations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/non_blocking_visualization.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef demo_non_blocking_visualization():\n    source, target, source_down, target_down = prepare_data()\n    vis = o3d.visualization.Visualizer()\n    vis.create_window()\n    vis.add_geometry(source)\n    vis.add_geometry(target)\n    threshold = 0.05\n    icp_iteration = 100\n    save_image = False\n```\n\n----------------------------------------\n\nTITLE: Boolean Array Indexing in Open3D Tensors (Python)\nDESCRIPTION: Demonstrates boolean array indexing in Open3D tensors. It shows how to use boolean arrays as indices and how to apply operations to elements that meet certain conditions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\na = o3c.Tensor(np.array([1, -1, -2, 3]))\nprint(\"a = {}\\n\".format(a))\n\n# Add constant to all negative numbers.\na[a < 0] += 20\nprint(\"a = {}\\n\".format(a))\n```\n\n----------------------------------------\n\nTITLE: Loading Avocado Model with Embedded Textures in Python\nDESCRIPTION: Demonstrates how to load the Avocado GLB model with PNG format embedded textures in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.AvocadoModel()\nmodel = o3d.io.read_triangle_model(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Reading and Creating RGBD Image from SUN Dataset\nDESCRIPTION: Loads color and depth images from the SUN dataset and creates an RGBD image using the SUN format parser in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Read SUN dataset\")\nsun_rgbd = o3d.data.SampleSUNRGBDImage()\ncolor_raw = o3d.io.read_image(sun_rgbd.color_path)\ndepth_raw = o3d.io.read_image(sun_rgbd.depth_path)\nrgbd_image = o3d.geometry.RGBDImage.create_from_sun_format(color_raw, depth_raw)\nprint(rgbd_image)\n```\n\n----------------------------------------\n\nTITLE: Converting Point Cloud Normals to NumPy Arrays in Open3D\nDESCRIPTION: Shows how to convert the normal vectors of a point cloud to a NumPy array for further processing. This allows using NumPy's extensive array manipulation capabilities on point cloud data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Print the normal vectors of the first 10 points\")\nprint(np.asarray(downpcd.normals)[:10, :])\n```\n\n----------------------------------------\n\nTITLE: Loading and Visualizing Eagle Point Cloud Dataset in Python\nDESCRIPTION: Demonstrates how to load the Eagle point cloud dataset and visualize it using Open3D in Python.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\n\nif __name__ == \"__main__\":\n    dataset = o3d.data.EaglePointCloud()\n    pcd = o3d.io.read_point_cloud(dataset.path)\n    o3d.visualization.draw(pcd)\n```\n\n----------------------------------------\n\nTITLE: Applying Laplacian Filter to Smooth Mesh in Open3D\nDESCRIPTION: This snippet shows the application of the Laplacian filter to smooth a mesh. It demonstrates the effect of different numbers of iterations on the smoothing result.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint('filter with Laplacian with 10 iterations')\nmesh_out = mesh_in.filter_smooth_laplacian(number_of_iterations=10)\nmesh_out.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh_out])\n\nprint('filter with Laplacian with 50 iterations')\nmesh_out = mesh_in.filter_smooth_laplacian(number_of_iterations=50)\nmesh_out.compute_vertex_normals()\no3d.visualization.draw_geometries([mesh_out])\n```\n\n----------------------------------------\n\nTITLE: Creating Complete PoseGraph for Refined Scene\nDESCRIPTION: Main function that orchestrates the complete registration process, combining pairwise refinement and multiway registration to create and optimize the final pose graph.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/refine_registration.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef make_posegraph_for_refined_scene(ply_file_names, config):\n    pose_graph = o3d.pipelines.registration.PoseGraph()\n    pose_graph.nodes.append(\n        o3d.pipelines.registration.PoseGraphNode(np.identity(4)))\n\n    pcds = []\n    for i in range(len(ply_file_names)):\n        pcd = o3d.io.read_point_cloud(ply_file_names[i])\n        pcd_down = pcd.voxel_down_sample(config[\"voxel_size\"])\n        pcd_down.estimate_normals(\n            o3d.geometry.KDTreeSearchParamHybrid(radius=config[\"voxel_size\"] * 2.0,\n                                              max_nn=30))\n        pcds.append(pcd_down)\n        pose_graph.nodes.append(\n            o3d.pipelines.registration.PoseGraphNode(\n                np.identity(4)))  # add node i to pose_graph\n\n    if config[\"python_multi_threading\"]:  # register with fine view of detail\n        thread_num = config[\"max_threads\"]\n        thread_pool = Pool(thread_num)\n        icp_args = []\n        for edge in pose_graph.edges:\n            s = edge.source_node_id\n            t = edge.target_node_id\n            args = (pcds[s], pcds[t], edge.transformation,\n                   config[\"voxel_size\"], config[\"max_iter\"], config)\n            icp_args.append(args)\n        results = thread_pool.starmap(multiscale_icp, icp_args)\n        for idx, edge in enumerate(pose_graph.edges):\n            edge.transformation = results[idx]\n    else:\n        for edge in pose_graph.edges:  #register with fine view of detail\n            source_down = pcds[edge.source_node_id]\n            target_down = pcds[edge.target_node_id]\n            edge.transformation = multiscale_icp(source_down, target_down,\n                                               config[\"voxel_size\"],\n                                               config[\"max_iter\"], config)\n    return pose_graph\n```\n\n----------------------------------------\n\nTITLE: Converting Tensor Data Types through Casting\nDESCRIPTION: Shows how to convert a tensor from one data type to another, with examples of floating-point to integer and integer to floating-point conversion.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# E.g. float -> int\na = o3c.Tensor([0.1, 1.5, 2.7])\nb = a.to(o3c.Dtype.Int32)\nprint(a)\nprint(b)\n```\n\n----------------------------------------\n\nTITLE: Reading and Writing Point Cloud Data in Open3D\nDESCRIPTION: Demonstrates reading a sample PCD point cloud file and writing it to a new file. Shows basic point cloud I/O operations using Open3D's built-in functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/file_io.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Testing IO for point cloud ...\")\nsample_pcd_data = o3d.data.PCDPointCloud()\npcd = o3d.io.read_point_cloud(sample_pcd_data.path)\nprint(pcd)\no3d.io.write_point_cloud(\"copy_of_fragment.pcd\", pcd)\n```\n\n----------------------------------------\n\nTITLE: Initializing Model and Frame Components in RGB-D SLAM\nDESCRIPTION: Sets up the core components of the SLAM system including the voxel block grid model and frame objects for RGB-D input and model synthesis. Configures essential parameters like block resolution and depth threshold.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/dense_slam.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nmodel = o3d.t.pipelines.slam.Model(config)\nframe = o3d.t.pipelines.slam.Frame(config.depth_max)\nraycast_frame = o3d.t.pipelines.slam.Frame(config.depth_max)\n```\n\n----------------------------------------\n\nTITLE: Processing Lounge RGBD Images using Open3D C++\nDESCRIPTION: This C++ snippet loads the Lounge RGBD dataset (`open3d::data::LoungeRGBDImages`). It loops through the color and depth paths, reads the images using `io::CreateImageFromFile`, creates `geometry::RGBDImage` objects with specified scale and truncation, and finally loads the reconstructed triangle mesh.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_54\n\nLANGUAGE: cpp\nCODE:\n```\ndata::LoungeRGBDImages dataset;\n\nstd::vector<std::shared_ptr<geometry::RGBDImage>> rgbd_images;\nfor(size_t i = 0; i < dataset.GetDepthPaths().size(); ++i) {\n    auto color_raw = io::CreateImageFromFile(dataset.GetColorPaths()[i]);\n    auto depth_raw = io::CreateImageFromFile(dataset.GetDepthPaths()[i]);\n\n    auto rgbd_image = geometry::RGBDImage::CreateFromColorAndDepth(\n            *color_raw, *depth_raw,\n            /*depth_scale =*/1000.0,\n            /*depth_trunc =*/3.0,\n            /*convert_rgb_to_intensity =*/false);\n    rgbd_images.push_back(rgbd_image);\n}\n\nauto mesh = io::CreateTriangleMeshFromFile(dataset.GetReconstructionPath());\n```\n\n----------------------------------------\n\nTITLE: Executing Fast Global Registration with FPFH Features in Python\nDESCRIPTION: This function applies Fast Global Registration using FPFH features. It takes downsampled source and target point clouds, their FPFH features, and voxel size as inputs. The distance threshold is set to half the voxel size.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/global_registration.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef execute_fast_global_registration(source_down, target_down, source_fpfh,\n                                     target_fpfh, voxel_size):\n    distance_threshold = voxel_size * 0.5\n    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n            % distance_threshold)\n    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n        source_down, target_down, source_fpfh, target_fpfh,\n        o3d.pipelines.registration.FastGlobalRegistrationOption(\n            maximum_correspondence_distance=distance_threshold))\n    return result\n```\n\n----------------------------------------\n\nTITLE: Loading Terrazzo Texture for Material in Python\nDESCRIPTION: Demonstrates how to load terrazzo-based material textures (albedo, normal, roughness) in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nmat_data = o3d.data.TerrazzoTexture()\n\nmat = o3d.visualization.rendering.MaterialRecord()\nmat.shader = \"defaultLit\"\nmat.albedo_img = o3d.io.read_image(mat_data.albedo_texture_path)\nmat.normal_img = o3d.io.read_image(mat_data.normal_texture_path)\nmat.roughness_img = o3d.io.read_image(mat_data.roughness_texture_path)\n```\n\n----------------------------------------\n\nTITLE: Combining Advanced and Basic Indexing in Open3D Tensors (Python)\nDESCRIPTION: Explains and demonstrates the combination of advanced and basic indexing in Open3D tensors. It covers scenarios involving slices, ellipses, and newaxis, and shows how the indexing operation is processed in multiple steps.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nvals = np.array(range(24)).reshape((2, 3, 4))\na = o3c.Tensor(vals)\n\nprint(\"a[1, 0:2, [1, 2]] = \\n{}\\n\".format(a[1, 0:2, [1, 2]]))\n\n# Subtle difference in selection and advanced indexing.\nprint(\"a[(0, 1)] = {}\\n\".format(a[(0, 1)]))\nprint(\"a[[0, 1] = \\n{}\\n\".format(a[[0, 1]]))\n\na = o3c.Tensor(np.array(range(120)).reshape((2, 3, 4, 5)))\n\n# Interleaving slice and advanced indexing.\nprint(\"a[1, [[1, 2], [2, 1]], 0:4:2, [3, 4]] = \\n{}\\n\".format(\n    a[1, [[1, 2], [2, 1]], 0:4:2, [3, 4]]))\n```\n\n----------------------------------------\n\nTITLE: Visualizing Triangle Mesh with Custom Camera Settings\nDESCRIPTION: Shows how to load and visualize a triangle mesh (Stanford Bunny) with specific camera orientation parameters using Open3D's Plotly renderer.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/draw_plotly.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n#draw a triangle mesh\ndataset = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(dataset.path)\no3d.visualization.draw_plotly([mesh],\n                              up=[0, 1, 0],\n                              front=[0, 0, 1],\n                              lookat=[0.0, 0.1, 0.0],\n                              zoom=0.5)\n```\n\n----------------------------------------\n\nTITLE: Logging Output of RGBD Frame Integration (Shell)\nDESCRIPTION: This snippet shows the console output during the integration process. It displays progress for each fragment and frame being processed, indicating the total number of fragments and frames within each fragment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/integrate_scene.rst#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nFragment 000 / 013 :: integrate rgbd frame 0 (1 of 100).\nFragment 000 / 013 :: integrate rgbd frame 1 (2 of 100).\nFragment 000 / 013 :: integrate rgbd frame 2 (3 of 100).\nFragment 000 / 013 :: integrate rgbd frame 3 (4 of 100).\n:\nFragment 013 / 013 :: integrate rgbd frame 1360 (61 of 64).\nFragment 013 / 013 :: integrate rgbd frame 1361 (62 of 64).\nFragment 013 / 013 :: integrate rgbd frame 1362 (63 of 64).\nFragment 013 / 013 :: integrate rgbd frame 1363 (64 of 64).\nWriting PLY: [========================================] 100%\n```\n\n----------------------------------------\n\nTITLE: Reduction Operations with Dimension Specification\nDESCRIPTION: Demonstrates how to perform reduction operations along specific dimensions and control whether reduced dimensions are kept.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# With specified dimension.\nvals = np.array(range(24)).reshape((2, 3, 4))\na = o3c.Tensor(vals)\n\nprint(\"Along dim=0\\n{}\".format(a.sum(dim=(0))))\nprint(\"Along dim=(0, 2)\\n{}\\n\".format(a.sum(dim=(0, 2))))\n\n# Retention of reduced dimension.\nprint(\"Shape without retention : {}\".format(a.sum(dim=(0, 2)).shape))\nprint(\"Shape with retention : {}\".format(a.sum(dim=(0, 2), keepdim=True).shape))\n```\n\n----------------------------------------\n\nTITLE: Tensor Broadcasting and Automatic Type Casting\nDESCRIPTION: Shows how broadcasting works with tensors of different shapes and how automatic type casting is performed to avoid data loss.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Automatic broadcasting.\na = o3c.Tensor.ones((2, 3), dtype=o3c.Dtype.Float32)\nb = o3c.Tensor.ones((3,), dtype=o3c.Dtype.Float32)\nprint(\"a + b = \\n{}\\n\".format(a + b))\n\n# Automatic type casting.\na = a[0]\nprint(\"a + 1 = {}\".format(a + 1))  # Float + Int -> Float.\nprint(\"a + True = {}\".format(a + True))  # Float + Bool -> Float.\n\n# Inplace.\na -= True\nprint(\"a = {}\".format(a))\n```\n\n----------------------------------------\n\nTITLE: Listing Connected RealSense Devices (Python)\nDESCRIPTION: Shows how to list all connected RealSense devices and their capabilities using the Open3D Python API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nimport open3d as o3d\no3d.t.io.RealSenseSensor.list_devices()\n```\n\n----------------------------------------\n\nTITLE: Loading and Visualizing a Point Cloud in Open3D\nDESCRIPTION: Loads a PLY point cloud file, prints information about it, and visualizes it with custom camera positioning parameters. The point cloud is rendered as surfels for visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Load a ply point cloud, print it, and render it\")\nply_point_cloud = o3d.data.PLYPointCloud()\npcd = o3d.io.read_point_cloud(ply_point_cloud.path)\nprint(pcd)\nprint(np.asarray(pcd.points))\no3d.visualization.draw_geometries([pcd],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Loading and Downsampling Point Clouds in Open3D\nDESCRIPTION: Loads multiple point clouds from the DemoICPPointClouds dataset and downsamples them using voxel downsampling. This reduces the number of points for faster processing while maintaining the overall structure of the point clouds.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/multiway_registration.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef load_point_clouds(voxel_size=0.0):\n    pcds = []\n    demo_icp_pcds = o3d.data.DemoICPPointClouds()\n    for path in demo_icp_pcds.paths:\n        pcd = o3d.io.read_point_cloud(path)\n        pcd_down = pcd.voxel_down_sample(voxel_size=voxel_size)\n        pcds.append(pcd_down)\n    return pcds\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Cylinder with UV Mapping in Open3D\nDESCRIPTION: Illustrates the creation and visualization of a cylinder with UV mapping using Open3D's TriangleMesh class and visualization tools.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncylinder = o3d.geometry.TriangleMesh.create_cylinder(create_uv_map=True)\no3d.visualization.draw({'name': 'cylinder', 'geometry': cylinder, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Rendering Mesh Backface using HalfEdgeTriangleMesh\nDESCRIPTION: Creates a sphere mesh, crops it with a bounding box, converts it to a HalfEdgeTriangleMesh, and renders it with backfaces visible using the mesh_show_back_face parameter.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/half_edge_mesh.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Initialize a HalfEdgeTriangleMesh from TriangleMesh\nmesh = o3d.geometry.TriangleMesh.create_sphere()\nbbox = o3d.geometry.AxisAlignedBoundingBox()\nbbox.min_bound = [-1, -1, -1]\nbbox.max_bound = [1, 0.6, 1]\nmesh = mesh.crop(bbox)\nhet_mesh = o3d.geometry.HalfEdgeTriangleMesh.create_from_triangle_mesh(mesh)\no3d.visualization.draw_geometries([het_mesh], mesh_show_back_face=True)\n```\n\n----------------------------------------\n\nTITLE: Pairwise Global Registration of Point Clouds in Python for Open3D\nDESCRIPTION: This function performs pairwise global registration using either RANSAC or Fast Global Registration. It aligns two point clouds based on their FPFH features.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/register_fragments.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef register_point_cloud_fpfh(source, target, source_fpfh, target_fpfh, config):\n    distance_threshold = config[\"voxel_size\"] * 1.4\n    if config[\"global_registration\"] == \"fgr\":\n        result = o3d.pipelines.registration.registration_fast_based_on_feature_matching(\n            source, target, source_fpfh, target_fpfh,\n            o3d.pipelines.registration.FastGlobalRegistrationOption(\n                maximum_correspondence_distance=distance_threshold))\n    if config[\"global_registration\"] == \"ransac\":\n        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n            source, target, source_fpfh, target_fpfh, False, distance_threshold,\n            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n            3, [\n                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n                    0.9),\n                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n                    distance_threshold)\n            ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n    return result\n```\n\n----------------------------------------\n\nTITLE: Adjusting Camera Parameters for Point Cloud Visualization\nDESCRIPTION: Demonstrates how to control camera position and orientation by setting zoom, front, lookat, and up parameters to get a better view of a point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/draw_plotly.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#adjust the camera to get a better view\ndataset = o3d.data.PLYPointCloud()\noffice = o3d.io.read_point_cloud(dataset.path)\no3d.visualization.draw_plotly([office],\n                              point_sample_factor=0.1,\n                              zoom=0.3,\n                              front=[0.4257, -0.2125, -0.8795],\n                              lookat=[2.672, 2.0475, 1.532],\n                              up=[-0.0694, -0.9768, -0.2024])\n```\n\n----------------------------------------\n\nTITLE: Defining Initial Transformation Matrix for ICP Registration\nDESCRIPTION: Sets up the initial transformation matrix that roughly aligns the source point cloud to the target. This serves as the starting point for the ICP algorithm to refine the alignment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Initial alignment or source to target transform.\ninit_source_to_target = np.asarray([[0.862, 0.011, -0.507, 0.5],\n                                    [-0.139, 0.967, -0.215, 0.7],\n                                    [0.487, 0.255, 0.835, -1.4],\n                                    [0.0, 0.0, 0.0, 1.0]])\n```\n\n----------------------------------------\n\nTITLE: Running Open3D Reconstruction System with Custom Dataset\nDESCRIPTION: This snippet shows how to run the Open3D reconstruction system using a different dataset ('bedroom'). It demonstrates changing the default dataset while still performing all reconstruction steps.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/system_overview.rst#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npython run_system.py --default_dataset 'bedroom' --make --register --refine --integrate\n```\n\n----------------------------------------\n\nTITLE: Loading Crate Model with PBR Texture in C++\nDESCRIPTION: Shows how to load the Crate model with PBR texture in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_23\n\nLANGUAGE: cpp\nCODE:\n```\ndata::CrateModel dataset;\nvisualization::rendering::TriangleMeshModel model;\nio::ReadTriangleModel(dataset.GetPath(), model);\n```\n\n----------------------------------------\n\nTITLE: Reading and Writing Image Data in Open3D\nDESCRIPTION: Demonstrates reading and writing image files using Open3D. Shows how to handle image I/O operations with support for JPG and PNG formats.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/file_io.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Testing IO for images ...\")\nimage_data = o3d.data.JuneauImage()\nimg = o3d.io.read_image(image_data.path)\nprint(img)\no3d.io.write_image(\"copy_of_Juneau.jpg\", img)\n```\n\n----------------------------------------\n\nTITLE: Loading Monkey Model with PBR Texture in C++\nDESCRIPTION: Shows how to load the Monkey model with PBR texture in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_19\n\nLANGUAGE: cpp\nCODE:\n```\ndata::BunnyMesh dataset;\nvisualization::rendering::TriangleMeshModel model;\nauto model = io::ReadTriangleModel(dataset.GetPath(), model);\n```\n\n----------------------------------------\n\nTITLE: Applying Voxel Carving to Armadillo Mesh in Open3D\nDESCRIPTION: This snippet demonstrates the application of the voxel carving function to an Armadillo mesh. It sets up parameters and calls the voxel_carving function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/voxelization.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\narmadillo = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo.path)\n\nvisualization = True\ncubic_size = 2.0\nvoxel_resolution = 128.0\n\nvoxel_grid, voxel_carving, voxel_surface = voxel_carving(\n    mesh, cubic_size, voxel_resolution)\n```\n\n----------------------------------------\n\nTITLE: Converting Between PLY and SPLAT Formats\nDESCRIPTION: Demonstrates how to convert between PLY and SPLAT formats for 3D Gaussian Splats using Open3D's IO functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/3d_gaussian_splatting.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Compress .ply format 3DGS by saving to .splat format\no3d.t.io.write_point_cloud('mipnerf360_garden_crop_table_from_ply.splat', ply_3dgs)\n# Convert .splat format 3DGS to .ply format for wider compatibility\no3d.t.io.write_point_cloud('mipnerf360_garden_crop_table_from_splat.ply', splat_3dgs)\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for Open3D Python Applications\nDESCRIPTION: A minimal Dockerfile for setting up an environment to run Open3D Python applications. It installs necessary system dependencies and the Open3D package.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/docker.in.rst#2025-04-23_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\n# This could also be another Ubuntu or Debian based distribution\nFROM ubuntu:22.04\n\n# Install Open3D system dependencies and pip\nRUN apt-get update && apt-get install --no-install-recommends -y \\\n    libegl1 \\\n    libgl1 \\\n    libgomp1 \\\n    python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Open3D from the PyPI repositories\nRUN python3 -m pip install --no-cache-dir --upgrade pip && \\\n    python3 -m pip install --no-cache-dir --upgrade open3d\n```\n\n----------------------------------------\n\nTITLE: Loading Knot Mesh Dataset in C++\nDESCRIPTION: Shows how to load the 3D Mobius knot mesh dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_17\n\nLANGUAGE: cpp\nCODE:\n```\ndata::KnotMesh dataset;\nauto mesh = io::CreateMeshFromFile(dataset.GetPath());\n```\n\n----------------------------------------\n\nTITLE: Generating Voxel Indices for Active Blocks in Open3D Python\nDESCRIPTION: This code unrolls voxel indices in the active blocks into a flattened array, along with their corresponding voxel coordinates.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/customized_integration.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvoxel_indices = vbg.hashmap.compute_key(block_indices, voxel_coords)\nvoxel_coords = voxel_block_coords * voxel_size + voxel_coords * vbg.voxel_size\n```\n\n----------------------------------------\n\nTITLE: Combined Translation and Rotation in Open3D\nDESCRIPTION: Shows how to combine translation and rotation operations. Translates the mesh first and then applies rotation around the coordinate center.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_coordinate_frame()\nmesh_r = copy.deepcopy(mesh).translate((2, 0, 0))\nmesh_r.rotate(mesh.get_rotation_matrix_from_xyz((np.pi / 2, 0, np.pi / 4)),\n              center=(0, 0, 0))\no3d.visualization.draw_geometries([mesh, mesh_r])\n```\n\n----------------------------------------\n\nTITLE: Loading Fountain RGBD Dataset\nDESCRIPTION: Function to load color and depth image pairs, create RGBD images, and read camera trajectory and mesh data from the fountain dataset.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/color_map_optimization.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef load_fountain_dataset():\n    rgbd_images = []\n    fountain_rgbd_dataset = o3d.data.SampleFountainRGBDImages()\n    for i in range(len(fountain_rgbd_dataset.depth_paths)):\n        depth = o3d.io.read_image(fountain_rgbd_dataset.depth_paths[i])\n        color = o3d.io.read_image(fountain_rgbd_dataset.color_paths[i])\n        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n            color, depth, convert_rgb_to_intensity=False)\n        rgbd_images.append(rgbd_image)\n\n    camera_trajectory = o3d.io.read_pinhole_camera_trajectory(\n        fountain_rgbd_dataset.keyframe_poses_log_path)\n    mesh = o3d.io.read_triangle_mesh(\n        fountain_rgbd_dataset.reconstruction_path)\n\n    return mesh, rgbd_images, camera_trajectory\n```\n\n----------------------------------------\n\nTITLE: Manually Reserving Hash Map Capacity in Open3D\nDESCRIPTION: Demonstrates how to manually reserve a larger capacity for the hash map to avoid automatic rehashing, which can be inefficient for large insertions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nhashmap.reserve(100)\nprint('size:', hashmap.size())\nprint('capacity:', hashmap.capacity())\n```\n\n----------------------------------------\n\nTITLE: Computing Closest Point on Surface in Open3D\nDESCRIPTION: This snippet shows how to use RaycastingScene.compute_closest_points() to find the closest point on the surface for a given query point, including geometry and primitive information.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nquery_point = o3d.core.Tensor([[0, 0, 0]], dtype=o3d.core.Dtype.Float32)\n\n# We compute the closest point on the surface for the point at position [0,0,0].\nans = scene.compute_closest_points(query_point)\n\n# Compute_closest_points provides the point on the surface, the geometry id,\n# and the primitive id.\n# The dictionary keys are\n#.    points\n#.    geometry_ids\n#.    primitive_ids\nprint('The closest point on the surface is', ans['points'].numpy())\nprint('The closest point is on the surface of the',\n      mesh_ids[ans['geometry_ids'][0].item()])\nprint('The closest point belongs to triangle', ans['primitive_ids'][0].item())\n```\n\n----------------------------------------\n\nTITLE: Evaluating Initial Alignment for ICP Registration\nDESCRIPTION: This code evaluates the initial alignment between source and target point clouds. It calculates and prints metrics such as fitness and inlier RMSE using Open3D's evaluation function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/icp_registration.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Initial alignment\")\nevaluation = o3d.pipelines.registration.evaluate_registration(\n    source, target, threshold, trans_init)\nprint(evaluation)\n```\n\n----------------------------------------\n\nTITLE: Loading Damaged Helmet Model with Embedded Textures in Python\nDESCRIPTION: Demonstrates how to load the Damaged Helmet GLB model with JPG format embedded textures in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.DamagedHelmetModel()\nmodel = o3d.io.read_triangle_model(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D and Required Libraries for Distance Queries\nDESCRIPTION: This snippet imports necessary libraries and sets up the environment for the Open3D tutorial on distance queries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport sys\n\n# only needed for tutorial, monkey patches visualization\nsys.path.append('..')\nimport open3d_tutorial\n# change to True if you want to interact with the visualization windows\nopen3d_tutorial.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Visualizing Point Cloud with Colored Neighbor Points in Open3D\nDESCRIPTION: Visualizes the point cloud with differently colored points using Open3D's visualization tools. The anchor point is red, k-nearest neighbors are blue, and radius-based neighbors are green.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/kdtree.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Visualize the point cloud.\")\no3d.visualization.draw_geometries([pcd],\n                                  zoom=0.5599,\n                                  front=[-0.4958, 0.8229, 0.2773],\n                                  lookat=[2.1126, 1.0163, -1.8543],\n                                  up=[0.1007, -0.2626, 0.9596])\n```\n\n----------------------------------------\n\nTITLE: Applying Texture Maps to Objects in Open3D\nDESCRIPTION: This function demonstrates how to apply texture maps (albedo, normal, ao, metallic, roughness) to 3D objects in Open3D. It loads an object model and checks for available textures in the specified directory, then applies them to the object.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/customized_visualization.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport open3d.visualization.gui as gui\nimport open3d.visualization.rendering as rendering\nimport sys, os\n\ndef main():\n    if len(sys.argv) < 2:\n        print (\"Usage: texture-model.py [model directory]\\n\\t This example will load [model directory].obj and any of albedo, normal, ao, metallic and roughness textures present.\")\n        exit()\n\n    # Derive the object path set the model, material, and shader\n    model_dir = sys.argv[1]\n    model_name = os.path.join(model_dir, os.path.basename(model_dir) + \".obj\")\n    model = o3d.io.read_triangle_mesh(model_name)\n    material = o3d.visualization.rendering.Material()\n    material.shader = \"defaultLit\"\n\n    # Derive the texture paths\n    albedo_name = os.path.join(model_dir, \"albedo.png\")\n    normal_name = os.path.join(model_dir, \"normal.png\")\n    ao_name = os.path.join(model_dir, \"ao.png\")\n    metallic_name = os.path.join(model_dir, \"metallic.png\")\n    roughness_name = os.path.join(model_dir, \"roughness.png\")\n\n    # Check if the textures are available and loads the texture. For example, if metallic exists then load metallic texture\n    if os.path.exists(albedo_name):\n        material.albedo_img = o3d.io.read_image(albedo_name)\n    if os.path.exists(normal_name):\n        material.normal_img = o3d.io.read_image(normal_name)\n    if os.path.exists(ao_name):\n        material.ao_img = o3d.io.read_image(ao_name)\n    if os.path.exists(metallic_name):\n        material.base_metallic = 1.0\n        material.metallic_img = o3d.io.read_image(metallic_name)\n    if os.path.exists(roughness_name):\n        material.roughness_img = o3d.io.read_image(roughness_name)\n    \n    # Draw an object named cube using the available model and texture\n    o3d.visualization.draw([{\"name\": \"cube\", \"geometry\": model, \"material\": material}])\n\nif __name__ == \"__main__\":\n main()\n```\n\n----------------------------------------\n\nTITLE: Feature Matching Point Clouds Demo\nDESCRIPTION: Loads point clouds with their FPFH and L32D features for feature matching demonstration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_60\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.DemoFeatureMatchingPointClouds()\n\npcd0 = o3d.io.read_point_cloud(dataset.point_cloud_paths[0])\npcd1 = o3d.io.read_point_cloud(dataset.point_cloud_paths[1])\n\nfpfh_feature0 = o3d.io.read_feature(dataset.fpfh_feature_paths[0])\nfpfh_feature1 = o3d.io.read_feature(dataset.fpfh_feature_paths[1])\n\nl32d_feature0 = o3d.io.read_feature(dataset.l32d_feature_paths[0])\nl32d_feature1 = o3d.io.read_feature(dataset.l32d_feature_paths[1])\n```\n\n----------------------------------------\n\nTITLE: Tuned Standard ICP with Larger Threshold\nDESCRIPTION: Attempts to improve the standard point-to-plane ICP registration by increasing the threshold for correspondence search. This shows that simply adjusting the threshold is not sufficient for dealing with outliers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/robust_kernels.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nthreshold = 1.0\nprint(\"Vanilla point-to-plane ICP, threshold={}:\".format(threshold))\np2l = o3d.pipelines.registration.TransformationEstimationPointToPlane()\nreg_p2l = o3d.pipelines.registration.registration_icp(source_noisy, target,\n                                                      threshold, trans_init,\n                                                      p2l)\n\nprint(reg_p2l)\nprint(\"Transformation is:\")\nprint(reg_p2l.transformation)\ndraw_registration_result(source, target, reg_p2l.transformation)\n```\n\n----------------------------------------\n\nTITLE: Loading PCD Point Cloud Dataset in C++\nDESCRIPTION: Shows how to load a PCD format point cloud dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_3\n\nLANGUAGE: cpp\nCODE:\n```\ndata::PCDPointCloud dataset;\nauto pcd = io::CreatePointCloudFromFile(dataset.GetPath());\n```\n\n----------------------------------------\n\nTITLE: Visualizing Custom Distance Field and Geometry IDs in Open3D\nDESCRIPTION: This snippet demonstrates how to use the custom signed distance function to compute a grid of distances and geometry IDs, and visualize slices of both using matplotlib.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# compute range\nxyz_range = np.linspace([-2, -2, -2], [2, 2, 2], num=32)\n# query_points is a [32,32,32,3] array ..\nquery_points = np.stack(np.meshgrid(*xyz_range.T), axis=-1).astype(np.float32)\n\nsdf, closest_geom = compute_signed_distance_and_closest_goemetry(query_points)\n\n# We can visualize a slice of the grids directly with matplotlib\nfig, axes = plt.subplots(1, 2)\naxes[0].imshow(sdf[:, :, 16])\naxes[1].imshow(closest_geom[:, :, 16])\n```\n\n----------------------------------------\n\nTITLE: Running Azure Kinect Recorder (Python)\nDESCRIPTION: Command to run the Open3D Azure Kinect Recorder Python script to record RGB and depth streams to an MKV file.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/azure_kinect.rst#2025-04-23_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\npython examples/python/reconstruction_system/sensors/azure_kinect_recorder.py --output record.mkv\n```\n\n----------------------------------------\n\nTITLE: Enabling SYCL Kernel Binary Caching (Shell and Python)\nDESCRIPTION: Commands to enable caching of JIT compiled SYCL kernel binaries to improve subsequent run performance.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/sycl.rst#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nexport SYCL_CACHE_PERSISTENT=1\n```\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\no3d.core.sycl.enable_persistent_jit_cache()\n```\n\n----------------------------------------\n\nTITLE: Loading Multiple Office Point Clouds in C++\nDESCRIPTION: Shows how to load multiple point clouds from the Office dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_11\n\nLANGUAGE: cpp\nCODE:\n```\ndata::OfficePointClouds dataset;\nstd::vector<std::shared_ptr<geometry::PointCloud>> pcds;\nfor (const std::string& pcd_path: dataset.GetPaths()) {\n    pcds.push_back(io::CreatePointCloudFromFile(pcd_path));\n}\n```\n\n----------------------------------------\n\nTITLE: Reading RealSense Bag Files (Python)\nDESCRIPTION: Shows how to read a RealSense bag file using the Open3D Python API, including opening the file, iterating through frames, and closing the reader.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nimport open3d as o3d\nbag_reader = o3d.t.io.RSBagReader()\nbag_reader.open(bag_filename)\nim_rgbd = bag_reader.next_frame()\nwhile not bag_reader.is_eof():\n    # process im_rgbd.depth and im_rgbd.color\n    im_rgbd = bag_reader.next_frame()\n\nbag_reader.close()\n```\n\n----------------------------------------\n\nTITLE: Helper Function for Reading NYU PGM Format Depth Images\nDESCRIPTION: Custom function to read NYU dataset's special big endian PGM format depth images. Parses the PGM header and extracts the depth data as a numpy array.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.image as mpimg\nimport re\n\n\n# This is special function used for reading NYU pgm format\n# as it is written in big endian byte order.\ndef read_nyu_pgm(filename, byteorder='>'):\n    with open(filename, 'rb') as f:\n        buffer = f.read()\n    try:\n        header, width, height, maxval = re.search(\n            b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n            b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n    except AttributeError:\n        raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n    img = np.frombuffer(buffer,\n                        dtype=byteorder + 'u2',\n                        count=int(width) * int(height),\n                        offset=len(header)).reshape((int(height), int(width)))\n    img_out = img.astype('u2')\n    return img_out\n```\n\n----------------------------------------\n\nTITLE: Comparison Operations in Open3D Tensors (Python)\nDESCRIPTION: Demonstrates comparison operations in Open3D tensors, including greater than, less than, equal to, and not equal to. It also shows how these operations handle broadcasting when tensor shapes are not the same.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\na = o3c.Tensor([0, 1, -1])\nb = o3c.Tensor([0, 0, 0])\n\nprint(\"a > b = {}\".format(a > b))\nprint(\"a >= b = {}\".format(a >= b))\nprint(\"a < b = {}\".format(a < b))\nprint(\"a <= b = {}\".format(a <= b))\nprint(\"a == b = {}\".format(a == b))\nprint(\"a != b = {}\".format(a != b))\n\n# Throws exception if device/dtype is not shape.\n# If shape is not same, then tensors should be broadcast compatible.\nprint(\"a > b = {}\".format(a > b[0]))\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for Open3D External Project\nDESCRIPTION: Sets up CMake project with minimum version requirement, project name, and build options. It configures an external project to clone and build Open3D from its Git repository.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-external-project/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\n# On Ubuntu 20.04, get the latest CMake from https://apt.kitware.com/.\ncmake_minimum_required(VERSION 3.24)\n\nproject(Open3DCMakeExternalProject LANGUAGES C CXX)\n\noption(GLIBCXX_USE_CXX11_ABI   \"Set -D_GLIBCXX_USE_CXX11_ABI=1\"       OFF)\noption(STATIC_WINDOWS_RUNTIME  \"Use static (MT/MTd) Windows runtime\"  ON )\n\nif(NOT CMAKE_BUILD_TYPE)\n    message(STATUS \"No CMAKE_BUILD_TYPE specified, default to Release.\")\n    set(CMAKE_BUILD_TYPE \"Release\")\nendif()\n\ninclude(ExternalProject)\nExternalProject_Add(\n    external_open3d\n    PREFIX open3d\n    GIT_REPOSITORY https://github.com/isl-org/Open3D.git\n    GIT_TAG main   # Use a specific tag, e.g. v0.18.0 to pin Open3D version.\n    GIT_SHALLOW ON\n    UPDATE_COMMAND \"\"\n    # Check out https://github.com/intel-isl/Open3D/blob/master/CMakeLists.txt\n    # For the full list of available options.\n    CMAKE_ARGS\n        -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR>\n        -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}\n        -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}\n        -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}\n        -DGLIBCXX_USE_CXX11_ABI=${GLIBCXX_USE_CXX11_ABI}\n        -DSTATIC_WINDOWS_RUNTIME=${STATIC_WINDOWS_RUNTIME}\n        -DBUILD_SHARED_LIBS=ON\n        -DBUILD_PYTHON_MODULE=OFF\n        -DBUILD_EXAMPLES=OFF\n)\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Custom Line Set Geometry\nDESCRIPTION: Shows how to create a custom line set representing a cube by defining points, lines, and colors, then visualizing it with Open3D's Plotly renderer.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/draw_plotly.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n#draw a point set\npoints = [\n    [0, 0, 0],\n    [1, 0, 0],\n    [0, 1, 0],\n    [1, 1, 0],\n    [0, 0, 1],\n    [1, 0, 1],\n    [0, 1, 1],\n    [1, 1, 1],\n]\nlines = [\n    [0, 1],\n    [0, 2],\n    [1, 3],\n    [2, 3],\n    [4, 5],\n    [4, 6],\n    [5, 7],\n    [6, 7],\n    [0, 4],\n    [1, 5],\n    [2, 6],\n    [3, 7],\n]\ncolors = [[1, 0, 0] for i in range(len(lines))]\nline_set = o3d.geometry.LineSet(\n    points=o3d.utility.Vector3dVector(points),\n    lines=o3d.utility.Vector2iVector(lines),\n)\nline_set.colors = o3d.utility.Vector3dVector(colors)\no3d.visualization.draw_plotly([line_set])\n```\n\n----------------------------------------\n\nTITLE: Clustering Connected Triangles in Python using Open3D\nDESCRIPTION: This snippet demonstrates the use of the cluster_connected_triangles function in Open3D to identify connected components in a mesh.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Cluster connected triangles\")\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    triangle_clusters, cluster_n_triangles, cluster_area = (\n        mesh.cluster_connected_triangles())\ntriangle_clusters = np.asarray(triangle_clusters)\ncluster_n_triangles = np.asarray(cluster_n_triangles)\ncluster_area = np.asarray(cluster_area)\n```\n\n----------------------------------------\n\nTITLE: Loading PLY Point Cloud Dataset in Python\nDESCRIPTION: Demonstrates how to load a PLY format point cloud dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.PLYPointCloud()\npcd = o3d.io.read_point_cloud(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Basic Open3D Python API Usage Example\nDESCRIPTION: Example command demonstrating basic Open3D functionality by creating and visualizing a sphere mesh with vertex normals.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Python API\npython -c \"import open3d as o3d; \\\n               mesh = o3d.geometry.TriangleMesh.create_sphere(); \\\n               mesh.compute_vertex_normals(); \\\n               o3d.visualization.draw(mesh, raw_mode=True)\"\n```\n\n----------------------------------------\n\nTITLE: Reading and Writing Mesh Data in Open3D\nDESCRIPTION: Shows how to read a sample knot mesh file and write it to a new PLY file. Demonstrates mesh I/O operations using Open3D's triangle mesh functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/file_io.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Testing IO for meshes ...\")\nknot_data = o3d.data.KnotMesh()\nmesh = o3d.io.read_triangle_mesh(knot_data.path)\nprint(mesh)\no3d.io.write_triangle_mesh(\"copy_of_knot.ply\", mesh)\n```\n\n----------------------------------------\n\nTITLE: Initializing Color ICP Transformation Estimator\nDESCRIPTION: Creates a transformation estimation object specifically for colored ICP registration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nestimation = treg.TransformationEstimationForColoredICP()\n```\n\n----------------------------------------\n\nTITLE: Optimizing PoseGraph for Fragment in Python using Open3D\nDESCRIPTION: This function performs global optimization on a pose graph to estimate poses of RGBD images in a fragment. It uses Open3D's global_optimization function with custom parameters.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/make_fragments.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef optimize_posegraph_for_fragment(path_dataset, fragment_id):\n    pose_graph_name = join(path_dataset,\n                            config[\"template_fragment_posegraph\"] % fragment_id)\n    pose_graph = o3d.io.read_pose_graph(pose_graph_name)\n    o3d.utility.set_verbosity_level(o3d.utility.VerbosityLevel.Debug)\n    criteria = o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria()\n    criteria.max_iteration = config[\"max_iteration\"]\n    option = o3d.pipelines.registration.GlobalOptimizationOption(\n        config[\"max_depth_diff\"], config[\"preference_loop_closure\"])\n    option.max_correspondence_distance = config[\"max_depth_diff\"]\n    o3d.pipelines.registration.global_optimization(\n        pose_graph,\n        o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n        criteria, option)\n    o3d.io.write_pose_graph(pose_graph_name, pose_graph)\n```\n\n----------------------------------------\n\nTITLE: Converting NumPy Array to Open3D Point Cloud and Saving to File\nDESCRIPTION: Demonstrates how to convert a NumPy array to an Open3D PointCloud object using Vector3dVector. The point cloud is then saved to a PLY file format for later use.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/working_with_numpy.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\npcd = o3d.geometry.PointCloud()\npcd.points = o3d.utility.Vector3dVector(xyz)\no3d.io.write_point_cloud(\"sync.ply\", pcd)\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing an Octahedron with UV Mapping in Open3D\nDESCRIPTION: Demonstrates the process of creating an octahedron with UV mapping and visualizing it using Open3D's visualization tools.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nocto = o3d.geometry.TriangleMesh.create_octahedron(create_uv_map=True)\no3d.visualization.draw({'name': 'octahedron', 'geometry': octo, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Visualizing TUM Dataset RGBD Image Components\nDESCRIPTION: Displays the color and depth components of the TUM dataset RGBD image using Matplotlib.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nplt.subplot(1, 2, 1)\nplt.title('TUM grayscale image')\nplt.imshow(rgbd_image.color)\nplt.subplot(1, 2, 2)\nplt.title('TUM depth image')\nplt.imshow(rgbd_image.depth)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Loading Wood Textures into MaterialRecord using Open3D Python\nDESCRIPTION: This snippet demonstrates how to load the built-in wood texture dataset (albedo, normal, roughness) using `o3d.data.WoodTexture()` in Python. It then reads these texture images using `o3d.io.read_image` and assigns them to an `o3d.visualization.rendering.MaterialRecord` with the 'defaultLit' shader.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nmat_data = o3d.data.WoodTexture()\n\nmat = o3d.visualization.rendering.MaterialRecord()\nmat.shader = \"defaultLit\"\nmat.albedo_img = o3d.io.read_image(mat_data.albedo_texture_path)\nmat.normal_img = o3d.io.read_image(mat_data.normal_texture_path)\nmat.roughness_img = o3d.io.read_image(mat_data.roughness_texture_path)\n```\n\n----------------------------------------\n\nTITLE: Running RealSense Recorder Script in Bash\nDESCRIPTION: This snippet shows the different modes for running the RealSense recorder script, including recording images, recording a rosbag, or playing back a rosbag.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/capture_your_own_dataset.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython realsense_recorder.py --record_imgs\npython realsense_recorder.py --record_rosbag\npython realsense_recorder.py --playback_rosbag\n```\n\n----------------------------------------\n\nTITLE: Using Python Help Function with Open3D Module\nDESCRIPTION: Shows how to get overall documentation for the Open3D module using Python's built-in help function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/python_interface.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nhelp(o3d)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Open3D and NumPy Integration\nDESCRIPTION: Imports the necessary libraries for working with Open3D and NumPy, and sets up the environment for the tutorial. Includes paths for tutorial helpers and disables interactive mode when running in CI environments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/working_with_numpy.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Changing Field of View in Open3D Visualization\nDESCRIPTION: This function demonstrates how to change the field of view of the camera in Open3D visualization. It uses the change_field_of_view method of the ViewControl object to adjust the FOV.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/customized_visualization.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef custom_draw_geometry_with_custom_fov(pcd, fov_step):\n    vis = o3d.visualization.Visualizer()\n    vis.create_window()\n    vis.add_geometry(pcd)\n    ctr = vis.get_view_control()\n    print(\"Field of view (before changing) {}\".format(ctr.get_field_of_view()))\n    ctr.change_field_of_view(step=fov_step)\n    print(\"Field of view (after changing) {}\".format(ctr.get_field_of_view()))\n    vis.run()\n    vis.destroy_window()\n```\n\n----------------------------------------\n\nTITLE: Accessing Tensor Properties\nDESCRIPTION: Shows how to access various properties of a tensor including shape, strides, data type, device, and number of dimensions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nvals = np.array((range(24))).reshape(2, 3, 4)\na = o3c.Tensor(vals, dtype=o3c.Dtype.Float64, device=o3c.Device(\"CUDA:0\"))\nprint(f\"a.shape: {a.shape}\")\nprint(f\"a.strides: {a.strides}\")\nprint(f\"a.dtype: {a.dtype}\")\nprint(f\"a.device: {a.device}\")\nprint(f\"a.ndim: {a.ndim}\")\n```\n\n----------------------------------------\n\nTITLE: Downloading 3D Gaussian Splatting Data\nDESCRIPTION: Downloads sample 3DGS data files in PLY and SPLAT formats from the MipNeRF 360 dataset.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/3d_gaussian_splatting.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!curl -O https://github.com/isl-org/open3d_downloads/releases/download/3dgs-1/mipnerf360_garden_crop_table.ply\n!curl -O https://github.com/isl-org/open3d_downloads/releases/download/3dgs-1/mipnerf360_garden_crop_table.splat\n```\n\n----------------------------------------\n\nTITLE: Listing Connected RealSense Devices (C++)\nDESCRIPTION: Demonstrates how to list all connected RealSense devices and their capabilities using the Open3D C++ API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_4\n\nLANGUAGE: C++\nCODE:\n```\n#include <open3d/open3d.hpp>\nopen3d::t::io::RealSenseSensor::ListDevices();\n```\n\n----------------------------------------\n\nTITLE: Reading RealSense Bag Files (C++)\nDESCRIPTION: Demonstrates how to read a RealSense bag file using the Open3D C++ API, including opening the file, iterating through frames, and closing the reader.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_2\n\nLANGUAGE: C++\nCODE:\n```\n#include <open3d/open3d.hpp>\nusing namespace open3d;\nt::io::RSBagReader bag_reader;\nbag_reader.Open(bag_filename);\nauto im_rgbd = bag_reader.NextFrame();\nwhile (!bag_reader.IsEOF()) {\n    // process im_rgbd.depth_ and im_rgbd.color_\n    im_rgbd = bag_reader.NextFrame();\n}\nbag_reader.Close();\n```\n\n----------------------------------------\n\nTITLE: Loading Eagle Point Cloud Dataset in C++\nDESCRIPTION: Shows how to load the Eagle colored point cloud dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_7\n\nLANGUAGE: cpp\nCODE:\n```\ndata::EaglePointCloud dataset;\nauto pcd = io::CreatePointCloudFromFile(dataset.GetPath());\n```\n\n----------------------------------------\n\nTITLE: Running Open3D CLI Visualization Example\nDESCRIPTION: Command to run a visualization example using Open3D's command-line interface (CLI), which demonstrates the library's built-in examples.\nSOURCE: https://github.com/isl-org/open3d/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nopen3d example visualization/draw\n```\n\n----------------------------------------\n\nTITLE: Processing Single Fragment in Python for Open3D Reconstruction\nDESCRIPTION: This function processes a single fragment by registering RGBD pairs, creating and optimizing a pose graph, and integrating RGB frames. It's part of the batch processing system for fragment creation in Open3D's reconstruction pipeline.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/make_fragments.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef process_single_fragment(fragment_id, color_files, depth_files, n_files,\n                           n_fragments, config):\n    if config[\"path_intrinsic\"]:\n        intrinsic = o3d.io.read_pinhole_camera_intrinsic(\n            config[\"path_intrinsic\"])\n    else:\n        intrinsic = o3d.camera.PinholeCameraIntrinsic(\n            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n\n    sid = fragment_id * config['n_frames_per_fragment']\n    eid = min(sid + config['n_frames_per_fragment'], n_files)\n\n    make_posegraph_for_fragment(config[\"path_dataset\"], sid, eid, color_files,\n                                depth_files, fragment_id, n_fragments,\n                                intrinsic, config[\"with_opencv\"])\n    optimize_posegraph_for_fragment(config[\"path_dataset\"], fragment_id)\n    mesh = integrate_rgb_frames_for_fragment(\n        color_files, depth_files, fragment_id, n_fragments,\n        config[\"path_dataset\"] + config[\"template_fragment_posegraph\"] %\n        fragment_id, intrinsic, config)\n    o3d.io.write_triangle_mesh(\n        config[\"path_dataset\"] + config[\"template_fragment_mesh\"] % fragment_id,\n        mesh,\n        False,\n        True)\n\ndef run(config):\n    print(\"Making fragments from RGBD sequence.\")\n    make_clean_folder(join(config[\"path_dataset\"], config[\"folder_fragment\"]))\n\n    [color_files, depth_files] = get_rgbd_file_lists(config[\"path_dataset\"])\n    n_files = len(color_files)\n    n_fragments = int(math.ceil(float(n_files) /\n                                config['n_frames_per_fragment']))\n\n    if config[\"python_multi_threading\"] is True:\n        from joblib import Parallel, delayed\n        import multiprocessing\n        import subprocess\n        MAX_THREAD = min(multiprocessing.cpu_count(), n_fragments)\n        Parallel(n_jobs=MAX_THREAD)(delayed(process_single_fragment)(\n            fragment_id, color_files, depth_files, n_files, n_fragments, config)\n                                     for fragment_id in range(n_fragments))\n    else:\n        for fragment_id in range(n_fragments):\n            process_single_fragment(fragment_id, color_files, depth_files,\n                                    n_files, n_fragments, config)\n    print(\"Done.\")\n```\n\n----------------------------------------\n\nTITLE: Executing Octree Traversal\nDESCRIPTION: Demonstrates the execution of octree traversal using the defined traversal function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/octree.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\noctree = o3d.geometry.Octree(max_depth=4)\noctree.convert_from_point_cloud(pcd, size_expand=0.01)\noctree.traverse(f_traverse)\n```\n\n----------------------------------------\n\nTITLE: Rendering Loop Pseudocode in Open3D\nDESCRIPTION: This snippet shows the pseudocode for the rendering loop used in draw_geometries(). It demonstrates how geometry binding and rendering are controlled by flags for efficient updates.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/non_blocking_visualization.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nwhile(true):\n    if (geometry has changed):\n        re-bind geometry to shaders\n    if (view parameters have changed):\n        re-render the scene\n    if (any user mouse/keyboard input):\n        respond to it and set flags for re-rendering\n```\n\n----------------------------------------\n\nTITLE: Initial Point Cloud Alignment Setup\nDESCRIPTION: Sets up initial alignment between two point clouds using a transformation matrix, which is required for ICP algorithm to converge efficiently.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndemo_icp_pcds = o3d.data.DemoICPPointClouds()\nsource = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[0])\ntarget = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[1])\n\n# Initial guess transform between the two point-cloud.\n# ICP algorithm requires a good initial alignment to converge efficiently.\ntrans_init = np.asarray([[0.862, 0.011, -0.507, 0.5],\n                         [-0.139, 0.967, -0.215, 0.7],\n                         [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n\ndraw_registration_result(source, target, trans_init)\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Cone with UV Mapping in Open3D\nDESCRIPTION: Demonstrates how to create a cone with UV mapping and visualize it using Open3D. The 'create_uv_map' parameter is set to True to generate UV coordinates.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncone = o3d.geometry.TriangleMesh.create_cone(create_uv_map=True)\no3d.visualization.draw({'name': 'cone', 'geometry': cone, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Non-rigid Color Map Optimization\nDESCRIPTION: Implements non-rigid optimization for enhanced color mapping quality, considering local image warping with anchor points.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/color_map_optimization.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Run non-rigid optimization.\nmaximum_iteration = 100 if is_ci else 300\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    mesh, camera_trajectory = o3d.pipelines.color_map.run_non_rigid_optimizer(\n        mesh, rgbd_images, camera_trajectory,\n        o3d.pipelines.color_map.NonRigidOptimizerOption(\n            maximum_iteration=maximum_iteration))\n```\n\n----------------------------------------\n\nTITLE: Applying Gaussian Noise to Source Point Cloud\nDESCRIPTION: Defines a function to apply Gaussian noise to a point cloud and applies it to the source point cloud to simulate noisy data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef apply_noise(pcd, mu, sigma):\n    device = pcd.point[\"positions\"].device\n    noisy_pcd = pcd.cpu().clone()\n    noisy_pcd.point[\"positions\"] += o3d.core.Tensor(\n        np.random.normal(mu, sigma, size=noisy_pcd.point[\"positions\"].shape),\n        noisy_pcd.point[\"positions\"].dtype)\n    return noisy_pcd\n\n\nmu, sigma = 0, 0.1  # mean and standard deviation\nsource_noisy = apply_noise(source, mu, sigma)\n\nprint(\"Source PointCloud + noise:\")\no3d.visualization.draw_geometries([source_noisy.to_legacy()],\n                                  zoom=0.4459,\n                                  front=[0.353, -0.469, -0.809],\n                                  lookat=[2.343, 2.217, 1.809],\n                                  up=[-0.097, -0.879, 0.467])\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Headless CPU Rendering in Jupyter\nDESCRIPTION: Sets the EGL_PLATFORM environment variable to 'surfaceless' in a Jupyter notebook to enable headless CPU rendering before importing Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/cpu_rendering.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n%env EGL_PLATFORM surfaceless   # Ubuntu 20.04+\nimport open3d as o3d\n```\n\n----------------------------------------\n\nTITLE: Defining Core Module Structure in ReStructuredText\nDESCRIPTION: This snippet defines the structure of the Core module documentation using ReStructuredText directives. It sets up a table of contents (toctree) that includes references to tensor and hashmap components.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/core/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _core\n\nCore\n======\n\n.. toctree::\n    tensor\n    hashmap\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Setting Up Environment for Open3D ICP Registration\nDESCRIPTION: This snippet imports necessary libraries and sets up the environment for the ICP registration tutorial. It includes Open3D, NumPy, and custom modules for visualization helpers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/icp_registration.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport copy\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Initial Texture Mapping Visualization\nDESCRIPTION: Performs initial texture mapping without optimization (maximum_iteration=0) to show unoptimized results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/color_map_optimization.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Before full optimization, let's visualize texture map\n# with given geometry, RGBD images, and camera poses.\nmesh, camera_trajectory = o3d.pipelines.color_map.run_rigid_optimizer(\n    mesh, rgbd_images, camera_trajectory,\n    o3d.pipelines.color_map.RigidOptimizerOption(maximum_iteration=0))\no3d.visualization.draw_geometries([mesh],\n                                  zoom=0.5399,\n                                  front=[0.0665, -0.1107, -0.9916],\n                                  lookat=[0.7353, 0.6537, 1.0521],\n                                  up=[0.0136, -0.9936, 0.1118])\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Point Cloud in Python for Open3D Reconstruction\nDESCRIPTION: This function downsamples a point cloud, estimates normals, and computes FPFH features. It prepares the point cloud for registration by making it sparser and regularly distributed.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/register_fragments.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_point_cloud(pcd, config):\n    voxel_size = config[\"voxel_size\"]\n    pcd_down = pcd.voxel_down_sample(voxel_size)\n    pcd_down.estimate_normals(\n        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2.0,\n                                            max_nn=30))\n    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n        pcd_down,\n        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5.0,\n                                            max_nn=100))\n    return (pcd_down, pcd_fpfh)\n```\n\n----------------------------------------\n\nTITLE: Rendering a 3D Sphere with Open3D Python API\nDESCRIPTION: Python code example demonstrating how to create a 3D sphere mesh, compute vertex normals, and visualize it using Open3D's visualization module.\nSOURCE: https://github.com/isl-org/open3d/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npython -c \"import open3d as o3d; \\\n           mesh = o3d.geometry.TriangleMesh.create_sphere(); \\\n           mesh.compute_vertex_normals(); \\\n           o3d.visualization.draw(mesh, raw_mode=True)\"\n```\n\n----------------------------------------\n\nTITLE: Reading and Creating RGBD Image from TUM Dataset\nDESCRIPTION: Loads color and depth images from the TUM dataset and creates an RGBD image using the TUM format parser in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Read TUM dataset\")\ntum_rgbd = o3d.data.SampleSUNRGBDImage()\ncolor_raw = o3d.io.read_image(tum_rgbd.color_path)\ndepth_raw = o3d.io.read_image(tum_rgbd.depth_path)\nrgbd_image = o3d.geometry.RGBDImage.create_from_tum_format(color_raw, depth_raw)\nprint(rgbd_image)\n```\n\n----------------------------------------\n\nTITLE: Examining Ray Hit Results\nDESCRIPTION: Displays the hit distance and geometry IDs from the ray casting results, showing which ray hit the mesh and which one missed.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(ans['t_hit'].numpy(), ans['geometry_ids'].numpy())\n```\n\n----------------------------------------\n\nTITLE: Configuring WebRTC STUN/TURN Servers for Open3D\nDESCRIPTION: This snippet demonstrates how to set up WebRTC STUN/TURN servers for Open3D. It includes examples for TCP-only configuration and a combination of UDP and TCP servers. These settings are crucial for establishing peer connections in various network environments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# TCP only\nWEBRTC_STUN_SERVER=\"turn:user:password@my_tcp_turn_server.com:3478?transport=tcp\"\n# UDP and TCP (more than one TURN servers)\nWEBRTC_STUN_SERVER=\"turn:user:password@my_turn_server.com:3478;turn:user:password@my_tcp_turn_server.com:3478?transport=tcp\"\n```\n\n----------------------------------------\n\nTITLE: Processing Redwood Indoor Living Room Dataset\nDESCRIPTION: Loads and processes the Redwood indoor living room dataset including point cloud and RGBD image sequences.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_62\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.RedwoodIndoorLivingRoom1()\nassert Path(gt_download_dir).is_dir()\npcd = o3d.io.read_point_cloud(dataset.point_cloud_path)\n\nim_rgbds = []\nfor color_path, depth_path in zip(dataset.color_paths, dataset.depth_paths):\n    im_color = o3d.io.read_image(color_path)\n    im_depth = o3d.io.read_image(depth_path)\n    im_rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        im_color, im_depth)\n    im_rgbds.append(im_rgbd)\n\nim_noisy_rgbds = []\nfor color_path, depth_path in zip(dataset.color_paths,\n                                  dataset.noisy_depth_paths):\n    im_color = o3d.io.read_image(color_path)\n    im_depth = o3d.io.read_image(depth_path)\n    im_rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        im_color, im_depth)\n    im_noisy_rgbds.append(im_rgbd)\n```\n\n----------------------------------------\n\nTITLE: Implementing Hash Set in Open3D\nDESCRIPTION: Demonstrates the usage of hash set for storing unique keys without associated values. Shows initialization, insertion of potentially duplicate values, and viewing active keys.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nhashset = o3c.HashSet(capacity,\n                      key_dtype=o3c.int64,\n                      key_element_shape=(1,),\n                      device=device)\nkeys = o3c.Tensor([1, 3, 5, 7, 5, 3, 1], dtype=o3c.int64,\n                  device=device).reshape((-1, 1))\nhashset.insert(keys)\n\nkeys = o3c.Tensor([5, 7, 9, 11], dtype=o3c.int64, device=device).reshape(\n    (-1, 1))\nhashset.insert(keys)\n\n\ndef print_active_keys(hashset):\n    active_buf_indices = hashset.active_buf_indices().to(o3c.int64)\n    active_keys = hashset.key_tensor()[active_buf_indices]\n    print('active keys:\\n', active_keys)\n\n\nprint_active_keys(hashset)\n```\n\n----------------------------------------\n\nTITLE: Loading Point Cloud Data for ICP Registration\nDESCRIPTION: Loads source and target point clouds from demo data provided by Open3D for ICP registration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndemo_icp_pcds = o3d.data.DemoICPPointClouds()\nsource = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[0])\ntarget = o3d.t.io.read_point_cloud(demo_icp_pcds.paths[1])\n```\n\n----------------------------------------\n\nTITLE: Azure Kinect Sensor Configuration (JSON)\nDESCRIPTION: Example JSON configuration for Azure Kinect sensor settings, including camera FPS, color format, and depth mode.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/azure_kinect.rst#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"camera_fps\" : \"K4A_FRAMES_PER_SECOND_30\",\n    \"color_format\" : \"K4A_IMAGE_FORMAT_COLOR_MJPG\",\n    \"color_resolution\" : \"K4A_COLOR_RESOLUTION_720P\",\n    \"depth_delay_off_color_usec\" : \"0\",\n    \"depth_mode\" : \"K4A_DEPTH_MODE_WFOV_2X2BINNED\",\n    \"disable_streaming_indicator\" : \"false\",\n    \"subordinate_delay_off_master_usec\" : \"0\",\n    \"synchronized_images_only\" : \"false\",\n    \"wired_sync_mode\" : \"K4A_WIRED_SYNC_MODE_STANDALONE\"\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D and Setting Up Environment for ICP Registration\nDESCRIPTION: Imports necessary Open3D modules and sets up the environment for ICP registration, including device-specific imports and visualization helpers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport open3d.core as o3c\n\nif o3d.__DEVICE_API__ == 'cuda':\n    import open3d.cuda.pybind.t.pipelines.registration as treg\nelse:\n    import open3d.cpu.pybind.t.pipelines.registration as treg\n\nimport numpy as np\nimport sys\nimport os\nimport time\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Sphere with UV Mapping in Open3D\nDESCRIPTION: Shows the process of creating a sphere with UV mapping and visualizing it using Open3D's TriangleMesh class and visualization functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nsphere = o3d.geometry.TriangleMesh.create_sphere(create_uv_map=True)\no3d.visualization.draw({'name': 'sphere', 'geometry': sphere, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Colorizing Mesh Boundary Vertices\nDESCRIPTION: Identifies boundary vertices of a HalfEdgeTriangleMesh and colorizes them to red, while setting other vertices to a gray color. Uses Vector3dVector to convert the numpy array of colors to Open3D format.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/half_edge_mesh.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Colorize boundary vertices to red\nvertex_colors = 0.75 * np.ones((len(het_mesh.vertices), 3))\nfor boundary in het_mesh.get_boundaries():\n    for vertex_id in boundary:\n        vertex_colors[vertex_id] = [1, 0, 0]\nhet_mesh.vertex_colors = o3d.utility.Vector3dVector(vertex_colors)\no3d.visualization.draw_geometries([het_mesh], mesh_show_back_face=True)\n```\n\n----------------------------------------\n\nTITLE: Verifying Open3D Installation in Python\nDESCRIPTION: Command to verify the successful installation of Open3D by importing the package and displaying its version number.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Verify installation\npython -c \"import open3d as o3d; print(o3d.__version__)\"\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Virtual Environment for Open3D\nDESCRIPTION: Commands to install virtualenv, create a Python 3 virtual environment, and install required packages (numpy and matplotlib) for Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/headless_rendering.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ sudo apt-get install virtualenv python-pip\n$ virtualenv -p /usr/bin/python3 py3env\n$ source py3env/bin/activate\n(py3env) $ pip install numpy matplotlib\n```\n\n----------------------------------------\n\nTITLE: Open3D PyTorch Operations Module Structure\nDESCRIPTION: ReStructuredText documentation defining the structure and available functions in the open3d.ml.torch.ops module. Lists key operations like spatial hash table building, continuous convolutions, search algorithms, and voxel operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/python_api_in/open3d.ml.torch.ops.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: open3d.ml.torch.ops\n\n.. automodule:: open3d.ml.torch.ops\n\n**Functions**\n\n.. autosummary::\n\n    build_spatial_hash_table\n    continuous_conv\n    continuous_conv_transpose\n    fixed_radius_search\n    invert_neighbors_list\n    knn_search\n    nms\n    radius_search\n    reduce_subarrays_sum\n    voxel_pooling\n    voxelize\n```\n\n----------------------------------------\n\nTITLE: Pickle Support for Open3D Tensors (Python)\nDESCRIPTION: Demonstrates the pickle support for Open3D tensors, allowing serialization and deserialization. It covers pickling tensors on both CPU and GPU, as well as handling non-contiguous tensors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport pickle\nimport tempfile\n\n\na = o3c.Tensor([1, 2, 3, 4])\nprint(f'After serialization: {a}\\n')\nwith tempfile.TemporaryDirectory() as path:\n    file_name = os.path.join(path, 'tensor')\n    pickle.dump(a, open(file_name, 'wb'))\n    b = pickle.load(open(file_name, 'rb'))\n    print(f'After deserialization: {b}\\n')\n\n# Pickle tensor on GPU.\na = o3c.Tensor([1, 2, 3, 4], device=o3c.Device('cuda:0'))\nprint(f'After serialization: {a}\\n')\nwith tempfile.TemporaryDirectory() as path:\n    file_name = os.path.join(path, 'tensor')\n    pickle.dump(a, open(file_name, 'wb'))\n    b = pickle.load(open(file_name, 'rb'))\n    print(f'After deserialization: {b}\\n')\n\n# Pickle non-contiguous tensor.\na = o3c.Tensor.ones((100))\na = a[::2]\nprint(f'Contiguous: {a.is_contiguous()}\\n')\nwith tempfile.TemporaryDirectory() as path:\n    file_name = os.path.join(path, 'tensor')\n    pickle.dump(a, open(file_name, 'wb'))\n    b = pickle.load(open(file_name, 'rb'))\n    print(f'Contiguous: {b.is_contiguous()}\\n')\n```\n\n----------------------------------------\n\nTITLE: Updating Pose Graph for Scene Registration in Python with Open3D\nDESCRIPTION: This function builds and updates a pose graph for multiway registration of all fragments. It computes pairwise registrations and adds them to the pose graph for global optimization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/register_fragments.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef update_posegraph_for_scene(s, t, transformation, information, odometry,\n                         pose_graph):\n    if t == s + 1:  # odometry case\n        odometry = np.dot(transformation, odometry)\n        odometry_inv = np.linalg.inv(odometry)\n        pose_graph.nodes.append(\n            o3d.pipelines.registration.PoseGraphNode(odometry_inv))\n        pose_graph.edges.append(\n            o3d.pipelines.registration.PoseGraphEdge(s,\n                                                    t,\n                                                    transformation,\n                                                    information,\n                                                    uncertain=False))\n    else:  # loop closure case\n        pose_graph.edges.append(\n            o3d.pipelines.registration.PoseGraphEdge(s,\n                                                    t,\n                                                    transformation,\n                                                    information,\n                                                    uncertain=True))\n    return pose_graph\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D Python Module\nDESCRIPTION: Shows how to import the Open3D Python module with the standard alias o3d.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/python_interface.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\n```\n\n----------------------------------------\n\nTITLE: Querying Keys in an Open3D Hash Map\nDESCRIPTION: Demonstrates how to find values associated with specific keys in the hash map. The operation returns buffer indices and masks for successful matches.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nquery_keys = o3c.Tensor([[1000], [100], [300], [200], [100], [0]],\n                        dtype=o3c.int64,\n                        device=device)\nbuf_indices, masks = hashmap.find(query_keys)\nvalid_keys = query_keys[masks]\nbuf_indices = buf_indices[masks].to(o3c.int64)\nvalid_vals = hashmap.value_tensor()[buf_indices]\nprint('found valid keys: \\n', valid_keys)\nprint('found valid values: \\n', valid_vals)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Geometry IDs from Ray Casting\nDESCRIPTION: Visualizes which geometry (cube, torus, or sphere) was hit by each ray, using the geometry IDs returned from ray casting.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nplt.imshow(ans['geometry_ids'].numpy(), vmax=3)\n```\n\n----------------------------------------\n\nTITLE: Configuring ManuallyAlignPointCloud Executable in CMake\nDESCRIPTION: Sets up the ManuallyAlignPointCloud executable with its source files, dependencies, and build properties. The executable is configured to link against Open3D and third-party libraries (jsoncpp and tinyfiledialogs) while also setting folder organization and warning behavior.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tools/ManuallyAlignPointCloud/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(ManuallyAlignPointCloud)\n\ntarget_sources(ManuallyAlignPointCloud PRIVATE\n    ManuallyAlignPointCloud.cpp\n    AlignmentSession.cpp\n    VisualizerForAlignment.cpp\n)\ntarget_link_libraries(ManuallyAlignPointCloud PRIVATE\n    Open3D::Open3D\n    Open3D::3rdparty_jsoncpp\n    Open3D::3rdparty_tinyfiledialogs\n)\n\nset_target_properties(ManuallyAlignPointCloud PROPERTIES FOLDER \"Tools\")\nopen3d_show_and_abort_on_warning(ManuallyAlignPointCloud)\nopen3d_set_global_properties(ManuallyAlignPointCloud)\n```\n\n----------------------------------------\n\nTITLE: Loading Juneau Image using Open3D C++\nDESCRIPTION: This C++ snippet shows how to load the Juneau sample image dataset via `open3d::data::JuneauImage`. It uses the path provided by the dataset object to load the image using `open3d::io::CreateImageFromFile`.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_43\n\nLANGUAGE: cpp\nCODE:\n```\ndata::JuneauImage img_data;\nauto img = io::CreateImageFromFile(img_data.path);\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Signed Distance Function in Open3D\nDESCRIPTION: This code defines a custom function to compute signed distances and closest geometry IDs for query points using RaycastingScene's intersection counting and closest point computation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef compute_signed_distance_and_closest_goemetry(query_points: np.ndarray):\n    closest_points = scene.compute_closest_points(query_points)\n    distance = np.linalg.norm(query_points - closest_points['points'].numpy(),\n                              axis=-1)\n    rays = np.concatenate([query_points, np.ones_like(query_points)], axis=-1)\n    intersection_counts = scene.count_intersections(rays).numpy()\n    is_inside = intersection_counts % 2 == 1\n    distance[is_inside] *= -1\n    return distance, closest_points['geometry_ids'].numpy()\n```\n\n----------------------------------------\n\nTITLE: Loading Point Cloud and Creating RGBD Images in Python\nDESCRIPTION: This snippet demonstrates loading a point cloud and creating RGBD images from color and depth data using Open3D's Python API. It reads the dataset, loads the point cloud, and then iterates through color and depth image pairs to create both clean and noisy RGBD images.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_63\n\nLANGUAGE: python\nCODE:\n```\nassert Path(gt_download_dir).is_dir()\npcd = o3d.io.read_point_cloud(dataset.point_cloud_path)\n\nim_rgbds = []\nfor color_path, depth_path in zip(dataset.color_paths, dataset.depth_paths):\n    im_color = o3d.io.read_image(color_path)\n    im_depth = o3d.io.read_image(depth_path)\n    im_rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        im_color, im_depth)\n    im_rgbds.append(im_rgbd)\n\nim_noisy_rgbds = []\nfor color_path, depth_path in zip(dataset.color_paths,\n                                  dataset.noisy_depth_paths):\n    im_color = o3d.io.read_image(color_path)\n    im_depth = o3d.io.read_image(depth_path)\n    im_rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        im_color, im_depth)\n    im_noisy_rgbds.append(im_rgbd)\n```\n\n----------------------------------------\n\nTITLE: Extracting Frames from Azure Kinect MKV (Python)\nDESCRIPTION: Command to run the Open3D Azure Kinect MKV Reader Python script to extract color and depth image frames from an MKV file.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/azure_kinect.rst#2025-04-23_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\npython examples/python/reconstruction_system/sensors/azure_kinect_mkv_reader.py --input record.mkv --output frames\n```\n\n----------------------------------------\n\nTITLE: Achieving Stable Plane Segmentation with Open3D RANSAC in Python\nDESCRIPTION: This snippet shows how to achieve deterministic results for plane segmentation using Open3D's RANSAC implementation. By setting the random seed using `o3d.utility.random.seed(0)` before calling `segment_plane` and setting the `probability` parameter to 1.0, the algorithm is forced to run for the exact number of iterations specified by `num_iterations`, ensuring reproducible outcomes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n```python\no3d.utility.random.seed(0)\n\nplane_model, inliers = pcd.segment_plane(distance_threshold=0.01,\n                                            ransac_n=3,\n                                            num_iterations=1000, \n                                            probability=1.0)\n```\n```\n\n----------------------------------------\n\nTITLE: Loading Multiple Living Room Point Clouds in Python\nDESCRIPTION: Demonstrates how to load multiple point clouds from the Living Room dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.LivingRoomPointClouds()\npcds = []\nfor pcd_path in dataset.paths:\n    pcds.append(o3d.io.read_point_cloud(pcd_path))\n```\n\n----------------------------------------\n\nTITLE: Directory Structure Comparison of Open3D Installation for Linux/MacOS and Windows\nDESCRIPTION: This code snippet shows the directory structure comparison between Linux/MacOS and Windows installations of Open3D. It illustrates where to find header files, libraries, shared objects, and resources after extracting the archive to a local folder.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nLinux / MacOSX:                       Windows:\nOpen3D_install                        Open3D_install\n include                            bin\n    open3d                            Open3D.dll\n        core                          resources\n        ...                               brightday_ibl.ktx\n        Open3DConfig.h                    ...\n        Open3D.h                  \n        ...                        CMake\n lib                                   Open3DConfig.cmake\n    cmake                             ...\n       Open3D                     include\n            ...                      open3d\n    pkgconfig                             core\n       Open3D.pc                         ...\n       ...                               Open3DConfig.h\n|   |                                         Open3D.h\n    libOpen3D.so                          ...\n    open3d_tf_ops.so               lib\n    open3d_torch_ops.so                Open3D.lib\n share\n     resources\n         html\n             ...\n         brightday_ibl.ktx\n         ...\n```\n\n----------------------------------------\n\nTITLE: Open3D PyTorch Operations TOC Tree\nDESCRIPTION: ReStructuredText table of contents tree structure defining the documentation pages for each operation in the module. Each operation has its own dedicated documentation page.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/python_api_in/open3d.ml.torch.ops.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :hidden:\n\n    build_spatial_hash_table <open3d.ml.torch.ops.build_spatial_hash_table>\n    continuous_conv <open3d.ml.torch.ops.continuous_conv>\n    continuous_conv_transpose <open3d.ml.torch.ops.continuous_conv_transpose>\n    fixed_radius_search <open3d.ml.torch.ops.fixed_radius_search>\n    invert_neighbors_list <open3d.ml.torch.ops.invert_neighbors_list>\n    knn_search <open3d.ml.torch.ops.knn_search>\n    nms <open3d.ml.torch.ops.nms>\n    radius_search <open3d.ml.torch.ops.radius_search>\n    reduce_subarrays_sum <open3d.ml.torch.ops.reduce_subarrays_sum>\n    voxel_pooling <open3d.ml.torch.ops.voxel_pooling>\n    voxelize <open3d.ml.torch.ops.voxelize>\n```\n\n----------------------------------------\n\nTITLE: Enabling WebRTC Server in C++\nDESCRIPTION: Demonstrates how to enable the WebRTC server backend in C++ code for Open3D web visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_0\n\nLANGUAGE: cpp\nCODE:\n```\nopen3d::visualization::webrtc_server::WebRTCWindowSystem::GetInstance()->EnableWebRTC();\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D and Setting Up Environment for ISS Keypoint Detection\nDESCRIPTION: Sets up the necessary imports for Open3D and configures visualization options. It includes system path modification to access tutorial helpers and disables interactive mode in CI environments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/iss_keypoint_detector.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport os\nimport time\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Include Directories for tpipelines\nDESCRIPTION: Conditionally adds CUDA toolkit include directories to the tpipelines target if CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nif(BUILD_CUDA_MODULE)\n    target_include_directories(tpipelines SYSTEM PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Updating PoseGraph for Scene Registration\nDESCRIPTION: Updates a pose graph for multiway registration of fragments. Each node represents a fragment and its pose in global space, with edges representing the registration between fragment pairs.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/refine_registration.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef update_posegraph_for_scene(s, t, transformation, information, odometry, pose_graph):\n    if t == s + 1:  # odometry case\n        pose_graph.edges.append(\n            o3d.pipelines.registration.PoseGraphEdge(s,\n                                                     t,\n                                                     transformation,\n                                                     information,\n                                                     uncertain=False))\n    else:  # loop closure case\n        pose_graph.edges.append(\n            o3d.pipelines.registration.PoseGraphEdge(s,\n                                                     t,\n                                                     transformation,\n                                                     information,\n                                                     uncertain=True))\n```\n\n----------------------------------------\n\nTITLE: Tuning Vanilla ICP with Increased Max Correspondence Distance\nDESCRIPTION: Adjusts the maximum correspondence distance parameter for vanilla ICP to attempt improving registration results with noisy data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nestimation = treg.TransformationEstimationPointToPlane()\n\nmax_correspondence_distance = 0.5\n\nvoxel_size = 0.02\n\nprint(\"Vanilla point-to-plane ICP, max_correspondence_distance={}:\".format(\n    max_correspondence_distance))\n\ns = time.time()\n\nreg_point_to_plane = treg.icp(source, target, max_correspondence_distance,\n                              init_source_to_target, estimation, criteria,\n                              voxel_size)\n\nicp_time = time.time() - s\n\nprint(\"Time taken by Point-To-Plane ICP: \", icp_time)\nprint(\"Fitness: \", reg_point_to_plane.fitness)\nprint(\"Inlier RMSE: \", reg_point_to_plane.inlier_rmse)\n\ndraw_registration_result(source, target, reg_point_to_plane.transformation)\n```\n\n----------------------------------------\n\nTITLE: Locating Point in Octree\nDESCRIPTION: Shows how to find the leaf node containing a specific point in the octree structure.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/octree.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\noctree.locate_leaf_node(pcd.points[0])\n```\n\n----------------------------------------\n\nTITLE: Visualizing SPLAT Format Data\nDESCRIPTION: Visualizes 3D Gaussian Splats from SPLAT format as a point cloud without view-dependent effects.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/3d_gaussian_splatting.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Visualize splat format 3DGS as a point cloud (no view-dependent effects)\ndraw(splat_3dgs)\n```\n\n----------------------------------------\n\nTITLE: Building and Running Open3D Viewer Docker Container\nDESCRIPTION: Commands to build a Docker image with the Open3D viewer application and run it with GPU support. It demonstrates how to set up X11 forwarding and GPU access.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/docker.in.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir open3d-viewer-docker && cd open3d-viewer-docker\n# Download Open3D viewer deb package.\nwget https://github.com/isl-org/Open3D/releases/download/v@OPEN3D_VERSION@/open3d-app-@OPEN3D_VERSION@-Ubuntu.deb\n# Build docker image in folder containing Open3D deb package.\ndocker build -t open3d-viewer -f- . <<EOF\nFROM ubuntu:20.04\nCOPY open3d*.deb /root/\nRUN apt-get update \\\n    && apt-get install --yes /root/open3d*.deb \\\n    && rm -rf /var/lib/apt/lists/*\nENTRYPOINT [\"Open3D\"]\nEOF\n\n# Allow local X11 connections\nxhost local:root\n# Run Open3D viewer docker image with the Intel GPU\ndocker run --device=/dev/dri:/dev/dri \\\n    -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \\\n    -v \"$PWD\":/root open3d-viewer:latest\n# Run Open3D viewer docker image with the NVIDIA GPU\ndocker run  --gpus 'all,\"capabilities=compute,utility,graphics\"' \\\n    -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \\\n    -v \"$PWD\":/root open3d-viewer:latest\n# Run Open3D viewer docker image without a GPU (CPU rendering)\ndocker run -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \\\n    -v \"$PWD\":/root open3d-viewer:latest\n```\n\n----------------------------------------\n\nTITLE: Loading Painted Plaster Texture for Material in C++\nDESCRIPTION: Shows how to load painted plaster-based material textures (albedo, normal, roughness) in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_33\n\nLANGUAGE: cpp\nCODE:\n```\ndata::PaintedPlasterTexture mat_data;\n\nauto mat = visualization::rendering::MaterialRecord();\nmat.shader = \"defaultUnlit\";\nmat.albedo_img = io::CreateImageFromFile(mat_data.albedo_texture_path);\nmat.normal_img = io::CreateImageFromFile(mat_data.normal_texture_path);\nmat.roughness_img = io::CreateImageFromFile(mat_data.roughness_texture_path);\n```\n\n----------------------------------------\n\nTITLE: Helper Function for Visualizing Inliers and Outliers\nDESCRIPTION: Defines a function that visualizes inlier and outlier points in different colors. This helper function uses select_by_index to separate points based on a binary mask, coloring inliers gray and outliers red.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud_outlier_removal.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef display_inlier_outlier(cloud, ind):\n    inlier_cloud = cloud.select_by_index(ind)\n    outlier_cloud = cloud.select_by_index(ind, invert=True)\n\n    print(\"Showing outliers (red) and inliers (gray): \")\n    outlier_cloud.paint_uniform_color([1, 0, 0])\n    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\n    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud],\n                                      zoom=0.3412,\n                                      front=[0.4257, -0.2125, -0.8795],\n                                      lookat=[2.6172, 2.0475, 1.532],\n                                      up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Loading Redwood Indoor Office 2 Dataset in C++\nDESCRIPTION: This C++ code snippet demonstrates loading the Redwood Indoor Office 2 dataset using Open3D's C++ API. It loads a point cloud and creates two collections of RGBD images: one from clean depth data and another from noisy depth data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_66\n\nLANGUAGE: cpp\nCODE:\n```\ndata::RedwoodIndoorOffice2 dataset;\n\nauto pcd = io::CreatePointCloudFromFile(dataset.GetPointCloudPath());\n\nstd::vector<std::shared_ptr<geometry::RGBDImage>> im_rgbds;\nfor (size_t i = 0; i < dataset.GetColorPaths().size(); ++i) {\n    auto im_color = io::CreateImageFromFile(dataset.GetColorPaths()[i]);\n    auto im_depth = io::CreateImageFromFile(dataset.GetDepthPaths()[i]);\n    auto im_rgbd = geometry::RGBDImage::CreateFromColorAndDepth(*im_color,\n                                                                *im_depth);\n    im_rgbds.push_back(im_rgbd);\n}\n\nstd::vector<std::shared_ptr<geometry::RGBDImage>> im_noisy_rgbds;\nfor (size_t i = 0; i < dataset.GetColorPaths().size(); ++i) {\n    auto im_color = io::CreateImageFromFile(dataset.GetColorPaths()[i]);\n    auto im_depth =\n            io::CreateImageFromFile(dataset.GetNoisyDepthPaths()[i]);\n    auto im_rgbd = geometry::RGBDImage::CreateFromColorAndDepth(*im_color,\n                                                                *im_depth);\n    im_noisy_rgbds.push_back(im_rgbd);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining CameraPose Class and Reading Trajectory from Log File in Python\nDESCRIPTION: This snippet defines a CameraPose class and a read_trajectory function to parse camera trajectory data from a .log file. It's used to process camera pose information for RGBD integration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/rgbd_integration.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass CameraPose:\n\n    def __init__(self, meta, mat):\n        self.metadata = meta\n        self.pose = mat\n\n    def __str__(self):\n        return 'Metadata : ' + ' '.join(map(str, self.metadata)) + '\\n' + \\\n            \"Pose : \" + \"\\n\" + np.array_str(self.pose)\n\n\ndef read_trajectory(filename):\n    traj = []\n    with open(filename, 'r') as f:\n        metastr = f.readline()\n        while metastr:\n            metadata = list(map(int, metastr.split()))\n            mat = np.zeros(shape=(4, 4))\n            for i in range(4):\n                matstr = f.readline()\n                mat[i, :] = np.fromstring(matstr, dtype=float, sep=' \\t')\n            traj.append(CameraPose(metadata, mat))\n            metastr = f.readline()\n    return traj\n```\n\n----------------------------------------\n\nTITLE: Point-to-Plane ICP Registration Setup\nDESCRIPTION: Configures and executes point-to-plane ICP registration which typically has faster convergence than point-to-point ICP.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nestimation = treg.TransformationEstimationPointToPlane()\n\ncriteria = treg.ICPConvergenceCriteria(relative_fitness=0.0000001,\n                                       relative_rmse=0.0000001,\n                                       max_iteration=30)\n```\n\n----------------------------------------\n\nTITLE: Loading PCD Point Cloud Dataset in Python\nDESCRIPTION: Demonstrates how to load a PCD format point cloud dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.PCDPointCloud()\npcd = o3d.io.read_point_cloud(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Including TensorBoard Plugin Documentation in Markdown\nDESCRIPTION: This snippet uses a Sphinx directive to include external Markdown content for the TensorBoard plugin documentation. It references a file named 'tensorboard.md' located two directory levels up from the current file.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/tensorboard_plugin.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _tensorboard_plugin:\n\n.. mdinclude:: ../../tensorboard.md\n```\n\n----------------------------------------\n\nTITLE: Citation for Open3D in BibTeX Format\nDESCRIPTION: BibTeX citation format for referencing the Open3D library in academic publications, pointing to the original paper by Zhou, Park, and Koltun.\nSOURCE: https://github.com/isl-org/open3d/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{Zhou2018,\n    author    = {Qian-Yi Zhou and Jaesik Park and Vladlen Koltun},\n    title     = {{Open3D}: {A} Modern Library for {3D} Data Processing},\n    journal   = {arXiv:1801.09847},\n    year      = {2018},\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Optimized Results\nDESCRIPTION: Displays the final mesh after non-rigid optimization with specific camera viewpoint parameters.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/color_map_optimization.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\no3d.visualization.draw_geometries([mesh],\n                                  zoom=0.5399,\n                                  front=[0.0665, -0.1107, -0.9916],\n                                  lookat=[0.7353, 0.6537, 1.0521],\n                                  up=[0.0136, -0.9936, 0.1118])\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Automatic Rehashing in Open3D Hash Map\nDESCRIPTION: Shows how hash map capacity automatically increases (rehashing) when insertions exceed the current capacity, affecting the buffer indices of existing entries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint('size:', hashmap.size())\nprint('capacity:', hashmap.capacity())\n\nkeys = o3c.Tensor([[700], [1200], [1500]], dtype=o3c.int64, device=device)\nvals = o3c.Tensor([[7], [12], [-1]], dtype=o3c.int64, device=device)\nbuf_indices, masks = hashmap.insert(keys, vals)\nprint('size:', hashmap.size())\nprint('capacity:', hashmap.capacity())\nprint_active_entries(hashmap)\n\nkeys = o3c.Tensor([[1600], [1700], [1800]], dtype=o3c.int64, device=device)\nvals = o3c.Tensor([[16], [17], [18]], dtype=o3c.int64, device=device)\nbuf_indices, masks = hashmap.insert(keys, vals)\nprint('size:', hashmap.size())\nprint('capacity:', hashmap.capacity())\nprint_active_entries(hashmap)\n```\n\n----------------------------------------\n\nTITLE: Defining Dimension Limits for Hash Map Keys in C++\nDESCRIPTION: This code snippet defines the dimension limits for hash map keys through a macro. It supports up to 6D coordinates in integer by default and provides error handling for unsupported dimensions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/hashmap.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: cpp\nCODE:\n```\n#define DIM_SWITCHER(DTYPE, DIM, ...)                                    \\\n    if (DIM == 1) {                                                      \\\n        INSTANTIATE_TYPES(DTYPE, 1)                                      \\\n        return __VA_ARGS__();                                            \\\n    } else if (DIM == 2) {                                               \\\n        INSTANTIATE_TYPES(DTYPE, 2)                                      \\\n        return __VA_ARGS__();                                            \\\n    } else if (DIM == 3) {                                               \\\n        INSTANTIATE_TYPES(DTYPE, 3)                                      \\\n        return __VA_ARGS__();                                            \\\n    } else if (DIM == 4) {                                               \\\n        INSTANTIATE_TYPES(DTYPE, 4)                                      \\\n        return __VA_ARGS__();                                            \\\n    } else if (DIM == 5) {                                               \\\n        INSTANTIATE_TYPES(DTYPE, 5)                                      \\\n        return __VA_ARGS__();                                            \\\n    } else if (DIM == 6) {                                               \\\n        INSTANTIATE_TYPES(DTYPE, 6)                                      \\\n        return __VA_ARGS__();                                            \\\n    } else {                                                             \\\n        utility::LogError(                                               \\\n                \"Unsupported dim {}, please modify {} and compile from \" \\\n                \"source\",                                                \\\n                DIM, __FILE__);                                          \\\n    }\n```\n\n----------------------------------------\n\nTITLE: Reading PLY Format Gaussian Splats\nDESCRIPTION: Loads and prints 3D Gaussian Splats from a PLY file format using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/3d_gaussian_splatting.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nply_3dgs = o3d.t.io.read_point_cloud('mipnerf360_garden_crop_table.ply')\nprint(ply_3dgs)\n```\n\n----------------------------------------\n\nTITLE: Rendering Triangle Mesh with Wireframe Visualization\nDESCRIPTION: Demonstrates how to visualize a triangle mesh with wireframe overlay by setting the mesh_show_wireframe parameter to true.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/draw_plotly.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n#draw a triangle mesh with wireframes.\ndataset = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(dataset.path)\no3d.visualization.draw_plotly([mesh],\n                              mesh_show_wireframe=True,\n                              up=[0, 1, 0],\n                              front=[0, 0, 1],\n                              lookat=[0.0, 0.1, 0.0],\n                              zoom=0.5)\n```\n\n----------------------------------------\n\nTITLE: Building with pkg-config in Shell\nDESCRIPTION: Example of how to compile a C++ program that uses Open3D using pkg-config to get the necessary compiler and linker flags. It first adds the Open3D installation path to the PKG_CONFIG_PATH environment variable, then compiles the program with the flags provided by pkg-config.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/cpp_project.rst#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nexport PKG_CONFIG_PATH=\"$PKG_CONFIG_PATH:<Open3D_install_path>/lib/pkgconfig\"\nc++ Draw.cpp -o Draw $(pkg-config --cflags --libs Open3D)\n```\n\n----------------------------------------\n\nTITLE: Loading Metal Texture for Material in Python\nDESCRIPTION: Demonstrates how to load metal-based material textures (albedo, normal, roughness, metallic) in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nmat_data = o3d.data.MetalTexture()\n\nmat = o3d.visualization.rendering.MaterialRecord()\nmat.shader = \"defaultLit\"\nmat.albedo_img = o3d.io.read_image(mat_data.albedo_texture_path)\nmat.normal_img = o3d.io.read_image(mat_data.normal_texture_path)\nmat.roughness_img = o3d.io.read_image(mat_data.roughness_texture_path)\nmat.metallic_img = o3d.io.read_image(mat_data.metallic_texture_path)\n```\n\n----------------------------------------\n\nTITLE: Visualizing SUN Dataset RGBD Image Components\nDESCRIPTION: Displays the color and depth components of the SUN dataset RGBD image using Matplotlib.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nplt.subplot(1, 2, 1)\nplt.title('SUN grayscale image')\nplt.imshow(rgbd_image.color)\nplt.subplot(1, 2, 2)\nplt.title('SUN depth image')\nplt.imshow(rgbd_image.depth)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Loading Sample TUM RGBD Image using Open3D C++\nDESCRIPTION: This C++ code snippet loads the Sample TUM RGBD Image dataset using `open3d::data::SampleTUMRGBDImage`. It reads the color and depth images with `io::CreateImageFromFile` and then constructs an `open3d::geometry::RGBDImage` using the TUM-specific `CreateFromTUMFormat` function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_52\n\nLANGUAGE: cpp\nCODE:\n```\ndata::SampleTUMRGBDImage dataset;\n\nauto color_raw = io::CreateImageFromFile(dataset.GetColorPath());\nauto depth_raw = io::CreateImageFromFile(dataset.GetDepthPath());\nauto rgbd_image = geometry::RGBDImage::CreateFromTUMFormat(\n    *color_raw, *depth_raw, /*convert_rgb_to_intensity =*/ false);\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Environment and Dependencies\nDESCRIPTION: Sets up the required imports and configures environment variables for Open3D tutorial execution. Includes interactive mode handling for CI environments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/color_map_optimization.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport re\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n# if running on Travis CI, the number of iterations is reduced\nis_ci = \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Implementing ARAP Mesh Deformation\nDESCRIPTION: Demonstrates the implementation of as-rigid-as-possible mesh deformation using Open3D. Sets up static and handle constraints for the Armadillo mesh and applies deformation with 50 iterations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh_deformation.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\narmadillo = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(armadillo.path)\n\nvertices = np.asarray(mesh.vertices)\nstatic_ids = [idx for idx in np.where(vertices[:, 1] < -30)[0]]\nstatic_pos = []\nfor id in static_ids:\n    static_pos.append(vertices[id])\nhandle_ids = [2490]\nhandle_pos = [vertices[2490] + np.array((-40, -40, -40))]\nconstraint_ids = o3d.utility.IntVector(static_ids + handle_ids)\nconstraint_pos = o3d.utility.Vector3dVector(static_pos + handle_pos)\n\nwith o3d.utility.VerbosityContextManager(\n        o3d.utility.VerbosityLevel.Debug) as cm:\n    mesh_prime = mesh.deform_as_rigid_as_possible(constraint_ids,\n                                                  constraint_pos,\n                                                  max_iter=50)\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Environment with Dependencies\nDESCRIPTION: Sets up the Open3D environment by importing required libraries and configuring visualization settings. Includes monkey patching for visualization and helper functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/file_io.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Processing Sample Redwood RGBD Images using Open3D C++\nDESCRIPTION: This C++ snippet loads the Sample Redwood RGBD dataset via `open3d::data::SampleRedwoodRGBDImages`. It loops through the color and depth image paths, loads them using `io::CreateImageFromFile`, and creates `geometry::RGBDImage` objects using `CreateFromColorAndDepth` with specified depth scale and truncation. Finally, it loads the reconstructed point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_45\n\nLANGUAGE: cpp\nCODE:\n```\ndata::SampleRedwoodRGBDImages dataset;\n\nstd::vector<std::shared_ptr<geometry::RGBDImage>> rgbd_images;\nfor(size_t i = 0; i < dataset.GetDepthPaths().size(); ++i) {\n    auto color_raw = io::CreateImageFromFile(dataset.GetColorPaths()[i]);\n    auto depth_raw = io::CreateImageFromFile(dataset.GetDepthPaths()[i]);\n\n    auto rgbd_image = geometry::RGBDImage::CreateFromColorAndDepth(\n            *color_raw, *depth_raw,\n            /*depth_scale =*/1000.0,\n            /*depth_trunc =*/3.0,\n            /*convert_rgb_to_intensity =*/false);\n    rgbd_images.push_back(rgbd_image);\n}\n\nauto pcd = io::CreatePointCloudFromFile(dataset.GetReconstructionPath());\n```\n\n----------------------------------------\n\nTITLE: Loading Multiple Living Room Point Clouds in C++\nDESCRIPTION: Shows how to load multiple point clouds from the Living Room dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_9\n\nLANGUAGE: cpp\nCODE:\n```\ndata::LivingRoomPointClouds dataset;\nstd::vector<std::shared_ptr<geometry::PointCloud>> pcds;\nfor (const std::string& pcd_path: dataset.GetPaths()) {\n    pcds.push_back(io::CreatePointCloudFromFile(pcd_path));\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning Open3D Repository with Git\nDESCRIPTION: Command to clone the Open3D repository from GitHub using git.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/isl-org/Open3D\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D in Python\nDESCRIPTION: Example code showing the standard way to import Open3D in Python scripts, demonstrating the conventional import alias.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/contribute/example_python_docstring.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\n```\n\n----------------------------------------\n\nTITLE: Installing Jupyter for Open3D Visualization\nDESCRIPTION: Shell commands for installing Jupyter Notebook or JupyterLab for use with Open3D web visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\npip install jupyter\njupyter notebook\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D and Web Visualizer\nDESCRIPTION: This snippet imports the necessary modules from Open3D, including the main library and the web visualizer for rendering 3D objects.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/jupyter_visualization.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nfrom open3d.web_visualizer import draw\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Source Files for Miscellaneous Operations\nDESCRIPTION: Conditionally adds CUDA implementations of miscellaneous operations like hash table building and search operations when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\n    target_sources(open3d_tf_ops PRIVATE\n        misc/BuildSpatialHashTableOpKernel.cu\n        misc/FixedRadiusSearchOpKernel.cu\n        misc/InvertNeighborsListOpKernel.cu\n        misc/NmsOpKernel.cu\n        misc/ReduceSubarraysSumOpKernel.cu\n        misc/VoxelizeOpKernel.cu\n    )\n```\n\n----------------------------------------\n\nTITLE: Building Open3D Python Wheel with Docker on ARM64 Linux\nDESCRIPTION: This snippet shows how to build Open3D Python wheels using Docker for different Python versions on ARM64 Linux. It includes commands for building and installing the wheel.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/arm.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd docker\n\n./docker_build.sh openblas-arm64-py38   # Python 3.8\n./docker_build.sh openblas-arm64-py39   # Python 3.9\n./docker_build.sh openblas-arm64-py310  # Python 3.10\n./docker_build.sh openblas-arm64-py311  # Python 3.11\n./docker_build.sh openblas-arm64-py312  # Python 3.12\n\n# Optional: activate your virtualenv\nconda activate your-virtual-env\n\n# Install and test\npip install open3d-*.whl\npython -c \"import open3d; print(open3d.__version__)\"\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw_geometries([c])\"\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw(c)\"\n```\n\n----------------------------------------\n\nTITLE: Downsampling Point Cloud for Faster Visualization\nDESCRIPTION: Shows how to downsample a point cloud by adjusting the point_sample_factor parameter to improve visualization performance.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/draw_plotly.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#we can downsample these points to speed up visualization by adjusting \n# point_sample_factor to a smaller number\ndataset = o3d.data.PLYPointCloud()\noffice = o3d.io.read_point_cloud(dataset.path)\no3d.visualization.draw_plotly([office], point_sample_factor=0.1)\n```\n\n----------------------------------------\n\nTITLE: Customized Ray Casting Rendering in Open3D Python\nDESCRIPTION: This snippet demonstrates how to perform customized ray casting rendering. It manually performs trilinear interpolation by accessing properties at 8 nearest neighbor voxels with respect to the found surface point per pixel.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/ray_casting.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nresults = vbg.ray_cast(block_coords, intrinsic, extrinsic, resolution,\n                       depth, properties, o3c.nns.ball_query(0.02, 8))\n\nrendered_color = render_color(results['indices'], results['weights'],\n                               results['sdf'], results['color'])\nrendered_normal = render_normal(results['indices'], results['weights'],\n                                 results['sdf'], results['normal'])\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Box with UV Mapping in Open3D\nDESCRIPTION: Demonstrates how to create a box with UV mapping and visualize it using Open3D. The 'create_uv_map' parameter is set to True to generate UV coordinates.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nbox = o3d.geometry.TriangleMesh.create_box(create_uv_map=True)\no3d.visualization.draw({'name': 'box', 'geometry': box, 'material': material})\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Building Open3D on ARM64 Linux\nDESCRIPTION: This snippet provides instructions for installing dependencies and building Open3D directly on ARM64 Linux. It includes commands for installing dependencies, configuring CMake, and building the project.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/arm.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Install dependencies\n./util/install_deps_ubuntu.sh\n\n# Optional: ccache is recommended to speed up subsequent builds\nsudo apt-get install -y ccache\n\n# Check cmake version, you should have 3.19+\ncmake --version\n\n# Optional: activate your virtualenv\nconda activate your-virtual-env\n\n# Configure\n# Set -DBUILD_CUDA_MODULE=ON if CUDA is available (e.g. on Nvidia Jetson)\n# Set -DBUILD_GUI=ON if full OpenGL is available (e.g. on Nvidia Jetson)\ncd Open3D && mkdir build && cd build\ncmake -DBUILD_CUDA_MODULE=OFF -DBUILD_GUI=OFF ..\n\n# Build\nmake -j$(nproc)\nmake install-pip-package -j$(nproc)\n\n# Test C++ viewer app (only available when -DBUILD_GUI=ON)\n./bin/Open3D/Open3D\n\n# Test Python visualization (only available when -DBUILD_GUI=ON)\npython -c \"import open3d; print(open3d.__version__)\"\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw_geometries([c])\"\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw(c)\"\n```\n\n----------------------------------------\n\nTITLE: Loading Crate Model with PBR Texture in Python\nDESCRIPTION: Demonstrates how to load the Crate model with PBR texture in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.CrateModel()\nmodel = o3d.io.read_triangle_model(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Customized Rendering Loop for ICP Visualization in Python\nDESCRIPTION: This code snippet demonstrates how to create a custom rendering loop to visualize ICP registration iterations. It shows how to update geometry and render new frames without blocking.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/non_blocking_visualization.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nvis = Visualizer()\nvis.create_window()\nvis.add_geometry(geometry)\nfor i in range(icp_iteration):\n    # do ICP single iteration\n    # transform geometry using ICP\n    vis.update_geometry(geometry)\n    vis.poll_events()\n    vis.update_renderer()\n```\n\n----------------------------------------\n\nTITLE: Pose Graph Optimization Demo\nDESCRIPTION: Loads fragment and global pose graphs for pose graph optimization demonstration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_61\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.DemoPoseGraphOptimization()\npose_graph_fragment = o3d.io.read_pose_graph(dataset.pose_graph_fragment_path)\npose_graph_global = o3d.io.read_pose_graph(dataset.pose_graph_global_path)\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D and Required Libraries in Python\nDESCRIPTION: This snippet imports necessary libraries including Open3D, NumPy, Matplotlib, and sets up the environment for the tutorial.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/voxelization.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\nimport os\nimport sys\n\n# only needed for tutorial, monkey patches visualization\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Loading Wood Textures into MaterialRecord using Open3D C++\nDESCRIPTION: This C++ snippet demonstrates loading the built-in wood texture dataset using `open3d::data::WoodTexture`. It reads the albedo, normal, and roughness texture images using `open3d::io::CreateImageFromFile` and assigns them to an `open3d::visualization::rendering::MaterialRecord` configured with the 'defaultUnlit' shader.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_39\n\nLANGUAGE: cpp\nCODE:\n```\ndata::WoodTexture mat_data;\n\nauto mat = visualization::rendering::MaterialRecord();\nmat.shader = \"defaultUnlit\";\nmat.albedo_img = io::CreateImageFromFile(mat_data.albedo_texture_path);\nmat.normal_img = io::CreateImageFromFile(mat_data.normal_texture_path);\nmat.roughness_img = io::CreateImageFromFile(mat_data.roughness_texture_path);\n```\n\n----------------------------------------\n\nTITLE: Getting Help for PointCloud Class in Open3D\nDESCRIPTION: Demonstrates how to access documentation for the PointCloud class in Open3D's geometry module using Python's help function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/python_interface.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nhelp(o3d.geometry.PointCloud)\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D Python Package via pip\nDESCRIPTION: Commands for installing the Open3D Python package using pip. Includes options for both standard and CPU-only installations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install open3d        # or\npip install open3d-cpu    # Smaller CPU only wheel on x86_64 Linux (since v0.17+)\n```\n\n----------------------------------------\n\nTITLE: Loading Redwood Indoor Office 1 Dataset in C++\nDESCRIPTION: This C++ code example demonstrates loading the Redwood Indoor Office 1 dataset using Open3D's C++ API. It creates a point cloud from a file and constructs vectors of RGBD images from both clean and noisy depth data paired with color images.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_64\n\nLANGUAGE: cpp\nCODE:\n```\ndata::RedwoodIndoorOffice1 dataset;\n\nauto pcd = io::CreatePointCloudFromFile(dataset.GetPointCloudPath());\n\nstd::vector<std::shared_ptr<geometry::RGBDImage>> im_rgbds;\nfor (size_t i = 0; i < dataset.GetColorPaths().size(); ++i) {\n    auto im_color = io::CreateImageFromFile(dataset.GetColorPaths()[i]);\n    auto im_depth = io::CreateImageFromFile(dataset.GetDepthPaths()[i]);\n    auto im_rgbd = geometry::RGBDImage::CreateFromColorAndDepth(*im_color,\n                                                                *im_depth);\n    im_rgbds.push_back(im_rgbd);\n}\n\nstd::vector<std::shared_ptr<geometry::RGBDImage>> im_noisy_rgbds;\nfor (size_t i = 0; i < dataset.GetColorPaths().size(); ++i) {\n    auto im_color = io::CreateImageFromFile(dataset.GetColorPaths()[i]);\n    auto im_depth =\n            io::CreateImageFromFile(dataset.GetNoisyDepthPaths()[i]);\n    auto im_rgbd = geometry::RGBDImage::CreateFromColorAndDepth(*im_color,\n                                                                *im_depth);\n    im_noisy_rgbds.push_back(im_rgbd);\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Available SYCL Devices for Open3D\nDESCRIPTION: Example of the sycl-ls command output showing available SYCL devices, which is used to identify GPU devices for Open3D SYCL implementation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README_SYCL.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ sycl-ls\n[opencl:acc:0] Intel(R) FPGA Emulation Platform for OpenCL(TM)\n[opencl:cpu:1] Intel(R) OpenCL, 12th Gen Intel(R) Core(TM) i9-12900K\n[opencl:gpu:2] Intel(R) OpenCL HD Graphics, Intel(R) UHD Graphics 770\n[ext_oneapi_level_zero:gpu:0] Intel(R) Level-Zero, Intel(R) UHD Graphics 770\n[host:host:0] SYCL host platform, SYCL host device\n```\n\n----------------------------------------\n\nTITLE: Setting Up Project Structure and Custom Targets in CMake\nDESCRIPTION: Configures the main project structure including library, examples, and documentation. It also sets up custom targets for code style checking and formatting for both C++ and Python files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_28\n\nLANGUAGE: CMake\nCODE:\n```\n# Include convenience functions\ninclude(Open3DLink3rdpartyLibraries)\ninclude(Open3DSetGlobalProperties)\ninclude(Open3DShowAndAbortOnWarning)\ninclude(Open3DSYCLTargetSources)\n\n# Enumerate all third-party libraries which we need later\n# This creates the necessary targets and sets the\n# Open3D_3RDPARTY_*_TARGETS variables we use in open3d_link_3rdparty_libraries\ninclude(3rdparty/find_dependencies.cmake)\n\n# Open3D library\nadd_subdirectory(cpp)\n\n# Examples\nadd_subdirectory(examples)\n\n# Documentation\nadd_subdirectory(docs)\n\n# Install CMake configuration files\ninstall(EXPORT ${PROJECT_NAME}Targets NAMESPACE ${PROJECT_NAME}:: DESTINATION ${Open3D_INSTALL_CMAKE_DIR})\nexport(EXPORT ${PROJECT_NAME}Targets NAMESPACE ${PROJECT_NAME}::)\n\nif (Python3_EXECUTABLE)\n    # `make check-style` checks style for c++/cuda/python/ipynb files\n    add_custom_target(check-style\n        COMMAND ${Python3_EXECUTABLE}\n        ${CMAKE_CURRENT_SOURCE_DIR}/util/check_style.py\n        COMMENT \"Python executable used for style check: ${Python3_EXECUTABLE}.\"\n    )\n\n    # `make apply-style` applies style for c++/cuda/python/ipynb files\n    add_custom_target(apply-style\n        COMMAND ${Python3_EXECUTABLE}\n        ${CMAKE_CURRENT_SOURCE_DIR}/util/check_style.py --apply\n        COMMENT \"Python executable used for style check: ${Python3_EXECUTABLE}.\"\n    )\nendif()\n\ninclude(Open3DPackaging)\n\n# `make check-cpp-style` checks style for c++/cuda files.\n# This works outside of python virtualenv.\nadd_custom_target(check-cpp-style\n    COMMAND ${CMAKE_COMMAND}\n    -DPROJECT_SOURCE_DIR=\"${PROJECT_SOURCE_DIR}\"\n    -DAPPLY=OFF\n    -P ${CMAKE_CURRENT_SOURCE_DIR}/util/check_cpp_style.cmake\n)\n\n# `make apply-cpp-style` applies style for c++/cuda files.\n# This works outside of python virtualenv.\nadd_custom_target(apply-cpp-style\n    COMMAND ${CMAKE_COMMAND}\n    -DPROJECT_SOURCE_DIR=\"${PROJECT_SOURCE_DIR}\"\n    -DAPPLY=ON\n    -P ${CMAKE_CURRENT_SOURCE_DIR}/util/check_cpp_style.cmake\n)\n\ninclude(Open3DPrintConfigurationSummary)\nopen3d_print_configuration_summary()\n```\n\n----------------------------------------\n\nTITLE: Running Open3D Style Checker Directly\nDESCRIPTION: This snippet demonstrates how to run the Open3D style checker directly using Python. It includes options for both checking and applying the style.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/contribute/styleguide.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython util/check_style.py\npython util/check_style.py --apply\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Visualization and Material for UV Mapping Examples\nDESCRIPTION: Sets up the necessary imports, creates a material record, and loads a texture image for use in subsequent UV mapping examples.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/uvmaps.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport open3d.visualization.rendering as rendering\n\nmaterial = rendering.MaterialRecord()\nmaterial.shader = 'defaultUnlit'\nmaterial.albedo_img = o3d.io.read_image('/Users/renes/Downloads/uv1.png')\n```\n\n----------------------------------------\n\nTITLE: Verifying CUDA Installation\nDESCRIPTION: Commands to verify that CUDA is properly installed and configured on the system for Open3D CUDA support.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nnvidia-smi      # Prints CUDA-enabled GPU information\nnvcc -V         # Prints compiler version\n```\n\n----------------------------------------\n\nTITLE: RealSense Camera Configuration (JSON)\nDESCRIPTION: Provides a sample JSON configuration for a RealSense camera, including color and depth resolution, frame rate, and visual preset settings.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"serial\": \"\",\n    \"color_format\": \"RS2_FORMAT_RGB8\",\n    \"color_resolution\": \"0,540\",\n    \"depth_format\": \"RS2_FORMAT_Z16\",\n    \"depth_resolution\": \"0,480\",\n    \"fps\": \"30\",\n    \"visual_preset\": \"RS2_L500_VISUAL_PRESET_MAX_RANGE\"\n }\n```\n\n----------------------------------------\n\nTITLE: Running Azure Kinect MKV Reader (Python)\nDESCRIPTION: Command to run the Open3D Azure Kinect MKV Reader Python script to view a recorded MKV file.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/azure_kinect.rst#2025-04-23_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\npython examples/python/reconstruction_system/sensors/azure_kinect_mkv_reader.py --input record.mkv\n```\n\n----------------------------------------\n\nTITLE: Loading Redwood Indoor Office 2 Dataset in Python\nDESCRIPTION: This Python snippet demonstrates initializing and loading the Redwood Indoor Office 2 dataset using Open3D. It loads a point cloud and iterates through color and depth image pairs to create clean and noisy RGBD images for processing.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_65\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.RedwoodIndoorOffice2()\nassert Path(gt_download_dir).is_dir()\npcd = o3d.io.read_point_cloud(dataset.point_cloud_path)\n\nim_rgbds = []\nfor color_path, depth_path in zip(dataset.color_paths, dataset.depth_paths):\n    im_color = o3d.io.read_image(color_path)\n    im_depth = o3d.io.read_image(depth_path)\n    im_rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        im_color, im_depth)\n    im_rgbds.append(im_rgbd)\n\nim_noisy_rgbds = []\nfor color_path, depth_path in zip(dataset.color_paths,\n                                  dataset.noisy_depth_paths):\n    im_color = o3d.io.read_image(color_path)\n    im_depth = o3d.io.read_image(depth_path)\n    im_rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        im_color, im_depth)\n    im_noisy_rgbds.append(im_rgbd)\n```\n\n----------------------------------------\n\nTITLE: Installing ccache 4.0+ from Source on Ubuntu 20.04+ (Bash)\nDESCRIPTION: Provides instructions to compile and install ccache version 4.6 (or newer) from source on Ubuntu 20.04+. This is necessary to get CUDA compilation caching support, as the default apt package might be older. The script clones the repository, checks out a specific tag, configures the build with CMake, compiles, installs to ${HOME}/bin, updates the PATH environment variable, and verifies the installation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n# Clone\ngit clone https://github.com/ccache/ccache.git\ncd ccache\ngit checkout v4.6 -b 4.6\n\n# Build\nmkdir build\ncd build\ncmake -DZSTD_FROM_INTERNET=ON \\\n      -DHIREDIS_FROM_INTERNET=ON \\\n      -DCMAKE_BUILD_TYPE=Release \\\n      -DCMAKE_INSTALL_PREFIX=${HOME} \\\n      ..\nmake -j$(nproc)\nmake install -j$(nproc)\n\n# Add ${HOME}/bin to ${PATH} in your ~/.bashrc\necho \"PATH=${HOME}/bin:${PATH}\" >> ~/.bashrc\n\n# Restart the terminal now, or source ~/.bashrc\nsource ~/.bashrc\n\n# Verify `ccache` has been installed correctly\nwhich ccache\nccache --version\n```\n\n----------------------------------------\n\nTITLE: Loading Sword Model with PBR Texture in Python\nDESCRIPTION: Demonstrates how to load the Sword model with PBR texture in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.SwordModel()\nmodel = o3d.io.read_triangle_model(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Computing Distances for Multiple Points in Open3D\nDESCRIPTION: This code shows how to compute signed distances for multiple random points within the bounding box of the mesh using RaycastingScene.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/distance_queries.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmin_bound = mesh.vertex.positions.min(0).numpy()\nmax_bound = mesh.vertex.positions.max(0).numpy()\n\nN = 256\nquery_points = np.random.uniform(low=min_bound, high=max_bound,\n                                 size=[N, 3]).astype(np.float32)\n\n# Compute the signed distance for N random points\nsigned_distance = scene.compute_signed_distance(query_points)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Headless Rendering with Open3D in Docker\nDESCRIPTION: Instructions for creating a Docker container for headless rendering with Open3D. It includes a Dockerfile and commands to run the container with different GPU configurations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/docker.in.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmkdir open3d-headless-docker && cd open3d-headless-docker\nwget https://raw.githubusercontent.com/isl-org/Open3D/v@OPEN3D_VERSION@/examples/python/visualization/render_to_image.py\n# Build docker image\ndocker build -t open3d-headless -f- . <<EOF\nFROM ubuntu:20.04\nRUN apt-get update \\\n    && apt-get install --yes --no-install-recommends \\\n    libegl1 libgl1 libgomp1 python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Open3D from the PyPI repositories\nRUN python3 -m pip install --no-cache-dir --upgrade pip && \\\n    python3 -m pip install --no-cache-dir --upgrade open3d==@OPEN3D_VERSION@\n\n# Configure Mesa EGL for headless rendering\nENV EGL_PLATFORM=surfaceless\nWORKDIR /root/\nENTRYPOINT [\"python3\", \"/root/render_to_image.py\"]\nEOF\n\n# Run headless rendering example with Intel GPU\ndocker run --device=/dev/dri:/dev/dri \\\n    -v \"$PWD\":/root open3d-headless:latest\n# Run headless rendering example with Nvidia GPU\ndocker run  --gpus 'all,\"capabilities=compute,utility,graphics\"' \\\n    -v \"$PWD\":/root open3d-headless:latest\n# Run headless rendering example without GPU (CPU rendering)\ndocker run -v \"$PWD\":/root open3d-headless:latest\n```\n\n----------------------------------------\n\nTITLE: Loading Damaged Helmet Model with Embedded Textures in C++\nDESCRIPTION: Shows how to load the Damaged Helmet GLB model with JPG format embedded textures in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_29\n\nLANGUAGE: cpp\nCODE:\n```\ndata::DamagedHelmetModel dataset;\nvisualization::rendering::TriangleMeshModel model;\nio::ReadTriangleModel(dataset.GetPath(), model);\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Environment in Python\nDESCRIPTION: Sets up the Open3D environment by importing necessary modules and configuring visualization settings. It also includes a helper module for tutorials.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/visualization.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D Development Version via pip\nDESCRIPTION: Command to install the latest development version of Open3D directly using pip, with options to use only binary packages.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -U -f https://www.open3d.org/docs/latest/getting_started.html --only-binary open3d open3d\n```\n\n----------------------------------------\n\nTITLE: Loading Metal Texture for Material in C++\nDESCRIPTION: Shows how to load metal-based material textures (albedo, normal, roughness, metallic) in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_31\n\nLANGUAGE: cpp\nCODE:\n```\ndata::MetalTexture mat_data;\n\nauto mat = visualization::rendering::MaterialRecord();\nmat.shader = \"defaultUnlit\";\nmat.albedo_img = io::CreateImageFromFile(mat_data.albedo_texture_path);\nmat.normal_img = io::CreateImageFromFile(mat_data.normal_texture_path);\nmat.roughness_img = io::CreateImageFromFile(mat_data.roughness_texture_path);\nmat.metallic_img = io::CreateImageFromFile(mat_data.metallic_texture_path);\n```\n\n----------------------------------------\n\nTITLE: Building GLEW on Windows using MSYS/Mingw\nDESCRIPTION: Commands for building GLEW on Windows systems using MSYS/Mingw. Includes steps for compiling and installing.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/README.md#2025-04-23_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\n$ mingw32-make\n$ mingw32-make install\n$ mingw32-make install.all\n```\n\n----------------------------------------\n\nTITLE: Configuring Pipeline Library Properties\nDESCRIPTION: Sets up warning handling, global properties, library properties, and links third-party dependencies for the pipeline library.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/pipelines/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nopen3d_show_and_abort_on_warning(pipelines)\nopen3d_set_global_properties(pipelines)\nopen3d_set_open3d_lib_properties(pipelines)\nopen3d_link_3rdparty_libraries(pipelines)\n```\n\n----------------------------------------\n\nTITLE: Loading Knot Mesh Dataset in Python\nDESCRIPTION: Demonstrates how to load the 3D Mobius knot mesh dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.KnotMesh()\nmesh = o3d.io.read_triangle_mesh(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Building Open3D on Ubuntu\nDESCRIPTION: Command to compile Open3D on Ubuntu using make with optimal parallelization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# On Ubuntu\nmake -j$(nproc)\n```\n\n----------------------------------------\n\nTITLE: Selecting Point Correspondences in Open3D (Python)\nDESCRIPTION: This function uses VisualizerWithEditing to allow users to pick corresponding points in a point cloud. It's used in the manual registration process to select matching points between two point clouds.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/interactive_visualization.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef pick_points(pcd):\n    print(\"\")\n    print(\n        \"1) Please pick at least three correspondences using [shift + left click]\")\n    print(\"   Press [shift + right click] to undo point picking\")\n    print(\"2) After picking points, press 'Q' to close the window\")\n    vis = o3d.visualization.VisualizerWithEditing()\n    vis.create_window()\n    vis.add_geometry(pcd)\n    vis.run()  # user picks points\n    vis.destroy_window()\n    print(\"\")\n    return vis.get_picked_points()\n```\n\n----------------------------------------\n\nTITLE: Running Azure Kinect Viewer (Python)\nDESCRIPTION: Command to run the Open3D Azure Kinect Viewer Python script with depth aligned to color.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/azure_kinect.rst#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npython examples/python/reconstruction_system/sensors/azure_kinect_viewer.py --align_depth_to_color\n```\n\n----------------------------------------\n\nTITLE: Loading Colored ICP Point Cloud Data\nDESCRIPTION: Loads two point cloud fragments for Colored-ICP demonstration from the Redwood RGB-D apartment scene dataset.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_58\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.DemoColoredICPPointClouds()\npcd0 = o3d.io.read_point_cloud(dataset.paths[0])\npcd1 = o3d.io.read_point_cloud(dataset.paths[1])\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for Open3D with RealSense Support (C++)\nDESCRIPTION: Shows the CMake command to build Open3D from source with RealSense support enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ncmake -D BUILD_LIBREALSENSE=ON -D <OTHER_FLAGS> /path/to/Open3D/source/\n```\n\n----------------------------------------\n\nTITLE: Loading Monkey Model with PBR Texture in Python\nDESCRIPTION: Demonstrates how to load the Monkey model with PBR texture in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.MonkeyModel()\nmodel = o3d.io.read_triangle_model(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Headless CPU Rendering in Bash\nDESCRIPTION: Sets the EGL_PLATFORM environment variable to 'surfaceless' for Ubuntu 20.04+ to enable headless CPU rendering before running a Python script.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/cpu_rendering.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nEGL_PLATFORM=surfaceless python examples/python/visualization/render_to_image.py\n```\n\n----------------------------------------\n\nTITLE: Loading Tiles Texture for Material in C++\nDESCRIPTION: Shows how to load tiles-based material textures (albedo, normal, roughness) in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_35\n\nLANGUAGE: cpp\nCODE:\n```\ndata::TilesTexture mat_data;\n\nauto mat = visualization::rendering::MaterialRecord();\nmat.shader = \"defaultUnlit\";\nmat.albedo_img = io::CreateImageFromFile(mat_data.albedo_texture_path);\nmat.normal_img = io::CreateImageFromFile(mat_data.normal_texture_path);\nmat.roughness_img = io::CreateImageFromFile(mat_data.roughness_texture_path);\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Open3D Mesh Operations\nDESCRIPTION: Sets up the necessary imports for Open3D mesh operations, including numpy for numerical operations and helper modules for tutorials. Also configures interactive visualization based on environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/half_edge_mesh.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport open3d as o3d\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Configuring TICPSequential for KITTI Dataset Processing in INI\nDESCRIPTION: This INI configuration file sets up parameters for the TICPSequential.cpp example. It includes settings for visualization, verbosity, dataset path, frame range, registration method, and multi-scale ICP parameters for processing KITTI dataset samples.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cpp/registration_example_util/TICPSequentialConfigKitti.txt#2025-04-23_snippet_0\n\nLANGUAGE: INI\nCODE:\n```\n# This is a config file for the `TICPSequential.cpp` Example.\n# When voxel_size is -1, no downsampling is performed.\n# To run TICPSequential:\n# 1. Run the `download_kitti.py` script.\n#    python3 download_kitti.py \n#    This will download a city sequence in examples/test_data/open3d_downloads/datasets/kitti_samples/\n#    if it does not exists, and save the processed frames in `/output/`.\n# 2. If you are downloading it anywhere else, change the `dataset_path` accordingly.\n# 3. Go to build/bin/examples directory.\n# 4. Run the following command:\n# ./TICPSequential CPU:0 ../../../examples/cpp/registration_example_util/TICPOdomConfigKitti.txt\n# Change CPU:0 to CUDA:0 for running it on primary GPU.\n\n# option to turn ON / OFF visualization:\nvisualization = ON\nvisualization_min = -1.5\nvisualization_max = 1.5\n\n# Verbosity can be Info, Debug.\nverbosity = Info\n\n# Path of the downloaded dataset containing frames in .pcd or .ply format.\ndataset_path = ../../../examples/test_data/open3d_downloads/datasets/kitti_samples/output/\n\n# Range of frames is start_index to end_index.\nstart_index = 0\nend_index = 1000 \n\n# Registration method can be PointToPoint or PointToPlane.\nregistration_method = PointToPlane\n\n# Multi-Scale ICP parameters:\n\n# Scale 1:\n voxel_size = 0.8\n search_radii = 1.2\n criteria.relative_fitness = 0.01\n criteria.relative_rmse = 0.01\n criteria.max_iterations = 10\n\n# Scale 2:\n voxel_size = 0.5\n search_radii = 1.0\n criteria.relative_fitness = 0.001\n criteria.relative_rmse = 0.001\n criteria.max_iterations = 10\n\n# One can also add more scales ...\n```\n\n----------------------------------------\n\nTITLE: Processing ICP Point Clouds Demo Data\nDESCRIPTION: Loads three point cloud fragments in PCD format from the Redwood RGB-D dataset for ICP demonstration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_57\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.DemoICPPointClouds()\npcd0 = o3d.io.read_point_cloud(dataset.paths[0])\npcd1 = o3d.io.read_point_cloud(dataset.paths[1])\npcd2 = o3d.io.read_point_cloud(dataset.paths[2])\n```\n\n----------------------------------------\n\nTITLE: Installing macOS Documentation Dependencies\nDESCRIPTION: Installs required system packages for building documentation on macOS using Homebrew.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbrew install ghostscript pandoc doxygen\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Visualization Library Properties in CMake\nDESCRIPTION: Sets global properties, Open3D-specific library properties, and links third-party libraries for both the main visualization library and its implementation. Also handles GUI resource directory configuration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(visualization)\nopen3d_set_global_properties(visualization)\nopen3d_set_open3d_lib_properties(visualization)\nopen3d_link_3rdparty_libraries(visualization)\n\nopen3d_show_and_abort_on_warning(visualization_impl)\nopen3d_set_global_properties(visualization_impl)\nopen3d_set_open3d_lib_properties(visualization_impl)\nopen3d_link_3rdparty_libraries(visualization_impl)\n\n# export GUI_RESOURCE_DIR to parent scope\nif (BUILD_GUI)\n    set(GUI_RESOURCE_DIR ${GUI_RESOURCE_DIR} PARENT_SCOPE)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Loading Flight Helmet Model with PBR Texture in C++\nDESCRIPTION: Shows how to load the Flight Helmet GLTF model with PBR texture in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_25\n\nLANGUAGE: cpp\nCODE:\n```\ndata::FlightHelmetModel dataset;\nvisualization::rendering::TriangleMeshModel model;\nio::ReadTriangleModel(dataset.GetPath(), model);\n```\n\n----------------------------------------\n\nTITLE: Creating ISPC Object Library for Open3D Pipelines\nDESCRIPTION: Creates an ISPC object library named 'tpipelines' using a custom Open3D CMake function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(tpipelines OBJECT)\n```\n\n----------------------------------------\n\nTITLE: Building Open3D on macOS\nDESCRIPTION: Command to compile Open3D on macOS using make with optimal parallelization based on available CPU cores.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# On macOS\nmake -j$(sysctl -n hw.physicalcpu)\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies in requirements.txt - Plain Text\nDESCRIPTION: This snippet enumerates external Python package dependencies using the requirements.txt format. Each line specifies a package along with an optional minimum version constraint (using '>='), such as numpy>=1.18.0 and flask>=3.0.0. Tools like 'pip' can automatically parse this file to install all needed packages. No imports or Python code are present; instead, the file is directly referenced by pip for dependency resolution. The list structure supports one package per line and ignores comments or blank lines.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\nnumpy>=1.18.0\\ndash>=2.6.0\\nwerkzeug>=3.0.0\\nflask>=3.0.0\\nnbformat>=5.7.0\\nconfigargparse\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D Python Package Options on Windows\nDESCRIPTION: Commands for installing the Open3D Python library with different options on Windows.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_11\n\nLANGUAGE: bat\nCODE:\n```\n:: Activate the virtualenv first\n:: Install pip package in the current python environment\ncmake --build . --config Release --target install-pip-package\n\n:: Create Python package in build/lib\ncmake --build . --config Release --target python-package\n\n:: Create pip package in build/lib\n:: This creates a .whl file that you can install manually.\ncmake --build . --config Release --target pip-package\n```\n\n----------------------------------------\n\nTITLE: Loading Sample SUN RGBD Image using Open3D C++\nDESCRIPTION: This C++ snippet loads the Sample SUN RGBD Image dataset via `open3d::data::SampleSUNRGBDImage`. It uses `io::CreateImageFromFile` to load the raw color and depth images and then creates an `open3d::geometry::RGBDImage` using the specific `CreateFromSUNFormat` function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_50\n\nLANGUAGE: cpp\nCODE:\n```\ndata::SampleSUNRGBDImage dataset;\n\nauto color_raw = io::CreateImageFromFile(dataset.GetColorPath());\nauto depth_raw = io::CreateImageFromFile(dataset.GetDepthPath());\n\nauto rgbd_image = geometry::RGBDImage::CreateFromSUNFormat(\n    *color_raw, *depth_raw, /*convert_rgb_to_intensity =*/ false);\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Intel GPU Double Precision Support (Shell)\nDESCRIPTION: Commands to set environment variables for enabling float64 emulation during compilation and double precision emulation at runtime for Intel GPUs.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/sycl.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport IGC_EnableDPEmulation=1\nexport OverrideDefaultFP64Settings=1\n```\n\n----------------------------------------\n\nTITLE: Loading Armadillo Mesh Dataset in C++\nDESCRIPTION: Shows how to load the Stanford Armadillo mesh dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_15\n\nLANGUAGE: cpp\nCODE:\n```\ndata::ArmadilloMesh dataset;\nauto mesh = io::CreateMeshFromFile(dataset.GetPath());\n```\n\n----------------------------------------\n\nTITLE: Getting Information Matrix for Point Cloud Registration\nDESCRIPTION: Retrieves the information matrix that indicates the quality of point cloud alignment using the registration result.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ninformation_matrix = treg.get_information_matrix(\n    source, target, max_correspondence_distances[2],\n    registration_ms_icp.transformation)\n\nprint(information_matrix)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake for macOS arm64 ML Build\nDESCRIPTION: CMake configuration command for building Open3D with ML operations on macOS arm64 architecture. Enables TensorFlow and PyTorch operations with Open3D ML bundling.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/release.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncmake -DCMAKE_BUILD_TYPE=Release -DDEVELOPER_BUILD=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=ON \n                    -DBUILD_TENSORFLOW_OPS=ON -DBUILD_PYTORCH_OPS=ON -DBUNDLE_OPEN3D_ML=ON  ..\n```\n\n----------------------------------------\n\nTITLE: Transferring Tensors Between Devices\nDESCRIPTION: Demonstrates how to transfer tensors between CPU and GPU devices, and between multiple GPU devices.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Host -> Device.\na_cpu = o3c.Tensor([0, 1, 2])\na_gpu = a_cpu.cuda(0)\nprint(a_gpu)\n\n# Device -> Host.\na_gpu = o3c.Tensor([0, 1, 2], device=o3c.Device(\"CUDA:0\"))\na_cpu = a_gpu.cpu()\nprint(a_cpu)\n\n# Device -> another Device.\na_gpu_0 = o3c.Tensor([0, 1, 2], device=o3c.Device(\"CUDA:0\"))\na_gpu_1 = a_gpu_0.cuda(1)\nprint(a_gpu_1)\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies and Setup for Open3D Tutorial\nDESCRIPTION: Imports necessary libraries including Open3D, NumPy, and sets up the tutorial environment. This snippet also configures whether visualization will be interactive or not based on environment variables.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/pointcloud_outlier_removal.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Enabling Interactive CPU Rendering with Mesa Drivers for Python Scripts\nDESCRIPTION: Sets the LIBGL_ALWAYS_SOFTWARE environment variable to 'true' to enable interactive CPU rendering with Mesa drivers v20.2 or higher before running a Python script using Open3D visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/cpu_rendering.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nLIBGL_ALWAYS_SOFTWARE=true python examples/python/visualization/draw.py\n```\n\n----------------------------------------\n\nTITLE: Installing and Testing Open3D on ARM64\nDESCRIPTION: This snippet demonstrates how to install Open3D via pip and run basic tests to verify the installation, including importing the library and testing both legacy and new GUI visualizers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/arm.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install open3d\npython -c \"import open3d; print(open3d.__version__)\"\n\n# Test the legacy visualizer\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw_geometries([c])\"\n\n# Test the new GUI visualizer\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw(c)\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Template Files with CMake for Open3D Project\nDESCRIPTION: This snippet uses CMake's configure_file command to process template files by replacing variables with actual values. It configures a Doxygen configuration file and two reStructuredText documentation files, replacing template variables marked with @ONLY directive.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nconfigure_file(${CMAKE_CURRENT_SOURCE_DIR}/Doxyfile.in\n    ${CMAKE_CURRENT_SOURCE_DIR}/Doxyfile @ONLY)\nconfigure_file(${CMAKE_CURRENT_SOURCE_DIR}/getting_started.in.rst\n    ${CMAKE_CURRENT_SOURCE_DIR}/getting_started.rst @ONLY)\nconfigure_file(${CMAKE_CURRENT_SOURCE_DIR}/docker.in.rst\n    ${CMAKE_CURRENT_SOURCE_DIR}/docker.rst @ONLY)\n```\n\n----------------------------------------\n\nTITLE: Setting Build Properties and Dependencies for Open3D GUI\nDESCRIPTION: Applies global properties to the GUI target, sets warning handling, and links third-party libraries required by the Open3D GUI module.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/gui/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(GUI)\nopen3d_set_global_properties(GUI)\nopen3d_link_3rdparty_libraries(GUI)\n```\n\n----------------------------------------\n\nTITLE: Building Ubuntu ARM64 Python Wheels\nDESCRIPTION: Docker build command for creating Open3D Python wheels for ARM64 architecture on Ubuntu. This command initiates the build process using the specified Docker configuration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/release.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd docker; ./docker_build.sh openblas-arm64-py311; ...\n```\n\n----------------------------------------\n\nTITLE: Using Open3D in Example Project on Windows\nDESCRIPTION: This snippet shows how to download, extract, build, and run an Open3D example project on Windows. It includes steps for downloading the source, configuring with CMake, and building with the Visual Studio compiler.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-external-project/README.md#2025-04-23_snippet_2\n\nLANGUAGE: batch\nCODE:\n```\nwget https://github.com/isl-org/Open3D/archive/refs/heads/main.zip -o Open3D-main.zip\nunzip Open3D-main.zip 'Open3D-main/cmake/ispc_isas/*' -d example-project\ncd example-project/Open3D-main/examples/cmake/open3d-cmake-external-project\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release --parallel 12\nRelease\\Draw\n```\n\n----------------------------------------\n\nTITLE: Installing OSMesa for Headless Rendering in Ubuntu\nDESCRIPTION: Command to install OSMesa library, which is necessary for generating a headless context.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/headless_rendering.rst#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ sudo apt-get install libosmesa6-dev\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D C++ Library on Windows\nDESCRIPTION: Command to install the Open3D C++ library on Windows after compilation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_10\n\nLANGUAGE: bat\nCODE:\n```\ncmake --build . --config Release --target INSTALL\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing a Blue Cube\nDESCRIPTION: This code creates a blue cube using Open3D's TriangleMesh, computes its vertex normals, paints it blue, and visualizes it using the web visualizer.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/jupyter_visualization.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncube_blue = o3d.geometry.TriangleMesh.create_box(1, 2, 4)\ncube_blue.compute_vertex_normals()\ncube_blue.paint_uniform_color((0.0, 0.0, 1.0))\ndraw(cube_blue)\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch with CXX11 ABI for Open3D SYCL Backend (Shell)\nDESCRIPTION: Command to install PyTorch with CXX11 ABI compatibility, which is required for using the Open3D PyTorch extension with the SYCL backend.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/sycl.rst#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install torch==2.2.2+cpu.cxx11.abi -i https://download.pytorch.org/whl/cpu/\n```\n\n----------------------------------------\n\nTITLE: Loading Bunny Mesh Dataset in C++\nDESCRIPTION: Shows how to load the Stanford Bunny mesh dataset in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_13\n\nLANGUAGE: cpp\nCODE:\n```\ndata::BunnyMesh dataset;\nauto mesh = io::CreateMeshFromFile(dataset.GetPath());\n```\n\n----------------------------------------\n\nTITLE: Selecting an Anchor Point in Point Cloud\nDESCRIPTION: Selects the 1501st point in the point cloud as an anchor point for neighbor search operations and colors it red to distinguish it in visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/kdtree.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Paint the 1501st point red.\")\npcd.colors[1500] = [1, 0, 0]\n```\n\n----------------------------------------\n\nTITLE: Using Open3D in Example Project on Ubuntu/macOS\nDESCRIPTION: This snippet shows how to set up and build an example project using the installed Open3D library on Ubuntu or macOS. It includes copying the example, configuring with CMake, building, and running the example.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-find-package/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncp -ar Open3D/examples/cmake/open3d-cmake-find-package .\ncd open3d-cmake-find-package\nmkdir build\ncd build\ncmake -DOpen3D_ROOT=${HOME}/open3d_install ..\nmake -j 12\n./Draw\n```\n\n----------------------------------------\n\nTITLE: Loading Wood Floor Textures into MaterialRecord using Open3D Python\nDESCRIPTION: This Python snippet shows how to load the wood floor texture dataset (albedo, normal, roughness) via `o3d.data.WoodFloorTexture()`. The textures are read using `o3d.io.read_image` and applied to an `o3d.visualization.rendering.MaterialRecord` using the 'defaultLit' shader.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nmat_data = o3d.data.WoodFloorTexture()\n\nmat = o3d.visualization.rendering.MaterialRecord()\nmat.shader = \"defaultLit\"\nmat.albedo_img = o3d.io.read_image(mat_data.albedo_texture_path)\nmat.normal_img = o3d.io.read_image(mat_data.normal_texture_path)\nmat.roughness_img = o3d.io.read_image(mat_data.roughness_texture_path)\n```\n\n----------------------------------------\n\nTITLE: Preloading Mesa Driver Library for Interactive CPU Rendering\nDESCRIPTION: Exports the LD_PRELOAD environment variable to use the Mesa driver library for interactive CPU rendering when using Nvidia or AMD drivers with recent Mesa drivers installed.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/cpu_rendering.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLX_mesa.so.0\nOpen3D\n```\n\n----------------------------------------\n\nTITLE: Building Open3D in Docker with Various Configurations\nDESCRIPTION: Commands to build Open3D from source using Docker with different configurations, including Python versions, hardware architectures, and build modes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/docker.in.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd docker\n\n./docker_build.sh cuda_wheel_py38_dev   # Python 3.8, AMD64, CUDA with MKL, developer mode\n./docker_build.sh openblas-amd64-py310  # Python 3.10, AMD64 with OpenBLAS instead of MKL, release mode\n./docker_build.sh openblas-arm64-py37   # Python 3.7, ARM64 with OpenBLAS, release mode\n```\n\n----------------------------------------\n\nTITLE: Configuring ISPC Module for Vectorized Computation\nDESCRIPTION: Conditionally adds Intel SPMD Program Compiler (ISPC) specific source files when ISPC module is enabled, providing vectorized implementations for improved performance on CPUs.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/core/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_ISPC_MODULE)\n    target_sources(core PRIVATE\n        Indexer.ispc\n    )\n    target_sources(core_impl PRIVATE\n        kernel/BinaryEWCPU.ispc\n        kernel/UnaryEWCPU.ispc\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Copying GUI Resources to Build Output Directory in CMake\nDESCRIPTION: Gathers GUI resource files and copies them to the build output directory. Creates a 'resources' directory in the runtime output location and copies all files from the Resources source directory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/gui/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n# --- build resources ----\nfile(GLOB GUI_RESOURCE_SOURCE_FILES \"${CMAKE_CURRENT_SOURCE_DIR}/Resources/*\")\n\n# copy GUI/Resources -> <output>/resources\nset(GUI_RESOURCE_DIR \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/resources\")\nfile(MAKE_DIRECTORY ${GUI_RESOURCE_DIR})\nfile(COPY ${GUI_RESOURCE_SOURCE_FILES}\n     DESTINATION ${GUI_RESOURCE_DIR})\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D Dependencies on Ubuntu\nDESCRIPTION: This snippet shows how to install the minimal Open3D compilation dependencies on Ubuntu using apt-get.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-external-project/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Install minimal Open3D compilation dependencies. For the full list, checkout:\n# https://github.com/isl-org/Open3D/blob/master/util/install_deps_ubuntu.sh\nsudo apt-get --yes install xorg-dev libglu1-mesa-dev\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable for Headless CPU Rendering in Python\nDESCRIPTION: Sets the EGL_PLATFORM environment variable to 'surfaceless' in Python code to enable headless CPU rendering before importing Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/cpu_rendering.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ['EGL_PLATFORM'] = 'surfaceless'   # Ubuntu 20.04+\nimport open3d as o3d\n```\n\n----------------------------------------\n\nTITLE: Block Activation in TSDF Integration\nDESCRIPTION: Demonstrates how to activate blocks within the viewing frustum for TSDF integration using Open3D's VoxelBlockGrid.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/integration.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvoxel_grid.hashmap().activate(frustum_block_coords)\nblock_coords = voxel_grid.hashmap().get_active_keys()\nfill_in_scalars = False\n```\n\n----------------------------------------\n\nTITLE: Painting a Mesh with Uniform Color in Open3D\nDESCRIPTION: This code shows how to paint a mesh with a uniform color using the paint_uniform_color() method. The color is specified in RGB format with values in the [0, 1] range.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/mesh.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Painting the mesh\")\nmesh1.paint_uniform_color([1, 0.706, 0])\no3d.visualization.draw_geometries([mesh1])\n```\n\n----------------------------------------\n\nTITLE: Building Open3D on Windows\nDESCRIPTION: Command to build Open3D on Windows using CMake command line interface.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_9\n\nLANGUAGE: bat\nCODE:\n```\ncmake --build . --config Release --target ALL_BUILD\n```\n\n----------------------------------------\n\nTITLE: Compiling Open3D on ARM64 macOS\nDESCRIPTION: This snippet demonstrates how to compile Open3D on ARM64 macOS. It includes steps for installing dependencies, configuring the build, compiling different components, and testing the installation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/arm.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Dependencies\nbrew install gfortran\n\n# Optional: ccache is recommended to speed up subsequent builds\nsudo apt-get install -y ccache\n\n# Optional: activate your virtualenv\nconda activate your-virtual-env\n\n# Configure and choose build options\ncd Open3D && mkdir build && cd build\ncmake -DCMAKE_BUILD_TYPE=Release -DBUILD_TENSORFLOW_OPS=ON -DBUILD_PYTORCH_OPS=ON -DBUNDLE_OPEN3D_ML=ON ..\n\n# Build\nmake pip-package -j8    # Build Python wheel\nmake package -j8        # Build macOS devel binary package\nmake Open3DViewer -j8   # Build Open3D viewer app\n\n# Test C++ viewer app\n./bin/Open3D/Open3D\n\n# Test Python visualization\npython -c \"import open3d; print(open3d.__version__)\"\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw_geometries([c])\"\npython -c \"import open3d as o3d; c = o3d.geometry.TriangleMesh.create_box(); o3d.visualization.draw(c)\"\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Open3D Ray Casting\nDESCRIPTION: Imports necessary libraries for the Open3D ray casting tutorial, including Open3D, NumPy, Matplotlib, and standard Python modules. Also sets up the tutorial environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport sys\n\n# only needed for tutorial, monkey patches visualization\nsys.path.append('..')\nimport open3d_tutorial\n# change to True if you want to interact with the visualization windows\nopen3d_tutorial.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Compiling and Installing Open3D on Ubuntu/macOS\nDESCRIPTION: This snippet shows the commands to clone the Open3D repository, configure the build with CMake, and install it on Ubuntu or macOS systems. It uses shared libraries and allows specifying the installation path.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-find-package/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/isl-org/Open3D.git\ncd Open3D\nmkdir build\ncd build\ncmake -DBUILD_SHARED_LIBS=ON -DCMAKE_INSTALL_PREFIX=${HOME}/open3d_install ..\nmake install -j 12\ncd ../..\n```\n\n----------------------------------------\n\nTITLE: Creating Tensors with Shallow Copy Constructor\nDESCRIPTION: Shows how tensors created through copy constructor share the same memory, meaning changes in one tensor will reflect in the other.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Shallow copy constructor.\nvals = np.array([1, 2, 3])\nsrc = o3c.Tensor(vals)\ndst = src\nsrc[0] += 10\n\n# Changes in one will get reflected in other.\nprint(\"Source tensor:\\n{}\".format(src))\nprint(\"\\nTarget tensor:\\n{}\".format(dst))\n```\n\n----------------------------------------\n\nTITLE: Compiling and Installing Open3D with Headless Rendering\nDESCRIPTION: Commands to build Open3D and install the pip package after configuring with CMake.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/headless_rendering.rst#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n(py3env) $ make -j$(nproc)\n(py3env) $ make install-pip-package\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D with GCC on macOS\nDESCRIPTION: Commands to install GCC and configure Open3D to build with GCC (for OpenMP support) on macOS.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nbrew install gcc --without-multilib\ncmake -DCMAKE_C_COMPILER=gcc-6 -DCMAKE_CXX_COMPILER=g++-6 ..\nmake -j\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Data Library in CMake\nDESCRIPTION: Sets up the 'data' library as an object library for Open3D. It includes the main Dataset.cpp file and a comprehensive list of dataset-specific source files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/data/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(data OBJECT)\n\ntarget_sources(data PRIVATE\n    Dataset.cpp\n)\n\ntarget_sources(data PRIVATE\n    dataset/ArmadilloMesh.cpp\n    dataset/AvocadoModel.cpp\n    dataset/BedroomRGBDImages.cpp\n    dataset/BunnyMesh.cpp\n    dataset/CrateModel.cpp\n    dataset/DamagedHelmetModel.cpp\n    dataset/DemoColoredICPPointClouds.cpp\n    dataset/DemoCropPointCloud.cpp\n    dataset/DemoCustomVisualization.cpp\n    dataset/DemoDopplerICPSequence.cpp\n    dataset/DemoFeatureMatchingPointClouds.cpp\n    dataset/DemoICPPointClouds.cpp\n    dataset/DemoPoseGraphOptimization.cpp\n    dataset/EaglePointCloud.cpp\n    dataset/FlightHelmetModel.cpp\n    dataset/JackJackL515Bag.cpp\n    dataset/JuneauImage.cpp\n    dataset/KnotMesh.cpp\n    dataset/LivingRoomPointClouds.cpp\n    dataset/LoungeRGBDImages.cpp\n    dataset/MetalTexture.cpp\n    dataset/MonkeyModel.cpp\n    dataset/OfficePointClouds.cpp\n    dataset/PaintedPlasterTexture.cpp\n    dataset/PCDPointCloud.cpp\n    dataset/PLYPointCloud.cpp\n    dataset/PTSPointCloud.cpp\n    dataset/RedwoodIndoorLivingRoom1.cpp\n    dataset/RedwoodIndoorLivingRoom2.cpp\n    dataset/RedwoodIndoorOffice1.cpp\n    dataset/RedwoodIndoorOffice2.cpp\n    dataset/SampleFountainRGBDImages.cpp\n    dataset/SampleL515Bag.cpp\n    dataset/SampleNYURGBDImage.cpp\n    dataset/SampleRedwoodRGBDImages.cpp\n    dataset/SampleSUNRGBDImage.cpp\n    dataset/SampleTUMRGBDImage.cpp\n    dataset/SwordModel.cpp\n    dataset/TerrazzoTexture.cpp\n    dataset/TilesTexture.cpp\n    dataset/WoodFloorTexture.cpp\n    dataset/WoodTexture.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Conditional Azure Kinect Support in CMake\nDESCRIPTION: Adds Azure Kinect sensor support if BUILD_AZURE_KINECT is enabled, including recorder, sensor configuration, and MKV file handling.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/io/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_AZURE_KINECT)\n    target_sources(io PRIVATE\n        sensor/azure_kinect/AzureKinectRecorder.cpp\n        sensor/azure_kinect/AzureKinectSensor.cpp\n        sensor/azure_kinect/AzureKinectSensorConfig.cpp\n        sensor/azure_kinect/K4aPlugin.cpp\n        sensor/azure_kinect/MKVMetadata.cpp\n        sensor/azure_kinect/MKVReader.cpp\n        sensor/azure_kinect/MKVWriter.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Building and Running C++ WebRTC Example\nDESCRIPTION: Shell commands for building and running the C++ WebRTC example in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nmkdir build && cd build\ncmake ..\nmake DrawWebRTC -j$(nproc)\ncd bin/example\n./DrawWebRTC\ngoogle-chrome http://localhost:8888  # Or, open the address in your browser\n```\n\n----------------------------------------\n\nTITLE: Alternative pip Installation Methods for Open3D\nDESCRIPTION: Various pip command options for installing Open3D in different environments, including using pip3, installing for the current user, or using Python's module method.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip3 install open3d\n# or\npip install --user open3d\n# or\npython3 -m pip install --user open3d\n```\n\n----------------------------------------\n\nTITLE: Activating Blocks and Obtaining Buffer Indices in Open3D Python\nDESCRIPTION: This snippet demonstrates how to activate blocks selected by the frustum and obtain their buffer indices using Open3D's hashmap functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/customized_integration.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Activate and get active buffer indices\nblock_coords = active_block_coords.to(o3c.int32)\nblock_indices = vbg.hashmap.activate(block_coords)\nvoxel_block_coords = block_coords[block_indices]\n```\n\n----------------------------------------\n\nTITLE: Converting Between Tensor and Legacy Point Cloud Formats\nDESCRIPTION: Shows how to convert between the tensor-based point cloud format and the legacy Open3D point cloud format. Includes conversion with specific data type specification.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlegacy_pcd = pcd.to_legacy()\nprint(legacy_pcd, \"\\n\")\n\ntensor_pcd = o3d.t.geometry.PointCloud.from_legacy(legacy_pcd)\nprint(tensor_pcd, \"\\n\")\n\n# Convert from legacy point cloud with data type of float64.\ntensor_pcd_f64 = o3d.t.geometry.PointCloud.from_legacy(legacy_pcd, o3c.float64)\nprint(tensor_pcd_f64, \"\\n\")\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D with Azure Kinect Support (CMake)\nDESCRIPTION: Command to build Open3D from source with Azure Kinect support enabled using CMake.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/azure_kinect.rst#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ncmake -DBUILD_AZURE_KINECT=ON -DOTHER_FLAGS ..\n```\n\n----------------------------------------\n\nTITLE: Checking PyTorch and TensorFlow ABI Version\nDESCRIPTION: Python commands to check the ABI versions used by PyTorch and TensorFlow for compatibility with Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npython -c \"import torch; print(torch._C._GLIBCXX_USE_CXX11_ABI)\"\npython -c \"import tensorflow; print(tensorflow.__cxx11_abi_flag__)\"\n```\n\n----------------------------------------\n\nTITLE: Save and Load TSDF Data\nDESCRIPTION: Demonstrates how to persist and load TSDF voxel block grid data using NPZ file format.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/integration.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nvolume = o3d.t.io.read_voxel_block_grid(args.voxel_path)\nvoxel_grid.save(args.voxel_path)\n```\n\n----------------------------------------\n\nTITLE: Installing ccache via Homebrew on macOS (Bash)\nDESCRIPTION: Command to install ccache on macOS using the Homebrew package manager. Requires Homebrew to be installed on the system.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\nbrew install ccache\n```\n\n----------------------------------------\n\nTITLE: Loading Bunny Mesh Dataset in Python\nDESCRIPTION: Demonstrates how to load the Stanford Bunny mesh dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.BunnyMesh()\nmesh = o3d.io.read_triangle_mesh(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Running Azure Kinect Viewer with Config (Python)\nDESCRIPTION: Command to run the Open3D Azure Kinect Viewer Python script with a custom configuration file.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/azure_kinect.rst#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\npython examples/python/reconstruction_system/sensors/azure_kinect_viewer.py --config config.json\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Build Options\nDESCRIPTION: Defines the main build options for Open3D, including shared libraries, examples, tests, CUDA, ISPC, GUI, and other core modules. Different defaults are set based on platform detection.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\noption(BUILD_SHARED_LIBS          \"Build shared libraries\"                   OFF)\noption(BUILD_EXAMPLES             \"Build Open3D examples programs\"           ON )\noption(BUILD_UNIT_TESTS           \"Build Open3D unit tests\"                  OFF)\noption(BUILD_BENCHMARKS           \"Build the micro benchmarks\"               OFF)\noption(BUILD_PYTHON_MODULE        \"Build the python module\"                  ON )\noption(BUILD_CUDA_MODULE          \"Build the CUDA module\"                    OFF)\noption(BUILD_WITH_CUDA_STATIC     \"Build with static CUDA libraries\"         ON )\noption(BUILD_COMMON_CUDA_ARCHS    \"Build for common CUDA GPUs (for release)\" OFF)\nif (WIN32)   # Causes CUDA runtime error on Windows (See issue #6555)\n    option(ENABLE_CACHED_CUDA_MANAGER \"Enable cached CUDA memory manager\"    OFF)\nelse()\n    option(ENABLE_CACHED_CUDA_MANAGER \"Enable cached CUDA memory manager\"    ON )\nendif()\nif(NOT LINUX_AARCH64 AND NOT APPLE_AARCH64)\n    option(BUILD_ISPC_MODULE      \"Build the ISPC module\"                    ON )\nelse()\n    option(BUILD_ISPC_MODULE      \"Build the ISPC module\"                    OFF)\nendif()\noption(BUILD_COMMON_ISPC_ISAS     \"Build for common ISPC ISAs (for release)\" OFF)\noption(BUILD_GUI                  \"Builds new GUI\"                           ON )\noption(WITH_OPENMP                \"Use OpenMP multi-threading\"               ON )\noption(WITH_IPP                \"Use Intel Integrated Performance Primitives\" ON )\noption(ENABLE_HEADLESS_RENDERING  \"Use OSMesa for headless rendering\"        OFF)\n```\n\n----------------------------------------\n\nTITLE: Configuring WebRTC and Additional Open3D Options\nDESCRIPTION: Sets options for WebRTC visualizer, Jupyter extension, and C++11 ABI support. WebRTC is enabled by default on Windows and non-ARM Linux platforms when GUI is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\noption(GLIBCXX_USE_CXX11_ABI      \"Set -D_GLIBCXX_USE_CXX11_ABI=1\"           ON )\noption(ENABLE_SYCL_UNIFIED_SHARED_MEMORY \"Enable SYCL unified shared memory\" OFF)\nif(BUILD_GUI AND (WIN32 OR UNIX AND NOT LINUX_AARCH64 AND NOT APPLE_AARCH64))\n    option(BUILD_WEBRTC           \"Build WebRTC visualizer\"                  ON )\nelse()\n    option(BUILD_WEBRTC           \"Build WebRTC visualizer\"                  OFF)\nendif()\noption(BUILD_JUPYTER_EXTENSION    \"Build Jupyter, requires BUILD_WEBRTC=ON\"  OFF)\n```\n\n----------------------------------------\n\nTITLE: Conditionally Adding RealSense Support to Open3D TIO Library\nDESCRIPTION: Adds RealSense-specific source files if BUILD_LIBREALSENSE is enabled, including sensor configuration and bag reader functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/io/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_LIBREALSENSE)\n    target_sources(tio PRIVATE\n        sensor/realsense/RealSenseSensor.cpp\n        sensor/realsense/RealSenseSensorConfig.cpp\n        sensor/realsense/RSBagReader.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Visualization Libraries in CMake\nDESCRIPTION: Sets up the main visualization library and its implementation as object libraries, configuring source files, shaders, and build options. Includes conditional compilation for GUI-related features.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(visualization OBJECT)\n\nopen3d_ispc_add_library(visualization_impl OBJECT)\nset_target_properties(visualization_impl PROPERTIES CXX_VISIBILITY_PRESET hidden)\n\ntarget_sources(visualization_impl PRIVATE\n    shader/GeometryRenderer.cpp\n    shader/ImageMaskShader.cpp\n    shader/ImageShader.cpp\n    shader/NormalShader.cpp\n    shader/PhongShader.cpp\n    shader/PickingShader.cpp\n    shader/RGBDImageShader.cpp\n    shader/ShaderWrapper.cpp\n    shader/Simple2DShader.cpp\n    shader/SimpleBlackShader.cpp\n    shader/SimpleShader.cpp\n    shader/TexturePhongShader.cpp\n    shader/TextureSimpleShader.cpp\n)\n\ntarget_sources(visualization PRIVATE\n    utility/ColorMap.cpp\n    utility/DrawGeometry.cpp\n    utility/GLHelper.cpp\n    utility/PointCloudPicker.cpp\n    utility/SelectionPolygon.cpp\n    utility/SelectionPolygonVolume.cpp\n)\n\ntarget_sources(visualization PRIVATE\n    visualizer/RenderOption.cpp\n    visualizer/RenderOptionWithEditing.cpp\n    visualizer/ViewControl.cpp\n    visualizer/ViewControlWithCustomAnimation.cpp\n    visualizer/ViewControlWithEditing.cpp\n    visualizer/ViewParameters.cpp\n    visualizer/ViewTrajectory.cpp\n    visualizer/Visualizer.cpp\n    visualizer/VisualizerCallback.cpp\n    visualizer/VisualizerRender.cpp\n    visualizer/VisualizerWithCustomAnimation.cpp\n    visualizer/VisualizerWithEditing.cpp\n    visualizer/VisualizerWithKeyCallback.cpp\n    visualizer/VisualizerWithVertexSelection.cpp\n)\n\ntarget_sources(visualization PRIVATE\n    rendering/Material.cpp  # For RPC serialization\n)\n\nif (BUILD_GUI)\n    target_sources(visualization PRIVATE\n        rendering/Camera.cpp\n        rendering/CameraInteractorLogic.cpp\n        rendering/CameraSphereInteractorLogic.cpp\n        rendering/ColorGrading.cpp\n        rendering/Gradient.cpp\n        rendering/IBLRotationInteractorLogic.cpp\n        rendering/LightDirectionInteractorLogic.cpp\n        rendering/MaterialModifier.cpp\n        rendering/MatrixInteractorLogic.cpp\n        rendering/ModelInteractorLogic.cpp\n        rendering/Open3DScene.cpp\n        rendering/Renderer.cpp\n        rendering/RendererHandle.cpp\n        rendering/RotationInteractorLogic.cpp\n        rendering/filament/FilamentEngine.cpp\n        rendering/filament/FilamentRenderer.cpp\n    )\n\n    target_sources(visualization_impl PRIVATE\n        rendering/filament/FilamentCamera.cpp\n        rendering/filament/FilamentEntitiesMods.cpp\n        rendering/filament/FilamentGeometryBuffersBuilder.cpp\n        rendering/filament/FilamentRenderToBuffer.cpp\n        rendering/filament/FilamentResourceManager.cpp\n        rendering/filament/FilamentScene.cpp\n        rendering/filament/FilamentView.cpp\n        rendering/filament/LineSetBuffers.cpp\n        rendering/filament/PointCloudBuffers.cpp\n        rendering/filament/TriangleMeshBuffers.cpp\n        rendering/filament/GaussianSplatBuffers.cpp\n    )\n\n    target_sources(visualization PRIVATE\n        utility/Draw.cpp\n    )\n\n    target_sources(visualization PRIVATE\n        visualizer/MessageProcessor.cpp\n        visualizer/GuiSettingsModel.cpp\n        visualizer/GuiSettingsView.cpp\n        visualizer/GuiVisualizer.cpp\n        visualizer/GuiWidgets.cpp\n        visualizer/O3DVisualizer.cpp\n        visualizer/O3DVisualizerSelections.cpp\n    )\n\n    target_sources(visualization PRIVATE\n        app/Viewer.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Troubleshooting Open3D Import Errors\nDESCRIPTION: Command to enable detailed Python warnings when importing Open3D to help troubleshoot installation issues.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython -W default -c \"import open3d as o3d\"\n```\n\n----------------------------------------\n\nTITLE: Enabling WebRTC Server in Python\nDESCRIPTION: Shows how to enable the WebRTC server backend in Python code for Open3D web visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\no3d.visualization.webrtc_server.enable_webrtc()\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D Python Package Options on Unix\nDESCRIPTION: Commands for installing the Open3D Python library with different options on Unix-based systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Activate the virtualenv first\n# Install pip package in the current python environment\nmake install-pip-package\n\n# Create Python package in build/lib\nmake python-package\n\n# Create pip wheel in build/lib\n# This creates a .whl file that you can install manually.\nmake pip-package\n```\n\n----------------------------------------\n\nTITLE: Testing Headless Rendering with Open3D Python Script\nDESCRIPTION: Command to run a Python script that demonstrates headless rendering by saving depth and surface normal sequences.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/headless_rendering.rst#2025-04-23_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n(py3env) $ cd ~/Open3D/examples/python/visualization\n(py3env) $ python headless_rendering.py\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Open3D Point Cloud Tutorial\nDESCRIPTION: Imports the necessary libraries for working with Open3D point clouds, including Open3D core, NumPy, Matplotlib, and utility modules. Also sets up the tutorial environment and handles visualization settings based on CI environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport open3d.core as o3c\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\nimport os\nimport sys\n\n# Only needed for tutorial, monkey patches visualization\nsys.path.append(\"..\")\nimport open3d_tutorial as o3dtut\n# Change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Building Open3D with OSMesa Support\nDESCRIPTION: CMake command to configure Open3D build with headless rendering support, using OSMesa and building GLEW and GLFW from source.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/headless_rendering.rst#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n(py3env) $ cmake -DENABLE_HEADLESS_RENDERING=ON \\\n                     -DBUILD_GUI=OFF \\\n                     -DBUILD_WEBRTC=OFF \\\n                     -DUSE_SYSTEM_GLEW=OFF \\\n                     -DUSE_SYSTEM_GLFW=OFF \\\n                     ..\n```\n\n----------------------------------------\n\nTITLE: Installing Ubuntu Documentation Dependencies\nDESCRIPTION: Installs required system packages for building documentation on Ubuntu, including doxygen, texlive and other utilities.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get -y install doxygen texlive texlive-latex-extra ghostscript pandoc\n```\n\n----------------------------------------\n\nTITLE: Memory Sharing Between NumPy and Open3D using Constructor\nDESCRIPTION: Shows how tensor creation using a constructor does not share memory with the original NumPy array, so changes in one do not affect the other.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Using constructor.\nnp_a = np.ones((5,), dtype=np.int32)\no3_a = o3c.Tensor(np_a)\nprint(f\"np_a: {np_a}\")\nprint(f\"o3_a: {o3_a}\")\nprint(\"\")\n\n# Changes to numpy array will not reflect as memory is not shared.\nnp_a[0] += 100\no3_a[1] += 200\nprint(f\"np_a: {np_a}\")\nprint(f\"o3_a: {o3_a}\")\n```\n\n----------------------------------------\n\nTITLE: Citing Open3D in Academic Publications - BibTeX Entry\nDESCRIPTION: This BibTeX snippet demonstrates how to cite the Open3D library in academic work. Required dependency is the LaTeX or BibTeX toolchain, where users include this entry in their .bib bibliography files. Key parameters include the citation key (Zhou2018), author names, title, journal (arXiv reference), and year. The code is intended for integration into manuscript preparation workflows employing reference management tools for publication.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: BibTeX\nCODE:\n```\n@article{Zhou2018,\\n    author    = {Qian-Yi Zhou and Jaesik Park and Vladlen Koltun},\\n    title     = {{Open3D}: {A} Modern Library for {3D} Data Processing},\\n    journal   = {arXiv:1801.09847},\\n    year      = {2018},\\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Environment\nDESCRIPTION: Sets up the required imports and configuration for Open3D visualization tutorials.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/surface_reconstruction.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport sys\n\n# only needed for tutorial, monkey patches visualization\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Configuring and Running Open3D Style Checker with CMake\nDESCRIPTION: This snippet shows how to configure the Open3D project with CMake and run the style checker using make commands. It includes instructions for both Ubuntu/macOS and Windows environments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/contribute/styleguide.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir build\ncd build\ncmake ..\n\n# Ubuntu/macOS\nmake check-style\nmake apply-style\n\n# Windows\ncmake --build . --target check-style\ncmake --build . --target apply-style\n```\n\n----------------------------------------\n\nTITLE: Building Documentation Examples\nDESCRIPTION: Various examples of building documentation with different options using make_docs.py script.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\n\n# Run `python make_docs.py --help` to usage of the flags.\npython make_docs.py --help\n\n# Example: build .rst and C++ docs only, skip notebooks.\npython make_docs.py --execute_notebooks=never --sphinx --doxygen\n\n# Example: build .rst and C++ docs only, skip notebooks, with parallel build.\npython make_docs.py --execute_notebooks=never --sphinx --doxygen --parallel\n\n# Example: build .rst and c++ docs, execute notebooks when it has not been executed.\npython make_docs.py --execute_notebooks=auto --sphinx --doxygen\n```\n\n----------------------------------------\n\nTITLE: Setting Open3D Library Properties Function\nDESCRIPTION: CMake function that configures version, visibility, and symbol export properties for the Open3D library. Handles different platform-specific symbol visibility settings for shared libraries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nfunction(open3d_set_open3d_lib_properties target)\n    cmake_parse_arguments(arg \"HIDDEN\" \"\" \"\" ${ARGN})\n    set_target_properties(${target} PROPERTIES\n        VERSION ${PROJECT_VERSION}\n        SOVERSION ${OPEN3D_ABI_VERSION}\n    )\n    if(NOT BUILD_SHARED_LIBS)\n        target_compile_definitions(${target} PUBLIC OPEN3D_STATIC)\n    endif()\n    if (arg_HIDDEN)\n        set_target_properties(${target} PROPERTIES\n                        CXX_VISIBILITY_PRESET hidden\n                        VISIBILITY_INLINES_HIDDEN ON\n                        )\n    else ()\n        target_compile_definitions(${target} PRIVATE OPEN3D_ENABLE_DLL_EXPORTS)\n    endif()\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Support for Open3D Tensor Geometry Library\nDESCRIPTION: Conditionally includes CUDA toolkit headers when the CUDA module is enabled in the build.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/geometry/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nif(BUILD_CUDA_MODULE)\n    target_include_directories(tgeometry SYSTEM PRIVATE\n        ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Optional Modules for Open3D Tests in CMake\nDESCRIPTION: This snippet adds configuration for optional modules like Azure Kinect and CUDA. It includes necessary headers and links libraries when these modules are enabled in the build.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_AZURE_KINECT)\n    # K4A headers are directly used in test. Currently we don't need to link\n    # the K4A libraries.\n    target_include_directories(tests SYSTEM PRIVATE ${K4A_INCLUDE_DIR})\nendif()\n\nif (BUILD_CUDA_MODULE)\n    # We still need to explicitly link against CUDA libraries.\n    # Consider removing dependencies of CUDA headers in the future.\n    find_package(CUDAToolkit REQUIRED)\n    target_link_libraries(tests PRIVATE CUDA::cudart)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting up ARM64 Docker Environment\nDESCRIPTION: Commands to install and configure QEMU for ARM64 support on x86-64 hosts.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docker/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get --yes install qemu binfmt-support qemu-user-static\n\n# Run the registering scripts\ndocker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n```\n\n----------------------------------------\n\nTITLE: Using Open3D in Example Project on Ubuntu/macOS\nDESCRIPTION: This snippet demonstrates how to download, extract, build, and run an Open3D example project on Ubuntu or macOS. It includes steps for downloading the source, configuring with CMake, and compiling with make.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-external-project/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwget https://github.com/isl-org/Open3D/archive/refs/heads/main.zip -o Open3D-main.zip\nunzip Open3D-main.zip 'Open3D-main/cmake/ispc_isas/*' -d example-project\ncd example-project/Open3D-main/examples/cmake/open3d-cmake-external-project\nmkdir build\ncd build\ncmake ..\nmake -j 12\n./Draw\n```\n\n----------------------------------------\n\nTITLE: Installing Python Documentation Dependencies\nDESCRIPTION: Installs required Python packages for building documentation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install -r docs/requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Open3D RGBD Processing\nDESCRIPTION: Imports the necessary libraries for RGBD image processing including Open3D, NumPy, Matplotlib, and adds path for tutorials.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Upgrading pip for Open3D Installation on Linux\nDESCRIPTION: Command to upgrade pip to version 20.3 or higher, which is required for installing Open3D on Linux systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -U \"pip>=20.3\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Windows Runtime and SYCL Module Settings\nDESCRIPTION: Sets options for Windows runtime (static or dynamic) based on build type and configures SYCL module settings for Intel oneAPI, including targets and backend options.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(BUILD_SHARED_LIBS)\n    option(STATIC_WINDOWS_RUNTIME \"Use static (MT/MTd) Windows runtime\"      OFF)\nelse()\n    option(STATIC_WINDOWS_RUNTIME \"Use static (MT/MTd) Windows runtime\"      ON )\nendif()\noption(BUILD_SYCL_MODULE          \"Build SYCL module with Intel oneAPI\"      OFF)\nif(BUILD_SYCL_MODULE)\n    set(OPEN3D_SYCL_TARGETS \"spir64\" CACHE STRING \n    \"SYCL targets: spir64 for JIT, or another for AOT compilation. See https://github.com/intel/llvm/blob/sycl/sycl/doc/UsersManual.md.\"\n)\n    set(OPEN3D_SYCL_TARGET_BACKEND_OPTIONS \"\" CACHE STRING \n    \"SYCL target backend options, e.g. to compile for a specific device. See https://github.com/intel/llvm/blob/sycl/sycl/doc/UsersManual.md.\"\n)\n    set(BUILD_ISPC_MODULE OFF CACHE BOOL \"Build the ISPC module\" FORCE)\n    set(BUILD_CUDA_MODULE OFF CACHE BOOL \"Build the CUDA module\" FORCE)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Geometry Transformation for Voxel Projection in Open3D Python\nDESCRIPTION: This snippet transforms voxel coordinates to the frame's coordinate system, projects them to image space, and filters out-of-bound correspondences.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/customized_integration.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nxyz = voxel_coords @ frame.pose[:3, :3].T + frame.pose[:3, 3]\nz = xyz[:, 2]\nuv = xyz[:, :2] / z[:, None]\nu, v = uv[:, 0], uv[:, 1]\nz = z.reshape((-1, 1))\n\nmask = (depth_scale * 1 / 5 < z) & (z < depth_scale * 3)\nmask = mask & (0 <= u) & (u < im_w) & (0 <= v) & (v < im_h)\nu = u[mask]\nv = v[mask]\nz = z[mask]\n\nvoxel_indices = voxel_indices[mask]\nu = (u + 0.5).to(o3c.int64)\nv = (v + 0.5).to(o3c.int64)\n```\n\n----------------------------------------\n\nTITLE: Configuring TURN Server for WebRTC\nDESCRIPTION: Shows how to set a custom TURN server for WebRTC traffic forwarding using an environment variable.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\n# UDP only\nWEBRTC_STUN_SERVER=\"turn:user:password@my_turn_server.com:3478\"\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies on Ubuntu\nDESCRIPTION: Command to install required dependencies for Open3D on Ubuntu using the provided installation script.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Only needed for Ubuntu\nutil/install_deps_ubuntu.sh\n```\n\n----------------------------------------\n\nTITLE: Installing ccache via Apt on Ubuntu 22.04+ (Bash)\nDESCRIPTION: Command to install ccache using the apt package manager on Ubuntu 22.04 or later. This version typically includes ccache 4.0+ which supports CUDA caching. Requires sudo privileges.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install ccache\n```\n\n----------------------------------------\n\nTITLE: Creating Dummy Network Interface for WebRTC\nDESCRIPTION: Shell commands for creating a dummy network interface to enable WebRTC in airplane mode on Ubuntu.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\n# Setup\nsudo ip link add dummy0 type dummy\nsudo ip addr add 1.1.1.1/24 dev dummy0\nsudo ip link set dummy0 up\n\n# Check interfaces\nip addr\n\n# Do WebRTC things here\npython examples/python/visualization/draw_webrtc.py\ngoogle-chrome http://localhost:8888  # Or, open the address in your browser\n\n# Clean up\nsudo ip link set dummy0 down\nsudo ip link delete dummy0\n```\n\n----------------------------------------\n\nTITLE: Symbol Visibility Configuration\nDESCRIPTION: Platform-specific symbol visibility configuration for shared libraries. Includes symbol map generation for macOS and Linux to control symbol exports.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif (TARGET_TYPE STREQUAL SHARED_LIBRARY)\n        if (APPLE)\n            file(GENERATE OUTPUT libOpen3D.map CONTENT\n                [=[*open3d*\n                   *Open3D*\n                ]=])\n            target_link_options(${target} PRIVATE $<$<CONFIG:Release>:\n                -Wl,-exported_symbols_list\n                \"${CMAKE_CURRENT_BINARY_DIR}/libOpen3D.map\" >)\n        elseif (UNIX)   # Linux\n            file(GENERATE OUTPUT libOpen3D.map CONTENT\n                [=[{\n    global:\n        *open3d*;\n        extern \"C++\" {\n             open3d::*;\n        };\n    local: *;\n};]=])\n            target_link_options(${target} PRIVATE $<$<CONFIG:Release>:\n                \"-Wl,--version-script=${CMAKE_CURRENT_BINARY_DIR}/libOpen3D.map\" >)\n        elseif (WIN32)\n            # TODO(Sameer): Only export open3d symbols\n        endif()\n    endif()\n```\n\n----------------------------------------\n\nTITLE: Adding Odometry Source Files to tpipelines\nDESCRIPTION: Adds the RGBDOdometry.cpp source file to the tpipelines target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tpipelines PRIVATE\n    odometry/RGBDOdometry.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Open3D Tool CMake Macro\nDESCRIPTION: Defines a macro 'open3d_add_tool' that simplifies adding tool executables to the project. The macro handles common configuration like linking with Open3D, setting folder properties, and applying warning settings.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tools/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nmacro(open3d_add_tool TOOL_NAME)\n    add_executable(${TOOL_NAME})\n\n    target_sources(${TOOL_NAME} PRIVATE \"${TOOL_NAME}.cpp\")\n    target_link_libraries(${TOOL_NAME} PRIVATE Open3D::Open3D ${ARGN})\n\n    set_target_properties(${TOOL_NAME} PROPERTIES FOLDER \"Tools\")\n    open3d_show_and_abort_on_warning(${TOOL_NAME})\n    open3d_set_global_properties(${TOOL_NAME})\nendmacro()\n```\n\n----------------------------------------\n\nTITLE: Verifying Open3D Python Installation on Windows\nDESCRIPTION: Command to verify that the Open3D Python library was installed correctly on Windows.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npython -c \"import open3d; print(open3d)\"\n```\n\n----------------------------------------\n\nTITLE: Verifying Docker Installation\nDESCRIPTION: Command to verify that Docker is installed correctly by running a simple test container.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/docker.in.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# You should be able to run this without sudo.\ndocker run hello-world\n```\n\n----------------------------------------\n\nTITLE: Installing WSL via PowerShell\nDESCRIPTION: PowerShell commands to install and setup Windows Subsystem for Linux.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docker/README.md#2025-04-23_snippet_5\n\nLANGUAGE: powershell\nCODE:\n```\nwsl --install\nwsl --install -d Ubuntu-24.04\n```\n\n----------------------------------------\n\nTITLE: GUI-Dependent Python Binding Sources in CMake\nDESCRIPTION: Conditionally adds GUI-related source files when BUILD_GUI is enabled, including the O3D visualizer, viewer application, GUI event handling, and rendering components.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/visualization/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif (BUILD_GUI)\n    target_sources(pybind PRIVATE\n        o3dvisualizer.cpp\n    )\n\n    target_sources(pybind PRIVATE\n        app/viewer.cpp\n    )\n\n    target_sources(pybind PRIVATE\n        gui/events.cpp\n        gui/gui.cpp\n    )\n\n    target_sources(pybind PRIVATE\n        rendering/rendering.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D\nDESCRIPTION: Command to install Open3D using pip package manager.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install open3d\n```\n\n----------------------------------------\n\nTITLE: Setting Up Open3D Environment for KDTree Tutorial\nDESCRIPTION: Initializes the Open3D environment by importing required libraries and setting up visualization helpers. It imports Open3D, NumPy, and adds a tutorial module to the path to provide visualization utilities.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/kdtree.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport os\nimport sys\n\n# monkey patches visualization and provides helpers to load geometries\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Building GLEW on Linux using CMake\nDESCRIPTION: Instructions for building GLEW on Linux systems using CMake. Includes steps for installing dependencies, configuring the build, and compiling.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/README.md#2025-04-23_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\n$ cd build\n$ cmake ./cmake\n$ make -j4\n```\n\n----------------------------------------\n\nTITLE: Adding Hashmap, Kernel, Linear Algebra, and NNS Components to Core Library\nDESCRIPTION: Adds additional source files to the core library related to hashmaps, kernels, linear algebra operations, and nearest neighbor search functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/core/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(core PRIVATE\n    hashmap/CPU/CPUHashBackendBuffer.cpp\n    hashmap/CPU/CreateCPUHashBackend.cpp\n    hashmap/DeviceHashBackend.cpp\n    hashmap/HashBackendBuffer.cpp\n    hashmap/HashMap.cpp\n    hashmap/HashSet.cpp\n    kernel/Kernel.cpp\n    linalg/AddMM.cpp\n    linalg/Det.cpp\n    linalg/Inverse.cpp\n    linalg/LeastSquares.cpp\n    linalg/LU.cpp\n    linalg/Matmul.cpp\n    linalg/Solve.cpp\n    linalg/SVD.cpp\n    linalg/Tri.cpp\n    nns/FixedRadiusIndex.cpp\n    nns/FixedRadiusSearchOps.cpp\n    nns/KnnIndex.cpp\n    nns/NanoFlannIndex.cpp\n    nns/NearestNeighborSearch.cpp\n    nns/NNSIndex.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Building and Running Open3D C++ Unit Tests (Bash)\nDESCRIPTION: Commands to configure the build with unit tests enabled using CMake, compile the project including tests using make, and then execute the compiled C++ tests. Assumes execution within the build directory. Requires CMake and a C++ build toolchain.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\ncmake -DBUILD_UNIT_TESTS=ON ..\nmake -j$(nproc)\n./bin/tests\n```\n\n----------------------------------------\n\nTITLE: Selecting Specific SYCL Devices (Shell and Python)\nDESCRIPTION: Examples of how to select specific SYCL devices using environment variables and Python code.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/sycl.rst#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsycl-ls\nexport ONEAPI_DEVICE_SELECTOR=\"opencl:1\"\n```\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"SYCL_DEVICE_ALLOWLIST\"] = \"BackendName:cuda\"\nimport open3d as o3d\no3d.core.sycl.print_sycl_devices(print_all=True)\n\no3d.core.sycl.get_available_devices()\n\no3d.core.sycl.is_available(o3d.core.Device(\"SYCL:0\"))\n```\n\n----------------------------------------\n\nTITLE: Configuring RealSense Dataset in JSON\nDESCRIPTION: This JSON configuration file specifies the paths for the RealSense dataset and camera intrinsic parameters. It's used to set up the reconstruction system for processing the captured data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/capture_your_own_dataset.rst#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"RealSense bag file\",\n    \"path_dataset\": \"dataset/realsense/\",\n    \"path_intrinsic\": \"dataset/realsense/camera_intrinsic.json\",\n    \"max_depth\": 3.0,\n    \"voxel_size\": 0.05,\n    \"max_depth_diff\": 0.07,\n    \"preference_loop_closure_odometry\": 0.1,\n    \"preference_loop_closure_registration\": 5.0,\n    \"tsdf_cubic_size\": 3.0,\n    \"icp_method\": \"color\",\n    \"global_registration\": \"ransac\",\n    \"python_multi_threading\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Open3D Package Namespace Structure\nDESCRIPTION: Comprehensive listing of Open3D's package hierarchy showing all available modules and subpackages, including core functionality, machine learning extensions, visualization tools, and specialized pipelines.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/documented_modules.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Parsed by make_docs.py\nopen3d.camera\nopen3d.core\nopen3d.core.nns\nopen3d.data\nopen3d.geometry\nopen3d.io\nopen3d.io.rpc\nopen3d.t\nopen3d.t.geometry\nopen3d.t.io\nopen3d.t.pipelines\nopen3d.t.pipelines.odometry\nopen3d.t.pipelines.registration\nopen3d.t.pipelines.slac\nopen3d.t.pipelines.slam\nopen3d.ml\nopen3d.ml.tf\nopen3d.ml.tf.layers\nopen3d.ml.tf.ops\nopen3d.ml.tf.datasets\nopen3d.ml.tf.datasets.utils\nopen3d.ml.tf.datasets.augment\nopen3d.ml.tf.utils\nopen3d.ml.tf.vis\nopen3d.ml.tf.dataloaders\nopen3d.ml.tf.models\nopen3d.ml.tf.modules\nopen3d.ml.tf.modules.losses\nopen3d.ml.tf.modules.metrics\nopen3d.ml.tf.pipelines\nopen3d.ml.torch\nopen3d.ml.torch.layers\nopen3d.ml.torch.ops\nopen3d.ml.torch.classes\nopen3d.ml.torch.datasets\nopen3d.ml.torch.datasets.utils\nopen3d.ml.torch.datasets.augment\nopen3d.ml.torch.datasets.samplers\nopen3d.ml.torch.utils\nopen3d.ml.torch.vis\nopen3d.ml.torch.dataloaders\nopen3d.ml.torch.models\nopen3d.ml.torch.modules\nopen3d.ml.torch.modules.losses\nopen3d.ml.torch.modules.metrics\nopen3d.ml.torch.pipelines\nopen3d.pipelines\nopen3d.pipelines.color_map\nopen3d.pipelines.integration\nopen3d.pipelines.odometry\nopen3d.pipelines.registration\nopen3d.utility\nopen3d.visualization\nopen3d.visualization.gui\nopen3d.visualization.rendering\nopen3d.visualization.webrtc_server\nopen3d.visualization.tensorboard_plugin.summary\n```\n\n----------------------------------------\n\nTITLE: Setting Up Core Implementation Library for Internal Functions\nDESCRIPTION: Creates and configures the core_impl library which contains implementations of core functions not exposed in the public API. Sets visibility to hidden and adds kernel and linear algebra implementation files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/core/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# core_impl contains the implementation of core functions that are not exposed in the public API\nopen3d_ispc_add_library(core_impl OBJECT)\nset_target_properties(core_impl PROPERTIES CXX_VISIBILITY_PRESET \"hidden\")\n\ntarget_sources(core_impl PRIVATE\n    kernel/Arange.cpp\n    kernel/BinaryEW.cpp\n    kernel/IndexGetSet.cpp\n    kernel/IndexReduction.cpp\n    kernel/NonZero.cpp\n    kernel/Reduction.cpp\n    kernel/UnaryEW.cpp\n    kernel/ArangeCPU.cpp\n    kernel/BinaryEWCPU.cpp\n    kernel/IndexGetSetCPU.cpp\n    kernel/IndexReductionCPU.cpp\n    kernel/NonZeroCPU.cpp\n    kernel/ReductionCPU.cpp\n    kernel/UnaryEWCPU.cpp\n    linalg/AddMMCPU.cpp\n    linalg/InverseCPU.cpp\n    linalg/LeastSquaresCPU.cpp\n    linalg/LUCPU.cpp\n    linalg/MatmulCPU.cpp\n    linalg/SolveCPU.cpp\n    linalg/SVDCPU.cpp\n    linalg/TriCPU.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Module Build Check\nDESCRIPTION: Checks if CUDA module should be built and displays appropriate build message.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/pytorch/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nif(BUILD_CUDA_MODULE)\n    message(STATUS \"Building PyTorch ops with CUDA\")\nelse()\n    message(STATUS \"Building PyTorch ops\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Linking Libraries for Open3D Tests in CMake\nDESCRIPTION: This snippet specifies the libraries to be linked with the Open3D tests executable. It includes core Open3D libraries, third-party dependencies, and conditionally links OpenMP if available.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(tests PRIVATE\n    Open3D::Open3D\n    Open3D::3rdparty_jsoncpp\n    Open3D::3rdparty_googletest\n    Open3D::3rdparty_threads\n    Open3D::3rdparty_vtk\n)\n\nif (TARGET Open3D::3rdparty_openmp)\n    target_link_libraries(tests PRIVATE\n        Open3D::3rdparty_openmp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Odometry Sources\nDESCRIPTION: Incorporates odometry-related source files for RGB-D odometry implementation and Jacobian calculations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/pipelines/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pipelines PRIVATE\n    odometry/Odometry.cpp\n    odometry/RGBDOdometryJacobian.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Source Files for Open3D Python Bindings\nDESCRIPTION: CMake configuration that specifies the source files required to build Python bindings for Open3D's geometry and visualization components. The target 'pybind' is configured with various C++ source files that implement Python interfaces for point clouds, meshes, lines, images, and other 3D geometry types.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    geometry.cpp\n    drawablegeometry.cpp\n    image.cpp\n    lineset.cpp\n    pointcloud.cpp\n    boundingvolume.cpp\n    raycasting_scene.cpp\n    tensormap.cpp\n    trianglemesh.cpp\n    voxel_block_grid.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Project Version Strings and PyPI Package Name - CMake - CMake\nDESCRIPTION: This snippet constructs the project version string in MAJOR.MINOR.PATCH format for npm and configures the PyPI package name, defaulting to 'open3d' unless overridden. It is used for packaging/distribution tasks and ensures consistency in versioning across targets. No external dependencies are required.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_20\n\nLANGUAGE: CMake\nCODE:\n```\n# npm version has to be MAJOR.MINOR.PATCH\nstring(CONCAT PROJECT_VERSION_THREE_NUMBER \"${OPEN3D_VERSION_MAJOR}\"\n                                           \".${OPEN3D_VERSION_MINOR}\"\n                                           \".${OPEN3D_VERSION_PATCH}\")\n\n# PyPI package name controls specifies the repository name on PyPI. The default\n# name is \"open3d\". In the past, for historical reasons, we've used the\n# following names for PyPI, while they are now deprecated:\n# - open3d-python\n# - py3d\n# - open3d-original\n# - open3d-official\n# - open-3d\nif(NOT DEFINED PYPI_PACKAGE_NAME)\n    set(PYPI_PACKAGE_NAME \"open3d\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D Libraries\nDESCRIPTION: Initial imports required for working with Open3D and its web visualizer.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/3d_gaussian_splatting.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nfrom open3d.web_visualizer import draw\n```\n\n----------------------------------------\n\nTITLE: Including Registration Module in Open3D Python Bindings\nDESCRIPTION: This snippet adds multiple source files related to the registration module. It includes features, global optimization, registration, and robust kernels, providing comprehensive registration functionality in the Python API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/pipelines/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    registration/feature.cpp\n    registration/global_optimization.cpp\n    registration/registration.cpp\n    registration/robust_kernels.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring C++ Source Files for Open3D Benchmarks in CMake\nDESCRIPTION: Defines the primary C++ source files to be compiled as part of the 'benchmarks' target in Open3D. These files appear to be various benchmark implementations for binary operations, hash maps, linear algebra, memory management, and other core functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/core/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    BinaryEW.cpp\n    HashMap.cpp\n    Linalg.cpp\n    MemoryManager.cpp\n    ParallelFor.cpp\n    Reduction.cpp\n    UnaryEW.cpp\n    Zeros.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Checking SYCL Module Compatibility and Enforcing Constraints - CMake - CMake\nDESCRIPTION: This snippet verifies that the SYCL module can be safely enabled, checking compiler type, platform, ABI compatibility, and mutual exclusivity with CUDA. Fatal errors are emitted if any constraints are violated. This ensures stable builds for SYCL acceleration, only supporting Linux and IntelLLVM (DPC++) compilers. All input parameters are CMake variables/flags, and no additional dependencies are required.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_16\n\nLANGUAGE: CMake\nCODE:\n```\n# Check SYCL compatiblility\nif (BUILD_SYCL_MODULE AND NOT CMAKE_CXX_COMPILER_ID MATCHES \"IntelLLVM\")\n    message(FATAL_ERROR \"BUILD_SYCL_MODULE requires IntelLLVM (DPC++) compiler, \"\n                        \"but got CMAKE_CXX_COMPILER_ID: ${CMAKE_CXX_COMPILER_ID} \"\n                        \"and CMAKE_CXX_COMPILER: ${CMAKE_CXX_COMPILER}.\")\nendif()\nif (BUILD_SYCL_MODULE AND (NOT UNIX OR APPLE))\n    message(FATAL_ERROR \"Open3D SYCL support is only available on Linux\")\nendif()\nif(BUILD_SYCL_MODULE AND NOT GLIBCXX_USE_CXX11_ABI)\n    message(FATAL_ERROR \"BUILD_SYCL_MODULE=ON requires GLIBCXX_USE_CXX11_ABI=ON\")\nendif()\nif(BUILD_SYCL_MODULE AND BUILD_CUDA_MODULE)\n    message(FATAL_ERROR \"BUILD_SYCL_MODULE and BUILD_SYCL_MODULE cannot be on at the same time for now.\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Benchmark Library Options in CMake\nDESCRIPTION: Disables installation, testing, and Google Test integration for the Benchmark library to simplify its integration into Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/benchmark/MakeAvailable/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\n# Turn off installing and testing of the benchmark lib\nset(BENCHMARK_ENABLE_INSTALL OFF CACHE BOOL \"This should be OFF. Enables installing the benchmark lib\" FORCE)\nset(BENCHMARK_ENABLE_GTEST_TESTS OFF CACHE BOOL \"This should be OFF. Enables gtest framework for the benchmark lib\" FORCE)\nset(BENCHMARK_ENABLE_TESTING OFF CACHE BOOL \"This should be OFF. Enables tests for the benchmark lib\" FORCE)\n```\n\n----------------------------------------\n\nTITLE: Adding Subsampling Operation Source Files\nDESCRIPTION: Adds TensorFlow subsampling operations for point cloud processing to the library.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(open3d_tf_ops PRIVATE\n    tf_subsampling/tf_batch_subsampling.cpp\n    tf_subsampling/tf_subsampling.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Linking CUDA-specific Dependencies\nDESCRIPTION: Conditionally links CUDA-specific dependencies when CUDA module is enabled, including CUTLASS and CUB libraries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_18\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    target_link_libraries(open3d_tf_ops PRIVATE\n        Open3D::3rdparty_cutlass\n        CUDA::cuda_driver\n    )\n\n    if (TARGET Open3D::3rdparty_cub)\n        target_link_libraries(open3d_tf_ops PRIVATE\n            Open3D::3rdparty_cub\n        )\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Library Properties and Dependencies for Open3D Pipeline Kernel\nDESCRIPTION: Configures build properties for the tpipelines_kernel library, including warning handling, global properties, and linking third-party dependencies. Note that symbol hiding is commented out because the kernels are used in unit tests.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/kernel/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(tpipelines_kernel)\nopen3d_set_global_properties(tpipelines_kernel)\n# The kernels are used in the unit tests, so they cannot be hidden for now.\nopen3d_set_open3d_lib_properties(tpipelines_kernel)\n#open3d_set_open3d_lib_properties(tpipelines_kernel HIDDEN)\nopen3d_link_3rdparty_libraries(tpipelines_kernel)\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D with CUDA Support\nDESCRIPTION: CMake command to configure Open3D build with CUDA support enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ncmake -DBUILD_CUDA_MODULE=ON -DCMAKE_INSTALL_PREFIX=<open3d_install_directory> ..\n```\n\n----------------------------------------\n\nTITLE: Adding Integration Sources\nDESCRIPTION: Adds integration-related source files to the pipeline library, including implementations for scalable and uniform TSDF (Truncated Signed Distance Function) volumes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/pipelines/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pipelines PRIVATE\n    integration/ScalableTSDFVolume.cpp\n    integration/UniformTSDFVolume.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Installation Paths for Different Platforms - CMake - CMake\nDESCRIPTION: This code calculates install directories for various targets (include, binary, library, resources, CMake files) for Unix-like and Windows platforms, using GNUInstallDirs if available. Paths are set as variables for later install steps, ensuring platform-specific correctness. No direct outputs are produced except updated variables.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_21\n\nLANGUAGE: CMake\nCODE:\n```\n# Set installation paths\nif(UNIX OR CYGWIN)\n    include(GNUInstallDirs)\n    set(Open3D_INSTALL_INCLUDE_DIR \"${CMAKE_INSTALL_INCLUDEDIR}\")\n    set(Open3D_INSTALL_BIN_DIR \"${CMAKE_INSTALL_BINDIR}\")\n    set(Open3D_INSTALL_LIB_DIR \"${CMAKE_INSTALL_LIBDIR}\")\n    # Put resources in */share/\n    set(Open3D_INSTALL_RESOURCE_DIR \"${CMAKE_INSTALL_DATADIR}\")\n    set(Open3D_INSTALL_CMAKE_DIR \"${CMAKE_INSTALL_LIBDIR}/cmake/${PROJECT_NAME}\")\nelse()\n    set(Open3D_INSTALL_INCLUDE_DIR include)\n    set(Open3D_INSTALL_BIN_DIR bin)\n    set(Open3D_INSTALL_LIB_DIR lib)\n    # Put resources in */bin, with executables / DLLs\n    set(Open3D_INSTALL_RESOURCE_DIR bin)\n    set(Open3D_INSTALL_CMAKE_DIR CMake)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Validating Build Options and Emitting Errors/Warnings - CMake - CMake\nDESCRIPTION: This block enforces build constraints, checks architecture, enabled modules, and compatibility between options like headless rendering, GUI support, and ARM builds. It emits errors or warnings as needed and sets variables to disable or enforce options accordingly. The logic ensures incompatible features are not enabled simultaneously and warns about missing dependencies, particularly on ARM and macOS platforms.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_13\n\nLANGUAGE: CMake\nCODE:\n```\nif ((LINUX_AARCH64 OR APPLE_AARCH64) AND BUILD_ISPC_MODULE)\n    message(FATAL_ERROR \"ISPC module is not yet supported on ARM Linux\")\nendif()\nif (LINUX_AARCH64 AND NOT BUILD_FILAMENT_FROM_SOURCE)\n    message(FATAL_ERROR \"ARM CPU detected, you must set BUILD_FILAMENT_FROM_SOURCE=ON.\")\nendif()\nif ((LINUX_AARCH64 OR APPLE_AARCH64) AND NOT USE_BLAS)\n    message(FATAL_ERROR \"ARM CPU detected, you must set USE_BLAS=ON.\")\nendif()\nif (APPLE AND ENABLE_HEADLESS_RENDERING)\n    message(WARNING \"Headless rendering is not supported on Mac OS\")\n    set(ENABLE_HEADLESS_RENDERING OFF)\nendif()\nif(ENABLE_HEADLESS_RENDERING AND BUILD_GUI)\n    message(WARNING \"Headless rendering disables the Open3D GUI\")\n    set(BUILD_GUI OFF)\nendif()\nif(ENABLE_HEADLESS_RENDERING AND (USE_SYSTEM_GLEW OR USE_SYSTEM_GLFW))\n    message(WARNING \"Headless rendering requires customized GLEW and GLFW builds\")\n    set(USE_SYSTEM_GLEW OFF)\n    set(USE_SYSTEM_GLFW OFF)\nendif()\nif(BUNDLE_OPEN3D_ML AND NOT (BUILD_TENSORFLOW_OPS OR BUILD_PYTORCH_OPS))\n    message(SEND_ERROR \"3DML depends on TensorFlow or PyTorch Ops. Enable them with -DBUILD_TENSORFLOW_OPS=ON or -DBUILD_PYTORCH_OPS=ON\")\nendif()\nif(BUILD_WEBRTC AND LINUX_AARCH64)\n    message(FATAL_ERROR \"BUILD_WEBRTC=ON is not yet supported on ARM Linux\")\nendif()\nif(BUILD_WEBRTC AND NOT BUILD_GUI)\n    message(FATAL_ERROR \"BUILD_WEBRTC=ON requires BUILD_GUI=ON\")\nendif()\nif(BUILD_JUPYTER_EXTENSION AND NOT BUILD_WEBRTC)\n    # BUILD_JUPYTER_EXTENSION transitively depends on BUILD_GUI\n    message(FATAL_ERROR \"BUILD_JUPYTER_EXTENSION=ON requires BUILD_WEBRTC=ON\")\nendif()\nif(BUILD_JUPYTER_EXTENSION AND NOT BUILD_PYTHON_MODULE)\n    message(FATAL_ERROR \"BUILD_JUPYTER_EXTENSION=ON requires BUILD_PYTHON_MODULE=ON\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D Library\nDESCRIPTION: Basic import statement for the Open3D library, which is required for all subsequent 3D visualization examples.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/draw_plotly.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\n```\n\n----------------------------------------\n\nTITLE: Adding Registration Sources\nDESCRIPTION: Adds registration-related source files including implementations for ICP variants, feature matching, pose graph optimization, and transformation estimation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/pipelines/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pipelines PRIVATE\n    registration/ColoredICP.cpp\n    registration/CorrespondenceChecker.cpp\n    registration/FastGlobalRegistration.cpp\n    registration/Feature.cpp\n    registration/GeneralizedICP.cpp\n    registration/GlobalOptimization.cpp\n    registration/PoseGraph.cpp\n    registration/Registration.cpp\n    registration/RobustKernel.cpp\n    registration/TransformationEstimation.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring GUI Application Build Settings in CMake\nDESCRIPTION: Macro for configuring platform-specific GUI application build settings, including resource bundling, macOS bundle configuration, and installation directives for Linux and Windows.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/apps/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nmacro(open3d_add_app_gui SRC_DIR APP_NAME TARGET_NAME)\n    set(APPS_DIR \"${PROJECT_SOURCE_DIR}/cpp/apps\")\n    set(SOURCE_DIR \"${APPS_DIR}/${SRC_DIR}\")\n\n    if (APPLE)\n        file(GLOB OBJC_FILES \"${SOURCE_DIR}/*.mm\")\n        target_sources(${TARGET_NAME} PRIVATE ${OBJC_FILES})\n\n        file(GLOB RESOURCE_FILES \"${SOURCE_DIR}/*.icns\")\n        list(APPEND RESOURCE_FILES \"${SOURCE_DIR}/Assets.car\")\n\n        set(INFO_PLIST \"${SOURCE_DIR}/Info.plist.in\")\n\n        set(MACOSX_BUNDLE_NAME ${APP_NAME})\n        set(MACOSX_BUNDLE_EXECUTABLE_NAME ${APP_NAME})\n        set(MACOSX_BUNDLE_GUI_IDENTIFIER com.isl-org.open3d.${APP_NAME})\n        set(MACOSX_BUNDLE_LONG_VERSION_STRING ${PROJECT_VERSION_THREE_NUMBER})\n        set(MACOSX_BUNDLE_SHORT_VERSION_STRING ${PROJECT_VERSION_THREE_NUMBER})\n        set(MACOSX_BUNDLE_BUNDLE_VERSION ${PROJECT_VERSION_THREE_NUMBER})\n        set(MACOSX_BUNDLE_COPYRIGHT \"Copyright (c) 2018-2025 www.open3d.org\")\n    endif()\n\n    # Rest of the macro implementation...\nendmacro()\n```\n\n----------------------------------------\n\nTITLE: Using Open3D Command Line Interface\nDESCRIPTION: Example command showing how to run Open3D visualization examples through the command line interface.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/getting_started.in.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Open3D CLI\nopen3d example visualization/draw\n```\n\n----------------------------------------\n\nTITLE: Defining Open3D Version Constants in C++\nDESCRIPTION: This snippet defines the major, minor, and patch version numbers for Open3D. These constants are used to specify the current version of the Open3D library, following semantic versioning principles.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/version.txt#2025-04-23_snippet_0\n\nLANGUAGE: C++\nCODE:\n```\nOPEN3D_VERSION_MAJOR 0\nOPEN3D_VERSION_MINOR 19\nOPEN3D_VERSION_PATCH 0\n```\n\n----------------------------------------\n\nTITLE: Visualizing NYU Dataset RGBD Image Components\nDESCRIPTION: Displays the color and depth components of the NYU dataset RGBD image using Matplotlib.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/rgbd_image.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nplt.subplot(1, 2, 1)\nplt.title('NYU grayscale image')\nplt.imshow(rgbd_image.color)\nplt.subplot(1, 2, 2)\nplt.title('NYU depth image')\nplt.imshow(rgbd_image.depth)\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Properties for TensorFlow Ops Library\nDESCRIPTION: Sets global properties for the TensorFlow operations library, including warning handling and stripping.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_13\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(open3d_tf_ops)\nopen3d_enable_strip(open3d_tf_ops)\n# do not use open3d_set_global_properties(open3d_tf_ops) here because some\n# options are not compatible for tf op libraries\n```\n\n----------------------------------------\n\nTITLE: Setting Output Directories and Properties for pybind in CMake\nDESCRIPTION: Configures the output directories and properties for the pybind target, including RPATH settings for Unix systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nset(PYTHON_COMPILED_MODULE_DIR\n    \"${CMAKE_LIBRARY_OUTPUT_DIRECTORY}/Python/$<IF:$<BOOL:${BUILD_CUDA_MODULE}>,cuda,cpu>\")\n\nif (UNIX AND NOT APPLE)\n    # Use RPATH instead of RUNPATH in pybind so that needed libc++.so can find child dependant libc++abi.so in RPATH\n    # https://stackoverflow.com/questions/69662319/managing-secondary-dependencies-of-shared-libraries\n    target_link_options(pybind PRIVATE \"LINKER:--disable-new-dtags\")\nendif()\nset_target_properties(pybind PROPERTIES\n                      FOLDER \"Python\"\n                      LIBRARY_OUTPUT_DIRECTORY \"${PYTHON_COMPILED_MODULE_DIR}\"\n                      ARCHIVE_OUTPUT_DIRECTORY \"${PYTHON_COMPILED_MODULE_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D TIO Library Properties and Dependencies\nDESCRIPTION: Sets global properties, library-specific properties, and links third-party libraries for the TIO library. Also enables warnings as errors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/io/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(tio)\nopen3d_set_global_properties(tio)\nopen3d_set_open3d_lib_properties(tio)\nopen3d_link_3rdparty_libraries(tio)\n```\n\n----------------------------------------\n\nTITLE: Adding SLAM Model Source File to tpipelines\nDESCRIPTION: Adds the SLAM (Simultaneous Localization and Mapping) Model.cpp source file to the tpipelines target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tpipelines PRIVATE\n    slam/Model.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenGL Policy Based on GLFW Usage - CMake - CMake\nDESCRIPTION: This snippet conditionally sets the CMake OpenGL compatibility policy (CMP0072) based on whether system GLFW is used, retrieving the current policy value for debugging or logic elsewhere. The configuration applies only when NOT USE_SYSTEM_GLFW is true and CMP0072 relates to FindOpenGL handling. No external dependencies are required besides CMake.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_12\n\nLANGUAGE: CMake\nCODE:\n```\nif(NOT USE_SYSTEM_GLFW)\n    cmake_policy(SET CMP0072 OLD)\nendif()\ncmake_policy(GET CMP0072 CMP0072_VALUE)\n```\n\n----------------------------------------\n\nTITLE: Configuring VTK and Filament Build Options\nDESCRIPTION: Sets options for building VTK and Filament from source, with special handling for ARM platforms. On Linux and Apple ARM64, VTK is built from source by default.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nif(LINUX_AARCH64 OR APPLE_AARCH64)\n    option(BUILD_VTK_FROM_SOURCE      \"Build VTK from source\"                ON )\nelse()\n    option(BUILD_VTK_FROM_SOURCE      \"Build VTK from source\"                OFF)\nendif()\nif(LINUX_AARCH64)\n    option(BUILD_FILAMENT_FROM_SOURCE \"Build filament from source\"           ON )\nelse()\n    option(BUILD_FILAMENT_FROM_SOURCE \"Build filament from source\"           OFF)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring ISPC Module in CMake\nDESCRIPTION: Sets up Intel ISPC (Intel SPMD Program Compiler) language support for the project. It fetches the ISPC compiler, determines appropriate instruction sets, and enables the ISPC language for building performance-optimized code.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_25\n\nLANGUAGE: CMake\nCODE:\n```\n# ISPC language emulation support\ninclude(Open3DISPC)\n\nif (CMAKE_ISPC_COMPILER_LOADED OR (CMAKE_GENERATOR MATCHES \"Make\" OR CMAKE_GENERATOR MATCHES \"Ninja\"))\n    option(ISPC_USE_LEGACY_EMULATION \"Use legacy ISPC language emulation over first-class CMake support\" OFF)\nelse()\n    option(ISPC_USE_LEGACY_EMULATION \"Use legacy ISPC language emulation over first-class CMake support\" ON)\nendif()\nmark_as_advanced(ISPC_USE_LEGACY_EMULATION)\noption(ISPC_PRINT_LEGACY_COMPILE_COMMANDS \"Prints legacy compile commands on CMake configuration time\" ON)\nmark_as_advanced(ISPC_PRINT_LEGACY_COMPILE_COMMANDS)\n\n# Build ISPC module by default if ISPC is available\nif (BUILD_ISPC_MODULE)\n    include(Open3DFetchISPCCompiler)\n    open3d_fetch_ispc_compiler()\n\n    include(Open3DMakeISPCInstructionSets)\n    open3d_make_ispc_instruction_sets(ISPC_ISAS)\n    set(CMAKE_ISPC_INSTRUCTION_SETS ${ISPC_ISAS})\n\n    message(STATUS \"Using ISPC instruction sets: ${CMAKE_ISPC_INSTRUCTION_SETS}\")\n\n    open3d_ispc_enable_language(ISPC)\n\n    if (CMAKE_ISPC_COMPILER_ID STREQUAL \"Intel\" AND CMAKE_ISPC_COMPILER_VERSION VERSION_LESS \"1.16\")\n        message(FATAL_ERROR \"ISPC 1.15 and older are not supported. Please upgrade to ISPC 1.16 or newer.\")\n    endif()\n\n    if (NOT CMAKE_ISPC_COMPILER_ID)\n        message(FATAL_ERROR \"Unknown ISPC compiler.\")\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining Camera Library Target in Open3D with CMake\nDESCRIPTION: Creates an ISPC object library for Open3D's camera module. The library includes source files related to pinhole camera functionality and links with necessary dependencies while applying Open3D's standard build properties.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/camera/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(camera OBJECT)\n\ntarget_sources(camera PRIVATE\n    PinholeCameraIntrinsic.cpp\n    PinholeCameraParameters.cpp\n    PinholeCameraTrajectory.cpp\n)\n\nopen3d_show_and_abort_on_warning(camera)\nopen3d_set_global_properties(camera)\nopen3d_set_open3d_lib_properties(camera)\nopen3d_link_3rdparty_libraries(camera)\n```\n\n----------------------------------------\n\nTITLE: Adding SYCL-Specific Implementation Files for Hardware Acceleration\nDESCRIPTION: Conditionally adds SYCL-specific implementation files when SYCL module is enabled, providing hardware acceleration support for various kernel operations and linear algebra functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/core/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_SYCL_MODULE)\nopen3d_sycl_target_sources(core_impl PRIVATE\n    kernel/UnaryEWSYCL.cpp\n    kernel/BinaryEWSYCL.cpp\n    kernel/ArangeSYCL.cpp\n    kernel/IndexGetSetSYCL.cpp\n    kernel/NonZeroSYCL.cpp\n    kernel/IndexReductionSYCL.cpp\n    kernel/ReductionSYCL.cpp\n    linalg/AddMMSYCL.cpp\n    linalg/InverseSYCL.cpp\n    linalg/LeastSquaresSYCL.cpp\n    linalg/LUSYCL.cpp\n    linalg/MatmulSYCL.cpp\n    linalg/SolveSYCL.cpp\n    linalg/SVDSYCL.cpp\n    linalg/TriSYCL.cpp\n)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Verifying Open3D Python Installation on Unix\nDESCRIPTION: Command to verify that the Open3D Python library was installed correctly.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython -c \"import open3d\"\n```\n\n----------------------------------------\n\nTITLE: Linking Library Dependencies\nDESCRIPTION: Links necessary dependencies to the TensorFlow operations library, including TensorFlow, Open3D, and third-party libraries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_17\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(open3d_tf_ops PRIVATE\n    ${Tensorflow_FRAMEWORK_LIB}\n    Open3D::Open3D\n    Open3D::3rdparty_fmt\n    Open3D::3rdparty_nanoflann\n    TBB::tbb\n)\n```\n\n----------------------------------------\n\nTITLE: Creating and Installing Pip Package in CMake for Open3D\nDESCRIPTION: This snippet defines CMake targets for creating a pip package and installing it. It includes commands for building a wheel package and installing it in the current Python environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\n# Use `make pip-package` to create the pip package in the build directory\nadd_custom_target(pip-package\n    COMMAND ${Python3_EXECUTABLE} setup.py bdist_wheel --dist-dir pip_package\n    COMMAND echo \"pip wheel created at ${PYTHON_PACKAGE_DST_DIR}/pip_package\"\n    WORKING_DIRECTORY ${PYTHON_PACKAGE_DST_DIR}\n    DEPENDS python-package\n)\n\n# Use `make install-pip-package` to install pip wheel package to the current\n# python environment.\nadd_custom_target(install-pip-package\n    COMMAND ${CMAKE_COMMAND}\n            -DPYTHON_PACKAGE_DST_DIR=${PYTHON_PACKAGE_DST_DIR}\n            -DPython3_EXECUTABLE=${Python3_EXECUTABLE}\n            -P ${CMAKE_CURRENT_SOURCE_DIR}/make_install_pip_package.cmake\n    DEPENDS pip-package\n)\n\n# FOR DEBUGGING ONLY Use `make install-python-package` to build and install\n# python package in the current python environment. This is substantially\n# faster than `make install-pip-package`. However this approach does not create\n# wheel or egg files and does not take care of dependencies thus not suitable\n# for deployment.\n# Ref: https://stackoverflow.com/a/33791008/1255535\nadd_custom_target(install-python-package\n    COMMAND ${Python3_EXECUTABLE} setup.py install --single-version-externally-managed --root=/\n    WORKING_DIRECTORY ${PYTHON_PACKAGE_DST_DIR}\n    DEPENDS python-package\n)\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Source Files for Continuous Convolution Operations\nDESCRIPTION: Conditionally adds CUDA implementations of continuous convolution operations when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    target_sources(open3d_tf_ops PRIVATE\n        continuous_conv/ContinuousConvBackpropFilterOpKernel.cu\n        continuous_conv/ContinuousConvOpKernel.cu\n        continuous_conv/ContinuousConvTransposeBackpropFilterOpKernel.cu\n        continuous_conv/ContinuousConvTransposeOpKernel.cu\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Properties for tpipelines\nDESCRIPTION: Sets various build properties for the tpipelines target using custom Open3D CMake functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(tpipelines)\nopen3d_set_global_properties(tpipelines)\nopen3d_set_open3d_lib_properties(tpipelines)\nopen3d_link_3rdparty_libraries(tpipelines)\n```\n\n----------------------------------------\n\nTITLE: Configuring Third-Party Dependency Download Directory - CMake - CMake\nDESCRIPTION: This snippet sets and configures the directory for caching third-party dependencies needed by Open3D, using CMake's set and message commands. It defines variables for download paths and communicates the chosen directory during the configuration phase. No explicit external dependencies are required, but it assumes standard CMake usage and permissions for file system access. It outputs messages to the build log and constraints are those inherent to CMake variable scopes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\n# a limited number of 3rd party libraries.\nset(OPEN3D_THIRD_PARTY_DOWNLOAD_DIR \"${CMAKE_CURRENT_SOURCE_DIR}/3rdparty_downloads\"\n    CACHE PATH \"Third-party download directory for caching.\")\nmessage(STATUS \"Downloading third-party dependencies to ${OPEN3D_THIRD_PARTY_DOWNLOAD_DIR}\")\n\nset(FILAMENT_PRECOMPILED_ROOT \"\" CACHE PATH \"Path to precompiled Filament library (used if BUILD_FILAMENT_FROM_SOURCE=OFF)\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Test Sources in CMake for Open3D\nDESCRIPTION: Adds source files to the 'tests' target using CMake's target_sources command. The files include various geometry-related test implementations like PointCloud, LineSet, and TriangleMesh tests.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/t/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    Image.cpp\n    LineSet.cpp\n    PointCloud.cpp\n    TensorMap.cpp\n    TriangleMesh.cpp\n    AxisAlignedBoundingBox.cpp\n    OrientedBoundingBox.cpp\n    VoxelBlockGrid.cpp\n    VtkUtils.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Pipeline Library\nDESCRIPTION: Creates an OBJECT library for Open3D pipelines and configures source files for color mapping functionality. Includes implementations for color map utilities, image warping, and optimization algorithms.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nopen3d_ispc_add_library(pipelines OBJECT)\n\ntarget_sources(pipelines PRIVATE\n    color_map/ColorMapUtils.cpp\n    color_map/ImageWarpingField.cpp\n    color_map/NonRigidOptimizer.cpp\n    color_map/RigidOptimizer.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Linking Open3D Library to Benchmarks\nDESCRIPTION: Links the main Open3D library to the benchmarks executable.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_link_libraries(benchmarks PRIVATE Open3D::Open3D)\n```\n\n----------------------------------------\n\nTITLE: Running Python Unit Tests with pytest - Bash\nDESCRIPTION: This multi-line Bash code block demonstrates running pytest to automatically discover and execute unit tests following the 'test_*.py' filename and 'test_*' function naming conventions. It shows various usage patterns: invoking pytest in the current directory, specifying a custom test directory, and using the '-s' command-line flag to display standard output during test execution. These commands require pytest to be installed and test files to be properly structured.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/test/readme.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Picks up all files named \"test_*.py\", and runs all functions named \"test_*\"\npytest\n\n# Or point to a test directory, e.g.\npytest /path/to/root/test/directory\n\n# Use -s to show stdout\npytest -s\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Core Library Object Files\nDESCRIPTION: Sets up the core library object files with various source files related to tensor operations, memory management, and utilities. Includes conditional compilation for SYCL support.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/core/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(core OBJECT)\n\ntarget_sources(core PRIVATE\n    AdvancedIndexing.cpp\n    CUDAUtils.cpp\n    Device.cpp\n    Dtype.cpp\n    Indexer.cpp\n    MemoryManager.cpp\n    MemoryManagerCached.cpp\n    MemoryManagerCPU.cpp\n    MemoryManagerStatistic.cpp\n    ShapeUtil.cpp\n    SizeVector.cpp\n    SmallVector.cpp\n    Tensor.cpp\n    TensorCheck.cpp\n    TensorFunction.cpp\n    TensorKey.cpp\n    TensorList.cpp\n)\n\n# Compile regardless BUILD_SYCL_MODULE == ON or OFF.\nopen3d_sycl_target_sources(core PRIVATE\n    EigenConverter.cpp\n    SYCLUtils.cpp\n)\n\n# Compile only when BUILD_SYCL_MODULE == ON.\nif (BUILD_SYCL_MODULE)\n    open3d_sycl_target_sources(core PRIVATE\n        MemoryManagerSYCL.cpp\n        SYCLContext.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Monitoring ccache Statistics (Bash)\nDESCRIPTION: Command to display ccache usage statistics. This helps in verifying if ccache is actively caching compilations and shows metrics like cache hits, misses, and cache size. Requires ccache to be installed and accessible in the PATH.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\nccache -s\n```\n\n----------------------------------------\n\nTITLE: Parsing and Constructing Open3D Version Information - CMake - CMake\nDESCRIPTION: This snippet reads Open3D's version numbers from a text file, sets corresponding CMake variables, and constructs full and ABI version strings. If in developer mode, it fetches a Git commit hash to append for development builds. It also sets project metadata and repository URLs. Dependencies include access to the version.txt file and, optionally, a Git repository for dev builds. Outputs are stored in various CMake variables.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_14\n\nLANGUAGE: CMake\nCODE:\n```\n# Parse Open3D version number\nfile(STRINGS \"cpp/open3d/version.txt\" OPEN3D_VERSION_READ)\nforeach(ver ${OPEN3D_VERSION_READ})\n    if (ver MATCHES \"OPEN3D_VERSION_(MAJOR|MINOR|PATCH) +([^ ]+)$\")\n        set(OPEN3D_VERSION_${CMAKE_MATCH_1} \"${CMAKE_MATCH_2}\" CACHE INTERNAL \"\")\n    endif()\nendforeach()\nset(OPEN3D_VERSION_DEVHASH \"\")\nif(DEVELOPER_BUILD)\n    execute_process(COMMAND git -C \"${CMAKE_SOURCE_DIR}\" log --pretty=format:%h -n 1\n        OUTPUT_VARIABLE GIT_REV)\n    if (GIT_REV)\n        set(OPEN3D_VERSION_DEVHASH \"+${GIT_REV}\")\n    endif()\nendif()\nstring(CONCAT OPEN3D_VERSION\n    \"${OPEN3D_VERSION_MAJOR}\"\n    \".${OPEN3D_VERSION_MINOR}\"\n    \".${OPEN3D_VERSION_PATCH}\"\n)\nset(OPEN3D_VERSION_FULL \"${OPEN3D_VERSION}${OPEN3D_VERSION_DEVHASH}\" CACHE\n    STRING \"Open3D full version.\")\nset(OPEN3D_ABI_VERSION \"${OPEN3D_VERSION_MAJOR}.${OPEN3D_VERSION_MINOR}\" CACHE\n    STRING \"Open3D ABI version / SOVERSION (for releases only).\")\n# Set additional info\nset(PROJECT_EMAIL       \"open3d@intel.com\")\nset(PROJECT_DOCS        \"https://www.open3d.org/docs\")\nset(PROJECT_CODE        \"https://github.com/isl-org/Open3D\")\nset(PROJECT_ISSUES      \"https://github.com/isl-org/Open3D/issues\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Installation and Package Config\nDESCRIPTION: Sets up installation rules for the TensorFlow operations library and generates pkg-config file for Unix systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_19\n\nLANGUAGE: CMake\nCODE:\n```\ninstall(TARGETS open3d_tf_ops EXPORT Open3DTFOps\n    LIBRARY DESTINATION ${Open3D_INSTALL_LIB_DIR}\n)\ninstall(EXPORT Open3DTFOps NAMESPACE ${PROJECT_NAME}:: DESTINATION ${Open3D_INSTALL_CMAKE_DIR})\n\nif (BUILD_SHARED_LIBS AND UNIX)\n    file(CONFIGURE OUTPUT open3d_tf_ops.pc.in\n             CONTENT [=[\nprefix=${pcfiledir}/../..\nlibdir=${prefix}/lib\nincludedir=${prefix}/include/\n\nName: Open3D TensorFlow Ops\nDescription: @PROJECT_DESCRIPTION@ This library contains 3D ML Ops for use with Tensorflow.\nURL: @PROJECT_HOMEPAGE_URL@\nVersion: @PROJECT_VERSION@\nRequires: Open3D = @PROJECT_VERSION@\nCflags:\nLibs: -lopen3d_tf_ops -ltbb]=]  @ONLY NEWLINE_STYLE LF)\n    file(GENERATE OUTPUT open3d_tf_ops.pc INPUT\n        \"${CMAKE_CURRENT_BINARY_DIR}/open3d_tf_ops.pc.in\"\n        TARGET open3d_tf_ops)\n    install(FILES \"${CMAKE_CURRENT_BINARY_DIR}/open3d_tf_ops.pc\"\n        DESTINATION \"${Open3D_INSTALL_LIB_DIR}/pkgconfig\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Core Source Files to Open3D Python Bindings in CMake\nDESCRIPTION: Adds the core IO and RPC C++ source files to the 'pybind' target for Python bindings. These files handle file input/output operations and remote procedure calls functionality within Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    class_io.cpp\n    io.cpp\n    rpc.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Extending CMake Module Path for Custom Modules - CMake - CMake\nDESCRIPTION: By appending custom directories to the CMAKE_MODULE_PATH, this snippet ensures CMake can include project-specific and third-party modules during the build. It enables modular configuration and find_package overrides located in project or third-party source trees. There are no direct inputs/outputs, but it makes internal CMake modules discoverable.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_18\n\nLANGUAGE: CMake\nCODE:\n```\n# CMake modules\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\" \"${CMAKE_CURRENT_SOURCE_DIR}/3rdparty/cmake\")\n```\n\n----------------------------------------\n\nTITLE: Running Reconstruction System in Bash\nDESCRIPTION: This command demonstrates how to run the reconstruction system using the RealSense configuration file. It includes optional flags for different stages of the reconstruction process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/capture_your_own_dataset.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/python/reconstruction_system/\npython run_system.py config/realsense.json [--make] [--register] [--refine] [--integrate]\n```\n\n----------------------------------------\n\nTITLE: Adding File Format Handlers to Open3D TIO Library\nDESCRIPTION: Includes source files for various file format handlers such as ASSIMP, JPG, PCD, PLY, SPLAT, PNG, PTS, and TXT.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/io/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tio PRIVATE\n    file_format/FileASSIMP.cpp\n    file_format/FileJPG.cpp\n    file_format/FilePCD.cpp\n    file_format/FilePLY.cpp\n    file_format/FileSPLAT.cpp\n    file_format/FilePNG.cpp\n    file_format/FilePTS.cpp\n    file_format/FileTXT.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Compiler Cache with ccache\nDESCRIPTION: Configures ccache for C, C++, and CUDA compilers to speed up repeated builds by caching intermediate compilation results.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\nfind_program(CCACHE \"ccache\")\nif (CCACHE)\n    message(STATUS \"ccache found at ${CCACHE}\")\n    set(CMAKE_C_COMPILER_LAUNCHER ${CCACHE})\n    set(CMAKE_CXX_COMPILER_LAUNCHER ${CCACHE})\n    if(BUILD_CUDA_MODULE)\n        set(CMAKE_CUDA_COMPILER_LAUNCHER ${CCACHE})\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Registration Test Sources in Open3D CMake\nDESCRIPTION: Adds registration-related test source files to the tests target. These tests cover point cloud feature extraction, point cloud registration, and transformation estimation algorithms.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/t/pipelines/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    registration/Feature.cpp\n    registration/Registration.cpp\n    registration/TransformationEstimation.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Copying Open3D DLLs for Windows Shared Library Build\nDESCRIPTION: Adds a custom command to copy necessary DLL files to the executable directory when building on Windows with shared libraries. This ensures that the required DLLs are available alongside the executable.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-find-package/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\n# On Windows if BUILD_SHARED_LIBS is enabled, copy .dll files to the executable directory\nif(WIN32)\n    get_target_property(open3d_type Open3D::Open3D TYPE)\n    if(open3d_type STREQUAL \"SHARED_LIBRARY\")\n        set(copy_dlls \"${CMAKE_INSTALL_PREFIX}/bin/tbb12$<$<CONFIG:Debug>:_debug>.dll\" \n                      \"${CMAKE_INSTALL_PREFIX}/bin/Open3D.dll\")\n    else() \n        set(copy_dlls \"${CMAKE_INSTALL_PREFIX}/bin/tbb12$<$<CONFIG:Debug>:_debug>.dll\") \n    endif()\n    add_custom_command(TARGET Draw POST_BUILD\n                        COMMAND ${CMAKE_COMMAND} -E copy ${copy_dlls}\n                        ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIG>\n                        COMMENT \"Copying Open3D DLLs to ${CMAKE_CURRENT_BINARY_DIR}/$<CONFIG>\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring SYCL Support for Benchmarks\nDESCRIPTION: Conditionally adds Intel SYCL support to the benchmarks if the SYCL module is enabled in the build.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_SYCL_MODULE)\n    find_package(IntelSYCL REQUIRED)   # requires cmake>=3.25 on Windows\n    add_sycl_to_target(TARGET benchmarks)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Data Library Properties in CMake\nDESCRIPTION: Applies various build properties to the 'data' library, including warning handling, global properties, Open3D-specific library properties, and linking third-party libraries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/data/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(data)\nopen3d_set_global_properties(data)\nopen3d_set_open3d_lib_properties(data)\nopen3d_link_3rdparty_libraries(data)\n```\n\n----------------------------------------\n\nTITLE: Third-Party Libraries List\nDESCRIPTION: Comprehensive listing of all third-party libraries used in Open3D, including versions, licenses, and descriptions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README.md#2025-04-23_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\n--------------------------------------------------------------------------------\nbenchmark                   1.5.5                               Apache-2 license\nA microbenchmark support library\nhttps://github.com/google/benchmark\n--------------------------------------------------------------------------------\nboringssl:                  edfe413            Dual OpenSSL, SSLeay, ISC license\nBoringSSL is a fork of OpenSSL that is designed to meet Google's needs.\nhttps://github.com/google/boringssl\n[...remaining library entries...]\n```\n\n----------------------------------------\n\nTITLE: PyTorch Version Check\nDESCRIPTION: Verifies PyTorch version compatibility with Python 3.9+ to prevent segmentation faults.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/pytorch/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif (Python3_VERSION VERSION_GREATER_EQUAL 3.9 AND Pytorch_VERSION VERSION_LESS 1.8.0)\n    message(FATAL_ERROR \"Please update to PyTorch 1.8.0+ to build PyTorch Ops \"\n    \"with Python 3.9 to prevent a segmentation fault. See \"\n    \"https://github.com/pytorch/pytorch/issues/50014 for details\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Core Pipeline Sources\nDESCRIPTION: Adds the main pipeline source file to the pybind target build\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    pipelines.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Handling macOS Build Preferences and Frameworks - CMake - CMake\nDESCRIPTION: This snippet applies macOS-specific configuration for CMake's framework and app bundle search order if Homebrew preferences are set. It sets CMake policies to LAST for finding frameworks and app bundles, affecting how dependencies are resolved on macOS. The code is only relevant when PREFER_OSX_HOMEBREW is defined and runs in a macOS build context.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_11\n\nLANGUAGE: CMake\nCODE:\n```\nif (PREFER_OSX_HOMEBREW)\n    set(CMAKE_FIND_FRAMEWORK LAST)\n    set(CMAKE_FIND_APPBUNDLE LAST)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Building and Testing Open3D Docker Container\nDESCRIPTION: Commands to build and test an Open3D Docker container with specific configuration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docker/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd docker\n\n# Build Docker.\n./docker_build.sh openblas-amd64-py38-dev\n\n# Test Docker.\n./docker_test.sh openblas-amd64-py38-dev\n```\n\n----------------------------------------\n\nTITLE: Adding PointNet and PVCNN Operation Source Files\nDESCRIPTION: Adds PointNet-related operations (ball query, interpolation, RoI pooling, sampling) and PVCNN's trilinear devoxelization operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(open3d_tf_ops PRIVATE\n    pointnet/BallQueryOps.cpp\n    pointnet/InterpolateOps.cpp\n    pointnet/RoiPoolOps.cpp\n    pointnet/SamplingOps.cpp\n    pvcnn/TrilinearDevoxelizeOps.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Cloning and Building Open3D in WSL\nDESCRIPTION: Commands for cloning Open3D repository and building it using Docker in WSL environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docker/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/isl-org/Open3D /path/to/Open3D\ncd /path/to/Open3D/docker\nexport BUILD_PYTORCH_OPS=OFF\nexport BUILD_TENSORFLOW_OPS=OFF\n./docker_build.sh openblas-amd64-py312\n./docker_test.sh openblas-amd64-py312\n```\n\n----------------------------------------\n\nTITLE: Adding Odometry Tests to Open3D Test Module\nDESCRIPTION: Adds odometry test source files that verify various odometry components including general odometry functionality, options, tools, and RGB-D odometry jacobian implementations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/pipelines/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    odometry/Odometry.cpp\n    odometry/OdometryOption.cpp\n    odometry/OdometryTools.cpp\n    odometry/RGBDOdometryJacobianFromColorTerm.cpp\n    odometry/RGBDOdometryJacobianFromHybridTerm.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Core Tensor Sources to Python Bindings\nDESCRIPTION: CMake directive that adds core tensor operation and utility source files to the pybind target. Includes files for tensor operations, CUDA/SYCL utilities, device management, and data type handling.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/core/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    blob.cpp\n    core.cpp\n    cuda_utils.cpp\n    device.cpp\n    dtype.cpp\n    hashmap.cpp\n    kernel.cpp\n    linalg.cpp\n    scalar.cpp\n    size_vector.cpp\n    sycl_utils.cpp\n    tensor_accessor.cpp\n    tensor_converter.cpp\n    tensor_function.cpp\n    tensor_type_caster.cpp\n    tensor.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Conditionally Adding GUI Test Sources in CMake for Open3D\nDESCRIPTION: This CMake snippet conditionally adds GUI-related test sources to the 'tests' target when the BUILD_GUI option is enabled. It specifically includes the 'MaterialModifier.cpp' file from the rendering directory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/visualization/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_GUI)\n    target_sources(tests PRIVATE\n        rendering/MaterialModifier.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Reading SPLAT Format Gaussian Splats\nDESCRIPTION: Loads and prints 3D Gaussian Splats from a SPLAT file format using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/3d_gaussian_splatting.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsplat_3dgs = o3d.t.io.read_point_cloud('mipnerf360_garden_crop_table.splat')\nprint(splat_3dgs)\n```\n\n----------------------------------------\n\nTITLE: Compiling and Installing Open3D on Windows\nDESCRIPTION: This snippet demonstrates the process of cloning, configuring, and installing Open3D on Windows using CMake and Visual Studio. It specifies the use of shared libraries and allows setting the installation directory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-find-package/README.md#2025-04-23_snippet_1\n\nLANGUAGE: batch\nCODE:\n```\ngit clone https://github.com/isl-org/Open3D.git\ncd Open3D\nmkdir build\ncd build\ncmake -DBUILD_SHARED_LIBS=ON -DCMAKE_INSTALL_PREFIX=C:\\open3d_install ..\ncmake --build . --config Release --parallel 12 --target install\ncd ..\\..\n```\n\n----------------------------------------\n\nTITLE: Application Build Configuration Implementation\nDESCRIPTION: Configuration for building specific Open3D applications including the Open3D Viewer and Offline Reconstruction tools.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/apps/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nif (BUILD_GUI)\n    open3d_add_app_common(Open3DViewer Open3D Open3DViewer)\n    open3d_add_app_gui(Open3DViewer Open3D Open3DViewer)\nendif()\n\nopen3d_add_app_common(OfflineReconstruction OfflineReconstruction OfflineReconstruction)\n```\n\n----------------------------------------\n\nTITLE: Installing Style Checker Dependencies for Open3D\nDESCRIPTION: This snippet shows how to install the required dependencies for the Open3D style checker using pip. It emphasizes the importance of using the correct version of the style checker.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/contribute/styleguide.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda activate <your-virtual-env>\n\n# The version of the style checker is critical.\n# cd to the root of the Open3D folder first.\npip install -r python/requirements_style.txt\n```\n\n----------------------------------------\n\nTITLE: Specifying Source Files for Open3D Benchmarks in CMake\nDESCRIPTION: This CMake snippet adds three C++ source files to the 'benchmarks' target. These files contain performance benchmarks for KDTreeFlann, SamplePoints, and TriangleMesh components of the Open3D library.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    KDTreeFlann.cpp\n    SamplePoints.cpp\n    TriangleMesh.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Test Source Files for Open3D using CMake\nDESCRIPTION: This CMake snippet defines the source files to be compiled into the 'tests' target for Open3D. It includes test files for various geometric primitives and data structures like point clouds, meshes, and spatial indexing structures.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    AccumulatedPoint.cpp\n    AxisAlignedBoundingBox.cpp\n    EstimateNormals.cpp\n    HalfEdgeTriangleMesh.cpp\n    Image.cpp\n    IntersectionTest.cpp\n    KDTreeFlann.cpp\n    Line3D.cpp\n    LineSet.cpp\n    Octree.cpp\n    PointCloud.cpp\n    RGBDImage.cpp\n    TetraMesh.cpp\n    TriangleMesh.cpp\n    VoxelGrid.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Kernel Implementations\nDESCRIPTION: Conditionally adds CUDA kernel implementations for continuous and sparse convolution operations when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_11\n\nLANGUAGE: CMake\nCODE:\n```\n    target_sources(open3d_tf_ops PRIVATE\n        ../impl/continuous_conv/ContinuousConvCUDAKernels.cu\n        ../impl/sparse_conv/SparseConvCUDAKernels.cu\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating Python Type Hints\nDESCRIPTION: Commands to generate and install Python type hints for Open3D using pybind11-stubgen.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# Install open3d and pybind11-stubgen\npip install pybind11-stubgen open3d\n# Print location of install open3d library\npip show open3d\n# This outputs a line like: \n# Location: path/to/venv/site-packages\n# Create stubs and place them next to Open3D files\npybind11-stubgen -o <path/to/venv/site-packages/> --root-suffix \"\" open3d\n```\n\n----------------------------------------\n\nTITLE: Adding SLAM Module Sources\nDESCRIPTION: Adds SLAM (Simultaneous Localization And Mapping) implementation source files\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/pipelines/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    slam/slam.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Core IO Source Files in CMake\nDESCRIPTION: Adds the main source files for various IO operations to the 'io' target, including feature, image, mesh, and point cloud IO implementations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/io/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(io PRIVATE\n    FeatureIO.cpp\n    FileFormatIO.cpp\n    IJsonConvertibleIO.cpp\n    ImageIO.cpp\n    ImageWarpingFieldIO.cpp\n    LineSetIO.cpp\n    ModelIO.cpp\n    OctreeIO.cpp\n    PinholeCameraTrajectoryIO.cpp\n    PointCloudIO.cpp\n    PoseGraphIO.cpp\n    TriangleMeshIO.cpp\n    VoxelGridIO.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding SLAC Test Sources in Open3D CMake\nDESCRIPTION: Adds SLAC (Simultaneous Localization And Calibration) test source files to the tests target. These tests validate control grid functionality and the SLAC algorithm implementation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/t/pipelines/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    slac/ControlGrid.cpp\n    slac/SLAC.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Visualizing PLY Format Data\nDESCRIPTION: Visualizes 3D Gaussian Splats from PLY format as a point cloud.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/visualization/3d_gaussian_splatting.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Visualize full ply format 3DGS as a point cloud.\ndraw(ply_3dgs)\n```\n\n----------------------------------------\n\nTITLE: Configuring Python Package Build in CMake for Open3D\nDESCRIPTION: This snippet sets up the CMake target for building the Open3D Python package. It configures various build options and generates the necessary Python files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\nconfigure_file(\"_build_config.py.in\"\n               \"${CMAKE_BINARY_DIR}/lib/_build_config.py.in\")\nfile(GENERATE\n    OUTPUT \"${PYTHON_COMPILED_MODULE_DIR}/_build_config.py\"\n    INPUT \"${CMAKE_BINARY_DIR}/lib/_build_config.py.in\"\n)\n\nadd_custom_target(python-package\n    COMMAND ${CMAKE_COMMAND}\n            -DPYTHON_PACKAGE_SRC_DIR=${PYTHON_PACKAGE_SRC_DIR}\n            -DPYTHON_PACKAGE_DST_DIR=${PYTHON_PACKAGE_DST_DIR}\n            -DPYTHON_COMPILED_MODULE_DIR=${PYTHON_COMPILED_MODULE_DIR}\n            -DPYTHON_VERSION=${PYTHON_VERSION}\n            \"-DCOMPILED_MODULE_PATH_LIST=${COMPILED_MODULE_PATH_LIST}\"\n            \"-DPYTHON_EXTRA_LIBRARIES=${PYTHON_EXTRA_LIBRARIES}\"\n            -DBUILD_JUPYTER_EXTENSION=${BUILD_JUPYTER_EXTENSION}\n            -DBUILD_TENSORFLOW_OPS=${BUILD_TENSORFLOW_OPS}\n            -DBUILD_PYTORCH_OPS=${BUILD_PYTORCH_OPS}\n            -DBUNDLE_OPEN3D_ML=${BUNDLE_OPEN3D_ML}\n            -DOPEN3D_ML_ROOT=${OPEN3D_ML_ROOT}\n            -DBUILD_GUI=${BUILD_GUI}\n            -DBUILD_CUDA_MODULE=${BUILD_CUDA_MODULE}\n            -DBUILD_SYCL_MODULE=${BUILD_SYCL_MODULE}\n            -DGUI_RESOURCE_DIR=${GUI_RESOURCE_DIR}\n            -DPROJECT_EMAIL=${PROJECT_EMAIL}\n            -DPROJECT_HOMEPAGE_URL=${PROJECT_HOMEPAGE_URL}\n            -DPROJECT_DOCS=${PROJECT_DOCS}\n            -DPROJECT_CODE=${PROJECT_CODE}\n            -DPROJECT_ISSUES=${PROJECT_ISSUES}\n            -DPROJECT_VERSION=${OPEN3D_VERSION_FULL}\n            -DPROJECT_DESCRIPTION=${PROJECT_DESCRIPTION}\n            -DPROJECT_VERSION_THREE_NUMBER=${PROJECT_VERSION_THREE_NUMBER}\n            -DPYPI_PACKAGE_NAME=${PYPI_PACKAGE_NAME}\n            -P ${CMAKE_CURRENT_SOURCE_DIR}/make_python_package.cmake\n    VERBATIM\n    DEPENDS ${GENERATED_OUTPUTS}\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D Environment\nDESCRIPTION: Sets up the required imports and configuration for Open3D visualization tutorial. Includes necessary dependencies and interactive visualization settings.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d as o3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\nimport os\nimport sys\n\n# only needed for tutorial, monkey patches visualization\nsys.path.append('..')\nimport open3d_tutorial as o3dtut\n# change to True if you want to interact with the visualization windows\no3dtut.interactive = not \"CI\" in os.environ\n```\n\n----------------------------------------\n\nTITLE: Detecting and Configuring Python Interpreter - CMake - CMake\nDESCRIPTION: This code detects Python 3.6+ and sets relevant variables for both the Open3D project and its third-party modules (including support for deprecated PythonInterp usage). It emits a fatal error if Python is required but not found. The snippet is specific to cross-platform builds and ensures compatibility with Open3D's Python modules. Input is from the system environment and path, and it outputs variables for find_package and PYTHON_EXECUTABLE.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_19\n\nLANGUAGE: CMake\nCODE:\n```\n# Setup Python executable\nif(NOT DEFINED Python3_FIND_REGISTRY)\n    # Only consider PATH variable on Windows by default\n    set(Python3_FIND_REGISTRY NEVER)\nendif()\n# Requires Python 3.6+\nfind_package(Python3 3.6\n             COMPONENTS Interpreter Development)\nif (Python3_FOUND)\n    # Setup PYTHON_EXECUTABLE for 3rdparty modules\n    # which still use the deprecated find_package(PythonInterp)\n    set(PYTHON_EXECUTABLE ${Python3_EXECUTABLE} CACHE STRING\n        \"Deprecated path to the Python executable (for 3rdparty only)\" FORCE)\nelse()\n    if (BUILD_PYTHON_MODULE)\n        message(FATAL_ERROR \"BUILD_PYTHON_MODULE=ON requires Python >= 3.6. Please ensure it is in PATH.\")\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding IntelLLVM Compiler-Specific Options in CMake\nDESCRIPTION: Adds specific compiler options for the IntelLLVM (SYCL) compiler to handle floating-point operations correctly and avoid NaN comparison issues during compilation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/benchmark/MakeAvailable/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\n# IntelLLVM (SYCL) compiler defaults to fast math, causing NaN comparison\n# code compilation error.\nadd_compile_options($<$<CXX_COMPILER_ID:IntelLLVM>:-ffp-contract=on>)\nadd_compile_options($<$<CXX_COMPILER_ID:IntelLLVM>:-fno-fast-math>)\n```\n\n----------------------------------------\n\nTITLE: Configuring IPP Conditional Testing\nDESCRIPTION: Sets up conditional compilation definitions based on whether Intel Performance Primitives (IPP) support is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nif (WITH_IPP)\n    target_compile_definitions(benchmarks PRIVATE IPP_CONDITIONAL_TEST_STR=) # Empty string (test not disabled)\nelse()\n    target_compile_definitions(benchmarks PRIVATE IPP_CONDITIONAL_TEST_STR=DISABLED_)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Capturing Images in Customized Animation with Open3D\nDESCRIPTION: This function demonstrates how to capture color and depth images during a customized animation in Open3D. It reads a camera trajectory and defines an animation function to move through it, saving images at each step.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/customized_visualization.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef custom_draw_geometry_with_camera_trajectory(pcd):\n    custom_draw_geometry_with_camera_trajectory.index = -1\n    custom_draw_geometry_with_camera_trajectory.trajectory =\\\n            o3d.io.read_pinhole_camera_trajectory(\"../../test_data/camera_trajectory.json\")\n    custom_draw_geometry_with_camera_trajectory.vis = o3d.visualization.Visualizer()\n    image_path = os.path.join(\"image/\")\n    if not os.path.exists(image_path):\n        os.makedirs(image_path)\n    depth_path = os.path.join(\"depth/\")\n    if not os.path.exists(depth_path):\n        os.makedirs(depth_path)\n\n    def move_forward(vis):\n        # This function is called within the o3d.visualization.Visualizer::run() loop\n        # The run loop calls the function, then re-render\n        # So the sequence in this function is to:\n        # 1. Capture frame\n        # 2. index++, check ending criteria\n        # 3. Set camera\n        # 4. (Re-render)\n        ctr = vis.get_view_control()\n        glb = custom_draw_geometry_with_camera_trajectory\n        if glb.index >= 0:\n            print(\"Capture image {:05d}\".format(glb.index))\n            depth = vis.capture_depth_float_buffer()\n            image = vis.capture_screen_float_buffer()\n            plt.imsave(os.path.join(depth_path, \"{:05d}.png\".format(glb.index)),\\\n                    np.asarray(depth),\n                    dpi = 1)\n            plt.imsave(os.path.join(image_path, \"{:05d}.png\".format(glb.index)),\\\n                    np.asarray(image),\n                    dpi = 1)\n            #vis.capture_depth_image(\"depth/{:05d}.png\".format(glb.index), False)\n            #vis.capture_screen_image(\"image/{:05d}.png\".format(glb.index), False)\n        glb.index = glb.index + 1\n        if glb.index < len(glb.trajectory.parameters):\n            ctr.convert_from_pinhole_camera_parameters(\n                glb.trajectory.parameters[glb.index])\n        else:\n            custom_draw_geometry_with_camera_trajectory.vis.\\\n                    register_animation_callback(None)\n        return False\n\n    vis = custom_draw_geometry_with_camera_trajectory.vis\n    vis.create_window()\n    vis.add_geometry(pcd)\n    vis.get_render_option().load_from_json(\"../../test_data/renderoption.json\")\n    vis.register_animation_callback(move_forward)\n    vis.run()\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Contributed Implementations\nDESCRIPTION: Conditionally adds CUDA implementations of contributed operations when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_12\n\nLANGUAGE: CMake\nCODE:\n```\n    target_sources(open3d_tf_ops PRIVATE\n        ../contrib/BallQuery.cu\n        ../contrib/InterpolatePoints.cu\n        ../contrib/Nms.cu\n        ../contrib/RoiPoolKernel.cu\n        ../contrib/TrilinearDevoxelize.cu\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Creating VTK Archive Custom Target\nDESCRIPTION: Defines a custom build target that creates a compressed tar archive of the VTK build, including the necessary directories and generating a SHA256 checksum for verification purposes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/vtk/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nset(ARCHIVE_NAME \"vtk_${VTK_VERSION}${ARCHIVE_SUFFIX}.tar.gz\")\n\nadd_custom_target(vtk_archive ALL\n    COMMENT \"Creating tar archive\"\n    COMMAND ${CMAKE_COMMAND} -E tar -cvzf ${ARCHIVE_NAME} vtk/include vtk/lib vtk/share\n    COMMAND ${CMAKE_COMMAND} -E sha256sum ${ARCHIVE_NAME}\n    DEPENDS ext_vtk\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring ISPC Target Sources\nDESCRIPTION: Defines the ISPC executable target and its source files, including necessary include directories for Open3D integration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cmake/ispc_isas/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nopen3d_ispc_add_executable(ispc_isas)\n\ntarget_sources(ispc_isas PRIVATE\n    ISADispatcher.c\n    ISADispatcher.ispc\n)\n\ntarget_include_directories(ispc_isas PRIVATE\n    \"${CMAKE_CURRENT_SOURCE_DIR}/../../cpp\"\n)\n```\n\n----------------------------------------\n\nTITLE: CPU Data Type Combinations for TSDF\nDESCRIPTION: Defines the supported CPU data type combinations for TSDF integration components.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/integration.rst#2025-04-23_snippet_2\n\nLANGUAGE: cpp\nCODE:\n```\nINSTANTIATE_TSDF_INTEGRATION(float, uint16_t, uint8_t, float, float,\n                        uint8_t)  // default\nINSTANTIATE_TSDF_INTEGRATION(float, uint16_t, uint8_t, float, float,\n                        float)  // for gradients\nINSTANTIATE_TSDF_INTEGRATION(float, uint16_t, float, float, float, float)\n```\n\n----------------------------------------\n\nTITLE: Adding Point Cloud IO Source to Benchmarks Target\nDESCRIPTION: CMake directive that adds PointCloudIO.cpp source file to the benchmarks target compilation list using target_sources command\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    PointCloudIO.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding SLAC Source Files to tpipelines\nDESCRIPTION: Adds SLAC (Simultaneous Localization and Calibration) related source files to the tpipelines target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tpipelines PRIVATE\n    slac/ControlGrid.cpp\n    slac/SLACOptimizer.cpp\n    slac/Visualization.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Specifying Dataset Source Files for Open3D Python Bindings in CMake\nDESCRIPTION: This CMake directive adds dataset.cpp as a private source file to the 'pybind' target. It defines which C++ source files should be compiled and linked when building the Python bindings for Open3D's dataset functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/data/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    dataset.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Loading Tiles Texture for Material in Python\nDESCRIPTION: Demonstrates how to load tiles-based material textures (albedo, normal, roughness) in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nmat_data = o3d.data.TilesTexture()\n\nmat = o3d.visualization.rendering.MaterialRecord()\nmat.shader = \"defaultLit\"\nmat.albedo_img = o3d.io.read_image(mat_data.albedo_texture_path)\nmat.normal_img = o3d.io.read_image(mat_data.normal_texture_path)\nmat.roughness_img = o3d.io.read_image(mat_data.roughness_texture_path)\n```\n\n----------------------------------------\n\nTITLE: Encoding Shaders for Open3D Visualization in CMake\nDESCRIPTION: Encodes GLSL shader files into a C++ header file for use in the visualization library. This process allows embedding shader code directly into the compiled binary.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ninclude(Open3DAddEncodedShader)\n\nopen3d_add_encoded_shader(shader\n    OUTPUT_HEADER\n    shader/Shader.h\n    SOURCES\n    shader/glsl/ImageFragmentShader.glsl\n    shader/glsl/ImageMaskFragmentShader.glsl\n    shader/glsl/ImageMaskVertexShader.glsl\n    shader/glsl/ImageVertexShader.glsl\n    shader/glsl/NormalFragmentShader.glsl\n    shader/glsl/NormalVertexShader.glsl\n    shader/glsl/PhongFragmentShader.glsl\n    shader/glsl/PhongVertexShader.glsl\n    shader/glsl/PickingFragmentShader.glsl\n    shader/glsl/PickingVertexShader.glsl\n    shader/glsl/RGBDImageFragmentShader.glsl\n    shader/glsl/Simple2DFragmentShader.glsl\n    shader/glsl/Simple2DVertexShader.glsl\n    shader/glsl/SimpleBlackFragmentShader.glsl\n    shader/glsl/SimpleBlackVertexShader.glsl\n    shader/glsl/SimpleFragmentShader.glsl\n    shader/glsl/SimpleVertexShader.glsl\n    shader/glsl/TexturePhongFragmentShader.glsl\n    shader/glsl/TexturePhongVertexShader.glsl\n    shader/glsl/TextureSimpleFragmentShader.glsl\n    shader/glsl/TextureSimpleVertexShader.glsl\n)\n\n# Source group for Visual Studio\nadd_source_group(shader/glsl)\n\nadd_dependencies(visualization_impl shader)\n```\n\n----------------------------------------\n\nTITLE: Marking Benchmark Cache Variables as Advanced in CMake\nDESCRIPTION: Hides benchmark-related CMake cache variables from the standard view to reduce clutter in the CMake interface, improving usability while maintaining access to these variables if needed.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/benchmark/MakeAvailable/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\n# Set the cache vars introduced by the benchmark lib as advanced to not\n# clutter the CMake interfaces\nmark_as_advanced(\n    BENCHMARK_ENABLE_INSTALL\n    BENCHMARK_ENABLE_GTEST_TESTS\n    BENCHMARK_ENABLE_TESTING\n    BENCHMARK_ENABLE_ASSEMBLY_TESTS\n    BENCHMARK_DOWNLOAD_DEPENDENCIES\n    BENCHMARK_BUILD_32_BITS\n    BENCHMARK_ENABLE_EXCEPTIONS\n    BENCHMARK_ENABLE_LTO\n    BENCHMARK_USE_LIBCXX\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Library Naming and Runtime Path\nDESCRIPTION: Sets library naming conventions (no 'lib' prefix, debug postfix) and runtime search paths for finding dependencies.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_15\n\nLANGUAGE: CMake\nCODE:\n```\n# Do not add \"lib\" prefix\nset_target_properties(open3d_tf_ops PROPERTIES PREFIX \"\")\nset_target_properties(open3d_tf_ops PROPERTIES DEBUG_POSTFIX \"_debug\")\n# Set BUILD_RPATH to find tbb. We don't install through cmake.\nif (APPLE)\n    set_target_properties(open3d_tf_ops PROPERTIES BUILD_RPATH \"@loader_path/..\")\nelseif (UNIX)\n    set_target_properties(open3d_tf_ops PROPERTIES BUILD_RPATH \"$ORIGIN/..\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Material Sources and Dependencies in CMake\nDESCRIPTION: Sets up source groups for Visual Studio, adds the materials target as a dependency of the GUI target, and retrieves the list of compiled material files. This ensures materials are properly built before the GUI component.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/gui/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\n# Source group for Visual Studio\nadd_source_group(Materials)\n\nadd_dependencies(GUI materials)\n\nget_target_property(GUI_MATERIAL_COMPILED_FILES materials COMPILED_MATERIALS)\n```\n\n----------------------------------------\n\nTITLE: Windows-Specific Configuration for LibUSB in CMake\nDESCRIPTION: Sets up Windows-specific build settings for LibUSB, including changing dynamic to static runtime libraries and adding UTF-8 support. These settings ensure proper compilation on Windows platforms.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/librealsense/libusb-CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    set_target_properties (usb PROPERTIES\n        FOLDER \"3rd Party\"\n    )\n    include_directories(msvc)\n    foreach(flag_var\n        CMAKE_CXX_FLAGS CMAKE_CXX_FLAGS_DEBUG CMAKE_CXX_FLAGS_RELEASE\n        CMAKE_CXX_FLAGS_MINSIZEREL CMAKE_CXX_FLAGS_RELWITHDEBINFO\n        CMAKE_C_FLAGS CMAKE_C_FLAGS_DEBUG CMAKE_C_FLAGS_RELEASE\n        CMAKE_C_FLAGS_MINSIZEREL CMAKE_C_FLAGS_RELWITHDEBINFO)\n        if(${flag_var} MATCHES \"/MD\")\n            string(REGEX REPLACE \"/MD\" \"/MT\" ${flag_var} \"${${flag_var}}\")\n        endif(${flag_var} MATCHES \"/MD\")\n    endforeach(flag_var)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /utf-8\")\n    set(CMAKE_C_FLAGS   \"${CMAKE_C_FLAGS}   /utf-8\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Building Open3D Utility Tools\nDESCRIPTION: Uses the defined macro to build several Open3D tools including ConvertPointCloud, GLInfo, ManuallyCropGeometry, MergeMesh, and ViewGeometry. Some tools require additional dependencies like OpenGL and GLFW.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tools/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nopen3d_add_tool(ConvertPointCloud)\nopen3d_add_tool(GLInfo                  Open3D::3rdparty_opengl Open3D::3rdparty_glfw)\nopen3d_add_tool(ManuallyCropGeometry)\nopen3d_add_tool(MergeMesh)\nopen3d_add_tool(ViewGeometry)\n```\n\n----------------------------------------\n\nTITLE: Installing LibUSB Library Targets in CMake\nDESCRIPTION: Configures the installation of the LibUSB library targets for system-wide use, specifying where the libraries, headers, and binaries should be installed. This makes the library available for other projects.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/librealsense/libusb-CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\ninstall(TARGETS ${PROJECT_NAME}\n    EXPORT realsense2Targets\n    ARCHIVE DESTINATION lib\n    LIBRARY DESTINATION lib\n    RUNTIME DESTINATION bin\n    )\n```\n\n----------------------------------------\n\nTITLE: Including Color Mapping Module in Open3D Python Bindings\nDESCRIPTION: This snippet adds the color mapping module source file to the Python bindings. It enables color mapping functionality in the Python API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/pipelines/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    color_map/color_map.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Core Python Binding Sources Configuration in CMake\nDESCRIPTION: Defines the core source files required for Open3D's Python bindings visualization functionality, including render options, utilities, view control, and basic visualization components.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/visualization/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    renderoption.cpp\n    utility.cpp\n    viewcontrol.cpp\n    visualization.cpp\n    visualizer.cpp\n    rendering/material.cpp  # for RPC serialization\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Integration Tests to Open3D Test Module\nDESCRIPTION: Adds integration test source files for Scalable and Uniform TSDF (Truncated Signed Distance Field) Volume implementations to the Open3D tests target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    integration/ScalableTSDFVolume.cpp\n    integration/UniformTSDFVolume.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Patching Third-Party Library with Git\nDESCRIPTION: Step-by-step bash commands for creating and testing patches for third-party libraries, using Assimp as an example.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Do this outside of a git directory\ncd /tmp\n\n# Download the tar.gz\nwget https://github.com/assimp/assimp/archive/refs/tags/v5.1.3.tar.gz\ntar xzf v5.1.3.tar.gz\ncd assimp-5.1.3\n\n# Init git and add all source\ngit init\ngit add .\ngit commit -am \"Init commit\"\n\n# Make changes to the files, commit\ncp /my/new/ObjFileData.h          code/AssetLib/Obj/ObjFileData.h\ncp /my/new/ObjFileImporter.cpp    code/AssetLib/Obj/ObjFileImporter.cpp\ncp /my/new/ObjFileMtlImporter.cpp code/AssetLib/Obj/ObjFileMtlImporter.cpp\ngit add .\ngit commit -am \"Patch Assimp Obj importer\"\n\n# Create patch file to HEAD~1\ngit format-patch HEAD~1\n\n# Test the patch\ngit reset --hard HEAD~1\ngit apply --ignore-space-change --ignore-whitespace 0001-Patch-Assimp-Obj-importer.patch\ngit status\n```\n\n----------------------------------------\n\nTITLE: Configuring Sensor and Machine Learning Options\nDESCRIPTION: Sets options for sensor support (Intel RealSense, Azure Kinect) and machine learning integrations (TensorFlow, PyTorch) in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\noption(PREFER_OSX_HOMEBREW        \"Prefer Homebrew libs over frameworks\"     ON )\noption(WITH_MINIZIP               \"Enable MiniZIP\"                           OFF)\n\n# Sensor options\noption(BUILD_LIBREALSENSE         \"Build support for Intel RealSense camera\" OFF)\noption(USE_SYSTEM_LIBREALSENSE    \"Use system pre-installed librealsense\"    OFF)\noption(BUILD_AZURE_KINECT         \"Build support for Azure Kinect sensor\"    OFF)\n\n# ML library options\noption(BUILD_TENSORFLOW_OPS       \"Build ops for TensorFlow\"                 OFF)\noption(BUILD_PYTORCH_OPS          \"Build ops for PyTorch\"                    OFF)\noption(BUNDLE_OPEN3D_ML           \"Includes the Open3D-ML repo in the wheel\" OFF)\n```\n\n----------------------------------------\n\nTITLE: Creating Open3D Interface Target\nDESCRIPTION: Creates an interface library to simulate importing Open3D::Open3D. It sets up include directories, link directories, and links against the Open3D library built by the external project.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-external-project/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nExternalProject_Get_Property(external_open3d INSTALL_DIR)\nadd_library(Open3DHelper INTERFACE)\nadd_dependencies(Open3DHelper external_open3d)\ntarget_compile_features(Open3DHelper INTERFACE cxx_std_14)\ntarget_compile_definitions(Open3DHelper INTERFACE _GLIBCXX_USE_CXX11_ABI=$<BOOL:${GLIBCXX_USE_CXX11_ABI}>)\ntarget_include_directories(Open3DHelper INTERFACE \"${INSTALL_DIR}/include\" \"${INSTALL_DIR}/include/open3d/3rdparty\")\ntarget_link_directories(Open3DHelper INTERFACE \"${INSTALL_DIR}/lib\")\ntarget_link_libraries(Open3DHelper INTERFACE Open3D)\nadd_library(Open3D::Open3D ALIAS Open3DHelper)\n```\n\n----------------------------------------\n\nTITLE: Adding Benchmark Subdirectories\nDESCRIPTION: Adds various subdirectories containing benchmark implementations for different Open3D components.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(benchmark_utilities)\nadd_subdirectory(core)\nadd_subdirectory(geometry)\nadd_subdirectory(io)\nadd_subdirectory(pipelines)\nadd_subdirectory(t/geometry)\nadd_subdirectory(t/io)\nadd_subdirectory(t/pipelines)\n```\n\n----------------------------------------\n\nTITLE: Creating Open3D GUI Library with Source Files in CMake\nDESCRIPTION: Creates an object library named 'GUI' and adds all the source files that make up the Open3D GUI module. This includes common UI components like buttons, labels, and window management systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/gui/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(GUI OBJECT)\n\ntarget_sources(GUI PRIVATE\n    Application.cpp\n    BitmapWindowSystem.cpp\n    Button.cpp\n    Checkbox.cpp\n    Color.cpp\n    ColorEdit.cpp\n    Combobox.cpp\n    Dialog.cpp\n    Events.cpp\n    FileDialog.cpp\n    FileDialogNative.cpp\n    Font.cpp\n    GLFWWindowSystem.cpp\n    Gui.cpp\n    ImageWidget.cpp\n    ImguiFilamentBridge.cpp\n    Label.cpp\n    Label3D.cpp\n    Layout.cpp\n    ListView.cpp\n    Menu.cpp\n    MenuImgui.cpp\n    NumberEdit.cpp\n    RadioButton.cpp\n    PickPointsInteractor.cpp\n    ProgressBar.cpp\n    SceneWidget.cpp\n    Slider.cpp\n    StackedWidget.cpp\n    TabControl.cpp\n    Task.cpp\n    TextEdit.cpp\n    Theme.cpp\n    ToggleSwitch.cpp\n    TreeView.cpp\n    UIImage.cpp\n    Util.cpp\n    VectorEdit.cpp\n    Widget.cpp\n    WidgetProxy.cpp\n    WidgetStack.cpp\n    Window.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Platform-Specific Source Files for LibUSB in CMake\nDESCRIPTION: Adds platform-specific source files to the LibUSB build based on the target operating system. Handles Windows, macOS, Android, and Linux implementations with their specific USB interfaces.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/librealsense/libusb-CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n  LIST(APPEND LIBUSB_C\n  libusb/os/threads_windows.c\n  libusb/os/poll_windows.c\n  libusb/os/windows_winusb.c\n  libusb/os/windows_nt_common.c\n  libusb/os/windows_usbdk.c\n  )\nelseif (APPLE)\n  LIST(APPEND LIBUSB_C\n  libusb/os/poll_posix.c\n  libusb/os/threads_posix.c\n  libusb/os/darwin_usb.c\n  )\nelseif(ANDROID)\n  LIST(APPEND LIBUSB_C\n  libusb/os/linux_usbfs.c\n  libusb/os/poll_posix.c\n  libusb/os/threads_posix.c\n  libusb/os/linux_netlink.c\n  )\nelse()\n  LIST(APPEND LIBUSB_C\n  config.h\n  libusb/os/linux_usbfs.c\n  libusb/os/poll_posix.c\n  libusb/os/threads_posix.c\n  libusb/os/linux_udev.c\n  )\nendif()\n```\n\n----------------------------------------\n\nTITLE: WebRTC Installation Configuration\nDESCRIPTION: Configures installation of WebRTC headers and libraries. Preserves directory structure for headers and installs static libraries to the lib directory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/webrtc/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nfile(GLOB_RECURSE WEBRTC_INCLUDES RELATIVE ${WEBRTC_ROOT}/src\n    ${WEBRTC_ROOT}/src/*.h\n    )\nforeach(header ${WEBRTC_INCLUDES})\n    get_filename_component(dir ${header} DIRECTORY)\n    install(FILES ${WEBRTC_ROOT}/src/${header} DESTINATION include/${dir})\nendforeach()\ninstall(FILES\n    ${WEBRTC_NINJA_ROOT}/obj/${CMAKE_STATIC_LIBRARY_PREFIX}webrtc${CMAKE_STATIC_LIBRARY_SUFFIX}\n    ${WEBRTC_NINJA_ROOT}/obj/${CMAKE_STATIC_LIBRARY_PREFIX}webrtc_extra${CMAKE_STATIC_LIBRARY_SUFFIX}\n    DESTINATION lib\n)\n```\n\n----------------------------------------\n\nTITLE: macOS-Specific Configuration for LibUSB in CMake\nDESCRIPTION: Configures macOS-specific dependencies for LibUSB including CoreFoundation and IOKit frameworks. These frameworks are required for USB device access on macOS systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/librealsense/libusb-CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(APPLE)\n  find_library(corefoundation_lib CoreFoundation)\n  find_library(iokit_lib IOKit)\n  target_include_directories(usb PRIVATE XCode)\n  TARGET_LINK_LIBRARIES(usb objc ${corefoundation_lib} ${iokit_lib})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Integration Module to Open3D Python Bindings\nDESCRIPTION: This snippet includes the integration module source file in the Python bindings. It likely provides integration-related functions in the Python API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/pipelines/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    integration/integration.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: CUDA Data Type Combinations for TSDF\nDESCRIPTION: Defines the supported CUDA data type combinations for TSDF integration components.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/integration.rst#2025-04-23_snippet_3\n\nLANGUAGE: cpp\nCODE:\n```\nINSTANTIATE_TSDF_INTEGRATION(float, uint16_t, uint8_t, float, float,\n                        uint8_t)  // default\nINSTANTIATE_TSDF_INTEGRATION(float, uint16_t, uint8_t, float, float,\n                        float)  // for gradients\nINSTANTIATE_TSDF_INTEGRATION(float, uint16_t, float, float, float, float)\n```\n\n----------------------------------------\n\nTITLE: Incorporating Odometry Module in Open3D Python Bindings\nDESCRIPTION: This snippet adds the odometry module source file to the Python bindings. It enables odometry-related functionality in the Python API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/pipelines/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    odometry/odometry.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Conditional CUDA Module Test Sources in CMake for Open3D\nDESCRIPTION: This snippet conditionally adds CUDA-specific test sources when the CUDA module is enabled. It includes tests for FixedRadiusIndex, KnnIndex, and a CUDA version of ParallelFor.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/core/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    target_sources(tests PRIVATE\n        FixedRadiusIndex.cpp\n        KnnIndex.cpp\n        ParallelFor.cu\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Platform-Specific Compilation Definitions for WebRTC\nDESCRIPTION: Defines platform-specific compilation flags for the WebRTC server based on the target platform (Linux, macOS, or Windows). Also sets file offset bits and large file source flags for civetweb compatibility.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/webrtc_server/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_compile_definitions(webrtc_server PRIVATE\n    $<$<PLATFORM_ID:Linux,Darwin>:WEBRTC_POSIX>\n    $<$<PLATFORM_ID:Darwin>:WEBRTC_MAC>\n    $<$<PLATFORM_ID:Windows>:WEBRTC_WIN>\n    _FILE_OFFSET_BITS=64 # for civetweb\n    _LARGEFILE_SOURCE=1  # for civetweb\n)\nadd_dependencies(webrtc_server copy_html_dir)\n```\n\n----------------------------------------\n\nTITLE: Configuring Release Build Settings and Default Build Type\nDESCRIPTION: Configures developer build options and default build type. For release builds (DEVELOPER_BUILD=OFF), common CUDA architectures are built by default. When no build type is specified, Release is used as the default.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\noption(DEVELOPER_BUILD      \"Add +commit_hash to the project version number\" ON )\nif (NOT DEVELOPER_BUILD)\n    if (NOT BUILD_COMMON_CUDA_ARCHS)\n        set(BUILD_COMMON_CUDA_ARCHS ON CACHE BOOL \"Build for common CUDA GPUs (for release)\" FORCE)\n        message(WARNING \"Setting BUILD_COMMON_CUDA_ARCHS=ON since DEVELOPER_BUILD is OFF.\")\n    endif()\nendif()\n\n# Default build type on single-config generators.\n# For multi-config generators (e.g. Visual Studio), CMAKE_CONFIGURATION_TYPES\n# will be set, and we don't specify a default CMAKE_BUILD_TYPE.\n# https://blog.kitware.com/cmake-and-the-default-build-type/\nif(NOT CMAKE_CONFIGURATION_TYPES)\n    if(NOT CMAKE_BUILD_TYPE)\n        message(STATUS \"Setting build type to Release as none was specified.\")\n        set(CMAKE_BUILD_TYPE Release CACHE STRING \"Choose the type of build.\" FORCE)\n        # Set the possible values of build type for cmake-gui.\n        set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS\n                    \"Debug\" \"Release\" \"MinSizeRel\" \"RelWithDebInfo\")\n    endif()\n    message(STATUS \"CMAKE_BUILD_TYPE is set to ${CMAKE_BUILD_TYPE}.\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Sensor Components to Open3D TIO Library\nDESCRIPTION: Incorporates sensor-related source files for RGBD video metadata and reader functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/io/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tio PRIVATE\n    sensor/RGBDVideoMetadata.cpp\n    sensor/RGBDVideoReader.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Executable Target Using Open3D\nDESCRIPTION: Defines an executable target named 'Draw' that uses the Open3D library. It specifies the source file and links against the Open3D interface target created earlier.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-external-project/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_executable(Draw)\ntarget_sources(Draw PRIVATE Draw.cpp)\ntarget_link_libraries(Draw PRIVATE Open3D::Open3D)\n```\n\n----------------------------------------\n\nTITLE: Setting Platform-specific Archive Naming Conventions\nDESCRIPTION: Determines the appropriate suffix for the VTK archive based on the detected platform, architecture, and build configuration to ensure proper identification of binary packages.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/vtk/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(LINUX_AARCH64)\n    set(ARCHIVE_SUFFIX \"_linux_aarch64\")\nelseif(APPLE_AARCH64)\n    set(ARCHIVE_SUFFIX \"_macos_${CMAKE_OSX_DEPLOYMENT_TARGET}_arm64\")\nelseif(APPLE)\n    set(ARCHIVE_SUFFIX \"_macos_${CMAKE_OSX_DEPLOYMENT_TARGET}\")\nelseif(UNIX)\n    set(ARCHIVE_SUFFIX \"_linux_x86_64\")\nelseif(WIN32)\n    if (STATIC_WINDOWS_RUNTIME)\n        set(ARCHIVE_SUFFIX \"_win_staticrt\")\n    else()\n        set(ARCHIVE_SUFFIX \"_win\")\n    endif()\nelse()\n    message(FATAL \"Unsupported platform\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Geometry Library in CMake\nDESCRIPTION: This CMake snippet defines the source files for the Open3D geometry library and sets up build properties. It includes a wide range of geometry-related components such as bounding volumes, normal estimation, point clouds, mesh processing, and surface reconstruction algorithms.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(geometry OBJECT)\n\ntarget_sources(geometry PRIVATE\n    BoundingVolume.cpp\n    EstimateNormals.cpp\n    Geometry3D.cpp\n    HalfEdgeTriangleMesh.cpp\n    Image.cpp\n    ImageFactory.cpp\n    IntersectionTest.cpp\n    ISSKeypoints.cpp\n    KDTreeFlann.cpp\n    Line3D.cpp\n    LineSet.cpp\n    LineSetFactory.cpp\n    MeshBase.cpp\n    Octree.cpp\n    PointCloud.cpp\n    PointCloudCluster.cpp\n    PointCloudFactory.cpp\n    PointCloudSegmentation.cpp\n    PointCloudPlanarPatchDetection.cpp\n    Qhull.cpp\n    RGBDImage.cpp\n    RGBDImageFactory.cpp\n    SurfaceReconstructionAlphaShape.cpp\n    SurfaceReconstructionBallPivoting.cpp\n    SurfaceReconstructionPoisson.cpp\n    TetraMesh.cpp\n    TetraMeshFactory.cpp\n    TriangleMesh.cpp\n    TriangleMeshDeformation.cpp\n    TriangleMeshFactory.cpp\n    TriangleMeshSimplification.cpp\n    TriangleMeshSubdivide.cpp\n    VoxelGrid.cpp\n    VoxelGridFactory.cpp\n)\n\nopen3d_show_and_abort_on_warning(geometry)\nopen3d_set_global_properties(geometry)\nopen3d_set_open3d_lib_properties(geometry)\nopen3d_link_3rdparty_libraries(geometry)\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for Sensor Module in reStructuredText\nDESCRIPTION: This RST code defines the table of contents for the Sensor module documentation, including links to Azure Kinect and RealSense sensor pages.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n\n    azure_kinect\n    realsense\n```\n\n----------------------------------------\n\nTITLE: Configuring liblzf Library Build in CMake\nDESCRIPTION: CMake configuration block for building liblzf as a static library. Currently commented out as liblzf is integrated directly into IO module. Shows how to build liblzf as an independent static library if needed.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/liblzf/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\n#project(liblzf)\n#add_library(liblzf STATIC liblzf/lzf_c.c liblzf/lzf_d.c liblzf/lzf.h)\n```\n\n----------------------------------------\n\nTITLE: Creating Static LibUSB Library with Properties in CMake\nDESCRIPTION: Configures the LibUSB static library target with position-independent code and visibility settings. Sets up the library to be usable as a dependency with proper symbol visibility.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/librealsense/libusb-CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nadd_library(usb STATIC ${LIBUSB_C} ${LIBUSB_H})\n# Apply LANG_VISIBILITY_PRESET to static libraries and archives as well\ncmake_policy(SET CMP0063 NEW)\nset_target_properties(usb PROPERTIES POSITION_INDEPENDENT_CODE ON\n    C_VISIBILITY_PRESET hidden\n    VISIBILITY_INLINES_HIDDEN ON\n    )\n```\n\n----------------------------------------\n\nTITLE: WebRTC Path and Sanity Checks\nDESCRIPTION: Configures WebRTC paths and performs validation checks to ensure required directories exist. Sets up build type paths for debug or release configurations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/webrtc/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nset(WEBRTC_ROOT ${PROJECT_SOURCE_DIR})\nset(DEPOT_TOOLS_ROOT ${PROJECT_SOURCE_DIR}/../depot_tools)\n\nif(NOT EXISTS ${WEBRTC_ROOT}/src)\n    message(FATAL_ERROR \"Cannot find ${WEBRTC_ROOT}/src, please check WEBRTC_ROOT\")\nendif()\nif(NOT EXISTS ${DEPOT_TOOLS_ROOT}/fetch)\n    message(FATAL_ERROR \"Cannot find ${DEPOT_TOOLS_ROOT}/fetch, please check DEPOT_TOOLS_ROOT\")\nendif()\n\nif(WEBRTC_IS_DEBUG)\n    set(WEBRTC_BUILD Debug)\nelse()\n    set(WEBRTC_BUILD Release)\nendif()\nset(WEBRTC_NINJA_ROOT ${WEBRTC_ROOT}/src/out/${WEBRTC_BUILD})\n```\n\n----------------------------------------\n\nTITLE: Configuring Windows-specific Build Settings in CMake\nDESCRIPTION: Sets Windows-specific build configurations including symbol visibility, compiler options for MSVC to handle large object files, and runtime library selection based on static/dynamic linking preference.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/vtk/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nif(WIN32)\n    # Windows defaults to hidden symbol visibility, override that\n    # TODO: It would be better to explictly export symbols.\n    #       Then, we could use -fvisibility=hidden for Linux as well\n    SET(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON)\n    if(MSVC)\n        # Make sure we don't hit the 65535 object member limit with MSVC\n        #\n        # /bigobj allows object files with more than 65535 members\n        # /Ob2 enables function inlining, because MSVC is particularly\n        # verbose with inline members\n        #\n        # See: https://github.com/tensorflow/tensorflow/pull/10962\n        add_compile_options(\"$<$<COMPILE_LANGUAGE:CXX>:/bigobj;/Ob2>\")\n    endif()\n    if (STATIC_WINDOWS_RUNTIME)\n        set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>\")\n    else()\n        set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>DLL\")\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Source Files for Python Bindings in Open3D\nDESCRIPTION: CMake target_sources command that adds C++ source files implementing Python bindings for Open3D's I/O and sensor functionality to the 'pybind' target. Includes class_io.cpp, io.cpp, and sensor.cpp files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    class_io.cpp\n    io.cpp\n    sensor.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Compiler Definitions and Include Directories\nDESCRIPTION: Configures compiler definitions for TensorFlow and CUDA support, and sets include directories for dependencies.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_16\n\nLANGUAGE: CMake\nCODE:\n```\n# _GLIBCXX_USER_CXX11_ABI is set separately\nlist(REMOVE_ITEM Tensorflow_DEFINITIONS \"_GLIBCXX_USE_CXX11_ABI=0\"\n    \"_GLIBCXX_USE_CXX11_ABI=1\")\ntarget_compile_definitions(open3d_tf_ops PRIVATE \"${Tensorflow_DEFINITIONS}\")\n\nif (BUILD_CUDA_MODULE)\n    target_compile_definitions(open3d_tf_ops PRIVATE \"BUILD_CUDA_MODULE\")\nendif()\n\n# Silence warnings caused by tensorflow's Eigen. Travis has a different version\n# of protobuf in /usr/local/include TBB is in /usr/local/include, so it needs to\n# be after TensorFlow\ntarget_include_directories(open3d_tf_ops SYSTEM PRIVATE\n    ${PROJECT_SOURCE_DIR}/cpp\n    ${Tensorflow_INCLUDE_DIR}\n    ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Build on Unix\nDESCRIPTION: Commands to create a build directory and run CMake to configure the Open3D build on Unix-based systems (Ubuntu/macOS).\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir build\ncd build\ncmake ..\n```\n\n----------------------------------------\n\nTITLE: Building Open3D with ML Module Support\nDESCRIPTION: CMake configuration for building Open3D with CUDA and ML framework support, including PyTorch and TensorFlow operations, and bundling with Open3D-ML.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n# In the build directory\ncmake -DBUILD_CUDA_MODULE=ON \\\n      -DGLIBCXX_USE_CXX11_ABI=OFF \\\n      -DBUILD_PYTORCH_OPS=ON \\\n      -DBUILD_TENSORFLOW_OPS=ON \\\n      -DBUNDLE_OPEN3D_ML=ON \\\n      -DOPEN3D_ML_ROOT=https://github.com/isl-org/Open3D-ML.git \\\n      ..\n# Install the python wheel with pip\nmake -j install-pip-package\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Test Dependencies with Version Pinning\nDESCRIPTION: This configuration lists Python packages required for testing the Open3D project. It specifies exact versions for `pytest`, `pytest-randomly`, `scipy`, `tensorboard`, `oauthlib`, and `certifi`. Conditional versions for `scipy` and `tensorboard` are defined based on whether the Python version is less than 3.12 or greater than or equal to 3.12, ensuring compatibility. These dependencies are typically installed using a package manager like pip (e.g., `pip install -r requirements.txt`).\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_test.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npytest==7.1.2\npytest-randomly==3.8.0\nscipy==1.10.1; python_version < \"3.12\"\nscipy==1.11.4; python_version >= \"3.12\"\ntensorboard==2.13.0; python_version < \"3.12\"\ntensorboard==2.16.2; python_version >= \"3.12\"\noauthlib==3.2.2\ncertifi==2024.7.4\n```\n\n----------------------------------------\n\nTITLE: Defining Open3D Example Addition Macro in CMake\nDESCRIPTION: This macro sets up an executable target for an Open3D example, configuring its sources, libraries, and properties. It also handles conditional builds and warning settings.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cpp/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nmacro(open3d_add_example EXAMPLE_CPP_NAME)\n    add_executable(${EXAMPLE_CPP_NAME})\n\n    target_sources(${EXAMPLE_CPP_NAME} PRIVATE \"${EXAMPLE_CPP_NAME}.cpp\")\n    target_link_libraries(${EXAMPLE_CPP_NAME} PRIVATE Open3D::Open3D ${ARGN})\n\n    open3d_show_and_abort_on_warning(${EXAMPLE_CPP_NAME})\n    open3d_set_global_properties(${EXAMPLE_CPP_NAME})\n\n    set_target_properties(${EXAMPLE_CPP_NAME} PROPERTIES\n        FOLDER \"examples/cpp/\"\n        RUNTIME_OUTPUT_DIRECTORY \"${EXAMPLE_BIN_DIR}\"\n    )\n\n    if (NOT BUILD_EXAMPLES)\n        set_target_properties(${EXAMPLE_CPP_NAME} PROPERTIES\n            EXCLUDE_FROM_ALL TRUE\n        )\n    endif()\n\n    list(APPEND EXAMPLE_TARGETS ${EXAMPLE_CPP_NAME})\nendmacro()\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D with pip\nDESCRIPTION: A simple example showing how to install Open3D using pip package manager.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/contribute/example_python_docstring.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install open3d\n```\n\n----------------------------------------\n\nTITLE: Configuring OSMesa for GLEW\nDESCRIPTION: Sets up OSMesa dependencies and libraries when GLEW_OSMESA is enabled. Handles platform-specific library names and includes necessary headers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif (GLEW_OSMESA)\n\tfind_package(OSMesa REQUIRED)\n\tinclude_directories(string(${OSMESA_INCLUDE_DIR} \"/GL/\"))\n\tif (WIN32)\n\t\tset (OSMESA_LIB_NAME osmesa)\n\telse ()\n\t\tset (OSMESA_LIB_NAME OSMesa)\n\tendif ()\n\tadd_definitions (-DGLEW_OSMESA)\n\tset (GLEW_LIBRARIES ${OSMESA_LIB_NAME} ${OPENGL_LIBRARIES})\n\tset (X11_LIBRARIES)\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Adding Gaussian Noise to Point Cloud\nDESCRIPTION: Defines and applies a function to add Gaussian noise to a point cloud. This creates a noisy version of the source point cloud to demonstrate the effectiveness of robust kernels in handling outliers.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/robust_kernels.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef apply_noise(pcd, mu, sigma):\n    noisy_pcd = copy.deepcopy(pcd)\n    points = np.asarray(noisy_pcd.points)\n    points += np.random.normal(mu, sigma, size=points.shape)\n    noisy_pcd.points = o3d.utility.Vector3dVector(points)\n    return noisy_pcd\n\n\nmu, sigma = 0, 0.1  # mean and standard deviation\nsource_noisy = apply_noise(source, mu, sigma)\n\nprint(\"Source PointCloud + noise:\")\no3d.visualization.draw_geometries([source_noisy],\n                                  zoom=0.4459,\n                                  front=[0.353, -0.469, -0.809],\n                                  lookat=[2.343, 2.217, 1.809],\n                                  up=[-0.097, -0.879, 0.467])\n```\n\n----------------------------------------\n\nTITLE: Setting Up GLEW Library Build\nDESCRIPTION: Configures the GLEW library build, including source and header files, and sets up the library target with appropriate properties.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude_directories(\"${CMAKE_CURRENT_SOURCE_DIR}/include\")\n\n# SET LIBNAME\nset(GLEW_LIBRARY glew)\n\nfile(GLOB glew_sources src/glew.c)\nif (GLEW_OSMESA)\n\tfile(GLOB glew_headers ${OSMESA_INCLUDE_DIR}/GL/*.h include/GL/*.h)\nelse ()\n\tfile(GLOB glew_headers include/GL/*.h)\nendif ()\n\nadd_library(${GLEW_LIBRARY} STATIC ${glew_sources} ${glew_headers})\nset_target_properties(${GLEW_LIBRARY} PROPERTIES\n\t\tOUTPUT_NAME ${GLEW_LIBRARY}\n\t\tPOSITION_INDEPENDENT_CODE ON\n\t\tCXX_VISIBILITY_PRESET \"hidden\"\n\t\tFOLDER \"3rdparty\"\n)\n```\n\n----------------------------------------\n\nTITLE: Setting macOS Deployment Target in CMake\nDESCRIPTION: Configures the minimum macOS version required for deployment by setting the CMAKE_OSX_DEPLOYMENT_TARGET variable to 12.6.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/vtk/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif (APPLE)\nset (CMAKE_OSX_DEPLOYMENT_TARGET \"12.6\" CACHE STRING\n    \"Minimum OS X deployment version\" FORCE)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Nearest Neighbor Search Sources\nDESCRIPTION: CMake directive that adds nearest neighbor search implementation source files to the pybind target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/core/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    nns/nearest_neighbor_search.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing TensorFlow Ops Build in CMake\nDESCRIPTION: Sets up the initial build configuration for TensorFlow operations, checking for CUDA support and finding the TensorFlow package.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nmessage(STATUS \"Building TensorFlow ops\")\n\nget_property(languages GLOBAL PROPERTY ENABLED_LANGUAGES)\nif(BUILD_CUDA_MODULE)\n    message(STATUS \"Building TensorFlow ops with CUDA\")\nendif()\n\nfind_package(Tensorflow REQUIRED)\n```\n\n----------------------------------------\n\nTITLE: Checking Open3D ABI Version\nDESCRIPTION: Python command to check the ABI version used by the installed Open3D package.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\npython -c \"import open3d; print(open3d.pybind._GLIBCXX_USE_CXX11_ABI)\"\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Source Files for GPU Acceleration in Open3D Pipeline\nDESCRIPTION: Conditionally adds CUDA source files to the tpipelines_kernel when BUILD_CUDA_MODULE is enabled. This allows for GPU-accelerated implementations of registration, linear system operations, odometry, transformation, and feature extraction.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/kernel/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    target_sources(tpipelines_kernel PRIVATE\n        RegistrationCUDA.cu\n        FillInLinearSystemCUDA.cu\n        RGBDOdometryCUDA.cu\n        TransformationConverter.cu\n        FeatureCUDA.cu\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding RPC Functionality in CMake\nDESCRIPTION: Incorporates Remote Procedure Call (RPC) related source files, including connection handling, message processing, and ZMQ integration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/io/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(io PRIVATE\n    rpc/BufferConnection.cpp\n    rpc/Connection.cpp\n    rpc/DummyReceiver.cpp\n    rpc/MessageProcessorBase.cpp\n    rpc/MessageUtils.cpp\n    rpc/RemoteFunctions.cpp\n    rpc/ZMQContext.cpp\n    rpc/ZMQReceiver.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Build on Windows\nDESCRIPTION: Commands to create a build directory and configure the Open3D build on Windows using Visual Studio.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_8\n\nLANGUAGE: bat\nCODE:\n```\nmkdir build\ncd build\n\n:: Specify the generator based on your Visual Studio version\n:: If CMAKE_INSTALL_PREFIX is a system folder, admin access is needed for installation\ncmake -G \"Visual Studio 16 2019\" -A x64 -DCMAKE_INSTALL_PREFIX=\"<open3d_install_directory>\" ..\n```\n\n----------------------------------------\n\nTITLE: Configuring Core Test Sources in CMake for Open3D\nDESCRIPTION: This CMake snippet configures the primary test source files for the Open3D project. It adds various utility test files such as Download, Extract, Eigen, FileSystem and others to the 'tests' target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/utility/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    Download.cpp\n    Extract.cpp\n    Eigen.cpp\n    FileSystem.cpp\n    Helper.cpp\n    IJsonConvertible.cpp\n    ISAInfo.cpp\n    Logging.cpp\n    Preprocessor.cpp\n    ProgressBar.cpp\n    Timer.cpp\n    Random.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Core Pipeline Source to Python Bindings in Open3D\nDESCRIPTION: This snippet adds the main pipelines.cpp file to the Python bindings target. It's likely the entry point for the pipelines module in the Python API.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    pipelines.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D Core and NumPy Libraries\nDESCRIPTION: Basic import statements required for using Open3D's tensor functionality along with NumPy for array operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport open3d.core as o3c\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Configuring Pinhole Camera Test Sources in CMake\nDESCRIPTION: This CMake directive adds multiple test source files to the 'tests' target using target_sources. It includes test files for PinholeCameraIntrinsic, PinholeCameraParameters, and PinholeCameraTrajectory components of Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/camera/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    PinholeCameraIntrinsic.cpp\n    PinholeCameraParameters.cpp\n    PinholeCameraTrajectory.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Standard Point-to-Plane ICP Registration\nDESCRIPTION: Performs standard point-to-plane ICP registration on the noisy source point cloud with a small threshold value. This demonstrates how vanilla ICP struggles with noisy data.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/pipelines/robust_kernels.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nthreshold = 0.02\nprint(\"Vanilla point-to-plane ICP, threshold={}:\".format(threshold))\np2l = o3d.pipelines.registration.TransformationEstimationPointToPlane()\nreg_p2l = o3d.pipelines.registration.registration_icp(source_noisy, target,\n                                                      threshold, trans_init,\n                                                      p2l)\n\nprint(reg_p2l)\nprint(\"Transformation is:\")\nprint(reg_p2l.transformation)\ndraw_registration_result(source, target, reg_p2l.transformation)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Building tinyfiledialogs Library with CMake\nDESCRIPTION: This CMake script sets up the tinyfiledialogs library as a static library. It defines the project, sets minimum CMake version, configures source files, and sets up installation rules for the library.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/tinyfiledialogs/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nproject(tinyfiledialogs C)\n\ncmake_minimum_required(VERSION 3.0.0)\nset(CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS true)\n\n# SET LIBNAME\nset(FILEDIALOG_LIBRARY tinyfiledialogs)\n\nfile(GLOB tinyfiledialogs_sources include/tinyfiledialogs/tinyfiledialogs.c)\nfile(GLOB tinyfiledialogs_headers include/tinyfiledialogs/tinyfiledialogs.h)\n\nadd_library(${FILEDIALOG_LIBRARY} STATIC ${tinyfiledialogs_sources} ${tinyfiledialogs_headers})\nset_target_properties(${FILEDIALOG_LIBRARY} PROPERTIES\n        OUTPUT_NAME ${FILEDIALOG_LIBRARY}\n        FOLDER \"3rdparty\"\n    )\n\n# install\nif (NOT BUILD_SHARED_LIBS)\n    install(TARGETS ${FILEDIALOG_LIBRARY}\n            RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/bin\n            LIBRARY DESTINATION ${CMAKE_INSTALL_PREFIX}/lib\n            ARCHIVE DESTINATION ${CMAKE_INSTALL_PREFIX}/lib)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring RPLY as an Independent Library in CMake\nDESCRIPTION: Commented CMake configuration that would build rply as a standalone static library. Currently disabled since rply is integrated directly into the Open3D IO module instead of being built separately.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/rply/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\n#project(rply)\n#add_library(rply STATIC rply/rply.c rply/rply.h)\n```\n\n----------------------------------------\n\nTITLE: Defining Test Source Files for Open3D IO Testing in CMake\nDESCRIPTION: This CMake code specifies the source files to be included in the 'tests' target for Open3D's IO functionality testing. The target_sources command adds ImageIO.cpp, NumpyIO.cpp, PointCloudIO.cpp, and TriangleMeshIO.cpp to the tests target, all of which test different aspects of Open3D's input/output capabilities.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/t/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    ImageIO.cpp\n    NumpyIO.cpp\n    PointCloudIO.cpp\n    TriangleMeshIO.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Defining External Project CMake Arguments\nDESCRIPTION: Sets up CMake arguments for configuring external projects with proper compiler settings, deployment targets, and build configurations. Includes two variants: standard and hidden symbol visibility.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/vtk/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n# CMake arguments for configuring ExternalProjects. Use the second _hidden\n# version by default.\nset(ExternalProject_CMAKE_ARGS\n    -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}\n    -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}\n    -DCMAKE_CUDA_COMPILER=${CMAKE_CUDA_COMPILER}\n    -DCMAKE_C_COMPILER_LAUNCHER=${CMAKE_C_COMPILER_LAUNCHER}\n    -DCMAKE_CXX_COMPILER_LAUNCHER=${CMAKE_CXX_COMPILER_LAUNCHER}\n    -DCMAKE_CUDA_COMPILER_LAUNCHER=${CMAKE_CUDA_COMPILER_LAUNCHER}\n    -DCMAKE_OSX_DEPLOYMENT_TARGET=${CMAKE_OSX_DEPLOYMENT_TARGET}\n    # Always build 3rd party code in Release mode. Ignored by multi-config\n    # generators (XCode, MSVC). MSVC needs matching config anyway.\n    -DCMAKE_BUILD_TYPE=Release\n    -DCMAKE_POLICY_DEFAULT_CMP0091:STRING=NEW\n    -DCMAKE_MSVC_RUNTIME_LIBRARY:STRING=${CMAKE_MSVC_RUNTIME_LIBRARY}\n    -DCMAKE_POSITION_INDEPENDENT_CODE=ON\n)\n# Keep 3rd party symbols hidden from Open3D user code. Do not use if 3rd party\n# libraries throw exceptions that escape Open3D.\nset(ExternalProject_CMAKE_ARGS_hidden\n    ${ExternalProject_CMAKE_ARGS}\n    # Apply LANG_VISIBILITY_PRESET to static libraries and archives as well\n    -DCMAKE_POLICY_DEFAULT_CMP0063:STRING=NEW\n    -DCMAKE_CXX_VISIBILITY_PRESET=hidden\n    -DCMAKE_CUDA_VISIBILITY_PRESET=hidden\n    -DCMAKE_C_VISIBILITY_PRESET=hidden\n    -DCMAKE_VISIBILITY_INLINES_HIDDEN=ON\n)\n```\n\n----------------------------------------\n\nTITLE: Building C++ API Documentation\nDESCRIPTION: Commands to clone the Open3D repository and generate C++ API documentation using Doxygen.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/isl-org/open3d\ncd open3d/docs\ndoxygen Doxyfile.in\n```\n\n----------------------------------------\n\nTITLE: Signing Open3D macOS Application\nDESCRIPTION: Shell command for signing the Open3D application bundle on macOS. Uses the signing script with parameters for the app bundle, entitlements file, and Apple developer credentials.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/release.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n../../cpp/apps/sign_open3d_app.sh Open3D.app ../../cpp/apps/Open3DViewer/Open3dViewer.entitlements <apple-id>\n                                    <cert-name> <team-id> <app-password>\n```\n\n----------------------------------------\n\nTITLE: Adding Source Files to CMake Benchmarks Target\nDESCRIPTION: CMake configuration that adds Rand.cpp to the benchmarks target compilation list using target_sources command.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/benchmark_utilities/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    Rand.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Source Files for Open3D Tensor Geometry Library\nDESCRIPTION: Specifies the C++ source files that implement various geometry data structures like PointCloud, TriangleMesh, and LineSet.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/geometry/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tgeometry PRIVATE\n    Image.cpp\n    LineSet.cpp\n    BoundingVolume.cpp\n    PointCloud.cpp\n    RGBDImage.cpp\n    TensorMap.cpp\n    TriangleMesh.cpp\n    TriangleMeshFactory.cpp\n    VoxelBlockGrid.cpp\n    VtkUtils.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Dependency Specification for pygments (Python)\nDESCRIPTION: Requires the `pygments` package, version 2.7.4 or higher (`>=2.7.4`). Pygments is a widely used syntax highlighting library for various programming languages.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_jupyter_build.txt#2025-04-23_snippet_2\n\nLANGUAGE: requirements\nCODE:\n```\npygments>=2.7.4\n```\n\n----------------------------------------\n\nTITLE: Adding Source Files to Open3D Benchmarks Target in CMake\nDESCRIPTION: This CMake snippet adds PointCloudIO.cpp and TriangleMeshIO.cpp as source files to the 'benchmarks' target. These files likely contain performance benchmarks for point cloud and triangle mesh I/O operations in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/t/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    PointCloudIO.cpp\n    TriangleMeshIO.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Point-to-Plane ICP with Robust Kernel\nDESCRIPTION: Performs point-to-plane ICP registration using the configured robust kernel. Includes timing measurement and prints registration quality metrics including fitness and inlier RMSE.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_robust_kernel.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Vanilla point-to-plane ICP, max_correspondence_distance={}\".format(\n    max_correspondence_distance))\n\ns = time.time()\n\nreg_point_to_plane = treg.icp(source, target, max_correspondence_distance,\n                              init_source_to_target, estimation, criteria,\n                              voxel_size)\n\nicp_time = time.time() - s\nprint(\"Time taken by Point-To-Plane ICP: \", icp_time)\nprint(\"Fitness: \", reg_point_to_plane.fitness)\nprint(\"Inlier RMSE: \", reg_point_to_plane.inlier_rmse)\n\ndraw_registration_result(source, target, reg_point_to_plane.transformation)\n```\n\n----------------------------------------\n\nTITLE: Creating Open3D Geometry Kernel Library with CPU and CUDA Support in CMake\nDESCRIPTION: Configures the Open3D geometry kernel library target with core CPU sources and optional CUDA implementation sources. The configuration handles dependencies, compilation flags, and various build options including ISPC, CUDA, and IPP accelerations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/geometry/kernel/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(tgeometry_kernel OBJECT)\nset_target_properties(tgeometry_kernel PROPERTIES CXX_VISIBILITY_PRESET \"hidden\")\n\n\ntarget_sources(tgeometry_kernel PRIVATE\n    Image.cpp\n    ImageCPU.cpp\n    PCAPartition.cpp\n    PointCloud.cpp\n    PointCloudCPU.cpp\n    Metrics.cpp\n    MinimumOBB.cpp\n    TriangleMesh.cpp\n    TriangleMeshCPU.cpp\n    Transform.cpp\n    TransformCPU.cpp\n    UVUnwrapping.cpp\n    VoxelBlockGrid.cpp\n    VoxelBlockGridCPU.cpp\n)\n\nif (BUILD_CUDA_MODULE)\n    target_sources(tgeometry_kernel PRIVATE\n        ImageCUDA.cu\n        NPPImage.cpp\n        PointCloudCUDA.cu\n        TriangleMeshCUDA.cu\n        TransformCUDA.cu\n        VoxelBlockGridCUDA.cu\n    )\nendif()\n\nif (WITH_IPP)\n    target_sources(tgeometry_kernel PRIVATE\n        IPPImage.cpp\n    )\nendif()\n\nopen3d_show_and_abort_on_warning(tgeometry_kernel)\nopen3d_set_global_properties(tgeometry_kernel)\nopen3d_set_open3d_lib_properties(tgeometry_kernel HIDDEN)\nopen3d_link_3rdparty_libraries(tgeometry_kernel)\n\nif(BUILD_CUDA_MODULE)\n  target_include_directories(tgeometry_kernel SYSTEM\n                             PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Open3D Build Properties for Tensor Geometry Library\nDESCRIPTION: Applies standard Open3D build configurations including warning handling, global properties, library properties, and third-party library linking.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/geometry/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(tgeometry)\nopen3d_set_global_properties(tgeometry)\nopen3d_set_open3d_lib_properties(tgeometry)\nopen3d_link_3rdparty_libraries(tgeometry)\n```\n\n----------------------------------------\n\nTITLE: WebRTC CMake Project Configuration\nDESCRIPTION: Sets up the CMake project with version requirements and basic options for WebRTC compilation. Includes debug build configuration and C++11 ABI settings.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/webrtc/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.18)\nproject(webrtc CXX)\n\ninclude(CMakeDependentOption)\ncmake_dependent_option(WEBRTC_IS_DEBUG\n    \"WebRTC Debug build. Use ON for Win32 Open3D Debug.\" OFF\n    \"NOT CMAKE_BUILD_TYPE STREQUAL Debug OR NOT WIN32\" ON)\noption(GLIBCXX_USE_CXX11_ABI \"Set -D_GLIBCXX_USE_CXX11_ABI=1\" ON)\n```\n\n----------------------------------------\n\nTITLE: Specifying Camera Source Files for Python Bindings in Open3D\nDESCRIPTION: This CMake directive adds camera.cpp as a source file to the 'pybind' target. This file likely contains the code that exposes Open3D's camera functionality to Python through pybind11.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/camera/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    camera.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding File Format Handlers in CMake\nDESCRIPTION: Includes source files for various file format handlers, supporting formats like ASSIMP, BIN, GLTF, JPG, JSON, OBJ, PLY, and more.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/io/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(io PRIVATE\n    file_format/FileASSIMP.cpp\n    file_format/FileBIN.cpp\n    file_format/FileGLTF.cpp\n    file_format/FileJPG.cpp\n    file_format/FileJSON.cpp\n    file_format/FileLOG.cpp\n    file_format/FileOBJ.cpp\n    file_format/FileOFF.cpp\n    file_format/FilePCD.cpp\n    file_format/FilePLY.cpp\n    file_format/FilePNG.cpp\n    file_format/FilePTS.cpp\n    file_format/FileSTL.cpp\n    file_format/FileTUM.cpp\n    file_format/FileXYZ.cpp\n    file_format/FileXYZN.cpp\n    file_format/FileXYZRGB.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Detecting ARM Architecture on Linux and macOS\nDESCRIPTION: Uses system commands to detect ARM64 architecture on Linux and macOS platforms, setting appropriate variables for conditional logic later in the build process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/vtk/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif(UNIX AND NOT APPLE)\n    execute_process(COMMAND uname -p\n        OUTPUT_VARIABLE PROCESSOR_ARCH\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    if(PROCESSOR_ARCH STREQUAL \"aarch64\")\n        set(LINUX_AARCH64 TRUE)\n    endif()\nendif()\nif(APPLE)\n    execute_process(COMMAND uname -m\n        OUTPUT_VARIABLE PROCESSOR_ARCH\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    if(PROCESSOR_ARCH STREQUAL \"arm64\")\n        set(APPLE_AARCH64 TRUE)\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Loading RGBD Images from Bedroom Dataset\nDESCRIPTION: Creates RGBD images from color and depth image pairs using Open3D's RGBDImage class and loads a triangle mesh reconstruction.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_56\n\nLANGUAGE: python\nCODE:\n```\nrgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n                                                   color_raw, depth_raw)\nrgbd_images.append(rgbd_image)\n\nmesh = o3d.io.read_triangle_mesh(dataset.reconstruction_path)\n```\n\n----------------------------------------\n\nTITLE: Bundling Open3D-ML in CMake for Open3D\nDESCRIPTION: This snippet sets up the bundling of Open3D-ML if enabled. It finds the Open3D-ML root directory and adds it as an external project to the build process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUNDLE_OPEN3D_ML)\n    find_path(\n        OPEN3D_ML_ROOT\n        NAMES set_open3d_ml_root.sh\n        HINTS $ENV{OPEN3D_ML_ROOT}\n        DOC \"Path to the Open3D-ML repo. This should be set if BUNDLE_OPEN3D_ML is enabled. Alternatively set an env var with the same name to populate this var.\"\n        REQUIRED\n        NO_DEFAULT_PATH\n    )\n\n    ExternalProject_Add(\n        open3d_ml\n        PREFIX \"${CMAKE_BINARY_DIR}/open3d_ml\"\n        GIT_REPOSITORY \"${OPEN3D_ML_ROOT}\"\n        GIT_TAG origin/main\n        GIT_SHALLOW\n        BUILD_IN_SOURCE ON\n        # do not configure\n        CONFIGURE_COMMAND \"\"\n        # do not build\n        BUILD_COMMAND \"\"\n        # do not install\n        INSTALL_COMMAND \"\"\n        )\n    list(APPEND GENERATED_OUTPUTS open3d_ml)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Common Application Build Configuration in CMake\nDESCRIPTION: Macro for setting up common build configurations for Open3D applications, including source file gathering, executable configuration, and linking dependencies.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/apps/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nmacro(open3d_add_app_common SRC_DIR APP_NAME TARGET_NAME)\n    set(APPS_DIR \"${PROJECT_SOURCE_DIR}/cpp/apps\")\n    set(SOURCE_DIR \"${APPS_DIR}/${SRC_DIR}\")\n\n    file(GLOB SOURCE_FILES \"${SOURCE_DIR}/*.cpp\")\n    file(GLOB HEADER_FILES \"${SOURCE_DIR}/*.h\")\n\n    if (APPLE)\n        add_executable(${TARGET_NAME} ${SOURCE_FILES} ${HEADER_FILES})\n        set_target_properties(${TARGET_NAME} PROPERTIES\n                              MACOSX_BUNDLE TRUE\n                              MACOSX_BUNDLE_INFO_PLIST \"${INFO_PLIST}\"\n                              XCODE_ATTRIBUTE_CODE_SIGN_IDENTITY \"\" # disable\n                              OUTPUT_NAME ${APP_NAME}\n                              INSTALL_RPATH \"@loader_path;@loader_path/../lib/\")\n    elseif (WIN32)\n        set(CMAKE_RUNTIME_OUTPUT_DIRECTORY \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/../${APP_NAME}\")\n        add_executable(${TARGET_NAME} ${SOURCE_FILES} ${HEADER_FILES})\n    else()\n        set(CMAKE_RUNTIME_OUTPUT_DIRECTORY \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/../${APP_NAME}\")\n        add_executable(${TARGET_NAME} ${SOURCE_FILES} ${HEADER_FILES})\n        set_target_properties(${TARGET_NAME} PROPERTIES\n                            OUTPUT_NAME ${APP_NAME}\n                            INSTALL_RPATH \"$ORIGIN;$ORIGIN/../lib/\")\n    endif()\n\n    target_link_libraries(${TARGET_NAME} PRIVATE Open3D::Open3D TBB::tbb ${ARGN})\n    set_target_properties(${TARGET_NAME} PROPERTIES FOLDER \"apps\")\n\n    if (BUILD_SYCL_MODULE)\n        find_package(IntelSYCL REQUIRED)   # requires cmake>=3.25 on Windows\n        add_sycl_to_target(TARGET ${TARGET_NAME})\n    endif()\n\n    open3d_link_3rdparty_libraries(${TARGET_NAME})\n    open3d_show_and_abort_on_warning(${TARGET_NAME})\n    open3d_set_global_properties(${TARGET_NAME})\nendmacro()\n```\n\n----------------------------------------\n\nTITLE: Configuring WebRTC Server Library in CMake\nDESCRIPTION: Creates a WebRTC server object library and configures its source files. The library includes components for bitmap tracking, HTTP server handling, image capturing, peer connection management, and window system integration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/webrtc_server/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(webrtc_server OBJECT)\n\ntarget_sources(webrtc_server PRIVATE\n    BitmapTrackSource.cpp\n    HttpServerRequestHandler.cpp\n    ImageCapturer.cpp\n    PeerConnectionManager.cpp\n    WebRTCWindowSystem.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Running Open3D SYCL Demos and Tests\nDESCRIPTION: Commands for running SYCL demos in C++ and Python to ensure proper linking and that all runtime dependencies are satisfied.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README_SYCL.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# C++ test\nmake tests -j$(nproc)\n./bin/tests --gtest_filter=\"*SYCLDemo*\"\n\n# C++ example\nmake SYCLDemo -j$(nproc)\n./bin/examples/SYCLDemo\n\n# Python\nmake install-pip-package -j$(nproc)\npytest ../python/test/core/test_sycl_utils.py -s\n```\n\n----------------------------------------\n\nTITLE: Adding Source Files to Tests Target in Open3D CMake Configuration\nDESCRIPTION: This CMake directive adds ShapeChecking.cpp as a source file to the 'tests' target in Open3D. The PRIVATE keyword indicates that this source file is only used for building the 'tests' target itself and not exposed to targets that depend on it.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/ml/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    ShapeChecking.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Python Package Configuration in CMake\nDESCRIPTION: Configures the Python package build process, including setting up paths, adding compiled modules, and handling TensorFlow ops if enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\nset(PYTHON_PACKAGE_SRC_DIR \"${PROJECT_SOURCE_DIR}/python\")\nset(PYTHON_PACKAGE_DST_DIR \"${CMAKE_BINARY_DIR}/lib/python_package\")\nmessage(STATUS \"PYPI_PACKAGE_NAME: ${PYPI_PACKAGE_NAME}\")\n\n\n# add the open3d python module first\nset(COMPILED_MODULE_PATH_LIST $<TARGET_FILE:pybind>)\n# add the open3d DSO / DLL if shared\nif (BUILD_SHARED_LIBS)\n    list(APPEND COMPILED_MODULE_PATH_LIST $<TARGET_FILE_DIR:pybind>/${_libopen3d_soname})\nendif()\n\nset(GENERATED_OUTPUTS \"\")\n\n# add additional optional compiled modules\nif (BUILD_TENSORFLOW_OPS)\n    list(APPEND COMPILED_MODULE_PATH_LIST $<TARGET_FILE:open3d_tf_ops> )\n    add_custom_command(OUTPUT \"${CMAKE_BINARY_DIR}/lib/ml/tf/python/ops/ops.py\"\n            COMMAND ${Python3_EXECUTABLE} generate_tf_ops_wrapper.py --input \"${PYTHON_PACKAGE_SRC_DIR}/open3d/ml/tf/python/ops/ops.py.in\" --output \"${CMAKE_BINARY_DIR}/lib/ml/tf/python/ops/ops.py\" --lib $<TARGET_FILE:open3d_tf_ops>\n                        DEPENDS open3d_tf_ops\n                        WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n                        COMMENT \"Generating python ops.py\" )\n\n    list(APPEND GENERATED_OUTPUTS \"${CMAKE_BINARY_DIR}/lib/ml/tf/python/ops/ops.py\")\n    # find tensorflow to get some info for the _build_config.py\n    find_package(Tensorflow)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Displaying Inlier and Outlier Point Clouds - Open3D - Python\nDESCRIPTION: Defines a helper function that displays inliers and outliers of a point cloud using a binary mask, coloring outliers red and inliers gray. Useful for visually assessing the effects of outlier removal. Dependencies: Open3D; inputs: point cloud and mask tensor; outputs: visualization with distinct colors applied to two subsets.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef display_inlier_outlier(cloud : o3d.t.geometry.PointCloud, mask : o3c.Tensor):\\n    inlier_cloud = cloud.select_by_mask(mask)\\n    outlier_cloud = cloud.select_by_mask(mask, invert=True)\\n\\n    print(\"Showing outliers (red) and inliers (gray): \")\\n    outlier_cloud = outlier_cloud.paint_uniform_color([1.0, 0, 0])\\n    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\\n    inlier_cloud = o3d.visualization.draw_geometries([inlier_cloud.to_legacy(), outlier_cloud.to_legacy()],\\n                                      zoom=0.3412,\\n                                      front=[0.4257, -0.2125, -0.8795],\\n                                      lookat=[2.6172, 2.0475, 1.532],\\n                                      up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Adding PointCloud Benchmark Source to Open3D CMake Target\nDESCRIPTION: This CMake snippet adds the PointCloud.cpp file as a source for the 'benchmarks' target in the Open3D project. It uses the target_sources command to specify private sources for the target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/t/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    PointCloud.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Transformation Estimation Method for ICP\nDESCRIPTION: Selects the Point-to-Plane transformation estimation method for ICP registration. This method minimizes the point-to-plane distances between corresponding points and requires the target point cloud to have normal vectors.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_pipelines/t_icp_registration.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\nestimation = treg.TransformationEstimationPointToPlane()\n```\n\n----------------------------------------\n\nTITLE: Conditional TensorFlow and PyTorch Operations Build Configuration in CMake\nDESCRIPTION: Controls the build process for TensorFlow and PyTorch operations in Open3D. Prevents building TensorFlow ops on Windows due to compatibility issues, and conditionally includes subdirectories based on build flags.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nif (BUILD_TENSORFLOW_OPS AND WIN32)\n    message(FATAL_ERROR \"Building TensorFlow ops on Windows is currently not supported.\")\n    # see https://github.com/tensorflow/custom-op/issues/24\nendif()\n\nif (BUILD_TENSORFLOW_OPS)\n    add_subdirectory(tensorflow)\nendif()\n\nif (BUILD_PYTORCH_OPS)\n    add_subdirectory(pytorch)\nendif()\n\nadd_subdirectory(contrib)\n```\n\n----------------------------------------\n\nTITLE: Setting Global Properties and Linking Third-party Libraries\nDESCRIPTION: Applies Open3D warning configuration, global properties, and links third-party libraries to the benchmarks executable.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(benchmarks)\nopen3d_set_global_properties(benchmarks)\nopen3d_link_3rdparty_libraries(benchmarks)\n```\n\n----------------------------------------\n\nTITLE: Building Open3D with SYCL Support from Source (Shell)\nDESCRIPTION: Shell commands to build Open3D with SYCL support from source using Docker.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/sycl.rst#2025-04-23_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncd docker \n./docker_build.sh sycl-shared\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D IO Library Target in CMake\nDESCRIPTION: Sets up the 'io' library target as an object library using ISPC (Intel SPMD Program Compiler) integration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(io OBJECT)\n```\n\n----------------------------------------\n\nTITLE: Configuring ISPC Build Requirements in CMake\nDESCRIPTION: Sets up the initial CMake project configuration for ISPC ISAs with minimum CMake version and language requirements.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cmake/ispc_isas/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ncmake_minimum_required(VERSION 3.19.2)\n\nproject(ispc_isas\n    LANGUAGES C\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for Open3D Pipelines in reStructuredText\nDESCRIPTION: This code snippet defines a table of contents in reStructuredText format for various 3D processing pipelines in Open3D. It includes links to documentation for ICP registration, generalized ICP, robust kernels, colored pointcloud registration, global registration, multiway registration, RGBD integration, RGBD odometry, and color map optimization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/pipelines/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\nPipelines\n=========\n\n.. toctree::\n\n    icp_registration\n    generalized_icp\n    robust_kernels\n    colored_pointcloud_registration\n    global_registration\n    multiway_registration\n    rgbd_integration\n    rgbd_odometry\n    color_map_optimization\n```\n\n----------------------------------------\n\nTITLE: Configuring pybind Target Properties in CMake\nDESCRIPTION: Sets up the source files, include directories, and links libraries for the pybind target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    docstring.cpp\n    open3d_pybind.cpp\n    pybind_utils.cpp\n)\n\n# Include with `#include \"pybind/geometry/xxx.h`\ntarget_include_directories(pybind PRIVATE\n    \"${CMAKE_CURRENT_SOURCE_DIR}/..\"\n)\n\n# Suppress Pybind11 warnings\ntarget_include_directories(pybind SYSTEM PRIVATE\n    ${PYBIND11_INCLUDE_DIR}\n    ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES}\n)\n\nopen3d_show_and_abort_on_warning(pybind)\nopen3d_set_global_properties(pybind)\ntarget_link_libraries(pybind PRIVATE Open3D::Open3D)\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Project Build Targets in CMake\nDESCRIPTION: CMake script that defines the build structure for Open3D. It includes core components unconditionally and conditionally adds test, benchmark and Python binding directories based on build flags.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(open3d)\nadd_subdirectory(tools)\nadd_subdirectory(apps)\nif (BUILD_UNIT_TESTS)\n    add_subdirectory(tests)\nendif()\nif (BUILD_BENCHMARKS)\n    add_subdirectory(benchmarks)\nendif()\nif (BUILD_PYTHON_MODULE)\n    add_subdirectory(pybind)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D with RealSense Support via pip (Python)\nDESCRIPTION: Demonstrates how to install Open3D with RealSense support using pip in a Python environment.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install open3d\n```\n\n----------------------------------------\n\nTITLE: Setting C++11 ABI Compatibility in CMake\nDESCRIPTION: Conditionally adds compile definitions to enable or disable the C++11 ABI based on the GLIBCXX_USE_CXX11_ABI flag, ensuring correct binary compatibility.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/benchmark/MakeAvailable/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif(GLIBCXX_USE_CXX11_ABI)\n    add_compile_definitions(_GLIBCXX_USE_CXX11_ABI=1)\nelse()\n    add_compile_definitions(_GLIBCXX_USE_CXX11_ABI=0)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA-Specific Implementation Files for GPU Acceleration\nDESCRIPTION: Conditionally adds CUDA-specific source files when CUDA module is enabled, including CUDA memory manager, hashmap backends, kernel operations, and linear algebra functions for GPU acceleration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/core/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    target_sources(core PRIVATE\n        MemoryManagerCUDA.cpp\n    )\n    target_sources(core_impl PRIVATE\n        hashmap/CUDA/CreateCUDAHashBackend.cu\n        hashmap/CUDA/CUDAHashBackendBuffer.cu\n        hashmap/CUDA/SlabNodeManager.cu\n        kernel/ArangeCUDA.cu\n        kernel/BinaryEWCUDA.cu\n        kernel/IndexGetSetCUDA.cu\n        kernel/IndexReductionCUDA.cu\n        kernel/NonZeroCUDA.cu\n        kernel/ReductionCUDA.cu\n        kernel/UnaryEWCUDA.cu\n        linalg/AddMMCUDA.cpp\n        linalg/InverseCUDA.cpp\n        linalg/LeastSquaresCUDA.cpp\n        linalg/LinalgUtils.cpp\n        linalg/LUCUDA.cpp\n        linalg/MatmulCUDA.cpp\n        linalg/SolveCUDA.cpp\n        linalg/SVDCUDA.cpp\n        linalg/TriCUDA.cu\n        nns/FixedRadiusSearchOps.cu\n        nns/kernel/BlockSelectFloat32.cu\n        nns/kernel/BlockSelectFloat64.cu\n        nns/KnnSearchOps.cu\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Registration Benchmark Sources in CMake\nDESCRIPTION: Adds the Registration.cpp source file to the benchmarks target. This file likely contains performance benchmarks for various registration algorithms in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    registration/Registration.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Absolute Translation in Open3D\nDESCRIPTION: Shows how to perform absolute translation by setting relative=False. Moves the mesh center directly to the specified position.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/transformation.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmesh = o3d.geometry.TriangleMesh.create_coordinate_frame()\nmesh_mv = copy.deepcopy(mesh).translate((2, 2, 2), relative=False)\nprint(f'Center of mesh: {mesh.get_center()}')\nprint(f'Center of translated mesh: {mesh_mv.get_center()}')\no3d.visualization.draw_geometries([mesh, mesh_mv])\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Utility Library Build\nDESCRIPTION: CMake configuration that defines the utility library build target with its source files and dependencies. Includes conditional compilation of ISPC modules and sets up library properties and third-party linkage.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/utility/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nopen3d_ispc_add_library(utility OBJECT)\n\ntarget_sources(utility PRIVATE\n    CompilerInfo.cpp\n    Console.cpp\n    CPUInfo.cpp\n    Download.cpp\n    Eigen.cpp\n    Extract.cpp\n    ExtractZIP.cpp\n    FileSystem.cpp\n    Helper.cpp\n    IJsonConvertible.cpp\n    ISAInfo.cpp\n    Logging.cpp\n    Parallel.cpp\n    ProgressBar.cpp\n    Random.cpp\n    Timer.cpp\n)\n\nif (BUILD_ISPC_MODULE)\n    target_sources(utility PRIVATE\n        ISAInfo.ispc\n    )\nendif()\n\nopen3d_show_and_abort_on_warning(utility)\nopen3d_set_global_properties(utility)\nopen3d_set_open3d_lib_properties(utility)\nopen3d_link_3rdparty_libraries(utility)\n```\n\n----------------------------------------\n\nTITLE: CMake External Project Patch Configuration\nDESCRIPTION: CMake configuration for applying patches to external projects using ExternalProject_Add.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README.md#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nfind_package(Git QUIET REQUIRED)\n\nExternalProject_Add(\n    ...\n    PATCH_COMMAND ${GIT_EXECUTABLE} init\n    COMMAND       ${GIT_EXECUTABLE} apply --ignore-space-change --ignore-whitespace\n                  /path/to/0001-Patch-Assimp-Obj-importer.patch\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Pytest with pip - Bash\nDESCRIPTION: This Bash snippet installs the pytest framework using the pip package manager. It assumes Python and pip are already installed on the system. The command downloads and sets up pytest in the current Python environment, making it available for testing Python code.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/test/readme.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install pytest\n```\n\n----------------------------------------\n\nTITLE: Including CUDA Toolkit Headers for GPU Support in Open3D\nDESCRIPTION: Conditionally adds CUDA toolkit include directories to the build configuration when BUILD_CUDA_MODULE is enabled. This ensures that CUDA headers are available during compilation of GPU-accelerated code.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/kernel/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif(BUILD_CUDA_MODULE)\n    target_include_directories(tpipelines_kernel SYSTEM PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Exporting GUI Resource Information to Parent Scope\nDESCRIPTION: Exports resource file paths and the resource directory to the parent CMake scope. This allows other parts of the build system to access GUI resources and material files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/gui/CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\n# Export GUI_RESOURCE_FILES to parent CMake context (cpp/open3d/)\nset(GUI_RESOURCE_FILES\n    ${GUI_RESOURCE_SOURCE_FILES} ${GUI_MATERIAL_COMPILED_FILES}\n    PARENT_SCOPE)\nset(GUI_RESOURCE_DIR ${GUI_RESOURCE_DIR} PARENT_SCOPE)\n```\n\n----------------------------------------\n\nTITLE: Compiling Material Files for Open3D GUI\nDESCRIPTION: Compiles material files used by the renderer in the Open3D GUI. This uses a custom CMake function to process material files for different rendering scenarios like default lighting, transparency, and specialized rendering modes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/gui/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\ninclude(Open3DAddCompiledMaterials)\n\nopen3d_add_compiled_materials(materials\n    OUTPUT_DIRECTORY\n    ${GUI_RESOURCE_DIR}\n    SOURCES\n    Materials/colorMap.mat\n    Materials/defaultLit.mat\n    Materials/defaultLitSSR.mat\n    Materials/defaultLitTransparency.mat\n    Materials/defaultUnlit.mat\n    Materials/defaultUnlitTransparency.mat\n    Materials/depth_value.mat\n    Materials/depth.mat\n    Materials/img_blit.mat\n    Materials/infiniteGroundPlane.mat\n    Materials/normals.mat\n    Materials/pointcloud.mat\n    Materials/gaussianSplat.mat\n    Materials/ui_blit.mat\n    Materials/unlitBackground.mat\n    Materials/unlitGradient.mat\n    Materials/unlitLine.mat\n    Materials/unlitPolygonOffset.mat\n    Materials/unlitSolidColor.mat\n)\n```\n\n----------------------------------------\n\nTITLE: Detecting ARM Architecture on Linux and macOS\nDESCRIPTION: Detects if the system is running on ARM architecture (aarch64) for Linux and macOS platforms, setting appropriate variables and OS deployment targets.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nif(UNIX AND NOT APPLE)\n    execute_process(COMMAND uname -m\n        OUTPUT_VARIABLE PROCESSOR_ARCH\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    if(PROCESSOR_ARCH STREQUAL \"aarch64\")\n        set(LINUX_AARCH64 TRUE)\n    endif()\nendif()\nif(APPLE)\n    execute_process(COMMAND uname -m\n        OUTPUT_VARIABLE PROCESSOR_ARCH\n        OUTPUT_STRIP_TRAILING_WHITESPACE\n    )\n    if(PROCESSOR_ARCH STREQUAL \"arm64\")\n        set(APPLE_AARCH64 TRUE)\n        set (CMAKE_OSX_DEPLOYMENT_TARGET \"11.0\" CACHE STRING\n            \"Minimum OS X deployment version\" FORCE)\n    else()\n        set (CMAKE_OSX_DEPLOYMENT_TARGET \"10.15\" CACHE STRING\n            \"Minimum OS X deployment version\" FORCE)\n    endif()\nendif()\n```\n\n----------------------------------------\n\nTITLE: Conditional ISPC Module Source Addition in CMake\nDESCRIPTION: Conditionally adds ISPC (Intel SPMD Program Compiler) source files to the benchmarks target when the BUILD_ISPC_MODULE option is enabled. This allows for specialized SIMD-optimized implementations for certain benchmarks.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/core/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_ISPC_MODULE)\n    target_sources(benchmarks PRIVATE\n        ParallelFor.ispc\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring tpipelines_kernel Library with CPU Source Files in Open3D\nDESCRIPTION: Initializes the tpipelines_kernel object library and adds the core CPU-based source files for registration, linear system, odometry, transformation, and feature implementations. These files form the foundation of the pipeline processing capabilities.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/kernel/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(tpipelines_kernel OBJECT)\n\ntarget_sources(tpipelines_kernel PRIVATE\n    Registration.cpp\n    RegistrationCPU.cpp\n    FillInLinearSystem.cpp\n    FillInLinearSystemCPU.cpp\n    RGBDOdometry.cpp\n    RGBDOdometryCPU.cpp\n    TransformationConverter.cpp\n    Feature.cpp\n    FeatureCPU.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding ManuallyAlignPointCloud Subdirectory in CMake\nDESCRIPTION: Adds the ManuallyAlignPointCloud subdirectory to the CMake build process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tools/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\nadd_subdirectory(ManuallyAlignPointCloud)\n```\n\n----------------------------------------\n\nTITLE: Loading Armadillo Mesh Dataset in Python\nDESCRIPTION: Demonstrates how to load the Stanford Armadillo mesh dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.ArmadilloMesh()\nmesh = o3d.io.read_triangle_mesh(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project for Open3D Usage\nDESCRIPTION: Sets up a CMake project that uses Open3D, including version requirements, project configuration, and Windows runtime options. It finds the Open3D package and configures an executable target linked against Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-find-package/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\n# On Ubuntu 20.04, get the latest CMake from https://apt.kitware.com/.\ncmake_minimum_required(VERSION 3.24)\n\nproject(Open3DCMakeFindPackage LANGUAGES C CXX)\n\n# The options need to be the same as Open3D's default\n# If Open3D is configured and built with custom options, you'll also need to\n# specify the same custom options.\noption(STATIC_WINDOWS_RUNTIME \"Use static (MT/MTd) Windows runtime\" ON)\nif(STATIC_WINDOWS_RUNTIME)\n    set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>\")\nelse()\n    set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>DLL\")\nendif()\n\n# Find installed Open3D, which exports Open3D::Open3D\nfind_package(Open3D REQUIRED)\n\nadd_executable(Draw)\ntarget_sources(Draw PRIVATE Draw.cpp)\ntarget_link_libraries(Draw PRIVATE Open3D::Open3D)\n```\n\n----------------------------------------\n\nTITLE: Adding File Format Handler Test Sources in CMake\nDESCRIPTION: Includes test source files for various file format handlers supporting different 3D data formats like BIN, GLTF, JPG, JSON, LOG, PCD, PLY, PNG, PTS, STL, and XYZ variants.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/io/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    file_format/FileBIN.cpp\n    file_format/FileGLTF.cpp\n    file_format/FileJPG.cpp\n    file_format/FileJSON.cpp\n    file_format/FileLOG.cpp\n    file_format/FilePCD.cpp\n    file_format/FilePLY.cpp\n    file_format/FilePNG.cpp\n    file_format/FilePTS.cpp\n    file_format/FileSTL.cpp\n    file_format/FileXYZ.cpp\n    file_format/FileXYZN.cpp\n    file_format/FileXYZRGB.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Open3D Benchmarks Executable with ISPC\nDESCRIPTION: Initializes the benchmarks executable using the Open3D ISPC custom command.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_executable(benchmarks)\n```\n\n----------------------------------------\n\nTITLE: Adding Registration Source Files to tpipelines\nDESCRIPTION: Adds registration-related source files to the tpipelines target, including Registration.cpp, TransformationEstimation.cpp, and Feature.cpp.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tpipelines PRIVATE\n    registration/Registration.cpp\n    registration/TransformationEstimation.cpp\n    registration/Feature.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Platform-Specific Settings in CMake\nDESCRIPTION: Sets platform-specific compiler and linker options for Windows, MSVC, and Linux platforms. It handles symbol visibility, runtime library linking, and compiler optimizations for different build environments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_26\n\nLANGUAGE: CMake\nCODE:\n```\n# OS specific settings\nif(WIN32)\n    # Windows defaults to hidden symbol visibility, override that\n    # TODO: It would be better to explicitly export symbols.\n    #       Then, we could use -fvisibility=hidden for Linux as well\n    SET(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON)\n    if(MSVC)\n        # MSVC standards-compliant mode: Error in PoissonRecon 3rd party header\n        # add_compile_options($<$<COMPILE_LANGUAGE:CXX>:\"/permissive-\">)   \n        # Make sure we don't hit the 65535 object member limit with MSVC\n        #\n        # /bigobj allows object files with more than 65535 members\n        # /Ob2 enables function inlining, because MSVC is particularly\n        # verbose with inline members\n        #\n        # See: https://github.com/tensorflow/tensorflow/pull/10962\n        add_compile_options(\"$<$<COMPILE_LANGUAGE:CXX>:/bigobj;/Ob2>\")\n    endif()\n    if (STATIC_WINDOWS_RUNTIME)\n        set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>\")\n    else()\n        set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>DLL\")\n    endif()\nendif()\n\n# Folder view for project files\nset_property(GLOBAL PROPERTY USE_FOLDERS ON)\n\nif (LINUX_AARCH64)\n# Fix for ImportError: ... /pybind.cpython-310-aarch64-linux-gnu.so: cannot allocate memory in static TLS block\n# https://bugs.launchpad.net/ubuntu/+source/mysql-8.0/+bug/1889851\n    add_compile_options(\"-ftls-model=global-dynamic\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding Machine Learning Source to Open3D Python Bindings\nDESCRIPTION: This CMake snippet adds the machine learning source file to the pybind target in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/ml/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    ml.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Defining and Configuring ml_contrib Library in CMake\nDESCRIPTION: Creates an OBJECT library named ml_contrib and sets its source files. Conditionally adds CUDA sources if BUILD_CUDA_MODULE is enabled. Applies Open3D-specific build properties and links third-party libraries.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/contrib/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_library(ml_contrib OBJECT)\n\ntarget_sources(ml_contrib PRIVATE\n    Cloud.cpp\n    GridSubsampling.cpp\n    IoU.cpp\n)\n\nif(BUILD_CUDA_MODULE)\n    target_sources(ml_contrib PRIVATE\n        IoU.cu\n    )\nendif()\n\nopen3d_show_and_abort_on_warning(ml_contrib)\nopen3d_set_global_properties(ml_contrib)\nopen3d_set_open3d_lib_properties(ml_contrib)\nopen3d_link_3rdparty_libraries(ml_contrib)\n\nif(BUILD_CUDA_MODULE)\n    target_include_directories(ml_contrib SYSTEM PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\nendif()\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Open3D C++ API\nDESCRIPTION: ReStructuredText markup defining the documentation structure and links for Open3D C++ API documentation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/cpp_api.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. _cpp_api:\n\nC++ documentation\n=================\n\nPlease refer to the following pages for Open3D C++ API.\n\n- Full C++ API documentation: `Open3D C++ Doxygen documentation <./cpp_api/index.html>`_\n- Linking Open3D to your C++ projects: :ref:`cplusplus_example_project`\n- Compiling Open3D from source: :ref:`compilation`\n```\n\n----------------------------------------\n\nTITLE: Initializing Open3D TIO Library in CMake\nDESCRIPTION: Sets up the TIO library as an OBJECT library and adds core source files for image, numpy, hashmap, point cloud, and triangle mesh IO operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(tio OBJECT)\n\ntarget_sources(tio PRIVATE\n    ImageIO.cpp\n    NumpyIO.cpp\n    HashMapIO.cpp\n    PointCloudIO.cpp\n    TriangleMeshIO.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Dataset.cpp to Open3D Test Sources in CMake\nDESCRIPTION: This CMake snippet adds the Dataset.cpp file to the 'tests' target as a private source. It is likely part of a larger CMakeLists.txt file for configuring the Open3D project's test suite.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/data/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    Dataset.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Platform-Specific Source Files in CMake\nDESCRIPTION: Conditionally adds platform-specific source files to the GUI target based on the target platform (Windows, macOS, or Linux). Each platform has its own native implementation files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/gui/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif (WIN32)\n    target_sources(GUI PRIVATE\n        NativeWin32.cpp\n    )\nelseif (APPLE)\n    target_sources(GUI PRIVATE\n        NativeMacOS.mm\n        MenuMacOS.mm\n    )\nelse()\n    target_sources(GUI PRIVATE\n        NativeLinux.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Iterative Build for Open3D Examples in CMake\nDESCRIPTION: This snippet sets up a custom target for building Open3D examples iteratively, which is useful for conserving space on CI machines. It uses a separate CMake script for the build process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cpp/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ninclude(ProcessorCount)\nProcessorCount(NPROC)\n\nadd_custom_target(build-examples-iteratively\n    COMMAND ${CMAKE_COMMAND}\n    -DEXAMPLE_TARGETS=\"${EXAMPLE_TARGETS}\"\n    -DCMAKE_BINARY_DIR=\"${CMAKE_BINARY_DIR}\"\n    -DEXAMPLE_BIN_DIR=\"${EXAMPLE_BIN_DIR}\"\n    -DCMAKE_BUILD_TYPE=\"$<CONFIG>\"\n    -DNPROC=\"${NPROC}\"\n    -P ${CMAKE_CURRENT_SOURCE_DIR}/iterative_build_examples.cmake\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Odometry Module Sources\nDESCRIPTION: Includes odometry-related source files for Python binding compilation\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/pipelines/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    odometry/odometry.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Enabling Position Independent Code and Threading Preferences - CMake - CMake\nDESCRIPTION: This snippet sets global security and compatibility flags by enabling position independent code for all targets and preferring the -pthread linker flag (important for CUDA/Threads interaction). It also overrides threading options in module imports where required. The macro open3d_patch_findthreads_module_ ensures the correct threading flags are used by targets, handling CUDA, ISPC, and standard C++ cases. This is essential for portable threading configuration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_23\n\nLANGUAGE: CMake\nCODE:\n```\n# Global Security options (including 3rd party code)\n# Add -fPIC for library and -fPIE for executable to compiler and linker. Does not add -pie !\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\n# Explicitly specify the preference of using -pthread over -lpthread.\n# This must be defined here since CUDA calls find_package(Threads) internally.\nset(THREADS_PREFER_PTHREAD_FLAG TRUE)\n\n# Overwrites property for Thread::Threads in find_package(Threads)\n# For CUDA, \"-pthread\" is replaced with \"-Xcompiler -pthread\" (CMake's default)\n# For ISPC, \"-pthread\" is disabled\nmacro(open3d_patch_findthreads_module_)\n    if(TARGET Threads::Threads AND THREADS_HAVE_PTHREAD_ARG)\n        set_property(TARGET Threads::Threads\n                     PROPERTY INTERFACE_COMPILE_OPTIONS\n                     \"$<$<COMPILE_LANG_AND_ID:CUDA,NVIDIA>:SHELL:-Xcompiler -pthread>\"\n                     \"$<$<AND:$<NOT:$<COMPILE_LANG_AND_ID:CUDA,NVIDIA>>,$<NOT:$<COMPILE_LANGUAGE:ISPC>>>:-pthread>\")\n    endif()\nendmacro()\ncmake_language(EVAL CODE \"cmake_language(DEFER CALL open3d_patch_findthreads_module_)\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Test Executable in CMake\nDESCRIPTION: This snippet sets up the main 'tests' executable for Open3D, including subdirectories, source files, and include directories. It also handles conditional compilation for GPU and IPP tests based on build configuration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_executable(tests)\n\nadd_subdirectory(camera)\nadd_subdirectory(core)\nadd_subdirectory(data)\nadd_subdirectory(geometry)\nadd_subdirectory(io)\nadd_subdirectory(ml)\nadd_subdirectory(pipelines)\nadd_subdirectory(t/geometry)\nadd_subdirectory(t/io)\nadd_subdirectory(t/pipelines)\nadd_subdirectory(test_utility)\nadd_subdirectory(utility)\nadd_subdirectory(visualization)\n\ntarget_sources(tests PRIVATE\n    Main.cpp\n    Tests.cpp\n)\n\ntarget_include_directories(tests PRIVATE \".\")\n\n# If gpu not available, add \"DISABLED_\" to the gpu test names\nif (BUILD_CUDA_MODULE)\n    target_compile_definitions(tests PRIVATE GPU_CONDITIONAL_TEST_STR=) # Empty string\nelse()\n    target_compile_definitions(tests PRIVATE GPU_CONDITIONAL_TEST_STR=DISABLED_)\nendif()\n\nif (WITH_IPP)\n    target_compile_definitions(tests PRIVATE IPP_CONDITIONAL_TEST_STR=) # Empty string (test not disabled)\nelse()\n    target_compile_definitions(tests PRIVATE IPP_CONDITIONAL_TEST_STR=DISABLED_)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Including C++ Subdirectory in Open3D CMake Build\nDESCRIPTION: This CMake command adds the 'cpp' subdirectory to the build process, indicating that the C++ source code for the Open3D project is located in this directory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(cpp)\n```\n\n----------------------------------------\n\nTITLE: Adding Open3D Examples in CMake\nDESCRIPTION: This section adds various Open3D examples as targets using the previously defined macro. It includes conditional additions based on available modules and dependencies.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cpp/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_add_example(CameraPoseTrajectory)\nopen3d_add_example(ColorMapOptimization)\nopen3d_add_example(DepthCapture)\nopen3d_add_example(EvaluatePCDMatch)\nopen3d_add_example(FileDialog                Open3D::3rdparty_tinyfiledialogs)\nopen3d_add_example(FileSystem)\nopen3d_add_example(Flann)\nopen3d_add_example(Image)\nopen3d_add_example(IntegrateRGBD)\nopen3d_add_example(ISSKeypoints)\nopen3d_add_example(PlanarPatchDetection   ${OPENMP_TARGET})\nopen3d_add_example(LineSet)\nopen3d_add_example(Log)\nopen3d_add_example(Octree)\nopen3d_add_example(OdometryRGBD)\nif (TARGET Open3D::3rdparty_openmp)\n    open3d_add_example(OpenMP                    Open3D::3rdparty_openmp)\nelse()\n    open3d_add_example(OpenMP)\nendif()\n# ... (more examples)\n```\n\n----------------------------------------\n\nTITLE: Adding Miscellaneous Operation Source Files\nDESCRIPTION: Adds various miscellaneous operations such as spatial hash table building, search operations, voxel operations, and reduction operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(open3d_tf_ops PRIVATE\n    misc/BuildSpatialHashTableOpKernel.cpp\n    misc/BuildSpatialHashTableOps.cpp\n    misc/FixedRadiusSearchOpKernel.cpp\n    misc/FixedRadiusSearchOps.cpp\n    misc/InvertNeighborsListOpKernel.cpp\n    misc/InvertNeighborsListOps.cpp\n    misc/KnnSearchOpKernel.cpp\n    misc/KnnSearchOps.cpp\n    misc/NmsOpKernel.cpp\n    misc/NmsOps.cpp\n    misc/RadiusSearchOpKernel.cpp\n    misc/RadiusSearchOps.cpp\n    misc/ReduceSubarraysSumOpKernel.cpp\n    misc/ReduceSubarraysSumOps.cpp\n    misc/VoxelizeOpKernel.cpp\n    misc/VoxelizeOps.cpp\n    misc/VoxelPoolingGradOpKernel.cpp\n    misc/VoxelPoolingOpKernel.cpp\n    misc/VoxelPoolingOps.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Target Sources Configuration\nDESCRIPTION: Configures source files for continuous convolution, sparse convolution, misc operations, and other PyTorch operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/pytorch/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(open3d_torch_ops PRIVATE\n    continuous_conv/ContinuousConvBackpropFilterOpKernel.cpp\n    continuous_conv/ContinuousConvOpKernel.cpp\n    continuous_conv/ContinuousConvOps.cpp\n    continuous_conv/ContinuousConvTransposeBackpropFilterOpKernel.cpp\n    continuous_conv/ContinuousConvTransposeOpKernel.cpp\n    continuous_conv/ContinuousConvTransposeOps.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Source Groups for Project Organization in CMake\nDESCRIPTION: Defines a macro for organizing source files into groups for better IDE project organization. It groups header files, source files, ISPC files, shaders, and material files into separate folders.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_27\n\nLANGUAGE: CMake\nCODE:\n```\nmacro(add_source_group module_name)\n    file(GLOB MODULE_HEADER_FILES \"${module_name}/*.h\")\n    source_group(\"Header Files\\\\${module_name}\" FILES ${MODULE_HEADER_FILES})\n    file(GLOB MODULE_SOURCE_FILES \"${module_name}/*.cpp\")\n    source_group(\"Source Files\\\\${module_name}\" FILES ${MODULE_SOURCE_FILES})\n    file(GLOB MODULE_ISPC_HEADER_FILES \"${module_name}/*.isph\")\n    source_group(\"Header Files\\\\ISPC\" FILES ${MODULE_ISPC_HEADER_FILES})\n    file(GLOB MODULE_ISPC_SOURCE_FILES \"${module_name}/*.ispc\")\n    source_group(\"Source Files\\\\ISPC\" FILES ${MODULE_ISPC_SOURCE_FILES})\n    file(GLOB MODULE_SHADER_FILES \"${module_name}/*.glsl\")\n    source_group(\"Source Files\\\\Shader\\\\GLSL\" FILES ${MODULE_SHADER_FILES})\n    file(GLOB MODULE_MATERIAL_FILES \"${module_name}/*.mat\")\n    source_group(\"Source Files\\\\Material\" FILES ${MODULE_MATERIAL_FILES})\nendmacro()\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Output Directories - CMake - CMake\nDESCRIPTION: This snippet assigns output directories for archives, libraries, and executables, using $<CONFIG> generator expressions to ensure build outputs are consistently routed (especially for IDEs). This helps in predictable build artifact organization across different configurations (Debug, Release, etc). No inputs required except the PROJECT_BINARY_DIR variable.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_22\n\nLANGUAGE: CMake\nCODE:\n```\n# Put build results in some predictable places\n# The $<CONFIG> generator expression makes sure that XCode or Visual Studio do not\n# append additional path components, as we need to know *exactly* where the build results\n# end up.\nset(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/lib/$<CONFIG>)\nset(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/lib/$<CONFIG>)\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/bin)\n```\n\n----------------------------------------\n\nTITLE: Adding Source Files to Python Bindings Target in CMake\nDESCRIPTION: This CMake directive adds the file t.cpp to the 'pybind' target for compilation. It's specifying files to be included in the Python bindings build for Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    t.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Library Properties and Dependencies for Open3D Core Libraries\nDESCRIPTION: Applies common properties, warnings, and third-party library dependencies to the core and core_impl libraries. Conditionally adds CUDA toolkit include directories when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/core/CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(core)\nopen3d_set_global_properties(core)\nopen3d_set_open3d_lib_properties(core)\nopen3d_link_3rdparty_libraries(core)\n\nopen3d_show_and_abort_on_warning(core_impl)\nopen3d_set_global_properties(core_impl)\nopen3d_set_open3d_lib_properties(core_impl)\nopen3d_link_3rdparty_libraries(core_impl)\n\nif(BUILD_CUDA_MODULE)\n    target_include_directories(core SYSTEM PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\n    target_include_directories(core_impl SYSTEM PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\nendif()\n```\n\n----------------------------------------\n\nTITLE: Setting Values in Tensors using Indexing\nDESCRIPTION: Shows how to modify tensor values using indexing and slicing operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/core/tensor.ipynb#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nvals = np.array(range(24)).reshape((2, 3, 4))\na = o3c.Tensor(vals)\n\n# Example __setitem__\na[:, :, 2] += 100\nprint(a)\n```\n\n----------------------------------------\n\nTITLE: Configuring WebRTC Server Properties and Dependencies\nDESCRIPTION: Sets global properties, library properties, and links third-party libraries for the WebRTC server component using Open3D's custom CMake functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/webrtc_server/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(webrtc_server)\nopen3d_set_global_properties(webrtc_server)\nopen3d_set_open3d_lib_properties(webrtc_server)\nopen3d_link_3rdparty_libraries(webrtc_server)\n```\n\n----------------------------------------\n\nTITLE: Checking Python 3 Availability in CMake\nDESCRIPTION: Verifies if Python 3 is found and sets the Python version variable for configuration purposes.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nif (NOT Python3_EXECUTABLE)\n    message(FATAL_ERROR \"Python 3 not found in top level file\")\nendif()\n\n# We need to get python version to configure some meta files\nset(PYTHON_VERSION \"${Python3_VERSION_MAJOR}.${Python3_VERSION_MINOR}\")\n```\n\n----------------------------------------\n\nTITLE: Setting CMake Policy for Downloaded Content\nDESCRIPTION: Sets CMake policy CMP0135 to NEW, which makes URL content in ExternalProject_Add to be timestamped by download time rather than by ETag or actual content.\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_9\n\nLANGUAGE: CMake\nCODE:\n```\nif(POLICY CMP0135)\n    cmake_policy(SET CMP0135 NEW)  # URL contents timestamped by download time\nendif()\n```\n\n----------------------------------------\n\nTITLE: Conditional ISPC Module Test Sources in CMake for Open3D\nDESCRIPTION: This snippet conditionally adds ISPC-specific test sources when the ISPC module is enabled. It includes ISPC versions of Indexer and ParallelFor tests.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/core/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_ISPC_MODULE)\n    target_sources(tests PRIVATE\n        Indexer.ispc\n        ParallelFor.ispc\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring Third-Party Library Options\nDESCRIPTION: Sets options for using system-installed libraries versus building from source. Different defaults are set for linear algebra libraries on ARM platforms (BLAS vs MKL).\nSOURCE: https://github.com/isl-org/open3d/blob/main/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\nif(LINUX_AARCH64 OR APPLE_AARCH64)\n    option(USE_BLAS               \"Use BLAS/LAPACK instead of MKL\"           ON )\nelse()\n    option(USE_BLAS               \"Use BLAS/LAPACK instead of MKL\"           OFF)\nendif()\nif(USE_BLAS)\n    option(USE_SYSTEM_BLAS        \"Use system pre-installed openblas\"        OFF)\nelse()\n    option(USE_SYSTEM_BLAS        \"Use system pre-installed openblas\"        ON )\nendif()\noption(USE_SYSTEM_ASSIMP          \"Use system pre-installed assimp\"          OFF)\noption(USE_SYSTEM_CURL            \"Use system pre-installed curl\"            OFF)\noption(USE_SYSTEM_CUTLASS         \"Use system pre-installed cutlass\"         OFF)\noption(USE_SYSTEM_EIGEN3          \"Use system pre-installed eigen3\"          OFF)\noption(USE_SYSTEM_EMBREE          \"Use system pre-installed Embree\"          OFF)\noption(USE_SYSTEM_FILAMENT        \"Use system pre-installed filament\"        OFF)\noption(USE_SYSTEM_FMT             \"Use system pre-installed fmt\"             OFF)\noption(USE_SYSTEM_GLEW            \"Use system pre-installed glew\"            OFF)\noption(USE_SYSTEM_GLFW            \"Use system pre-installed glfw\"            OFF)\noption(USE_SYSTEM_GOOGLETEST      \"Use system pre-installed Googletest\"      OFF)\noption(USE_SYSTEM_IMGUI           \"Use system pre-installed imgui\"           OFF)\noption(USE_SYSTEM_JPEG            \"Use system pre-installed jpeg\"            OFF)\noption(USE_SYSTEM_JSONCPP         \"Use system pre-installed jsoncpp\"         OFF)\noption(USE_SYSTEM_LIBLZF          \"Use system pre-installed liblzf\"          OFF)\noption(USE_SYSTEM_MSGPACK         \"Use system pre-installed msgpack\"         OFF)\noption(USE_SYSTEM_NANOFLANN       \"Use system pre-installed nanoflann\"       OFF)\noption(USE_SYSTEM_OPENSSL         \"Use system pre-installed OpenSSL\"         OFF)\noption(USE_SYSTEM_PNG             \"Use system pre-installed png\"             OFF)\noption(USE_SYSTEM_PYBIND11        \"Use system pre-installed pybind11\"        OFF)\noption(USE_SYSTEM_QHULLCPP        \"Use system pre-installed qhullcpp\"        OFF)\noption(USE_SYSTEM_STDGPU          \"Use system pre-installed stdgpu\"          OFF)\noption(USE_SYSTEM_TBB             \"Use system pre-installed TBB\"             OFF)\noption(USE_SYSTEM_TINYGLTF        \"Use system pre-installed tinygltf\"        OFF)\noption(USE_SYSTEM_TINYOBJLOADER   \"Use system pre-installed tinyobjloader\"   OFF)\noption(USE_SYSTEM_VTK             \"Use system pre-installed VTK\"             OFF)\noption(USE_SYSTEM_ZEROMQ          \"Use system pre-installed ZeroMQ\"          OFF)\n```\n\n----------------------------------------\n\nTITLE: Specifying DPC++ Compiler Runtime Version for Open3D\nDESCRIPTION: This line specifies the required version of the Intel oneAPI DPC++ Compiler Runtime for the Open3D project. It indicates that version 2024.1.0 of the dpcpp-cpp-rt package is needed.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_sycl.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ndpcpp-cpp-rt==2024.1.0\n```\n\n----------------------------------------\n\nTITLE: Creating pybind11 Module and Adding Subdirectories in CMake\nDESCRIPTION: Sets up the pybind11 module and adds various subdirectories for the Open3D project components.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\npybind11_add_module(pybind)\n\nadd_subdirectory(camera)\nadd_subdirectory(core)\nadd_subdirectory(data)\nadd_subdirectory(geometry)\nadd_subdirectory(io)\nadd_subdirectory(ml)\nadd_subdirectory(pipelines)\nadd_subdirectory(t)\nadd_subdirectory(t/geometry)\nadd_subdirectory(t/io)\nadd_subdirectory(t/pipelines)\nadd_subdirectory(utility)\nadd_subdirectory(visualization)\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Source Files for PointNet and PVCNN Operations\nDESCRIPTION: Conditionally adds CUDA implementations of PointNet and PVCNN operations when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_10\n\nLANGUAGE: CMake\nCODE:\n```\n    target_sources(open3d_tf_ops PRIVATE\n        pointnet/BallQueryOpKernel.cu\n        pointnet/InterpolateOpKernel.cu\n        pointnet/RoiPoolOpKernel.cu\n        pointnet/SamplingOpKernel.cu\n        pvcnn/TrilinearDevoxelizeKernel.cu\n    )\n```\n\n----------------------------------------\n\nTITLE: Testing Nvidia Docker Installation\nDESCRIPTION: Command to verify Nvidia Docker setup by running nvidia-smi in a CUDA container.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docker/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm --gpus all nvidia/cuda:12.1-base nvidia-smi\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Test Properties and Windows-Specific Settings in CMake\nDESCRIPTION: This snippet sets global properties for the tests, handles warnings, and adds a Windows-specific post-build step to copy the TBB DLL to the output directory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(tests)\nopen3d_set_global_properties(tests)\n# On Windows, running tests from the build folder needs tbb.dll to be in the same folder.\nif (WIN32)\n  add_custom_command(\n      TARGET tests\n      POST_BUILD\n      COMMAND ${CMAKE_COMMAND} -E copy_if_different $<TARGET_FILE:tbb> \"${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/$<CONFIG>/\"\n  )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Configuring PyTorch Operations in CMake for Open3D\nDESCRIPTION: This snippet adds PyTorch operations to the Open3D build if enabled. It generates Python wrapper files for PyTorch ops and adds them to the build outputs.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_7\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_PYTORCH_OPS)\n    list( APPEND COMPILED_MODULE_PATH_LIST $<TARGET_FILE:open3d_torch_ops> )\n    add_custom_command( OUTPUT \"${CMAKE_BINARY_DIR}/lib/ml/torch/python/ops.py\" \"${CMAKE_BINARY_DIR}/lib/ml/torch/python/return_types.py\"\n            COMMAND ${Python3_EXECUTABLE} generate_torch_ops_wrapper.py --input_ops_py_in \"${PYTHON_PACKAGE_SRC_DIR}/open3d/ml/torch/python/ops.py.in\" --input_return_types_py_in \"${PYTHON_PACKAGE_SRC_DIR}/open3d/ml/torch/python/return_types.py.in\" --output_dir \"${CMAKE_BINARY_DIR}/lib/ml/torch/python/\" --lib $<TARGET_FILE:open3d_torch_ops> --tensorflow_ops_dir \"${CMAKE_CURRENT_SOURCE_DIR}/../open3d/ml/tensorflow\"\n                        DEPENDS open3d_torch_ops\n                        WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n                        COMMENT \"Generating python ops.py and return_types.py\" )\n\n    list(APPEND GENERATED_OUTPUTS \"${CMAKE_BINARY_DIR}/lib/ml/torch/python/ops.py\" \"${CMAKE_BINARY_DIR}/lib/ml/torch/python/return_types.py\")\n    # get the pytorch version information again here for _build_config.py\n    # because it is not safe to call find_package(Pytorch) again.\n    execute_process(\n        COMMAND ${Python3_EXECUTABLE} \"-c\"\n                \"import torch; print(torch.__version__, end='')\"\n        OUTPUT_VARIABLE Pytorch_VERSION)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Source Files for Sparse Convolution Operations\nDESCRIPTION: Conditionally adds CUDA implementations of sparse convolution operations when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\n    target_sources(open3d_tf_ops PRIVATE\n        sparse_conv/SparseConvBackpropFilterOpKernel.cu\n        sparse_conv/SparseConvOpKernel.cu\n        sparse_conv/SparseConvTransposeBackpropFilterOpKernel.cu\n        sparse_conv/SparseConvTransposeOpKernel.cu\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Additional Libraries for Python Package in CMake\nDESCRIPTION: Sets up additional libraries to be included in the Python package, handling platform-specific cases for shared libraries and OpenMP.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_SHARED_LIBS)\n    if (WIN32)    # CMake does not add soversion suffix to WIN32 DLLs\n        set(_libopen3d_soname \"Open3D.dll\")\n    elseif(APPLE)\n        set(_libopen3d_soname \"libOpen3D.${OPEN3D_ABI_VERSION}.dylib\")\n    else()\n        set(_libopen3d_soname \"libOpen3D.so.${OPEN3D_ABI_VERSION}\")\n    endif()\n    add_custom_command(TARGET pybind POST_BUILD\n        COMMAND ${CMAKE_COMMAND} -E copy_if_different\n            $<TARGET_FILE:Open3D> $<TARGET_FILE_DIR:pybind>/${_libopen3d_soname}\n    )\nendif()\n# Include additional libraries that may be absent from the user system\n# eg: libc++.so, libc++abi.so (needed by filament) for Linux.\n# libc++.so is a linker script including libc++.so.1 and libc++abi.so, so append 1 to libc++.so\nset(PYTHON_EXTRA_LIBRARIES $<TARGET_FILE:TBB::tbb>)\nif (BUILD_GUI AND CMAKE_SYSTEM_NAME STREQUAL \"Linux\")\n    list(APPEND PYTHON_EXTRA_LIBRARIES ${CPP_LIBRARY}.1 ${CPPABI_LIBRARY})\nendif()\nif (WITH_OPENMP AND APPLE AND NOT BUILD_SHARED_LIBS)\n# Package libomp v11.1.0, if it is not installed. Later version cause crash on\n# x86_64 if PyTorch is already imported. Case of shared libopen3d.dylib is not\n# handled.\n# https://github.com/microsoft/LightGBM/issues/4229\n    list(APPEND PYTHON_EXTRA_LIBRARIES ${OpenMP_libomp_LIBRARY})\n    execute_process(COMMAND brew list --versions libomp\n        COMMAND cut \"-d\\ \" -f2\n        OUTPUT_VARIABLE libomp_ver OUTPUT_STRIP_TRAILING_WHITESPACE)\n    if(libomp_ver VERSION_GREATER_EQUAL 12.0.0)\n        message(SEND_ERROR \"libomp ${libomp_ver} found, which can lead to interoperability problems with other Python libraries using libomp.  Please use libomp v11.1 to build Open3D.\")\n    endif()\n    file(GENERATE OUTPUT update_pybind_libomp.sh\n        CONTENT [=[libomp_library=$(dyld_info -dependents \"$<TARGET_FILE:pybind>\" |\ngrep libomp | tr -d '[:space:]')\ninstall_name_tool -change $libomp_library @rpath/$(basename $libomp_library) \\\n\"$<TARGET_FILE:pybind>\"]=])\n    add_custom_command(TARGET pybind POST_BUILD\n        COMMAND bash update_pybind_libomp.sh\n        COMMENT \"Updating pybind to use packaged libomp\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: Verifying ARM64 Environment\nDESCRIPTION: Command to test ARM64 Docker environment by checking platform architecture.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docker/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm arm64v8/ubuntu:24.04 uname -p\n```\n\n----------------------------------------\n\nTITLE: Adding Core Transformation Test Sources in Open3D CMake\nDESCRIPTION: Adds the core transformation test source files to the tests target. These tests likely cover functionality for converting between different transformation representations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/t/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    TransformationConverter.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Creating TensorFlow Ops Shared Library\nDESCRIPTION: Defines the main shared library for Open3D TensorFlow operations and sets up source files for continuous convolution operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nadd_library(open3d_tf_ops SHARED)\n\ntarget_sources(open3d_tf_ops PRIVATE\n    continuous_conv/ContinuousConvBackpropFilterOpKernel.cpp\n    continuous_conv/ContinuousConvBackpropFilterOps.cpp\n    continuous_conv/ContinuousConvOpKernel.cpp\n    continuous_conv/ContinuousConvOps.cpp\n    continuous_conv/ContinuousConvTransposeBackpropFilterOpKernel.cpp\n    continuous_conv/ContinuousConvTransposeBackpropFilterOps.cpp\n    continuous_conv/ContinuousConvTransposeOpKernel.cpp\n    continuous_conv/ContinuousConvTransposeOps.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Contrib Module Sources to Open3D Python Bindings\nDESCRIPTION: This CMake snippet adds multiple source files from the contrib module to the pybind target in Open3D. It includes functionality for subsampling, general contrib features, and IOU calculations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/ml/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    contrib/contrib_subsample.cpp\n    contrib/contrib.cpp\n    contrib/iou.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Output Directory Based on Architecture\nDESCRIPTION: Configures output directories for the TensorFlow operations library based on CPU/CUDA architecture.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_14\n\nLANGUAGE: CMake\nCODE:\n```\n# Set output directory according to architecture (cpu/cuda)\nget_target_property(TF_OPS_DIR open3d_tf_ops LIBRARY_OUTPUT_DIRECTORY)\nset(TF_OPS_ARCH_DIR\n    \"${TF_OPS_DIR}/$<IF:$<BOOL:${BUILD_CUDA_MODULE}>,cuda,cpu>\")\nset_target_properties(open3d_tf_ops PROPERTIES\n    LIBRARY_OUTPUT_DIRECTORY \"${TF_OPS_ARCH_DIR}\"\n    ARCHIVE_OUTPUT_DIRECTORY \"${TF_OPS_ARCH_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Open3D\nDESCRIPTION: This snippet lists the required Python packages and their versions for the Open3D project. It includes tools for documentation (Sphinx, docutils), styling (furo), data processing (matplotlib, lxml), and Jupyter notebook conversion (nbsphinx, nbconvert).\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\ndocutils==0.20.1\nfuro==2023.9.10\njinja2==3.1.5\nm2r2==0.3.3.post2\nmatplotlib==3.7.3\nnbsphinx==0.9.3\nsphinx==7.1.2\nsphinx-tabs==3.4.7\nsphinx-copybutton==0.5.2\nnbconvert==6.5.4\nlxml==5.2.1\nlxml_html_clean==0.4.0\n```\n\n----------------------------------------\n\nTITLE: Including RPC Test Sources in CMake\nDESCRIPTION: Adds Remote Procedure Call (RPC) related test source files to the tests target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/io/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    rpc/RemoteFunctions.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Source Files to Open3D Python Bindings Target\nDESCRIPTION: CMake configuration that adds C++ source files to the 'pybind' target for building Python bindings. The source files handle core functionality like Eigen integration, logging, random number generation, and utility functions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/utility/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    eigen.cpp\n    logging.cpp\n    random.cpp\n    utility.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Adding C++ Source Files to Open3D Python Bindings Target\nDESCRIPTION: This CMake command adds multiple C++ source files to the 'pybind' target. These files likely contain the implementation of various geometry-related classes and functions that will be exposed to Python through the bindings.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    boundingvolume.cpp\n    geometry.cpp\n    halfedgetrianglemesh.cpp\n    image.cpp\n    kdtreeflann.cpp\n    keypoint.cpp\n    lineset.cpp\n    meshbase.cpp\n    octree.cpp\n    pointcloud.cpp\n    tetramesh.cpp\n    trianglemesh.cpp\n    voxelgrid.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D IO Library Properties in CMake\nDESCRIPTION: Sets up warning handling, global properties, Open3D-specific library properties, and links third-party libraries for the 'io' target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/io/CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_show_and_abort_on_warning(io)\nopen3d_set_global_properties(io)\nopen3d_set_open3d_lib_properties(io)\nopen3d_link_3rdparty_libraries(io)\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure in reStructuredText\nDESCRIPTION: Defines the hierarchical documentation structure using toctree directives to organize content into Basics, Processing, and Interface sections. Each toctree specifies related documentation pages for geometry processing features.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/geometry/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n    :caption: Basics\n\n    pointcloud\n    mesh\n    rgbd_image\n    kdtree\n\n.. toctree::\n    :caption: Processing\n\n    file_io\n    pointcloud_outlier_removal\n    voxelization\n    octree\n    surface_reconstruction\n    transformation\n    mesh_deformation\n    iss_keypoint_detector\n    ray_casting\n    distance_queries\n    uvmaps\n\n.. toctree::\n    :caption: Interface\n\n    python_interface\n    working_with_numpy\n```\n\n----------------------------------------\n\nTITLE: Building Open3D with SYCL Support\nDESCRIPTION: CMake configuration and build command for compiling Open3D with SYCL support, using Intel oneAPI compilers (icx and icpx).\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README_SYCL.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncmake -DBUILD_SYCL_MODULE=ON -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx -DBUILD_UNIT_TESTS=ON ..\nmake -j$(nproc)\n```\n\n----------------------------------------\n\nTITLE: Adding Registration Module Sources\nDESCRIPTION: Adds registration-related source files including feature detection, registration algorithms, and robust kernel implementations\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/pipelines/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    registration/feature.cpp\n    registration/registration.cpp\n    registration/robust_kernel.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Conditionally Adding Azure Kinect Support to Open3D Python Bindings in CMake\nDESCRIPTION: Conditionally adds sensor-related C++ source files to the 'pybind' target when Azure Kinect support is enabled. This block is only processed if the BUILD_AZURE_KINECT flag is set during configuration.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/io/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_AZURE_KINECT)\n    target_sources(pybind PRIVATE\n        sensor.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding SLAC Module Sources\nDESCRIPTION: Includes SLAC (Simultaneous Localization And Calibration) implementation source files\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/t/pipelines/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(pybind PRIVATE\n    slac/slac.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up WebRTC Build Environment for Open3D\nDESCRIPTION: This code snippet demonstrates the process of setting up the WebRTC build environment for Open3D. It includes steps to download depot_tools, clone the WebRTC repository, and set up the necessary directory structure.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/webrtc/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# You're in Open3D\ncd ..\ngit clone https://chromium.googlesource.com/chromium/tools/depot_tools.git\nexport PATH=$PATH:`realpath depot_tools`\nmkdir webrtc\ncd webrtc\nfetch --no-history webrtc\ncd ../Open3D\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Open3D\nDESCRIPTION: Sphinx documentation root file containing toctree directives that organize the documentation hierarchy for Open3D. Includes sections for getting started guides, tutorials, API references, and contribution guidelines.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. Open3D documentation primary file, created by\n   sphinx-quickstart on Mon Apr  3 14:18:28 2017.\n   You can adapt this file completely to your liking, but it should at least\n   contain the root `toctree` directive.\n\n.. image:: _static/open3d_logo_horizontal.png\n    :alt: Open3D logo\n    :width: 320px\n    :align: center\n\n-----------\n\nOpen3D: A Modern Library for 3D Data Processing\n===============================================\n\n.. toctree::\n    :maxdepth: 1\n    :caption: Getting Started\n\n    introduction\n    getting_started\n    compilation\n    cpp_project\n    builddocs\n    docker\n    arm\n    sycl\n    open3d_ml\n```\n\n----------------------------------------\n\nTITLE: Running Python WebRTC Example\nDESCRIPTION: Shell command for running the Python WebRTC example in Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\npython examples/python/visualization/draw_webrtc.py\ngoogle-chrome http://localhost:8888  # Or, open the address in your browser\n```\n\n----------------------------------------\n\nTITLE: Adding Main Source File and Google Benchmark Library\nDESCRIPTION: Adds the main entry point source file to the benchmarks target and links the Google Benchmark library for performance measurement functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_8\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    Main.cpp\n)\ntarget_link_libraries(benchmarks PRIVATE benchmark::benchmark)\ntarget_include_directories(benchmarks PRIVATE ${CMAKE_CURRENT_SOURCE_DIR})\n```\n\n----------------------------------------\n\nTITLE: Platform-Specific Linker Configuration for pybind in CMake\nDESCRIPTION: Configures platform-specific linker options for Windows, macOS, and Linux to control symbol visibility and optimization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (WIN32)\n    target_link_options(pybind PUBLIC \"/force:multiple\")\n    # TODO(Sameer): Only export PyInit_pybind, open3d_core_cuda_device_count\nelseif (APPLE)\n    file(GENERATE OUTPUT pybind.map CONTENT\n        [=[_PyInit_pybind\nopen3d_core_cuda_device_count\n        ]=])\n    target_link_options(pybind PRIVATE $<$<CONFIG:Release>:\n        -Wl,-exported_symbols_list\n        \"${CMAKE_CURRENT_BINARY_DIR}/pybind.map\" >)\nelseif (UNIX)   # Linux\n    file(GENERATE OUTPUT pybind.map CONTENT\n        [=[{\n    global:\n        PyInit_pybind;\n        open3d_core_cuda_device_count;\n    local:\n        *;\n};]=])\n    target_link_options(pybind PRIVATE $<$<CONFIG:Release>:\n        \"-Wl,--version-script=${CMAKE_CURRENT_BINARY_DIR}/pybind.map\" >)\n    target_link_options(pybind PRIVATE \"-flto=auto\")\nendif()\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Open3D TensorFlow Layers\nDESCRIPTION: ReStructuredText documentation defining the structure and navigation for Open3D's TensorFlow layer classes. Includes module definition, class listing, and hidden toctree for detailed class documentation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/python_api_in/open3d.ml.tf.layers.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: open3d.ml.tf.layers\n\n.. automodule:: open3d.ml.tf.layers\n\n**Classes**\n\n.. autosummary::\n\n    ContinuousConv\n    FixedRadiusSearch\n    KNNSearch\n    RadiusSearch\n    SparseConv\n    SparseConvTranspose\n    VoxelPooling\n\n.. toctree::\n    :hidden:\n\n    ContinuousConv <open3d.ml.tf.layers.ContinuousConv>\n    FixedRadiusSearch <open3d.ml.tf.layers.FixedRadiusSearch>\n    KNNSearch <open3d.ml.tf.layers.KNNSearch>\n    RadiusSearch <open3d.ml.tf.layers.RadiusSearch>\n    SparseConv <open3d.ml.tf.layers.SparseConv>\n    SparseConvTranspose <open3d.ml.tf.layers.SparseConvTranspose>\n    VoxelPooling <open3d.ml.tf.layers.VoxelPooling>\n```\n\n----------------------------------------\n\nTITLE: Setting up HTML Resource Directory for WebRTC\nDESCRIPTION: Verifies that the GUI resource directory is defined and sets up a directory for HTML resources. This step ensures that the WebRTC server has access to necessary web resources.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/webrtc_server/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (NOT GUI_RESOURCE_DIR)\n    message(FATAL_ERROR \"GUI_RESOURCE_DIR is not defined.\")\nendif()\nmessage(STATUS \"Copying ${CMAKE_CURRENT_SOURCE_DIR}/html to ${GUI_RESOURCE_DIR}.\")\nfile(MAKE_DIRECTORY ${GUI_RESOURCE_DIR})\n```\n\n----------------------------------------\n\nTITLE: Building GLEW on Linux/Mac using GNU Make\nDESCRIPTION: Commands for building GLEW on Linux or Mac systems using GNU Make. Includes steps for installing dependencies, building, and cleaning up.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/README.md#2025-04-23_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\n$ make\n$ sudo make install\n$ make clean\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Target for HTML Directory Copying\nDESCRIPTION: Creates a custom build target that removes any existing HTML directory in the GUI resource directory and copies the current HTML directory to it. This ensures that the HTML resources are up-to-date with each build.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/visualization/webrtc_server/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: CMake\nCODE:\n```\n# Force update ${GUI_RESOURCE_DIR}/html every time.\nadd_custom_target(copy_html_dir ALL\n    COMMAND ${CMAKE_COMMAND} -E rm -rf\n        ${GUI_RESOURCE_DIR}/html\n    COMMAND ${CMAKE_COMMAND} -E copy_directory\n        ${CMAKE_CURRENT_SOURCE_DIR}/html\n        ${GUI_RESOURCE_DIR}/html\n)\n```\n\n----------------------------------------\n\nTITLE: Adding CUDA Include Directories\nDESCRIPTION: Conditionally adds CUDA toolkit include directories to the benchmarks target when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    target_include_directories(benchmarks SYSTEM PRIVATE ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\nendif()\n```\n\n----------------------------------------\n\nTITLE: WebRTC Library Build Configuration\nDESCRIPTION: Creates build targets for libwebrtc.a using ninja and libwebrtc_extra.a using CMake. Sets up build properties and dependencies for the extra library.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/webrtc/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nadd_custom_target(webrtc\n    ALL\n    COMMAND ${DEPOT_TOOLS_ROOT}/gn gen .\n    COMMAND ${DEPOT_TOOLS_ROOT}/ninja ${NINJA_TARGETS}\n    WORKING_DIRECTORY ${WEBRTC_NINJA_ROOT}\n    BYPRODUCTS ${EXTRA_WEBRTC_OBJS}\n)\n\nadd_library(webrtc_extra STATIC ${EXTRA_WEBRTC_OBJS})\nset_source_files_properties(${EXTRA_WEBRTC_OBJS} PROPERTIES\n    GENERATED TRUE\n    EXTERNAL_OBJECT TRUE)\nadd_dependencies(webrtc_extra webrtc)\nset_target_properties(webrtc_extra PROPERTIES LINKER_LANGUAGE CXX)\nset_target_properties(webrtc_extra PROPERTIES\n    ARCHIVE_OUTPUT_DIRECTORY ${WEBRTC_NINJA_ROOT}/obj\n)\n```\n\n----------------------------------------\n\nTITLE: WebRTC-Dependent Python Binding Sources in CMake\nDESCRIPTION: Conditionally adds WebRTC-related source files when BUILD_WEBRTC is enabled, specifically including the WebRTC window system implementation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/pybind/visualization/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\nif (BUILD_WEBRTC)\n    target_sources(pybind PRIVATE\n        webrtc_server/webrtc_window_system.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Dependency Specification for jupyter_packaging (Python)\nDESCRIPTION: Requires the `jupyter_packaging` package with a version compatible with 0.12 (`~=0.12`), meaning greater than or equal to 0.12 but less than 1.0. This package provides tools for building and distributing Jupyter extensions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_jupyter_build.txt#2025-04-23_snippet_3\n\nLANGUAGE: requirements\nCODE:\n```\njupyter_packaging~=0.12\n```\n\n----------------------------------------\n\nTITLE: Setting up oneAPI Environment for SYCL in Open3D\nDESCRIPTION: Commands for setting up the oneAPI environment, creating a conda environment, and activating it for SYCL development with Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README_SYCL.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Source environments\nsource /opt/intel/oneapi/setvars.sh\n\n# We'll be using oneAPI's distribution of conda and Python\n# Python 3.6+ will work\nconda create -n sycl python=3.8\nconda activate sycl\n```\n\n----------------------------------------\n\nTITLE: Compiling OSMesa from Source for Ubuntu 16.04\nDESCRIPTION: Series of commands to download, configure, and compile OSMesa 19.0.8 from source, which is necessary for Ubuntu 16.04 or systems with older OSMesa versions.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/headless_rendering.rst#2025-04-23_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n# install llvm-8\n(py3env) $ sudo apt install llvm-8\n\n# download OSMesa 19.0.8 release\n(py3env) $ curl -O https://mesa.freedesktop.org/archive/mesa-19.0.8.tar.xz\n(py3env) $ tar xvf mesa-19.0.8.tar.xz\n(py3env) $ cd mesa-19.0.8\n(py3env) $ LLVM_CONFIG=\"/usr/bin/llvm-config-8\" ./configure --prefix=$HOME/osmesa \\\n    --disable-osmesa --disable-driglx-direct --disable-gbm --enable-dri \\\n    --with-gallium-drivers=swrast --enable-autotools --enable-llvm --enable-gallium-osmesa\n(py3env) $ make -j$(nproc)\n(py3env) $ make install\n# this installed OSMesa libraries to $HOME/osmesa/lib; in order for Open3D to pick it up\n# LD_LIBRARY_PATH needs to be updated to include it:\n(py3env) $ export LD_LIBRARY_PATH=\"$HOME/osmesa/lib:$LD_LIBRARY_PATH\"\n# this needs to be done for every shell, or you can add it to your .bashrc\n(py3env) $ cd ~/Open3D\n(py3env) $ mkdir build&&cd build\n(py3env) $ cmake -DENABLE_HEADLESS_RENDERING=ON -DUSE_SYSTEM_GLEW=OFF -DUSE_SYSTEM_GLFW=OFF \\\n    -DOSMESA_INCLUDE_DIR=$HOME/osmesa/include -DOSMESA_LIBRARY=\"$HOME/osmesa/lib/libOSMesa.so\" \\\n    ..\n(py3env) $ make -j$(nproc)\n(py3env) $ make install-pip-package\n```\n\n----------------------------------------\n\nTITLE: Configuring CUDA Support for Benchmarks\nDESCRIPTION: Conditionally adds CUDA support to the benchmarks if the CUDA module is enabled in the build.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    find_package(CUDAToolkit REQUIRED)\n    target_link_libraries(benchmarks PRIVATE CUDA::cudart)\nendif()\n```\n\n----------------------------------------\n\nTITLE: Adding RGBD Odometry Test Sources in Open3D CMake\nDESCRIPTION: Adds the RGBD odometry test source files to the tests target. These tests focus on camera motion estimation using RGB and depth image pairs.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/t/pipelines/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    odometry/RGBDOdometry.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Customized TSDF Integration in Open3D Python\nDESCRIPTION: This code demonstrates conventional TSDF integration written in vectorized Python. It reads RGB-D properties, accesses voxel buffer arrays, and performs in-place modification.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/customized_integration.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nrgb = color_im[v, u]\ndepth = depth_im[v, u, 0]\nsdf = depth - z\n\ntsdf = vbg.attribute('tsdf').reshape((-1, 1))\nweight = vbg.attribute('weight').reshape((-1, 1))\ncolor = vbg.attribute('color').reshape((-1, 3))\n\ntsdf_o = tsdf[voxel_indices]\nweight_o = weight[voxel_indices]\ncolor_o = color[voxel_indices]\n\ntsdf_new = (tsdf_o * weight_o + sdf) / (weight_o + 1)\nw_new = weight_o + 1\ncolor_new = (color_o * weight_o + rgb) / w_new\n\ntsdf[voxel_indices] = tsdf_new\nweight[voxel_indices] = w_new\ncolor[voxel_indices] = color_new\n\nvbg.attribute('tsdf').assign(tsdf)\nvbg.attribute('weight').assign(weight)\nvbg.attribute('color').assign(color)\n```\n\n----------------------------------------\n\nTITLE: Dependency Specification for jupyterlab (Python)\nDESCRIPTION: Requires the `jupyterlab` package, version 3.0.0 or higher (`>=3.0.0`), but specifically constrained to the 3.x series (`==3.*`). JupyterLab is the next-generation web-based user interface for Project Jupyter.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_jupyter_build.txt#2025-04-23_snippet_4\n\nLANGUAGE: requirements\nCODE:\n```\njupyterlab>=3.0.0,==3.*\n```\n\n----------------------------------------\n\nTITLE: Adding Source Files to Open3D Benchmarks Target in CMake\nDESCRIPTION: This CMake code adds source files to the 'benchmarks' target in the Open3D project. It includes benchmark implementations for RGBD odometry and registration functionality (including feature extraction and registration algorithms).\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/benchmarks/t/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(benchmarks PRIVATE\n    odometry/RGBDOdometry.cpp\n    registration/Feature.cpp\n    registration/Registration.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Creating ISPC Geometry Library in Open3D\nDESCRIPTION: Creates an ISPC (Intel SPMD Program Compiler) object library for tensor-based geometry functionality.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/geometry/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: CMake\nCODE:\n```\nopen3d_ispc_add_library(tgeometry OBJECT)\n```\n\n----------------------------------------\n\nTITLE: Adding Sparse Convolution Source Files\nDESCRIPTION: Adds sparse convolution related source files to the TensorFlow operations library, including backpropagation and transpose operations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(open3d_tf_ops PRIVATE\n    sparse_conv/SparseConvBackpropFilterOpKernel.cpp\n    sparse_conv/SparseConvOpKernel.cpp\n    sparse_conv/SparseConvTransposeBackpropFilterOpKernel.cpp\n    sparse_conv/SparseConvTransposeOpKernel.cpp\n    sparse_conv/SparseConvBackpropFilterOps.cpp\n    sparse_conv/SparseConvOps.cpp\n    sparse_conv/SparseConvTransposeBackpropFilterOps.cpp\n    sparse_conv/SparseConvTransposeOps.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Open3D Test Sources in CMake\nDESCRIPTION: This CMake snippet defines the source files to be included in the 'tests' target for the Open3D project. It adds four C++ files (Compare.cpp, Rand.cpp, Raw.cpp, and Sort.cpp) as private sources to the target, meaning they'll be compiled into the test executable but won't be exposed as public interfaces.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/test_utility/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    Compare.cpp\n    Rand.cpp\n    Raw.cpp\n    Sort.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Setting ISPC Build Options\nDESCRIPTION: Configures ISPC-specific build options including legacy emulation support and compile command printing. Includes version checking for Intel ISPC compiler.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cmake/ispc_isas/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif (CMAKE_ISPC_COMPILER_LOADED OR (CMAKE_GENERATOR MATCHES \"Make\" OR CMAKE_GENERATOR MATCHES \"Ninja\"))\n    option(ISPC_USE_LEGACY_EMULATION \"Use legacy ISPC language emulation over first-class CMake support\" OFF)\nelse()\n    option(ISPC_USE_LEGACY_EMULATION \"Use legacy ISPC language emulation over first-class CMake support\" ON)\nendif()\nmark_as_advanced(ISPC_USE_LEGACY_EMULATION)\noption(ISPC_PRINT_LEGACY_COMPILE_COMMANDS \"Prints legacy compile commands on CMake configuration time\" ON)\nmark_as_advanced(ISPC_PRINT_LEGACY_COMPILE_COMMANDS)\n```\n\n----------------------------------------\n\nTITLE: Adding Contributed Utility Source Files\nDESCRIPTION: Adds contributed utility classes and functions for cloud processing, grid subsampling, and non-maximum suppression.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/tensorflow/CMakeLists.txt#2025-04-23_snippet_6\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(open3d_tf_ops PRIVATE\n    ../contrib/Cloud.cpp\n    ../contrib/GridSubsampling.cpp\n    ../contrib/Nms.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Loading Wood Floor Textures into MaterialRecord using Open3D C++\nDESCRIPTION: This C++ code snippet demonstrates loading the wood floor texture dataset with `open3d::data::WoodFloorTexture`. It uses `open3d::io::CreateImageFromFile` to load the albedo, normal, and roughness maps and assigns them to an `open3d::visualization::rendering::MaterialRecord` with the 'defaultUnlit' shader.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_41\n\nLANGUAGE: cpp\nCODE:\n```\ndata::WoodFloorTexture mat_data;\n\nauto mat = visualization::rendering::MaterialRecord();\nmat.shader = \"defaultUnlit\";\nmat.albedo_img = io::CreateImageFromFile(mat_data.albedo_texture_path);\nmat.normal_img = io::CreateImageFromFile(mat_data.normal_texture_path);\nmat.roughness_img = io::CreateImageFromFile(mat_data.roughness_texture_path);\n```\n\n----------------------------------------\n\nTITLE: Conventional Ray Casting Rendering in Open3D Python\nDESCRIPTION: This snippet demonstrates how to perform conventional ray casting rendering on a reconstructed voxel block grid. It uses the input depth as a rough range estimate for efficient scene rendering.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/t_reconstruction_system/ray_casting.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nintrinsic = o3c.camera.PinholeCameraIntrinsic(o3c.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\nextrinsic = np.eye(4)\nresolution = o3c.TensorVector2i(640, 480)\nproperties = o3c.TensorMap()\nproperties['depth_scale'] = o3c.Tensor([1000.0])\nproperties['depth_min'] = o3c.Tensor([0.1])\nproperties['depth_max'] = o3c.Tensor([3.0])\nproperties['step_size'] = o3c.Tensor([0.01])\nproperties['weight_threshold'] = o3c.Tensor([3.0])\n\nresults = vbg.ray_cast(block_coords, intrinsic, extrinsic, resolution,\n                       depth, properties, o3c.nns.ball_query(0.02, 1))\n```\n\n----------------------------------------\n\nTITLE: Pose Graph Optimization Output Example\nDESCRIPTION: Sample output showing the convergence of pose graph optimization, including residual values, number of valid edges, and iteration statistics.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/reconstruction_system/refine_registration.rst#2025-04-23_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\n[GlobalOptimizationLM] Optimizing PoseGraph having 14 nodes and 35 edges.\nLine process weight : 789.730200\n[Initial     ] residual : 1.208286e+04, lambda : 1.706306e+01\n[Iteration 00] residual : 2.410383e+03, valid edges : 22, time : 0.000 sec.\n[Iteration 01] residual : 8.127856e+01, valid edges : 22, time : 0.000 sec.\n[Iteration 02] residual : 8.031355e+01, valid edges : 22, time : 0.000 sec.\nDelta.norm() < 1.000000e-06 * (x.norm() + 1.000000e-06)\n[GlobalOptimizationLM] total time : 0.001 sec.\n[GlobalOptimizationLM] Optimizing PoseGraph having 14 nodes and 35 edges.\nLine process weight : 789.730200\n[Initial     ] residual : 8.031355e+01, lambda : 1.716826e+01\nDelta.norm() < 1.000000e-06 * (x.norm() + 1.000000e-06)\n[GlobalOptimizationLM] total time : 0.000 sec.\nCompensateReferencePoseGraphNode : reference : 0\n```\n\n----------------------------------------\n\nTITLE: Making Benchmark Library Available via FetchContent in CMake\nDESCRIPTION: Makes the previously defined external benchmark library available to the project using CMake's FetchContent module.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/benchmark/MakeAvailable/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nFetchContent_MakeAvailable(ext_benchmark)\n```\n\n----------------------------------------\n\nTITLE: Configuring GLEW Project with CMake\nDESCRIPTION: Sets up the GLEW project, defines minimum CMake version, and configures OSMesa support for headless rendering if enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nproject(glew C)\n\ncmake_minimum_required(VERSION 3.0.0)\nset(CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS true)\n\nif (ENABLE_HEADLESS_RENDERING)\n\tset(GLEW_OSMESA ON)\nelse ()\n\tset(GLEW_OSMESA OFF)\nendif ()\n```\n\n----------------------------------------\n\nTITLE: Configuring RaycastingScene Source with SYCL Conditional in Open3D\nDESCRIPTION: Conditionally adds the RaycastingScene.cpp source file based on whether the SYCL module is being built, using SYCL-specific compilation if available.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/geometry/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nif (BUILD_SYCL_MODULE)\n    open3d_sycl_target_sources(tgeometry PRIVATE\n        RaycastingScene.cpp\n    )\nelse()\n    target_sources(tgeometry PRIVATE\n        RaycastingScene.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: CUDA Sources Configuration\nDESCRIPTION: Adds CUDA-specific source files when CUDA module is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/pytorch/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nif (BUILD_CUDA_MODULE)\n    target_sources(open3d_torch_ops PRIVATE\n        continuous_conv/ContinuousConvBackpropFilterOpKernel.cu\n        continuous_conv/ContinuousConvOpKernel.cu\n        continuous_conv/ContinuousConvTransposeBackpropFilterOpKernel.cu\n        continuous_conv/ContinuousConvTransposeOpKernel.cu\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Including Kernel Subdirectory in CMake\nDESCRIPTION: Adds the 'kernel' subdirectory to the CMake build process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/pipelines/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(kernel)\n```\n\n----------------------------------------\n\nTITLE: Configuring LibUSB Core Source Files in CMake\nDESCRIPTION: Sets up the core source files required for the LibUSB library that are common across all platforms. These files handle the foundational functionality of the USB library.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/librealsense/libusb-CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\n  set(LIBUSB_C\n  libusb/core.c\n  libusb/descriptor.c\n  libusb/hotplug.c\n  libusb/io.c\n  libusb/strerror.c\n  libusb/sync.c\n  )\n```\n\n----------------------------------------\n\nTITLE: Specifying Minimum Python Dependency Version for ipywidgets\nDESCRIPTION: This line specifies a requirement for the 'ipywidgets' package, ensuring that at least version 8.0.4 is installed. It is used by package managers like pip to manage project dependencies defined in a requirements file.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_jupyter_install.txt#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nipywidgets>=8.0.4\n```\n\n----------------------------------------\n\nTITLE: Exporting GLEW Configuration\nDESCRIPTION: Sets and exports GLEW include directories and libraries for use in parent scope, allowing other parts of the project to use GLEW.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\nset(GLEW_INCLUDE_DIRS \"${CMAKE_CURRENT_SOURCE_DIR}/include\")\nset(GLEW_LIBRARIES \"glew\")\nset(GLEW_INCLUDE_DIRS ${GLEW_INCLUDE_DIRS} PARENT_SCOPE)\nset(GLEW_LIBRARIES ${GLEW_LIBRARIES} PARENT_SCOPE)\n```\n\n----------------------------------------\n\nTITLE: Listing WebRTC Integration Files for Open3D\nDESCRIPTION: This code block lists the main entry points and other files used in the WebRTC integration process for Open3D. It includes files for downloading pre-compiled WebRTC, building WebRTC from source, and supporting files for both methods.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/webrtc/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Main entry points\nwebrtc_download.cmake # Used by Open3D CMake. Consume pre-compiled WebRTC. (Method 1 Consume-Phase)\nwebrtc_build.cmake    # Used by Open3D CMake. Build and consume WebRTC.    (Method 2)\n\n# Other files\n0001-xxx.patch x3     # Git patch for -DBUILD_WEBRTC_FROM_SOURCE=ON.       (Method 1 Prepare-Phase & Method 2)\nCMakeLists.txt        # Used by `webrtc_build.sh` to compile WebRTC.       (Method 1 Prepare-Phase)\nDockerfile.webrtc     # Calls `webrtc_build.sh` to compile WebRTC.         (Method 1 Prepare-Phase)\nwebrtc_build.sh       # Used by `Dockerfile.webrtc`.                       (Method 1 Prepare-Phase)\nwebrtc_common.cmake   # Specifies Common WebRTC targets.                   (Method 1 Prepare-Phase)\n```\n\n----------------------------------------\n\nTITLE: Configuring Core Test Sources in CMake for Open3D\nDESCRIPTION: This snippet adds core test source files to the 'tests' target. It includes various component tests such as Blob, CoreTest, Device, and Tensor-related tests.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/core/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    Blob.cpp\n    CoreTest.cpp\n    CUDAUtils.cpp\n    Device.cpp\n    EigenConverter.cpp\n    HashMap.cpp\n    Indexer.cpp\n    Linalg.cpp\n    MemoryManager.cpp\n    NanoFlannIndex.cpp\n    NearestNeighborSearch.cpp\n    ParallelFor.cpp\n    Scalar.cpp\n    ShapeUtil.cpp\n    SizeVector.cpp\n    Tensor.cpp\n    TensorCheck.cpp\n    TensorFunction.cpp\n    TensorList.cpp\n    TensorObject.cpp\n    SYCLUtils.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Dependency Specification for ipywidgets (Python)\nDESCRIPTION: Requires the `ipywidgets` package, version 8.0.4 or higher (`>=8.0.4`). This package provides interactive HTML widgets for Jupyter notebooks and IPython kernels.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_jupyter_build.txt#2025-04-23_snippet_1\n\nLANGUAGE: requirements\nCODE:\n```\nipywidgets>=8.0.4\n```\n\n----------------------------------------\n\nTITLE: Farthest Point Downsampling a Point Cloud\nDESCRIPTION: Shows how to use farthest point sampling to downsample a point cloud to a fixed number of points. This technique iteratively selects points that are farthest from the currently selected points to preserve geometric information.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/t_geometry/pointcloud.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Downsample the point cloud by selecting 5000 farthest points.\")\ndownpcd_farthest = pcd.farthest_point_down_sample(5000)\no3d.visualization.draw_geometries([downpcd_farthest.to_legacy()],\n                                  zoom=0.3412,\n                                  front=[0.4257, -0.2125, -0.8795],\n                                  lookat=[2.6172, 2.0475, 1.532],\n                                  up=[-0.0694, -0.9768, 0.2024])\n```\n\n----------------------------------------\n\nTITLE: Running Open3D Python Unit Tests (Bash)\nDESCRIPTION: Steps to run the Python unit tests for Open3D. First, ensure a Python virtual environment is activated. Then, install the pytest library, install the Open3D Python package locally using 'make install-pip-package', and finally run pytest pointing to the test directory. Assumes execution within the build directory.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n# Activate virtualenv first\npip install pytest\nmake install-pip-package -j$(nproc)\npytest ../python/test\n```\n\n----------------------------------------\n\nTITLE: Defining Python Build/Development Dependencies (Text)\nDESCRIPTION: This text specifies required Python packages and their versions for the project. `setuptools>=67.3.2` requires setuptools version 67.3.2 or higher, `wheel==0.38.4` requires exactly version 0.38.4 of wheel, and `yapf==0.30.0` requires exactly version 0.30.0 of yapf. These are typically used for building, packaging, and code formatting within a Python environment using tools like pip.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_build.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nsetuptools>=67.3.2\nwheel==0.38.4\nyapf==0.30.0\n```\n\n----------------------------------------\n\nTITLE: Enabling Interactive CPU Rendering with Mesa Drivers in Bash\nDESCRIPTION: Sets the LIBGL_ALWAYS_SOFTWARE environment variable to 'true' to enable interactive CPU rendering with Mesa drivers v20.2 or higher before running the Open3D visualizer app.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/cpu_rendering.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nLIBGL_ALWAYS_SOFTWARE=true Open3D\n```\n\n----------------------------------------\n\nTITLE: Building GLEW on Windows using MSYS2/Mingw-w64\nDESCRIPTION: Instructions for building GLEW on Windows systems using MSYS2/Mingw-w64. Includes steps for installing dependencies, compiling, and installing.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/README.md#2025-04-23_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\n$ pacman -S gcc make mingw-w64-i686-gcc mingw-w64-x86_64-gcc\n$ make\n$ make install\n$ make install.all\n```\n\n----------------------------------------\n\nTITLE: Configuring Core IO Test Sources in CMake\nDESCRIPTION: Adds core IO-related test source files to the tests target, including features, JSON, image, octree, camera trajectory, point cloud, pose graph, triangle mesh, and voxel grid IO implementations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/io/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    FeatureIO.cpp\n    IJsonConvertibleIO.cpp\n    ImageIO.cpp\n    OctreeIO.cpp\n    PinholeCameraTrajectoryIO.cpp\n    PointCloudIO.cpp\n    PoseGraphIO.cpp\n    TriangleMeshIO.cpp\n    VoxelGridIO.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Specifying Conditional Python Dependency for pywinpty\nDESCRIPTION: This line defines a dependency on the 'pywinpty' package at exact version 2.0.2. It's a conditional dependency, only installed if the operating system is Windows ('sys_platform==\\'win32\\'') and the Python version is 3.6 ('python_version==\\'3.6\\''). This format is standard for Python requirements files.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_jupyter_install.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npywinpty==2.0.2; sys_platform=='win32' and python_version=='3.6'\n```\n\n----------------------------------------\n\nTITLE: Verifying Docker Installation\nDESCRIPTION: Command to verify basic Docker functionality by running a hello-world container.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docker/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# You should be able to run this without sudo.\ndocker run --rm hello-world\n```\n\n----------------------------------------\n\nTITLE: Using Open3D in Example Project on Windows\nDESCRIPTION: This snippet demonstrates how to set up and build an example project using the installed Open3D library on Windows. It covers copying the example, configuring with CMake, building with Visual Studio, and running the example.\nSOURCE: https://github.com/isl-org/open3d/blob/main/examples/cmake/open3d-cmake-find-package/README.md#2025-04-23_snippet_3\n\nLANGUAGE: batch\nCODE:\n```\ncp -ar Open3D/examples/cmake/open3d-cmake-find-package .\ncd open3d-cmake-find-package\nmkdir build\ncmake -DOpen3D_ROOT=C:\\open3d_install ..\ncmake --build . --config Release --parallel 12\nRelease\\Draw\n```\n\n----------------------------------------\n\nTITLE: Preloading Mesa Driver Library for Interactive CPU Rendering with Python\nDESCRIPTION: Exports the LD_PRELOAD environment variable to use the Mesa driver library for interactive CPU rendering when running Python scripts with Open3D visualization.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/cpu_rendering.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nexport LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLX_mesa.so.0\npython examples/python/visualization/draw.py\n```\n\n----------------------------------------\n\nTITLE: Generating GLEW Extension Data\nDESCRIPTION: Command for regenerating GLEW extension data from the top-level source directory. This is used for including new extensions or customizing code generation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/glew/README.md#2025-04-23_snippet_4\n\nLANGUAGE: Bash\nCODE:\n```\nmake extensions\n```\n\n----------------------------------------\n\nTITLE: Conditionally Adding ISPC Module Tests in CMake for Open3D\nDESCRIPTION: This CMake conditional block adds ISPC-specific test sources when the BUILD_ISPC_MODULE option is enabled. It specifically adds the Helper.ispc file to the tests target.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/utility/CMakeLists.txt#2025-04-23_snippet_1\n\nLANGUAGE: cmake\nCODE:\n```\nif (BUILD_ISPC_MODULE)\n    target_sources(tests PRIVATE\n        Helper.ispc\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Defining Module and Functions in reStructuredText\nDESCRIPTION: This snippet defines the module and lists the available functions using reStructuredText syntax for documentation. It specifies the current module and provides an autosummary of the 'add_3d' function.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/python_api_in/open3d.visualization.tensorboard_plugin.summary.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. currentmodule:: open3d.visualization.tensorboard_plugin.summary\n\n**Functions**\n\n.. autosummary::\n\n    add_3d\n\n.. toctree::\n    :hidden:\n\n    add_3d <open3d.visualization.tensorboard_plugin.summary.add_3d>\n```\n\n----------------------------------------\n\nTITLE: Conditional Dependency Specification for pywinpty (Python)\nDESCRIPTION: Specifies that the `pywinpty` package, version 2.0.2 exactly, is required only when the operating system is Windows (`sys_platform=='win32'`) and the Python version is 3.6 (`python_version=='3.6'`). This is often needed for terminal emulation on Windows within specific Python environments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_jupyter_build.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\npywinpty==2.0.2; sys_platform=='win32' and python_version=='3.6'\n```\n\n----------------------------------------\n\nTITLE: Adding Registration Tests to Open3D Test Module\nDESCRIPTION: Adds registration test source files to verify functionality of correspondence checking, fast global registration, feature extraction, global optimization, pose graph creation, and general registration techniques.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/pipelines/CMakeLists.txt#2025-04-23_snippet_2\n\nLANGUAGE: cmake\nCODE:\n```\ntarget_sources(tests PRIVATE\n    registration/CorrespondenceChecker.cpp\n    registration/FastGlobalRegistration.cpp\n    registration/Feature.cpp\n    registration/GlobalOptimization.cpp\n    registration/GlobalOptimizationConvergenceCriteria.cpp\n    registration/PoseGraph.cpp\n    registration/Registration.cpp\n    registration/TransformationEstimation.cpp\n)\n```\n\n----------------------------------------\n\nTITLE: Verifying oneAPI Installation for Open3D SYCL Development\nDESCRIPTION: Commands to verify the oneAPI installation by checking for required compilers (icx, icpx) and ensuring the Python environment is correctly set up.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/README_SYCL.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwhich icx        # /opt/intel/oneapi/compiler/<version>/linux/bin/icx\nwhich icpx       # /opt/intel/oneapi/compiler/<version>/linux/bin/icpx\nwhich python     # ${HOME}/.conda/envs/sycl/bin/python\npython --version # Python 3.8.12 :: Intel Corporation\n```\n\n----------------------------------------\n\nTITLE: Specifying Development Dependencies for Open3D\nDESCRIPTION: This snippet lists the required Python packages and their versions for Open3D development. It includes clang-format for C++ code formatting, yapf for Python code formatting, and nbformat for handling Jupyter notebooks.\nSOURCE: https://github.com/isl-org/open3d/blob/main/python/requirements_style.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nclang-format==10.0.1.1\nyapf==0.30.0\nnbformat==5.7.0\n```\n\n----------------------------------------\n\nTITLE: Conditional Azure Kinect Sensor Test Sources in CMake\nDESCRIPTION: Conditionally includes Azure Kinect sensor configuration test sources when BUILD_AZURE_KINECT is enabled.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/io/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: cmake\nCODE:\n```\nif (BUILD_AZURE_KINECT)\n    target_sources(tests PRIVATE\n        sensor/AzureKinect/AzureKinectSensorConfig.cpp\n    )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Using Callback Functions for Animation in Open3D\nDESCRIPTION: This function demonstrates how to use callback functions for animation in Open3D. It registers a Python function as the idle function of the main loop to rotate the view along the x-axis.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/customized_visualization.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef custom_draw_geometry_with_rotation(pcd):\n    def rotate_view(vis):\n        ctr = vis.get_view_control()\n        ctr.rotate(10.0, 0.0)\n        return False\n    o3d.visualization.draw_geometries_with_animation_callback([pcd],\n                                                              rotate_view)\n```\n\n----------------------------------------\n\nTITLE: Loading Painted Plaster Texture for Material in Python\nDESCRIPTION: Demonstrates how to load painted plaster-based material textures (albedo, normal, roughness) in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nmat_data = o3d.data.PaintedPlasterTexture()\n\nmat = o3d.visualization.rendering.MaterialRecord()\nmat.shader = \"defaultLit\"\nmat.albedo_img = o3d.io.read_image(mat_data.albedo_texture_path)\nmat.normal_img = o3d.io.read_image(mat_data.normal_texture_path)\nmat.roughness_img = o3d.io.read_image(mat_data.roughness_texture_path)\n```\n\n----------------------------------------\n\nTITLE: Loading Terrazzo Texture for Material in C++\nDESCRIPTION: Shows how to load terrazzo-based material textures (albedo, normal, roughness) in C++ using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_37\n\nLANGUAGE: cpp\nCODE:\n```\ndata::TerrazzoTexture mat_data;\n\nauto mat = visualization::rendering::MaterialRecord();\nmat.shader = \"defaultUnlit\";\nmat.albedo_img = io::CreateImageFromFile(mat_data.albedo_texture_path);\nmat.normal_img = io::CreateImageFromFile(mat_data.normal_texture_path);\nmat.roughness_img = io::CreateImageFromFile(mat_data.roughness_texture_path);\n```\n\n----------------------------------------\n\nTITLE: Commented SYCL Module Test Configuration in CMake for Open3D\nDESCRIPTION: This commented-out snippet shows a potential configuration for SYCL-specific tests. It includes a SYCL version of ParallelFor and sets SYCL-specific compile options. Currently not built due to CMake limitations.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/tests/core/CMakeLists.txt#2025-04-23_snippet_3\n\nLANGUAGE: CMake\nCODE:\n```\n# TODO: cmake does not currently build this test!\n# if (BUILD_SYCL_MODULE)\n#     target_sources(tests PRIVATE\n#         ParallelForSYCL.cpp\n#     )\n#     set_source_files_properties(ParallelForSYCL.cpp PROPERTIES\n#         COMPILE_OPTIONS \"-fsycl;-fsycl-targets=spir64_gen\")\n# endif()\n```\n\n----------------------------------------\n\nTITLE: Loading Juneau Image using Open3D Python\nDESCRIPTION: This Python snippet demonstrates how to load the Juneau sample image dataset using `o3d.data.JuneauImage()`. It retrieves the image path from the dataset object and loads the image using `o3d.io.read_image`.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_42\n\nLANGUAGE: python\nCODE:\n```\nimg_data = o3d.data.JuneauImage()\nimg = o3d.io.read_image(img_data.path)\n```\n\n----------------------------------------\n\nTITLE: Custom IP/Port Binding for WebRTC Server\nDESCRIPTION: Demonstrates how to set custom IP address and port for the Open3D web visualizer server using environment variables.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/visualization/web_visualizer.rst#2025-04-23_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\n# Bind to localhost:8888 (default)\npython examples/python/visualization/draw_webrtc.py\n\n# Bind to 127.0.0.1:8889\nWEBRTC_IP=127.0.0.1 WEBRTC_PORT=8889 python draw_webrtc.py\n```\n\n----------------------------------------\n\nTITLE: Building and Running RealSense Recorder in Open3D\nDESCRIPTION: Commands to build the RealSense Recorder and run it with a configuration file, saving the output to a bag file. The recorder is built using make and executed with specific command-line arguments.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/sensor/realsense.rst#2025-04-23_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nmake RealSenseRecorder\n```\n\nLANGUAGE: shell\nCODE:\n```\nbin/examples/RealSenseRecorder --config ../examples/test_data/rs_default_config.json --record test_data.bag\n```\n\n----------------------------------------\n\nTITLE: Linux-Specific Configuration for LibUSB in CMake\nDESCRIPTION: Sets up Linux-specific dependencies and build steps for LibUSB, including linking with udev and running the autogen.sh script to generate the config.h file. This ensures proper configuration on Linux systems.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/librealsense/libusb-CMakeLists.txt#2025-04-23_snippet_5\n\nLANGUAGE: CMake\nCODE:\n```\nif((NOT APPLE) AND (NOT ANDROID) AND (NOT WIN32))\n  TARGET_LINK_LIBRARIES(usb PUBLIC udev)\n  target_include_directories(usb PRIVATE ${CMAKE_CURRENT_SOURCE_DIR})\n  add_custom_command(OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/config.h\n      COMMAND ./autogen.sh\n      WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}\n      BYPRODUCTS Makefile libusb-1.0.pc\n      )\nendif()\n```\n\n----------------------------------------\n\nTITLE: Library Output Configuration\nDESCRIPTION: Configures library output directories and properties based on architecture (CPU/CUDA).\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/ml/pytorch/CMakeLists.txt#2025-04-23_snippet_4\n\nLANGUAGE: cmake\nCODE:\n```\nget_target_property(TORCH_OPS_DIR open3d_torch_ops LIBRARY_OUTPUT_DIRECTORY)\nset(TORCH_OPS_ARCH_DIR\n    \"${TORCH_OPS_DIR}/$<IF:$<BOOL:${BUILD_CUDA_MODULE}>,cuda,cpu>\")\nset_target_properties(open3d_torch_ops PROPERTIES\n    LIBRARY_OUTPUT_DIRECTORY \"${TORCH_OPS_ARCH_DIR}\"\n    ARCHIVE_OUTPUT_DIRECTORY \"${TORCH_OPS_ARCH_DIR}\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Visualizing Eagle Point Cloud Dataset in C++\nDESCRIPTION: Shows how to load the Eagle point cloud dataset and visualize it using Open3D in C++.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_1\n\nLANGUAGE: cpp\nCODE:\n```\n#include <string>\n#include <memory>\n#include \"open3d/Open3D.h\"\n\nint main() {\n    using namespace open3d;\n\n    data::EaglePointCloud dataset;\n    auto pcd = io::CreatePointCloudFromFile(dataset.GetPath());\n    visualization::Draw({pcd});\n\n    return 0;\n}\n```\n\n----------------------------------------\n\nTITLE: VTK Copyright Notice and License Terms\nDESCRIPTION: Copyright notice and BSD-style license terms for VTK software, including redistribution conditions, warranty disclaimers, and liability limitations. Authored by Ken Martin, Will Schroeder, and Bill Lorensen.\nSOURCE: https://github.com/isl-org/open3d/blob/main/3rdparty/vtk/Copyright.txt#2025-04-23_snippet_0\n\nLANGUAGE: cpp\nCODE:\n```\n/*=========================================================================\n\n  Program:   Visualization Toolkit\n  Module:    Copyright.txt\n\nCopyright (c) 1993-2015 Ken Martin, Will Schroeder, Bill Lorensen\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice,\n   this list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither name of Ken Martin, Will Schroeder, or Bill Lorensen nor the names\n   of any contributors may be used to endorse or promote products derived\n   from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS IS''\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n=========================================================================*/\n```\n\n----------------------------------------\n\nTITLE: Loading Flight Helmet Model with PBR Texture in Python\nDESCRIPTION: Demonstrates how to load the Flight Helmet GLTF model with PBR texture in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.FlightHelmetModel()\nmodel = o3d.io.read_triangle_model(dataset.path)\n```\n\n----------------------------------------\n\nTITLE: Loading Multiple Office Point Clouds in Python\nDESCRIPTION: Demonstrates how to load multiple point clouds from the Office dataset in Python using Open3D.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/tutorial/data/index.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndataset = o3d.data.OfficePointClouds()\npcds = []\nfor pcd_path in dataset.paths:\n    pcds.append(o3d.io.read_point_cloud(pcd_path))\n```\n\n----------------------------------------\n\nTITLE: Importing Open3D RPC Module in Python\nDESCRIPTION: This snippet shows how to import the open3d.io.rpc module in Python. It is inferred from the module path given in the documentation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/python_api_in/open3d.io.rpc.rst#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom open3d.io import rpc\n```\n\n----------------------------------------\n\nTITLE: Inspecting Ray Casting Results\nDESCRIPTION: Displays the keys available in the ray casting results, which include information about the ray intersection with scene geometry.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/jupyter/geometry/ray_casting.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(ans.keys())\n```\n\n----------------------------------------\n\nTITLE: Installing Open3D C++ Library on Unix\nDESCRIPTION: Command to install the Open3D C++ library on Unix-based systems after compilation.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/compilation.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake install\n```\n\n----------------------------------------\n\nTITLE: Previewing Documentation\nDESCRIPTION: Command to open the generated documentation in Google Chrome browser.\nSOURCE: https://github.com/isl-org/open3d/blob/main/docs/builddocs.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngoogle-chrome docs/_out/html/index.html\n```\n\n----------------------------------------\n\nTITLE: Adding Kernel Subdirectory in Open3D Geometry Module\nDESCRIPTION: Includes the kernel subdirectory in the CMake build process.\nSOURCE: https://github.com/isl-org/open3d/blob/main/cpp/open3d/t/geometry/CMakeLists.txt#2025-04-23_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\nadd_subdirectory(kernel)\n```"
  }
]