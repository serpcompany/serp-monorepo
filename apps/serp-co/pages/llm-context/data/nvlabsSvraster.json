[
  {
    "owner": "nvlabs",
    "repo": "svraster",
    "content": "TITLE: Installing SVRaster with CUDA Dependencies\nDESCRIPTION: Instructions for installing the Sparse Voxels Rasterizer, including installing PyTorch, required CUDA toolkit versions, and other dependencies.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\npip install -e cuda/\n```\n\n----------------------------------------\n\nTITLE: Scene Optimization for Custom Captures\nDESCRIPTION: Command for reconstructing a scene from captured images. This runs the training process and saves results to the specified output path.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --eval --source_path $DATA_PATH --model_path $OUTPUT_PATH\n```\n\n----------------------------------------\n\nTITLE: Rendering Views from Trained Model\nDESCRIPTION: Commands for rendering different view sets (training views, testing views) and evaluating results from a trained model.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython render.py $OUTPUT_PATH --skip_test --rgb_only --use_jpg\npython render.py $OUTPUT_PATH --skip_train\npython eval.py $OUTPUT_PATH\npython render_fly_through.py $OUTPUT_PATH\n```\n\n----------------------------------------\n\nTITLE: Running SVRaster Baseline Experiments in Bash\nDESCRIPTION: Shell script commands for running training on various datasets and summarizing results. The script initializes an experiment directory and runs training scripts followed by result statistics collection for five different datasets: mipnerf360, synthetic_nerf, tandt_db, dtu, and tnt.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nexp_dir=\"baseline\"\nother_cmd_args=\"\"\n\n# Run training\n./scripts/mipnerf360_run.sh     output/mipnerf360/baseline     $other_cmd_args\n./scripts/synthetic_nerf_run.sh output/synthetic_nerf/baseline $other_cmd_args\n./scripts/tandt_db_run.sh       output/tandt_db/baseline       $other_cmd_args\n./scripts/dtu_run.sh            output/dtu/baseline            $other_cmd_args\n./scripts/tnt_run.sh            output/tnt/baseline            $other_cmd_args\n\n# Summarize results\npython scripts/mipnerf360_stat.py     output/mipnerf360/baseline\npython scripts/synthetic_nerf_stat.py output/synthetic_nerf/baseline\npython scripts/tandt_db_stat.py       output/tandt_db/baseline\npython scripts/dtu_stat.py            output/dtu/baseline\npython scripts/tnt_stat.py            output/tnt/baseline\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for SVRaster\nDESCRIPTION: A requirements.txt file that lists all Python packages needed to run the SVRaster project. The dependencies are grouped by functionality, including core numerical libraries, image processing utilities, 3D geometry tools, and machine learning evaluation metrics.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\neinops\nopencv-python\n\nyacs\ntqdm\nnatsort\nargparse\npillow\nimageio\nimageio-ffmpeg\nscikit-image\n\nplyfile\nshapely\ntrimesh==4.0.4\nopen3d==0.18.0\ngpytoolbox\n\nlpips\npytorch-msssim\ngit+https://github.com/rahul-goel/fused-ssim/\n```\n\n----------------------------------------\n\nTITLE: Running Interactive Web-based Viewer\nDESCRIPTION: Command to launch an interactive web-based viewer for exploring the trained scene.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython viz.py $OUTPUT_PATH\n```\n\n----------------------------------------\n\nTITLE: Data Preparation Command for ScanNet++ Dataset in Python\nDESCRIPTION: Command for preprocessing ScanNet++ source data to prepare it for SVR. This script converts the original dataset format into a structure suitable for novel view synthesis, requiring the path to source data, output directory, and specific scene IDs.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/articles/scannetpp_dataset.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npython scripts/scannetpp_preproc.py --indir $PATH_TO_SOURCE_DATA --outdir data/scannetpp_nvs --ids $SEQUENCE_OF_SCENE_ID\n```\n\n----------------------------------------\n\nTITLE: Extracting Mesh from Optimized Scene\nDESCRIPTION: Command for generating a mesh from the optimized scene, requiring certain parameters during training for better geometry.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython extract_mesh.py $OUTPUT_PATH\n```\n\n----------------------------------------\n\nTITLE: Training Command with Sparse Depth Loss Parameter in Python\nDESCRIPTION: Command for running the training script with sparse point depth loss, which improves geometry and novel-view quality. This parameter wasn't used in the benchmark submission but was found to be helpful in later experiments.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/articles/scannetpp_dataset.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--lambda_sparse_depth 1e-2\n```\n\n----------------------------------------\n\nTITLE: Measuring Rendering Performance\nDESCRIPTION: Command to evaluate frames per second (FPS) performance for a trained model.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython render.py $OUTPUT_PATH --eval_fps\n```\n\n----------------------------------------\n\nTITLE: Running Evaluation Script for Barn Dataset\nDESCRIPTION: Shell command to execute the evaluation pipeline, first running mesh culling and then evaluation on the Barn dataset.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/scripts/eval_tnt/README.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# firstly, run cull_mesh.py to cull mesh and then \n./run.sh Barn\n```\n\n----------------------------------------\n\nTITLE: Sample Evaluation Output for Ignatius Dataset\nDESCRIPTION: Example console output showing the evaluation process including ICP iterations, point cloud processing, and final precision/recall metrics for the Ignatius dataset.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/scripts/eval_tnt/README.md#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n===========================\nEvaluating Ignatius\n===========================\npath/to/TanksAndTemples/evaluation/data/Ignatius/Ignatius_COLMAP.ply\nReading PLY: [========================================] 100%\nRead PointCloud: 6929586 vertices.\npath/to/TanksAndTemples/evaluation/data/Ignatius/Ignatius.ply\nReading PLY: [========================================] 100%\n:\nICP Iteration #0: Fitness 0.9980, RMSE 0.0044\nICP Iteration #1: Fitness 0.9980, RMSE 0.0043\nICP Iteration #2: Fitness 0.9980, RMSE 0.0043\nICP Iteration #3: Fitness 0.9980, RMSE 0.0043\nICP Iteration #4: Fitness 0.9980, RMSE 0.0042\nICP Iteration #5: Fitness 0.9980, RMSE 0.0042\nICP Iteration #6: Fitness 0.9979, RMSE 0.0042\nICP Iteration #7: Fitness 0.9979, RMSE 0.0042\nICP Iteration #8: Fitness 0.9979, RMSE 0.0042\nICP Iteration #9: Fitness 0.9979, RMSE 0.0042\nICP Iteration #10: Fitness 0.9979, RMSE 0.0042\n[EvaluateHisto]\nCropping geometry: [========================================] 100%\nPointcloud down sampled from 6929586 points to 1449840 points.\nPointcloud down sampled from 1449840 points to 1365628 points.\npath/to/TanksAndTemples/evaluation/data/Ignatius/evaluation//Ignatius.precision.ply\nCropping geometry: [========================================] 100%\nPointcloud down sampled from 5016769 points to 4957123 points.\nPointcloud down sampled from 4957123 points to 4181506 points.\n[compute_point_cloud_to_point_cloud_distance]\n[compute_point_cloud_to_point_cloud_distance]\n:\n[ViewDistances] Add color coding to visualize error\n[ViewDistances] Add color coding to visualize error\n:\n[get_f1_score_histo2]\n==============================\nevaluation result : Ignatius\n==============================\ndistance tau : 0.003\nprecision : 0.7679\nrecall : 0.7937\nf-score : 0.7806\n==============================\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies\nDESCRIPTION: This snippet lists the required Python packages and their version constraints for the project. It specifies matplotlib version 1.3 or higher and open3d version 0.10 specifically.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/scripts/eval_tnt/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nmatplotlib>=1.3\nopen3d==0.10\n```\n\n----------------------------------------\n\nTITLE: SVRaster Paper Citation in BibTeX Format\nDESCRIPTION: BibTeX citation for the SVRaster paper titled \"Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field Rendering\". The citation includes authors, journal, publication year, and arXiv reference.\nSOURCE: https://github.com/nvlabs/svraster/blob/main/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bibTeX\nCODE:\n```\n@article{Sun2024SVR,\n  title={Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field Rendering},\n  author={Cheng Sun and Jaesung Choe and Charles Loop and Wei-Chiu Ma and Yu-Chiang Frank Wang},\n  journal={ArXiv},\n  year={2024},\n  volume={abs/2412.04459},\n}\n```"
  }
]