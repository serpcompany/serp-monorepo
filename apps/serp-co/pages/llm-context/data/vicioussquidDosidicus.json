[
  {
    "owner": "vicioussquid",
    "repo": "dosidicus",
    "content": "TITLE: Implementing the DecisionEngine Class in Python\nDESCRIPTION: This Python code defines the `DecisionEngine` class, which calculates and executes decisions for a simulated squid. It initializes with a squid object and uses the `make_decision` method to weigh potential actions based on the squid's current state (hunger, anxiety, etc.), neural brain state, active memories, and personality traits (Timid, Adventurous, Greedy), incorporating randomness before selecting and triggering the highest-weighted action. Dependencies include the `random` module and a local `Personality` enum.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/DecisionEngine.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Decision engine version 1.0   April 2025\n    \nimport random\nfrom .personality import Personality\n\nclass DecisionEngine:\n    def __init__(self, squid):\n        \"\"\"\n        Initialize the DecisionEngine with a squid object.\n\n        Parameters:\n        - squid: An object representing the squid, containing attributes and methods\n                 related to its state and behaviors.\n        \"\"\"\n        self.squid = squid\n\n    def make_decision(self):\n        \"\"\"\n        Decision-making process based on the squid's neural network state and current conditions.\n        This function aims to simulate decision-making with minimal hardcoding, relying on\n        the squid's neural state and active memories.\n        \"\"\"\n        # Gather the current state of the squid\n        current_state = {\n            \"hunger\": self.squid.hunger,\n            \"happiness\": self.squid.happiness,\n            \"cleanliness\": self.squid.cleanliness,\n            \"sleepiness\": self.squid.sleepiness,\n            \"satisfaction\": self.squid.satisfaction,\n            \"anxiety\": self.squid.anxiety,\n            \"curiosity\": self.squid.curiosity,\n            \"is_sick\": self.squid.is_sick,\n            \"is_sleeping\": self.squid.is_sleeping,\n            \"has_food_visible\": bool(self.squid.get_visible_food()),\n            \"carrying_rock\": self.squid.carrying_rock,\n            \"rock_throw_cooldown\": getattr(self.squid, 'rock_throw_cooldown', 0)\n        }\n\n        # Retrieve the brain network state, which influences emergent behavior\n        brain_state = self.squid.tamagotchi_logic.squid_brain_window.brain_widget.state\n\n        # Collect active memories to influence the decision-making process\n        active_memories = self.squid.memory_manager.get_active_memories_data(3)\n        memory_influence = {}\n\n        # Process active memories to determine their influence on the current state\n        for memory in active_memories:\n            if isinstance(memory.get('raw_value'), dict):\n                for key, value in memory['raw_value'].items():\n                    if key in memory_influence:\n                        memory_influence[key] += value * 0.5  # Memory influence is half the weight of the current state\n                    else:\n                        memory_influence[key] = value * 0.5\n\n        # Apply the influence of memories to the current state\n        for key, value in memory_influence.items():\n            if key in current_state and isinstance(current_state[key], (int, float)):\n                current_state[key] = min(100, max(0, current_state[key] + value))\n\n        # Check for extreme conditions that should override neural decisions\n        if self.squid.sleepiness >= 95:\n            self.squid.go_to_sleep()\n            return \"sleeping\"\n\n        if self.squid.is_sleeping:\n            return \"sleeping\"\n\n        # Calculate decision weights for each possible action based on the neural state\n        decision_weights = {\n            \"exploring\": brain_state.get(\"curiosity\", 50) * 0.8 * (1 - (brain_state.get(\"anxiety\", 50) / 100)),\n            \"eating\": brain_state.get(\"hunger\", 50) * 1.2 if self.squid.get_visible_food() else 0,\n            \"approaching_rock\": brain_state.get(\"curiosity\", 50) * 0.7 if not self.squid.carrying_rock else 0,\n            \"throwing_rock\": brain_state.get(\"satisfaction\", 50) * 0.7 if self.squid.carrying_rock else 0,\n            \"avoiding_threat\": brain_state.get(\"anxiety\", 50) * 0.9,\n            \"organizing\": brain_state.get(\"satisfaction\", 50) * 0.5\n        }\n\n        # Adjust decision weights based on the squid's personality\n        if self.squid.personality == Personality.TIMID:\n            decision_weights[\"avoiding_threat\"] *= 1.5\n            decision_weights[\"approaching_rock\"] *= 0.7\n        elif self.squid.personality == Personality.ADVENTUROUS:\n            decision_weights[\"exploring\"] *= 1.3\n            decision_weights[\"approaching_rock\"] *= 1.2\n        elif self.squid.personality == Personality.GREEDY:\n            decision_weights[\"eating\"] *= 1.5\n\n        # Introduce randomness to make the behavior more unpredictable\n        for key in decision_weights:\n            decision_weights[key] *= random.uniform(0.85, 1.15)\n\n        # Determine the best decision based on the highest weight\n        best_decision = max(decision_weights, key=decision_weights.get)\n\n        # Implement the chosen decision\n        if best_decision == \"eating\" and self.squid.get_visible_food():\n            closest_food = min(self.squid.get_visible_food(),\n                               key=lambda f: self.squid.distance_to(f[0], f[1]))\n            self.squid.move_towards(closest_food[0], closest_food[1])\n            return \"moving_to_food\"\n        elif best_decision == \"approaching_rock\" and not self.squid.carrying_rock:\n            nearby_rocks = [d for d in self.squid.tamagotchi_logic.get_nearby_decorations(\n                self.squid.squid_x, self.squid.squid_y, 150)\n                if getattr(d, 'can_be_picked_up', False)]\n            if nearby_rocks:\n                self.squid.current_rock_target = random.choice(nearby_rocks)\n                return \"approaching_rock\"\n        elif best_decision == \"throwing_rock\" and self.squid.carrying_rock:\n            direction = random.choice([\"left\", \"right\"])\n            if self.squid.throw_rock(direction):\n                return \"throwing_rock\"\n        elif best_decision == \"organizing\" and self.squid.should_organize_decorations():\n            return self.squid.organize_decorations()\n        elif best_decision == \"avoiding_threat\" and self.squid.anxiety > 70:\n            # Move away from potential threats\n            if len(self.squid.tamagotchi_logic.poop_items) > 0:\n                self.squid.move_erratically()\n            return \"avoiding_threat\"\n\n        # Default to exploration with varying patterns\n        exploration_style = random.choice([\"normal\", \"slow\", \"erratic\"])\n        if exploration_style == \"slow\":\n            self.squid.move_slowly()\n        elif exploration_style == \"erratic\":\n            self.squid.move_erratically()\n        else:\n            self.squid.move_randomly()\n\n        return \"exploring\"\n```\n\n----------------------------------------\n\nTITLE: Initializing the MemoryManager Class in Python\nDESCRIPTION: Initializes the MemoryManager instance. Sets up the directory (`_memory`) and file paths for short-term (`ShortTerm.json`) and long-term (`LongTerm.json`) memory JSON files. Loads existing memories from these files using `load_memory`, defaulting to empty lists if files don't exist or are empty. Defines the maximum capacity (`short_term_limit`) and duration (`short_term_duration`) for short-term memory. Requires the `os` and `datetime` modules (specifically `timedelta`).\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Memory System.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass MemoryManager:\n    def __init__(self):\n        self.memory_dir = '_memory'\n        self.short_term_file = os.path.join(self.memory_dir, 'ShortTerm.json')\n        self.long_term_file = os.path.join(self.memory_dir, 'LongTerm.json')\n        self.short_term_memory = self.load_memory(self.short_term_file) or []\n        self.long_term_memory = self.load_memory(self.long_term_file) or []\n        self.short_term_limit = 50  # Maximum number of short-term memories\n        self.short_term_duration = timedelta(minutes=5)  # Duration of short-term memory\n```\n\n----------------------------------------\n\nTITLE: Eating Food Items - PyQt5 - Python\nDESCRIPTION: The eat method processes consumption logic when the squid encounters a food_item, triggering state effects such as hunger reduction, updating the squid's memory of what was eaten, and personality-specific reactions. It expects food_item as an input, and assumes integration with inventory, memory manager, and status attributes. Side effects include starting timers related to digestion and adjusting hunger, health, and happiness values. No external output or returned value is produced.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef eat(self, food_item):\n    # Handles eating behavior and applies effects\n\n```\n\n----------------------------------------\n\nTITLE: Adding Entries to Short-Term Memory in Python\nDESCRIPTION: Adds a new memory entry to the `short_term_memory` list. Creates a dictionary containing the memory's category, key, value, current timestamp (ISO format string), importance (defaulting to 1), and initial access count (1). Requires the `datetime` module. Appends this dictionary to the `self.short_term_memory` list.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Memory System.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef add_short_term_memory(self, category, key, value, importance=1):\n    memory = {\n        'category': category,\n        'key': key,\n        'value': value,\n        'timestamp': datetime.now().isoformat(),\n        'importance': importance,\n        'access_count': 1\n    }\n    self.short_term_memory.append(memory)\n```\n\n----------------------------------------\n\nTITLE: Performing Hebbian Learning Update in Python\nDESCRIPTION: The `perform_hebbian_learning` method implements the Hebbian learning rule. It first identifies 'active' neurons based on their state values (numeric value > 50 or boolean True). Then, it randomly samples a limited number of pairs of active neurons and calls `self.update_connection` for each pair, passing the neuron names and their current state values to modify the connection weight.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef perform_hebbian_learning(self):\n    active_neurons = [\n        n for n, v in self.state.items() \n        if (isinstance(v, (int, float)) and v > 50) \n        or (isinstance(v, bool) and v)\n    ]\n    \n    for i, j in random.sample(\n        [(a,b) for a in active_neurons for b in active_neurons if a != b], \n        min(5, len(active_neurons))\n    ):\n        self.update_connection(i, j, self.state[i], self.state[j])\n```\n\n----------------------------------------\n\nTITLE: Utilizing the Dosidicus Plugin API in Python\nDESCRIPTION: Demonstrates various methods available through the `tamagotchi_logic.mod_api` for plugin interaction with the Dosidicus game. Examples include UI manipulation (messages, menus), game operations (spawning items, modifying stats, adding memories), handling custom graphics, setting up timers, and registering keyboard shortcuts. Assumes access to the `tamagotchi_logic.mod_api` object provided by the game environment.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Creating Plugins.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# UI operations\napi.show_message(\"Hello world!\")\napi.register_menu(\"My Menu\")\n\n# Game operations\napi.spawn_food(x=100, y=100, is_sushi=True)\napi.modify_stat(\"happiness\", 10)  # Add 10 to happiness\napi.add_memory(\"mod\", \"action\", \"Did something cool\", importance=7)\n\n# Custom graphics\npixmap = QtGui.QPixmap(\"path/to/image.png\")\napi.register_custom_graphic(pixmap, x=200, y=200)\n\n# Timers\napi.register_timer(1000, my_timer_callback)  # Call every 1 second\n\n# Keyboard\napi.register_keyboard_shortcut(\"Ctrl+M\", my_shortcut_callback)\n```\n\n----------------------------------------\n\nTITLE: Initializing Neural Network Weights in Python\nDESCRIPTION: This snippet demonstrates the initialization of the connection weights within the neural network class. It uses a dictionary where keys are tuples representing neuron pairs (e.g., ('hunger', 'happiness')). Weights are initialized either randomly using `random.uniform(-1, 1)` or assigned pre-defined values, such as the negative correlation between 'cleanliness' and 'anxiety'. This setup occurs within the class instance (`self`).\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Example weight initialization\nself.weights = {\n    (\"hunger\", \"happiness\"): random.uniform(-1, 1),\n    (\"cleanliness\", \"anxiety\"): -0.5,  # Pre-wired negative correlation\n    # ...all possible pairwise connections...\n}\n```\n\n----------------------------------------\n\nTITLE: Moving Toward a Coordinate - PyQt5 - Python\nDESCRIPTION: The move_towards method manipulates the squid's position to approach a given (x, y) coordinate, adjusting movement vectors dynamically. Generally invoked when pursuing food or interacting with the environment, it assumes coordinates are valid and within the bounding area. The only required parameters are x and y positions. State changes are reflected in the squid's location attributes, with no return value.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef move_towards(self, x, y):\n    # Moves the squid towards a specific coordinate\n\n```\n\n----------------------------------------\n\nTITLE: Persisting and Loading Memory to/from JSON Files in Python\nDESCRIPTION: Defines methods for saving and loading memory lists. `save_memory` writes a given memory list (Python list of dictionaries) to a specified JSON file path with indentation, converting datetime objects to strings via `default=str`. `load_memory` reads a JSON file from a path if it exists, parses the JSON data, converts ISO format timestamp strings back to `datetime` objects, and returns the list; returns an empty list if the file doesn't exist. Requires `os`, `json`, and `datetime` modules.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Memory System.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef save_memory(self, memory, file_path):\n    with open(file_path, 'w') as file:\n        json.dump(memory, file, indent=4, default=str)\n\ndef load_memory(self, file_path):\n    if os.path.exists(file_path):\n        with open(file_path, 'r') as file:\n            memory = json.loads(file.read())\n            for item in memory:\n                if 'timestamp' in item:\n                    item['timestamp'] = datetime.fromisoformat(item['timestamp'])\n            return memory\n    return []\n```\n\n----------------------------------------\n\nTITLE: Saving Game State in Python\nDESCRIPTION: This method (`save_game`) serializes the complete game state, including the squid's attributes, the game logic's internal state, placed decorations, the current brain state, and memory systems. It accepts the core objects to save and an optional flag indicating if it's an autosave operation.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef save_game(self, squid, tamagotchi_logic, is_autosave=False):\n```\n\n----------------------------------------\n\nTITLE: Loading Saved Game State in Python\nDESCRIPTION: The `load_game` method is responsible for restoring the game state from a save file. It deserializes and applies saved data, including squid attributes, brain connections, memories, decorations, and the overall game logic state, allowing the player to resume a previous session.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef load_game(self):\n```\n\n----------------------------------------\n\nTITLE: Loading Squid State - PyQt5 - Python\nDESCRIPTION: The load_state method rehydrates the squid's state from a given state object or dictionary, synchronizing persistence data with current in-memory attributes. The only required parameter is state, which represents saved attribute values. This is key for game saves and restoration, assumes structural compatibility of the state object, and may trigger updates to any UI component reflecting squid status.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef load_state(self, state):\n    # Loads a saved state\n\n```\n\n----------------------------------------\n\nTITLE: Updating Squid Brain Visualization Data in Python\nDESCRIPTION: The `update_squid_brain` method collects comprehensive state information about the squid, including attributes, position, direction, and personality traits. This data package is then sent to the associated `BrainWindow` component for real-time visualization of the squid's simulated neural state.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef update_squid_brain(self):\n```\n\n----------------------------------------\n\nTITLE: Integrating Memory Retrieval into Decision-Making in Python\nDESCRIPTION: Illustrates how memories are retrieved within the `make_decision` method of another class (likely the main agent class). It calls `memory_manager` instance methods (presumably `get_all_short_term_memories` and `get_all_long_term_memories`, not fully shown) to fetch relevant memories filtered by the 'experiences' category. These retrieved memories are then combined with the `current_state` (details not shown) into a `combined_state` dictionary. This combined state, enriched with past experiences, is subsequently passed to the `squid_brain_window.make_decision` method to influence the agent's behavior.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Memory System.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef make_decision(self):\n    # ... (other code)\n    short_term_memories = self.memory_manager.get_all_short_term_memories('experiences')\n    long_term_memories = self.memory_manager.get_all_long_term_memories('experiences')\n\n    combined_state = current_state.copy()\n    combined_state.update(short_term_memories)\n    combined_state.update(long_term_memories)\n\n    decision = self.tamagotchi_logic.squid_brain_window.make_decision(combined_state)\n    # ... (rest of the decision-making process)\n```\n\n----------------------------------------\n\nTITLE: Visualizing a Triangular (New) Neuron with PyQt - Python\nDESCRIPTION: Renders a triangular neuron using QPainter and PyQt, assigning color based on the neuron's label prefix: red for stress/defense, yellow for novelty, and green for reward. The triangle is drawn at the specified position and scale, with the label centered underneath, visually distinguishing newly generated neurons from original types. Requires PyQt (QtGui, QtCore), a valid QPainter instance, and coordinates/value/label; output is a painted graphical element—limitations include hardcoded geometry and color selection.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Neurogenesis.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef draw_triangular_neuron(self, painter, x, y, value, label, scale=1.0):\\n    # Determine color by neuron type prefix\\n    if label.startswith('defense'):\\n        color = QtGui.QColor(255, 150, 150) # Light red\\n    elif label.startswith('novel'):\\n        color = QtGui.QColor(255, 255, 150) # Pale yellow\\n    else: # reward\\n        color = QtGui.QColor(150, 255, 150) # Light green\\n    painter.setBrush(color)\\n\\n    # Draw triangle\\n    triangle = QtGui.QPolygonF()\\n    size = 25 * scale\\n    triangle.append(QtCore.QPointF(x - size, y + size))\\n    triangle.append(QtCore.QPointF(x + size, y + size))\\n    triangle.append(QtCore.QPointF(x, y - size))\\n    painter.drawPolygon(triangle)\\n\\n    # Draw label\\n    painter.setPen(QtGui.QColor(0, 0, 0))\\n    font = painter.font()\\n    font.setPointSize(int(8 * scale))\\n    painter.setFont(font)\\n    painter.drawText(int(x - 30 * scale), int(y + 40 * scale), int(60 * scale), int(20 * scale), QtCore.Qt.AlignCenter, label)\n```\n\n----------------------------------------\n\nTITLE: Implementing Memory Transfer Logic from Short-Term to Long-Term in Python\nDESCRIPTION: Provides the mechanism for transferring memories. `should_transfer_to_long_term` determines if a short-term memory dictionary should be moved to long-term based on its 'importance' and 'access_count' values meeting specific thresholds (e.g., importance >= 7 or access_count >= 3). `review_and_transfer_memories` iterates through a copy of the `short_term_memory` list. For each memory, it checks if it should be transferred using `should_transfer_to_long_term`. If true, it calls `transfer_to_long_term_memory` (implementation not shown). If not transferable, it checks if the memory has expired based on its 'timestamp' and `short_term_duration`. Expired memories are removed from the `short_term_memory` list. Requires the `datetime` module.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Memory System.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef should_transfer_to_long_term(self, memory):\n    return (\n        memory['importance'] >= 7 or\n        memory['access_count'] >= 3 or\n        (memory['importance'] >= 5 and memory['access_count'] >= 2)\n    )\n\ndef review_and_transfer_memories(self):\n    for memory in list(self.short_term_memory):\n        if self.should_transfer_to_long_term(memory):\n            self.transfer_to_long_term_memory(memory['category'], memory['key'])\n        elif (datetime.now() - memory['timestamp']) > self.short_term_duration:\n            self.short_term_memory.remove(memory)\n```\n\n----------------------------------------\n\nTITLE: Performing Hebbian Learning in Python\nDESCRIPTION: Implements the Hebbian learning rule ('neurons that fire together wire together') within the `SquidBrainWindow`. This involves identifying currently active neurons based on the state, selecting random pairs among them, updating the connection weights between these pairs according to the learning rule, and logging these changes, typically triggered periodically by a timer.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nperform_hebbian_learning(self)\n```\n\n----------------------------------------\n\nTITLE: Handling Paint Events in PyQt5 Brain Widget (Python)\nDESCRIPTION: This is the core drawing method for the `BrainWidget`, triggered by Qt's event system whenever the widget needs to be repainted. It handles rendering all visual elements, including neurons (represented by circles, squares, or triangles based on type), connections between them (lines colored by weight polarity), connection weight values, and highlights for newly generated neurons.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\npaintEvent(self, event)\n```\n\n----------------------------------------\n\nTITLE: Pushing Decorations with Animation - PyQt5 - Python\nDESCRIPTION: The push_decoration method animates the act of pushing a decoration object in a specified direction, possibly leveraging the animation system. It requires the decoration reference and movement direction as input parameters, and may invoke UI updates or trigger chained behaviors. Assumes both the decoration and direction are valid.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef push_decoration(self, decoration, direction):\n    # Pushes a decoration with animation\n\n```\n\n----------------------------------------\n\nTITLE: Initializing the Squid Class - PyQt5 - Python\nDESCRIPTION: This constructor initializes a Squid object, setting references to the user interface, game logic, possible personality enum, and an optional cooldown parameter. It assigns default values for internal state management and prepares the squid for participation in the simulation. Dependencies include PyQt5, TamagotchiLogic, Personality enums, and UserInterface classes. The key parameters are user_interface (UI reference), tamagotchi_logic (optional game logic), personality (optional enum), and neuro_cooldown (optional timing parameter). The method outputs a configured Squid instance, and requires relevant object dependencies to be instantiated beforehand. The method signature does not return anything directly.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef __init__(self, user_interface, tamagotchi_logic=None, personality=None, neuro_cooldown=None):\n    # Initializes the squid with default values and sets up UI components\n\n```\n\n----------------------------------------\n\nTITLE: Consolidating Memory from Short-Term to Long-Term in Python\nDESCRIPTION: This Python code snippet illustrates the memory consolidation process. It checks if a memory item (`memory`) has a `weight` greater than a threshold (0.7). If the memory is deemed important enough, it's transferred to the long-term memory store using the `memory_manager.transfer_to_long_term_memory` method.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Consolidation\nif memory['weight'] > 0.7:  # Important memory\n    memory_manager.transfer_to_long_term_memory(memory)\n```\n\n----------------------------------------\n\nTITLE: Initializing TamagotchiLogic Game Controller in Python\nDESCRIPTION: The constructor (`__init__`) for the `TamagotchiLogic` class. It takes UI, Squid, and BrainWindow objects as arguments, initializes neurogenesis tracking, Hebbian learning, mental state cooldowns, game timers, connects UI signals, and sets up the statistics window, ensuring all components are linked before loading game state.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef __init__(self, user_interface, squid, brain_window):\n```\n\n----------------------------------------\n\nTITLE: Implementing Emergent Sleep-Wake Cycle Logic in Python\nDESCRIPTION: This Python code demonstrates logic for an emergent sleep-wake cycle. The agent decides to sleep (`self.go_to_sleep()`) primarily based on high `sleepiness` (> 90). However, the decision is probabilistic and influenced by `hunger`: the chance of resisting sleep increases with hunger level (`random.random() < hunger/100`).\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Emergent sleep-wake cycle\nif (sleepiness > 90 and \n    random.random() < hunger/100):  # Hunger affects sleep resistance\n    self.go_to_sleep()\n```\n\n----------------------------------------\n\nTITLE: Modifying Learning Rate by Personality in Python\nDESCRIPTION: This Python code demonstrates how a personality trait (`self.personality`) can influence the Hebbian learning process. If the personality is `Personality.GREEDY`, the calculated `weight_change` is multiplied by 1.5, effectively increasing the learning rate for connections potentially related to greed (e.g., food-related).\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nif self.personality == Personality.GREEDY:\n    weight_change *= 1.5  # Faster learning for food-related connections\n```\n\n----------------------------------------\n\nTITLE: Updating Game Simulation Loop in Python\nDESCRIPTION: The main game loop method (`update_simulation`) within `TamagotchiLogic`. It periodically updates the positions of dynamic objects like food and poop, updates the squid's position and internal state, manages mental states like startle and curiosity, tracks neurogenesis triggers, and updates the integrated brain representation.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef update_simulation(self):\n```\n\n----------------------------------------\n\nTITLE: Initializing Main Squid Brain Window in Python (PyQt5)\nDESCRIPTION: The constructor for the `SquidBrainWindow` class, the main application window. It initializes the window components, takes a reference to the core `tamagotchi_logic` for state updates, accepts an optional `debug_mode` flag, sets up necessary timers (e.g., for Hebbian learning updates), and creates the tab-based interface for different information displays.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n__init__(self, tamagotchi_logic, debug_mode=False)\n```\n\n----------------------------------------\n\nTITLE: Calculating Basic Hebbian Weight Change in Python\nDESCRIPTION: This snippet illustrates the core calculation for the Hebbian weight update. The `weight_change` is determined by the product of the normalized activation levels (`value1/100`, `value2/100`) of the two connected neurons, scaled by a learning rate (0.01). This implements the principle 'neurons that fire together, wire together'.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nweight_change = 0.01 * (value1/100) * (value2/100)\n```\n\n----------------------------------------\n\nTITLE: Moving the Squid - PyQt5 - Python\nDESCRIPTION: The move_squid method updates the position and animation state of the squid based on its direction, speed, and current state (i.e., awake or sleeping). It integrates logic to handle food pursuit if food is detected by the vision system, adjusts boundaries/collisions, and manages animation frame updates. Required dependencies include access to the main UI for boundaries and display updates, and connection to the squid's hunger, sleep states, and environmental sensors. The method does not accept parameters and updates state in-place, affecting visuals and positional attributes of the Squid instance.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef move_squid(self):\n    # Handles the squid's movement based on current direction and animation speed\n\n```\n\n----------------------------------------\n\nTITLE: Adding Short-Term Memory Entry in Python\nDESCRIPTION: This Python snippet shows how to add a new memory to the short-term memory store using a hypothetical `memory_manager` object. The `add_short_term_memory` method is called with parameters specifying the memory's `category`, `key` (a unique identifier or type), and `value` (often a dictionary representing state changes).\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Adding memory\nmemory_manager.add_short_term_memory(\n    category=\"interaction\",\n    key=\"rock_push\",\n    value={\"satisfaction\": +8, \"happiness\": +5}\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Entries to Long-Term Memory in Python\nDESCRIPTION: Adds a new memory entry to the `long_term_memory` list. Creates a dictionary containing the memory's category, key, value, and the current timestamp (ISO format string). Requires the `datetime` module. Appends this dictionary to the `self.long_term_memory` list. Long-term memories lack importance, access count, and expiration attributes as defined here.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Memory System.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef add_long_term_memory(self, category, key, value):\n    memory = {\n        'category': category,\n        'key': key,\n        'value': value,\n        'timestamp': datetime.now().isoformat()\n    }\n    self.long_term_memory.append(memory)\n```\n\n----------------------------------------\n\nTITLE: Initializing Brain Visualization Widget in Python\nDESCRIPTION: The constructor for the `BrainWidget` class. It sets up the initial state of the neural network visualization, including neuron positions, connections, initial state variables (like hunger, happiness), the neurogenesis tracking system, and various visualization settings. This method prepares the widget for rendering and interaction.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n__init__(self)\n```\n\n----------------------------------------\n\nTITLE: Updating Neuron State in Python\nDESCRIPTION: This Python method `update_state` selectively updates the state of specific primary neurons ('hunger', 'happiness', 'cleanliness', 'sleepiness') based on the input dictionary `new_state`. It iterates through the allowed keys and updates the internal `self.state` dictionary if the key exists in `new_state`. After updating the state, it calls `self.update_weights()` to potentially adjust connection strengths based on the new state.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef update_state(self, new_state):\n    # Only allow certain states to be modified\n    for key in ['hunger', 'happiness', 'cleanliness', 'sleepiness']:\n        if key in new_state:\n            self.state[key] = new_state[key]\n    self.update_weights()\n```\n\n----------------------------------------\n\nTITLE: Updating Specific Neuron Connection Weight in Python\nDESCRIPTION: This method in `SquidBrainWindow` updates the connection weight between two specific neurons, identified by their names (`neuron1`, `neuron2`). The update logic uses their respective activation levels (`value1`, `value2`, ranging from 0 to 100) to modify the weight, likely as part of the Hebbian learning process or direct stimulation effects.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nupdate_connection(self, neuron1, neuron2, value1, value2)\n```\n\n----------------------------------------\n\nTITLE: Updating Squid and Game Statistics in Python\nDESCRIPTION: This method (`update_statistics`) is responsible for updating the core attributes of the squid (hunger, happiness, cleanliness, sickness) and game state variables (satisfaction, anxiety, curiosity, points). It also manages transitions related to sleep.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef update_statistics(self):\n```\n\n----------------------------------------\n\nTITLE: Updating Brain Visualization from Main Window in Python\nDESCRIPTION: This method in `SquidBrainWindow` serves as the primary entry point for updating the entire brain visualization. It receives a complete `state` dictionary containing all current brain parameters and propagates these updates to the contained `BrainWidget` and potentially other relevant UI elements.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nupdate_brain(self, state)\n```\n\n----------------------------------------\n\nTITLE: Defining Memory Entry Structure in JSON\nDESCRIPTION: This JSON object defines the format for a single memory entry. It includes fields for `category` (e.g., 'food'), `value` (a description or state changes), `timestamp` (Unix timestamp), and `weight` (indicating importance, likely between 0 and 1).\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"category\": \"food\",\n    \"value\": \"Ate sushi: Hunger-20, Happiness+10\",\n    \"timestamp\": 1625097600,\n    \"weight\": 0.85\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Brain Widget State in Python\nDESCRIPTION: Updates the internal state of the `BrainWidget` with new data provided in the `new_state` dictionary. This typically involves updating variables like hunger, happiness, etc., and subsequently triggers a repaint or update of the visualization to reflect these changes.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nupdate_state(self, new_state)\n```\n\n----------------------------------------\n\nTITLE: Calculating Emergence Score Metric in Python\nDESCRIPTION: The `calculate_emergence_score` function defines a metric to quantify the complexity of learned behaviors. It calculates the average absolute value of all connection weights (`self.weights.values()`), excluding weights that are at their default initial or boundary values (-1, 0, 1). This score reflects the degree of learned adaptation in the network connections.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Behavior scoring metric\ndef calculate_emergence_score():\n    return sum(\n        abs(w) for w in self.weights.values() \n        if w not in [-1, 0, 1]  # Exclude default/min/max\n    ) / len(self.weights)\n```\n\n----------------------------------------\n\nTITLE: Defining Connection Weights Data Structure in Python\nDESCRIPTION: Illustrates the data structure used to store connection weights between neurons. It's a Python dictionary where keys are tuples representing pairs of neuron names (e.g., ('hunger', 'satisfaction')), and values are floats between -1 and 1 representing the strength and polarity of the connection.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n{\n    (\"hunger\", \"satisfaction\"): 0.75,\n    (\"happiness\", \"cleanliness\"): 0.32,\n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Plugin Directory Structure for Dosidicus\nDESCRIPTION: Specifies the standard directory layout required for a Dosidicus plugin. Each plugin should reside in its own directory under `plugins/`, containing a main Python script (`main.py`) and an optional `assets/` folder for resources.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Creating Plugins.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nplugins/\n└── plugin_name/\n    ├── main.py\n    └── assets/\n        └── (any images or other assets)\n```\n\n----------------------------------------\n\nTITLE: Updating Neuron Connection Weights Randomly in Python\nDESCRIPTION: This method within `BrainWidget` randomly adjusts the connection weights between neurons. This process is typically part of the ongoing simulation or learning mechanism but can be temporarily stopped ('frozen') via user interaction or specific states.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nupdate_weights(self)\n```\n\n----------------------------------------\n\nTITLE: Creating and Integrating a New Neuron in the Network - Python\nDESCRIPTION: Defines the method for creating new neurons when neurogenesis-triggering thresholds are reached. The method assigns a unique name based on type, computes spatial placement (randomly dispersed near active neurons), initializes neural state and visual attributes, and connects the new neuron to all existing neurons with randomized weights. It then tracks creation for visualization and updates the display. Dependencies include BrainWidget's data structures and Python's random and time modules. Inputs are neuron type and trigger data; the function modifies internal states and returns no value—limitations may involve thread safety and hardcoded color/position logic.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Neurogenesis.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef _create_neuron_internal(self, neuron_type, trigger_data):\\n    # Generate unique name (e.g., \"novel_1\", \"defense_2\")\\n    name_map = {'novelty': 'novel', 'stress': 'defense', 'reward': 'reward'}\\n    new_name = f\"{name_map[neuron_type]}_{len(self.neurogenesis_data['new_neurons'])}\"\\n\\n    # Position near an active neuron (or center if none)\\n    if self.neuron_positions:\\n        center_x = sum(x for x,y in self.neuron_positions.values())/len(self.neuron_positions)\\n        center_y = sum(y for x,y in self.neuron_positions.values())/len(self.neuron_positions)\\n    else:\\n        center_x, center_y = 600, 300\\n    self.neuron_positions[new_name] = (\\n        center_x + random.randint(-100, 100),\\n        center_y + random.randint(-100, 100)\\n    )\\n\\n    # Initialize state and color\\n    self.state[new_name] = 80  # High initial activation\\n    self.state_colors[new_name] = {\\n        'novelty': (255, 255, 150),   # Yellow\\n        'stress': (255, 150, 150),    # Red\\n        'reward': (150, 255, 150)     # Green\\n    }[neuron_type]\\n\\n    # Create connections to existing neurons\\n    for existing in self.neuron_positions:\\n        if existing != new_name:\\n            self.weights[(new_name, existing)] = random.uniform(-0.5, 0.5)\\n        if (existing, new_name) not in self.weights:\\n            self.weights[(existing, new_name)] = random.uniform(-0.5, 0.5)\\n\\n    # Update tracking data\\n    self.neurogenesis_data['new_neurons'].append(new_name)\\n    self.neurogenesis_data['last_neuron_time'] = time.time()\\n\\n    # Visual highlight\\n    self.neurogenesis_highlight = {\\n        'neuron': new_name,\\n        'start_time': time.time(),\\n        'duration': 5.0\\n    }\\n    self.update()  # Redraw the display\n```\n\n----------------------------------------\n\nTITLE: Defining Initial Neuron Positions in Python\nDESCRIPTION: This Python dictionary initialization stores the original (x, y) coordinates for visualizing each primary neuron. The `self.original_neuron_positions` dictionary maps neuron names (like 'hunger', 'happiness') to tuples representing their position on a 2D plane, likely used for graphical representation.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nself.original_neuron_positions = {\n    \"hunger\": (150, 150),       # x,y coordinates\n    \"happiness\": (450, 150),\n    # ...other positions...\n}\n```\n\n----------------------------------------\n\nTITLE: Applying Random Weight Drift in Python\nDESCRIPTION: This snippet shows how a small random change is applied to a specific connection weight (`self.weights[conn]`). It uses `random.uniform(-0.1, 0.1)` to add a small fluctuation, simulating random drift in synaptic strength as part of the network's weight dynamics.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Overview2.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nself.weights[conn] += random.uniform(-0.1, 0.1)  # Small random changes\n```\n\n----------------------------------------\n\nTITLE: Tracking Neurogenesis State in BrainWidget - Python\nDESCRIPTION: Defines dictionaries within the BrainWidget class for managing neurogenesis data, such as novelty counters, neuron lists, and the time of last neuron creation, alongside configuration parameters loaded from a JSON file. This code is responsible for persistently tracking neurogenesis enabling factors and configurations, like thresholds and cooldown periods, used throughout the simulation. Inputs include real-time experience data and configuration JSON; outputs are updated state dictionaries—limitations include reliance on accurate and up-to-date configuration.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Neurogenesis.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# In BrainWidget.__init__()\\nself.neurogenesis_data = {\\n    'novelty_counter': 0,         # Counts novel experiences\\n    'new_neurons': [],            # List of created neurons\\n    'last_neuron_time': time.time() # Timestamp of last creation\\n}\\n# Configuration from neurogenesis_config.json\\nself.neurogenesis_config = {\\n    'novelty_threshold': 3,   # Required novel experiences\\n    'stress_threshold': 0.7,  # Stress level needed\\n    'reward_threshold': 5,    # Positive outcomes needed\\n    'cooldown': 300           # 5 min cooldown (seconds)\\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Neurogenesis Conditions in Python\nDESCRIPTION: This method within `BrainWidget` evaluates the current brain `state` dictionary to determine if conditions for creating new neurons are met. It checks thresholds related to novelty, stress, and reward. Returns `True` if new neurons were successfully created as a result of these checks, `False` otherwise.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Brain Window.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ncheck_neurogenesis(self, state)\n```\n\n----------------------------------------\n\nTITLE: Getting Visible Food - PyQt5 - Python\nDESCRIPTION: The get_visible_food method identifies food items within the squid's vision cone using geometric calculations based on current orientation. The resulting set of food items can be prioritized or passed to pursuit logic such as move_towards. No parameters are required; the method operates on local environment and state data. Returns a set or list of visible food references.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef get_visible_food(self):\n    # Returns food items within the squid's vision cone\n\n```\n\n----------------------------------------\n\nTITLE: Tracking Neurogenesis Trigger Experience Data in TamagotchiLogic - Python\nDESCRIPTION: Tracks experience factors (novel objects, stress duration, reward count) that may trigger neurogenesis by maintaining counters in the TamagotchiLogic class's __init__ method. This data serves as direct input for threshold checks elsewhere in the neurogenesis process. It requires accurate event detection throughout the system; the code's use is limited to data gathering for downstream event processing.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Neurogenesis.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# In TamagotchiLogic.__init__()\\nself.neurogenesis_triggers = {\\n    'novel_objects': 0,        # Count of new objects encountered\\n    'high_stress_cycles': 0,   # Duration of stress periods\\n    'positive_outcomes': 0     # Count of rewards received\\n}\n```\n\n----------------------------------------\n\nTITLE: Tracking Neurogenesis Triggers for Brain Development in Python\nDESCRIPTION: The `track_neurogenesis_triggers` method manages counters related to brain development. It tracks events like encountering novel objects, experiencing high stress cycles, and achieving positive outcomes, which contribute to the simulated neurogenesis process.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef track_neurogenesis_triggers(self):\n```\n\n----------------------------------------\n\nTITLE: Vision Cone Membership Check - PyQt5 - Python\nDESCRIPTION: The is_in_vision_cone method determines if a provided (x, y) coordinate lies within the angular range of the squid's field of view, based on current orientation and view_cone_angle constants. The method takes coordinates as input and returns a boolean indicating membership. Used primarily for filtering relevant food or environmental targets.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef is_in_vision_cone(self, x, y):\n    # Determines if a point is within the squid's field of view\n\n```\n\n----------------------------------------\n\nTITLE: Changing the Squid's Direction - PyQt5 - Python\nDESCRIPTION: The change_direction method randomly selects a new movement direction for the squid, often used to create non-deterministic roaming behavior or to prevent boundary collisions. It does not accept parameters or return values and depends on randomization libraries and potentially boundaries defined in the UI or environment.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef change_direction(self):\n    # Randomly changes the squid's movement direction\n\n```\n\n----------------------------------------\n\nTITLE: Administering Medicine to Squid in Python\nDESCRIPTION: This method (`give_medicine`) simulates administering medicine to the squid. It cures sickness but reduces happiness and increases sleepiness. The action triggers a visual needle animation and forces the squid into a sleep state.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Tamagotchi Class.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef give_medicine(self):\n```\n\n----------------------------------------\n\nTITLE: Waking Up the Squid - PyQt5 - Python\nDESCRIPTION: The wake_up method returns the squid from a sleeping state to normal activity, restoring movement and interaction capabilities. It relies on the current internal state and does not require parameters, altering animation and activity pacing appropriately.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef wake_up(self):\n    # Wakes the squid up\n\n```\n\n----------------------------------------\n\nTITLE: Putting the Squid to Sleep - PyQt5 - Python\nDESCRIPTION: The go_to_sleep method transitions the squid into a sleeping state, halting normal movement, altering animations, and suppressing certain interactions. No parameters are required. Relies on the existing animation and state machinery to display appropriate visuals and adjust activity loops.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef go_to_sleep(self):\n    # Puts the squid to sleep\n\n```\n\n----------------------------------------\n\nTITLE: Organizing Decorations (Hoarding) - PyQt5 - Python\nDESCRIPTION: The organize_decorations method enables personality-dependent hoarding behavior, prompting the squid to reposition nearby decorations in a preferred manner. It is most relevant for defined personalities (e.g., GREEDY) and does not take parameters or return a value. Assumes access to the current decoration objects within reachable proximity.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Squid Class.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef organize_decorations(self):\n    # Hoards nearby decorations (personality-specific behavior)\n\n```\n\n----------------------------------------\n\nTITLE: Example RemoteSquidController Initialization Debug Output\nDESCRIPTION: Provides sample log messages generated when the `RemoteSquidController` is initialized, assuming debug mode is enabled. These logs show the controller confirming initialization, setting a randomized return time for the visit, and determining the direction the squid needs to travel to return home. This output is useful for debugging the autopilot's setup and initial state.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/multiplayer/squid_multiplayer_autopilot.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n[AutoPilot] Initialized for squid at (x, y)\n[AutoPilot] Will return home after 120 seconds\n[AutoPilot] Home direction: left\n```\n\n----------------------------------------\n\nTITLE: Re-identifying the Curiosity Goal Neuron\nDESCRIPTION: This snippet reiterates the `Curiosity` Goal Neuron, emphasizing its role in affecting how the squid reacts to its environment and noting that it's naturally high across different personality types.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Goal Neurons.md#_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\n`Curiosity`\n```\n\n----------------------------------------\n\nTITLE: Describing the Satisfied Squid State\nDESCRIPTION: This snippet uses the term `satisified` (likely a typo for 'satisfied') to describe the desired state of the squid, which is achieved when the `Satisfaction` Goal Neuron has a high value.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Goal Neurons.md#_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\n`satisified`\n```\n\n----------------------------------------\n\nTITLE: Identifying the Anxiety Goal Neuron\nDESCRIPTION: This snippet identifies `Anxiety` as one of the three core 'Goal Neurons'. Its value is dynamically adjusted by other neurons and personality. A key gameplay challenge is to keep the `Anxiety` level low.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Goal Neurons.md#_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n`Anxiety`\n```\n\n----------------------------------------\n\nTITLE: Identifying the Satisfaction Goal Neuron\nDESCRIPTION: This snippet identifies `Satisfaction` as one of the three core 'Goal Neurons'. Its value is dynamically adjusted by other neurons and personality. A key gameplay challenge is to keep the `Satisfaction` level high for a happy squid.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Goal Neurons.md#_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n`Satisfaction`\n```\n\n----------------------------------------\n\nTITLE: Identifying the Curiosity Goal Neuron\nDESCRIPTION: This snippet identifies `Curiosity` as one of the three core 'Goal Neurons' in the squid simulation. Its value is set dynamically, influenced by other neurons and personality, and affects how the squid reacts to its environment. Squids generally have high curiosity.\nSOURCE: https://github.com/vicioussquid/dosidicus/blob/main/Docs/Goal Neurons.md#_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n`Curiosity`\n```"
  }
]