[
  {
    "owner": "kubernetes-sigs",
    "repo": "cluster-api-provider-azure",
    "content": "TITLE: Management Cluster Setup Commands\nDESCRIPTION: Commands for creating a kind cluster and setting up Helm repositories for CAPI operator installation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/getting-started.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkind create cluster\n```\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add capi-operator https://kubernetes-sigs.github.io/cluster-api-operator\nhelm repo add jetstack https://charts.jetstack.io --force-update\nhelm repo update\n```\n\nLANGUAGE: bash\nCODE:\n```\nhelm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --set crds.enabled=true\n```\n\n----------------------------------------\n\nTITLE: Deploying a Cluster with MachinePool using clusterctl\nDESCRIPTION: This shell command uses 'clusterctl generate' to create a cluster configuration file named 'my-cluster.yaml'. It specifies the cluster name 'my-cluster', the desired Kubernetes version 'v1.22.0', and crucially uses the '--flavor machinepool' option. This flavor ensures that the generated configuration includes the necessary MachinePool and AzureMachinePool resources instead of the default MachineDeployment/AzureMachine setup. Prerequisites include having clusterctl installed and the Azure environment configured as per Cluster API documentation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/machinepools.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n```shell\nclusterctl generate cluster my-cluster --kubernetes-version v1.22.0 --flavor machinepool > my-cluster.yaml\n```\n```\n\n----------------------------------------\n\nTITLE: CAPI Operator Installation\nDESCRIPTION: Helm command to install the CAPI operator with custom values.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/getting-started.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nhelm install capi-operator capi-operator/cluster-api-operator --create-namespace -f values.yaml --wait --timeout 90s\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Cluster with clusterctl\nDESCRIPTION: Command to generate a cluster configuration with a customized template from the Azure provider and apply it to create a new cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/introduction.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nclusterctl generate cluster my-cluster \\\\n  --kubernetes-version v1.24.6 \\\\n  --control-plane-machine-count=3 \\\\n  --worker-machine-count=3 \\\\n  > my-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Deploying IIS Workload on Windows Kubernetes Cluster - YAML Manifest\nDESCRIPTION: This YAML snippet defines a Deployment and a Service for running an IIS web server container on a Windows-based Kubernetes node. The Deployment section specifies a single-container pod using the Microsoft IIS image, resource constraints for CPU and memory, and nodeSelector to ensure scheduling on Windows nodes. The Service is of type LoadBalancer, making the IIS web server accessible externally on port 80. Required dependencies include access to a configured Windows Kubernetes cluster, cluster networking setup, and appropriate permissions for applying resources. Inputs are the manifest file; outputs are the deployed pod and service. It is limited to clusters with Windows node support.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/windows.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: iis-1809\\n  labels:\\n    app: iis-1809\\nspec:\\n  replicas: 1\\n  template:\\n    metadata:\\n      name: iis-1809\\n      labels:\\n        app: iis-1809\\n    spec:\\n      containers:\\n      - name: iis\\n        image: mcr.microsoft.com/windows/servercore/iis:windowsservercore-ltsc2019\\n        resources:\\n          limits:\\n            cpu: 1\\n            memory: 800m\\n          requests:\\n            cpu: .1\\n            memory: 300m\\n        ports:\\n          - containerPort: 80\\n      nodeSelector:\\n        \\\"kubernetes.io/os\\\": windows\\n  selector:\\n    matchLabels:\\n      app: iis-1809\\n---\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: iis\\nspec:\\n  type: LoadBalancer\\n  ports:\\n  - protocol: TCP\\n    port: 80\\n  selector:\\n    app: iis-1809\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureCluster with Pre-existing VNet and Subnets (YAML)\nDESCRIPTION: This YAML snippet demonstrates how to configure an AzureCluster resource to use a pre-existing Azure Virtual Network (VNet) and associated subnets. It specifies the resource group and name of the existing VNet, along with the names and roles (control-plane, node) of the subnets. Optional security group and route table names can also be provided for the subnets. This setup requires the VNet and subnets to already exist in Azure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-byo-vnet\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      resourceGroup: custom-vnet\n      name: my-vnet\n    subnets:\n      - name: my-control-plane-subnet\n        role: control-plane\n        securityGroup:\n          name: my-control-plane-nsg\n      - name: my-node-subnet\n        role: node\n        routeTable:\n          name: my-node-routetable\n        securityGroup:\n          name: my-node-nsg\n  resourceGroup: cluster-byo-vnet\n```\n\n----------------------------------------\n\nTITLE: Azure Cluster Identity Configuration\nDESCRIPTION: YAML configuration for AzureClusterIdentity object defining authentication details for cluster deployment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/getting-started.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  labels:\n    clusterctl.cluster.x-k8s.io/move-hierarchy: \"true\"\n  name: <cluster-identity-name>\n  namespace: default\nspec:\n  allowedNamespaces: {}\n  clientID: <clientID>\n  clientSecret:\n    name: <client-secret-name>\n    namespace: <client-secret-namespace>\n  tenantID: <tenantID>\n  type: ServicePrincipal\n```\n\n----------------------------------------\n\nTITLE: Complete AzureMachineTemplate Example for Workload Identity (YAML)\nDESCRIPTION: This YAML snippet provides a full example manifest for an AzureMachineTemplate configured with user-assigned managed identity. Key fields include disk sizing, SSH public key, and VM size in addition to the required identity fields. Placeholders must be replaced with actual values.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureMachineTemplate\\nmetadata:\\n  name: ${CLUSTER_NAME}-md-0\\n  namespace: default\\nspec:\\n  template:\\n    spec:\\n      osDisk:\\n        diskSizeGB: 128\\n        osType: Linux\\n      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=\"\"}\\n      identity: UserAssigned\\n      userAssignedIdentities:\\n      - providerID: /subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/${USER_ASSIGNED_IDENTITY_NAME}\\n      vmSize: ${AZURE_NODE_MACHINE_TYPE}\n```\n\n----------------------------------------\n\nTITLE: Extending Default Security Rules in AzureCluster Subnets (YAML)\nDESCRIPTION: This YAML snippet illustrates how to extend the default network security rules for an AzureCluster's control-plane subnet without overriding the built-in rules for SSH and API server access. It adds a new inbound rule (`allow_port_9345`) to permit traffic on TCP port 9345, useful for scenarios like RKE2 node registration. It also demonstrates adding an additional port (9345) to the API Server Load Balancer via `additionalAPIServerLBPorts`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.0.0.0/16\n    additionalAPIServerLBPorts:\n      - name: RKE2\n        port: 9345\n    subnets:\n      - name: my-subnet-cp\n        role: control-plane\n        cidrBlocks:\n          - 10.0.1.0/24\n        securityGroup:\n          name: my-subnet-cp-nsg\n          securityRules:\n            - name: \"allow_port_9345\"\n              description: \"RKE2 - allow node registration on port 9345\"\n              direction: \"Inbound\"\n              priority: 2202\n              protocol: \"Tcp\"\n              destination: \"*\"\n              destinationPorts: \"9345\"\n              source: \"*\"\n              sourcePorts: \"*\"\n              action: \"Allow\"\n      - name: my-subnet-node\n        role: node\n        cidrBlocks:\n          - 10.0.2.0/24\n  resourceGroup: cluster-example\n```\n\n----------------------------------------\n\nTITLE: Setting Azure Environment Variables for Workload Cluster Creation (Bash)\nDESCRIPTION: This multi-line Bash snippet sets environment variables required for generating workload cluster YAML manifests on Azure using clusterctl. It includes Azure subscription, client, tenant IDs, preferred locations, and placeholders for identity variables. These values are referenced in clusterctl templates and YAML resources. Required: accounts and credentials must be valid before using these variables.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport AZURE_SUBSCRIPTION_ID=<your-azure-subscription-id>\\n# This is the client ID of the AAD app or user-assigned identity that you used to created the federated identity.\\nexport AZURE_CLIENT_ID=<your-azure-client-id>\\nexport AZURE_TENANT_ID=<your-azure-tenant-id>\\nexport AZURE_CONTROL_PLANE_MACHINE_TYPE=\"Standard_B2s\"\\nexport AZURE_NODE_MACHINE_TYPE=\"Standard_B2s\"\\nexport AZURE_LOCATION=\"eastus\"\\n\\n# Identity secret. Though these are not used in workload identity, we still\\n# need to set them for the sake of generating the workload cluster YAML configuration\\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAME=\"cluster-identity-secret\"\\nexport CLUSTER_IDENTITY_NAME=\"cluster-identity\"\\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAMESPACE=\"default\"\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentity for Workload Identity in Kubernetes (YAML)\nDESCRIPTION: This YAML snippet defines an `AzureClusterIdentity` Kubernetes resource configured to use the 'WorkloadIdentity' type. It requires specifying the Azure Tenant ID (`tenantID`), the Client ID (`clientID`) of the identity associated with the workload, and the Kubernetes namespaces (`allowedNamespaces`) where this identity can be used.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  name: cluster-identity\nspec:\n  type: WorkloadIdentity\n  tenantID: <your-tenant-id>\n  clientID: <your-client-id>\n  allowedNamespaces:\n    list:\n    - <cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Installing Calico via Helm with IPv4 - Bash\nDESCRIPTION: This command installs Calico on a workload cluster for IPv4-only networking using the official Helm chart. It adds the Calico chart repo, installs the tigera-operator with a specified values.yaml file, and injects the cluster's pod CIDR via the --set-string argument. Prerequisites include Helm, cluster access, and an assigned IPV4_CIDR_BLOCK environment variable.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add projectcalico https://docs.tigera.io/calico/charts && \\\nhelm install calico projectcalico/tigera-operator --version v3.26.1 -f https://raw.githubusercontent.com/kubernetes-sigs/cluster-api-provider-azure/main/templates/addons/calico/values.yaml --set-string \"installation.calicoNetwork.ipPools[0].cidr=${IPV4_CIDR_BLOCK}\" --namespace tigera-operator --create-namespace\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureCluster for VNet Peering (YAML)\nDESCRIPTION: This YAML snippet shows how to configure an AzureCluster resource to establish VNet peering between the cluster's newly created VNet and one or more pre-existing VNets. The `networkSpec.vnet.peerings` section lists the resource group and name of each remote VNet to be peered. The cluster's VNet CIDR and subnet configurations are also defined. Currently, peering is limited to VNets within the same Azure subscription.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-vnet-peering\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.255.0.0/16\n      peerings:\n      - resourceGroup: vnet-peering-rg\n        remoteVnetName: existing-vnet-1\n      - resourceGroup: vnet-peering-rg\n        remoteVnetName: existing-vnet-2\n    subnets:\n      - name: my-subnet-cp\n        role: control-plane\n        cidrBlocks:\n          - 10.255.0.0/24\n      - name: my-subnet-node\n        role: node\n        cidrBlocks:\n          - 10.255.1.0/24\n  resourceGroup: cluster-vnet-peering\n```\n\n----------------------------------------\n\nTITLE: Configuring User-assigned Managed Identity on AzureMachineTemplate - YAML\nDESCRIPTION: This YAML manifest configures an AzureMachineTemplate with a user-assigned managed identity for CAPZ. The 'identity' field is set to 'UserAssigned', and one or more identities are referenced in the 'userAssignedIdentities' list. Only the first listed identity will be used for cloud provider authentication by CAPZ; others can be used for additional workloads. Dependencies: CAPZ controller, the specified user-assigned identity pre-created in Azure, correct providerID value(s). Inputs: template values (e.g., cluster name, identity provider ID). Outputs: VMs with user-assigned AAD identity attached. The identity needs proper permissions such as 'Contributor' on the resource group or subscription.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureMachineTemplate\\nmetadata:\\n  name: ${CLUSTER_NAME}-md-0\\n  namespace: default\\nspec:\\n  template:\\n    spec:\\n      identity: UserAssigned\\n      userAssignedIdentities:\\n      - providerID: ${USER_ASSIGNED_IDENTITY_PROVIDER_ID}\\n      ...\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Subnets in AzureCluster and Referencing in AzureMachinePool YAML\nDESCRIPTION: This multi-document YAML snippet illustrates defining multiple subnets within an `AzureCluster` (`control-plane-subnet`, `subnet-mp-1`, `subnet-mp-2`) with distinct roles. It then shows how `AzureMachinePool` resources (`mp1`, `mp2`) can reference specific `node` subnets using the `subnetName` field in their templates, allowing different node pools to reside in different subnets. Specifying `subnetName` becomes mandatory when multiple subnets with the `node` role are defined.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    subnets:\n    - name: control-plane-subnet\n      role: control-plane\n    - name: subnet-mp-1\n      role: node\n    - name: subnet-mp-2\n      role: node\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.0.0.0/16\n  resourceGroup: cluster-example\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: mp1\n  namespace: default\nspec:\n  location: southcentralus\n  strategy:\n    rollingUpdate:\n      deletePolicy: Oldest\n      maxSurge: 25%\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    osDisk:\n      diskSizeGB: 30\n      managedDisk:\n        storageAccountType: Premium_LRS\n      osType: Linux\n    sshPublicKey: ${YOUR_SSH_PUB_KEY}\n    subnetName: subnet-mp-1\n    vmSize: Standard_B2s\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: mp2\n  namespace: default\nspec:\n  location: southcentralus\n  strategy:\n    rollingUpdate:\n      deletePolicy: Oldest\n      maxSurge: 25%\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    osDisk:\n      diskSizeGB: 30\n      managedDisk:\n        storageAccountType: Premium_LRS\n      osType: Linux\n    sshPublicKey: ${YOUR_SSH_PUB_KEY}\n    subnetName: subnet-mp-2\n    vmSize: Standard_B2s\n```\n\n----------------------------------------\n\nTITLE: Azure CLI Authentication and Setup\nDESCRIPTION: Series of Azure CLI commands to authenticate, select subscription and create service principal for CAPZ deployment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/getting-started.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naz login\n```\n\nLANGUAGE: bash\nCODE:\n```\naz account list -o table\n```\n\nLANGUAGE: bash\nCODE:\n```\naz account set -s <SubscriptionId>\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport AZURE_SUBSCRIPTION_ID=\"<SubscriptionId>\"\n```\n\nLANGUAGE: bash\nCODE:\n```\naz ad sp create-for-rbac --role contributor --scopes=\"/subscriptions/${AZURE_SUBSCRIPTION_ID}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Private DNS Zone Name in AzureCluster (YAML)\nDESCRIPTION: This YAML configuration defines an `AzureCluster` resource for Cluster API Provider Azure (CAPZ). It specifies a custom `privateDNSZoneName` (\"kubernetes.myzone.com\") within the `networkSpec`. This customization requires the `apiServerLB.type` to be set to `Internal`, which is also configured here along with VNet and subnet details. The default DNS zone name (`${CLUSTER_NAME}.capz.io`) is overridden by this setting.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-dns.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    privateDNSZoneName: \"kubernetes.myzone.com\"\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.0.0.0/16\n    subnets:\n      - name: my-subnet-cp\n        role: control-plane\n        cidrBlocks:\n          - 10.0.1.0/24\n      - name: my-subnet-node\n        role: node\n        cidrBlocks:\n          - 10.0.2.0/24\n    apiServerLB:\n      type: Internal\n      frontendIPs:\n        - name: lb-private-ip-frontend\n          privateIP: 172.16.0.100\n  resourceGroup: cluster-example\n```\n\n----------------------------------------\n\nTITLE: Creating MachinePool for Self-Managed VMSS in AKS\nDESCRIPTION: This YAML configuration defines the resources needed to add a self-managed VMSS node pool to a CAPZ-managed AKS cluster. It includes MachinePool, AzureMachinePool, and KubeadmConfig resources with customizable parameters.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster-join-vmss.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachinePool\nmetadata:\n  name: ${CLUSTER_NAME}-vmss\n  namespace: default\nspec:\n  clusterName: ${CLUSTER_NAME}\n  replicas: ${WORKER_MACHINE_COUNT}\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfig\n          name: ${CLUSTER_NAME}-vmss\n      clusterName: ${CLUSTER_NAME}\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachinePool\n        name: ${CLUSTER_NAME}-vmss\n      version: ${KUBERNETES_VERSION}\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: ${CLUSTER_NAME}-vmss\n  namespace: default\nspec:\n  location: ${AZURE_LOCATION}\n  strategy:\n    rollingUpdate:\n      deletePolicy: Oldest\n      maxSurge: 25%\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    osDisk:\n      diskSizeGB: 30\n      managedDisk:\n        storageAccountType: Premium_LRS\n      osType: Linux\n    sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=\"\"}\n    vmSize: ${AZURE_NODE_MACHINE_TYPE}\n---\napiVersion: bootstrap.cluster.x-k8s.io/v1beta1\nkind: KubeadmConfig\nmetadata:\n  name: ${CLUSTER_NAME}-vmss\n  namespace: default\nspec:\n  files:\n  - contentFrom:\n      secret:\n        key: worker-node-azure.json\n        name: ${CLUSTER_NAME}-vmss-azure-json\n    owner: root:root\n    path: /etc/kubernetes/azure.json\n    permissions: \"0644\"\n  - contentFrom:\n      secret:\n        key: value\n        name: ${CLUSTER_NAME}-kubeconfig\n    owner: root:root\n    path: /etc/kubernetes/admin.conf\n    permissions: \"0644\"\n  joinConfiguration:\n    discovery:\n      file:\n        kubeConfigPath: /etc/kubernetes/admin.conf\n    nodeRegistration:\n      kubeletExtraArgs:\n        cloud-provider: external\n      name: '{{ ds.meta_data[\"local_hostname\"] }}'\n  preKubeadmCommands:\n  - kubeadm init phase upload-config all\n```\n\n----------------------------------------\n\nTITLE: Defining AzureMachineTemplate for Confidential VM Control Plane Nodes - YAML\nDESCRIPTION: This YAML manifest details an AzureMachineTemplate for Cluster API setups where control-plane nodes are deployed as Confidential VMs on Azure. It specifies a custom compute gallery image (built for Confidential VM use), sets the security type to ConfidentialVM, enables vTPM and Secure Boot, configures storage encryption, and selects a supported VM size. Dependencies include valid image IDs in Azure, Cluster API infrastructure controllers, and supported VM/OS selection. Primary inputs are Azure subscription info, resource groups, secure image/galleries, and configuration settings; the output is a template ready for use with Cluster API deployment workflows.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/confidential-vms.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nkind: AzureMachineTemplate\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nmetadata:\n  name: capz-confidential-vms-example\nspec:\n  template:\n    spec:\n      image:\n        computeGallery:\n          subscriptionID: \"01234567-89ab-cdef-0123-4567890abcde\"\n          resourceGroup: \"cluster-api-images\"\n          gallery: \"ClusterAPI\"\n          name: \"capi-ubuntu-2204-cvm-1684153817\"\n          version: \"0.3.1684153817\"\n      securityProfile:\n        securityType: \"ConfidentialVM\"\n        uefiSettings:\n          vTpmEnabled: true\n          secureBootEnabled: true\n      osDisk:\n        diskSizeGB: 128\n        osType: \"Linux\"\n        managedDisk:\n          storageAccountType: \"Premium_LRS\"\n          securityProfile:\n            securityEncryptionType: \"VMGuestStateOnly\"\n      vmSize: \"Standard_DC4as_v5\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Public API Server LB with BYO Public IP - CAPZ YAML\nDESCRIPTION: This YAML describes how to configure an AzureCluster resource with the API server exposed publicly, assigning a specific, user-managed public IP with an FQDN. The apiServerLB.type is set to Public, and frontendIPs contains a publicIP property referencing the desired Azure Public IP resource with an explicit dnsName. The public IP referenced here must exist prior to use and is not managed by CAPZ lifecycle (i.e., not deleted during cluster teardown). This setup is used when a stable static endpoint and DNS name is required for the control plane while using CAPZ.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/api-server-endpoint.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureCluster\\nmetadata:\\n  name: my-cluster\\n  namespace: default\\nspec:\\n  location: eastus\\n  networkSpec:\\n    apiServerLB:\\n      type: Public\\n      frontendIPs:\\n        - name: lb-public-ip-frontend\\n          publicIP:\\n            name: my-public-ip\\n            dnsName: my-cluster-986b4408.eastus.cloudapp.azure.com\\n\n```\n\n----------------------------------------\n\nTITLE: Setting Azure Authentication and Identity Variables from Service Principal (Bash)\nDESCRIPTION: This snippet exports required authentication and identity environment variables by reading the previously generated sp.json file with jq and tr. It also specifies machine types for control plane and worker nodes, as well as identity secret details. Dependencies are jq for JSON parsing, a valid sp.json, and Bash shell. These variables are prerequisites for provisioning and managing Azure resources securely.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport AZURE_SUBSCRIPTION_ID=\"$(cat sp.json | jq -r .subscriptionId | tr -d '\\n')\"\nexport AZURE_CLIENT_SECRET=\"$(cat sp.json | jq -r .clientSecret | tr -d '\\n')\"\nexport AZURE_CLIENT_ID=\"$(cat sp.json | jq -r .clientId | tr -d '\\n')\"\nexport AZURE_CONTROL_PLANE_MACHINE_TYPE=\"Standard_D2s_v3\"\nexport AZURE_NODE_MACHINE_TYPE=\"Standard_D2s_v3\"\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAME=\"cluster-identity-secret\"\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAMESPACE=\"default\"\nexport CLUSTER_IDENTITY_NAME=\"cluster-identity\"\n```\n\n----------------------------------------\n\nTITLE: Specifying User-Assigned Managed Identity in AzureMachineTemplate (YAML)\nDESCRIPTION: This YAML fragment demonstrates how to include a user-assigned managed identity in the spec for AzureMachineTemplate resources. It sets identity: UserAssigned and lists userAssignedIdentities by providerID. Prerequisites: all environment variables must be substituted. Used in both control plane and worker node templates.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nidentity: UserAssigned\\nuserAssignedIdentities:\\n- providerID: /subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/${USER_ASSIGNED_IDENTITY_NAME}\n```\n\n----------------------------------------\n\nTITLE: Installing Cluster API Provider for Azure with clusterctl\nDESCRIPTION: Command to initialize the Kubernetes Cluster API with Azure provider using clusterctl. This sets up the Cluster API with Azure as the infrastructure provider.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/introduction.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nclusterctl init --infrastructure azure\n```\n\n----------------------------------------\n\nTITLE: Configuring and Mounting Data Disks and File Systems with Kubeadm and AzureMachine (YAML)\nDESCRIPTION: This YAML snippet provides a full example of configuring partitions, file systems, and mounting data disks for a Kubernetes control plane using KubeadmControlPlane and AzureMachineTemplate resources. It shows how to define partition and file system details (diskSetup), configure persistent mounts, and specify additional Azure-managed data disks with LUN assignments and storage profiles. Dependencies include Kubernetes Cluster API, Kubeadm, and Azure infrastructure types. Parameters such as device, tableType, or storageAccountType specify disk characteristics; expected input is a rendered YAML manifest, and output is a properly provisioned VM meeting the storage setup described. Ensure fields like 'lun' in both disk setup and dataDisks match for consistency.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/data-disks.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nkind: KubeadmControlPlane\napiVersion: controlplane.cluster.x-k8s.io/v1beta1\nmetadata:\n  name: \"${CLUSTER_NAME}-control-plane\"\nspec:\n    [...]\n    diskSetup:\n      partitions:\n        - device: /dev/disk/azure/scsi1/lun0\n          tableType: gpt\n          layout: true\n          overwrite: false\n        - device: /dev/disk/azure/scsi1/lun1\n          tableType: gpt\n          layout: true\n          overwrite: false\n      filesystems:\n        - label: etcd_disk\n          filesystem: ext4\n          device: /dev/disk/azure/scsi1/lun0\n          extraOpts:\n            - \"-E\"\n            - \"lazy_itable_init=1,lazy_journal_init=1\"\n        - label: ephemeral0\n          filesystem: ext4\n          device: ephemeral0.1\n          replaceFS: ntfs\n        - label: my_disk\n          filesystem: ext4\n          device: /dev/disk/azure/scsi1/lun1\n    mounts:\n      - - LABEL=etcd_disk\n        - /var/lib/etcddisk\n      - - LABEL=my_disk\n        - /var/lib/mydir\n---\nkind: AzureMachineTemplate\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nmetadata:\n  name: \"${CLUSTER_NAME}-control-plane\"\nspec:\n  template:\n    spec:\n      [...]\n      dataDisks:\n        - nameSuffix: etcddisk\n          diskSizeGB: 256\n          managedDisk:\n            storageAccountType: Standard_LRS\n          lun: 0\n        - nameSuffix: mydisk\n          diskSizeGB: 128\n          lun: 1\n```\n\n----------------------------------------\n\nTITLE: Creating AzureMachineTemplate with Custom Image\nDESCRIPTION: This YAML snippet demonstrates how to create an `AzureMachineTemplate` by specifying a custom image from the Azure Compute Gallery. Required fields include `resourceGroup`, `name`, `subscriptionID`, `gallery`, and `version`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: capz-compute-gallery-example\nspec:\n  template:\n    spec:\n      image:\n        computeGallery:\n          resourceGroup: \"cluster-api-images\"\n          name: \"capi-1234567890\"\n          subscriptionID: \"01234567-89ab-cdef-0123-4567890abcde\"\n          gallery: \"ClusterAPI\"\n          version: \"0.3.1234567890\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Internal API Server Load Balancer with CAPZ YAML\nDESCRIPTION: This YAML configuration defines an AzureCluster resource with the API server load balancer set to Internal mode via the networkSpec.apiServerLB.type property. It sets fundamental Kubernetes and Azure properties including name, namespace, location, and the internal-only load balancer. No additional VNet or subnet customizations are provided in this minimal example. Prerequisites include having Cluster API and the Azure infrastructure provider (CAPZ) installed. This snippet is used for setting up a private cluster where the API is only reachable within the Azure VNet.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/api-server-endpoint.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureCluster\\nmetadata:\\n  name: my-private-cluster\\n  namespace: default\\nspec:\\n  location: eastus\\n  networkSpec:\\n    apiServerLB:\\n      type: Internal\\n\n```\n\n----------------------------------------\n\nTITLE: Building Trusted Launch Image with Image Builder in Bash\nDESCRIPTION: This snippet demonstrates the use of the image-builder tool to create a custom Azure VM image that is compliant with trusted launch requirements. It targets Ubuntu Server 22.04 LTS as the base image for generation 2 VMs and requires the image-builder tool to be installed.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/trusted-launch-for-vms.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ make -C images/capi build-azure-sig-ubuntu-2204-gen2\n# many minutes later...\n==> sig-ubuntu-2204-gen2:\nBuild 'sig-ubuntu-2204-gen2' finished.\n\n==> Builds finished. The artifacts of successful builds are:\n--> sig-ubuntu-2204-gen2: Azure.ResourceManagement.VMImage:\n\nOSType: Linux\nManagedImageResourceGroupName: cluster-api-images\nManagedImageName: capi-ubuntu-2204-gen2-1684153817\nManagedImageId: /subscriptions/01234567-89ab-cdef-0123-4567890abcde/resourceGroups/cluster-api-images/providers/Microsoft.Compute/images/capi-ubuntu-2204-gen2-1684153817\nManagedImageLocation: southcentralus\nManagedImageSharedImageGalleryId: /subscriptions/01234567-89ab-cdef-0123-4567890abcde/resourceGroups/cluster-api-images/providers/Microsoft.Compute/galleries/ClusterAPI/images/capi-ubuntu-2204-gen2/versions/0.3.1684153817\n```\n\n----------------------------------------\n\nTITLE: Defining an AzureASOManagedCluster with ResourceGroup in YAML\nDESCRIPTION: Example YAML defining a basic AzureASOManagedCluster resource with an embedded ASO ResourceGroup. This demonstrates the new pattern of defining Azure resources inline within CAPZ resources using the spec.resources field.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/asomanagedcluster.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1alpha1\nkind: AzureASOManagedCluster\nmetadata:\n  name: my-cluster\n  namespace: default\nspec:\n  resources:\n  - apiVersion: resources.azure.com/v1api20200601\n    kind: ResourceGroup\n    metadata:\n      name: my-resource-group\n    spec:\n      location: eastus\n```\n\n----------------------------------------\n\nTITLE: Watching Cluster API Resource Progression (Bash)\nDESCRIPTION: Uses the `kubectl get cluster-api` command (assuming a plugin or alias `cluster-api` is configured for `kubectl get clusters,machines,machinedeployments,...`) to monitor the status and progression of all core Cluster API resources on the management cluster. This provides a high-level overview of the cluster provisioning process.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get cluster-api\n```\n\n----------------------------------------\n\nTITLE: Configuring Control Plane Outbound Load Balancer - CAPZ YAML\nDESCRIPTION: This YAML snippet provides an example configuration for setting up a control plane outbound load balancer by specifying the 'controlPlaneOutboundLB' block within an AzureCluster resource. It is intended for private clusters (with 'apiServerLB' type as 'Internal') in CAPZ and demonstrates how to allocate a single frontend IP ('frontendIPsCount: 1'). The snippet is designed to be used with CAPZ and Kubernetes, and modifying 'controlPlaneOutboundLB' after creation is not supported and will result in validation errors.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/control-plane-outbound-lb.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureCluster\\nmetadata:\\n  name: my-private-cluster\\n  namespace: default\\nspec:\\n  location: eastus\\n  networkSpec:\\n    apiServerLB:\\n      type: Internal\\n    controlPlaneOutboundLB:\\n      frontendIPsCount: 1\n```\n\n----------------------------------------\n\nTITLE: AKS Cluster Configuration Specification\nDESCRIPTION: Complete YAML configuration for AKS cluster setup including control plane, managed cluster, and machine pools.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: cluster.x-k8s.io/v1beta1\nkind: Cluster\nmetadata:\n  name: my-cluster\nspec:\n  clusterNetwork:\n    services:\n      cidrBlocks:\n      - 192.168.0.0/16\n  controlPlaneRef:\n    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n    kind: AzureManagedControlPlane\n    name: my-cluster-control-plane\n  infrastructureRef:\n    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n    kind: AzureManagedCluster\n    name: my-cluster\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureManagedControlPlane\nmetadata:\n  name: my-cluster-control-plane\nspec:\n  location: southcentralus\n  resourceGroupName: foo-bar\n  sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=\"\"}\n  subscriptionID: 00000000-0000-0000-0000-000000000000 # fake uuid\n  version: v1.21.2\n  networkPolicy: azure # or calico\n  networkPlugin: azure # or kubenet\n  sku:\n    tier: Free # or Standard\n  addonProfiles:\n  - name: azureKeyvaultSecretsProvider\n    enabled: true\n  - name: azurepolicy\n    enabled: true\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureManagedCluster\nmetadata:\n  name: my-cluster\n---\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachinePool\nmetadata:\n  name: agentpool0\nspec:\n  clusterName: my-cluster\n  replicas: 2\n  template:\n    spec:\n      clusterName: my-cluster\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureManagedMachinePool\n        name: agentpool0\n        namespace: default\n      version: v1.21.2\n```\n\n----------------------------------------\n\nTITLE: Azure KubeadmControlPlane Node max-pods Setting - YAML\nDESCRIPTION: This YAML example adds max-pods: \"30\" to both the initConfiguration and joinConfiguration.kubeletExtraArgs sections of a KubeadmControlPlane resource. This is necessary for enforcing pod density per node when using Azure CNI v1, and must be done for all control-plane nodes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: controlplane.cluster.x-k8s.io/v1beta1\nkind: KubeadmControlPlane\nmetadata:\n  name: ${CLUSTER_NAME}-control-plane\n  namespace: default\nspec:\n  kubeadmConfigSpec:\n    .\n    .\n    initConfiguration:\n      nodeRegistration:\n        kubeletExtraArgs:\n          max-pods: \"30\"\n          .\n          .\n    joinConfiguration:\n      nodeRegistration:\n        kubeletExtraArgs:\n          max-pods: \"30\"\n          .\n          .\n```\n\n----------------------------------------\n\nTITLE: Listing Azure Reference Images\nDESCRIPTION: These Bash commands list available reference images and specific versions in an Azure community gallery, focusing on Cluster API for Azure images. It includes the use of Azure CLI commands such as `az sig image-definition list-community` and `az sig image-version list-community`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# List the image definitions (distro and version)\naz sig image-definition list-community \\\n  --public-gallery-name ClusterAPI-f72ceb4f-5159-4c26-a0fe-2ea738f0d019 \\\n  --location northcentralus\n# List the versions for an image definition (Ubuntu 24.04 for example)\n# Version names are Kubernetes releases, such as \"1.28.15\" or \"1.31.2\".\naz sig image-version list-community \\\n  --public-gallery-name ClusterAPI-f72ceb4f-5159-4c26-a0fe-2ea738f0d019 \\\n  --gallery-image-definition capi-ubun2-2404 \\\n  --location northcentralus\n```\n\n----------------------------------------\n\nTITLE: Enabling Spot VMs in AzureMachineTemplate using YAML\nDESCRIPTION: This YAML snippet shows the basic configuration required within an `AzureMachineTemplate` resource to enable the use of Azure Spot Virtual Machines. Adding an empty `spotVMOptions: {}` object under `spec.template` activates spot instance usage for machines created from this template.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/spot-vms.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: capz-md-0\nspec:\n  location: westus2\n  template:\n    osDisk:\n      diskSizeGB: 30\n      managedDisk:\n        storageAccountType: Premium_LRS\n      osType: Linux\n    sshPublicKey: ${YOUR_SSH_PUB_KEY}\n    vmSize: Standard_B2s\n    spotVMOptions: {}\n```\n\n----------------------------------------\n\nTITLE: Creating an Azure Service Principal with Resource Group-level Scope using Azure CLI\nDESCRIPTION: These commands create a service principal with Contributor role scoped to a specific resource group. This limits the service principal's permissions to just the specified resource group for better security.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\naz login\naz account set --subscription=\"${AZURE_SUBSCRIPTION_ID}\"\naz ad sp create-for-rbac --role=\"Contributor\" --scopes=\"/subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${AZURE_RESOURCE_GROUP}\"\n```\n\n----------------------------------------\n\nTITLE: AKS Virtual Network Configuration\nDESCRIPTION: YAML configuration for deploying AKS cluster with existing Virtual Network settings.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureManagedControlPlane\nmetadata:\n  name: my-cluster-control-plane\nspec:\n  location: southcentralus\n  resourceGroupName: foo-bar\n  sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=\"\"}\n  subscriptionID: 00000000-0000-0000-0000-000000000000 # fake uuid\n  version: v1.21.2\n  virtualNetwork:\n    cidrBlock: 10.0.0.0/8\n    name: test-vnet\n    resourceGroup: test-rg\n    subnet:\n      cidrBlock: 10.0.2.0/24\n      name: test-subnet\n```\n\n----------------------------------------\n\nTITLE: Configuring Private IPv6 Cluster Outbound Load Balancer in YAML\nDESCRIPTION: This YAML document illustrates how to configure a node outbound load balancer for a private IPv6 Kubernetes cluster. The snippet demonstrates setting parameters like frontend IP count for private clusters. Prerequisites include Azure configuration allowing IPv6 traffic and dependencies involve a passive load balancer to not interfere with internal networking requirements.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/node-outbound-connection.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: my-private-cluster\n  namespace: default\nspec:\n  location: eastus\n  networkSpec:\n    apiServerLB:\n      type: Internal\n    subnets:\n    - cidrBlocks:\n      - 2001:0DB8:0000:1/64\n      name: subnet-node\n      role: node\n    nodeOutboundLB:\n      frontendIPsCount: 1\n\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureMachinePool Flexible Orchestration Mode in YAML\nDESCRIPTION: This YAML snippet defines an AzureMachinePool resource named 'capz-mp-0' and sets its orchestration mode to 'Flexible'. Using 'Flexible' mode requires Kubernetes v1.26.0 or later and allows for more granular control over individual VM instances within the scale set compared to the default 'Uniform' mode. After applying this configuration, the cloud-provider-azure Helm chart must be installed on the workload cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/machinepools.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n```yaml\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: capz-mp-0\nspec:\n  orchestrationMode: Flexible\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring System-assigned Managed Identity with Explicit Role on AzureMachineTemplate - YAML\nDESCRIPTION: This advanced YAML manifest for AzureMachineTemplate sets up a system-assigned managed identity and explicitly specifies the scope and Azure RBAC role using the 'systemAssignedIdentityRole' struct. The 'scope' defines where the role applies (e.g., a specific resource group), and 'definitionID' points to the Azure role definition (such as 'Owner'). Dependencies: proper Azure permissions to assign roles, valid role definition and scope values, and CAPZ support for this struct. Ensures granular control of identity permissions directly at deploy time.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureMachineTemplate\\nmetadata:\\n  name: ${CLUSTER_NAME}-md-0\\n  namespace: default\\nspec:\\n  template:\\n    spec:\\n      identity: SystemAssigned\\n      systemAssignedIdentityRole:\\n        scope: /subscriptions/${AZURE_SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP_NAME}\\n        definitionID: $/subscriptions/${AZURE_SUBSCRIPTION_ID}/providers/Microsoft.Authorization/roleDefinitions/8e3af657-a8ff-443c-a75c-2fe8c4bcb635\\n      ...\n```\n\n----------------------------------------\n\nTITLE: Creating a Service Principal for Azure Client Application - Bash\nDESCRIPTION: Creates a service principal for the previously defined Azure AD client application. The service principal enables the application to interact with Azure resources securely. Relies on AZURE_CLIENT_APP_ID and requires Azure CLI authentication.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\naz ad sp create --id ${AZURE_CLIENT_APP_ID}\n```\n\n----------------------------------------\n\nTITLE: Deploying Worker Nodes with AzureMachinePool and VM Scale Sets (YAML)\nDESCRIPTION: Demonstrates creating an Azure Virtual Machine Scale Set (VMSS) using `MachinePool` and `AzureMachinePool` resources. The `MachinePool` specifies the desired availability zones (`failureDomains`) for distribution (zones \"1\" and \"3\" in this case), and the `AzureMachinePool` defines the underlying Azure VMSS properties like location, VM size, and OS disk configuration.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/failure-domains.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachinePool\nmetadata:\n  labels:\n    cluster.x-k8s.io/cluster-name: my-cluster\n  name: ${CLUSTER_NAME}-vmss-0\n  namespace: default\nspec:\n  clusterName: my-cluster\n  failureDomains:\n    - \"1\"\n    - \"3\"\n  replicas: 3\n  template:\n    spec:\n      clusterName: my-cluster\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfigTemplate\n          name: ${CLUSTER_NAME}-vmss-0\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachinePool\n        name: ${CLUSTER_NAME}-vmss-0\n      version: ${KUBERNETES_VERSION}\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  labels:\n    cluster.x-k8s.io/cluster-name: my-cluster\n  name: ${CLUSTER_NAME}-vmss-0\n  namespace: default\nspec:\n  location: westeurope\n  template:\n    osDisk:\n      diskSizeGB: 30\n      osType: Linux\n    vmSize: Standard_B2s\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentity for Service Principal with Certificate Secret (YAML)\nDESCRIPTION: This YAML snippet defines an `AzureClusterIdentity` resource configured for 'ServicePrincipalCertificate' authentication using a certificate stored in a Kubernetes Secret. It specifies the Azure Tenant ID (`tenantID`), the Client ID (`clientID`) of the Service Principal, and a reference (`clientSecret`) to the Kubernetes Secret containing the certificate and password. The `allowedNamespaces` restrict usage.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  name: example-identity\n  namespace: default\nspec:\n  type: ServicePrincipalCertificate\n  tenantID: <azure-tenant-id>\n  clientID: <client-id-of-SP-identity>\n  clientSecret: {\"name\":\"<secret-name-for-client-password>\",\"namespace\":\"default\"}\n  allowedNamespaces:\n    list:\n    - <cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Defining Custom VNet and Subnet CIDRs in AzureCluster (YAML)\nDESCRIPTION: This YAML snippet illustrates how to create an AzureCluster with a custom VNet and specific CIDR blocks for the VNet and its subnets. Instead of using a pre-existing VNet, this configuration instructs CAPZ to create a new VNet (`my-vnet`) with the specified address space (`10.0.0.0/16`) and defines custom CIDRs for the control-plane (`10.0.1.0/24`) and node (`10.0.2.0/24`) subnets. If no CIDR is provided, defaults are used.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.0.0.0/16\n    subnets:\n      - name: my-subnet-cp\n        role: control-plane\n        cidrBlocks:\n          - 10.0.1.0/24\n      - name: my-subnet-node\n        role: node\n        cidrBlocks:\n          - 10.0.2.0/24\n  resourceGroup: cluster-example\n```\n\n----------------------------------------\n\nTITLE: Setting Max Price for Spot VMs in AzureMachineTemplate using YAML\nDESCRIPTION: This YAML snippet demonstrates how to optionally specify a maximum price for an Azure Spot VM within the `spotVMOptions` of an `AzureMachineTemplate`. The `maxPrice` field accepts a numerical value (up to 5 decimal places) representing the maximum price in USD per hour. However, it's generally recommended to omit this field to allow Azure to cap spending at the on-demand price and reduce interruptions.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/spot-vms.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  template:\n    spotVMOptions:\n      maxPrice: 0.04 # Price in USD per hour (up to 5 decimal places)\n```\n\n----------------------------------------\n\nTITLE: Creating Azure AD Server Application and Saving App ID - Bash\nDESCRIPTION: Uses Azure CLI to create a new Azure AD application for the server component and stores the resulting appId in the AZURE_SERVER_APP_ID environment variable. Depends on the Azure CLI (az), authenticated session, and sufficient permissions. Parameters used include CLUSTER_NAME for dynamic display name and identifier URIs.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport AZURE_SERVER_APP_ID=$(az ad app create \\\n    --display-name \"${CLUSTER_NAME}Server\" \\\n    --identifier-uris \"https://${CLUSTER_NAME}Server\" \\\n    --query appId -o tsv)\n```\n\n----------------------------------------\n\nTITLE: Configuring System-assigned Managed Identity on AzureMachineTemplate - YAML\nDESCRIPTION: This YAML snippet configures an AzureMachineTemplate to use a system-assigned managed identity by setting 'identity' to 'SystemAssigned'. CAPZ will enable the managed identity at VM creation time. No extra list of identities is needed, as Azure creates and manages the identity lifecycle. Inputs/outputs are similar to user-assigned, but the identity is tightly coupled to the VM resource; role assignment may default to 'Subscription contributor'. Suitable when automating identity management per node.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureMachineTemplate\\nmetadata:\\n  name: ${CLUSTER_NAME}-md-0\\n  namespace: default\\nspec:\\n  template:\\n    spec:\\n      identity: SystemAssigned\\n      ...\n```\n\n----------------------------------------\n\nTITLE: Installing Calico via Helm for Dual-Stack Clusters - Bash\nDESCRIPTION: This Helm command installs Calico for clusters supporting both IPv4 and IPv6 networking by specifying two ipPools with their CIDRs using environment variables. It uses a dual-stack-specific values.yaml and requires pre-set IPV4_CIDR_BLOCK and IPV6_CIDR_BLOCK environment variables.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add projectcalico https://docs.tigera.io/calico/charts && \\\nhelm install calico projectcalico/tigera-operator --version v3.26.1 -f https://raw.githubusercontent.com/kubernetes-sigs/cluster-api-provider-azure/main/templates/addons/calico-dual-stack/values.yaml --set-string \"installation.calicoNetwork.ipPools[0].cidr=${IPV4_CIDR_BLOCK}\",\"installation.calicoNetwork.ipPools[1].cidr=${IPV6_CIDR_BLOCK}\" --namespace tigera-operator --create-namespace\n```\n\n----------------------------------------\n\nTITLE: Setting Up Server-Side Encryption with Disk Encryption Set in YAML\nDESCRIPTION: This snippet demonstrates how to configure an AzureMachineTemplate to use server-side encryption with a disk encryption set. It requires the Disk Encryption Set ID to be specified in the managedDisk spec. This setup is part of configuring server-side encryption for OS and data disks in Azure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/disk-encryption.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: <machine-template-name>\n  namespace: <namespace>\nspec:\n  template:\n    spec:\n      [...]\n      osDisk:\n        managedDisk:\n          diskEncryptionSet:\n            id: <disk_encryption_set_id>\n      [...]\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Private API Server LB with Custom VNet and Static Private IP - CAPZ YAML\nDESCRIPTION: This YAML specifies an AzureCluster resource with a customized VNet and subnet configuration, assigning static IP addresses within chosen CIDR blocks. The networkSpec defines custom VNet and subnet blocks for both control plane and node subnets, and sets apiServerLB to Internal with an explicit frontendIPs.privateIP. The private IP specified must be within the control plane subnet range. This approach is essential for advanced scenarios where network segmentation or custom address ranges are required. Prior knowledge of Azure networking and matching the private IP to the subnet range is required.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/api-server-endpoint.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureCluster\\nmetadata:\\n  name: my-private-cluster\\n  namespace: default\\nspec:\\n  location: eastus\\n  networkSpec:\\n    vnet:\\n      name: my-vnet\\n      cidrBlocks:\\n        - 172.16.0.0/16\\n    subnets:\\n      - name: my-subnet-cp\\n        role: control-plane\\n        cidrBlocks:\\n          - 172.16.0.0/24\\n      - name: my-subnet-node\\n        role: node\\n        cidrBlocks:\\n          - 172.16.2.0/24\\n    apiServerLB:\\n      type: Internal\\n      frontendIPs:\\n        - name: lb-private-ip-frontend\\n          privateIP: 172.16.0.100\\n\n```\n\n----------------------------------------\n\nTITLE: Defining an AzureClusterTemplate for Self-Managed Clusters in CAPZ (YAML)\nDESCRIPTION: This YAML manifest defines an `AzureClusterTemplate`, a Cluster API Provider Azure (CAPZ) custom resource used within a ClusterClass for self-managed Kubernetes clusters. It specifies the Azure infrastructure details like location (`westus2`), network subnet configurations (including roles and NAT gateway for the node subnet), and the Azure subscription ID. This template serves as a blueprint referenced by a ClusterClass to provision the underlying Azure resources for self-managed clusters. Requires the `ClusterTopology=true` feature gate to be enabled.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/clusterclass.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterTemplate\nmetadata:\n  name: capz-clusterclass-cluster\n  namespace: default\nspec:\n  template:\n    spec:\n      location: westus2\n      networkSpec:\n        subnets:\n        - name: control-plane-subnet\n          role: control-plane\n        - name: node-subnet\n          natGateway:\n            name: node-natgateway\n          role: node\n      subscriptionID: 00000000-0000-0000-0000-000000000000\n```\n\n----------------------------------------\n\nTITLE: Exporting Environment Variables for Kubernetes and Azure Deployment (Bash)\nDESCRIPTION: This snippet initializes all necessary environment variables for deploying a cluster on Azure Public MEC, including Kubernetes cluster details, Azure region/edge configurations, and resource group setup. Dependencies include accessing Bash shell, an Azure subscription with correct privileges, and the intended namespacing for resources. Values such as cluster name, region, extended location, and resource group name must be customized; all variables are required as inputs for subsequent tooling and automation steps.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Kubernetes values\nexport CLUSTER_NAME=\"my-cluster\"\nexport WORKER_MACHINE_COUNT=2\nexport CONTROL_PLANE_MACHINE_COUNT=1\nexport KUBERNETES_VERSION=\"v1.25.0\"\n\n# Azure values\nexport AZURE_LOCATION=\"eastus2euap\"\nexport AZURE_EXTENDEDLOCATION_TYPE=\"EdgeZone\"\nexport AZURE_EXTENDEDLOCATION_NAME=\"microsoftrrdclab3\"\nexport AZURE_RESOURCE_GROUP=\"${CLUSTER_NAME}\"\n```\n\n----------------------------------------\n\nTITLE: Creating Azure AD Client Application and Capturing App ID - Bash\nDESCRIPTION: Executes an Azure CLI command to create a client-side Azure AD application with specified display name, reply URLs, and as a native client app. Stores the resulting appId in the AZURE_CLIENT_APP_ID variable for subsequent use. Dependencies include Azure CLI, environment variables, and adequate Azure permissions.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nAZURE_CLIENT_APP_ID=$(az ad app create \\\n    --display-name \"${CLUSTER_NAME}Client\" \\\n    --native-app \\\n    --reply-urls \"https://${CLUSTER_NAME}Client\" \\\n    --query appId -o tsv)\n```\n\n----------------------------------------\n\nTITLE: Defining Templates for Managed (AKS) Clusters in CAPZ ClusterClass (YAML)\nDESCRIPTION: This multi-document YAML manifest defines the required templates for deploying an Azure Kubernetes Service (AKS) cluster using ClusterClass with Cluster API Provider Azure (CAPZ). It includes: an `AzureManagedClusterTemplate` (largely a placeholder for AKS infrastructure), an `AzureManagedControlPlaneTemplate` specifying location, subscription ID, and Kubernetes version for the managed control plane, and an `AzureManagedMachinePoolTemplate` defining a system node pool (`pool0`) with its name, mode, and VM SKU. Note the warning against setting `virtualNetwork.Name` in the control plane template to avoid conflicts. Requires `ClusterTopology=true` and `MachinePool=true` feature gates.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/clusterclass.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureManagedClusterTemplate\nmetadata:\n  name: capz-clusterclass-cluster\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureManagedControlPlaneTemplate\nmetadata:\n  name: capz-clusterclass-control-plane\nspec:\n  location: westus2\n  subscriptionID: 00000000-0000-0000-0000-000000000000\n  version: 1.25.2\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureManagedMachinePoolTemplate\nmetadata:\n  name: capz-clusterclass-pool0\n  namespace: default\nspec:\n  template:\n    spec:\n      mode: System\n      name: pool0\n      sku: Standard_D2s_v3\n```\n\n----------------------------------------\n\nTITLE: AzureMachineTemplate with Third-Party Image\nDESCRIPTION: An example YAML configuration for an `AzureMachineTemplate` using a third-party image from the Azure Marketplace, detailing necessary fields like `publisher`, `offer`, `sku`, `version`, and `thirdPartyImage`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: capz-marketplace-example\nspec:\n  template:\n    spec:\n      image:\n        marketplace:\n          publisher: \"example-publisher\"\n          offer: \"example-offer\"\n          sku: \"k8s-1dot18dot8-ubuntu-1804\"\n          version: \"2020-07-25\"\n          thirdPartyImage: true\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentity for Service Principal with Certificate Path (YAML)\nDESCRIPTION: This YAML snippet defines an `AzureClusterIdentity` resource configured for 'ServicePrincipalCertificate' authentication, referencing a certificate file directly via a path (`certPath`) accessible to the controller manager pod, instead of using a Kubernetes Secret. It requires the Azure Tenant ID (`tenantID`), Client ID (`clientID`), the certificate path, and `allowedNamespaces`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  name: example-identity\n  namespace: default\nspec:\n  type: ServicePrincipalCertificate\n  tenantID: <azure-tenant-id>\n  clientID: <client-id-of-SP-identity>\n  certPath: <path-to-the-cert>\n  allowedNamespaces:\n    list:\n    - <cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for AKS Cluster Deployment\nDESCRIPTION: Sets required environment variables for Kubernetes cluster configuration and Azure resource settings before deploying with clusterctl.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Kubernetes values\nexport CLUSTER_NAME=\"my-cluster\"\nexport WORKER_MACHINE_COUNT=2\nexport KUBERNETES_VERSION=\"v1.27.3\"\n\n# Azure values\nexport AZURE_LOCATION=\"southcentralus\"\nexport AZURE_RESOURCE_GROUP=\"${CLUSTER_NAME}\"\n```\n\n----------------------------------------\n\nTITLE: Granting API Permissions Between Azure AD Applications - Bash\nDESCRIPTION: Fetches the OAuth permission ID of the server application and configures the client application with the required API permission, then grants consent. Ensures the client can authenticate and connect to the server application. Commands depend on properly initialized AZURE_SERVER_APP_ID and AZURE_CLIENT_APP_ID, and require Azure administrator rights.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\noAuthPermissionId=$(az ad app show --id ${AZURE_SERVER_APP_ID} --query \"oauth2Permissions[0].id\" -o tsv)\naz ad app permission add --id ${AZURE_CLIENT_APP_ID} --api ${AZURE_SERVER_APP_ID} --api-permissions ${oAuthPermissionId}=Scope\naz ad app permission grant --id ${AZURE_CLIENT_APP_ID} --api ${AZURE_SERVER_APP_ID}\n```\n\n----------------------------------------\n\nTITLE: Defining AzureMachinePool Rolling Update Strategy in YAML\nDESCRIPTION: This YAML snippet demonstrates configuring the deployment strategy for an AzureMachinePool named 'capz-mp-0'. It specifies a 'RollingUpdate' strategy with defined parameters: 'deletePolicy' set to 'Oldest' (deleting the oldest machines first during updates), 'maxSurge' set to '25%' (allowing the scale set to temporarily exceed the desired replica count by 25% during an update), and 'maxUnavailable' set to '1' (allowing at most one machine to be unavailable during the update process). This strategy enables safe, controlled rollouts of changes like Kubernetes version updates or OS image changes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/machinepools.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n```yaml\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: capz-mp-0\nspec:\n  strategy:\n    rollingUpdate:\n      deletePolicy: Oldest\n      maxSurge: 25%\n      maxUnavailable: 1\n    type: RollingUpdate\n```\n```\n\n----------------------------------------\n\nTITLE: Example Kubernetes Secret for Service Principal Client Secret (YAML)\nDESCRIPTION: This YAML snippet shows the structure of a Kubernetes Secret (`type: Opaque`) used to store the client secret for a Service Principal identity referenced by `AzureClusterIdentity`. The actual secret value is base64 encoded under the `data.clientSecret` key.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: <secret-name-for-client-password>\ntype: Opaque\ndata:\n  clientSecret: <client-secret-of-SP-identity>\n```\n\n----------------------------------------\n\nTITLE: Checking CAPZ Controller Logs for Credential Errors (Bash)\nDESCRIPTION: Retrieves logs from the CAPZ controller manager deployment within the 'capz-system' namespace on the management cluster. This is used to diagnose issues related to Azure credentials, such as invalid client secrets, indicated by specific error messages like 'AADSTS7000215'.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkubectl logs deploy/capz-controller-manager -n capz-system manager\n```\n\n----------------------------------------\n\nTITLE: Configuring Private Endpoints in AzureManagedControlPlane YAML\nDESCRIPTION: This YAML example demonstrates configuring an `AzureManagedControlPlane` (AKS) with a private endpoint on its specified subnet. It includes optional parameters like `customNetworkInterfaceName`, `applicationSecurityGroups`, `privateIPAddresses`, `location`, and detailed `privateLinkServiceConnections` including `groupIds` (e.g., for Azure Storage Blobs).\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureManagedControlPlane\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  version: v1.25.2\n  sshPublicKey: \"\"\n  identityRef:\n    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n    kind: AzureClusterIdentity\n    name: cluster-identity\n  location: eastus2\n  resourceGroupName: cluster-example\n  virtualNetwork:\n    name: my-vnet\n    cidrBlock: 10.0.0.0/16\n    subnet:\n      cidrBlock: 10.0.2.0/24\n      name: my-subnet\n      privateEndpoints:\n      - name: my-pe\n        customNetworkInterfaceName: nic-my-pe # optional\n        applicationSecurityGroups: # optional\n        - <ASG ID>\n        privateIPAddresses: # optional\n        - 10.0.2.10\n        location: eastus2 # optional\n        privateLinkServiceConnections:\n        - name: my-pls # optional\n          privateLinkServiceID: /subscriptions/<Subscription ID>/resourceGroups/<Remote Resource Group Name>/providers/Microsoft.Storage/storageAccounts/<Name>\n          groupIds:\n          - \"blob\"\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Service Principal and Saving Credentials (Bash)\nDESCRIPTION: This code generates a new Azure service principal with Contributor role scoped to the specified subscription and saves the authentication details in JSON format. Required dependencies are Azure CLI (az), appropriate RBAC privileges, and existing AZURE_SUBSCRIPTION_ID variable. The output file (sp.json) is essential for later steps to provide programmatic access to Azure resources for automation tools.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naz ad sp create-for-rbac --role Contributor --scopes=\"/subscriptions/${AZURE_SUBSCRIPTION_ID}\" --sdk-auth > sp.json\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentity for Service Principal in Kubernetes (YAML)\nDESCRIPTION: This YAML snippet defines an `AzureClusterIdentity` resource configured for 'ServicePrincipal' authentication. It requires the Azure Tenant ID (`tenantID`), the Client ID (`clientID`) of the Service Principal, and a reference (`clientSecret`) to a Kubernetes Secret containing the Service Principal's client secret. The `allowedNamespaces` field restricts where this identity can be used.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  name: example-identity\n  namespace: default\nspec:\n  type: ServicePrincipal\n  tenantID: <azure-tenant-id>\n  clientID: <client-id-of-SP-identity>\n  clientSecret: {\"name\":\"<secret-name-for-client-password>\",\"namespace\":\"default\"}\n  allowedNamespaces:\n    list:\n    - <cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Secret for Client Password using kubectl\nDESCRIPTION: This Bash command creates a Kubernetes Secret resource named according to the `AZURE_CLUSTER_IDENTITY_SECRET_NAME` environment variable. The secret stores the Azure client secret, provided via the `AZURE_CLIENT_SECRET` environment variable, under the key `clientSecret`. This secret is required by the `ManualServicePrincipal` identity type.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/multitenancy.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create secret generic \"${AZURE_CLUSTER_IDENTITY_SECRET_NAME}\" --from-literal=clientSecret=\"${AZURE_CLIENT_SECRET}\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Spot VMs in AzureMachinePool using YAML\nDESCRIPTION: This YAML configuration demonstrates how to enable Azure Spot instances for an experimental `AzureMachinePool` resource. Similar to `AzureMachineTemplate`, adding an empty `spotVMOptions: {}` block under `spec.template` enables spot instance usage for the machine pool.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/spot-vms.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: capz-mp-0\nspec:\n  location: westus2\n  template:\n    osDisk:\n      diskSizeGB: 30\n      managedDisk:\n        storageAccountType: Premium_LRS\n      osType: Linux\n    sshPublicKey: ${YOUR_SSH_PUB_KEY}\n    vmSize: Standard_B2s\n    spotVMOptions: {}\n```\n\n----------------------------------------\n\nTITLE: Enabling User-Managed Boot Diagnostics in AzureMachineTemplate - YAML\nDESCRIPTION: This example configures boot diagnostics with a user-managed storage account in AzureMachineTemplate by specifying storageAccountType as UserManaged and providing a custom storageAccountURI. It requires storageAccountType set to UserManaged and a valid storageAccountURI for successful diagnostics data storage. Intended for users needing to control the destination of diagnostic logs by specifying a particular storage URI.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-diagnostics.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nkind: AzureMachineTemplate\\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nmetadata:\\n  name: \"${CLUSTER_NAME}-control-plane\"\\nspec:\\n  template:\\n    spec:\\n      [...]\\n      diagnostics:\\n        boot:\\n           storageAccountType: UserManaged\\n           userManaged:\\n             storageAccountURI: \"<your-storage-URI>\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Managed Boot Diagnostics in AzureMachineTemplate - YAML\nDESCRIPTION: This snippet demonstrates enabling boot diagnostics using an Azure-managed storage account by setting storageAccountType to Managed within an AzureMachineTemplate. It is suitable for scenarios requiring diagnostics data to be managed automatically by Azure. The only required parameter is storageAccountType: Managed. Outputs include enabled boot diagnostics data stored in an automatically managed storage account.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-diagnostics.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nkind: AzureMachineTemplate\\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nmetadata:\\n  name: \"${CLUSTER_NAME}-control-plane\"\\nspec:\\n  template:\\n    spec:\\n      [...]\\n      diagnostics:\\n        boot:\\n           storageAccountType: Managed # defaults to Managed for backwards compatibility\n```\n\n----------------------------------------\n\nTITLE: Enabling Ephemeral OS Disk in AzureMachineTemplate (YAML)\nDESCRIPTION: This YAML example defines a complete `AzureMachineTemplate` resource for CAPZ, configuring an ephemeral OS disk by setting `osDisk.diffDiskSettings.option` to `Local`. It also specifies the location, OS disk size (defaulting to 30GB if omitted), managed disk storage type (potentially used as a fallback or ignored depending on Azure/CAPZ logic when ephemeral is active), OS type, SSH public key, and VM size using environment variables for dynamic configuration. Ephemeral OS disks utilize local VM storage (cache or temp disk) for better performance but are non-persistent, suitable for stateless workloads, and require specific Azure VM SKU support.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/os-disk.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: ${CLUSTER_NAME}-md-0\n  namespace: default\nspec:\n  template:\n    spec:\n      location: ${AZURE_LOCATION}\n      osDisk:\n        diffDiskSettings:\n          option: Local\n        diskSizeGB: 30\n        managedDisk:\n          storageAccountType: Standard_LRS\n        osType: Linux\n      sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=\"\"}\n      vmSize: ${AZURE_NODE_MACHINE_TYPE}\n```\n\n----------------------------------------\n\nTITLE: Listing Windows VM Images on Azure Marketplace - Azure CLI Command\nDESCRIPTION: This Azure CLI command lists available Windows Kubernetes images from the 'cncf-upstream' publisher in the Azure Marketplace. The '-o table' flag controls output formatting, and '--all' returns all available versions. Prerequisites: installed Azure CLI and authenticated session. Inputs are publisher and offer arguments. Outputs are tabular lists of images, SKUs, URNs, and versions suitable for use in cluster creation or image customization workflows.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/windows.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\naz vm image list --publisher cncf-upstream --offer capi-windows -o table --all\\nOffer         Publisher      Sku                                     Urn                                                                           Version\\n------------  -------------  ----------------------------            ------------------------------------------------------------------            ----------\\ncapi-windows  cncf-upstream  k8s-1dot22dot1-windows-2019-containerd  cncf-upstream:capi-windows:k8s-1dot22dot1-windows-2019-containerd:2021.10.15  2021.10.15\\ncapi-windows  cncf-upstream  k8s-1dot22dot2-windows-2019-containerd  cncf-upstream:capi-windows:k8s-1dot22dot2-windows-2019-containerd:2021.10.15  2021.10.15\n```\n\n----------------------------------------\n\nTITLE: Configuring Encryption at Host with Disk Encryption Set in YAML\nDESCRIPTION: This snippet shows how to enhance server-side encryption by setting up encryption at the host level. It involves modifying an AzureMachineTemplate YAML configuration to include both the Disk Encryption Set ID and enabling encryptionAtHost. This configuration ensures that even temp disks and disk caches are encrypted.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/disk-encryption.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: <machine-template-name>\n  namespace: <namespace>\nspec:\n  template:\n    spec:\n      [...]\n      osDisk:\n        managedDisk:\n          diskEncryptionSet:\n            id: <disk_encryption_set_id>\n      securityProfile:\n        encryptionAtHost: true\n      [...]\n\n```\n\n----------------------------------------\n\nTITLE: Deploying Runtime Classes to Kubernetes using kubectl\nDESCRIPTION: A command to apply a YAML configuration containing RuntimeClasses to a Kubernetes cluster. It utilizes a kubeconfig file to authenticate and target the specific Kubernetes workload cluster for deploying the configuration.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --kubeconfig=<workload-kubeconfig> apply -f wasm-runtimes.yaml\n```\n\n----------------------------------------\n\nTITLE: Generating Workload Cluster YAML Configuration with clusterctl (Bash)\nDESCRIPTION: This command runs clusterctl to generate a cluster YAML template named azwi-quickstart.yaml with three worker nodes and a specified Kubernetes version. The output file is used as the base for workload cluster creation. Prerequisites include valid environment variables and clusterctl installed. Outputs a YAML file to be further customized for workload identity.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nclusterctl generate cluster azwi-quickstart --kubernetes-version v1.27.3  --worker-machine-count=3 > azwi-quickstart.yaml\n```\n\n----------------------------------------\n\nTITLE: Overriding Configuration for Azure Cloud Provider in YAML\nDESCRIPTION: This YAML snippet demonstrates how to override Azure cloud provider configuration parameters, specifically the load balancer rate limits, using `spec.cloudProviderConfigOverrides` in an `AzureCluster` resource. This requires a Kubernetes version above `v1.18.0`. Ensure relevant Azure resources and subscriptions are correctly set.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/cloud-provider-config.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: ${CLUSTER_NAME}\n  namespace: default\nspec:\n  location: eastus\n  networkSpec:\n    vnet:\n      name: ${CLUSTER_NAME}-vnet\n  resourceGroup: cherry\n  subscriptionID: ${AZURE_SUBSCRIPTION_ID}\n  cloudProviderConfigOverrides:\n    rateLimits:\n      - name: \"defaultRateLimit\"\n        config:\n          cloudProviderRateLimit: true\n          cloudProviderRateLimitBucket: 1\n          cloudProviderRateLimitBucketWrite: 1\n          cloudProviderRateLimitQPS: 1,\n          cloudProviderRateLimitQPSWrite: 1,\n      - name: \"loadBalancerRateLimit\"\n        config:\n          cloudProviderRateLimit: true\n          cloudProviderRateLimitBucket: 2,\n          CloudProviderRateLimitBucketWrite: 2,\n          cloudProviderRateLimitQPS: 0,\n          CloudProviderRateLimitQPSWrite: 0\n```\n\n----------------------------------------\n\nTITLE: Adding AAD Group to Cluster Admin Role - Bash\nDESCRIPTION: Creates a ClusterRoleBinding granting cluster-admin permissions to a specified Azure AD group. The group is identified by its Object ID. Dependencies include valid AZURE_GROUP_OID and administrative kubectl privileges.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nAZURE_GROUP_OID=<Your Group ObjectID>\nkubectl create clusterrolebinding aad-group-cluster-admin-binding --clusterrole=cluster-admin --group=${AZURE_GROUP_OID}\n```\n\n----------------------------------------\n\nTITLE: Defining ClusterRoleBinding for Azure AD User - YAML\nDESCRIPTION: Provides a YAML manifest for Kubernetes to create a ClusterRoleBinding that grants cluster-admin privileges to a named Azure AD user. 'name' fields and 'your_objectId' placeholder should be set according to the specific user or objectId. Designed to be applied with kubectl and requires appropriate cluster-admin rights.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: my-cluster-admin\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- apiGroup: rbac.authorization.k8s.io\n  kind: User\n  name: your_objectId\n```\n\n----------------------------------------\n\nTITLE: Constraining Wasm Workloads to Specific Nodes in Kubernetes YAML\nDESCRIPTION: This snippet provides YAML definitions to constrain Wasm workloads to specific nodes in a Kubernetes cluster. It uses 'nodeSelector' labels in RuntimeClasses to direct the scheduler on which nodes are eligible to run certain Wasm runtime workloads. The node selectors ensure that workload scheduling constraints are properly managed.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-lunatic-v1\"\nhandler: \"lunatic\"\nscheduling:\n  nodeSelector:\n    \"cluster.x-k8s.io/wasmtime-lunatic-v1\": \"true\"\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-slight-v1\"\nhandler: \"slight\"\nscheduling:\n  nodeSelector:\n    \"cluster.x-k8s.io/wasmtime-slight-v1\": \"true\"\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-spin-v2\"\nhandler: \"spin\"\nscheduling:\n  nodeSelector:\n    \"cluster.x-k8s.io/wasmtime-spin-v2\": \"true\"\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-wws-v1\"\nhandler: \"wws\"\nscheduling:\n  nodeSelector:\n    \"cluster.x-k8s.io/wasmtime-wws-v1\": \"true\"\n\n```\n\n----------------------------------------\n\nTITLE: Building Azure Confidential VM-Compatible Image with Image-Builder - Bash\nDESCRIPTION: This snippet demonstrates how to build a custom Ubuntu 22.04 LTS image for use with Azure Confidential VMs using the image-builder tool. It uses Makefile targets within the images/capi directory to initiate the build and outputs key details (image name, resource group, location, and IDs) upon completion. Dependencies include image-builder, access to Azure resource groups, and appropriate CLI authentication, and the expected output is a set of managed image resources compatible with Confidential VM deployment. Limitations: Build time is lengthy and requires supporting OSes as detailed by Azure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/confidential-vms.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# many minutes later...\n==> sig-ubuntu-2204-cvm:\nBuild 'sig-ubuntu-2204-cvm' finished.\n\n==> Builds finished. The artifacts of successful builds are:\n--> sig-ubuntu-2204-cvm: Azure.ResourceManagement.VMImage:\n\nOSType: Linux\nManagedImageResourceGroupName: cluster-api-images\nManagedImageName: capi-ubuntu-2204-cvm-1684153817\nManagedImageId: /subscriptions/01234567-89ab-cdef-0123-4567890abcde/resourceGroups/cluster-api-images/providers/Microsoft.Compute/images/capi-ubuntu-2204-cvm-1684153817\nManagedImageLocation: southcentralus\nManagedImageSharedImageGalleryId: /subscriptions/01234567-89ab-cdef-0123-4567890abcde/resourceGroups/cluster-api-images/providers/Microsoft.Compute/galleries/ClusterAPI/images/capi-ubuntu-2204-cvm/versions/0.3.1684153817\n```\n\n----------------------------------------\n\nTITLE: Distributing Worker Nodes Across Failure Domains using Multiple MachineDeployments (YAML)\nDESCRIPTION: Demonstrates a workaround to distribute worker machines across multiple Azure availability zones (failure domains) by creating separate `MachineDeployment` resources, each explicitly assigned to a different `failureDomain`. This ensures resiliency by spreading worker nodes across zones 1, 2, and 3.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/failure-domains.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachineDeployment\nmetadata:\n  name: ${CLUSTER_NAME}-md-0\n  namespace: default\nspec:\n  clusterName: ${CLUSTER_NAME}\n  replicas: ${WORKER_MACHINE_COUNT}\n  selector:\n    matchLabels: null\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfigTemplate\n          name: ${CLUSTER_NAME}-md-0\n      clusterName: ${CLUSTER_NAME}\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachineTemplate\n        name: ${CLUSTER_NAME}-md-0\n      version: ${KUBERNETES_VERSION}\n      failureDomain: \"1\"\n---\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachineDeployment\nmetadata:\n  name: ${CLUSTER_NAME}-md-1\n  namespace: default\nspec:\n  clusterName: ${CLUSTER_NAME}\n  replicas: ${WORKER_MACHINE_COUNT}\n  selector:\n    matchLabels: null\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfigTemplate\n          name: ${CLUSTER_NAME}-md-1\n      clusterName: ${CLUSTER_NAME}\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachineTemplate\n        name: ${CLUSTER_NAME}-md-1\n      version: ${KUBERNETES_VERSION}\n      failureDomain: \"2\"\n---\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachineDeployment\nmetadata:\n  name: ${CLUSTER_NAME}-md-2\n  namespace: default\nspec:\n  clusterName: ${CLUSTER_NAME}\n  replicas: ${WORKER_MACHINE_COUNT}\n  selector:\n    matchLabels: null\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfigTemplate\n          name: ${CLUSTER_NAME}-md-2\n      clusterName: ${CLUSTER_NAME}\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachineTemplate\n        name: ${CLUSTER_NAME}-md-2\n      version: ${KUBERNETES_VERSION}\n      failureDomain: \"3\"\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Service Account Keys (Bash)\nDESCRIPTION: This Bash snippet sets environment variables referencing the absolute paths of the generated RSA service account key files. These variables are required when configuring the Kubernetes management cluster for workload identity support. It uses realpath for expansion. Prerequisites: the key files must already exist.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport SERVICE_ACCOUNT_SIGNING_KEY_FILE=$(realpath sa.key)\\nexport SERVICE_ACCOUNT_KEY_FILE=$(realpath sa.pub)\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Secret for Service Principal Client Secret (Bash)\nDESCRIPTION: This command uses `kubectl create secret generic` to create a Kubernetes Secret that stores the client secret (password) for an Azure Service Principal. It requires the desired secret name (`AZURE_CLUSTER_IDENTITY_SECRET_NAME`) and the client secret value (`AZURE_CLIENT_SECRET`) to be provided, typically as environment variables.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create secret generic \"${AZURE_CLUSTER_IDENTITY_SECRET_NAME}\" --from-literal=clientSecret=\"${AZURE_CLIENT_SECRET}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Public IPv6 Cluster Outbound Load Balancer in YAML\nDESCRIPTION: This YAML snippet configures a node outbound load balancer for a public IPv6 Kubernetes cluster. The configuration requires specifying the frontend IPs count and TCP idle timeout. Dependencies include a load balancer capable of handling IPv6 traffic. It highlights parameters necessary for customizing outbound load balancer settings in public clusters.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/node-outbound-connection.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: my-public-cluster\n  namespace: default\nspec:\n  location: eastus\n  networkSpec:\n    apiServerLB:\n      type: Public\n    subnets:\n    - cidrBlocks:\n      - 2001:0DB8:0000:1/64\n      name: subnet-node\n      role: node\n    nodeOutboundLB:\n      frontendIPsCount: 3\n      idleTimeoutInMinutes: 4\n\n```\n\n----------------------------------------\n\nTITLE: Explicitly Placing a Machine in a Specific Failure Domain (YAML)\nDESCRIPTION: Illustrates how to explicitly assign a Kubernetes Machine resource to a specific Azure availability zone by setting the `failureDomain` field directly in the `Machine` spec. This example places the control plane machine `controlplane-0` into failure domain \"1\".\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/failure-domains.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: cluster.x-k8s.io/v1beta1\nkind: Machine\nmetadata:\n  labels:\n    cluster.x-k8s.io/cluster-name: my-cluster\n    cluster.x-k8s.io/control-plane: \"true\"\n  name: controlplane-0\n  namespace: default\nspec:\n  version: \"v1.22.1\"\n  clusterName: my-cluster\n  failureDomain: \"1\"\n  bootstrap:\n    configRef:\n        apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n        kind: KubeadmConfigTemplate\n        name: my-cluster-md-0\n  infrastructureRef:\n    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n    kind: AzureMachineTemplate\n    name: my-cluster-md-0\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureMachineTemplate with Trusted Launch in YAML\nDESCRIPTION: This YAML snippet defines an AzureMachineTemplate for deploying a Kubernetes cluster with trusted launch security configuration. It specifies SecureBoot and vTPM as enabled, using a custom image from an Azure Compute Gallery. Requires a generation 2 VM size and Ubuntu Server 22.04 LTS as the base OS.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/trusted-launch-for-vms.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nkind: AzureMachineTemplate\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nmetadata:\n  name: capz-trusted-launch-example\nspec:\n  template:\n    spec:\n      image:\n        computeGallery:\n          subscriptionID: \"01234567-89ab-cdef-0123-4567890abcde\"\n          resourceGroup: \"cluster-api-images\"\n          gallery: \"ClusterAPI\"\n          name: \"capi-ubuntu-2204-gen2-1684153817\"\n          version: \"0.3.1684153817\"\n      securityProfile:\n        securityType: \"TrustedLaunch\"\n        uefiSettings:\n          vTpmEnabled: true\n          secureBootEnabled: true\n      osDisk:\n        diskSizeGB: 128\n        osType: \"Linux\"\n      vmSize: \"Standard_B2s\"\n```\n\n----------------------------------------\n\nTITLE: Example ASO Deployment Argument for CRD Patterns (Plaintext)\nDESCRIPTION: Illustrates how the `--crd-names` argument within the Azure Service Operator's Deployment configuration (in the `capz-system` namespace) reflects the CRDs specified via the `ADDITIONAL_ASO_CRDS` environment variable. This argument tells the ASO controller which CRDs it should manage or be aware of. This snippet shows the result of setting `ADDITIONAL_ASO_CRDS` as shown in the previous example.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aso.md#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n   .\n   - --crd-names=cache.azure.com/*;documentdb.azure.com/MongodbDatabase\n   .\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentity for User-Assigned Managed Identity (YAML)\nDESCRIPTION: This YAML snippet defines an `AzureClusterIdentity` resource configured to use a 'UserAssignedMSI' (Managed Service Identity). It requires the Azure Tenant ID (`tenantID`), the Client ID (`clientID`) of the pre-existing Azure User-Assigned Managed Identity, and the `allowedNamespaces`. This method is only viable if the management cluster itself runs on Azure infrastructure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  name: example-identity\n  namespace: default\nspec:\n  type: UserAssignedMSI\n  tenantID: <azure-tenant-id>\n  clientID: <client-id-of-user-assigned-identity>\n  allowedNamespaces:\n    list:\n    - <cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Sample AzureCluster Definition with Subnet Roles - YAML\nDESCRIPTION: This YAML snippet shows how to configure an AzureCluster resource to specify named subnets for control-plane and node roles, which is required when using Azure CNI v1 as a CNI. It highlights fields under spec.networkSpec.subnets and requires proper integration with the rest of the cluster manifest.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: ${CLUSTER_NAME}\n  namespace: default\nspec:\n  .\n  .\n  networkSpec:\n    subnets:\n    - name: control-plane-subnet # update this as per your nomenclature\n      role: control-plane\n    - name: node-subnet # update this as per your nomenclature\n      role: node\n  .\n  .\n```\n\n----------------------------------------\n\nTITLE: AzureMachineTemplate for Control-Plane Network Interfaces - YAML\nDESCRIPTION: This YAML snippet provides a partial AzureMachineTemplate for the control-plane, illustrating the addition of a networkInterfaces list with one entry mapping to the control-plane subnet and specifying privateIPConfigs. It must be merged into the full spec of the control-plane machine template.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: ${CLUSTER_NAME}-control-plane\n  namespace: default\nspec:\n  template:\n    spec:\n      .\n      .\n      networkInterfaces:\n      - privateIPConfigs: 30\n        subnetName: control-plane-subnet\n      .\n      .\n```\n\n----------------------------------------\n\nTITLE: Adding AKS Extensions via CAPZ Custom Resource - YAML\nDESCRIPTION: This AzureManagedControlPlane YAML manifest demonstrates how to enable official AKS cluster extensions using the 'extensions' field. It configures an extension named 'my-extension' with detailed plan info, such as type, name, product, and publisher. Useful for lifecycle management of third-party or Azure marketplace applications/services. Dependencies: CAPZ CRD, appropriate extension availability in Azure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureManagedControlPlane\\nmetadata:\\n  name: ${CLUSTER_NAME}\\n  namespace: default\\nspec:\\n  extensions:\\n  - name: my-extension\\n    extensionType: \"TraefikLabs.TraefikProxy\"\\n    plan:\\n      name: \"traefik-proxy\"\\n      product: \"traefik-proxy\"\\n      publisher: \"containous\"\\n\n```\n\n----------------------------------------\n\nTITLE: Installing Azure Cloud Provider via Helm for Flatcar (Bash)\nDESCRIPTION: This command installs the Azure external cloud provider using Helm, specifically tailored for Flatcar Linux based workload clusters. It includes an additional `--set-string` flag to specify the correct CA certificate directory (`/usr/share/ca-certificates`) required by Flatcar. Requires `helm`, access to the workload cluster, and the `CLUSTER_NAME` and `CCM_CIDR_BLOCK` environment variables.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nhelm install --repo https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo cloud-provider-azure --generate-name --set infra.clusterName=${CLUSTER_NAME} --set \"cloudControllerManager.clusterCIDR=${CCM_CIDR_BLOCK}\" --set-string \"cloudControllerManager.caCertDir=/usr/share/ca-certificates\"\n```\n\n----------------------------------------\n\nTITLE: Configuring User-assigned Managed Identity on AzureMachinePool - YAML\nDESCRIPTION: This YAML manifest shows how to assign a user-assigned managed identity to an AzureMachinePool. The 'identity' field is set to 'UserAssigned', and the list of 'userAssignedIdentities' must reference the relevant identity provider ID(s). CAPZ will assign the identities to each VM in the scale set, and the first entry is used for cloud provider authentication. Prerequisites include having the user-assigned identity pre-created with sufficient permissions. Suitable for scenarios where distinct RBAC for machine pools is needed.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureMachinePool\\nmetadata:\\n  name: ${CLUSTER_NAME}-mp-0\\n  namespace: default\\nspec:\\n  identity: UserAssigned\\n  userAssignedIdentities:\\n  - providerID: ${USER_ASSIGNED_IDENTITY_PROVIDER_ID}\\n  ...\n```\n\n----------------------------------------\n\nTITLE: Specifying Third Party Image Details in Kubernetes YAML\nDESCRIPTION: Shows how to include publisher, offer, and SKU fields when using third-party images such as 'Flatcar Linux' by Kinvolk in an AzureMachineTemplate. This ensures correct licensing in Azure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: capz-community-gallery-example\nspec:\n  template:\n    spec:\n      image:\n        computeGallery:\n          gallery: testGallery-3282f15c-906a-4c4b-b206-eb3c51adb5be\n          name: capi-flatcar-stable-3139.2.0\n          version: 0.3.1651499183\n          plan:\n            publisher: kinvolk\n            offer: flatcar-container-linux-free\n            sku: stable\n```\n\n----------------------------------------\n\nTITLE: Updating Cluster Template with Mariner Image in Kubernetes YAML\nDESCRIPTION: Instructions for editing a Kubernetes cluster template to include a Mariner Linux image by specifying the resource group, image name, subscription ID, and gallery details. This customization integrates a custom image from a shared gallery.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: ${CLUSTER_NAME}-control-plane\n  namespace: default\nspec:\n  template:\n    spec:\n      image:\n        computeGallery:\n          resourceGroup: cluster-api-images\n          name: capi-mariner-2\n          subscriptionID: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n          gallery: ClusterAPI1689801353abcd\n          version: \"0.3.1689801407\"\n```\n\n----------------------------------------\n\nTITLE: Joining CAPZ AKS Cluster to AKS Fleet Manager - YAML\nDESCRIPTION: This YAML snippet adds the 'fleetsMember' configuration to the AzureManagedControlPlane resource spec, enabling the cluster to join an AKS Fleet via Fleet Manager. It specifies the fleet update group, manager name, and manager resource group. Required for multi-cluster management with Azure Fleet Manager; fields must match existing Azure Fleet resources. Dependencies: Fleet Manager must be created beforehand.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureManagedControlPlane\\nmetadata:\\n  name: ${CLUSTER_NAME}\\n  namespace: default\\nspec:\\n  fleetsMember:\\n    group: fleet-update-group\\n    managerName: fleet-manager-name\\n    managerResourceGroup: fleet-manager-resource-group\\n\n```\n\n----------------------------------------\n\nTITLE: Checking Network Configuration and Connectivity (Dual-Stack) within a Pod (Bash)\nDESCRIPTION: These commands are intended to be executed within the shell of a pod in a dual-stack cluster. `ifconfig eth0` displays the network interface configuration, showing both assigned IPv4 and IPv6 addresses. The `ping` commands test network reachability to another pod using its IPv4 (`10.244.1.2`) and IPv6 (`2001:1234:5678:9a41::2`) addresses, verifying dual-stack connectivity.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/dual-stack.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# inside the nginx-pod\n/ # ifconfig eth0\neth0      Link encap:Ethernet  HWaddr 8A:B2:32:92:4F:87\n          inet addr:10.244.2.2  Bcast:0.0.0.0  Mask:255.255.255.255\n          inet6 addr: 2001:1234:5678:9a42::2/128 Scope:Global\n          inet6 addr: fe80::88b2:32ff:fe92:4f87/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:9 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:10 errors:0 dropped:1 overruns:0 carrier:0\n          collisions:0 txqueuelen:0\n          RX bytes:906 (906.0 B)  TX bytes:840 (840.0 B)\n\n/ # ping -c 2 10.244.1.2\nPING 10.244.1.2 (10.244.1.2): 56 data bytes\n64 bytes from 10.244.1.2: seq=0 ttl=62 time=1.366 ms\n64 bytes from 10.244.1.2: seq=1 ttl=62 time=1.396 ms\n\n--- 10.244.1.2 ping statistics ---\n2 packets transmitted, 2 packets received, 0% packet loss\nround-trip min/avg/max = 1.366/1.381/1.396 ms\n/ # ping -c 2 2001:1234:5678:9a41::2\nPING 2001:1234:5678:9a41::2 (2001:1234:5678:9a41::2): 56 data bytes\n64 bytes from 2001:1234:5678:9a41::2: seq=0 ttl=62 time=1.264 ms\n64 bytes from 2001:1234:5678:9a41::2: seq=1 ttl=62 time=1.233 ms\n\n--- 2001:1234:5678:9a41::2 ping statistics ---\n2 packets transmitted, 2 packets received, 0% packet loss\nround-trip min/avg/max = 1.233/1.248/1.264 ms\n```\n\n----------------------------------------\n\nTITLE: Retrieving Cluster and Machine Status with kubectl - Bash\nDESCRIPTION: This snippet checks the provisioning status of the cluster and machines using 'kubectl get' commands. Inputs include the cluster name and machine identifiers as arguments, and it outputs the status and version information of the cluster and nodes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/gpu.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl get cluster azure-gpu\n$ kubectl get machines\n```\n\n----------------------------------------\n\nTITLE: Deploying Mariner Cluster with Helm Argument for CA Certs\nDESCRIPTION: Deploy a CAPZ Mariner cluster using the specified location and adjusting cloud-provider-azure settings with Helm to manage the unique CA certificate directory in Mariner Linux.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n--set-string cloudControllerManager.caCertDir=/etc/pki/tls\n```\n\n----------------------------------------\n\nTITLE: Configuring Private Endpoints in AzureCluster YAML\nDESCRIPTION: This YAML snippet shows how to define an `AzureCluster` resource and configure a private endpoint on one of its subnets (`my-subnet-node`). The `privateEndpoints` field within the subnet definition is used to specify the private endpoint's name and the target Private Link Service via `privateLinkServiceID`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  location: eastus2\n  resourceGroup: cluster-example\n  networkSpec:\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.0.0.0/16\n    subnets:\n      - name: my-subnet-cp\n        role: control-plane\n        cidrBlocks:\n          - 10.0.1.0/24\n      - name: my-subnet-node\n        role: node\n        cidrBlocks:\n          - 10.0.2.0/24\n        privateEndpoints:\n         - name: my-pe\n           privateLinkServiceConnections:\n           - privateLinkServiceID: /subscriptions/<Subscription ID>/resourceGroups/<Remote Resource Group Name>/providers/Microsoft.Network/privateLinkServices/<Private Link Service Name>\n```\n\n----------------------------------------\n\nTITLE: Applying Cluster YAML Manifest to Management Cluster (Bash)\nDESCRIPTION: This command applies the previously generated YAML template (edgezone-cluster.yaml) to the management cluster using kubectl. Dependencies are kubectl, access to the running management Kubernetes cluster, and the valid manifest file. This operation triggers resource creation and reconciliation for the user cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f edgezone-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Updating Controller Manager Args for Flannel Cluster - YAML\nDESCRIPTION: This YAML snippet demonstrates how to enable allocate-node-cidrs in a KubeadmControlPlane resource, a prerequisite for deploying Flannel CNI on a new cluster. It sets controllerManager.extraArgs.allocate-node-cidrs to \"true\" in the control plane's kubeadm config spec. It must be applied before cluster deployment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: controlplane.cluster.x-k8s.io/v1beta1\nkind: KubeadmControlPlane\nspec:\n  kubeadmConfigSpec:\n    clusterConfiguration:\n      controllerManager:\n        extraArgs:\n          allocate-node-cidrs: \"true\"\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureClusterIdentity for Workload Identity (YAML)\nDESCRIPTION: This YAML snippet defines an AzureClusterIdentity resource with WorkloadIdentity type. It omits the clientSecret (not required for workload identity) and specifies tenantID and clientID along with allowedNamespaces. Prerequisites: correct substitution of placeholder values (<your-tenant-id>, <your-client-id>, etc.). Output is a customized YAML manifest to be applied to the cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureClusterIdentity\\nmetadata:\\n  name: cluster-identity\\nspec:\\n  type: WorkloadIdentity\\n  allowedNamespaces:\\n    list:\\n    - <cluster-namespace>\\n  tenantID: <your-tenant-id>\\n  clientID: <your-client-id>\n```\n\n----------------------------------------\n\nTITLE: Disabling Boot Diagnostics in AzureMachineTemplate - YAML\nDESCRIPTION: This YAML example shows how to disable boot diagnostics by setting storageAccountType to Disabled in the diagnostics section of AzureMachineTemplate. When applied, no diagnostics data will be collected or stored for the VM, suitable for minimal configurations or environments without diagnostic requirements. Only storageAccountType: Disabled is necessary.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-diagnostics.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nkind: AzureMachineTemplate\\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nmetadata:\\n  name: \"${CLUSTER_NAME}-control-plane\"\\nspec:\\n  template:\\n    spec:\\n      [...]\\n      diagnostics:\\n        boot:\\n           storageAccountType: Disabled\n```\n\n----------------------------------------\n\nTITLE: Enabling Preview API Features for ManagedClusters with CAPZ - YAML\nDESCRIPTION: These YAML code blocks enable preview features in AzureManagedControlPlane and AzureManagedMachinePool by using 'enablePreviewFeatures' and patch fields. The first block uses 'asoManagedClusterPatches' to add new preview spec fields for managed clusters, while the second block uses 'asoManagedClustersAgentPoolPatches' for the agent pool. Required for experimenting with APIs not officially supported by CAPZ. Use with caution; misconfiguration can affect cluster operation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureManagedControlPlane\\nmetadata:\\n  name: ${CLUSTER_NAME}\\n  namespace: default\\nspec:\\n  enablePreviewFeatures: true\\n  asoManagedClusterPatches:\\n  - '{\"spec\": {\"enableNamespaceResources\": true}}'\\n---\\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureManagedMachinePool\\nmetadata:\\n  ...\\nspec:\\n  asoManagedClustersAgentPoolPatches:\\n  - '{\"spec\": {\"enableCustomCATrust\": true}}'\\n\n```\n\n----------------------------------------\n\nTITLE: Peering VNets via Helper Script - Bash\nDESCRIPTION: This shell command runs a helper script to peer management and workload cluster VNets and potentially apply custom tilt settings. It expects critical environment variables (AZURE_INTERNAL_LB_PRIVATE_IP, CLUSTER_NAME, CLUSTER_NAMESPACE) to be exported, and the script to be available at ./scripts/peer-vnets.sh. The command enables network-level connectivity between clusters by employing Azure peering configuration within the automation workflow. Output: updated Azure networking state for CI clusters. Must be executed after initial test orchestration and when the clusters are created.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/tilt-with-aks-as-mgmt-ilb.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nAZURE_INTERNAL_LB_PRIVATE_IP=\"<Internal-IP-from-the-e2e-test>\" CLUSTER_NAME=\"<e2e workload-cluster-name>\" CLUSTER_NAMESPACE=\"<e2e-cluster-namespace>\" ./scripts/peer-vnets.sh ./tilt-settings.yaml\n```\n\n----------------------------------------\n\nTITLE: Debugging: Azure Authorization Failure Log Example (Bash log excerpt)\nDESCRIPTION: This snippet shows a Bash-format log message encountered when the user-assigned identity does not have correct Azure role assignments. It is for reference during debugging. The error suggests a missing Contributor role for the identity.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nMessage: group failed to create or update. err: failed to get existing resource\\ndemo/demo(service: group): resources.GroupsClient#Get: Failure\\nresponding to request: StatusCode=403 -- Original Error: autorest/azure:\\nService returned an error. Status=403 Code=\"AuthorizationFailed\"\\nMessage=\"The client '<id-redacted>' with object id '<id-redacted>' does not have\\nauthorization to perform action 'Microsoft.Resources/subscriptions/resourcegroups/read'\\nover scope '/subscriptions/<sub-id-redacted>/resourcegroups/ashu-test' or the\\nscope is invalid. If access was recently granted, please refresh your\\ncredentials.\". Object will be requeued after 15s\n```\n\n----------------------------------------\n\nTITLE: Example MachinePool, AzureMachinePool, and KubeadmConfig Resources in YAML\nDESCRIPTION: This YAML manifest provides a complete example for creating a pool of VMs using Azure VM Scale Sets managed by CAPZ. It defines three interconnected resources: 1) A 'MachinePool' ('capz-mp-0') specifying replicas, Kubernetes version, and references to bootstrap ('KubeadmConfig') and infrastructure ('AzureMachinePool') configurations. 2) An 'AzureMachinePool' ('capz-mp-0') defining Azure-specific details like location ('westus2'), VM size ('Standard_D2s_v3'), OS disk properties, SSH public key (placeholder), and the rolling update strategy. 3) A 'KubeadmConfig' ('capz-mp-0') providing bootstrap instructions, including the 'azure.json' cloud provider configuration file content (with placeholders for credentials) and node registration settings.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/machinepools.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n```yaml\n---\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachinePool\nmetadata:\n  name: capz-mp-0\nspec:\n  clusterName: capz\n  replicas: 2\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfig\n          name: capz-mp-0\n      clusterName: capz\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachinePool\n        name: capz-mp-0\n      version: v1.22.0\n---\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: capz-mp-0\nspec:\n  location: westus2\n  strategy:\n    rollingUpdate:\n      deletePolicy: Oldest\n      maxSurge: 25%\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    osDisk:\n      diskSizeGB: 30\n      managedDisk:\n        storageAccountType: Premium_LRS\n      osType: Linux\n    sshPublicKey: ${YOUR_SSH_PUB_KEY}\n    vmSize: Standard_D2s_v3\n---\napiVersion: bootstrap.cluster.x-k8s.io/v1beta1\nkind: KubeadmConfig\nmetadata:\n  name: capz-mp-0\nspec:\n  files:\n  - content: |\n      {\n        \"cloud\": \"AzurePublicCloud\",\n        \"tenantId\": \"tenantID\",\n        \"subscriptionId\": \"subscriptionID\",\n        \"aadClientId\": \"clientID\",\n        \"aadClientSecret\": \"secret\",\n        \"resourceGroup\": \"capz\",\n        \"securityGroupName\": \"capz-node-nsg\",\n        \"location\": \"westus2\",\n        \"vmType\": \"vmss\",\n        \"vnetName\": \"capz-vnet\",\n        \"vnetResourceGroup\": \"capz\",\n        \"subnetName\": \"capz-node-subnet\",\n        \"routeTableName\": \"capz-node-routetable\",\n        \"loadBalancerSku\": \"Standard\",\n        \"maximumLoadBalancerRuleCount\": 250,\n        \"useManagedIdentityExtension\": false,\n        \"useInstanceMetadata\": true\n      }\n    owner: root:root\n    path: /etc/kubernetes/azure.json\n    permissions: \"0644\"\n  joinConfiguration:\n    nodeRegistration:\n      name: '{{ ds.meta_data[\"local_hostname\"] }}'\n```\n```\n\n----------------------------------------\n\nTITLE: Listing Available AKS Extensions using Azure CLI - Bash\nDESCRIPTION: This bash command leverages the Azure CLI to list all extension types available for a specific managed AKS cluster. It requires specifying the resource group, cluster name, and cluster type parameters. The output includes available extensions and detailed plan information; Azure CLI must be installed and authenticated.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\naz k8s-extension extension-types list-by-cluster --resource-group my-resource-group --cluster-name mycluster --cluster-type managedClusters\\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple NAT Gateways in a Virtual Network using YAML\nDESCRIPTION: This YAML configuration demonstrates assigning multiple NAT gateways to different node subnets within an IPv4 Kubernetes cluster's virtual network. Dependencies include a pre-existing Azure virtual network. Each NAT gateway is specified under a subnet, with respective NAT gateway and Public IP names provided. This setup supports distinct outbound paths for different subnet nodes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/node-outbound-connection.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-natgw\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      name: my-vnet\n    subnets:\n      - name: subnet-cp\n        role: control-plane\n      - name: subnet-node-1\n        role: node\n        natGateway:\n          name: node-natgw-1\n          NatGatewayIP:\n            name: pip-cluster-natgw-subnet-node-natgw-1\n      - name: subnet-node-2\n        role: node\n        natGateway:\n          name: node-natgw-2\n          NatGatewayIP:\n            name: pip-cluster-natgw-subnet-node-natgw-2\n  resourceGroup: cluster-natgw\n\n```\n\n----------------------------------------\n\nTITLE: Getting VM Boot Diagnostics Logs via Azure CLI (Bash)\nDESCRIPTION: Uses the Azure CLI (`az`) to retrieve the boot diagnostics log for a specific Azure virtual machine. Replace `MyVirtualMachine` with the target VM name and `MyResourceGroup` with its resource group name. This log contains output from the VM's boot process, including cloud-init execution, useful for debugging bootstrap failures.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\naz vm boot-diagnostics get-boot-log --name MyVirtualMachine --resource-group MyResourceGroup\n```\n\n----------------------------------------\n\nTITLE: Disabling Local Accounts in AKS with Azure AD - YAML\nDESCRIPTION: This YAML manifest configures an AzureManagedMachinePool resource to disable local user accounts when integrating AKS with Azure Active Directory (AAD). It sets the 'disableLocalAccounts' flag and specifies admin AAD group object IDs for cluster administrative access. Users must ensure the Service Principal is assigned to the admin group as direct local account access is blocked. Dependencies: Cluster API Provider Azure CRDs, proper AAD setup.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureManagedMachinePool\\nmetadata:\\n  ...\\nspec:\\n  aadProfile:\\n    managed: true\\n    adminGroupObjectIDs:\\n    -  00000000-0000-0000-0000-000000000000 # group object id created in azure.\\n  disableLocalAccounts: true\\n  ...\\n\n```\n\n----------------------------------------\n\nTITLE: Generating GPU Cluster Configuration with clusterctl - Bash\nDESCRIPTION: This snippet generates a manifest for a GPU-enabled Kubernetes cluster using the 'clusterctl generate cluster' command. It requires specifying the machine types, location, and Kubernetes version. Inputs include environment variables for machine types and location, and it outputs a YAML manifest for cluster deployment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/gpu.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAZURE_CONTROL_PLANE_MACHINE_TYPE=Standard_B2s \\\nAZURE_NODE_MACHINE_TYPE=Standard_NC6s_v3 \\\nAZURE_LOCATION=southcentralus \\\nclusterctl generate cluster azure-gpu \\\n  --kubernetes-version=v1.22.1 \\\n  --worker-machine-count=1 \\\n  --flavor=nvidia-gpu > azure-gpu-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Specifying Custom VM Extensions in AzureMachineTemplate YAML\nDESCRIPTION: This YAML snippet demonstrates the addition of a 'CustomScript' VM extension in an `AzureMachineTemplate`. It requires specifying the extension's `name`, `publisher`, and `version`. Optional `settings` and `protectedSettings` can be added to configure extension execution. This is used within the context of CAPZ to manage VM configurations.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vm-extensions.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: test-machine-template\n  namespace: default\nspec:\n  template:\n    spec:\n      vmExtensions:\n      - name: CustomScript\n        publisher: Microsoft.Azure.Extensions\n        version: '2.1'\n        settings:\n          fileUris: https://raw.githubusercontent.com/me/project/hello.sh\n        protectedSettings:\n          commandToExecute: ./hello.sh\n```\n\n----------------------------------------\n\nTITLE: Applying AzureClusterIdentity Configuration using kubectl (Bash)\nDESCRIPTION: This command uses `kubectl apply` to deploy or update the `AzureClusterIdentity` resource defined in the `azure-cluster-identity.yaml` file to the Kubernetes cluster. This action makes the defined identity available for use by Cluster API Provider Azure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f azure-cluster-identity.yaml\n```\n\n----------------------------------------\n\nTITLE: Applying Kubernetes ClusterRoleBinding Manifest - Bash\nDESCRIPTION: Uses kubectl to apply the YAML manifest file created for ClusterRoleBinding. Associates user or group access rights with the Kubernetes cluster. Requires kubectl installed and configured, and the manifest file present in the local directory.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f my-azure-ad-binding.yaml\n```\n\n----------------------------------------\n\nTITLE: Querying Azure VM Sizes for UltraSSD Support via Azure CLI (bash)\nDESCRIPTION: This bash snippet uses the Azure CLI to list all VM sizes in a given region and zone that support the UltraSSDAvailable capability, which is required for provisioning UltraSSD data disks. It requires az CLI to be installed and authenticated. Replace <location> and <VM-size> with the desired Azure region and VM size respectively. Outputs a list of VM SKUs meeting the specified criteria.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/data-disks.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naz vm list-skus -l <location> -z -s <VM-size>\n```\n\n----------------------------------------\n\nTITLE: Specifying Custom VM Extensions in AzureMachinePool YAML\nDESCRIPTION: This YAML example adds a 'CustomScript' VM extension to an `AzureMachinePool` resource within CAPZ. Required fields include `name`, `publisher`, and `version`. Optional `settings` and `protectedSettings` fields provide additional configuration. This setup enables automated extension deployments across VM pools.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vm-extensions.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: test-machine-pool\n  namespace: default\nspec:\n  template:\n    vmExtensions:\n      - name: CustomScript\n        publisher: Microsoft.Azure.Extensions\n        version: '2.1'\n        settings:\n          fileUris: https://raw.githubusercontent.com/me/project/hello.sh\n        protectedSettings:\n          commandToExecute: ./hello.sh\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster with Custom Kubernetes Builds in Bash\nDESCRIPTION: Commands to create a cluster using a template for custom-built Kubernetes components. It sets the cluster template and runs a creation script.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/kubernetes-developers.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport CLUSTER_TEMPLATE=\"test/dev/cluster-template-custom-builds.yaml\"\n./hack/create-dev-cluster.sh\n```\n\n----------------------------------------\n\nTITLE: Listing Azure VM Extensions via Azure CLI Bash Script\nDESCRIPTION: This script uses the Azure CLI to list all VM extensions available in the 'westus' region in table format. Ensure Azure CLI is installed and configured with necessary permissions before execution. The output displays the list of available extensions in a tabular form.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vm-extensions.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ az vm extension image list --location westus --output table\n```\n\n----------------------------------------\n\nTITLE: Configuring System-assigned Managed Identity on AzureMachinePool - YAML\nDESCRIPTION: This YAML manifest configures AzureMachinePool to use system-assigned managed identity. The 'identity' field is set to 'SystemAssigned', which triggers the CAPZ controller to provision an identity for each VM in the scale set managed by Azure. No identity list is needed. Inputs include the standard resource manifest values, and the output is a set of VMs with system-assigned identities managed by their own lifecycle. Used for simplified identity management within node pools.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureMachinePool\\nmetadata:\\n  name: ${CLUSTER_NAME}-mp-0\\n  namespace: default\\nspec:\\n  identity: SystemAssigned\\n  ...\n```\n\n----------------------------------------\n\nTITLE: KubeadmConfigTemplate for Worker Nodes max-pods Setting - YAML\nDESCRIPTION: This YAML illustrates a KubeadmConfigTemplate resource for worker nodes, where joinConfiguration.nodeRegistration.kubeletExtraArgs.max-pods is set to \"30\". This is necessary for limiting pod density per worker node with Azure CNI v1.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: bootstrap.cluster.x-k8s.io/v1beta1\nkind: KubeadmConfigTemplate\nmetadata:\n  name: ${CLUSTER_NAME}-md-0\n  namespace: default\nspec:\n  template:\n    spec:\n      .\n      .\n      joinConfiguration:\n        nodeRegistration:\n          kubeletExtraArgs:\n            max-pods: \"30\"\n            .\n            .\n```\n\n----------------------------------------\n\nTITLE: Labeling Nodes for Cloud Provider Azure in AKS\nDESCRIPTION: This bash command labels a node in the AKS cluster to enable Cloud Provider Azure functionality. It needs to be repeated for each node in the MachinePool.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster-join-vmss.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkubectl label node <node name> kubernetes.azure.com/cluster=<nodeResourceGroupName>\n```\n\n----------------------------------------\n\nTITLE: Provisioning SSH Keys via KubeadmConfigTemplate YAML\nDESCRIPTION: This YAML snippet sets up SSH access by customizing the KubeadmConfigTemplate Custom Resource (CR) for Machine Deployments. It provides SSH keys and defines sudo permissions for a specific user.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ssh-access.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: bootstrap.cluster.x-k8s.io/v1beta1\nkind: KubeadmConfigTemplate\nmetadata:\n  name: test1-md-0\n  namespace: default\nspec:\n  template:\n    spec:\n      files:\n      ...\n      - content: \"username ALL = (ALL) NOPASSWD: ALL\"\n        owner: root:root\n        path: /etc/sudoers.d/username\n        permissions: \"0440\"\n      ...\n      users:\n      - name: username\n        sshAuthorizedKeys:\n        - \"ssh-rsa AAAA...\"\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Cluster Identity Secret in Management Cluster (Bash)\nDESCRIPTION: This kubectl command creates a Kubernetes secret in the management cluster with the name specified by AZURE_CLUSTER_IDENTITY_SECRET_NAME. It loads the Azure client secret as a literal and stores it in the default namespace (or as specified). Requires kubectl access to the management cluster and correctly exported environment variables. This secret will be used by cluster components for Azure API authentication.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create secret generic \"${AZURE_CLUSTER_IDENTITY_SECRET_NAME}\" --from-literal=clientSecret=\"${AZURE_CLIENT_SECRET}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureManagedControlPlane with Security Profile - YAML\nDESCRIPTION: This YAML manifest for AzureManagedControlPlane shows advanced security profile configuration, including workload identity, image cleaner, Key Vault KMS integration, Defender settings, and enabling OIDC issuer. It demonstrates specifying managed identity, key vault references, and defender workspace for security monitoring. Required fields include Azure region, resource group, and relevant identities or secrets.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nkind: AzureManagedControlPlane\\nmetadata:\\n  name: my-cluster-control-plane\\nspec:\\n  location: southcentralus\\n  resourceGroupName: foo-bar\\n  sshPublicKey: ${AZURE_SSH_PUBLIC_KEY_B64:=\"\"}\\n  subscriptionID: 00000000-0000-0000-0000-000000000000 # fake uuid\\n  version: v1.29.4\\n  identity:\\n    type: UserAssigned\\n    userAssignedIdentityResourceID: /subscriptions/00000000-0000-0000-0000-00000000/resourcegroups/<your-resource-group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<your-managed-identity>\\n  oidcIssuerProfile:\\n    enabled: true\\n  securityProfile:\\n    workloadIdentity:\\n      enabled: true\\n    imageCleaner:\\n      enabled: true\\n      intervalHours: 48\\n    azureKeyVaultKms:\\n      enabled: true\\n      keyID: https://key-vault.vault.azure.net/keys/secret-key/00000000000000000\\n    defender:\\n      logAnalyticsWorkspaceResourceID: /subscriptions/00000000-0000-0000-0000-00000000/resourcegroups/<your-resource-group>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<your-managed-identity>\\n      securityMonitoring:\\n        enabled: true\\n\n```\n\n----------------------------------------\n\nTITLE: Customizing Network Security Rules in AzureCluster Subnets (YAML)\nDESCRIPTION: This YAML snippet demonstrates adding custom network security rules to the control-plane subnet within an AzureCluster definition. It defines specific inbound rules for SSH (port 22) and the Kubernetes API server (port 6443), overriding the defaults, and adds a custom outbound rule for TCP port 50000. Each rule specifies name, description, direction, priority, protocol, source/destination ports and addresses, and action (Allow/Deny).\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.0.0.0/16\n    subnets:\n      - name: my-subnet-cp\n        role: control-plane\n        cidrBlocks:\n          - 10.0.1.0/24\n        securityGroup:\n          name: my-subnet-cp-nsg\n          securityRules:\n            - name: \"allow_ssh\"\n              description: \"allow SSH\"\n              direction: \"Inbound\"\n              priority: 2200\n              protocol: \"*\"\n              destination: \"*\"\n              destinationPorts: \"22\"\n              source: \"*\"\n              sourcePorts: \"*\"\n              action: \"Allow\"\n            - name: \"allow_apiserver\"\n              description: \"Allow K8s API Server\"\n              direction: \"Inbound\"\n              priority: 2201\n              protocol: \"*\"\n              destination: \"*\"\n              destinationPorts: \"6443\"\n              source: \"*\"\n              sourcePorts: \"*\"\n              action: \"Allow\"\n            - name: \"allow_port_50000\"\n              description: \"allow port 50000\"\n              direction: \"Outbound\"\n              priority: 2202\n              protocol: \"Tcp\"\n              destination: \"*\"\n              destinationPorts: \"50000\"\n              source: \"*\"\n              sourcePorts: \"*\"\n              action: \"Allow\"\n      - name: my-subnet-node\n        role: node\n        cidrBlocks:\n          - 10.0.2.0/24\n  resourceGroup: cluster-example\n```\n\n----------------------------------------\n\nTITLE: Customizing Azure Bastion Resources in YAML\nDESCRIPTION: This YAML example allows for customization of Azure Bastion resources in a CAPZ cluster, including setting a custom name, subnet, security group, public IP, SKU, and tunneling preferences.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ssh-access.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: test1\n  namespace: default\nspec:\n  bastionSpec:\n    azureBastion:\n      name: \"...\" // The name of the Azure Bastion, defaults to '<cluster name>-azure-bastion'\n      subnet:\n        name: \"...\" // The name of the Subnet. The only supported name is `AzureBastionSubnet` (this is an Azure limitation).\n        securityGroup: {} // No security group is assigned by default. You can choose to have one created and assigned by defining it. \n      publicIP:\n        \"name\": \"...\" // The name of the Public IP, defaults to '<cluster name>-azure-bastion-pip'.\n      sku: \"...\" // The SKU/tier of the Azure Bastion resource. The options are `Standard` and `Basic`. The default value is `Basic`.\n      enableTunneling: \"...\" // Whether or not to enable tunneling/native client support. The default value is `false`.\n```\n\n----------------------------------------\n\nTITLE: Debugging: AADSTS70021 No Matching Federated Identity Record (Bash log excerpt)\nDESCRIPTION: This log message demonstrates a common error when the federated identity record is not found, which can happen if the service account issuer URL does not match. It is included to aid troubleshooting. Inputs: audit or error logs.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n\"error\": \"invalid_request\",\\n\"error_description\": \"AADSTS70021: No matching federated identity record found for presented assertion. Assertion\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Custom Azure Cloud Provider Images in Bash\nDESCRIPTION: Commands to set environment variables for custom-built Azure cloud provider images, including registry, image names, and tags.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/kubernetes-developers.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport IMAGE_REGISTRY=docker.io/myusername\nexport CCM_IMAGE_NAME=azure-cloud-controller-manager\nexport CNM_IMAGE_NAME=azure-node-controller-manager\nexport IMAGE_TAG=canary\n```\n\n----------------------------------------\n\nTITLE: AzureMachineTemplate for Worker Node Network Interfaces - YAML\nDESCRIPTION: This YAML snippet shows the AzureMachineTemplate spec for worker nodes, adding networkInterfaces configuration. Each network interface associates with the node-subnet and specifies private IP allocations. Required when using Azure CNI v1 for worker nodes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: ${CLUSTER_NAME}-md-0\n  namespace: default\nspec:\n  template:\n    spec:\n      networkInterfaces:\n      - privateIPConfigs: 30\n        subnetName: node-subnet\n      .\n      .\n```\n\n----------------------------------------\n\nTITLE: Customizing Flannel Network CIDR in ConfigMap - YAML\nDESCRIPTION: This YAML snippet displays a section of the kube-flannel-cfg ConfigMap, showing how to set the Flannel network CIDR to match the cluster's pod network configuration. The net-conf.json data includes the Network field (e.g., 192.168.0.0/16) and specifies VXLAN as the backend. Must be manually inserted or modified in the Flannel deployment manifest before application.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: kube-flannel-cfg\ndata:\n  net-conf.json: |\n    {\n      \"Network\": \"192.168.0.0/16\",\n      \"Backend\": {\n        \"Type\": \"vxlan\"\n      }\n    }\n```\n\n----------------------------------------\n\nTITLE: Installing Calico via Helm with IPv6 - Bash\nDESCRIPTION: This command performs a Helm-based Calico installation for IPv6-only workloads, using a dedicated values.yaml and injecting the pod network CIDR from the IPV6_CIDR_BLOCK variable. Helm and cluster access are prerequisites for execution.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add projectcalico https://docs.tigera.io/calico/charts && \\\nhelm install calico projectcalico/tigera-operator --version v3.26.1 -f https://raw.githubusercontent.com/kubernetes-sigs/cluster-api-provider-azure/main/templates/addons/calico-ipv6/values.yaml  --set-string \"installation.calicoNetwork.ipPools[0].cidr=${IPV6_CIDR_BLOCK}\" --namespace tigera-operator --create-namespace\n```\n\n----------------------------------------\n\nTITLE: Deploying Spin Workload to Kubernetes using kubectl\nDESCRIPTION: A command for deploying a Kubernetes configuration (spin.yaml) that contains a Deployment and a Service workload for the Spin Wasm runtime. This command interacts with a Kubernetes cluster using a specified kubeconfig file to ensure the proper execution of the deployment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --kubeconfig=<workload-kubeconfig> apply -f spin.yaml\n```\n\n----------------------------------------\n\nTITLE: Extracting IPv4 and IPv6 CIDRs for Calico Dual-Stack Installation - Bash\nDESCRIPTION: This snippet extracts both IPv4 and IPv6 CIDR blocks from the Kubernetes cluster's pod network configuration and exports them as environment variables. Both are required for dual-stack Calico deployments. A correctly set CLUSTER_NAME variable and kubectl access are required.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport IPV4_CIDR_BLOCK=$(kubectl get cluster \"${CLUSTER_NAME}\" -o=jsonpath='{.spec.clusterNetwork.pods.cidrBlocks[0]}')\nexport IPV6_CIDR_BLOCK=$(kubectl get cluster \"${CLUSTER_NAME}\" -o=jsonpath='{.spec.clusterNetwork.pods.cidrBlocks[1]}')\n```\n\n----------------------------------------\n\nTITLE: Disabling Azure Network Discovery via cloud-init (YAML)\nDESCRIPTION: This YAML configuration, placed in `/etc/cloud/cloud.cfg.d/15_azure-vnet.cfg`, disables the default Azure behavior of assigning secondary IP configurations to the host OS via cloud-init. This is necessary when using custom images (not built with image-builder) with Azure CNI, as Azure CNI requires these IPs to be free for pod allocation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\ndatasource:\n  Azure:\n    apply_network_config: false\n```\n\n----------------------------------------\n\nTITLE: Applying Azure Cluster Configuration to Kubernetes\nDESCRIPTION: Command to apply the generated cluster configuration to a Kubernetes cluster using kubectl.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/introduction.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f my-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Secret for Service Principal Certificate and Password (Bash)\nDESCRIPTION: This command uses `kubectl create secret generic` to create a Kubernetes Secret storing an Azure Service Principal's certificate (from a .pfx file) and its associated password. It requires the desired secret name (`AZURE_CLUSTER_IDENTITY_SECRET_NAME`), the path to the certificate file (`ad-sp-cert.pfx`), and the password.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create secret generic \"${AZURE_CLUSTER_IDENTITY_SECRET_NAME}\" --from-file=certificate=ad-sp-cert.pfx --from-literal=password=<password>\n```\n\n----------------------------------------\n\nTITLE: Retrieving Cluster Kubeconfig and Installing Azure Cloud Provider Components (Bash)\nDESCRIPTION: This sequence extracts the kubeconfig for the new cluster from Kubernetes secrets using kubectl and jq, writes it to a file, and uses helm to install the out-of-tree Azure cloud provider. Dependencies are jq, base64, helm, and a sufficiently recent version of the Azure cloud provider. Key parameters include the cluster name and location of the kubeconfig file. This step is necessary for cluster integration with Azure networking and compute features, but only supports the out-of-tree version.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# get the kubeconfig of the cluster\nkubectl get secrets ${CLUSTER_NAME}-kubeconfig -o json | jq -r .data.value | base64 --decode > ./kubeconfig\n\nhelm install --repo https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo cloud-provider-azure --generate-name --set infra.clusterName=${CLUSTER_NAME} --kubeconfig=./kubeconfig\n```\n\n----------------------------------------\n\nTITLE: Kubernetes Deployment and Service for Spin Workload in YAML\nDESCRIPTION: The snippet demonstrates a Kubernetes Deployment and Service definition using YAML for deploying a \"Spin\" Wasm workload. This includes specifying a runtime class to use the Spin v2 shim, defining replicas, resource requests, and service type with LoadBalancer configuration. The deployment aims to create a load-balanced 'hello world' service using Spin microservices.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: wasm-spin\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: wasm-spin\n  template:\n    metadata:\n      labels:\n        app: wasm-spin\n    spec:\n      runtimeClassName: wasmtime-spin-v2\n      containers:\n        - name: spin-hello\n          image: ghcr.io/deislabs/containerd-wasm-shims/examples/spin-rust-hello:latest\n          command: [\"/\"]\n          resources:\n            requests:\n              cpu: 10m\n              memory: 10Mi\n            limits:\n              cpu: 500m\n              memory: 128Mi\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: wasm-spin\nspec:\n  type: LoadBalancer\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n  selector:\n    app: wasm-spin\n\n```\n\n----------------------------------------\n\nTITLE: Checking AzureMachine Status (Bash)\nDESCRIPTION: Retrieves the status of all AzureMachine resources in the current namespace on the management cluster using `kubectl`. The '-o wide' flag provides additional information. This command is used to check if virtual machines corresponding to nodes are ready and in the expected state (e.g., 'Succeeded' or 'Updating'). A 'false' value in the READY column indicates the bootstrap script hasn't completed successfully.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get azuremachines -o wide\n```\n\n----------------------------------------\n\nTITLE: Retrieving Kubernetes Node Details with Bash\nDESCRIPTION: This command fetches detailed node information in a Kubernetes cluster, using the specified output format. It helps validate node configurations, ensuring they have the desired IPv6 attributes. It requires access to a Kubernetes cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get nodes -o wide\n```\n\n----------------------------------------\n\nTITLE: Deploying Custom Azure Cloud Provider Components with Helm in Bash\nDESCRIPTION: Helm command to install custom-built Azure cloud provider components in the test cluster, specifying custom image repositories, names, and tags.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/kubernetes-developers.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nhelm install --repo https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo cloud-provider-azure --generate-name --set infra.clusterName=${CLUSTER_NAME} \\\n--set cloudControllerManager.imageRepository=\"${IMAGE_REGISTRY}\" \\\n--set cloudNodeManager.imageRepository=\"${IMAGE_REGISTRY}\" \\\n--set cloudControllerManager.imageName=\"${CCM_IMAGE_NAME}\" \\\n--set cloudNodeManager.imageName=\"${CNM_IMAGE_NAME}\" \\\n--set cloudControllerManager.imageTag=\"${IMAGE_TAG}\" \\\n--set cloudNodeManager.imageTag=\"${IMAGE_TAG}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring VNet Service Endpoints in AzureCluster Subnets (YAML)\nDESCRIPTION: This YAML snippet shows how to enable Azure Virtual Network service endpoints for subnets within an AzureCluster definition. The `serviceEndpoints` array is added to each subnet specification, listing the desired Azure services (e.g., `Microsoft.AzureActiveDirectory`, `Microsoft.Storage`) and optionally specifying locations. This allows secure and direct connectivity from the subnet to the specified Azure services over the Azure backbone network.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-vnet.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-example\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      name: my-vnet\n      cidrBlocks:\n        - 10.0.0.0/16\n    subnets:\n      - name: my-subnet-cp\n        role: control-plane\n        cidrBlocks:\n          - 10.0.1.0/24\n        serviceEndpoints:\n          - service: Microsoft.AzureActiveDirectory\n            locations: [\"*\"]\n      - name: my-subnet-node\n        role: node\n        cidrBlocks:\n          - 10.0.2.0/24\n        serviceEndpoints:\n          - service: Microsoft.AzureActiveDirectory\n            locations: [\"*\"]\n          - service: Microsoft.Storage\n            locations: [\"southcentralus\"]\n  resourceGroup: cluster-example\n```\n\n----------------------------------------\n\nTITLE: Restricting Announced Failure Domains via AzureCluster (YAML)\nDESCRIPTION: Shows how to configure the `AzureCluster` resource to limit the failure domains (Azure Availability Zones) that are considered available for placement by the Cluster API controllers. In this example, only zone \"1\" is marked as available for control plane nodes, influencing automatic placement strategies.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/failure-domains.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: my-cluster\n  namespace: default\nspec:\n  location: eastus\n  failureDomains:\n    1:\n      controlPlane: true\n```\n\n----------------------------------------\n\nTITLE: Running Docker to Build Mariner Image with Credentials\nDESCRIPTION: Uses Docker to run the image-builder tool for Mariner Linux images. Requires Azure credentials stored in an environment file to create resources in Azure, including a Compute Gallery.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -it --rm --env-file azure-creds.env registry.k8s.io/scl-image-builder/cluster-node-image-builder-amd64:v0.1.17 build-azure-sig-mariner-2\n```\n\n----------------------------------------\n\nTITLE: Checking Node PodCIDR in Kubernetes with Bash\nDESCRIPTION: This bash command retrieves a node's PodCIDR in a Kubernetes cluster using a go-template format, useful for validating the IPv6 PodCIDR assignment. Requires access to the Kubernetes cluster with kubectl.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get nodes ipv6-0-md-0-7k8vm -o go-template --template='{{.spec.podCIDR}}'\n```\n\n----------------------------------------\n\nTITLE: Creating Management Cluster using kind (Bash)\nDESCRIPTION: This simple command provisions a local Kubernetes cluster using kind (Kubernetes IN Docker) to serve as the management cluster for Cluster API components. Dependence on kind being installed and accessible in $PATH. Used early in the management-plane bootstrap process, typically run on the platform admin’s workstation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkind create cluster\n```\n\n----------------------------------------\n\nTITLE: Creating a Service Principal for Azure Server Application - Bash\nDESCRIPTION: Creates an Azure AD service principal for the server application using its application ID. Service principals are needed for resource access and application authentication. Requires Azure CLI and AZURE_SERVER_APP_ID set appropriately.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\naz ad sp create --id ${AZURE_SERVER_APP_ID}\n```\n\n----------------------------------------\n\nTITLE: Creating Kubernetes Management Cluster with kind (Bash YAML heredoc)\nDESCRIPTION: This snippet pipes a multi-document YAML configuration into the kind CLI to create a Kubernetes management cluster configured for workload identity. It mounts the previously generated key files, sets necessary extra arguments in kubeadm patches, and injects issuer and signing key configuration. Prerequisites: kind installed, environment variables set as above. Input: custom YAML; Output: new kind cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncat <<EOF | kind create cluster --name azure-workload-identity --config=-\\nkind: Cluster\\napiVersion: kind.x-k8s.io/v1alpha4\\nnodes:\\n- role: control-plane\\n  extraMounts:\\n    - hostPath: ${SERVICE_ACCOUNT_KEY_FILE}\\n      containerPath: /etc/kubernetes/pki/sa.pub\\n    - hostPath: ${SERVICE_ACCOUNT_SIGNING_KEY_FILE}\\n      containerPath: /etc/kubernetes/pki/sa.key\\n  kubeadmConfigPatches:\\n  - |\\n    kind: ClusterConfiguration\\n    apiServer:\\n      extraArgs:\\n        service-account-issuer: ${SERVICE_ACCOUNT_ISSUER}\\n        service-account-key-file: /etc/kubernetes/pki/sa.pub\\n        service-account-signing-key-file: /etc/kubernetes/pki/sa.key\\n    controllerManager:\\n      extraArgs:\\n        service-account-private-key-file: /etc/kubernetes/pki/sa.key\\nEOF\n```\n\n----------------------------------------\n\nTITLE: Generating a Cluster with Custom Flavor in clusterctl\nDESCRIPTION: Command to generate a cluster configuration with a specific flavor (private) using clusterctl, outputting the result to a YAML file.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/templates/flavors/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nclusterctl generate cluster my-cluster --kubernetes-version v1.29.5 \\\n    --flavor private > my-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Generic Check of CAPZ Controller Logs (Bash)\nDESCRIPTION: Retrieves the logs from the Cluster API Provider for Azure (CAPZ) controller manager running in the 'capz-system' namespace on the management cluster. This is a general command used to investigate the primary controller's activity and potential errors during Azure infrastructure reconciliation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl logs deploy/capz-controller-manager -n capz-system manager\n```\n\n----------------------------------------\n\nTITLE: Viewing workload cluster nodes\nDESCRIPTION: Command to view the nodes in the workload cluster using kubectl with the retrieved kubeconfig file.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/introduction.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl --kubeconfig=my-cluster.kubeconfig get nodes\n```\n\n----------------------------------------\n\nTITLE: Inside Pod Networking and Ping with Bash\nDESCRIPTION: These commands validate the in-pod networking configuration and test connectivity to another IPv6 address from within a pod. This is beneficial for validating dual-stack configurations.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# inside the nginx-pod\n#  # ifconfig eth0\n  eth0      Link encap:Ethernet  HWaddr 3E:DA:12:82:4C:C2\n            inet6 addr: fe80::3cda:12ff:fe82:4cc2/64 Scope:Link\n            inet6 addr: 2001:1234:5678:9a40:100::4/128 Scope:Global\n            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n            RX packets:15 errors:0 dropped:0 overruns:0 frame:0\n            TX packets:20 errors:0 dropped:1 overruns:0 carrier:0\n            collisions:0 txqueuelen:0\n            RX bytes:1562 (1.5 KiB)  TX bytes:1832 (1.7 KiB)\n# ping 2001:1234:5678:9a40::2\nPING 2001:1234:5678:9a40::2 (2001:1234:5678:9a40::2): 56 data bytes\n64 bytes from 2001:1234:5678:9a40::2: seq=0 ttl=62 time=1.690 ms\n64 bytes from 2001:1234:5678:9a40::2: seq=1 ttl=62 time=1.009 ms\n64 bytes from 2001:1234:5678:9a40::2: seq=2 ttl=62 time=1.388 ms\n64 bytes from 2001:1234:5678:9a40::2: seq=3 ttl=62 time=0.925 ms\n```\n\n----------------------------------------\n\nTITLE: Annotation for ASO Resource Adoption\nDESCRIPTION: The annotation required on ASO ManagedCluster and ManagedClustersAgentPool resources to trigger adoption by CAPZ when using the AzureASOManaged API method.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/adopting-clusters.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nsigs.k8s.io/cluster-api-provider-azure-adopt: true\n```\n\n----------------------------------------\n\nTITLE: Checking KubeadmControlPlane Controller Logs (Bash)\nDESCRIPTION: Displays logs from the KubeadmControlPlane controller manager deployment within the 'capi-kubeadm-control-plane-system' namespace on the management cluster. This is useful for troubleshooting issues related to the Kubernetes control plane setup managed by CAPI, such as missing control plane replicas.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl logs deploy/capi-kubeadm-control-plane-controller-manager -n capi-kubeadm-control-plane-system manager\n```\n\n----------------------------------------\n\nTITLE: Building Azure CAPI Images\nDESCRIPTION: This Bash command uses the Image Builder to create a custom `Azure CAPI` image for Ubuntu 18.04. The expected output includes key parameters such as `ManagedImageResourceGroupName`, `ManagedImageName`, and `ManagedImageId`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ make -C images/capi/ build-azure-sig-ubuntu-1804\n# many minutes later...\n==> sig-ubuntu-1804:\nBuild 'sig-ubuntu-1804' finished.\n\n==> Builds finished. The artifacts of successful builds are:\n--> sig-ubuntu-1804: Azure.ResourceManagement.VMImage:\n\nOSType: Linux\nManagedImageResourceGroupName: cluster-api-images\nManagedImageName: capi-1234567890\nManagedImageId: /subscriptions/01234567-89ab-cdef-0123-4567890abcde/resourceGroups/cluster-api-images/providers/Microsoft.Compute/images/capi-1234567890\nManagedImageLocation: southcentralus\nManagedImageSharedImageGalleryId: /subscriptions/01234567-89ab-cdef-0123-4567890abcde/resourceGroups/cluster-api-images/providers/Microsoft.Compute/galleries/ClusterAPI/images/capi-ubuntu-1804/versions/0.3.1234567890\n```\n\n----------------------------------------\n\nTITLE: Adding AAD User to Cluster Admin Role - Bash\nDESCRIPTION: Creates a ClusterRoleBinding granting cluster-admin permissions to a specific Azure AD user, identified by either ObjectID or UserPrincipalName. Useful for onboarding new users to the CAPZ-managed cluster. Requires valid USER_OID and sufficient kubectl privileges.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nUSER_OID=<Your User ObjectID or UserPrincipalName>\nkubectl create clusterrolebinding aad-user-binding --clusterrole=cluster-admin --user ${USER_OID}\n```\n\n----------------------------------------\n\nTITLE: Generating RSA Key Pair for Service Account Signing (Bash)\nDESCRIPTION: This snippet provides Bash commands for generating a 2048-bit RSA key pair using OpenSSL. The private key (sa.key) and public key (sa.pub) are used as the service account signing and key files, respectively, crucial for Kubernetes workload identity configuration. Dependencies: OpenSSL and Bash shell; outputs two files needed later in the setup process.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nopenssl genrsa -out sa.key 2048\\nopenssl rsa -in sa.key -pubout -out sa.pub\n```\n\n----------------------------------------\n\nTITLE: Downloading the Flannel Deployment Manifest - Bash\nDESCRIPTION: This Bash command uses wget to download the default Flannel deployment manifest (kube-flannel.yml) for manual editing. The file is retrieved from the official Flannel documentation and is to be edited prior to deployment. Requires wget to be installed.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nwget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n\n----------------------------------------\n\nTITLE: Viewing Cloud-Init Output Log on Node (Bash)\nDESCRIPTION: Uses the `less` command to view the cloud-init output log file located at `/var/log/cloud-init-output.log`. This command should be run after SSHing into a specific cluster node (control plane or worker) to inspect the detailed output of the cloud-init bootstrapping process for errors or diagnostic information.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n# look at cloud-init logs\nless /var/log/cloud-init-output.log\n```\n\n----------------------------------------\n\nTITLE: Switching Kubectl Context and Verifying Cluster Access - Bash\nDESCRIPTION: Commands to activate the context for the AAD-authenticated user and verify cluster access by listing all pods. These steps confirm successful Azure AD setup and connectivity. Requires finished user/context setup, successful login, and kubectl access.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config use-context ${CLUSTER_NAME}-ad-user@${CLUSTER_NAME}\nkubectl get pods -A\n```\n\n----------------------------------------\n\nTITLE: Installing Azure External Cloud Provider via Helm (Bash)\nDESCRIPTION: This command installs the Azure external cloud provider components onto the workload cluster using its official Helm chart. It requires the `helm` command-line tool, access to the workload cluster, and the `CLUSTER_NAME` and `CCM_CIDR_BLOCK` environment variables (obtained from the previous snippet). The `--generate-name` flag creates a unique release name.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nhelm install --repo https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo cloud-provider-azure --generate-name --set infra.clusterName=${CLUSTER_NAME} --set \"cloudControllerManager.clusterCIDR=${CCM_CIDR_BLOCK}\"\n```\n\n----------------------------------------\n\nTITLE: Specifying Managed OS Disk Storage Account Type in AzureMachineTemplate (YAML)\nDESCRIPTION: This YAML snippet demonstrates how to configure the `storageAccountType` for the managed OS disk within an AzureMachine or AzureMachineTemplate resource in Cluster API Provider Azure (CAPZ). It specifically sets the type to `Premium_LRS`. Other supported values mentioned are `Standard_LRS` and `StandardSSDLRS`. This setting allows overriding the default Azure choice based on VM size.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/os-disk.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n        managedDisk:\n          storageAccountType: Premium_LRS\n```\n\n----------------------------------------\n\nTITLE: Exporting Cluster Name Environment Variable - Bash\nDESCRIPTION: Initializes the environment variable CLUSTER_NAME to identify the future AAD-integrated Kubernetes cluster. This variable is reused in subsequent commands for naming and configuration consistency. Requires a bash-compatible shell environment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport CLUSTER_NAME=my-aad-cluster\n```\n\n----------------------------------------\n\nTITLE: Example Cluster Pod Network CIDR Configuration - YAML\nDESCRIPTION: This YAML snippet provides a sample Cluster resource that defines the pod network's CIDR block, which is essential for aligning Flannel's networking configuration. Users are instructed to extract their actual pod CIDR from a similar resource (e.g., capi-cluster.yaml) before applying Flannel.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: cluster.x-k8s.io/v1beta1\nkind: Cluster\nspec:\n  clusterNetwork:\n    pods:\n      cidrBlocks:\n      - 192.168.0.0/16\n```\n\n----------------------------------------\n\nTITLE: Listing AzureMachines from Control Plane Node (Bash)\nDESCRIPTION: Executes `kubectl get azuremachines` from within an SSH session on a control plane node. This command lists the AzureMachine resources as seen from the workload cluster's perspective (assuming kubectl is configured there or accessing the management cluster API). It's used here to identify the names of other machines, potentially including worker nodes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# list nodes\nkubectl get azuremachines\n```\n\n----------------------------------------\n\nTITLE: AzureMachineTemplate with Image ID\nDESCRIPTION: A YAML representation for an `AzureMachineTemplate` illustrating how to specify a custom image using its managed image ID. This method is suitable for environments where custom image reference by ID is needed.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: capz-image-id-example\nspec:\n  template:\n    spec:\n      image:\n        id: \"/subscriptions/01234567-89ab-cdef-0123-4567890abcde/resourceGroups/myResourceGroup/providers/Microsoft.Compute/images/myImage\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Node Internal IPs (Dual-Stack) using kubectl (Bash)\nDESCRIPTION: This command uses `kubectl get node` with a Go template (`-o go-template`) to extract and display both the IPv4 and IPv6 internal IP addresses assigned to a specific Kubernetes node in a dual-stack cluster. Replace `<node name>` with the actual name of the target node.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/dual-stack.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get node <node name> -o go-template --template='{{range .status.addresses}}{{printf \"%s: %s \\n\" .type .address}}{{end}}'\n```\n\n----------------------------------------\n\nTITLE: CAPI Operator Configuration\nDESCRIPTION: YAML configuration for CAPI operator defining core components and feature gates.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/getting-started.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ncore: \"cluster-api:v1.9.6\"\ninfrastructure: \"azure:v1.17.2\"\naddon: \"helm:v0.2.5\"\nmanager:\n  featureGates:\n    core:\n      ClusterTopology: true\n```\n\n----------------------------------------\n\nTITLE: Listing Official Flatcar VM Images with Azure CLI\nDESCRIPTION: This command uses the Azure CLI to list available Flatcar Container Linux VM images published by Kinvolk in the Azure Marketplace. It filters for the 'flatcar-container-linux-corevm-amd64' offer, 'kinvolk' publisher, and 'stable-gen2' SKU, displaying the results in a table format. This is relevant for the 'flatcar-sysext' flavor.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/flatcar.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\naz vm image list --offer flatcar-container-linux-corevm-amd64 --publisher kinvolk --sku stable-gen2 -o table --all\n```\n\n----------------------------------------\n\nTITLE: Tagging Resources for CAPZ Adoption\nDESCRIPTION: A command or pattern showing the required tag to apply to resources to opt them into CAPZ management. This tag includes the cluster name and indicates the resource is owned by CAPZ.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/adopting-clusters.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsigs.k8s.io_cluster-api-provider-azure_cluster_<CAPI Cluster name>: owned\n```\n\n----------------------------------------\n\nTITLE: Configuring OTLP Exporter for Container Logs in YAML\nDESCRIPTION: This YAML configuration replaces the default logging exporter with an OTLP exporter for container logs and includes collector logs in the pipeline.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/README.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nagentCollector:\n  containerLogs:\n    enabled: true\n\n  configOverride:\n    exporters:\n      otlphttp:\n        endpoint: https://example.com:55681\n    receivers:\n      filelog:\n        exclude: []\n    service:\n      pipelines:\n        logs:\n          exporters:\n            - otlphttp\n\nimage:\n  repository: otel/opentelemetry-collector-contrib\n\ncommand:\n  name: otelcol-contrib\n```\n\n----------------------------------------\n\nTITLE: Building and Pushing CAPZ Docker Images\nDESCRIPTION: Shell commands for building custom CAPZ container images with specified tags and registry, and pushing them to a container registry for use with a development environment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nexport REGISTRY=\"<container-registry>\"\nexport MANAGER_IMAGE_TAG=\"<image-tag>\" # optional - defaults to `dev`.\nPULL_POLICY=IfNotPresent make docker-build\n```\n\n----------------------------------------\n\nTITLE: Configuring Kind Cluster for Service Account Signing (YAML)\nDESCRIPTION: This YAML configuration snippet defines a Kind cluster setup. It mounts the service account public and private keys (`sa.pub`, `sa.key`) from the host machine into the control plane node container at `/etc/kubernetes/pki/`. It also uses `kubeadmConfigPatches` to modify the `ClusterConfiguration`, adding extra arguments to the `apiServer` and `controllerManager` to specify the OIDC issuer URL and the paths to the service account keys, enabling custom service account token signing required for Azure Workload Identity.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n```yaml\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n  extraMounts:\n      # path on node where the public key exists\n    - hostPath: ${SERVICE_ACCOUNT_KEY_FILE}\n      containerPath: /etc/kubernetes/pki/sa.pub\n      # path on node where the private key exists\n    - hostPath: ${SERVICE_ACCOUNT_SIGNING_KEY_FILE}\n      containerPath: /etc/kubernetes/pki/sa.key\n  kubeadmConfigPatches:\n  - |\n    kind: ClusterConfiguration\n    apiServer:\n      extraArgs:\n        # the oidc url after it has been set up\n        service-account-issuer: ${SERVICE_ACCOUNT_ISSUER}\n        service-account-key-file: /etc/kubernetes/pki/sa.pub\n        service-account-signing-key-file: /etc/kubernetes/pki/sa.key\n    controllerManager:\n      extraArgs:\n        service-account-private-key-file: /etc/kubernetes/pki/sa.key\n```\n```\n\n----------------------------------------\n\nTITLE: Initializing CAPZ Management Cluster with clusterctl (Bash)\nDESCRIPTION: This Bash command initializes the newly created kind cluster as a Cluster API management cluster with Azure as the infrastructure provider. It requires clusterctl to be installed and configures controllers for Kubernetes/cluster lifecycle operations via CAPZ. Input: none; Output: initializes management cluster with CAPZ components.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/workload-identity.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nclusterctl init --infrastructure azure\n```\n\n----------------------------------------\n\nTITLE: Example Kubernetes Secret for Service Principal Certificate (YAML)\nDESCRIPTION: This YAML snippet illustrates the structure of a Kubernetes Secret (`type: Opaque`) designed to hold the certificate (.pfx content) and password for Service Principal certificate authentication. The actual certificate and password values are base64 encoded under the `data.certificate` and `data.password` keys, respectively.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: <secret-name-for-client-password>\ntype: Opaque\ndata:\n  certificate: CERTIFICATE\n  password: PASSWORD\n```\n\n----------------------------------------\n\nTITLE: VSCode Launch Configuration for Remote Debugging CAPZ\nDESCRIPTION: JSON configuration for VSCode launch.json that allows connecting to the CAPZ controller running with delve debugger in the Tilt environment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"name\": \"Connect to CAPZ\",\n   \"type\": \"go\",\n   \"request\": \"attach\",\n   \"mode\": \"remote\",\n   \"remotePath\": \"\",\n   \"port\": 30000,\n   \"host\": \"127.0.0.1\",\n   \"showLog\": true,\n   \"trace\": \"log\",\n   \"logOutput\": \"rpc\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Projected Volume Mount for CAPZ Manager (YAML)\nDESCRIPTION: This YAML snippet shows proposed changes to the CAPZ manager deployment configuration. It adds a `volumeMount` named `azure-identity-token` to the manager container at `/var/run/secrets/azure/tokens`. It also defines a corresponding `volume` using the `projected` type, specifically configured to project a `serviceAccountToken` into the volume. This token is configured with a specific audience (`api://AzureADTokenExchange`) and expiration time, intended for use with Azure Workload Identity.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n```yaml\n          volumeMounts:\n            - mountPath: /var/run/secrets/azure/tokens\n              name: azure-identity-token\n              readOnly: true\n...\n      volumes:\n      - name: azure-identity-token\n        projected:\n          defaultMode: 420\n          sources:\n          - serviceAccountToken:\n              audience: api://AzureADTokenExchange\n              expirationSeconds: 3600\n              path: azure-identity-token\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring SSH Access on Windows Nodes - KubeadmConfigTemplate YAML\nDESCRIPTION: This YAML snippet shows how to configure SSH access on Windows machine nodes in a Kubernetes cluster using KubeadmConfigTemplate. Specifying users and sshAuthorizedKeys under the 'users' property ensures the desired SSH keys are provisioned during VM bootstrap. Dependencies: Kubernetes cluster, Cluster API Provider for Azure, Cloudbase-init on Windows images. Inputs are user and key data; outputs are Windows VMs with specified SSH access. Required for enabling SSH into Windows cluster nodes. The '...' indicates other template parameters should be filled in as required by the deployment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/windows.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: bootstrap.cluster.x-k8s.io/v1beta1\\nkind: KubeadmConfigTemplate\\nmetadata:\\n  name: test1-md-0\\n  namespace: default\\nspec:\\n  template:\\n    spec:\\n      ...\\n      users:\\n      - name: username\\n        groups: Administrators\\n        sshAuthorizedKeys:\\n        - \\\"ssh-rsa AAAA...\\\"\n```\n\n----------------------------------------\n\nTITLE: Applying Wasm Runtime Classes in Kubernetes YAML\nDESCRIPTION: The snippet contains YAML definitions for Kubernetes RuntimeClasses to enable 'lunatic', 'slight', 'spin', and 'wws' Wasm runtimes within the cluster. These configurations allow containerd to utilize shims compatible with each runtime for executing Wasm workloads. No external dependencies are required except Kubernetes itself, and constraints can be applied using these runtime classes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-lunatic-v1\"\nhandler: \"lunatic\"\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-slight-v1\"\nhandler: \"slight\"\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-spin-v2\"\nhandler: \"spin\"\n---\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: \"wasmtime-wws-v1\"\nhandler: \"wws\"\n\n```\n\n----------------------------------------\n\nTITLE: Kubeadm Bootstrap Config GVK Example\nDESCRIPTION: Example showing the format for specifying an alternative bootstrap config group version kind using the --bootstrap-config-gvk flag.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/CHANGELOG/v1.16.0.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nKubeadmConfig.v1beta1.bootstrap.cluster.x-k8s.io\n```\n\n----------------------------------------\n\nTITLE: Required Resource Tags for AKS Cluster Adoption\nDESCRIPTION: Essential tags that need to be applied to an AKS cluster during the adoption process with the AzureManagedControlPlane API method.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/adopting-clusters.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsigs.k8s.io_cluster-api-provider-azure_cluster_<clusterName>: owned\nsigs.k8s.io_cluster-api-provider-azure_role: common\n```\n\n----------------------------------------\n\nTITLE: Tilt Development Configuration\nDESCRIPTION: YAML configuration for setting up local development environment with Tilt, including Azure credentials for authentication\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nkustomize_substitutions:\n  AZURE_SUBSCRIPTION_ID: <subscription-id>\n  AZURE_TENANT_ID: <tenant-id>\n  AZURE_CLIENT_SECRET: <client-secret>\n  AZURE_CLIENT_ID: <client-id>\n```\n\n----------------------------------------\n\nTITLE: Example Kubernetes Secret Structure for Client Password in YAML\nDESCRIPTION: This YAML snippet shows the expected structure of the Kubernetes Secret created to hold the Azure service principal's client secret. It's an opaque Secret containing the base64-encoded client secret under the `clientSecret` key within the `data` field. This secret is referenced by the `AzureClusterIdentity` resource.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/multitenancy.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: Secret\nmetadata:\n  name: <secret-name-for-client-password>\ntype: Opaque\ndata:\n  clientSecret: <client-secret-of-SP-identity>\n```\n\n----------------------------------------\n\nTITLE: Converting PEM Certificate to PKCS12 using OpenSSL (Bash)\nDESCRIPTION: This command utilizes `openssl pkcs12` to convert a certificate and private key stored in a PEM file (`fileWithCertAndPrivateKey.pem`) into the PKCS12 format (`ad-sp-cert.pfx`). It also sets a password for the resulting .pfx file, which is required when creating the Kubernetes secret.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nopenssl pkcs12 -export -in fileWithCertAndPrivateKey.pem -out ad-sp-cert.pfx -passout pass:<password>\n```\n\n----------------------------------------\n\nTITLE: Cloning CAPZ Repository\nDESCRIPTION: Commands to clone the Cluster API Provider Azure repository and navigate to its directory\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/kubernetes-sigs/cluster-api-provider-azure\ncd cluster-api-provider-azure\n```\n\n----------------------------------------\n\nTITLE: Generating Tilt Settings YAML Configuration for CAPI/CAPZ Development\nDESCRIPTION: Shell script to create a tilt-settings.yaml file that configures Tilt to use both CAPI and CAPZ repositories with necessary Azure credentials.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncat <<EOF > tilt-settings.yaml\ndefault_registry: \"${REGISTRY}\"\nprovider_repos:\n- ../cluster-api-provider-azure\nenable_providers:\n- azure\n- docker\n- kubeadm-bootstrap\n- kubeadm-control-plane\nkustomize_substitutions:\n  AZURE_SUBSCRIPTION_ID: <subscription-id>\n  AZURE_TENANT_ID: <tenant-id>\n  AZURE_CLIENT_SECRET: <client-secret>\n  AZURE_CLIENT_ID: <client-id>\nEOF\n```\n\n----------------------------------------\n\nTITLE: Installing Jaeger All-In-One Helm Chart\nDESCRIPTION: Commands to add the Jaeger all-in-one Helm repository and install the chart with default values. This installs a development-ready Jaeger tracing instance in your Kubernetes cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/jaeger/chart/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ helm repo add jaeger-all-in-one https://raw.githubusercontent.com/hansehe/jaeger-all-in-one/master/helm/charts\n$ helm install jaeger-all-in-one jaeger-all-in-one/jaeger-all-in-one\n```\n\n----------------------------------------\n\nTITLE: Creating Kind Development Cluster using Bash\nDESCRIPTION: This command uses the project's Makefile to create a local Kubernetes development cluster using Kind. This is typically run after resetting the environment and setting necessary environment variables.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nmake create-cluster\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Azure Management Identity\nDESCRIPTION: Shell commands to set up required environment variables for Azure managed identity and registry configuration in shell profile files.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/tilt-with-aks-as-mgmt-ilb.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport USER_IDENTITY=\"<user-assigned-managed-identity-name>\"\nexport AZURE_CLIENT_ID_USER_ASSIGNED_IDENTITY=\"<user-assigned-managed-identity-client-id>\"\nexport AZURE_CLIENT_ID=\"${AZURE_CLIENT_ID_USER_ASSIGNED_IDENTITY}\"\nexport AZURE_OBJECT_ID_USER_ASSIGNED_IDENTITY=\"<user-assigned-managed-identity--object-id>\"\nexport AZURE_USER_ASSIGNED_IDENTITY_RESOURCE_ID=\"<resource-id-of-user-assigned-managed-id-from-json-view>\"\nexport AZURE_LOCATION=\"<azure-location-having-quota-for-B2s-and-D4s_v3-SKU>\"\nexport REGISTRY=<your-container-registry>\n```\n\n----------------------------------------\n\nTITLE: CAPZ Cluster Configuration Environment Variables\nDESCRIPTION: Shell script with environment variables needed to customize a CAPZ cluster deployment, including cluster settings, Azure resource configuration, and machine specifications.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n# Cluster settings.\nexport CLUSTER_NAME=\"capz-cluster\"\nexport AZURE_VNET_NAME=${CLUSTER_NAME}-vnet\n\n# Azure settings.\nexport AZURE_LOCATION=\"southcentralus\"\nexport AZURE_RESOURCE_GROUP=${CLUSTER_NAME}\nexport AZURE_SUBSCRIPTION_ID_B64=\"$(echo -n \"$AZURE_SUBSCRIPTION_ID\" | base64 | tr -d '\\n')\"\nexport AZURE_TENANT_ID_B64=\"$(echo -n \"$AZURE_TENANT_ID\" | base64 | tr -d '\\n')\"\nexport AZURE_CLIENT_ID_B64=\"$(echo -n \"$AZURE_CLIENT_ID\" | base64 | tr -d '\\n')\"\nexport AZURE_CLIENT_SECRET_B64=\"$(echo -n \"$AZURE_CLIENT_SECRET\" | base64 | tr -d '\\n')\"\n\n# Machine settings.\nexport CONTROL_PLANE_MACHINE_COUNT=3\nexport AZURE_CONTROL_PLANE_MACHINE_TYPE=\"Standard_B2s\"\nexport AZURE_NODE_MACHINE_TYPE=\"Standard_B2s\"\nexport WORKER_MACHINE_COUNT=2\nexport KUBERNETES_VERSION=\"v1.25.6\"\n\n# Identity secret.\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAME=\"cluster-identity-secret\"\nexport CLUSTER_IDENTITY_NAME=\"cluster-identity\"\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAMESPACE=\"default\"\n\n# Generate SSH key.\n# If you want to provide your own key, skip this step and set AZURE_SSH_PUBLIC_KEY_B64 to your existing file.\nSSH_KEY_FILE=.sshkey\nrm -f \"${SSH_KEY_FILE}\" 2>/dev/null\nssh-keygen -t rsa -b 2048 -f \"${SSH_KEY_FILE}\" -N '' 1>/dev/null\necho \"Machine SSH key generated in ${SSH_KEY_FILE}\"\n# For Linux the ssh key needs to be b64 encoded because we use the azure api to set it\n# Windows doesn't support setting ssh keys so we use cloudbase-init to set which doesn't require base64\nexport AZURE_SSH_PUBLIC_KEY_B64=$(cat \"${SSH_KEY_FILE}.pub\" | base64 | tr -d '\\r\\n')\nexport AZURE_SSH_PUBLIC_KEY=$(cat \"${SSH_KEY_FILE}.pub\" | tr -d '\\r\\n')\n```\n\n----------------------------------------\n\nTITLE: Provisioning AzureCluster and AzureClusterIdentity Resources - YAML\nDESCRIPTION: Demonstrates how to declare AzureCluster resources referencing AzureClusterIdentity objects using YAML manifests for both Service Principal and User Assigned Identity scenarios. Dependencies include Cluster API types and the corresponding versioned infrastructure CRDs installed on the Kubernetes management cluster. Parameters such as clientID, tenantID, clientSecret (for Service Principal), and allowed namespaces must be specified correctly. Input consists of YAML definitions that can be applied directly with kubectl; they result in cluster and identity resources that CAPZ controllers utilize for authentication. Limitations include matching namespace references and ensuring referenced secrets are correctly provisioned.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20200720-single-controller-multitenancy.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n---\\napiVersion: infrastructure.cluster.x-k8s.io/v1alpha3\\nkind: AzureCluster\\nmetadata:\\n  name: cluster1\\n  namespace: default\\nspec:\\n  identityRef:\\n    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3\\n    kind: AzureClusterIdentity\\n    name: sp-identity\\n    namespace: default\\n  location: westus2\\n  networkSpec:\\n    vnet:\\n      name: cluster1-vnet\\n  resourceGroup: cluster1\\n  subscriptionID: 8000873c-41a6-11eb-8907-4db4e45a2e79\\n---\\napiVersion: infrastructure.cluster.x-k8s.io/v1alpha3\\nkind: AzureClusterIdentity\\nmetadata:\\n  name: sp-identity\\n  namespace: default\\nspec:\\n  clientID: 74e870e6-cac6-11ea-87d0-0242ac130003\\n  clientSecret:\\n    name: secretName\\n    namespace: secretNamespace\\n  tenantID: 6bec3eaa-cac6-11ea-87d0-0242ac130003\\n  type: ServicePrincipal\n```\n\nLANGUAGE: yaml\nCODE:\n```\n---\\napiVersion: infrastructure.cluster.x-k8s.io/v1alpha3\\nkind: AzureCluster\\nmetadata:\\n  name: cluster1\\n  namespace: default\\nspec:\\n  identityRef:\\n    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3\\n    kind: AzureClusterIdentity\\n    name: sp-identity\\n    namespace: default\\n  location: westus2\\n  networkSpec:\\n    vnet:\\n      name: cluster1-vnet\\n  resourceGroup: cluster1\\n  subscriptionID: 8000873c-41a6-11eb-8907-4db4e45a2e79\\n---\\napiVersion: infrastructure.cluster.x-k8s.io/v1alpha3\\nkind: AzureClusterIdentity\\nmetadata:\\n  name: sp-identity\\n  namespace: default\\nspec:\\n  clientID: 74e870e6-cac6-11ea-87d0-0242ac130003\\n  tenantID: 6bec3eaa-cac6-11ea-87d0-0242ac130003\\n  type: UserAssignedMSI\n```\n\n----------------------------------------\n\nTITLE: Generating Go Mocks using Bash\nDESCRIPTION: This command utilizes the project's Makefile to generate Go mock implementations using GoMock. These mocks are used in unit tests to simulate dependencies.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nmake generate-go\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Service Principal\nDESCRIPTION: Creates a new service principal with Contributor role and exports required Azure credentials.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naz ad sp create-for-rbac --role Contributor --scopes=\"/subscriptions/${AZURE_SUBSCRIPTION_ID}\" --sdk-auth > sp.json\n```\n\nLANGUAGE: bash\nCODE:\n```\nexport AZURE_SUBSCRIPTION_ID=\"$(cat sp.json | jq -r .subscriptionId | tr -d '\\n')\"\nexport AZURE_CLIENT_SECRET=\"$(cat sp.json | jq -r .clientSecret | tr -d '\\n')\"\nexport AZURE_CLIENT_ID=\"$(cat sp.json | jq -r .clientId | tr -d '\\n')\"\nexport AZURE_TENANT_ID=\"$(cat sp.json | jq -r .tenantId | tr -d '\\n')\"\nexport AZURE_NODE_MACHINE_TYPE=\"Standard_D2s_v3\"\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAME=\"cluster-identity-secret\"\nexport AZURE_CLUSTER_IDENTITY_SECRET_NAMESPACE=\"default\"\nexport CLUSTER_IDENTITY_NAME=\"cluster-identity\"\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentity for User-Assigned Identity Credentials (YAML)\nDESCRIPTION: This YAML snippet defines an `AzureClusterIdentity` resource using the 'UserAssignedIdentityCredential' type, primarily for 1st party Microsoft applications. It requires the Azure Tenant ID (`tenantID`), Client ID (`clientID`), the path (`userAssignedIdentityCredentialsPath`) to a JSON file containing the identity's certificate information (as shown in the JSON example), the cloud type (`userAssignedIdentityCredentialsCloudType`), and `allowedNamespaces`.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  name: example-identity\n  namespace: default\nspec:\n  type: UserAssignedIdentityCredential\n  tenantID: <azure-tenant-id>\n  clientID: <client-id-of-user-assigned-identity>\n  userAssignedIdentityCredentialsPath: <path-to-JSON-file-with-mi-certifcate-information>\n  userAssignedIdentityCredentialsCloudType: \"public\"\n  allowedNamespaces:\n    list:\n    - <cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Extracting IPv4 CIDR for Calico Installation - Bash\nDESCRIPTION: This snippet exports the IPv4 CIDR block used by the Kubernetes cluster's pod network to an environment variable by querying the cluster resource via kubectl. It requires access to the management cluster and expects a correctly set CLUSTER_NAME variable. The exported IPV4_CIDR_BLOCK is then referenced in subsequent Helm installation commands.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport IPV4_CIDR_BLOCK=$(kubectl get cluster \"${CLUSTER_NAME}\" -o=jsonpath='{.spec.clusterNetwork.pods.cidrBlocks[0]}')\n```\n\n----------------------------------------\n\nTITLE: Tilt Management Cluster Commands\nDESCRIPTION: Shell commands for creating and managing a local development cluster using Kind and Tilt\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmake kind-create tilt-up\n```\n\n----------------------------------------\n\nTITLE: Running Windows Conformance Tests with CI Artifacts for Azure Cluster API Provider\nDESCRIPTION: Command to run Windows conformance tests with 4 nodes using CI artifacts. Used in the pull-cluster-api-provider-azure-windows-upstream-with-ci-artifacts presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nE2E_ARGS=\"-kubetest.use-ci-artifacts\" WINDOWS=\"true\" CONFORMANCE_NODES=\"4\" ./scripts/ci-conformance.sh\n```\n\n----------------------------------------\n\nTITLE: Implementing Machine Deployment Strategy Types in Go\nDESCRIPTION: Defines structures for managing rolling updates of machine deployments, including configuration for maximum unavailable and surge capacity.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20210222-azure-machinepool-machine.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\n// MachineDeploymentStrategy describes how to replace existing machines with new ones.\ntype MachineDeploymentStrategy struct {\n    // Type of deployment. Currently the only supported strategy is\n    // \"RollingUpdate\".\n    // Default is RollingUpdate.\n    // +optional\n    Type MachineDeploymentStrategyType `json:\"type,omitempty\"`\n\n    // Rolling update config params. Present only if\n    // MachineDeploymentStrategyType = RollingUpdate.\n    // +optional\n    RollingUpdate *MachineRollingUpdateDeployment `json:\"rollingUpdate,omitempty\"`\n}\n\n// MachineRollingUpdateDeployment is used to control the desired behavior of rolling update.\ntype MachineRollingUpdateDeployment struct {\n    MaxUnavailable *intstr.IntOrString `json:\"maxUnavailable,omitempty\"`\n    MaxSurge *intstr.IntOrString `json:\"maxSurge,omitempty\"`\n    DeletePolicy *string `json:\"deletePolicy,omitempty\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Control Plane Nodes Using Shell Commands\nDESCRIPTION: These shell commands demonstrate how to obtain the DNS name for SSH connection to control plane nodes and perform SSH operations in a CAPZ cluster with a Public Load Balancer.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ssh-access.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ kubectl get azurecluster test1 -o json | jq '.spec.networkSpec.apiServerLB.frontendIPs[0].publicIP.dnsName'\ntest1-21192f78.eastus.cloudapp.azure.com\n\n$ ssh username@test1-21192f78.eastus.cloudapp.azure.com hostname\ntest1-control-plane-cn9lm\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ ssh -J username@test1-21192f78.eastus.cloudapp.azure.com username@10.1.0.4 hostname\ntest1-md-0-scctm\n```\n\n----------------------------------------\n\nTITLE: Declaring AzureClusterIdentity and AzureClusterSpec Types - Go\nDESCRIPTION: Defines Go structs for the AzureClusterIdentity resource and AzureClusterSpec, modeling the identity metadata and specification for use by Azure clusters in CAPZ. Required dependencies are Kubernetes meta/v1 for type and object metadata, corev1 for secret references, and API types for identity management. These structs specify fields to store identity type, associated credentials, tenant ID, and a list of namespaces allowed to reference the identity, as well as an optional identity reference in cluster specs. Inputs and outputs are fully-specified API struct definitions for Kubernetes CRDs; the key limitation is the requirement to correctly configure referencing and allowed namespaces for security.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20200720-single-controller-multitenancy.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\n// AzureClusterIdentity is the Schema for the azureclustersidentities API\\ntype AzureClusterIdentity struct {\\n  metav1.TypeMeta   `json:\\\",inline\\\"`\\n  metav1.ObjectMeta `json:\\\"metadata,omitempty\\\"`\\n  \\n  Spec   AzureClusterIdentitySpec   `json:\\\"spec,omitempty\\\"`\\n  Status AzureClusterIdentityStatus `json:\\\"status,omitempty\\\"`\\n}\\n\\n\\ntype AzureClusterIdentitySpec struct {\\n  // UserAssignedMSI or Service Principal\\n  Type IdentityType `json:\\\"type\\\"`\\n  // User assigned MSI resource id.\\n  // +optional\\n  ResourceID string `json:\\\"resourceID,omitempty\\\"`\\n  // Both User Assigned MSI and SP can use this field.\\n  ClientID string `json:\\\"clientID\\\"`\\n  // ClientSecret is a secret reference which should contain either a Service Principal password or certificate secret.\\n  // +optional\\n  ClientSecret corev1.SecretReference `json:\\\"clientSecret,omitempty\\\"`\\n  // Service principal primary tenant id.\\n  TenantID string `json:\\\"tenantID\\\"`\\n  // AllowedNamespaces is an array of namespaces that AzureClusters can\\n  // use this Identity from.\\n  //\\n  // An empty list (default) indicates that AzureClusters can use this\\n  // Identity from any namespace. This field is intentionally not a\\n  // pointer because the nil behavior (no namespaces) is undesirable here.\\n  // +optional\\n  AllowedNamespaces []string `json:\\\"allowedNamespaces\\\"`\\n}\\n\\n\\ntype  AzureClusterSpec  struct {\\n  ...\\n  // +optional\\n  IdentityRef *corev1.ObjectReference `json:\\\"identityRef,omitempty\\\"`\n```\n\n----------------------------------------\n\nTITLE: Running API Diff for Azure Cluster API Provider\nDESCRIPTION: Command to execute the API difference check script. Used in the pull-cluster-api-provider-azure-apidiff presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-apidiff.sh\n```\n\n----------------------------------------\n\nTITLE: Defining Cluster Scope and Azure Client Context - Go\nDESCRIPTION: Defines the ClusterScope and AzureClients Go structs, which encapsulate all client, resource, and authorization context needed for Azure operations within CAPZ controllers. Dependencies include Kubernetes client-go, controller-runtime, API definitions for clusters, and Azure autorest for the Authorizer. The ClusterScope struct is the central context for authenticated interactions, taking references to cluster objects and identity information, with key parameters for client, patch helper, cluster objects, and identity handling. Inputs are Go structs passed by reference, and outputs are encapsulated context objects; sensitive to correct instantiation and initialization.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20200720-single-controller-multitenancy.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ntype ClusterScope struct {\\n\\tlogr.Logger\\n\\tclient      client.Client\\n\\tpatchHelper *patch.Helper\\n\\n\\tAzureClients\\n\\tCluster      *clusterv1.Cluster\\n\\tAzureCluster *infrav1.AzureCluster\\n}\n```\n\nLANGUAGE: go\nCODE:\n```\n// AzureClients contains all the Azure clients used by the scopes.\\ntype AzureClients struct {\\n\\tSubscriptionID             string\\n\\tResourceManagerEndpoint    string\\n\\tResourceManagerVMDNSSuffix string\\n\\tAuthorizer                 autorest.Authorizer\\n\\n}\n```\n\nLANGUAGE: go\nCODE:\n```\nfunc NewClusterScope(params ClusterScopeParams) (*ClusterScope, error) {\\n  ...\\n  return &ClusterScope{\\n    ...\\n  }, nil\\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Host Metrics Receiver on Agent Collectors in YAML\nDESCRIPTION: This YAML configuration enables the host metrics receiver on agent collectors and sets up necessary environment variables and host path mounts.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/README.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nagentCollector:\n  configOverride:\n    receivers:\n      hostmetrics:\n        scrapers:\n          cpu:\n          load:\n          memory:\n          disk:\n    service:\n      pipelines:\n        metrics:\n          receivers: [prometheus, hostmetrics]\n  extraEnvs:\n  - name: HOST_PROC\n    value: /hostfs/proc\n  - name: HOST_SYS\n    value: /hostfs/sys\n  - name: HOST_ETC\n    value: /hostfs/etc\n  - name: HOST_VAR\n    value: /hostfs/var\n  - name: HOST_RUN\n    value: /hostfs/run\n  - name: HOST_DEV\n    value: /hostfs/dev\n  extraHostPathMounts:\n  - name: hostfs\n    hostPath: /\n    mountPath: /hostfs\n    readOnly: true\n    mountPropagation: HostToContainer\n```\n\n----------------------------------------\n\nTITLE: Running Post-Submit Image Push for Azure Cluster API Provider\nDESCRIPTION: Command to run the post-submit image push script with project staging, scratch bucket, and environment variable passthrough. Used in the post-cluster-api-provider-azure-push-images postsubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n/run.sh\n```\n\n----------------------------------------\n\nTITLE: Release Notes Details Template\nDESCRIPTION: Markdown template for adding the comparison link in release notes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/releasing.md#2025-04-22_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n## Details\n<!-- markdown-link-check-disable-next-line -->\nhttps://github.com/kubernetes-sigs/cluster-api-provider-azure/compare/v1.14.4...v1.14.5\n```\n\n----------------------------------------\n\nTITLE: Running CI Build Script for Azure Cluster API Provider\nDESCRIPTION: Command to execute the CI build script for the Cluster API Provider Azure project. Used in the pull-cluster-api-provider-azure-build presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-build.sh\n```\n\n----------------------------------------\n\nTITLE: Retrieving Kubernetes Service Endpoints and Accessing IIS - Shell Commands\nDESCRIPTION: These shell commands are used to list services in the Kubernetes cluster and access a web application exposed by a LoadBalancer service. The first command queries service objects to find their external IPs and ports. The second command ('curl <EXTERNAL-IP>') attempts to connect to the external endpoint of the deployed IIS workload. Dependencies include kubectl, a running Kubernetes cluster, and curl installed locally. Inputs are no parameters or the external IP obtained from the previous output; outputs are service listings and web content. Replace <EXTERNAL-IP> with the real IP from the service.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/windows.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get services\\nNAME         TYPE           CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE\\niis          LoadBalancer   10.0.9.47    <pending>     80:31240/TCP   1m\\nkubernetes   ClusterIP      10.0.0.1     <none>        443/TCP        46m\n```\n\nLANGUAGE: shell\nCODE:\n```\ncurl <EXTERNAL-IP>\n```\n\n----------------------------------------\n\nTITLE: Proposing WorkloadIdentity Type for AzureClusterIdentity (Go)\nDESCRIPTION: This Go code defines the `IdentityType` enumeration and constants used in `AzureClusterIdentitySpec`. It proposes adding a new constant `WorkloadIdentity` to the existing types (`UserAssignedMSI`, `ServicePrincipal`, etc.) to explicitly support Azure Workload Identity as a configurable identity type within CAPZ. A validation comment (`+kubebuilder:validation:Enum=...`) is updated to include the new type.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_4\n\nLANGUAGE: go\nCODE:\n```\n```go\n// IdentityType represents different types of identities.\n// +kubebuilder:validation:Enum=ServicePrincipal;UserAssignedMSI;ManualServicePrincipal;ServicePrincipalCertificate;WorkloadIdentity\ntype IdentityType string\n\nconst (\n\t// UserAssignedMSI represents a user-assigned managed identity.\n\tUserAssignedMSI IdentityType = \"UserAssignedMSI\"\n\n\t// ServicePrincipal represents a service principal using a client password as secret.\n\tServicePrincipal IdentityType = \"ServicePrincipal\"\n\n\t// ManualServicePrincipal represents a manual service principal.\n\tManualServicePrincipal IdentityType = \"ManualServicePrincipal\"\n\n\t// ServicePrincipalCertificate represents a service principal using a certificate as secret.\n\tServicePrincipalCertificate IdentityType = \"ServicePrincipalCertificate\"\n\t\n\t//[Proposed Change] WorkloadIdentity represents  azure workload identity.\n\tWorkloadIdentity IdentityType = \"WorkloadIdentity\"\n)\n\n```\n```\n\n----------------------------------------\n\nTITLE: Including Azure Provider v1beta1 API Documentation Template\nDESCRIPTION: A template include directive that loads the v1beta1 API documentation from a raw HTML file. This is likely used as part of generating documentation for the Azure provider's API endpoints and types.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/reference/v1beta1-api.md#2025-04-22_snippet_0\n\nLANGUAGE: gotemplate\nCODE:\n```\n{{ #include v1beta1-api-raw.html }}\n```\n\n----------------------------------------\n\nTITLE: Running Test Coverage for Azure Cluster API Provider\nDESCRIPTION: Command to execute the test coverage script. Used in the pull-cluster-api-provider-azure-coverage presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-test-coverage\n```\n\n----------------------------------------\n\nTITLE: Expected JSON Format for User-Assigned Identity Credentials (JSON)\nDESCRIPTION: This JSON snippet illustrates the required structure for the credentials file used with the 'UserAssignedIdentityCredential' type in `AzureClusterIdentity`. It includes essential fields like `client_id`, `client_secret` (a base64 encoded certificate), `tenant_id`, `resource_id`, various authentication endpoints, and certificate validity timestamps (`not_before`, `not_after`, etc.). This format is typically obtained from the Azure MSI data plane and used by 1st party Microsoft applications.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/identities.md#2025-04-22_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n        {\n            \"client_id\": \"0998...\",\n            \"client_secret\": \"MIIKUA...\",\n            \"client_secret_url\": \"https://control...\",\n            \"tenant_id\": \"93b...\",\n            \"object_id\": \"ae...\",\n            \"resource_id\": \"/subscriptions/...\",\n            \"authentication_endpoint\": \"https://login.microsoftonline.com/\",\n            \"mtls_authentication_endpoint\": \"https://login.microsoftonline.com/\",\n            \"not_before\": \"2025-02-07T13:29:00Z\",\n            \"not_after\": \"2025-05-08T13:29:00Z\",\n            \"renew_after\": \"2025-03-25T13:29:00Z\",\n            \"cannot_renew_after\": \"2025-08-06T13:29:00Z\"\n        }\n```\n\n----------------------------------------\n\nTITLE: Retrieving Cluster Pod CIDR Blocks using kubectl (Bash)\nDESCRIPTION: This Bash script uses kubectl to query the management cluster for the specified Cluster API cluster object (`${CLUSTER_NAME}`) and extracts the primary pod CIDR block, exporting it as `CCM_CIDR_BLOCK`. It also attempts to retrieve a secondary CIDR block for dual-stack configurations and exports both concatenated into `CCM_CLUSTER_CIDR` if the secondary exists. Requires `kubectl` access to the management cluster and the `CLUSTER_NAME` environment variable to be set.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nexport CCM_CIDR_BLOCK=$(kubectl get cluster \"${CLUSTER_NAME}\" -o=jsonpath='{.spec.clusterNetwork.pods.cidrBlocks[0]}')\nif DUAL_CIDR=$(kubectl get cluster \"${CLUSTER_NAME}\" -o=jsonpath='{.spec.clusterNetwork.pods.cidrBlocks[1]}' 2> /dev/null); then\n  export CCM_CLUSTER_CIDR=\"${CCM_CLUSTER_CIDR}\\,${DUAL_CIDR}\"\nfi\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for Internal Load Balancer Features in Tests - Go\nDESCRIPTION: This Go snippet shows how to set critical Azure-related environment variables before applying the test cluster template using clusterctl. The snippet employs the Expect/os.Setenv pattern (Gomega) to ensure environment variables for enabling apiserver ILB and specifying CIDR/IP ranges are reliably set before invoking cluster API workflows. Dependencies: Go test environment, Gomega for assertions, and clusterctl. Inputs: Strings for feature flags and CIDR/IP values. Output: Test environment ready with required Azure settings. Must be inserted before clusterctl.ApplyClusterTemplateAndWait().\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/tilt-with-aks-as-mgmt-ilb.md#2025-04-22_snippet_3\n\nLANGUAGE: go\nCODE:\n```\nExpect(os.Setenv(\"EXP_APISERVER_ILB\", \"true\")).To(Succeed())\nExpect(os.Setenv(\"AZURE_INTERNAL_LB_PRIVATE_IP\", \"10.0.0.101\")).To(Succeed())\nExpect(os.Setenv(\"AZURE_VNET_CIDR\", \"10.0.0.0/8\")).To(Succeed())\nExpect(os.Setenv(\"AZURE_CP_SUBNET_CIDR\", \"10.0.0.0/16\")).To(Succeed())\nExpect(os.Setenv(\"AZURE_NODE_SUBNET_CIDR\", \"10.1.0.0/16\")).To(Succeed())\n```\n\n----------------------------------------\n\nTITLE: Documenting CHANGELOG Folder Purpose in Markdown\nDESCRIPTION: This markdown snippet explains the purpose of the CHANGELOG folder, its role in triggering automated releases, and provides a link to more detailed release documentation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/CHANGELOG/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# CHANGELOG\n\nThis folder contains release notes for past releases. Changes to this folder in the main branch trigger a GitHub Action that creates release tags and a draft release.\n\nSee [release documentation](https://capz.sigs.k8s.io/developers/releasing) for more information.\n```\n\n----------------------------------------\n\nTITLE: Configuring Terraform GCR Module for Developer Environment in HCL\nDESCRIPTION: An example of using the terraform-gcr-init module to set up a Google Cloud project with GCR for a developer. The module creates a project with a specific owner, organization ID, and billing account, making GCR repositories publicly readable.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/terraform-gcr-init/README.md#2025-04-22_snippet_0\n\nLANGUAGE: hcl\nCODE:\n```\nmodule \"a_dev\" {\n  source  = \"<path to here>\"\n\n  // The name of the developer\n  short_name = \"a_dev\"\n\n  // A Google entity that has ownership of the project\n  owners = \"group:cluster-provider-azure@sigs.k8s.io\"\n\n  // The organisation ID\n  org_id = \"123456789012\"\n\n  // The billing account for this project\n  billing_account = \"012345-6789AB-CDEF01\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running Kubernetes Conformance Test Suite in CAPZ\nDESCRIPTION: Command to run the Kubernetes Conformance test suite locally in Cluster API Provider Azure. The script handles setting up a test cluster and executing the conformance tests against it.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-conformance.sh\n```\n\n----------------------------------------\n\nTITLE: Defining Azure Cloud Config Fields for Workload Identity (Go)\nDESCRIPTION: This Go code snippet shows two fields added to a struct, likely representing the Azure cloud provider configuration (`cloud-config`). `AADFederatedTokenFile` specifies the path to the projected service account token file, and `UseFederatedWorkloadIdentityExtension` is a boolean flag to enable the workload identity feature within the cloud provider. CAPZ sets these fields when workload identity is configured.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\n```go\n\tAADFederatedTokenFile string `json:\"aadFederatedTokenFile,omitempty\" yaml:\"aadFederatedTokenFile,omitempty\"`\n\tUseFederatedWorkloadIdentityExtension bool `json:\"useFederatedWorkloadIdentityExtension,omitempty\" yaml:\"useFederatedWorkloadIdentityExtension,omitempty\"`\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Azure Resource Conditions in Cluster API Provider for Azure\nDESCRIPTION: Go code defining constants for resource conditions and reasons that track the state of various Azure resources. These conditions provide granular status information about resources like resource groups, VNets, security groups, and more.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20210716-async-azure-resource-creation-deletion.md#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\n// Azure Services Conditions and Reasons.\nconst (\n    // ResourceGroupReadyCondition means the resource group exists and is ready to be used.\n    ResourceGroupReadyCondition clusterv1.ConditionType = \"ResourceGroupReady\"\n    // VNetReadyCondition means the virtual network exists and is ready to be used.\n    VNetReadyCondition clusterv1.ConditionType = \"VNetReady\"\n    // SecurityGroupsReadyCondition means the security groups exist and are ready to be used.\n    SecurityGroupsReadyCondition clusterv1.ConditionType = \"SecurityGroupsReady\"\n    // RouteTablesReadyCondition means the route tables exist and are ready to be used.\n    RouteTablesReadyCondition clusterv1.ConditionType = \"RouteTablesReady\"\n    // PublicIPsReadyCondition means the public IPs exist and are ready to be used.\n    PublicIPsReadyCondition clusterv1.ConditionType = \"PublicIPsReady\"\n    // NATGatewaysReadyCondition means the NAT gateways exist and are ready to be used.\n    NATGatewaysReadyCondition clusterv1.ConditionType = \"NATGatewaysReady\"\n    // SubnetsReadyCondition means the subnets exist and are ready to be used.\n    SubnetsReadyCondition clusterv1.ConditionType = \"SubnetsReady\"\n    // LoadBalancersReadyCondition means the load balancers exist and are ready to be used.\n    LoadBalancersReadyCondition clusterv1.ConditionType = \"LoadBalancersReady\"\n    // PrivateDNSReadyCondition means the private DNS exists and is ready to be used.\n    PrivateDNSReadyCondition clusterv1.ConditionType = \"PrivateDNSReady\"\n    // BastionHostReadyCondition means the bastion host exists and is ready to be used.\n    BastionHostReadyCondition clusterv1.ConditionType = \"BastionHostReady\"\n    // InboundNATRulesReadyCondition means the inbound NAT rules exist and are ready to be used.\n    InboundNATRulesReadyCondition clusterv1.ConditionType = \"InboundNATRulesReady\"\n    // AvailabilitySetReadyCondition means the availability set exists and is ready to be used.\n    AvailabilitySetReadyCondition clusterv1.ConditionType = \"AvailabilitySetReady\"\n    // RoleAssignmentReadyCondition means the role assignment exists and is ready to be used.\n    RoleAssignmentReadyCondition clusterv1.ConditionType = \"RoleAssignmentReady\"\n\n    // CreatingReason means the resource is being created.\n    CreatingReason = \"Creating\"\n    // FailedReason means the resource failed to be created.\n    FailedReason = \"Failed\"\n    // DeletingReason means the resource is being deleted.\n    DeletingReason = \"Deleting\"\n    // DeletedReason means the resource was deleted.\n    DeletedReason = \"Deleted\"\n    // DeletionFailedReason means the resource failed to be deleted.\n    DeletionFailedReason = \"DeletionFailed\"\n)\n```\n\n----------------------------------------\n\nTITLE: Running E2E Test Workflow with Feature Flags and Azure Environment - Bash\nDESCRIPTION: This bash snippet runs the CAPZ E2E test script `ci-e2e.sh` with numerous environment variables and feature flags, configuring the CI/CD pipeline for AKS management clusters, control plane and node counts, and network-related options. Parameters include GINKGO_FOCUS for test selection, registry settings, cluster identifiers, Azure location, and flags enabling the apiserver ILB. Requires all variables to be pre-set and the script to be present. Output: orchestrated e2e test run with specified cluster and networking setup. Should be run from a shell with appropriate toolchain and credentials.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/tilt-with-aks-as-mgmt-ilb.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nGINKGO_FOCUS=\"With 3 control-plane nodes and 2 Linux and 2 Windows worker nodes\" USE_LOCAL_KIND_REGISTRY=false SKIP_CLEANUP=\"true\" SKIP_LOG_COLLECTION=\"true\" REGISTRY=\"<>\" MGMT_CLUSTER_TYPE=\"aks\" EXP_APISERVER_ILB=true AZURE_LOCATION=\"<>\" ARCH=\"amd64\" scripts/ci-e2e.sh\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Header for Kubernetes Azure Provider\nDESCRIPTION: The standard Apache License 2.0 header that appears at the top of source code files in the Kubernetes Azure Provider codebase. It specifies the copyright ownership by The Kubernetes Authors and outlines the licensing terms.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate/boilerplate.go.txt#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\n/*\nCopyright YEAR The Kubernetes Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Prometheus Configuration\nDESCRIPTION: File structure showing the organization of Prometheus configuration files including monitoring resources, service definitions, and RBAC configurations.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/prometheus/readme.md#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./hack/observability/prometheus/\n├── capz_prom_label.yaml\n├── kustomization.yaml\n├── readme.md\n└── resources\n    ├── monitor.yaml\n    ├── prom_service.yaml\n    ├── role_binding.yaml\n    ├── role.yaml\n    └── service_account.yaml\n```\n\n----------------------------------------\n\nTITLE: Running E2E Tests for Cluster API Provider Azure\nDESCRIPTION: Basic command to run end-to-end tests locally for Cluster API Provider Azure. Requires Azure credentials to be set as environment variables before execution.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-e2e.sh\n```\n\n----------------------------------------\n\nTITLE: Installing NVIDIA GPU Operator with Helm - Shell\nDESCRIPTION: This snippet installs the NVIDIA GPU Operator on the newly created Kubernetes cluster using Helm. It requires access to the kubeconfig file of the cluster and installs the operator from the NVIDIA Helm repository. The command outputs the status of the Helm release.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/gpu.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ helm install --kubeconfig ./azure-gpu-cluster.conf --repo https://helm.ngc.nvidia.com/nvidia gpu-operator --generate-name\n```\n\n----------------------------------------\n\nTITLE: Setting Eviction Policy for Spot VMs in AzureMachineTemplate using YAML\nDESCRIPTION: This YAML snippet illustrates configuring the `evictionPolicy` for Azure Spot VMs within an `AzureMachineTemplate`'s `spotVMOptions`. The policy determines the VM's state upon eviction: `Deallocate` (the default, stops the VM) or `Delete` (permanently removes the VM).\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/spot-vms.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nspec:\n  template:\n    spotVMOptions:\n      evictionPolicy: Delete # or Deallocate\n```\n\n----------------------------------------\n\nTITLE: Checking CAPZ Controller Logs for Quota Errors (Bash)\nDESCRIPTION: Fetches logs from the CAPZ controller manager deployment in the 'capz-system' namespace on the management cluster. This command helps identify problems where Azure virtual machine creation fails due to insufficient quota for the requested VM size or family in the target Azure region, often indicated by errors containing 'OperationNotAllowed' and 'exceeding approved ... quota'.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl logs deploy/capz-controller-manager -n capz-system manager\n```\n\n----------------------------------------\n\nTITLE: Listing and Connecting to Azure Machine Pool Instances in Bash\nDESCRIPTION: Shows how to use capz-ssh to list instances of an Azure Machine Pool and connect to a specific instance using its ID. This is useful for debugging individual nodes in a machine pool.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/debugging/Readme.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./hack/debugging/kubectl-capz-ssh  --list-azure-machine-pool  --azure-machine-pool machinepool-template-mp-0\nUtility tool to ssh'ing into CAPZ nodes\n\nListing Azure Machine Pool machinepool-template-mp-0\nID      ComputerName\n========================================\n2       machinepool-template-mp-0000002\n3       machinepool-template-mp-0000003\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ ./hack/debugging/kubectl-capz-ssh  --azure-machine-pool machinepool-template-mp-0 --azure-machine-pool-id 2\n```\n\n----------------------------------------\n\nTITLE: Apache 2.0 License Header in Go Comment Format\nDESCRIPTION: Standard Apache License 2.0 header formatted as a Go multi-line comment. Establishes copyright ownership by The Kubernetes Authors and specifies the terms under which the code can be used and distributed.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate.go.txt#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\n/*\nCopyright The Kubernetes Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n```\n\n----------------------------------------\n\nTITLE: Verifying CUDA Application Execution - Bash\nDESCRIPTION: This snippet checks the execution status of the CUDA application pod using 'kubectl get po' and 'kubectl logs'. It verifies proper execution by examining output logs for expected results, indicating successful CUDA workload execution.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/gpu.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl get po cuda-vector-add\n$ kubectl logs cuda-vector-add\n```\n\n----------------------------------------\n\nTITLE: Retrieving Node Pod CIDRs (Dual-Stack) using kubectl (Bash)\nDESCRIPTION: This command utilizes `kubectl get node` combined with a Go template (`-o go-template`) to retrieve and list both the IPv4 and IPv6 PodCIDR ranges allocated to a specified Kubernetes node within a dual-stack environment. You need to substitute `<node name>` with the relevant node's name.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/dual-stack.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get node <node name> -o go-template --template='{{range .spec.podCIDRs}}{{printf \"%s\\n\" .}}{{end}}'\n```\n\n----------------------------------------\n\nTITLE: Installing Jaeger All-In-One Helm Chart with Custom Values\nDESCRIPTION: Command to install the Jaeger all-in-one Helm chart with custom configuration values from a YAML file. This allows for customized deployments of Jaeger tracing.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/jaeger/chart/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ helm install jaeger-all-in-one -f values.yaml jaeger-all-in-one/jaeger-all-in-one\n```\n\n----------------------------------------\n\nTITLE: Defining Apache 2.0 License Header for Kubernetes Projects\nDESCRIPTION: Standard license header to be included at the top of Kubernetes project source files. It specifies the Apache 2.0 license terms with a placeholder for the copyright year that should be replaced with the actual year when used.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate/boilerplate.Makefile.txt#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Copyright YEAR The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Getting Kubernetes Services Information with Bash\nDESCRIPTION: This command retrieves service details in a Kubernetes cluster, including valid IPv6 ClusterIPs and ExternalIPs. Essential for verifying IPv6 load balancer configurations. Requires kubectl with access to the Kubernetes cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get svc\n```\n\n----------------------------------------\n\nTITLE: Retrieving Pod IPs (Dual-Stack) using kubectl (Bash)\nDESCRIPTION: This command employs `kubectl get pods` along with a Go template (`-o go-template`) to fetch and display both the IPv4 and IPv6 IP addresses assigned to a specific pod running in a dual-stack Kubernetes cluster. Replace `<pod name>` with the actual name of the target pod.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/dual-stack.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods <pod name> -o go-template --template='{{range .status.podIPs}}{{printf \"%s \\n\" .ip}}{{end}}'\n```\n\n----------------------------------------\n\nTITLE: Applying Patches for Networking Configuration via Kustomize - YAML\nDESCRIPTION: This YAML block provides kustomize patches to update AzureCluster and KubeadmConfigTemplate CRDs, enabling advanced networking features such as API server internal load balancer support, CIDR assignment for clusters and subnets, and OS-specific kubeadm pre-commands. Each patch specifies the resource kind and, if needed, a name pattern for target selection. Parameters such as frontend/public/private IPs, subnet CIDRs, and special preKubeadm commands are templated with environment variables. Required tools: kustomize and cluster-api-provider-azure with custom variables. Limitations: expects target resources already exist before patching.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/tilt-with-aks-as-mgmt-ilb.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n- target:\n    kind: AzureCluster\n  patch: |-\n    - op: add\n      path: /spec/networkSpec/apiServerLB\n      value:\n        frontendIPs:\n        - name: ${CLUSTER_NAME}-api-lb\n          publicIP:\n            dnsName: ${CLUSTER_NAME}-${APISERVER_LB_DNS_SUFFIX}.${AZURE_LOCATION}.cloudapp.azure.com\n            name: ${CLUSTER_NAME}-api-lb\n        - name: ${CLUSTER_NAME}-internal-lb-private-ip\n          privateIP: ${AZURE_INTERNAL_LB_PRIVATE_IP}\n- target:\n    kind: AzureCluster\n  patch: |-\n    - op: add\n      path: /spec/networkSpec/vnet/cidrBlocks\n      value: []\n    - op: add\n      path: /spec/networkSpec/vnet/cidrBlocks/-\n      value: ${AZURE_VNET_CIDR}\n- target:\n    kind: AzureCluster\n  patch: |-\n    - op: add\n      path: /spec/networkSpec/subnets/0/cidrBlocks\n      value: []\n    - op: add\n      path: /spec/networkSpec/subnets/0/cidrBlocks/-\n      value: ${AZURE_CP_SUBNET_CIDR}\n- target:\n    kind: AzureCluster\n  patch: |-\n    - op: add\n      path: /spec/networkSpec/subnets/1/cidrBlocks\n      value: []\n    - op: add\n      path: /spec/networkSpec/subnets/1/cidrBlocks/-\n      value: ${AZURE_NODE_SUBNET_CIDR}\n- target:\n    kind: KubeadmConfigTemplate\n    name: .*-md-0\n  patch: |-\n    - op: add\n      path: /spec/template/spec/preKubeadmCommands\n      value: []\n    - op: add\n      path: /spec/template/spec/preKubeadmCommands/-\n      value: echo '${AZURE_INTERNAL_LB_PRIVATE_IP}   ${CLUSTER_NAME}-${APISERVER_LB_DNS_SUFFIX}.${AZURE_LOCATION}.cloudapp.azure.com' >> /etc/hosts\n- target:\n    kind: KubeadmConfigTemplate\n    name: .*-md-win\n  patch: |-\n    - op: add\n      path: /spec/template/spec/preKubeadmCommands/-\n      value:\n        powershell -Command \"Add-Content -Path 'C:\\\\Windows\\\\System32\\\\drivers\\\\etc\\\\hosts' -Value '${AZURE_INTERNAL_LB_PRIVATE_IP} ${CLUSTER_NAME}-${APISERVER_LB_DNS_SUFFIX}.${AZURE_LOCATION}.cloudapp.azure.com'\"\n```\n\n----------------------------------------\n\nTITLE: Recovering from Rejected MachinePool Deletion in AKS Clusters\nDESCRIPTION: This YAML example shows both the old MachinePool that needs to be deleted (with finalizers that should be removed) and the new MachinePool that should be created to maintain the reference to the AzureManagedMachinePool. The example includes all necessary references, labels, and configuration settings needed for the recovery process.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/troubleshooting.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# MachinePool deleted\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachinePool\nmetadata:\n  finalizers:             # remove finalizers once new object is pointing to the AzureManagedMachinePool\n  - machinepool.cluster.x-k8s.io\n  labels:\n    cluster.x-k8s.io/cluster-name: capz-managed-aks\n  name: agentpool0\n  namespace: default\n  ownerReferences:\n  - apiVersion: cluster.x-k8s.io/v1beta1\n    kind: Cluster\n    name: capz-managed-aks\n    uid: 152ecf45-0a02-4635-987c-1ebb89055fa2\n  uid: ae4a235a-f0fa-4252-928a-0e3b4c61dbea\nspec:\n  clusterName: capz-managed-aks\n  minReadySeconds: 0\n  providerIDList:\n  - azure:///subscriptions/9107f2fb-e486-a434-a948-52e2929b6f18/resourceGroups/MC_rg_capz-managed-aks_eastus/providers/Microsoft.Compute/virtualMachineScaleSets/aks-agentpool0-10226072-vmss/virtualMachines/0\n  replicas: 1\n  template:\n    metadata: {}\n    spec:\n      bootstrap:\n        dataSecretName: \"\"\n      clusterName: capz-managed-aks\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureManagedMachinePool\n        name: agentpool0\n        namespace: default\n      version: v1.21.2\n\n---\n# New Machinepool\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachinePool\nmetadata:\n  finalizers:\n  - machinepool.cluster.x-k8s.io\n  generation: 2\n  labels:\n    cluster.x-k8s.io/cluster-name: capz-managed-aks\n  name: agentpool2    # change the name of the machinepool\n  namespace: default\n  ownerReferences:\n  - apiVersion: cluster.x-k8s.io/v1beta1\n    kind: Cluster\n    name: capz-managed-aks\n    uid: 152ecf45-0a02-4635-987c-1ebb89055fa2\n  # uid: ae4a235a-f0fa-4252-928a-0e3b4c61dbea     # remove the uid set for machinepool\nspec:\n  clusterName: capz-managed-aks\n  minReadySeconds: 0\n  providerIDList:\n  - azure:///subscriptions/9107f2fb-e486-a434-a948-52e2929b6f18/resourceGroups/MC_rg_capz-managed-aks_eastus/providers/Microsoft.Compute/virtualMachineScaleSets/aks-agentpool0-10226072-vmss/virtualMachines/0\n  replicas: 1\n  template:\n    metadata: {}\n    spec:\n      bootstrap:\n        dataSecretName: \"\"\n      clusterName: capz-managed-aks\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureManagedMachinePool\n        name: agentpool0\n        namespace: default\n      version: v1.21.2\n```\n\n----------------------------------------\n\nTITLE: Defining AzureManagedControlPlaneClassSpec with Inline ManagedClusterTemplate in Go\nDESCRIPTION: This snippet defines the AzureManagedControlPlaneClassSpec struct with a ManagedClusterTemplate field, which allows for inline definition of an ASO ManagedCluster template using an unstructured map.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20231122-automate-aks-features.md#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\ntype AzureManagedControlPlaneClassSpec struct {\n\t// ManagedClusterTemplate is the ASO ManagedCluster to be used as a template from which new\n\t// ManagedClusters will be created.\n\tManagedClusterTemplate map[string]interface{} `json:\"managedClusterTemplate\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Header Template for Kubernetes Files\nDESCRIPTION: Standard Apache License 2.0 copyright header template used for files in the Kubernetes ecosystem. The 'YEAR' placeholder is typically replaced with the actual copyright year when the template is applied to source files.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate/boilerplate.sh.txt#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Copyright YEAR The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Testing Connectivity to IPv6 ExternalIP with Curl\nDESCRIPTION: Executes a curl command to test HTTP connectivity to a Kubernetes workload using its IPv6 ExternalIP. Requires curl installed, and network access to the target IP; might be reliant on ISP IPv6 support.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl [2603:1030:805:2::b] -v\n* Rebuilt URL to: [2603:1030:805:2::b]/\n*   Trying 2603:1030:805:2::b...\n* TCP_NODELAY set\n* Connected to 2603:1030:805:2::b (2603:1030:805:2::b) port 80 (#0)\n> GET / HTTP/1.1\n> Host: [2603:1030:805:2::b]\n> User-Agent: curl/7.58.0\n> Accept: */*\n>\n< HTTP/1.1 200 OK\n< Server: nginx/1.17.0\n< Date: Fri, 18 Sep 2020 23:07:12 GMT\n< Content-Type: text/html\n< Content-Length: 612\n< Last-Modified: Tue, 21 May 2019 15:33:12 GMT\n< Connection: keep-alive\n< ETag: \"5ce41a38-264\"\n< Accept-Ranges: bytes\n```\n\n----------------------------------------\n\nTITLE: Extracting IPv6 CIDR for Calico Installation - Bash\nDESCRIPTION: This snippet sets the environment variable IPV6_CIDR_BLOCK by querying the IPv6 CIDR used in the cluster's pod network configuration. It utilizes kubectl and requires an existing CLUSTER_NAME env variable. The exported value is leveraged during Helm-based Calico installation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport IPV6_CIDR_BLOCK=$(kubectl get cluster \"${CLUSTER_NAME}\" -o=jsonpath='{.spec.clusterNetwork.pods.cidrBlocks[0]}')\n```\n\n----------------------------------------\n\nTITLE: Defining AzureManagedControlPlaneClassSpec with Typed ManagedClusterSpec in Go\nDESCRIPTION: This snippet defines the AzureManagedControlPlaneClassSpec struct with a ManagedClusterSpec field, which uses the exact type of an ASO ManagedCluster for inline definition of the template.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20231122-automate-aks-features.md#2025-04-22_snippet_3\n\nLANGUAGE: go\nCODE:\n```\ntype AzureManagedControlPlaneClassSpec struct {\n\t// ManagedClusterSpec defines the spec of the ASO ManagedCluster managed by this AzureManagedControlPlane.\n\tManagedClusterSpec v1api20230201.ManagedCluster_Spec `json:\"managedClusterSpec\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Python Script Initialization with Apache License\nDESCRIPTION: A Python script initialization with a shebang line that specifies Python 3 as the interpreter, followed by the Apache License 2.0 header. The script appears to be a utility for the Kubernetes Cluster API Provider for Azure, but the actual implementation code is not present in this snippet.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate/boilerplate.py.txt#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#!/usr/bin/env python3\n\n# Copyright YEAR The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Checking Out-of-Tree Azure Cloud Provider Logs (Bash)\nDESCRIPTION: Fetches logs from the external Azure cloud-controller-manager deployment within the workload cluster's 'kube-system' namespace. This command is applicable when using the 'out-of-tree' Azure cloud provider and helps diagnose failures related to Azure services, particularly LoadBalancer services.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nkubectl logs cloud-controller-manager -n kube-system\n```\n\n----------------------------------------\n\nTITLE: Verifying NVIDIA Device Plugin Availability - Bash\nDESCRIPTION: This snippet checks the availability of the 'nvidia.com/gpu' resource on cluster nodes by querying the node status using 'kubectl get nodes' and 'kubectl get node'. It outputs the allocatable resources including GPU availability.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/gpu.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl --kubeconfig ./azure-gpu-cluster.conf get nodes\n$ kubectl --kubeconfig ./azure-gpu-cluster.conf get node azure-gpu-md-0-gcc8v -o jsonpath={.status.allocatable} | jq\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentity (ManualServicePrincipal - Deprecated) in YAML\nDESCRIPTION: This YAML snippet defines an `AzureClusterIdentity` resource for Cluster API Provider Azure using the deprecated `ManualServicePrincipal` type. It specifies the Azure tenant ID, the service principal's client ID, and references a Kubernetes secret containing the client secret. The `allowedNamespaces` field restricts which namespaces can use this identity.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/multitenancy.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureClusterIdentity\nmetadata:\n  name: example-identity\n  namespace: default\nspec:\n  type: ManualServicePrincipal\n  tenantID: <azure-tenant-id>\n  clientID: <client-id-of-SP-identity>\n  clientSecret: {\"name\":\"<secret-name-for-client-password>\",\"namespace\":\"default\"}\n  allowedNamespaces:\n    list:\n    - <cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Configuring IPv4 Cluster NAT Gateway in YAML\nDESCRIPTION: This YAML snippet details the configuration of an Azure NAT gateway for node outbound traffic in an IPv4 Kubernetes cluster. Dependencies include an Azure virtual network and subnets where the NAT gateway is assigned. Key parameters like the NAT gateway name and corresponding Public IP must be specified. The snippet illustrates resource naming and assignment to nodes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/node-outbound-connection.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: cluster-natgw\n  namespace: default\nspec:\n  location: southcentralus\n  networkSpec:\n    vnet:\n      name: my-vnet\n    subnets:\n      - name: subnet-cp\n        role: control-plane\n      - name: subnet-node\n        role: node\n        natGateway:\n          name: node-natgw\n          NatGatewayIP:\n            name: pip-cluster-natgw-subnet-node-natgw\n  resourceGroup: cluster-natgw\n\n```\n\n----------------------------------------\n\nTITLE: Defining AzureClusterIdentitySpec Structure (Go)\nDESCRIPTION: This Go code snippet defines the `AzureClusterIdentitySpec` struct used within CAPZ. It contains parameters for creating an Azure Identity, notably the `Type` field which determines the kind of identity used (e.g., Service Principal, Managed Identity). This struct provides context for the proposed API changes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_3\n\nLANGUAGE: go\nCODE:\n```\n```go\n// AzureClusterIdentitySpec defines the parameters that are used to create an AzureIdentity.\ntype AzureClusterIdentitySpec struct {\n\t// Type is the type of Azure Identity used.\n\t// ServicePrincipal, ServicePrincipalCertificate, UserAssignedMSI or ManualServicePrincipal.\n\tType IdentityType `json:\"type\"`\n\n\t// ...\n\t// ...\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Fetching Latest Changes for Release\nDESCRIPTION: Commands to fetch the latest changes from upstream and checkout the main branch before generating release notes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/releasing.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit fetch upstream\ngit checkout main\n```\n\n----------------------------------------\n\nTITLE: Deploying CUDA Vector Add Pod - Shell\nDESCRIPTION: This snippet deploys a test pod running a CUDA vector addition application in the cluster. It creates a YAML manifest and applies it to the cluster using 'kubectl apply'. It verifies that the pod completes successfully, indicating functional GPU support.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/gpu.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ cat > cuda-vector-add.yaml << EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: cuda-vector-add\nspec:\n  restartPolicy: OnFailure\n  containers:\n    - name: cuda-vector-add\n      image: \"registry.k8s.io/cuda-vector-add:v0.1\"\n      resources:\n        limits:\n          nvidia.com/gpu: 1\nEOF\n$ kubectl --kubeconfig ./azure-gpu-cluster.conf apply -f cuda-vector-add.yaml\n```\n\n----------------------------------------\n\nTITLE: Defining Existing AzureMachinePoolStatus with Single LongRunningOperationState in Go\nDESCRIPTION: This Go code defines the `Future` struct and the existing `AzureMachinePoolStatus` struct within the CAPZ project. The `LongRunningOperationState` field, of type `*infrav1.Future`, is used to store the state of a single Azure long-running operation (like VMSS creation/deletion) so that it can be resumed across controller reconcile loops. This represents the synchronous approach before the proposed changes.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20210716-async-azure-resource-creation-deletion.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\n// Future contains the data needed for an Azure long-running operation to continue across reconcile loops.\ntype Future struct {\n    // Type describes the type of future, update, create, delete, etc\n    Type string `json:\"type\"`\n    // ResourceGroup is the Azure resource group for the resource\n    // +optional\n    ResourceGroup string `json:\"resourceGroup,omitempty\"`\n    // Name is the name of the Azure resource\n    // +optional\n    Name string `json:\"name,omitempty\"`\n    // FutureData is the base64 url encoded json Azure AutoRest Future\n    FutureData string `json:\"futureData,omitempty\"`\n}\n\n// AzureMachinePoolStatus defines the observed state of AzureMachinePool\nAzureMachinePoolStatus struct {\n    /*\n      Other fields omitted for brevity    \n    */\n    \n    // LongRunningOperationState saves the state for an Azure long-running operations so it can be continued on the\n    // next reconciliation loop.\n    // +optional\n    LongRunningOperationState *infrav1.Future `json:\"longRunningOperationState,omitempty\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Verifying Release Image\nDESCRIPTION: Command to verify that the promoted release image is available in the registry.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/releasing.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull registry.k8s.io/cluster-api-azure/cluster-api-azure-controller:${RELEASE_TAG}\n```\n\n----------------------------------------\n\nTITLE: Applying Cluster Configuration with kubectl - Bash\nDESCRIPTION: This snippet applies the generated cluster manifest to the management cluster, creating a GPU-enabled workload cluster. It uses 'kubectl apply' to apply the configuration. The input is a YAML manifest file, and it does not have any output beyond the server-side application acknowledgement.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/gpu.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl apply -f azure-gpu-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureASOManagedControlPlane with Disabled Local Accounts\nDESCRIPTION: YAML configuration for an AzureASOManagedControlPlane that works with disabled local accounts. This example shows how to properly configure the userCredentials secret to avoid conflicts with CAPZ's management of kubeconfig secrets.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/asomanagedcluster.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1alpha1\nkind: AzureASOManagedControlPlane\nmetadata:\n  name: ${CLUSTER_NAME}\nspec:\n  resources:\n  - apiVersion: containerservice.azure.com/v1api20231001\n    kind: ManagedCluster\n    metadata:\n      name: ${CLUSTER_NAME}\n    spec:\n      operatorSpec:\n        secrets:\n          userCredentials:\n            name: ${CLUSTER_NAME}-user-kubeconfig # NOT ${CLUSTER_NAME}-kubeconfig\n            key: value\n```\n\n----------------------------------------\n\nTITLE: Installing Azure CNI on AKS Cluster\nDESCRIPTION: This bash command applies the Azure CNI (Container Network Interface) configuration to the AKS cluster. It uses a template file from the cluster-api-provider-azure repository.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster-join-vmss.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/cluster-api-provider-azure/main/templates/addons/azure-cni-v1.yaml\n```\n\n----------------------------------------\n\nTITLE: Deprecation Warning for extraConfigMapMounts\nDESCRIPTION: Checks if extraConfigMapMounts parameter is set and displays a deprecation warning suggesting the use of extraVolumes or extraVolumeMounts instead.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/templates/NOTES.txt#2025-04-22_snippet_0\n\nLANGUAGE: helm\nCODE:\n```\n{{- if not (eq (toString .Values.extraConfigMapMounts) \"<nil>\") }}\n[WARNING] \"extraConfigMapMounts\" parameter is deprecated, please use \"extraVolumes\" or \"extraVolumesMounts\" instead.\n{{ end }}\n```\n\n----------------------------------------\n\nTITLE: Configuring Advanced CAPZ Flavor Overrides in Tilt\nDESCRIPTION: Extended YAML configuration for tilt-settings.yaml showing how to override default variables for different cluster flavors with flavor-specific and global settings.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/templates/flavors/README.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nkustomize_substitutions:\n  AZURE_SUBSCRIPTION_ID: \"****\"\n  AZURE_TENANT_ID: \"****\"\n  AZURE_CLIENT_SECRET: \"****\"\n  AZURE_CLIENT_ID: \"****\"\nworker-templates:\n  flavors:\n    default:\n      CLUSTER_NAME: example-default-cluster-name\n      AZURE_VNET_NAME: example-vnet-one\n    system-assigned-identity:\n      CLUSTER_NAME: example-SAI-cluster-name\n      AZURE_LOCATION: westus\n      AZURE_VNET_NAME: example-vnet-two\n  metadata:\n    AZURE_LOCATION: eastus\n    AZURE_RESOURCE_GROUP: test-resource-group-name\n    CONTROL_PLANE_MACHINE_COUNT: \"1\"\n    KUBERNETES_VERSION: v1.22.1\n    AZURE_CONTROL_PLANE_MACHINE_TYPE: Standard_B2s\n    WORKER_MACHINE_COUNT: \"2\"\n    AZURE_NODE_MACHINE_TYPE: Standard_B2s\n```\n\n----------------------------------------\n\nTITLE: Fetching Admin Kubeconfig for CAPZ Cluster - Bash\nDESCRIPTION: Retrieves the administrator Kubernetes configuration file for the specified CAPZ cluster and sets the KUBECONFIG environment variable for subsequent kubectl commands. Requires clusterctl CLI and valid CLUSTER_NAME.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nclusterctl get kubeconfig ${CLUSTER_NAME} > ./kubeconfig\nexport KUBECONFIG=./kubeconfig\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Header Template for Kubernetes Projects\nDESCRIPTION: The standard copyright and license header to be included at the top of source files in Kubernetes projects. It references the Apache License 2.0 and includes the condition that the code cannot be used outside the terms of the license.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate/boilerplate.bzl.txt#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Copyright YEAR The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Tilt Cluster Cleanup Command\nDESCRIPTION: Command to tear down and reset the Kind management cluster\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nmake kind-reset\n```\n\n----------------------------------------\n\nTITLE: Querying Azure AD for Signed-in User Object ID - Bash\nDESCRIPTION: Uses Azure CLI to query the objectId of the currently authenticated Azure AD user. The objectId is used for assigning RBAC permissions in the Kubernetes cluster. Requires az CLI and permission to query signed-in user info.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\naz ad signed-in-user show --query objectId -o tsv\n```\n\n----------------------------------------\n\nTITLE: Defining Kubernetes Cluster with Multiple Machine Deployments for Azure Availability Sets\nDESCRIPTION: A YAML configuration that defines a Kubernetes cluster with three machine deployments to demonstrate how availability sets are created in Azure regions without failure domains. This configuration creates four availability sets: one for the control plane and one for each of the three machine deployments.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/failure-domains.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: cluster.x-k8s.io/v1beta1\nkind: Cluster\nmetadata:\n  labels:\n    cni: calico\n  name: ${CLUSTER_NAME}\n  namespace: default\nspec:\n  clusterNetwork:\n    pods:\n      cidrBlocks:\n      - 192.168.0.0/16\n  controlPlaneRef:\n    apiVersion: controlplane.cluster.x-k8s.io/v1beta1\n    kind: KubeadmControlPlane\n    name: ${CLUSTER_NAME}-control-plane\n  infrastructureRef:\n    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n    kind: AzureCluster\n    name: ${CLUSTER_NAME}\n---\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachineDeployment\nmetadata:\n  name: ${CLUSTER_NAME}-md-0\n  namespace: default\nspec:\n  clusterName: ${CLUSTER_NAME}\n  replicas: ${WORKER_MACHINE_COUNT}\n  selector:\n    matchLabels: null\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfigTemplate\n          name: ${CLUSTER_NAME}-md-0\n      clusterName: ${CLUSTER_NAME}\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachineTemplate\n        name: ${CLUSTER_NAME}-md-0\n      version: ${KUBERNETES_VERSION}\n---\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachineDeployment\nmetadata:\n  name: ${CLUSTER_NAME}-md-1\n  namespace: default\nspec:\n  clusterName: ${CLUSTER_NAME}\n  replicas: ${WORKER_MACHINE_COUNT}\n  selector:\n    matchLabels: null\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfigTemplate\n          name: ${CLUSTER_NAME}-md-1\n      clusterName: ${CLUSTER_NAME}\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachineTemplate\n        name: ${CLUSTER_NAME}-md-1\n      version: ${KUBERNETES_VERSION}\n---\napiVersion: cluster.x-k8s.io/v1beta1\nkind: MachineDeployment\nmetadata:\n  name: ${CLUSTER_NAME}-md-2\n  namespace: default\nspec:\n  clusterName: ${CLUSTER_NAME}\n  replicas: ${WORKER_MACHINE_COUNT}\n  selector:\n    matchLabels: null\n  template:\n    spec:\n      bootstrap:\n        configRef:\n          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1\n          kind: KubeadmConfigTemplate\n          name: ${CLUSTER_NAME}-md-2\n      clusterName: ${CLUSTER_NAME}\n      infrastructureRef:\n        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1\n        kind: AzureMachineTemplate\n        name: ${CLUSTER_NAME}-md-2\n      version: ${KUBERNETES_VERSION}\n```\n\n----------------------------------------\n\nTITLE: Copying kubeadm-config ConfigMap for Calico Windows Node Support - Bash\nDESCRIPTION: This multi-line Bash snippet ensures that the kubeadm-config ConfigMap is available in the calico-system namespace, needed for Calico Windows node support. It creates the namespace if absent, retrieves the ConfigMap from kube-system, updates its metadata to the new namespace, and recreates it using kubectl and sed. Requires kubectl and administrative permission to modify ConfigMaps and namespaces.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create ns calico-system\nkubectl get configmap kubeadm-config --namespace=kube-system -o yaml \\\n| sed 's/namespace: kube-system/namespace: calico-system/' \\\n| kubectl create -f -\n```\n\n----------------------------------------\n\nTITLE: Dockerfile Syntax Definition for Cluster API Provider Azure\nDESCRIPTION: Sets the syntax parser for the Dockerfile to use the docker/dockerfile:1 parser, which is the standard Docker parser.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate/boilerplate.Dockerfile.txt#2025-04-22_snippet_0\n\nLANGUAGE: Dockerfile\nCODE:\n```\n# syntax=docker/dockerfile:1\n```\n\n----------------------------------------\n\nTITLE: Resetting Kind Development Environment using Bash\nDESCRIPTION: This command cleans the development environment and resets the Kind (Kubernetes in Docker) cluster. It's a preparatory step before creating a new cluster to ensure a clean state.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nmake clean kind-reset\n```\n\n----------------------------------------\n\nTITLE: Patching CoreDNS to Use Host Network in Kubernetes with Bash\nDESCRIPTION: This bash command updates the CoreDNS deployment to use the host network, enabling DNS resolution via host routes on the v4 network. This is necessary because Azure DNS nameserver supports only IPv4. Execute this command in a terminal with kubectl installed and access to your Kubernetes cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkubectl patch deploy/coredns -n kube-system --type=merge -p '{\"spec\": {\"template\": {\"spec\":{\"hostNetwork\": true}}}}'\n```\n\n----------------------------------------\n\nTITLE: Running Conformance Tests with CI Artifacts for Azure Cluster API Provider\nDESCRIPTION: Command to run conformance tests using CI artifacts. Used in the pull-cluster-api-provider-azure-conformance-with-ci-artifacts presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nE2E_ARGS=\"-kubetest.use-ci-artifacts\" ./scripts/ci-conformance.sh\n```\n\n----------------------------------------\n\nTITLE: Checking Kubernetes Node Internal IPs with Bash\nDESCRIPTION: This command inspects a specific node's internal IP addresses in a Kubernetes cluster using a go-template. It verifies that the node has both IPv6 and IPv4 addresses, important for dual-stack host configurations. Ensure kubectl access to the target cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get nodes ipv6-0-md-0-7k8vm -o go-template --template='{{range .status.addresses}}{{printf \"%s: %s \\n\" .type .address}}{{end}}'\n```\n\n----------------------------------------\n\nTITLE: Verifying Azure Service Principal Authentication using Azure CLI\nDESCRIPTION: These commands test the service principal by authenticating with it and running a basic Azure CLI command. This verifies that the service principal has been created correctly and has the necessary permissions.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\naz login --service-principal -u NAME -p PASSWORD --tenant TENANT\naz vm list-sizes --location eastus\n```\n\n----------------------------------------\n\nTITLE: Checking In-Tree Azure Cloud Provider Logs (Bash)\nDESCRIPTION: Retrieves logs from the kube-controller-manager pod running on a specific control plane node within the workload cluster's 'kube-system' namespace. This command is used when the Azure cloud provider integration is running 'in-tree' (part of Kubernetes core components) to diagnose issues with cloud-specific operations like LoadBalancer provisioning. Replace `<control-plane-node-name>` with the actual node name.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl logs kube-controller-manager-<control-plane-node-name> -n kube-system\n```\n\n----------------------------------------\n\nTITLE: Running Windows Conformance Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run v1beta1 conformance tests for Windows with 4 nodes. Used in the pull-cluster-api-provider-azure-upstream-v1beta1-windows presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nWINDOWS=\"true\" CONFORMANCE_NODES=\"4\" ./scripts/ci-conformance.sh\n```\n\n----------------------------------------\n\nTITLE: Fetching Pod IP Address in Kubernetes with Bash\nDESCRIPTION: This command retrieves the IP address of a specific Kubernetes pod using a go-template, useful for confirming IPv6 pod networking. It requires kubectl installed and configured to access your cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ipv6.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods nginx-f89759699-h65lt -o go-template --template='{{.status.podIP}}'\n```\n\n----------------------------------------\n\nTITLE: Running CAPI E2E Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run Cluster API E2E tests. Used in the pull-cluster-api-provider-capi-e2e presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nGINKGO_FOCUS=\"Cluster API E2E tests\" GINKGO_SKIP=\"\" ./scripts/ci-e2e.sh\n```\n\n----------------------------------------\n\nTITLE: Connecting to Spin Microservice using curl\nDESCRIPTION: A shell command utilizing 'curl' to access the Spin Wasm microservice and retrieve a simple 'Hello world' response. The command makes an HTTP GET request to the external IP at port 80, allowing interaction with the deployed service.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncurl http://20.121.244.48/hello\nHello world from Spin!\n\n```\n\n----------------------------------------\n\nTITLE: Setting Kubectl User Context for Azure AD Authentication - Bash\nDESCRIPTION: Updates kubectl configuration to define a user leveraging kubelogin for Azure AD authentication and sets a named context for this user in the target cluster. Prerequisites include kubelogin installation, exported variables AZURE_ENVIRONMENT, AZURE_SERVER_APP_ID, AZURE_CLIENT_APP_ID, AZURE_TENANT_ID, and an existing kubeconfig file. This step is necessary for performing authenticated operations as an AAD user.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config set-credentials ad-user --exec-command kubelogin --exec-api-version=client.authentication.k8s.io/v1beta1 --exec-arg=get-token --exec-arg=--environment --exec-arg=$AZURE_ENVIRONMENT --exec-arg=--server-id --exec-arg=$AZURE_SERVER_APP_ID --exec-arg=--client-id --exec-arg=$AZURE_CLIENT_APP_ID --exec-arg=--tenant-id --exec-arg=$AZURE_TENANT_ID\nkubectl config set-context ${CLUSTER_NAME}-ad-user@${CLUSTER_NAME} --user ad-user --cluster ${CLUSTER_NAME}\n```\n\n----------------------------------------\n\nTITLE: Running Pre-Submission Checks using Bash\nDESCRIPTION: This set of bash commands executes various checks recommended before submitting a Pull Request. `make lint` checks code style, `make lint-fix` attempts to fix lint errors, `make verify` runs verification scripts, and `make test` executes Go unit tests.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nmake lint # Runs a suite of quick scripts to check code structure\nmake lint-fix # Runs a suite of quick scripts to fix lint errors\nmake verify # Runs a suite of verifying binaries\nmake test # Runs tests on the Go code\n```\n\n----------------------------------------\n\nTITLE: Running Verification for Azure Cluster API Provider\nDESCRIPTION: Command to run verification checks using make. Used in the pull-cluster-api-provider-azure-verify presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmake verify\n```\n\n----------------------------------------\n\nTITLE: Listing Community Flatcar CAPI Images with Azure CLI\nDESCRIPTION: These commands use the Azure CLI to find community-published Flatcar images built specifically for Cluster API (CAPI) within a designated Azure Community Gallery. The first command lists image definitions, and the second lists available versions for a specific image definition ('flatcar-stable-amd64-capi-v1.26.0'). This is relevant for the 'flatcar' flavor which uses pre-built images.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/flatcar.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ az sig image-definition list-community --location westeurope --public-gallery-name flatcar4capi-742ef0cb-dcaa-4ecb-9cb0-bfd2e43dccc0 --only-show-errors -o table\nHyperVGeneration    Location    Name                                OsState      OsType    UniqueId\n------------------  ----------  ----------------------------------  -----------  --------  ---------------------------------------------------------------------------------------------------------------\nV2                  westeurope  flatcar-stable-amd64-capi-v1.23.13  Generalized  Linux     /CommunityGalleries/flatcar4capi-742ef0cb-dcaa-4ecb-9cb0-bfd2e43dccc0/Images/flatcar-stable-amd64-capi-v1.23.13\nV2                  westeurope  flatcar-stable-amd64-capi-v1.25.4   Generalized  Linux     /CommunityGalleries/flatcar4capi-742ef0cb-dcaa-4ecb-9cb0-bfd2e43dccc0/Images/flatcar-stable-amd64-capi-v1.25.4\nV2                  westeurope  flatcar-stable-amd64-capi-v1.26.0   Generalized  Linux     /CommunityGalleries/flatcar4capi-742ef0cb-dcaa-4ecb-9cb0-bfd2e43dccc0/Images/flatcar-stable-amd64-capi-v1.26.0\n$\n```\n\nLANGUAGE: console\nCODE:\n```\n$ az sig image-version list-community --location westeurope --public-gallery-name flatcar4capi-742ef0cb-dcaa-4ecb-9cb0-bfd2e43dccc0 --only-show-errors --gallery-image-definition flatcar-stable-amd64-capi-v1.26.0\nExcludeFromLatest    Location    Name      PublishedDate                     UniqueId\n-------------------  ----------  --------  --------------------------------  --------------------------------------------------------------------------------------------------------------------------------\nFalse                westeurope  3227.2.3  2022-12-09T18:05:58.830464+00:00  /CommunityGalleries/flatcar4capi-742ef0cb-dcaa-4ecb-9cb0-bfd2e43dccc0/Images/flatcar-stable-amd64-capi-v1.26.0/Versions/3227.2.3\n```\n\n----------------------------------------\n\nTITLE: Running Windows E2E Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run E2E tests focusing on Windows-specific functionality. Used in the pull-cluster-api-provider-azure-windows presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nGINKGO_FOCUS=\".*Windows.*\" GINKGO_SKIP=\"\" ./scripts/ci-e2e.sh\n```\n\n----------------------------------------\n\nTITLE: Applying Kubernetes Resource Manifest on Windows - Shell Command\nDESCRIPTION: This shell command applies a Kubernetes resource manifest (in this case, iis.yaml) to the current kube context, deploying the resources described therein. The command requires kubectl to be installed and configured to target the desired Kubernetes cluster. Input is the manifest filename/path; output is creation or update of the specified resources. Works on macOS, Linux, and Windows (with '\\\\' for Windows file paths).\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/windows.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl apply -f .\\iis.yaml\n```\n\n----------------------------------------\n\nTITLE: Deploying Cert-Manager in Kubernetes\nDESCRIPTION: Basic example of deploying cert-manager using the cert_manager extension. The extension provides a deploy_cert_manager() function that handles the installation and verification of cert-manager in the cluster. It supports optional parameters for customizing the deployment including registry source, version selection, and Kind cluster integration.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/tilt_modules/cert_manager/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nload('ext://cert_manager', 'deploy_cert_manager')\n\ndeploy_cert_manager()\n```\n\n----------------------------------------\n\nTITLE: Applying the Flannel Deployment Manifest - Bash\nDESCRIPTION: This Bash command applies the modified kube-flannel.yml to deploy Flannel as the CNI on the target Kubernetes cluster. It expects prior customization of the network CIDR to align with the cluster's actual pod network range.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f kube-flannel.yml\n```\n\n----------------------------------------\n\nTITLE: Starting OpenTelemetry Trace Span in Go Controller\nDESCRIPTION: This Go code snippet demonstrates how to start a new OpenTelemetry trace span at the beginning of a controller's reconcile loop. It uses `tele.StartSpanWithLogger` to create a new span linked to the parent span in the context (if any), adds key-value pair attributes for metadata, and returns a logger tied to the span. The `defer done()` ensures the span is closed when the function exits.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_13\n\nLANGUAGE: go\nCODE:\n```\nctx, logger, done := tele.StartSpanWithLogger(ctx, \"controllers.AzureMachineReconciler.Reconcile\",\n   tele.KVP(\"namespace\", req.Namespace),\n   tele.KVP(\"name\", req.Name),\n   tele.KVP(\"kind\", \"AzureMachine\"),\n)\ndefer done()\n```\n\n----------------------------------------\n\nTITLE: Applying AzureClusterIdentity Configuration using kubectl\nDESCRIPTION: This Bash command uses `kubectl apply` to deploy the `AzureClusterIdentity` resource defined in the `azure-cluster-identity.yaml` file to the Kubernetes cluster. This creates or updates the identity configuration within the cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/multitenancy.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f azure-cluster-identity.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubernetes RBAC for CAPZ Resource Management\nDESCRIPTION: This YAML configuration snippet details the necessary Kubernetes ClusterRole permissions required by Cluster API Provider Azure (CAPZ) to manage resource groups via Azure Service Operator (ASO). These permissions enable CAPZ to perform operations like getting, listing, watching, creating, updating, and deleting resource group resources.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20230123-azure-service-operator.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n- apiGroups:\\n  - resources.azure.com\\n  resources:\\n  - resourcegroups\\n  - resourcegroups/status\\n  verbs:\\n  - get\\n  - list\\n  - watch\\n  - create\\n  - update\\n  - delete\n```\n\n----------------------------------------\n\nTITLE: Implementing AzureMachinePool Specifications and Status in Go\nDESCRIPTION: Defines the proposed changes for AzureMachinePool and AzureMachinePoolMachine structures, including deployment strategy and node management capabilities.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20210222-azure-machinepool-machine.md#2025-04-22_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nconst azureMachinePoolUpdateInstanceAnnotation = \"azuremachinepool.infrastructure.cluster.x-k8s.io/updateInstance\"\n\ntype AzureMachinePoolSpec struct {\n    Strategy MachineDeploymentStrategy `json:\"strategy,omitempty\"`\n    NodeDrainTimeout *metav1.Duration `json:\"nodeDrainTimeout,omitempty\"`\n}\n\ntype AzureMachinePoolMachineSpec struct {\n    ProviderID string `json:\"providerID\"`\n}\n\ntype AzureMachinePoolMachineStatus struct {\n    NodeRef *corev1.ObjectReference `json:\"nodeRef,omitempty\"`\n    Version string `json:\"version\"`\n    ProvisioningState *infrav1.VMState `json:\"provisioningState\"`\n    InstanceID string `json:\"instanceID\"`\n    InstanceName string `json:\"instanceName\"`\n    FailureReason *string `json:\"failureReason,omitempty\"`\n    FailureMessage *string `json:\"failureMessage,omitempty\"`\n    Conditions clusterv1.Conditions `json:\"conditions,omitempty\"`\n    LongRunningOperationState *infrav1.Future `json:\"longRunningOperationState,omitempty\"`\n    LatestModelApplied bool `json:\"latestModelApplied\"`\n    Ready bool `json:\"ready\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Building and Uploading Custom Kubernetes Components in Bash\nDESCRIPTION: Commands to build Kubernetes components and upload artifacts to a registry and Azure blob storage. It sets environment variables and runs a build script.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/kubernetes-developers.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport AZURE_STORAGE_ACCOUNT=<AzureStorageAccount>\nexport AZURE_STORAGE_KEY=<AzureStorageKey>\nexport REGISTRY=<Registry>\nexport TEST_K8S=\"true\"\n\nsource ./scripts/ci-build-kubernetes.sh\n```\n\n----------------------------------------\n\nTITLE: Running Periodic Coverage Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run test coverage script periodically. Used in the periodic-cluster-api-provider-azure-coverage periodic job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\nbash\n```\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-test-coverage.sh\n```\n\n----------------------------------------\n\nTITLE: Defining AzureManagedControlPlaneClassSpec with ManagedClusterTemplateRef in Go\nDESCRIPTION: This snippet defines the AzureManagedControlPlaneClassSpec struct with a ManagedClusterTemplateRef field, which references an ASO ManagedCluster to be used as a template for creating new ManagedClusters.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20231122-automate-aks-features.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\ntype AzureManagedControlPlaneClassSpec struct {\n\t// ManagedClusterTemplateRef is a reference to the ASO ManagedCluster to be used as a template from which\n\t// new ManagedClusters will be created.\n\tManagedClusterTemplateref corev1.ObjectReference `json:\"managedClusterTemplateRef\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Proposing API Changes for Asynchronous Operations State in Go CRDs\nDESCRIPTION: This Go code details the proposed API changes to support asynchronous Azure operations in CAPZ. It defines an updated `Future` struct (adding `ServiceName`, making `Name` required, renaming `FutureData` to `Data`) and introduces a `Futures` type (a slice of `Future`). Crucially, it proposes adding a `LongRunningOperationStates` field of type `Futures` to the status structs of `AzureCluster`, `AzureMachine`, `AzureMachinePool`, and `AzureMachinePoolMachine`, replacing the previous single state field. This allows tracking multiple concurrent long-running Azure operations for each resource.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20210716-async-azure-resource-creation-deletion.md#2025-04-22_snippet_1\n\nLANGUAGE: go\nCODE:\n```\n// Future contains the data needed for an Azure long-running operation to continue across reconcile loops.\ntype Future struct {\n    // Type describes the type of future, such as update, create, delete, etc\n    Type string `json:\"type\"`\n    // ResourceGroup is the Azure resource group for the resource.\n    // +optional\n    ResourceGroup string `json:\"resourceGroup,omitempty\"`\n    // ServiceName is the name of the Azure service the resource belongs to.\n    ServiceName string `json:\"serviceName\"`\n    // Name is the name of the Azure resource.\n    Name string `json:\"name\"`\n    // Data is the base64 url encoded json Azure AutoRest Future.\n    Data string `json:\"data,omitempty\"`\n}\n\ntype Futures []Future\n\n// AzureClusterStatus defines the observed state of AzureCluster.\ntype AzureClusterStatus struct {\n    /*\n      Other fields omitted for brevity    \n    */\n\n    // LongRunningOperationStates saves the states for Azure long-running operations so they can be continued on the\n    // next reconciliation loop.\n    // +optional\n    LongRunningOperationStates Futures `json:\"longRunningOperationStates,omitempty\"`\n}\n\n// AzureMachineStatus defines the observed state of AzureMachine.\ntype AzureMachineStatus struct {\n    /*\n      Other fields omitted for brevity    \n    */\n\n    // LongRunningOperationStates saves the states for Azure long-running operations so they can be continued on the\n    // next reconciliation loop.\n    // +optional\n    LongRunningOperationStates Futures `json:\"longRunningOperationStates,omitempty\"`\n}\n\n// AzureMachinePoolStatus defines the observed state of AzureMachinePool.\ntype AzureMachinePoolStatus struct {\n    /*\n      Other fields omitted for brevity    \n    */\n\n    // LongRunningOperationStates saves the states for Azure long-running operations so they can be continued on the\n    // next reconciliation loop.\n    // +optional\n    LongRunningOperationStates Futures `json:\"longRunningOperationStates,omitempty\"`\n}\n\n// AzureMachinePoolMachineStatus defines the observed state of AzureMachinePoolMachine.\ntype AzureMachinePoolMachineStatus struct {\n    /*\n      Other fields omitted for brevity\n    */\n\n    // LongRunningOperationStates saves the states for Azure long-running operations so they can be continued on the\n    // next reconciliation loop.\n    // +optional\n    LongRunningOperationStates Futures `json:\"longRunningOperationStates,omitempty\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Authorizer Interface for Azure Identity Provider in Go\nDESCRIPTION: Interface definitions for Azure identity providers that implement the AutoREST Authorizer interface to handle authentication. Includes a Hash method to support caching of credentials by providing a unique hash of the credential data.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20200720-single-controller-multitenancy.md#2025-04-22_snippet_3\n\nLANGUAGE: go\nCODE:\n```\n// Authorizer is the interface that provides a PrepareDecorator used to supply request\n// authorization. Most often, the Authorizer decorator runs last so it has access to the full\n// state of the formed HTTP request.\ntype Authorizer interface {\n    WithAuthorization() PrepareDecorator\n}\n\ntype AzureIdentityProvider interface {\n    Authorizer\n\n    // Hash returns a unique hash of the data forming the credentials\n    // for this principal\n    Hash() (string, error)\n}\n```\n\n----------------------------------------\n\nTITLE: Tracking Last Image Prototype Timestamp in AzureMachinePool Status (YAML)\nDESCRIPTION: Illustrates how the timestamp of the last successful OS image caching operation is stored within the `status` field of an `AzureMachinePool` resource. The controller uses the `lastImagePrototype` field to determine when the configured caching interval has elapsed and a new snapshot process should be initiated.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20230612-node-os-image-caching.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nstatus:\n  lastImagePrototype: \"2023-06-12T23:14:55Z\"\n```\n\n----------------------------------------\n\nTITLE: Using capz-map to View Configuration Mappings in Bash\nDESCRIPTION: Demonstrates the use of the capz-map kubectl plugin to view how different Custom Resource Definitions (CRDs) are mapped together in a CAPZ deployment. This helps in understanding the relationships between various components.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/debugging/Readme.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ kubectl capz map\nAzureCluster: capz-cluster-0\nAzureMachine: capz-cluster-0-control-plane-5b5fc\nMachine: capz-cluster-0-control-plane-xhbjh\nKubeadmconfig: capz-cluster-0-control-plane-g8gql\n```\n\n----------------------------------------\n\nTITLE: Running CI Test Script for Azure Cluster API Provider\nDESCRIPTION: Command to execute the CI test script for the Cluster API Provider Azure project. Used in the pull-cluster-api-provider-azure-test presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-test.sh\n```\n\n----------------------------------------\n\nTITLE: Verifying Azure Cloud Provider Pod Status (Shell Output)\nDESCRIPTION: This snippet shows example output demonstrating the expected state of the Azure cloud provider pods within the `kube-system` namespace after a successful Helm installation. It lists the `cloud-controller-manager` pod and several `cloud-node-manager` daemonset pods in a `Running` state.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/addons.md#2025-04-22_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nkube-system   cloud-controller-manager                                            1/1     Running   0          41s\nkube-system   cloud-node-manager-5pklx                                            1/1     Running   0          26s\nkube-system   cloud-node-manager-hbbqt                                            1/1     Running   0          30s\nkube-system   cloud-node-manager-mfsdg                                            1/1     Running   0          39s\nkube-system   cloud-node-manager-qrz74                                            1/1     Running   0          24s\n```\n\n----------------------------------------\n\nTITLE: Installing Kubectl Plugins for CAPZ Debugging in Bash\nDESCRIPTION: Instructions for installing kubectl plugins by copying the debugging scripts to a directory in the system PATH. This allows the scripts to be used as kubectl plugins or standalone scripts.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/debugging/Readme.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncp hack/debugging/kubectl-* /usr/local/bin\n```\n\nLANGUAGE: bash\nCODE:\n```\n./hack/debugging/kubectl-capz-ssh\n```\n\n----------------------------------------\n\nTITLE: Querying Specific ASO Managed Cluster API Version\nDESCRIPTION: Shows how to query Azure Service Operator (ASO) managed clusters specifying an exact API version (`managedclusters.v1api20240402preview.containerservice.azure.com`). This method ensures retrieval of the resource representation corresponding to the specified version, bypassing kubectl's default version selection which might otherwise show an older version due to ASO's versioning scheme.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/FAQ.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get managedclusters.v1api20240402preview.containerservice.azure.com\n```\n\n----------------------------------------\n\nTITLE: Using capz-ssh to Connect to Azure Machine in Bash\nDESCRIPTION: Demonstrates how to use the capz-ssh kubectl plugin to connect to an Azure Machine for debugging VM join issues. It shows how to list Azure Machines and connect to a specific one.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/debugging/Readme.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# find the azure cluster and azure machine you wish to ssh too\n$ kubectl get azuremachine\nNAME                                 READY   STATE\ncapz-cluster-0-control-plane-5b5fc   true    Succeeded\ncapz-cluster-0-control-plane-vg8pl   true    Succeeded\ncapz-cluster-0-control-plane-z5pst   true    Succeeded\ncapz-cluster-0-md-0-fljwt            true    Succeeded\ncapz-cluster-0-md-0-wbx2r            true    Succeeded\n\n\n$ kubectl capz ssh -am capz-cluster-3-control-plane-rcmkh\n```\n\n----------------------------------------\n\nTITLE: Running Automated Log Collection Tool (Go/Bash)\nDESCRIPTION: Executes a Go-based log collection tool provided within the CAPZ repository (`test/logger.go`) to automatically gather logs from machines belonging to a specified workload cluster. Requires Go installed and the command run from the repository root. The `--name` and `--namespace` flags specify the target workload cluster. Logs are typically saved to `./_artifacts}`. Requires the local kubeconfig to be pointing to the management cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ngo run -tags e2e ./test/logger.go --name <workload-cluster-name> --namespace <workload-cluster-namespace>\n```\n\n----------------------------------------\n\nTITLE: Upgrading Azure Cloud Provider Components with Helm in Bash\nDESCRIPTION: Helm commands to upgrade the Azure cloud provider components in the test cluster with new image versions, demonstrating iterative development and testing.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/kubernetes-developers.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport IMAGE_TAG=canaryv2\nhelm upgrade --install --repo https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo cloud-provider-azure --generate-name --set infra.clusterName=${CLUSTER_NAME} \\\n--set cloudControllerManager.imageRepository=\"${IMAGE_REGISTRY}\" \\\n--set cloudNodeManager.imageRepository=\"${IMAGE_REGISTRY}\" \\\n--set cloudControllerManager.imageName=\"${CCM_IMAGE_NAME}\" \\\n--set cloudNodeManager.imageName=\"${CNM_IMAGE_NAME}\" \\\n--set cloudControllerManager.imageTag=\"${IMAGE_TAG}\" \\\n--set cloudNodeManager.imageTag=\"${IMAGE_TAG}\"\nexport IMAGE_TAG=canaryv3\nhelm upgrade --install --repo https://raw.githubusercontent.com/kubernetes-sigs/cloud-provider-azure/master/helm/repo cloud-provider-azure --generate-name --set infra.clusterName=${CLUSTER_NAME} \\\n--set cloudControllerManager.imageRepository=\"${IMAGE_REGISTRY}\" \\\n--set cloudNodeManager.imageRepository=\"${IMAGE_REGISTRY}\" \\\n--set cloudControllerManager.imageName=\"${CCM_IMAGE_NAME}\" \\\n--set cloudNodeManager.imageName=\"${CNM_IMAGE_NAME}\" \\\n--set cloudControllerManager.imageTag=\"${IMAGE_TAG}\" \\\n--set cloudNodeManager.imageTag=\"${IMAGE_TAG}\"\n```\n\n----------------------------------------\n\nTITLE: Managed Cluster Documentation Structure\nDESCRIPTION: Lists the structure of documents available under the Managed Clusters section, including adoption guides, configuration, and troubleshooting.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managed.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [Adopting Clusters](managed.md)\n- [ASO Managed Clusters](asomanagedcluster.md)\n- [Managed Clusters](managedcluster.md)\n- [Managed Clusters - Join VMSS Nodes](adopting-clusters.md)\n- [Troubleshooting](troubleshooting.md)\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for OpenTelemetry Resources\nDESCRIPTION: Directory structure showing the organization of OpenTelemetry-related files in the project, including configuration files, patches, and Helm chart components.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/readme.md#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n./hack/observability/opentelemetry/\n├── controller-manager-patch.yaml\n├── fetch-otel-resources.yaml\n├── readme.md\n├── values.yaml\n└── chart\n    ├── .helmignore\n    ├── Chart.yaml\n    ├── README.md\n    ├── values.schema.json\n    ├── values.yaml\n    └── templates\n        ├── _config.tpl\n        ├── configmap-agent.yaml\n        ├── deployment.yaml\n        └── ... (and many others)\n```\n\n----------------------------------------\n\nTITLE: Enabling Kubernetes Container Log Collection in YAML\nDESCRIPTION: This YAML configuration enables container log collection, uses the contrib version of the collector image, and sets the appropriate command.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/README.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nagentCollector:\n  containerLogs:\n    enabled: true\n\nimage:\n  repository: otel/opentelemetry-collector-contrib\n\ncommand:\n  name: otelcol-contrib\n```\n\n----------------------------------------\n\nTITLE: Deprecation Warning for extraHostPathMounts\nDESCRIPTION: Checks if extraHostPathMounts parameter is set and displays a deprecation warning suggesting the use of extraVolumes or extraVolumeMounts instead.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/templates/NOTES.txt#2025-04-22_snippet_1\n\nLANGUAGE: helm\nCODE:\n```\n{{- if not (eq (toString .Values.extraHostPathMounts) \"<nil>\") }}\n[WARNING] \"extraHostPathMounts\" parameter is deprecated, please use \"extraVolumes\" or \"extraVolumesMounts\" instead.\n{{ end }}\n```\n\n----------------------------------------\n\nTITLE: Running Conformance Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run v1beta1 conformance tests. Used in the pull-cluster-api-provider-azure-conformance-v1beta1 presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-conformance.sh\n```\n\n----------------------------------------\n\nTITLE: Checking Markdown Links for Azure Cluster API Provider\nDESCRIPTION: Command to check all markdown files for broken links using the markdown-link-check tool. Used in the Github Markdown-link-check presubmit workflow.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nfind . -name \\*.md | xargs -I{} markdown-link-check -c .markdownlinkcheck.json {}\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Collector Chart in Console\nDESCRIPTION: This command installs the OpenTelemetry Collector chart with the release name 'my-opentelemetry-collector'.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/README.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nhelm install my-opentelemetry-collector open-telemetry/opentelemetry-collector\n```\n\n----------------------------------------\n\nTITLE: Deprecation Warning for secretMounts\nDESCRIPTION: Checks if secretMounts parameter is set and displays a deprecation warning suggesting the use of extraVolumes or extraVolumeMounts instead.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/templates/NOTES.txt#2025-04-22_snippet_2\n\nLANGUAGE: helm\nCODE:\n```\n{{- if not (eq (toString .Values.secretMounts) \"<nil>\") }}\n[WARNING] \"secretMounts\" parameter is deprecated, please use \"extraVolumes\" or \"extraVolumesMounts\" instead.\n{{ end }}\n```\n\n----------------------------------------\n\nTITLE: Specifying Additional ASO CRDs via Environment Variable (Bash)\nDESCRIPTION: Sets the `ADDITIONAL_ASO_CRDS` environment variable to instruct `clusterctl` to install specific Azure Service Operator (ASO) Custom Resource Definitions (CRDs) in addition to the default ones required by CAPZ. This example specifies all CRDs from `cache.azure.com` and the `MongodbDatabase` CRD from `documentdb.azure.com`. This variable is used during both fresh `clusterctl init` and CAPZ upgrades (v1.14.0+). The variable accepts a semicolon-separated list of CRD patterns.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aso.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport ADDITIONAL_ASO_CRDS=\"cache.azure.com/*;documentdb.azure.com/MongodbDatabase\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure Instrumentation Key in tilt-settings.yaml\nDESCRIPTION: YAML configuration to specify the Azure Application Insights Instrumentation Key in tilt-settings.yaml, enabling trace export to Azure.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/readme.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nkustomize_substitutions:\n  AZURE_INSTRUMENTATION_KEY: \"12345678-1234-1234-1234-1234567890abc\"\n```\n\n----------------------------------------\n\nTITLE: Configuring GPU-Enabled Cluster Flavor in Tilt\nDESCRIPTION: YAML configuration example for tilt-settings.yaml that specifically configures the nvidia-gpu flavor to use N-series VMs capable of supporting GPU workloads.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/templates/flavors/README.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nkustomize_substitutions:\n  AZURE_SUBSCRIPTION_ID: \"****\"\n  AZURE_TENANT_ID: \"****\"\n  AZURE_CLIENT_SECRET: \"****\"\n  AZURE_CLIENT_ID: \"****\"\nworker-templates:\n  flavors:\n    nvidia-gpu:\n      AZURE_NODE_MACHINE_TYPE: Standard_NC6s_v3\n  metadata:\n    AZURE_CONTROL_PLANE_MACHINE_TYPE: Standard_B2s\n    AZURE_LOCATION: southcentralus\n    KUBERNETES_VERSION: v1.22.1\n    WORKER_MACHINE_COUNT: \"1\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving workload cluster kubeconfig\nDESCRIPTION: Command to get the kubeconfig for the newly created workload cluster to enable interaction with it.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/introduction.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nclusterctl get kubeconfig my-cluster > my-cluster.kubeconfig\n```\n\n----------------------------------------\n\nTITLE: Running Test Coverage Check for Azure Cluster API Provider\nDESCRIPTION: Command to run test coverage check using make. Used in the Github Code-coverage-check postsubmit workflow.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nmake test-cover\n```\n\n----------------------------------------\n\nTITLE: CAPZ Manager Aggregation Role Label\nDESCRIPTION: Kubernetes label used to include additional RBAC permissions in the CAPZ manager role.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/CHANGELOG/v1.16.0.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.x-k8s.io/aggregate-to-capz-manager: \"true\"\n```\n\n----------------------------------------\n\nTITLE: Creating Azure Federated Identity Credential (Bash)\nDESCRIPTION: This Azure CLI command creates a federated identity credential in Azure. It links a Kubernetes service account (specified by `--subject`) from a cluster with a specific OIDC issuer (`--issuer`) to an Azure user-assigned managed identity (`--identity-name`). This association allows the Kubernetes service account to exchange its projected token for an Azure AD access token. Environment variables are expected for identity name, resource group, issuer URL, service account namespace, and service account name.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n```bash\naz identity federated-credential create \\\n  --name \"kubernetes-federated-credential\" \\\n  --identity-name \"${USER_ASSIGNED_IDENTITY_NAME}\" \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --issuer \"${SERVICE_ACCOUNT_ISSUER}\" \\\n  --subject \"system:serviceaccount:${SERVICE_ACCOUNT_NAMESPACE}:${SERVICE_ACCOUNT_NAME}\"\n```\n```\n\n----------------------------------------\n\nTITLE: ASO Managed Cluster Setup\nDESCRIPTION: Commands and configuration for setting up an ASO managed cluster using Helm.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/getting-started.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add capi https://mboersma.github.io/cluster-api-charts\n```\n\nLANGUAGE: yaml\nCODE:\n```\ncredentialSecretName: \"aso-credentials\"\ncreateCredentials: true\nsubscriptionID: \"subscription-id\"\ntenantID: \"tenant-id\"\nclientID: \"client-id\"\nclientSecret: \"client-secret\"\nauthMode: \"podIdentity\"\n\nclusterName: \"\"\nlocation: westus3\n\nmanagedMachinePoolSpecs:\n  pool0:\n    count: 1\n    mode: System\n    vmSize: Standard_DS2_v2\n    type: VirtualMachineScaleSets\n  pool1:\n    count: 1\n    mode: User\n    vmSize: Standard_DS2_v2\n    type: VirtualMachineScaleSets\n```\n\nLANGUAGE: bash\nCODE:\n```\nhelm install quick-start capi/azure-aks-aso -f values.yaml\n```\n\n----------------------------------------\n\nTITLE: Enabling EdgeZone Feature Gate for Public MEC (Bash)\nDESCRIPTION: Export the EXP_EDGEZONE environment variable to enable deployment features specific to Azure Public MEC/EdgeZone. There are no software dependencies other than Bash shell. This flag must be set so that clusterctl picks up the correct flavor and behavior for edge deployments; missing this may result in improper resource configuration.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nexport EXP_EDGEZONE=true\n```\n\n----------------------------------------\n\nTITLE: Identifying a Healthy AzureMachinePoolMachine for Snapshotting (YAML)\nDESCRIPTION: Provides an example YAML structure representing an `AzureMachinePoolMachine` (despite the 'kind' field showing 'AzureMachinePool', the context indicates it refers to a machine) highlighting the status fields used for selecting a healthy node candidate for snapshotting. Key criteria include the earliest `metadata.creationTimestamp`, `status.latestModelApplied: true`, `status.ready: true`, and various 'True' status conditions (Ready, BootstrapSucceeded, NodeHealthy) to ensure stability and readiness.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20230612-node-os-image-caching.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: node-os-image-caching-machine-pool-machine\n  namespace: default\n  creationTimestamp: \"2023-06-20T17:41:54Z\"\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-06-20T17:43:39Z\"\n    status: \"True\"\n    type: Ready\n  - lastTransitionTime: \"2023-06-20T17:43:39Z\"\n    status: \"True\"\n    type: BootstrapSucceeded\n  - lastTransitionTime: \"2023-06-20T17:43:39Z\"\n    status: \"True\"\n    type: NodeHealthy\n  latestModelApplied: true\n  ready: true\n```\n\n----------------------------------------\n\nTITLE: Initializing Cluster API Azure Provider and Generating Cluster Template (Bash)\nDESCRIPTION: This compound snippet initializes the Cluster API (CAPI) Azure infrastructure provider and generates a cluster template YAML with the edgezone flavor, storing it locally. Dependencies include clusterctl (properly installed), access to the initialized management cluster, and configured environment variables. Output YAML (edgezone-cluster.yaml) requires later user modification to reference custom images.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/publicmec-clusters.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nclusterctl init --infrastructure azure\nclusterctl generate cluster ${CLUSTER_NAME} --kubernetes-version ${KUBERNETES_VERSION} --flavor edgezone > edgezone-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: AKS Cluster Deployment Commands\nDESCRIPTION: Series of commands to create and configure an AKS cluster using clusterctl and kubectl.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/managed/managedcluster.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkind create cluster\n\nkubectl create secret generic \"${AZURE_CLUSTER_IDENTITY_SECRET_NAME}\" --from-literal=clientSecret=\"${AZURE_CLIENT_SECRET}\"\n\nclusterctl init --infrastructure azure\nclusterctl generate cluster ${CLUSTER_NAME} --kubernetes-version ${KUBERNETES_VERSION} --flavor aks > cluster.yaml\n\nkubectl apply -f cluster.yaml\n\nkubectl get cluster-api -o wide\n```\n\n----------------------------------------\n\nTITLE: SSH Access to Windows Cluster Node via SSH Proxy - Shell Command\nDESCRIPTION: This shell command initiates an SSH session to a Windows node, using the API server as a jump host (proxy). The '-t' flag enables pseudo-terminal allocation, '-i' specifies the SSH key, and '-o' configures ProxyCommand for chained SSH connections. Dependencies include OpenSSH client, a valid SSH key with access, and required network/security group configuration on the cluster. Inputs are key paths, user, API server, and Windows IP. Output is an SSH session into the Windows node. Intended for advanced Windows node management.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/windows.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nssh -t -i .sshkey -o 'ProxyCommand ssh -i .sshkey -W %h:%p capi@<api-server-ip>' capi@<windows-ip>\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Tilt Settings for CAPZ Flavors\nDESCRIPTION: Minimal YAML configuration required in tilt-settings.yaml for Azure credentials when deploying flavor clusters as Tilt resources.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/templates/flavors/README.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nkustomize_substitutions:\n  AZURE_SUBSCRIPTION_ID: \"******\"\n  AZURE_TENANT_ID: \"******\"\n  AZURE_CLIENT_SECRET: \"******\"\n  AZURE_CLIENT_ID: \"******\"\n```\n\n----------------------------------------\n\nTITLE: Defining Diagnostics Configuration Block in AzureMachineTemplate - YAML\nDESCRIPTION: This YAML snippet outlines the structure required to configure VM boot diagnostics in AzureMachineTemplate for the Cluster API Provider. It includes comments describing each field, such as storageAccountType (Managed, UserManaged, Disabled) and userManaged with storageAccountURI for custom storage scenarios. This is foundational for implementing diagnostic settings and requires Cluster API Provider for Azure with the AzureMachineTemplate resource configured.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-diagnostics.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nkind: AzureMachineTemplate\\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\\nmetadata:\\n  name: \"${CLUSTER_NAME}-control-plane\"\\nspec:\\n  template:\\n    spec:\\n      [...]\\n      diagnostics: # defines a diagnostics configuration block\\n        boot: # defines a boot diagnostics configuration block\\n          storageAccountType: Managed | UserManaged | Disabled # defaults to Managed for backwards compatibility\\n          userManaged: # This is only valid to be set when the account type is UserManaged.\\n            storageAccountURI: \"<your-storage-URI>\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Azure Bastion in CAPZ Cluster YAML\nDESCRIPTION: This YAML snippet shows how to enable Azure Bastion for CAPZ clusters by editing the AzureCluster Custom Resource (CR) to include the bastionSpec.azureBastion field. This makes it possible to SSH into cluster VMs via the Azure Portal.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ssh-access.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureCluster\nmetadata:\n  name: test1\n  namespace: default\nspec:\n  bastionSpec:\n    azureBastion: {}\n  ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Tilt Settings with Debugging Support for CAPZ\nDESCRIPTION: YAML configuration for tilt-settings.yaml that enables debugging of the CAPZ controller using delve, exposing port 30000 for remote debugging connections.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ndefault_registry: \"${REGISTRY}\"\nprovider_repos:\n- ../cluster-api-provider-azure\nenable_providers:\n- azure\n- docker\n- kubeadm-bootstrap\n- kubeadm-control-plane\nkustomize_substitutions:\n  AZURE_SUBSCRIPTION_ID: <subscription-id>\n  AZURE_TENANT_ID: <tenant-id>\n  AZURE_CLIENT_SECRET: <client-secret>\n  AZURE_CLIENT_ID: <client-id>\ndebug:\n  azure:\n    continue: true\n    port: 30000\n```\n\n----------------------------------------\n\nTITLE: Explaining CI Test Templates Directory Structure in Markdown\nDESCRIPTION: Markdown documentation explaining the purpose and usage of template YAML specifications in the CI test directory. Details that these configurations are continuously validated and represent known-working cluster setups.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/templates/test/ci/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# CI test templates\n\nThe template yaml specs in this directory are intended for regular, automated testing by CI jobs.\n\nThe set of cluster configurations in `/templates/test/ci/` should be considered as the set of \"known-working\" cluster configurations, and continually validated against relevant code changes.\n```\n\n----------------------------------------\n\nTITLE: Pushing CAPZ Docker Images to Registry\nDESCRIPTION: Shell command to push built CAPZ container images to a specified container registry using make targets.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nREGISTRY=${REGISTRY} MANAGER_IMAGE_TAG=${MANAGER_IMAGE_TAG:=\"dev\"} make docker-push\n```\n\n----------------------------------------\n\nTITLE: Running Markdown Link Checker with Shell Command\nDESCRIPTION: Runs a link checker across all Markdown files in the repository, excluding those in the node_modules directory, using the markdown-link-check tool. This shell snippet ensures documentation quality by verifying hyperlinks, taking configuration from .markdownlinkcheck.json and running quietly (-q). Prerequisites include having markdown-link-check installed globally or in the environment, and a proper configuration file. The relevant patterns use GNU find command and shell escaping.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nfind . -name '*.md' -not -path './node_modules/*' -exec markdown-link-check '{}' --config .markdownlinkcheck.json -q ';'\n```\n\n----------------------------------------\n\nTITLE: Defining AzureManagedControlPlaneClassSpec with ASO ManagedCluster Patches in Go\nDESCRIPTION: This snippet defines the AzureManagedControlPlaneClassSpec struct with an ASOManagedClusterPatches field, which allows for specifying patches to be applied to the generated ASO ManagedCluster resource.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20231122-automate-aks-features.md#2025-04-22_snippet_4\n\nLANGUAGE: go\nCODE:\n```\ntype AzureManagedControlPlaneClassSpec struct {\n\t...\n\n\t// ASOManagedClusterPatches defines patches to be applied to the generated ASO ManagedCluster resource.\n\tASOManagedClusterPatches []string `json:\"asoManagedClusterPatches,omitempty\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Repository Directory Structure with Tree\nDESCRIPTION: Shows the expected folder structure after cloning both CAPI and CAPZ repositories, to be used with Tilt for development.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_4\n\nLANGUAGE: tree\nCODE:\n```\n|-- src/cluster-api-provider-azure\n|-- src/cluster-api (run `tilt up` here)\n```\n\n----------------------------------------\n\nTITLE: Defining AzureManagedControlPlaneSpec with ASO Reference in Go\nDESCRIPTION: This Go struct definition outlines Option 1 for the API design. The `AzureManagedControlPlaneSpec` struct contains a field `ManagedClusterRef` of type `corev1.ObjectReference`. This approach proposes that the CAPZ resource references an existing ASO ManagedCluster resource, which CAPZ would not create but would interact with. This relies on `corev1` from the Kubernetes API.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20231122-automate-aks-features.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\n```go\ntype AzureManagedControlPlaneSpec struct {\n\t// ManagedClusterRef is a reference to the ASO ManagedCluster backing this AzureManagedControlPlane.\n\tManagedClusterRef corev1.ObjectReference `json:\"managedClusterRef\"`\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Running Full E2E Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run all E2E tests focusing on workload cluster creation without skipping any tests. Used in the pull-cluster-api-provider-e2e-full presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nGINKGO_FOCUS=\"Workload cluster creation\" GINKGO_SKIP=\"\" ./scripts/ci-e2e.sh\n```\n\n----------------------------------------\n\nTITLE: Creating an Azure Service Principal with Subscription-level Scope using Azure CLI\nDESCRIPTION: These commands create a service principal with Contributor role at the subscription level. This grants the service principal permissions to manage resources within the entire subscription.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/vm-identity.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\naz login\naz account set --subscription=\"${AZURE_SUBSCRIPTION_ID}\"\naz ad sp create-for-rbac --role=\"Contributor\" --scopes=\"/subscriptions/${AZURE_SUBSCRIPTION_ID}\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Node OS Caching via Environment Variable in Bash\nDESCRIPTION: Demonstrates how an operator enables the proposed Node OS caching feature globally by setting the `AZURE_NODE_OS_CACHING` environment variable to `true`. This setting likely acts as a feature flag for the CAPZ controller manager, activating the caching logic.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20230612-node-os-image-caching.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport AZURE_NODE_OS_CACHING=true\n```\n\n----------------------------------------\n\nTITLE: Running AKS E2E Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run E2E tests focusing on AKS functionality. Used in the pull-cluster-api-provider-azure-e2e-exp presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nGINKGO_FOCUS=\".*AKS.*\" GINKGO_SKIP=\"\" ./scripts/ci-e2e.sh\n```\n\n----------------------------------------\n\nTITLE: Creating a Workload Cluster for Azure Cloud Provider Testing in Bash\nDESCRIPTION: Commands to set the cluster name and create a workload cluster for testing the Azure cloud provider.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/kubernetes-developers.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nexport CLUSTER_NAME=my-cluster\nmake create-workload-cluster\n```\n\n----------------------------------------\n\nTITLE: Including External HTML File\nDESCRIPTION: This directive is used by a documentation generation tool (like mdBook or a similar system) to include the entire content of the specified file ('v1alpha1-api-raw.html') at this point in the document. It allows for modular documentation by embedding content from other files.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/reference/v1alpha1-api.md#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n{{ #include v1alpha1-api-raw.html }}\n```\n\n----------------------------------------\n\nTITLE: Accessing Jaeger Traces via localhost URL in Markdown\nDESCRIPTION: Provides a URL for accessing the Jaeger web interface to view traces in a local development environment. This link is disabled for markdown link checking.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/readme.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- markdown-link-check-disable-next-line -->\nTo access traces in the Jaeger web interface, visit http://localhost:16686/ or select the\n\"traces: jaeger-all-in-one\" resource in the Tilt UI and click on \"View traces\" near the top of\nthe screen.\n```\n\n----------------------------------------\n\nTITLE: SSHing into First Control Plane Node (Bash)\nDESCRIPTION: Connects via SSH to the first control plane node of a workload cluster ('capz-cluster' in this example). It first retrieves the control plane endpoint hostname using `kubectl` against the management cluster and then uses this hostname with the `ssh` command, logging in as the user 'capi'. Requires SSH key access configured (e.g., via `AZURE_SSH_PUBLIC_KEY_B64`).\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n# connect to first control node - capi is default linux user created by deployment\nAPI_SERVER=$(kubectl get azurecluster capz-cluster -o jsonpath='{.spec.controlPlaneEndpoint.host}')\nssh capi@${API_SERVER}\n```\n\n----------------------------------------\n\nTITLE: Acquiring Azure Authorizer using Workload Identity (Go)\nDESCRIPTION: This Go code demonstrates how the CAPZ identity workflow would obtain an Azure authorizer using workload identity. It calls `newWorkloadIdentityCredential` (defined in the next snippet) to create a custom credential based on the projected token file. It then uses `azidext.NewTokenCredentialAdapter` from the `azidentity` extensions library to wrap this `azcore.TokenCredential` into an `autorest.Authorizer`, compatible with existing Azure SDK clients. The `tenantID` and `clientID` are fetched from `AzureClusterIdentity` or environment variables.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_6\n\nLANGUAGE: go\nCODE:\n```\n```go\n\n\t\t\t// see the next code section for details on this function\n\t\t\tcred, err := newWorkloadIdentityCredential(tenantID, clientID, tokenFilePath, wiCredOptions)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to setup workload identity\")\n\t\t\t}\n\n\t\t\tclient := subscriptions.NewClient()\n\n\t\t\t// setCredentialsForWorkloadIdentity just setups the \n\t\t\t// PublicCloud env URLs \n\t\t\tparams.AzureClients.setCredentialsForWorkloadIdentity(ctx, params.AzureCluster.Spec.SubscriptionID, params.AzureCluster.Spec.AzureEnvironment)\n\t\t\tclient.Authorizer = azidext.NewTokenCredentialAdapter(cred, []string{\"https://management.azure.com//.default\"})\n\t\t\tparams.AzureClients.Authorizer = client.Authorizer\n\n```\n```\n\n----------------------------------------\n\nTITLE: Using Azure Community Gallery with Kubernetes YAML\nDESCRIPTION: Demonstrates how to configure an AzureMachineTemplate to use an image from the Azure Community Gallery without specifying subscription or resource group IDs. It is necessary to provide the gallery's name and image details in the YAML specification.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/custom-images.md#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachineTemplate\nmetadata:\n  name: capz-community-gallery-example\nspec:\n  template:\n    spec:\n      image:\n        computeGallery:\n          gallery: testGallery-3282f15c-906a-4c4b-b206-eb3c51adb5be\n          name: capi-flatcar-stable-3139.2.0\n          version: 0.3.1651499183\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Workload Identity Credential (Go)\nDESCRIPTION: This Go code defines a custom `workloadIdentityCredential` struct and associated methods to implement the `azcore.TokenCredential` interface. It reads a service account token (assertion) from a specified file path (`file`), caches it for 5 minutes, and uses `azidentity.NewClientAssertionCredential` to handle the Azure AD token exchange process. The `getAssertion` method provides the token content to the `azidentity` library when requested. This implementation facilitates using projected service account tokens for Azure Workload Identity authentication within Go applications.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20221611-workload-identity-integration.md#2025-04-22_snippet_7\n\nLANGUAGE: go\nCODE:\n```\n```go\n\ntype workloadIdentityCredential struct {\n\tassertion string\n\tfile      string\n\tcred      *azidentity.ClientAssertionCredential\n\tlastRead  time.Time\n}\n\ntype workloadIdentityCredentialOptions struct {\n\tazcore.ClientOptions\n}\n\nfunc newWorkloadIdentityCredential(tenantID, clientID, file string, options *workloadIdentityCredentialOptions) (*workloadIdentityCredential, error) {\n\tw := &workloadIdentityCredential{file: file}\n\tcred, err := azidentity.NewClientAssertionCredential(tenantID, clientID, w.getAssertion, &azidentity.ClientAssertionCredentialOptions{ClientOptions: options.ClientOptions})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tw.cred = cred\n\treturn w, nil\n}\n\nfunc (w *workloadIdentityCredential) GetToken(ctx context.Context, opts policy.TokenRequestOptions) (azcore.AccessToken, error) {\n\treturn w.cred.GetToken(ctx, opts)\n}\n\nfunc (w *workloadIdentityCredential) getAssertion(context.Context) (string, error) {\n\tif now := time.Now(); w.lastRead.Add(5 * time.Minute).Before(now) {\n\t\tcontent, err := os.ReadFile(w.file)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tw.assertion = string(content)\n\t\tw.lastRead = now\n\t}\n\treturn w.assertion, nil\n}\n\n```\n```\n\n----------------------------------------\n\nTITLE: Querying ASO Managed Clusters with Default Kubectl Version\nDESCRIPTION: Demonstrates querying Azure Service Operator (ASO) managed clusters using the default `kubectl get` command without specifying an API version. Due to ASO's versioning scheme incompatibility with kubectl's default version selection, this command might display an older API version of the resource than the one potentially used for creation or the latest available.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/FAQ.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get managedcluster\n```\n\n----------------------------------------\n\nTITLE: Executing Custom Test Suite Command for CAPZ\nDESCRIPTION: Command to run a custom test suite on a CAPZ cluster. Requires Azure credentials (AZURE_CLIENT_ID, AZURE_CLIENT_SECRET, AZURE_SUBSCRIPTION_ID, AZURE_TENANT_ID) to be set before execution. The command changes to the project directory and runs the e2e tests.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/development.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-entrypoint.sh bash -c \"cd ${GOPATH}/src/github.com/my-org/my-project && make e2e\"\n```\n\n----------------------------------------\n\nTITLE: Provisioning SSH Keys via KubeadmControlPlane YAML\nDESCRIPTION: This YAML configuration is for provisioning SSH keys for a specified user on control plane VMs by editing the KubeadmControlPlane Custom Resource (CR). The snippet ensures the user can SSH into the control plane VMs and has sudo access.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/ssh-access.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: controlplane.cluster.x-k8s.io/v1beta1\nkind: KubeadmControlPlane\n...\nspec:\n  ...\n  kubeadmConfigSpec:\n    ...\n    users:\n    - name: username\n      sshAuthorizedKeys:\n      - \"ssh-rsa AAAA...\"\n    files:\n    - content: \"username ALL = (ALL) NOPASSWD: ALL\"\n      owner: root:root\n      path: /etc/sudoers.d/username\n      permissions: \"0440\"\n    ...\n```\n\n----------------------------------------\n\nTITLE: SSHing into Worker Node via Jump Host (Bash)\nDESCRIPTION: Connects via SSH to a specific worker node ('capz-cluster-md-0-s52wb' in the example) by first retrieving its IP address using `kubectl get azuremachine` and then using another node (identified by `${apiserver}`, presumably the control plane node from the previous step) as an SSH jump host (`-J`). This allows accessing nodes that may not have direct public IP addresses.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/troubleshooting.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n# pick node name from output above:\nnode=$(kubectl get azuremachine capz-cluster-md-0-s52wb -o jsonpath='{.status.addresses[0].address}')\nssh -J capi@${apiserver} capi@${node}\n```\n\n----------------------------------------\n\nTITLE: Labeling Kubernetes Nodes using kubectl\nDESCRIPTION: A command for applying labels to Kubernetes nodes, allowing constraints to be set for which nodes are capable of running specific Wasm workloads. This is crucial for configurations that use runtime class nodeSelectors to limit workload distribution.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --kubeconfig=<workload-kubeconfig> label nodes <your-node-name> <label>\n```\n\n----------------------------------------\n\nTITLE: Configuring Node Prototyping in AzureMachinePool\nDESCRIPTION: Example YAML configuration showing how to enable node prototyping in an AzureMachinePool resource with a specified update interval. The nodePrototyping field is added under spec.template.image with an interval setting.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20230612-node-os-image-caching.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: infrastructure.cluster.x-k8s.io/v1beta1\nkind: AzureMachinePool\nmetadata:\n  name: node-os-image-caching-machine-pool\n  namespace: default\nspec:\n  image:\n      nodePrototyping:\n        interval: 24h\n```\n\n----------------------------------------\n\nTITLE: Getting Kubernetes Service Information using kubectl\nDESCRIPTION: A command to watch the services in a specific Kubernetes cluster and display detailed information including cluster IP, external IP, and ports. It is especially useful for finding the external IP of services like 'wasm-spin' to connect to workloads running on the cluster.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/wasi.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubectl --kubeconfig=<workload-kubeconfig> get services -w\nNAME         TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE\nkubernetes   ClusterIP      10.96.0.1       <none>          443/TCP        14m\nwasm-spin    LoadBalancer   10.105.51.137   20.121.244.48   80:30197/TCP   3m8s\n\n```\n\n----------------------------------------\n\nTITLE: Defining AzureMachinePool Status Structure in Go\nDESCRIPTION: Defines the structure for tracking status of individual VM instances within a VMSS pool, including version, provisioning state, and instance identifiers.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/proposals/20210222-azure-machinepool-machine.md#2025-04-22_snippet_0\n\nLANGUAGE: go\nCODE:\n```\n// AzureMachinePoolStatus defines the observed state of AzureMachinePool\nAzureMachinePoolStatus struct {\n    /*\n        Other fields omitted for brevity\n    */\n\n    // Instances is the VM instance status for each VM in the VMSS\n    // +optional\n    Instances []*AzureMachinePoolInstanceStatus `json:\"instances,omitempty\"`\n}\n\n// AzureMachinePoolInstanceStatus provides status information for each instance in the VMSS\nAzureMachinePoolInstanceStatus struct {\n    // Version defines the Kubernetes version for the VM Instance\n    // +optional\n    Version string `json:\"version\"`\n\n    // ProvisioningState is the provisioning state of the Azure virtual machine instance.\n    // +optional\n    ProvisioningState *infrav1.VMState `json:\"provisioningState\"`\n\n    // ProviderID is the provider identification of the VMSS Instance\n    // +optional\n    ProviderID string `json:\"providerID\"`\n\n    // InstanceID is the identification of the Machine Instance within the VMSS\n    // +optional\n    InstanceID string `json:\"instanceID\"`\n\n    // InstanceName is the name of the Machine Instance within the VMSS\n    // +optional\n    InstanceName string `json:\"instanceName\"`\n\n    // LatestModelApplied indicates the instance is running the most up-to-date VMSS model\n    LatestModelApplied bool `json:\"latestModelApplied\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Adding OpenTelemetry Helm Repository in Console\nDESCRIPTION: This command adds the OpenTelemetry Helm repository to your local Helm installation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/README.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nhelm repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts\n```\n\n----------------------------------------\n\nTITLE: Updating Azure AD Application Group Membership Claims - Bash\nDESCRIPTION: Modifies an existing Azure AD application's properties to include all group membership claims. This is required for RBAC and group management through Azure AD. Requires prior creation of the application and definition of AZURE_SERVER_APP_ID.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/topics/aad-integration.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naz ad app update --id ${AZURE_SERVER_APP_ID} --set groupMembershipClaims=All\n```\n\n----------------------------------------\n\nTITLE: Configuring Zipkin Exporter and Disabling Metrics Pipeline in YAML\nDESCRIPTION: This YAML configuration disables the metrics pipeline and sets up a Zipkin exporter for the traces pipeline.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/README.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nconfig:\n  exporters:\n    zipkin:\n      endpoint: zipkin-all-in-one:14250\n  service:\n    pipelines:\n      metrics: null\n      traces:\n        exporters:\n          - zipkin\n```\n\n----------------------------------------\n\nTITLE: Configuring Tilt Settings for Corporate Subscription\nDESCRIPTION: YAML configuration for tilt-settings.yaml to set subscription type to corporate mode.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/tilt-with-aks-as-mgmt-ilb.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n.\n.\n.\nkustomize_substitutions:\nSUBSCRIPTION_TYPE: \"corporate\"\n.\n```\n\n----------------------------------------\n\nTITLE: Accessing Prometheus Metrics via localhost URL in Markdown\nDESCRIPTION: Provides a URL for accessing the Prometheus web interface to view metrics in a local development environment. This link is disabled for markdown link checking.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/readme.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- markdown-link-check-disable-next-line -->\nTo access metrics in the Prometheus web interface, visit http://localhost:9090/ or select the\n\"metrics: prometheus-operator\" resource in the Tilt UI and click on \"View metrics\" near the top of\nthe screen.\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Collector with Helm\nDESCRIPTION: Shell command to install the OpenTelemetry collector using Helm into an existing management cluster, configuring it to export traces to Azure Application Insights.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/readme.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nhelm install opentelemetry-collector ./hack/observability/opentelemetry/chart \\\n  --namespace capz-system --values ./hack/observability/opentelemetry/values.yaml \\\n  --set config.exporters.azuremonitor.instrumentation_key=$AZURE_INSTRUMENTATION_KEY\n```\n\n----------------------------------------\n\nTITLE: Accessing Jaeger Application via Helm-Defined Service Types\nDESCRIPTION: This template provides different access methods based on the Helm chart's configured service type. It generates specific kubectl commands for Ingress, NodePort, LoadBalancer, or ClusterIP configurations, helping users to connect to their Jaeger installation.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/jaeger/chart/templates/NOTES.txt#2025-04-22_snippet_0\n\nLANGUAGE: Helm\nCODE:\n```\n{{- if .Values.enabled }}\n1. Get the application URL by running these commands:\n{{- if .Values.ingress.enabled }}\n{{- range $host := .Values.ingress.hosts }}\n  {{- range .paths }}\n  http{{ if $.Values.ingress.tls }}s{{ end }}://{{ $host.host }}{{ . }}\n  {{- end }}\n{{- end }}\n{{- else if contains \"NodePort\" .Values.service.type }}\n  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath=\"{.spec.ports[0].nodePort}\" services {{ include \"jaeger-all-in-one.fullname\" . }})\n  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n  echo http://$NODE_IP:$NODE_PORT\n{{- else if contains \"LoadBalancer\" .Values.service.type }}\n     NOTE: It may take a few minutes for the LoadBalancer IP to be available.\n           You can watch the status of by running 'kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include \"jaeger-all-in-one.fullname\" . }}'\n  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include \"jaeger-all-in-one.fullname\" . }} --template \"{{\"{{\" range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}\"}}\")\n  echo http://$SERVICE_IP:{{ .Values.service.port }}\n{{- else if contains \"ClusterIP\" .Values.service.type }}\n  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l \"app.kubernetes.io/name={{ include \"jaeger-all-in-one.name\" . }},app.kubernetes.io/instance={{ .Release.Name }}\" -o jsonpath=\"{.items[0].metadata.name}\")\n  echo \"Visit http://127.0.0.1:{{ .Values.service.port }} to use your application\"\n  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME {{ .Values.service.port }}:{{ .Values.service.port }}\n{{- end }}\n{{- end }}\n```\n\n----------------------------------------\n\nTITLE: Generating Release Notes\nDESCRIPTION: Commands to generate release notes using GitHub token and specific release tag.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/releasing.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport GITHUB_TOKEN=<your GH token>\nexport RELEASE_TAG=v1.2.3\nmake release-notes\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Header for Kubernetes Azure Cluster API Provider\nDESCRIPTION: Standard Apache License 2.0 header used at the top of source files in the Kubernetes Azure Cluster API Provider project. This header indicates that the software is licensed under Apache 2.0 terms, requiring maintenance of copyright notices and specifying conditions for redistribution.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/boilerplate/boilerplate.generatebzl.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# Copyright The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: RDP Access to Windows Node via SSH Tunnel - Shell Command\nDESCRIPTION: This shell command establishes a local port-forward (5555) via SSH from the operator's machine to the Windows node's RDP (3389) port using the Kubernetes API server as a proxy. Input parameters are SSH key, user, API server IP, and Windows node IP. After running this command, the operator can launch an RDP client targeting localhost:5555 for access. Dependencies: SSH client, RDP client, valid keys, and network configuration. Output is a tunneled RDP session to the Windows VM. replace placeholder IPs accordingly.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/self-managed/windows.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nssh -L 5555:<windows-ip>:3389 capi@<api-server-ip>\n```\n\n----------------------------------------\n\nTITLE: Running CI Entrypoint for Azure Cluster API Provider\nDESCRIPTION: Command to validate cluster creation using the CI entrypoint script. Used in the pull-cluster-api-provider-azure-ci-entrypoint presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/ci-entrypoint.sh\n```\n\n----------------------------------------\n\nTITLE: Running E2E Tests for Azure Cluster API Provider\nDESCRIPTION: Command to run E2E tests focusing on workload cluster creation while skipping GPU, Windows, AKS, and external cloud provider tests. Used in the pull-cluster-api-provider-azure-e2e presubmit job.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/docs/book/src/developers/jobs.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nGINKGO_FOCUS=\"Workload cluster creation\" GINKGO_SKIP=\"Creating a GPU-enabled cluster|.*Windows.*|.*AKS.*|Creating a cluster that uses the external cloud provider\" ./scripts/ci-e2e.sh\n```\n\n----------------------------------------\n\nTITLE: Dependency Version Updates in CAPZ\nDESCRIPTION: List of new dependencies added to the project with their corresponding versions, including Azure SDK components and various Go packages.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/CHANGELOG/v1.13.0.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ngithub.com/Azure/azure-sdk-for-go/sdk/resourcemanager/containerservicefleet/armcontainerservicefleet: [v1.1.0]\ngithub.com/Azure/azure-sdk-for-go/sdk/resourcemanager/eventgrid/armeventgrid: [v1.0.0]\ngithub.com/Azure/azure-sdk-for-go/sdk/resourcemanager/internal/v2: [v2.0.0]\ngithub.com/Azure/azure-sdk-for-go/sdk/resourcemanager/monitor/armmonitor: [v0.11.0]\ngithub.com/ProtonMail/go-crypto: [7d5c6f0]\ngithub.com/bwesterb/go-ristretto: [v1.2.3]\ngithub.com/cloudflare/circl: [v1.3.7]\ngithub.com/distribution/reference: [v0.5.0]\ngithub.com/google/go-github/v53: [v53.2.0]\ngithub.com/klauspost/compress: [v1.17.0]\ngithub.com/minio/highwayhash: [v1.0.2]\ngithub.com/nats-io/jwt/v2: [v2.4.1]\ngithub.com/nats-io/nats.go: [v1.30.2]\ngithub.com/nats-io/nkeys: [v0.4.5]\ngithub.com/nats-io/nuid: [v1.0.1]\ngithub.com/sagikazarmark/locafero: [v0.3.0]\ngithub.com/sagikazarmark/slog-shim: [v0.1.0]\ngithub.com/sourcegraph/conc: [v0.3.0]\n```\n\n----------------------------------------\n\nTITLE: Configuring Standalone Collector Deployment in YAML\nDESCRIPTION: This YAML configuration disables the agent collector and enables the standalone collector deployment.\nSOURCE: https://github.com/kubernetes-sigs/cluster-api-provider-azure/blob/main/hack/observability/opentelemetry/chart/README.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nagentCollector:\n  enabled: false\nstandaloneCollector:\n  enabled: true\n```"
  }
]