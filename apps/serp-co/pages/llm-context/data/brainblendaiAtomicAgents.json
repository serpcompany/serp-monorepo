[
  {
    "owner": "brainblend-ai",
    "repo": "atomic-agents",
    "content": "TITLE: Creating a Basic Chatbot with OpenAI\nDESCRIPTION: Implementation of a simple chatbot using Atomic Agents with OpenAI's GPT-4. The code initializes agent memory, sets up the base agent with appropriate configuration, and creates an interactive chat loop for user interactions.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom rich.console import Console\nfrom dotenv import load_dotenv\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig\nfrom atomic_agents.lib.components.agent_memory import AgentMemory\n\n# Load environment variables and setup\nload_dotenv()\nconsole = Console()\n\n# Initialize memory with assistant's first message\nmemory = AgentMemory()\nmemory.add_assistant_message(\"Hello! I'm your AI assistant. How can I help you today?\")\n\n# Create agent\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=instructor.from_openai(OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))),\n        model=\"gpt-4-turbo-preview\",\n        model_api_parameters={\"max_tokens\": 2048}\n    )\n)\n\n# Chat loop\nwhile True:\n    # Get user input\n    user_input = console.input(\"[bold green]You:[/bold green] \")\n    if user_input.lower() in [\"exit\", \"quit\"]:\n        break\n\n    # Add user message to memory\n    memory.add_user_message(user_input)\n\n    # Get response from agent\n    response = agent.run(memory=memory)\n\n    # Add response to memory and display\n    memory.add_assistant_message(response)\n    console.print(\"[bold blue]Assistant:[/bold blue]\", response)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Tools with BaseTool\nDESCRIPTION: This example demonstrates how to implement custom tools by extending the BaseTool class. It shows how to define tool configuration, input/output schemas, and the tool's execution logic. This pattern provides a structured way to create reusable tools that can be integrated into AI agent workflows.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/components.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom atomic_agents.lib.base.base_tool import BaseTool, BaseToolConfig\nfrom pydantic import Field\n\nclass MyToolConfig(BaseToolConfig):\n    \"\"\"Tool configuration\"\"\"\n    api_key: str = Field(\n        default=os.getenv(\"API_KEY\"),\n        description=\"API key for the service\"\n    )\n\nclass MyTool(BaseTool):\n    \"\"\"Tool implementation\"\"\"\n    input_schema = MyToolInputSchema\n    output_schema = MyToolOutputSchema\n\n    def __init__(self, config: MyToolConfig = MyToolConfig()):\n        super().__init__(config)\n        self.api_key = config.api_key\n\n    def run(self, params: MyToolInputSchema) -> MyToolOutputSchema:\n        # Implement tool logic\n        pass\n```\n\n----------------------------------------\n\nTITLE: Creating and Using SystemPromptGenerator\nDESCRIPTION: This snippet shows how to create and use the SystemPromptGenerator to build structured system prompts for AI agents. It demonstrates initializing the generator with background information, processing steps, and output instructions to generate a comprehensive prompt for the AI.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/components.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom atomic_agents.lib.components.system_prompt_generator import (\n    SystemPromptGenerator,\n    SystemPromptContextProviderBase\n)\n\n# Create generator with static content\ngenerator = SystemPromptGenerator(\n    background=[\n        \"You are a helpful AI assistant.\",\n        \"You specialize in technical support.\"\n    ],\n    steps=[\n        \"1. Understand the user's request\",\n        \"2. Analyze available information\",\n        \"3. Provide clear solutions\"\n    ],\n    output_instructions=[\n        \"Use clear, concise language\",\n        \"Include step-by-step instructions\",\n        \"Cite relevant documentation\"\n    ]\n)\n\n# Generate prompt\nprompt = generator.generate_prompt()\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Agent with Atomic Agents\nDESCRIPTION: Example demonstrating how to create a powerful agent with a custom output schema, system prompt generator, and agent configuration. The agent responds to user queries and suggests follow-up questions.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Define a custom output schema\nclass CustomOutputSchema(BaseIOSchema):\n    \"\"\"\n    docstring for the custom output schema\n    \"\"\"\n    chat_message: str = Field(..., description=\"The chat message from the agent.\")\n    suggested_questions: List[str] = Field(..., description=\"Suggested follow-up questions.\")\n\n# Set up the system prompt\nsystem_prompt_generator = SystemPromptGenerator(\n    background=[\"This assistant is knowledgeable, helpful, and suggests follow-up questions.\"],\n    steps=[\n        \"Analyze the user's input to understand the context and intent.\",\n        \"Formulate a relevant and informative response.\",\n        \"Generate 3 suggested follow-up questions for the user.\"\n    ],\n    output_instructions=[\n        \"Provide clear and concise information in response to user queries.\",\n        \"Conclude each response with 3 relevant suggested questions for the user.\"\n    ]\n)\n\n# Initialize the agent\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=your_openai_client,  # Replace with your actual client\n        model=\"gpt-4o-mini\",\n        system_prompt_generator=system_prompt_generator,\n        memory=AgentMemory(),\n        output_schema=CustomOutputSchema\n    )\n)\n\n# Use the agent\nresponse = agent.run(user_input)\nprint(f\"Agent: {response.chat_message}\")\nprint(\"Suggested questions:\")\nfor question in response.suggested_questions:\n    print(f\"- {question}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Dynamic Context Providers for SystemPromptGenerator\nDESCRIPTION: This code demonstrates how to create dynamic context providers that inject real-time information into system prompts. It shows the implementation of a SearchResultsProvider class that formats search results for inclusion in AI prompts, allowing for context-specific prompt generation.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/components.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nfrom typing import List\n\n@dataclass\nclass SearchResult:\n    content: str\n    metadata: dict\n\nclass SearchResultsProvider(SystemPromptContextProviderBase):\n    def __init__(self, title: str):\n        super().__init__(title=title)\n        self.results: List[SearchResult] = []\n\n    def get_info(self) -> str:\n        \"\"\"Format search results for the prompt\"\"\"\n        if not self.results:\n            return \"No search results available.\"\n\n        return \"\\n\\n\".join([\n            f\"Result {idx}:\\nMetadata: {result.metadata}\\nContent:\\n{result.content}\\n{'-' * 80}\"\n            for idx, result in enumerate(self.results, 1)\n        ])\n\n# Use with generator\ngenerator = SystemPromptGenerator(\n    background=[\"You answer based on search results.\"],\n    context_providers={\n        \"search_results\": SearchResultsProvider(\"Search Results\")\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic AI Agent with Atomic Agents\nDESCRIPTION: Example code demonstrating how to create and interact with a basic AI agent using the Atomic Agents framework. Shows initialization with OpenAI client, memory setup, and basic agent interaction.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport instructor\nimport openai\nfrom atomic_agents.lib.components.agent_memory import AgentMemory\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseAgentInputSchema\n\n# Set up your API key (either in environment or pass directly)\n# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n# or pass it to the client: openai.OpenAI(api_key=\"your-api-key\")\n\n# Initialize agent with memory\nmemory = AgentMemory()\n\n# Set up client with your preferred provider\nclient = instructor.from_openai(openai.OpenAI())  # Pass your API key here if not in environment\n\n# Create an agent\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=client,\n        model=\"gpt-4o-mini\",  # Use your provider's model\n        memory=memory\n    )\n)\n\n# Interact with your agent (using the agent's input schema)\nresponse = agent.run(agent.input_schema(chat_message=\"Tell me about quantum computing\"))\n\n# Or more explicitly:\nresponse = agent.run(\n    BaseAgentInputSchema(chat_message=\"Tell me about quantum computing\")\n)\n\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Defining Custom IO Schemas with BaseIOSchema\nDESCRIPTION: This snippet shows how to create custom input/output schemas by extending the BaseIOSchema class. It demonstrates defining schema fields with descriptions using Pydantic's Field, which enables automatic schema validation and proper documentation of the data structure.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/components.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom atomic_agents.lib.base.base_io_schema import BaseIOSchema\nfrom pydantic import Field\n\nclass CustomSchema(BaseIOSchema):\n    \"\"\"Schema description (required)\"\"\"\n    field: str = Field(..., description=\"Field description\")\n```\n\n----------------------------------------\n\nTITLE: Chaining Agents with Aligned Schemas in Atomic Agents using Python\nDESCRIPTION: This example demonstrates how to chain agents in Atomic Agents by aligning their input and output schemas. It creates a query generation agent that outputs queries compatible with a search tool's input schema, allowing for easy integration and swapping of components.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport instructor\nimport openai\nfrom pydantic import Field\nfrom atomic_agents.agents.base_agent import BaseIOSchema, BaseAgent, BaseAgentConfig\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\n\n# Import the search tool you want to use\nfrom web_search_agent.tools.searxng_search import SearxNGSearchTool\n\n# Define the input schema for the query agent\nclass QueryAgentInputSchema(BaseIOSchema):\n    \"\"\"Input schema for the QueryAgent.\"\"\"\n    instruction: str = Field(..., description=\"Instruction to generate search queries for.\")\n    num_queries: int = Field(..., description=\"Number of queries to generate.\")\n\n# Initialize the query agent\nquery_agent = BaseAgent(\n    BaseAgentConfig(\n        client=instructor.from_openai(openai.OpenAI()),\n        model=\"gpt-4o-mini\",\n        system_prompt_generator=SystemPromptGenerator(\n            background=[\n                \"You are an intelligent query generation expert.\",\n                \"Your task is to generate a specified number of diverse and highly relevant queries based on a given instruction.\"\n            ],\n            steps=[\n                \"Receive the instruction and the number of queries to generate.\",\n                \"Generate the queries in JSON format.\"\n            ],\n            output_instructions=[\n                \"Ensure each query is unique and relevant.\",\n                \"Provide the queries in the expected schema.\"\n            ],\n        ),\n        input_schema=QueryAgentInputSchema,\n        output_schema=SearxNGSearchTool.input_schema,  # Align output schema\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Input/Output Schema with Pydantic\nDESCRIPTION: Example showing how to define and use custom Pydantic schemas for structured agent interactions. The code defines input and output models, configures the agent to use these schemas, and demonstrates how to pass structured data and handle structured responses.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\nclass CustomInput(BaseModel):\n    question: str = Field(..., description=\"The user's question\")\n    context: str = Field(..., description=\"Additional context for the question\")\n\nclass CustomOutput(BaseModel):\n    answer: str = Field(..., description=\"The answer to the user's question\")\n    confidence: float = Field(..., description=\"Confidence score (0-1)\")\n    sources: list[str] = Field(default_factory=list, description=\"Sources used\")\n\n# Create agent with custom schema\nagent = BaseAgent[CustomInput, CustomOutput](\n    config=BaseAgentConfig(\n        client=client,\n        model=model,\n        input_schema=CustomInput,\n        output_schema=CustomOutput\n    )\n)\n\n# Use with custom schema\nresult = agent.run(\n    memory=memory,\n    input_data=CustomInput(\n        question=\"What is machine learning?\",\n        context=\"Explain for a beginner\"\n    )\n)\nprint(f\"Answer: {result.answer}\")\nprint(f\"Confidence: {result.confidence}\")\nprint(f\"Sources: {result.sources}\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Multiple AI Providers with Atomic Agents\nDESCRIPTION: Implementation showing how to configure Atomic Agents with different AI providers including OpenAI, Anthropic, Groq, Ollama, and Gemini. Each provider has its own setup logic, handling the different client initialization patterns and model specifications.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport instructor\nfrom rich.console import Console\nfrom dotenv import load_dotenv\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig\n\nload_dotenv()\nconsole = Console()\n\ndef setup_client(provider):\n    if provider == \"openai\":\n        from openai import OpenAI\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        client = instructor.from_openai(OpenAI(api_key=api_key))\n        model = \"gpt-4-turbo-preview\"\n\n    elif provider == \"anthropic\":\n        from anthropic import Anthropic\n        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n        client = instructor.from_anthropic(Anthropic(api_key=api_key))\n        model = \"claude-3-haiku-20240307\"\n\n    elif provider == \"groq\":\n        from groq import Groq\n        api_key = os.getenv(\"GROQ_API_KEY\")\n        client = instructor.from_groq(\n            Groq(api_key=api_key),\n            mode=instructor.Mode.JSON\n        )\n        model = \"mixtral-8x7b-32768\"\n\n    elif provider == \"ollama\":\n        from openai import OpenAI as OllamaClient\n        client = instructor.from_openai(\n            OllamaClient(\n                base_url=\"http://localhost:11434/v1\",\n                api_key=\"ollama\"\n            )\n        )\n        model = \"llama2\"\n\n    elif provider == \"gemini\":\n        from openai import OpenAI\n        api_key = os.getenv(\"GEMINI_API_KEY\")\n        client = instructor.from_openai(\n            OpenAI(\n                api_key=api_key,\n                base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n            ),\n            mode=instructor.Mode.JSON\n        )\n        model = \"gemini-pro\"\n\n    else:\n        raise ValueError(f\"Unsupported provider: {provider}\")\n\n    return client, model\n\n# Choose a provider\nprovider = \"openai\"  # or \"anthropic\", \"groq\", \"ollama\", \"gemini\"\nclient, model = setup_client(provider)\n\n# Create agent with chosen provider\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=client,\n        model=model,\n        model_api_parameters={\"max_tokens\": 2048}\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom IO Schemas with Pydantic Fields\nDESCRIPTION: Example of creating custom input and output schemas by inheriting from BaseIOSchema and adding additional fields with validation using Pydantic's Field.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import Field\nfrom typing import List\nfrom atomic_agents.lib.base.base_io_schema import BaseIOSchema\n\nclass CustomInputSchema(BaseIOSchema):\n    chat_message: str = Field(..., description=\"User's message\")\n    context: str = Field(None, description=\"Optional context for the agent\")\n\nclass CustomOutputSchema(BaseIOSchema):\n    chat_message: str = Field(..., description=\"Agent's response\")\n    follow_up_questions: List[str] = Field(\n        default_factory=list,\n        description=\"Suggested follow-up questions\"\n    )\n    confidence: float = Field(\n        ...,\n        description=\"Confidence score for the response\",\n        ge=0.0,\n        le=1.0\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating BaseAgent with Custom Input/Output Schemas\nDESCRIPTION: Example of initializing a BaseAgent with custom input and output schemas for structured interactions with specific fields and validation.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass CustomInput(BaseIOSchema):\n    \"\"\"Custom input with specific fields\"\"\"\n    question: str = Field(..., description=\"User's question\")\n    context: str = Field(..., description=\"Additional context\")\n\nclass CustomOutput(BaseIOSchema):\n    \"\"\"Custom output with structured data\"\"\"\n    answer: str = Field(..., description=\"Answer to the question\")\n    sources: List[str] = Field(..., description=\"Source references\")\n\n# Create agent with custom schemas\nagent = BaseAgent[CustomInput, CustomOutput](\n    config=BaseAgentConfig(\n        client=client,\n        model=model,\n        input_schema=CustomInput,\n        output_schema=CustomOutput\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Registering Context Provider with Atomic Agent in Python\nDESCRIPTION: This snippet shows how to register a context provider named 'search_results' with an Atomic Agent. This allows the agent to include dynamic search results in its system prompt, enhancing its responses with up-to-date information.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Register the context provider with the agent\nagent.register_context_provider(\"search_results\", search_results_provider)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using AgentMemory in Python\nDESCRIPTION: This snippet demonstrates how to initialize and use the AgentMemory class for managing conversation history. It shows how to add messages, track conversation turns, access history, manage memory size, and persist conversation data. The AgentMemory class supports multimodal content and provides methods for serialization.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/components.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom atomic_agents.lib.components.agent_memory import AgentMemory\nfrom atomic_agents.lib.base.base_io_schema import BaseIOSchema\n\n# Initialize memory with optional max messages\nmemory = AgentMemory(max_messages=10)\n\n# Add messages\nmemory.add_message(\n    role=\"user\",\n    content=BaseIOSchema(...)\n)\n\n# Initialize a new turn\nmemory.initialize_turn()\nturn_id = memory.get_current_turn_id()\n\n# Access history\nhistory = memory.get_history()\n\n# Manage memory\nmemory.get_message_count()  # Get number of messages\nmemory.delete_turn_id(turn_id)  # Delete messages by turn\n\n# Persistence\nserialized = memory.dump()  # Save to string\nmemory.load(serialized)  # Load from string\n\n# Create copy\nnew_memory = memory.copy()\n```\n\n----------------------------------------\n\nTITLE: Swapping Search Providers in Chained Agents using Python\nDESCRIPTION: This snippet demonstrates how to easily switch between different search providers in a chained agent setup. By updating the output schema of the query agent to match the input schema of a different search tool, you can maintain modularity and flexibility in your AI applications.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Import a different search tool\nfrom web_search_agent.tools.another_search import AnotherSearchTool\n\n# Update the output schema\nquery_agent.config.output_schema = AnotherSearchTool.input_schema\n```\n\n----------------------------------------\n\nTITLE: Initializing BaseAgent with Configuration\nDESCRIPTION: Example of creating a BaseAgent instance with basic configuration including the OpenAI client, model selection, memory, and system prompt generator.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig\nfrom atomic_agents.lib.components.agent_memory import AgentMemory\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\n\n# Create agent with basic configuration\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=instructor.from_openai(OpenAI()),\n        model=\"gpt-4-turbo-preview\",\n        memory=AgentMemory(),\n        system_prompt_generator=SystemPromptGenerator()\n    )\n)\n\n# Run the agent\nresponse = agent.run(user_input)\n\n# Stream responses\nasync for partial_response in agent.run_async(user_input):\n    print(partial_response)\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Chatbot with Dynamic Context Providers\nDESCRIPTION: Implementation of a custom chatbot that uses system prompt generators and context providers. This example demonstrates how to inject dynamic information (like search results) into the agent's context, allowing for more sophisticated and context-aware AI responses.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nfrom typing import List\nfrom atomic_agents.lib.components.system_prompt_generator import (\n    SystemPromptGenerator,\n    SystemPromptContextProviderBase\n)\n\n@dataclass\nclass SearchResult:\n    content: str\n    metadata: dict\n\nclass SearchResultsProvider(SystemPromptContextProviderBase):\n    def __init__(self, title: str):\n        super().__init__(title=title)\n        self.results: List[SearchResult] = []\n\n    def get_info(self) -> str:\n        \"\"\"Dynamically format search results for the system prompt\"\"\"\n        if not self.results:\n            return \"No search results available.\"\n\n        return \"\\n\\n\".join([\n            f\"Result {idx}:\\nMetadata: {result.metadata}\\nContent:\\n{result.content}\\n{'-' * 80}\"\n            for idx, result in enumerate(self.results, 1)\n        ])\n\n# Create prompt generator with dynamic context\nprompt_generator = SystemPromptGenerator(\n    background=[\n        \"You are an AI assistant that answers questions based on search results.\",\n        \"Analyze the provided search results to give accurate answers.\"\n    ],\n    steps=[\n        \"1. Review all provided search results\",\n        \"2. Extract relevant information\",\n        \"3. Synthesize a comprehensive answer\"\n    ],\n    output_instructions=[\n        \"Base your answer only on the provided search results\",\n        \"Cite specific results when possible\",\n        \"Admit when information is not found in the results\"\n    ],\n    context_providers={\n        \"search_results\": SearchResultsProvider(\"Search Results\")\n    }\n)\n\n# Create agent with dynamic context\nagent = BaseAgent(\n    config=BaseAgentConfig(\n        client=client,\n        model=model,\n        system_prompt_generator=prompt_generator\n    )\n)\n\n# Example usage with dynamic updates\ndef process_question(question: str):\n    # Perform search and get results\n    results = perform_search(question)  # Your search implementation\n\n    # Update context provider with new results\n    search_provider = prompt_generator.context_providers[\"search_results\"]\n    search_provider.results = [\n        SearchResult(content=result.text, metadata=result.meta)\n        for result in results\n    ]\n\n    # Each call to the agent will now include the updated search results\n    response = agent.run(memory=memory)\n```\n\n----------------------------------------\n\nTITLE: Schema Inheritance Pattern Overview in Atomic Agents\nDESCRIPTION: Displays the inheritance hierarchy for schema validation in the Atomic Agents framework, showing how Pydantic BaseModel is extended through BaseIOSchema to create input and output schemas.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npydantic.BaseModel\n    └── BaseIOSchema\n        ├── BaseAgentInputSchema\n        └── BaseAgentOutputSchema\n```\n\n----------------------------------------\n\nTITLE: BaseAgentConfig Class Definition\nDESCRIPTION: Definition of the BaseAgentConfig class that provides configuration options for BaseAgent including client, model, memory, and schema settings.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass BaseAgentConfig:\n    client: instructor.Instructor  # Client for interacting with the language model\n    model: str = \"gpt-4-turbo-preview\"  # Model to use\n    memory: Optional[AgentMemory] = None  # Memory component\n    system_prompt_generator: Optional[SystemPromptGenerator] = None  # Prompt generator\n    input_schema: Optional[Type[BaseModel]] = None  # Custom input schema\n    output_schema: Optional[Type[BaseModel]] = None  # Custom output schema\n    model_api_parameters: Optional[dict] = None  # Additional API parameters\n```\n\n----------------------------------------\n\nTITLE: Defining the MCP Tool Interface\nDESCRIPTION: Shows the abstract base class that defines the contract for all MCP tools, including required properties, the execute method, and schema generation functionality.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass Tool(ABC):\n    \"\"\"Abstract base class for all tools.\"\"\"\n    name: ClassVar[str]\n    description: ClassVar[str]\n    input_model: ClassVar[Type[BaseToolInput]]\n    output_model: ClassVar[Optional[Type[BaseModel]]] = None\n\n    @abstractmethod\n    async def execute(self, input_data: BaseToolInput) -> ToolResponse:\n        \"\"\"Execute the tool with given arguments.\"\"\"\n        pass\n\n    def get_schema(self) -> Dict[str, Any]:\n        \"\"\"Get JSON schema for the tool.\"\"\"\n        schema = {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"input\": self.input_model.model_json_schema(),\n        }\n\n        if self.output_model:\n            schema[\"output\"] = self.output_model.model_json_schema()\n\n        return schema\n```\n\n----------------------------------------\n\nTITLE: Implementing a Context Provider for System Prompts\nDESCRIPTION: Example of creating a custom context provider for injecting dynamic information (search results) into the system prompt.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptContextProviderBase\n\nclass SearchResultsProvider(SystemPromptContextProviderBase):\n    def __init__(self, title: str):\n        super().__init__(title=title)\n        self.results = []\n\n    def get_info(self) -> str:\n        return \"\\n\\n\".join([\n            f\"Result {idx}:\\n{result}\"\n            for idx, result in enumerate(self.results, 1)\n        ])\n\n# Register with agent\nagent.register_context_provider(\n    \"search_results\",\n    SearchResultsProvider(\"Search Results\")\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Responses for Interactive Experience\nDESCRIPTION: Enhanced chatbot implementation that uses streaming for a more interactive experience. The code sets up a live stream of the AI's response using Rich's Live component, updating the display in real-time as tokens are generated.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom rich.console import Console\nfrom rich.live import Live\nfrom rich.markdown import Markdown\nfrom dotenv import load_dotenv\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig\nfrom atomic_agents.lib.components.agent_memory import AgentMemory\n\n# Setup as before...\n\n# Chat loop with streaming\nwhile True:\n    user_input = console.input(\"[bold green]You:[/bold green] \")\n    if user_input.lower() in [\"exit\", \"quit\"]:\n        break\n\n    memory.add_user_message(user_input)\n\n    # Stream the response\n    with Live(console=console, refresh_per_second=4) as live:\n        response = \"\"\n        for chunk in agent.stream(memory=memory):\n            response += chunk\n            live.update(Markdown(f\"**Assistant:** {response}\"))\n\n    memory.add_assistant_message(response)\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Interfaces in Python\nDESCRIPTION: Example code showing how to implement the required interfaces for a new tool, including defining input/output schemas and implementing the run method.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/contributing.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom atomic_agents.lib.tools import BaseTool\n\nclass MyToolInputs(BaseModel):\n    # Define input schema\n    pass\n\nclass MyToolOutputs(BaseModel):\n    # Define output schema\n    pass\n\nclass MyTool(BaseTool):\n    name = \"my_tool\"\n    description = \"Tool description\"\n    inputs_schema = MyToolInputs\n    outputs_schema = MyToolOutputs\n\n    def run(self, inputs: MyToolInputs) -> MyToolOutputs:\n        # Implement tool logic\n        pass\n```\n\n----------------------------------------\n\nTITLE: Using YouTube Transcript Scraper Tool in Python\nDESCRIPTION: This example shows how to initialize and use the YouTube Transcript Scraper Tool. It includes creating a configuration object, initializing the tool, defining input data, and fetching the transcript.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/youtube_transcript_scraper/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom tool.youtube_transcript_scraper import YouTubeTranscriptTool, YouTubeTranscriptToolConfig\n\n# Initialize the tool with your API key\nconfig = YouTubeTranscriptToolConfig(api_key=\"your_youtube_api_key\")\ntranscript_tool = YouTubeTranscriptTool(config=config)\n\n# Define input data\ninput_data = YouTubeTranscriptTool.input_schema(\n    video_url=\"https://www.youtube.com/watch?v=t1e8gqXLbsU\",\n    language=\"en\"\n)\n\n# Fetch the transcript\nresult = transcript_tool.run(input_data)\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Implementing Async Streaming Responses with BaseAgent\nDESCRIPTION: Example of using the async streaming API to receive and process chunks of the response as they are generated.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nasync def chat():\n    async for partial_response in agent.run_async(user_input):\n        # Handle each chunk of the response\n        print(partial_response.chat_message)\n```\n\n----------------------------------------\n\nTITLE: Implementing Pizza Ordering Tool Logic in Python\nDESCRIPTION: This snippet defines the main Pizza Ordering Tool class, including initialization, order processing, payment calculation, and helper methods for simulating API calls.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass PizzaOrderingTool(BaseTool):\n    \"\"\"\n    Tool for placing pizza orders through the Pizza Orders API.\n    \"\"\"\n\n    input_schema = PizzaOrderInputSchema\n    output_schemas = {\n        \"confirmation\": OrderConfirmationSchema,\n        \"payment\": PaymentDetailsSchema\n    }\n\n    def __init__(self, config: PizzaOrderingToolConfig = PizzaOrderingToolConfig()):\n        \"\"\"\n        Initializes the PizzaOrderingTool with the provided configuration.\n        \"\"\"\n        super().__init__(config)\n        self.api_endpoint = config.api_endpoint\n        self.supported_pizzas = config.supported_pizzas\n        self.api_key = config.api_key\n        self.tool_name = config.title or self.input_schema.__name__\n        self.tool_description = config.description or self.__doc__\n\n    def run(self, params: PizzaOrderInputSchema) -> dict:\n        \"\"\"\n        Executes the tool's main logic to place an order and process payment.\n        \"\"\"\n        # Validate pizza type\n        if params.pizza_type not in self.supported_pizzas:\n            raise ValueError(f\"Pizza type '{params.pizza_type}' is not supported.\")\n\n        # Simulate placing the order\n        order_id = self.place_order(params)\n        estimated_time = self.get_estimated_delivery_time(order_id)\n        amount = self.calculate_payment(params)\n        payment_status = self.process_payment(order_id, amount)\n\n        # Prepare outputs\n        confirmation = OrderConfirmationSchema(\n            order_id=order_id,\n            estimated_delivery_time=estimated_time,\n            status=OrderStatus.CONFIRMED\n        )\n        payment = PaymentDetailsSchema(\n            amount=amount,\n            payment_status=payment_status\n        )\n\n        return {\n            \"confirmation\": confirmation,\n            \"payment\": payment\n        }\n\n    def place_order(self, params: PizzaOrderInputSchema) -> str:\n        \"\"\"\n        Simulates placing an order and returns an order ID.\n        \"\"\"\n        # Placeholder logic; in reality, this would involve an API call.\n        return \"ORD123456\"\n\n    def get_estimated_delivery_time(self, order_id: str) -> str:\n        \"\"\"\n        Simulates retrieving the estimated delivery time.\n        \"\"\"\n        # Placeholder logic.\n        return \"30 minutes\"\n\n    def calculate_payment(self, params: PizzaOrderInputSchema) -> float:\n        \"\"\"\n        Calculates the total amount to be paid.\n        \"\"\"\n        base_prices = {\n            \"Margherita\": 8.99,\n            \"Pepperoni\": 9.99,\n            \"Veggie\": 10.99,\n            \"Hawaiian\": 9.49\n        }\n        size_multipliers = {\n            PizzaSize.SMALL: 1.0,\n            PizzaSize.MEDIUM: 1.2,\n            PizzaSize.LARGE: 1.5\n        }\n        topping_price = 0.99  # Price per additional topping\n\n        base_price = base_prices[params.pizza_type]\n        size_multiplier = size_multipliers[params.size]\n        toppings_cost = sum(\n            topping_price + (0.5 if topping.extra_cheese else 0)\n            for topping in params.toppings\n        ) if params.toppings else 0\n\n        total = (base_price * size_multiplier + toppings_cost) * params.quantity\n        return total\n\n    def process_payment(self, order_id: str, amount: float) -> str:\n        \"\"\"\n        Simulates payment processing.\n        \"\"\"\n        # Placeholder logic.\n        return \"Paid\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Webpage Scraper Parameters in Python\nDESCRIPTION: Example configuration setup for the WebpageScraperTool showing how to customize user agent, timeout, and content length limits.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/webpage_scraper/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nconfig = WebpageScraperToolConfig(\n    user_agent=\"Custom User Agent String\",\n    timeout=60,\n    max_content_length=2_000_000\n)\n```\n\n----------------------------------------\n\nTITLE: Memory Management in BaseAgent\nDESCRIPTION: Examples of accessing, resetting, and serializing the agent's conversation memory through the AgentMemory component.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Access memory\nhistory = agent.memory.get_history()\n\n# Reset to initial state\nagent.reset_memory()\n\n# Save/load memory state\nserialized = agent.memory.dump()\nagent.memory.load(serialized)\n```\n\n----------------------------------------\n\nTITLE: Initializing FastMCP Server with SSE Transport\nDESCRIPTION: Demonstrates how to initialize a FastMCP server with Server-Sent Events transport, including tool and resource registration, and creating a Starlette app with CORS support.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Initialize FastMCP server\nmcp = FastMCP(\"example-mcp-server\")\n\n# Register tools and resources\ntool_service.register_tools(get_available_tools())\nresource_service.register_resources(get_available_resources())\n\n# Create Starlette app with CORS support\napp = create_starlette_app(mcp_server)\n```\n\n----------------------------------------\n\nTITLE: BaseAgent Input/Output Schema Definitions\nDESCRIPTION: Default schema definitions for basic chat interactions in BaseAgent, including input and output schemas with chat_message fields.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass BaseAgentInputSchema(BaseIOSchema):\n    \"\"\"Input from the user to the AI agent.\"\"\"\n    chat_message: str = Field(\n        ...,\n        description=\"The chat message sent by the user.\"\n    )\n\nclass BaseAgentOutputSchema(BaseIOSchema):\n    \"\"\"Response generated by the chat agent.\"\"\"\n    chat_message: str = Field(\n        ...,\n        description=\"The markdown-enabled response generated by the chat agent.\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing a Context Provider for Atomic Agents\nDESCRIPTION: Shows how to create a custom Context Provider that injects dynamic information into an agent's system prompt at runtime. The example demonstrates a SearchResultsProvider that adds search results to the prompt.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptContextProviderBase\n\nclass SearchResultsProvider(SystemPromptContextProviderBase):\n    def __init__(self, title: str, search_results: List[str]):\n        super().__init__(title=title)\n        self.search_results = search_results\n\n    def get_info(self) -> str:\n        return \"\\n\".join(self.search_results)\n```\n\nLANGUAGE: python\nCODE:\n```\n# Initialize your context provider with dynamic data\nsearch_results_provider = SearchResultsProvider(\n    title=\"Search Results\",\n    search_results=[\"Result 1\", \"Result 2\", \"Result 3\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Message Structure Definition in AgentMemory\nDESCRIPTION: This code defines the Message class structure used in the AgentMemory component. Each message contains a role (like 'user' or 'assistant'), content that follows BaseIOSchema, and an optional turn_id for grouping related messages in a conversation.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/components.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Message(BaseModel):\n    role: str  # e.g., 'user', 'assistant', 'system'\n    content: BaseIOSchema  # Message content following schema\n    turn_id: Optional[str]  # Unique ID for grouping messages\n```\n\n----------------------------------------\n\nTITLE: Setting API Keys as Environment Variables\nDESCRIPTION: Example of how to set API keys as environment variables for different AI providers that can be used with Atomic Agents. This ensures secure credential management without hardcoding API keys in the application code.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# OpenAI\nexport OPENAI_API_KEY=\"your-openai-key\"\n\n# Anthropic\nexport ANTHROPIC_API_KEY=\"your-anthropic-key\"\n\n# Groq\nexport GROQ_API_KEY=\"your-groq-key\"\n\n# Gemini\nexport GEMINI_API_KEY=\"your-gemini-key\"\n```\n\n----------------------------------------\n\nTITLE: Complete Usage Example of Tavily Search Tool in Python\nDESCRIPTION: A comprehensive example showing how to initialize, configure, and use the Tavily Search Tool. This includes importing necessary modules, setting up the configuration with an API key from environment variables, defining search queries, and executing the search.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/tavily_search/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom tool.tavily_search import TavilyTool, TavilySearchToolConfig\n\n# Initialize the tool with your Tavily instance URL\nconfig = TavilySearchToolConfig(api_key=os.getenv(\"TAVILY_API_KEY\"), max_results=5)\nsearch_tool = TavilyTool(config=config)\n\n# Define input data\ninput_data = TavilyTool.input_schema(\n    queries=[\"Python programming\", \"Machine learning\"],\n)\n\n# Perform the search\nresult = search_tool.run(input_data)\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Handling Multimodal Content in AgentMemory\nDESCRIPTION: This example shows how to handle multimodal content like text and images from the conversation history. The code demonstrates iterating through message history and extracting different content types from structured messages.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/components.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# For content with images\nhistory = memory.get_history()\nfor message in history:\n    if isinstance(message.content, list):\n        text_content = message.content[0]  # JSON string\n        images = message.content[1:]  # List of images\n```\n\n----------------------------------------\n\nTITLE: Research Decision Flow Diagram in Mermaid\nDESCRIPTION: A flowchart depicting the decision process from receiving a user question to generating an answer. It shows the conditional path for web search when needed, including query generation, web search, webpage scraping, and context updating before answer generation.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/deep-research/mermaid.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    %% Decision Flow Diagram\n    subgraph DecisionFlow[\"Research Decision Flow\"]\n        Start([User Question]) --> B{Need Search?}\n        B -->|Yes| C[Generate Search Queries]\n        C --> D[Perform Web Search]\n        D --> E[Scrape Webpages]\n        E --> F[Update Context]\n        F --> G[Generate Answer]\n        B -->|No| G\n        G --> H[Show Answer & Follow-ups]\n        H --> End([End])\n    end\n\n    classDef default fill:#f9f9f9,stroke:#333,stroke-width:2px;\n    classDef decision fill:#ff9800,stroke:#f57c00,color:#fff;\n    classDef process fill:#4caf50,stroke:#388e3c,color:#fff;\n    classDef terminator fill:#9c27b0,stroke:#7b1fa2,color:#fff;\n\n    class B decision;\n    class C,D,E,F,G process;\n    class Start,End terminator;\n```\n\n----------------------------------------\n\nTITLE: Defining Pizza Order Input Schema in Python\nDESCRIPTION: This snippet defines the input schema for a pizza order using Pydantic models and Enum classes. It includes customer details, pizza specifications, and topping options.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass PizzaSize(Enum):\n    SMALL = \"Small\"\n    MEDIUM = \"Medium\"\n    LARGE = \"Large\"\n\nclass CrustType(Enum):\n    THIN = \"Thin\"\n    THICK = \"Thick\"\n    STUFFED = \"Stuffed\"\n\nclass Topping(BaseModel):\n    name: str = Field(..., description=\"Name of the topping.\")\n    extra_cheese: bool = Field(False, description=\"Add extra cheese to this topping.\")\n\nclass PizzaOrderInputSchema(BaseIOSchema):\n    \"\"\"\n    Captures customer details and order specifics for placing a pizza order.\n    \"\"\"\n    customer_name: str = Field(..., description=\"Name of the customer placing the order.\")\n    pizza_type: str = Field(..., description=\"Type of pizza to order (e.g., Margherita, Pepperoni).\")\n    size: PizzaSize = Field(..., description=\"Size of the pizza.\")\n    crust: CrustType = Field(..., description=\"Type of crust for the pizza.\")\n    toppings: Optional[List[Topping]] = Field(None, description=\"List of additional toppings.\")\n    quantity: int = Field(..., description=\"Number of pizzas to order.\")\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Pizza Ordering Tool Usage in Python\nDESCRIPTION: This snippet shows how to instantiate and use the Pizza Ordering Tool, including creating an order input and handling the tool's output.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    from rich.console import Console\n\n    console = Console()\n    pizza_tool = PizzaOrderingTool()\n\n    order_input = PizzaOrderInputSchema(\n        customer_name=\"Jane Smith\",\n        pizza_type=\"Veggie\",\n        size=PizzaSize.MEDIUM,\n        crust=CrustType.THIN,\n        toppings=[\n            Topping(name=\"Olives\", extra_cheese=False),\n            Topping(name=\"Mushrooms\", extra_cheese=True)\n        ],\n        quantity=2\n    )\n\n    try:\n        outputs = pizza_tool.run(order_input)\n        console.print(outputs)\n    except Exception as e:\n        console.print(f\"[red]Error:[/red] {e}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring SSE Mode Connection in Python Client\nDESCRIPTION: Python code snippet showing how to configure an MCP client to connect to the server in SSE mode over HTTP. This mode is better for production deployments and sharing tools across multiple clients.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmcp_server_url: str = \"http://localhost:6969\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Pizza Order Output Schemas in Python\nDESCRIPTION: This snippet defines the output schemas for order confirmation and payment details using Pydantic models. It includes order status, delivery time, and payment information.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass OrderStatus(Enum):\n    PENDING = \"Pending\"\n    CONFIRMED = \"Confirmed\"\n    DELIVERED = \"Delivered\"\n\nclass OrderConfirmationSchema(BaseIOSchema):\n    \"\"\"\n    Confirmation details of the placed order.\n    \"\"\"\n    order_id: str = Field(..., description=\"Unique identifier for the order.\")\n    estimated_delivery_time: str = Field(..., description=\"Estimated time for order delivery.\")\n    status: OrderStatus = Field(..., description=\"Current status of the order.\")\n\nclass PaymentDetailsSchema(BaseIOSchema):\n    \"\"\"\n    Payment information for the order.\n    \"\"\"\n    amount: float = Field(..., description=\"Total amount to be paid.\")\n    currency: str = Field(\"USD\", description=\"Currency of the payment.\")\n    payment_status: str = Field(..., description=\"Status of the payment (e.g., Paid, Pending).\")\n```\n\n----------------------------------------\n\nTITLE: Using the Webpage Scraper Tool in Python\nDESCRIPTION: Complete example demonstrating how to initialize the scraper, define input parameters, and execute the scraping operation with the WebpageScraperTool.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/webpage_scraper/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom tool.webpage_scraper import WebpageScraperTool, WebpageScraperToolConfig\n\n# Initialize the tool\nscraper = WebpageScraperTool(config=WebpageScraperToolConfig())\n\n# Define input data\ninput_data = WebpageScraperTool.input_schema(\n    url=\"https://example.com/article\",\n    include_links=True\n)\n\n# Perform the scraping\nresult = scraper.run(input_data)\nprint(f\"Title: {result.metadata.title}\")\nprint(f\"Content: {result.content[:200]}...\")  # Preview first 200 chars\n```\n\n----------------------------------------\n\nTITLE: Configuring YouTube Transcript Tool in Python\nDESCRIPTION: This snippet demonstrates how to create a configuration object for the YouTube Transcript Tool using the YouTubeTranscriptToolConfig class. It requires a YouTube API key as a parameter.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/youtube_transcript_scraper/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nconfig = YouTubeTranscriptToolConfig(\n    api_key=\"your_youtube_api_key\"\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom MCP Tool\nDESCRIPTION: Template for creating a new tool that implements the MCP Tool interface, including defining input parameters and implementing the execute method.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass MyNewTool(Tool):\n    name = \"my_new_tool\"\n    description = \"This tool performs a custom operation\"\n    input_model = create_model(\n        \"MyNewToolInput\",\n        param1=(str, Field(..., description=\"First parameter\")),\n        param2=(int, Field(..., description=\"Second parameter\")),\n        __base__=BaseToolInput\n    )\n\n    async def execute(self, input_data: BaseToolInput) -> ToolResponse:\n        # Access params with input_data.param1, input_data.param2\n        result = f\"Processed {input_data.param1} with {input_data.param2}\"\n        return ToolResponse.from_text(result)\n```\n\n----------------------------------------\n\nTITLE: Fetching and Managing MCP Tools in Client\nDESCRIPTION: Shows how to fetch available tools from an MCP server and build a mapping of tool schemas to corresponding tool classes for use in the client application.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Fetch available tools\ntools = fetch_mcp_tools(\n    mcp_endpoint=config.mcp_server_url,\n    use_stdio=False,\n)\n\n# Build tool schema mapping\ntool_schema_to_class_map = {\n    ToolClass.input_schema: ToolClass\n    for ToolClass in tools\n    if hasattr(ToolClass, \"input_schema\")\n}\n```\n\n----------------------------------------\n\nTITLE: Running MCP Server in Development Mode with Auto-Reload\nDESCRIPTION: Command to run the MCP server in SSE mode with auto-reload feature. This automatically restarts the server when code changes are detected, making development faster and more efficient.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npoetry run example-mcp-server --mode=sse --reload\n```\n\n----------------------------------------\n\nTITLE: BaseIOSchema Definition in RST Format\nDESCRIPTION: Documentation for the BaseIOSchema class that serves as the foundation for all agent input/output schemas, inheriting from Pydantic's BaseModel.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. py:class:: BaseIOSchema\n\n    Base schema class for all agent input/output schemas. Inherits from :class:`pydantic.BaseModel`.\n\n    All agent schemas must inherit from this class to ensure proper serialization and validation.\n\n    **Inheritance:**\n        - :class:`pydantic.BaseModel`\n```\n\n----------------------------------------\n\nTITLE: Running the Atomic Agents Examples\nDESCRIPTION: Instructions for running the Atomic Agents examples, including setting environment variables and executing the Python script with Poetry package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"your-api-key\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python chatbot.py\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies with Version Constraints\nDESCRIPTION: This snippet lists the required Python packages for the Atomic Agents project, along with their version constraints. It ensures compatibility and defines the project's ecosystem.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ninstructor>=1.3.4,<2.0.0\npydantic>=2.8.0,<3.0.0\nrich>=13.7.1,<14.0.0\ngitpython>=3.1.43,<4.0.0\npyfiglet>=1.0.2,<2.0.0\ntextual>=0.82.0,<1.0.0\npyyaml>=6.0.2,<7.0.0\nrequests>=2.32.3,<3.0.0\natomic-agents>=1.0.0,<2.0.0\n```\n\n----------------------------------------\n\nTITLE: BaseAgentInputSchema Definition in RST Format\nDESCRIPTION: Documentation for the BaseAgentInputSchema class which provides the default input structure for agent interactions, including a chat_message field.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. py:class:: BaseAgentInputSchema\n\n    Default input schema for agent interactions.\n\n    **Inheritance:**\n        - :class:`BaseIOSchema` → :class:`pydantic.BaseModel`\n\n    .. py:attribute:: chat_message\n        :type: str\n\n        The message to send to the agent.\n\n    Example:\n        >>> input_schema = BaseAgentInputSchema(chat_message=\"Hello, agent!\")\n        >>> agent.run(input_schema)\n```\n\n----------------------------------------\n\nTITLE: Configuring Pizza Ordering Tool in Python\nDESCRIPTION: This snippet defines the configuration class for the Pizza Ordering Tool, including API endpoint, supported pizzas, and authentication details.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass PizzaOrderingToolConfig(BaseToolConfig):\n    \"\"\"\n    Configuration for the PizzaOrderingTool.\n    \"\"\"\n    api_endpoint: str = Field(\n        default=\"https://api.pizzaorders.com/v1/orders\",\n        description=\"API endpoint for processing pizza orders.\"\n    )\n    supported_pizzas: List[str] = Field(\n        default=[\"Margherita\", \"Pepperoni\", \"Veggie\", \"Hawaiian\"],\n        description=\"List of supported pizza types.\"\n    )\n    api_key: str = Field(\n        default=os.getenv(\"PIZZA_API_KEY\"),\n        description=\"API key for authenticating with the pizza ordering service.\"\n    )\n    title: Optional[str] = Field(\n        default=\"Pizza Ordering Tool\",\n        description=\"Override the default title of the tool.\"\n    )\n    description: Optional[str] = Field(\n        default=\"A tool to place pizza orders and process payments.\",\n        description=\"Override the default description of the tool.\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration\nDESCRIPTION: Configuration for the .env file containing necessary API keys for the application\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/deep-research/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: System Architecture Diagram in Mermaid\nDESCRIPTION: A diagram showing the system architecture with three main components: AI Agents (ChoiceAgent, QueryAgent, AnswerAgent), External Tools (SearxNG Search, Webpage Scraper), and Context Providers (Scraped Content, Current Date). It illustrates how user questions flow through the system and how different components interact.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/deep-research/mermaid.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    %% System Architecture Diagram\n    subgraph Agents[\"AI Agents\"]\n        CA[ChoiceAgent]\n        QA[QueryAgent]\n        AA[AnswerAgent]\n    end\n\n    subgraph Tools[\"External Tools\"]\n        ST[SearxNG Search]\n        WS[Webpage Scraper]\n    end\n\n    subgraph Context[\"Context Providers\"]\n        SC[Scraped Content]\n        CD[Current Date]\n    end\n\n    %% Connections\n    User -->|Question| CA\n    CA -->|Search Request| QA\n    QA -->|Queries| ST\n    ST -->|URLs| WS\n    WS -->|Content| SC\n    SC -.->|Context| CA & QA & AA\n    CD -.->|Date Info| CA & QA & AA\n    CA -->|Direct Answer| AA\n    AA -->|Response| User\n\n    %% Styling\n    classDef agent fill:#4CAF50,stroke:#2E7D32,color:#fff;\n    classDef tool fill:#FF9800,stroke:#EF6C00,color:#fff;\n    classDef context fill:#F44336,stroke:#C62828,color:#fff;\n    classDef user fill:#9C27B0,stroke:#6A1B9A,color:#fff;\n\n    class CA,QA,AA agent;\n    class ST,WS tool;\n    class SC,CD context;\n    class User user;\n```\n\n----------------------------------------\n\nTITLE: Running Atomic Agents CLI using Bash\nDESCRIPTION: This code snippet shows different ways to run the Atomic Agents CLI based on how it was installed. It includes commands for running the CLI directly, with Poetry, or with uv package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\natomic\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry run atomic\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv run atomic\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables\nDESCRIPTION: Environment variables configuration needed for the YouTube Summarizer to function. Includes API keys for OpenAI and YouTube services.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-summarizer/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\nYOUTUBE_API_KEY=your_youtube_api_key\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using Calculator Tool in Python\nDESCRIPTION: This snippet demonstrates how to initialize the Calculator Tool, define input data, and perform a calculation. It shows the process of importing the necessary classes, creating an instance of the tool, setting up the input, and running the calculation.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/calculator/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom tool.calculator import CalculatorTool, CalculatorToolConfig\n\n# Initialize the tool\ncalculator = CalculatorTool(config=CalculatorToolConfig())\n\n# Define input data\ninput_data = CalculatorTool.input_schema(\n    expression=\"sin(pi/2) + cos(pi/4)\"\n)\n\n# Perform the calculation\nresult = calculator.run(input_data)\nprint(result)  # Expected output: {\"result\":\"1.70710678118655\"}\n```\n\n----------------------------------------\n\nTITLE: Configuring Tavily Search Tool in Python\nDESCRIPTION: Example of creating a configuration object for the Tavily Search Tool. The configuration requires an API key and optionally accepts a maximum number of search results parameter.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/tavily_search/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nconfig = TavilySearchToolConfig(\n    api_key=\"my-api-key\",\n    max_results=5\n)\n```\n\n----------------------------------------\n\nTITLE: Running the RAG Chatbot with Poetry in Bash\nDESCRIPTION: Command to execute the main Python script of the RAG Chatbot using Poetry.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/rag-chatbot/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python rag_chatbot/main.py\n```\n\n----------------------------------------\n\nTITLE: Configuring the MCP Client\nDESCRIPTION: Shows the configuration class for the MCP client, including server URL, OpenAI model selection, and API key configuration for both SSE and STDIO transport modes.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass MCPConfig:\n    mcp_server_url: str = \"http://localhost:6969\"\n    openai_model: str = \"gpt-4o-mini\"\n    openai_api_key: str = os.getenv(\"OPENAI_API_KEY\")\n```\n\n----------------------------------------\n\nTITLE: Configuring STDIO Mode Connection in Python Client\nDESCRIPTION: Python code snippet showing how to configure an MCP client to launch and connect to the server in STDIO mode. This mode is useful for local development and testing.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmcp_stdio_server_command: str = \"poetry run example-mcp-server --mode stdio\"\n```\n\n----------------------------------------\n\nTITLE: Running the Deep Research Agent\nDESCRIPTION: Command to execute the main Deep Research Agent application using Poetry\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/deep-research/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python deep_research/main.py\n```\n\n----------------------------------------\n\nTITLE: Configuring the MCP Client for STDIO Transport\nDESCRIPTION: Shows the configuration class for the MCP client using STDIO transport, specifying the command to start the MCP server in STDIO mode.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass MCPConfig:\n    openai_model: str = \"gpt-4o-mini\"\n    openai_api_key: str = os.getenv(\"OPENAI_API_KEY\")\n    mcp_stdio_server_command: str = \"poetry run example-mcp-server --mode stdio\"\n```\n\n----------------------------------------\n\nTITLE: Registering a Custom Tool with the MCP Server\nDESCRIPTION: Shows how to register a custom tool with the MCP server by adding it to the list of available tools returned by the get_available_tools function.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef get_available_tools() -> List[Tool]:\n    return [\n        # ... existing tools ...\n        MyNewTool(),\n    ]\n```\n\n----------------------------------------\n\nTITLE: Installing Atomic Agents with pip\nDESCRIPTION: Command to install the Atomic Agents framework using pip package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/quickstart.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Installing Atomic Agents Framework\nDESCRIPTION: Instructions for installing the Atomic Agents framework using pip or Poetry package managers. Includes optional provider installations for OpenAI and Groq.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/index.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install atomic-agents\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry add atomic-agents\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install openai groq\n```\n\n----------------------------------------\n\nTITLE: Implementing SSE Handler for MCP Server\nDESCRIPTION: Shows the server-side implementation of the Server-Sent Events (SSE) handler that creates communication streams and runs the MCP server with these streams.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Server-side SSE setup (from server_sse.py)\nasync def handle_sse(request: Request) -> None:\n    async with sse.connect_sse(\n        request.scope,\n        request.receive,\n        request._send,  # noqa: SLF001\n    ) as (read_stream, write_stream):\n        await mcp_server.run(\n            read_stream,\n            write_stream,\n            mcp_server.create_initialization_options(),\n        )\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Command to install project dependencies using Poetry, the recommended dependency management tool for the Atomic Agents project.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Example pyproject.toml for Atomic Tool\nDESCRIPTION: Shows a sample Poetry configuration file for an Atomic Tool, including metadata, dependencies, and build settings for a Pizza Ordering Tool example.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[tool.poetry]\nname = \"pizza-ordering-tool\"\nversion = \"1.0\"\ndescription = \"A tool for placing and processing pizza orders\"\nauthors = [\"Your Name <your.email@example.com>\"]\nreadme = \"README.md\"\npackage-mode = false\n\n[tool.poetry.dependencies]\npython = \">=3.9,<4.0\"\natomic-agents = {path = \"../../../\", develop = true}\npydantic = \">=2.8.2,<3.0.0\"\nrequests = \">=2.28.0,<3.0.0\"\n\n[tool.poetry.group.dev.dependencies]\ncoverage = \">=7.0.0,<8.0.0\"\npytest = \">=8.0.0,<9.0.0\"\npytest-cov = \">=5.0.0,<6.0.0\"\npython-dotenv = \">=1.0.0,<2.0.0\"\nrich = \">=13.7.0,<14.0.0\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up STDIO Transport for MCP Client\nDESCRIPTION: Demonstrates how to bootstrap STDIO transport for an MCP client, creating a communication channel with the server through standard input/output streams.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Client-side STDIO setup (from main_stdio.py)\nasync def _bootstrap_stdio():\n    stdio_exit_stack = AsyncExitStack()\n    command_parts = shlex.split(config.mcp_stdio_server_command)\n    server_params = StdioServerParameters(command=command_parts[0], args=command_parts[1:], env=None)\n    read_stream, write_stream = await stdio_exit_stack.enter_async_context(stdio_client(server_params))\n    session = await stdio_exit_stack.enter_async_context(ClientSession(read_stream, write_stream))\n    await session.initialize()\n    return session\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with Poetry\nDESCRIPTION: Commands to create a virtual environment and install dependencies using Poetry package manager. This is required before running the server.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Example Python Queries for the MCP Agent\nDESCRIPTION: Sample Python expressions and natural language queries to demonstrate the agent's capabilities from simple arithmetic to complex multi-step calculations.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simple arithmetic\n\"What is 2+2?\"\n# Uses AddNumbers tool directly\n\n# Complex expressions\n\"(5-9)*0.123\"\n# Uses SubtractNumbers followed by MultiplyNumbers\n\n# Multi-step calculations\n\"((4**3)-10)/100)**2\"\n# Uses multiple tools in sequence to break down the complex expression\n\n# Natural language queries\n\"Calculate the difference between 50 and 23, then multiply it by 3\"\n# Understands natural language and breaks it down into appropriate tool calls\n```\n\n----------------------------------------\n\nTITLE: Running MCP Server in Different Modes with Command Line Script\nDESCRIPTION: Commands to run the MCP server in either stdio mode (for subprocess communication) or SSE mode (HTTP Server-Sent Events) with various configuration options using the command line script.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Run in stdio mode (for direct subprocess communication)\npoetry run example-mcp-server --mode=stdio\n\n# Run in SSE mode (defaults to http://0.0.0.0:6969)\npoetry run example-mcp-server --mode=sse\n\n# Run in SSE mode with custom host/port\npoetry run example-mcp-server --mode=sse --host 127.0.0.1 --port 8000\n\n# Run in SSE mode with auto-reload for development\npoetry run example-mcp-server --mode=sse --reload\n```\n\n----------------------------------------\n\nTITLE: Activating the Virtual Environment\nDESCRIPTION: Command to activate the Poetry-managed virtual environment, isolating the project's dependencies from the system-wide Python installation.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry shell\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables\nDESCRIPTION: Example of the required environment variables to be placed in a .env file, specifically the OpenAI API key needed for the agent's functionality.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/orchestration-agent/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Writing Tests for a Custom Tool\nDESCRIPTION: Example test function for a custom tool, showing how to create test inputs and verify the expected outputs.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/contributing.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef test_my_tool():\n    tool = MyTool()\n    inputs = MyToolInputs(...)\n    result = tool.run(inputs)\n    assert isinstance(result, MyToolOutputs)\n    # Add more assertions\n```\n\n----------------------------------------\n\nTITLE: Setting Up the MCP Server with Poetry\nDESCRIPTION: Commands to navigate to the example MCP server directory and install dependencies using Poetry.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd example-mcp-server\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for OpenAI API\nDESCRIPTION: Sample content for a .env file that sets up the OpenAI API key, which is required for using GPT-4 Vision capabilities.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/basic-multimodal/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Installing Atomic Agents and Provider Dependencies\nDESCRIPTION: Commands for installing the Atomic Agents package and required provider dependencies via pip. Shows how to install the core package along with OpenAI and Groq providers.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install atomic-agents\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install openai groq\n```\n\n----------------------------------------\n\nTITLE: Setting Up the MCP Client with Poetry\nDESCRIPTION: Commands to navigate to the example client directory and install dependencies using Poetry.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd ../example-client\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Command to install all required dependencies for the project using Poetry package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/basic-multimodal/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Running the Server and Client with SSE Transport\nDESCRIPTION: Commands for starting the MCP server with SSE transport mode in one terminal and running the client with SSE transport in another terminal.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# First terminal: Start the server\ncd example-mcp-server\npoetry run example-mcp-server --mode=sse\n\n# Second terminal: Run the client\ncd example-client\npoetry run python -m example_client.main --transport sse\n```\n\n----------------------------------------\n\nTITLE: Building Documentation Locally\nDESCRIPTION: Commands to build and verify documentation locally using Sphinx.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/contributing.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\npoetry run sphinx-build -b html . _build/html\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Command to install project dependencies using Poetry package manager\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/deep-research/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Running the MCP Client with SSE Transport\nDESCRIPTION: Command line examples for running the MCP client, either using the main launcher with transport selection or directly calling the SSE-specific client module.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncd example-client\npoetry run python -m example_client.main --transport sse\n```\n\n----------------------------------------\n\nTITLE: Linting Code with Flake8\nDESCRIPTION: Command to run the Flake8 linter on the project's main directories, checking for code quality issues and adherence to PEP 8 guidelines.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nflake8 atomic_agents atomic_assembler\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Command to install all required dependencies for the YouTube Recipe Extractor using Poetry package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-to-recipe/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Command to install project dependencies using Poetry package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/web-search-agent/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Cloning and Setting Up the Atomic Agents Repository\nDESCRIPTION: Commands to fork and clone the repository, install dependencies using poetry, set up pre-commit hooks, and create a new feature branch for development.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/contributing.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/YOUR_USERNAME/atomic-agents.git\ncd atomic-agents\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\nLANGUAGE: bash\nCODE:\n```\npre-commit install\n```\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b feature/your-feature-name\n```\n\n----------------------------------------\n\nTITLE: Generating HTML Coverage Report\nDESCRIPTION: Command to generate a detailed HTML coverage report, allowing developers to visualize test coverage for the project.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncoverage html\n```\n\n----------------------------------------\n\nTITLE: Example requirements.txt for Atomic Tool\nDESCRIPTION: Shows a manually created requirements.txt file that includes only the runtime dependencies needed for the tool, excluding development dependencies from pyproject.toml.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\natomic-agents>=1.0.0,<2.0.0\npydantic>=2.8.2,<3.0.0\nrequests>=2.28.0,<3.0.0\n```\n\n----------------------------------------\n\nTITLE: Defining Atomic Tool Folder Structure\nDESCRIPTION: Shows the recommended folder structure for organizing an Atomic Tool, including the main tool directory, code files, tests, and configuration files.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntool_name/\n│   .coveragerc\n│   pyproject.toml\n│   README.md\n│   requirements.txt\n│   poetry.lock\n│\n├── tool/\n│   │   tool_name.py\n│   │   some_util_file.py\n│   │   another_util_file.py\n│\n└── tests/\n    │   test_tool_name.py\n    │   test_some_util_file.py\n    │   test_another_util_file.py\n```\n\n----------------------------------------\n\nTITLE: Committing and Pushing Changes\nDESCRIPTION: Git commands for committing changes with a descriptive message and pushing to a forked repository.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/contributing.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit add .\ngit commit -m \"feat: add new feature\"\n```\n\nLANGUAGE: bash\nCODE:\n```\ngit push origin feature/your-feature-name\n```\n\n----------------------------------------\n\nTITLE: Installing Atomic Agents for Local Development\nDESCRIPTION: Instructions for setting up Atomic Agents for local development by cloning the repository and installing dependencies using Poetry.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents.git\ncd atomic-agents\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Sample Import Section for Atomic Tool\nDESCRIPTION: Demonstrates the standard import section at the top of an Atomic Tool file, including standard libraries, third-party packages, and Atomic Agents framework modules.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/guides/tool_structure.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom enum import Enum\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel, Field\n\nfrom atomic_agents.agents.base_agent import BaseIOSchema\nfrom atomic_agents.lib.base.base_tool import BaseTool, BaseToolConfig\n```\n\n----------------------------------------\n\nTITLE: Pushing Changes to Fork\nDESCRIPTION: Git command to push the local feature branch to the developer's fork on GitHub, preparing for a pull request.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ngit push origin feature-branch\n```\n\n----------------------------------------\n\nTITLE: Creating a New Tool Using the Tool Template\nDESCRIPTION: Command to create a new tool using the atomic-assembler utility.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/contributing.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\natomic-assembler create-tool my-tool\n```\n\n----------------------------------------\n\nTITLE: Starting the MCP Server from Command Line\nDESCRIPTION: Command line example for starting the MCP server in SSE mode with specified host, port, and development reload option.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npoetry run example-mcp-server --mode=sse --host=0.0.0.0 --port=6969 --reload\n```\n\n----------------------------------------\n\nTITLE: Cloning the Atomic Agents Repository\nDESCRIPTION: Command to clone the Atomic Agents repository from GitHub to your local machine.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/orchestration-agent/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Running the Orchestration Agent Example\nDESCRIPTION: Command to execute the orchestration agent example using Poetry's run command.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/orchestration-agent/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python orchestration_agent/orchestrator.py\n```\n\n----------------------------------------\n\nTITLE: Running the Web Search Agent\nDESCRIPTION: Command to execute the main Python script for the Web Search Agent using Poetry.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/web-search-agent/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python web_search_agent/main.py\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies with Version Constraints\nDESCRIPTION: This snippet defines the required Python packages and their version ranges for the Atomic Agents project. It ensures compatibility by specifying minimum and maximum versions for each dependency.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/searxng_search/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\natomic-agents>=1.0.0,<2.0.0\npydantic>=2.8.2,<3.0.0\nsympy>=1.12,<2.0.0\n```\n\n----------------------------------------\n\nTITLE: Cloning the Repository and Navigating to Example Directory\nDESCRIPTION: Git commands to clone the Atomic Agents repository and navigate to the MCP agent example directory.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\ncd atomic-agents/atomic-examples/mcp-agent\n```\n\n----------------------------------------\n\nTITLE: Running the Client with STDIO Transport\nDESCRIPTION: Commands to navigate to the client directory and run the example using the default STDIO transport method.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd example-client\npoetry run python -m example_client.main\n```\n\n----------------------------------------\n\nTITLE: Running MCP Server as Python Module\nDESCRIPTION: Alternative commands to run the MCP server as a Python module, either using the unified server script or by calling the specific implementations directly. This provides more flexibility for integration.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Using the unified server script\npoetry run python -m example_mcp_server.server --mode=stdio\npoetry run python -m example_mcp_server.server --mode=sse\n\n# Or call the specific implementations directly\npoetry run python -m example_mcp_server.server_stdio\npoetry run python -m example_mcp_server.server_sse\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables\nDESCRIPTION: Example content for the .env file, including OpenAI API key and SearxNG base URL.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/web-search-agent/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\nSEARXNG_BASE_URL=your_searxng_instance_url\n```\n\n----------------------------------------\n\nTITLE: Running the MCP Client with STDIO Transport\nDESCRIPTION: Command line example for running the MCP client using STDIO transport by directly calling the STDIO-specific client module.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/examples/mcp_agent.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncd example-client\npoetry run python -m example_client.main_stdio\n```\n\n----------------------------------------\n\nTITLE: Navigating to the Example Directory\nDESCRIPTION: Command to change directory to the basic-multimodal example folder within the cloned repository.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/basic-multimodal/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-agents/atomic-examples/basic-multimodal\n```\n\n----------------------------------------\n\nTITLE: Cloning the Atomic Agents Repository\nDESCRIPTION: Command to clone the main Atomic Agents repository which contains the YouTube Recipe Extractor example.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-to-recipe/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Navigating to Project Directory in Bash\nDESCRIPTION: Command to change the current directory to the project location. This is the first step in the setup process before installing dependencies.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-examples/mcp-agent/example-mcp-server\n```\n\n----------------------------------------\n\nTITLE: Navigating to the Orchestration Agent Directory\nDESCRIPTION: Command to change directory to the orchestration-agent example folder within the cloned repository.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/orchestration-agent/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-agents/atomic-examples/orchestration-agent\n```\n\n----------------------------------------\n\nTITLE: Navigating to the YouTube Summarizer Directory\nDESCRIPTION: Command to change directory to the YouTube Summarizer example within the cloned repository.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-summarizer/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-agents/atomic-examples/youtube-summarizer\n```\n\n----------------------------------------\n\nTITLE: Cloning Atomic Agents Repository\nDESCRIPTION: Command to clone the Atomic Agents repository from GitHub.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/web-search-agent/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Cloning the Atomic Agents Repository\nDESCRIPTION: Command to clone the main Atomic Agents repository from GitHub to get access to the YouTube Summarizer example.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-summarizer/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables\nDESCRIPTION: Example of the .env file content required for the YouTube Recipe Extractor, including OpenAI and YouTube API keys.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-to-recipe/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\nYOUTUBE_API_KEY=your_youtube_api_key\n```\n\n----------------------------------------\n\nTITLE: BaseAgentOutputSchema Definition in RST Format\nDESCRIPTION: Documentation for the BaseAgentOutputSchema class which provides the default output structure for agent responses, including a chat_message field.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/agents.md#2025-04-22_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. py:class:: BaseAgentOutputSchema\n\n    Default output schema for agent responses.\n\n    **Inheritance:**\n        - :class:`BaseIOSchema` → :class:`pydantic.BaseModel`\n\n    .. py:attribute:: chat_message\n        :type: str\n\n        The response message from the agent.\n\n    Example:\n        >>> response = agent.run(input_schema)\n        >>> print(response.chat_message)\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Coverage\nDESCRIPTION: Command to run the project's test suite using pytest with coverage reporting, ensuring all new functionality is properly tested.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npytest --cov atomic_agents\n```\n\n----------------------------------------\n\nTITLE: Cloning the Atomic Agents Repository\nDESCRIPTION: Commands to clone the Atomic Agents repository and navigate to the project directory. This is the first step in setting up the development environment.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents.git\ncd atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Running the Multimodal Example\nDESCRIPTION: Command to execute the example application using Poetry, which will process nutrition label images and display structured results.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/basic-multimodal/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python basic_multimodal/main.py\n```\n\n----------------------------------------\n\nTITLE: TOC Structure in Sphinx Documentation\nDESCRIPTION: Sphinx toctree directive defining the structure of the user guide documentation, including links to quickstart, basic concepts, tools, and advanced usage sections.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/guides/index.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: 2\n:caption: Guides\n\nquickstart\nbasic_concepts\ntools\nadvanced_usage\n```\n\n----------------------------------------\n\nTITLE: Specifying Dependency Versions for Atomic Agents Project\nDESCRIPTION: This snippet defines the version requirements for key Python packages used in the Atomic Agents project. It ensures compatibility by specifying minimum and maximum versions for each package.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/tavily_search/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\natomic-agents>=1.0.0,<2.0.0\npydantic>=2.8.2,<3.0.0\nsympy>=1.12,<2.0.0\naiohttp>=3.9.0,<4.0.0\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies with Version Constraints\nDESCRIPTION: A requirements specification listing four Python packages with version constraints. The file specifies atomic-agents itself, Google API client library, Pydantic for data validation, and a YouTube transcript API, all with minimum and maximum version bounds.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-forge/tools/youtube_transcript_scraper/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\natomic-agents>=1.0.0,<2.0.0\ngoogle-api-python-client>=2.118.0,<3.0.0\npydantic>=2.8.2,<3.0.0\nyoutube-transcript-api>=0.6.2,<1.0.0\n```\n\n----------------------------------------\n\nTITLE: Running the YouTube Summarizer\nDESCRIPTION: Command to execute the YouTube Summarizer application using Poetry to manage the Python environment.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-summarizer/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python youtube_summarizer/main.py\n```\n\n----------------------------------------\n\nTITLE: Creating a New Feature Branch\nDESCRIPTION: Git command to create and switch to a new branch for developing a feature or fixing a bug, following the project's branching workflow.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b feature-branch\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for OpenAI API\nDESCRIPTION: Example content for the .env file to set up the OpenAI API key as an environment variable.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/rag-chatbot/README.md#2025-04-22_snippet_3\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=your_openai_api_key\n```\n\n----------------------------------------\n\nTITLE: Committing Changes\nDESCRIPTION: Git command to commit changes with a descriptive message, following the project's commit message conventions.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngit commit -m 'Add some feature'\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry in Bash\nDESCRIPTION: Command to install the project dependencies using Poetry package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/rag-chatbot/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Command to install all required dependencies using the Poetry package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/orchestration-agent/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Running the YouTube Recipe Extractor\nDESCRIPTION: Command to run the YouTube Recipe Extractor application after setup is complete.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-to-recipe/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python youtube_to_recipe/main.py\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry\nDESCRIPTION: Command to install all required dependencies for the YouTube Summarizer using Poetry package manager.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-summarizer/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for API Reference in Sphinx\nDESCRIPTION: This code snippet defines the table of contents for the API reference documentation using Sphinx's toctree directive. It specifies the depth and caption for the table of contents, and lists the main sections of the API documentation.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/api/index.md#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n```{toctree}\n:maxdepth: 2\n:caption: API Reference\n\nagents\ncomponents\nutils\n```\n```\n\n----------------------------------------\n\nTITLE: Displaying Project Structure Using Tree Command\nDESCRIPTION: Shows the directory and file structure of the Example MCP Server project, illustrating how the code is organized into packages, modules, and interfaces.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/mcp-agent/example-mcp-server/README.md#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n./\n├── example_mcp_server/           # Python package for your server code\n│   ├── __init__.py              # Package initialization\n│   ├── server.py                # Unified server entry point with mode selection\n│   ├── server_stdio.py          # Implementation for stdio transport\n│   ├── server_sse.py            # Implementation for SSE transport (HTTP)\n│   ├── interfaces/              # Base classes/interfaces for tools and resources\n│   │   ├── __init__.py\n│   │   ├── resource.py\n│   │   └── tool.py\n│   ├── resources/               # Implementation of resources\n│   │   ├── __init__.py\n│   │   ├── hello_world.py       # Example static resource\n│   │   └── user_profile.py      # Example dynamic resource with URI parameters\n│   ├── services/                # Services for managing tools and resources\n│   │   ├── __init__.py\n│   │   ├── resource_service.py  # Handles resource registration and routing\n│   │   └── tool_service.py      # Handles tool registration and execution\n│   └── tools/                   # Implementation of tools\n│       ├── __init__.py\n│       └── hello_world.py       # Example tool with input/output schemas\n├── pyproject.toml               # Project metadata and dependencies\n└── README.md                    # This file\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Pytest\nDESCRIPTION: Command to run tests using pytest through poetry.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/docs/contributing.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run pytest\n```\n\n----------------------------------------\n\nTITLE: Formatting Code with Black\nDESCRIPTION: Command to run the Black code formatter on the project's main directories, ensuring consistent code style across the codebase.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/guides/DEV_GUIDE.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nblack atomic_agents atomic_assembler\n```\n\n----------------------------------------\n\nTITLE: Navigating to Web Search Agent Directory\nDESCRIPTION: Command to change directory to the web-search-agent folder within the cloned repository.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/web-search-agent/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-agents/atomic-examples/web-search-agent\n```\n\n----------------------------------------\n\nTITLE: Navigating to RAG Chatbot Directory in Bash\nDESCRIPTION: Command to change the current directory to the RAG Chatbot example folder.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/rag-chatbot/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-agents/atomic-examples/rag-chatbot\n```\n\n----------------------------------------\n\nTITLE: Navigating to Deep Research Directory\nDESCRIPTION: Command to change directory to the Deep Research example folder\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/deep-research/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-agents/atomic-examples/deep-research\n```\n\n----------------------------------------\n\nTITLE: Cloning Atomic Agents Repository\nDESCRIPTION: Command to clone the main Atomic Agents repository from GitHub\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/deep-research/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Navigating to the YouTube Recipe Extractor Directory\nDESCRIPTION: Command to change directory to the YouTube Recipe Extractor project folder after cloning the repository.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/youtube-to-recipe/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd atomic-agents/atomic-examples/youtube-to-recipe\n```\n\n----------------------------------------\n\nTITLE: Cloning Atomic Agents Repository in Bash\nDESCRIPTION: Command to clone the main Atomic Agents repository from GitHub.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/rag-chatbot/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\n```\n\n----------------------------------------\n\nTITLE: Cloning the Atomic Agents Repository\nDESCRIPTION: Command to clone the main Atomic Agents repository from GitHub, which is the first step in setting up the project.\nSOURCE: https://github.com/brainblend-ai/atomic-agents/blob/main/atomic-examples/basic-multimodal/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/BrainBlend-AI/atomic-agents\n```"
  }
]