[
  {
    "owner": "ag2ai",
    "repo": "faststream",
    "content": "TITLE: Implementing Basic RabbitMQ Subscriber with FastStream in Python\nDESCRIPTION: This code snippet shows how to create a basic RabbitMQ subscriber using FastStream's RabbitBroker. It defines a broker, creates a subscriber function, and runs the application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/index.py !}\n```\n\n----------------------------------------\n\nTITLE: Starting Redis Test Broker Container\nDESCRIPTION: Docker command to start a Redis test broker container for development purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --rm -p 6379:6379 --name test-mq redis\n```\n\n----------------------------------------\n\nTITLE: Creating a Redis Stream Subscriber with FastStream\nDESCRIPTION: This code snippet shows the complete implementation of a FastStream app that consumes messages from a Redis stream named 'test-stream'. It includes imports, broker setup, and a subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/subscription.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test-stream\")\nasync def handle(msg: str):\n    logger.info(msg)\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream and KafkaBroker\nDESCRIPTION: Demonstrates how to import the necessary FastStream components to work with Kafka. This imports the FastStream application class and the KafkaBroker for connecting to Kafka.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Subscriber/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/confluent/consumes_basics/app.py [ln:3-4] !}\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Redis in Python\nDESCRIPTION: Example of how to publish a message to a Redis channel using FastStream. The RedisBroker is used as an async context manager for handling connections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync with RedisBroker() as br:\n    await br.publish(\"message\", \"channel\")\n```\n\n----------------------------------------\n\nTITLE: Complete Django-FastStream Integration with ASGI\nDESCRIPTION: Full example of integrating FastStream with Django using Starlette for ASGI support, static file serving, and broker lifecycle management.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom contextlib import asynccontextmanager\n\nfrom django.core.asgi import get_asgi_application\nfrom starlette.applications import Starlette\nfrom starlette.routing import Mount\nfrom starlette.staticfiles import StaticFiles\nfrom faststream.kafka import KafkaBroker\n\n\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"app.settings\")\n\nbroker = KafkaBroker()\n\n@asynccontextmanager\nasync def broker_lifespan(app):\n    await broker.start()\n    try:\n        yield\n    finally:\n        await broker.close()\n\napplication = Starlette(\n    routes=(\n        Mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\"),\n        Mount(\"/\", get_asgi_application()),\n    ),\n    lifespan=broker_lifespan,\n)\n```\n\n----------------------------------------\n\nTITLE: FastStream Application with Pydantic Models and AIOKafka\nDESCRIPTION: An example of using Pydantic models for message serialization in a FastStream application with AIOKafka.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/kafka/pydantic.py !}\n```\n\n----------------------------------------\n\nTITLE: Basic FastStream Application with Kafka\nDESCRIPTION: A simple FastStream application that consumes messages from an 'in' topic and publishes transformed messages to an 'out' topic using Kafka. The example shows how to use function decorators for subscribing and publishing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n# from faststream.rabbit import RabbitBroker\n# from faststream.nats import NatsBroker\n# from faststream.redis import RedisBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\n# broker = RabbitBroker(\"amqp://guest:guest@localhost:5672/\")\n# broker = NatsBroker(\"nats://localhost:4222/\")\n# broker = RedisBroker(\"redis://localhost:6379/\")\n\napp = FastStream(broker)\n\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def handle_msg(user: str, user_id: int) -> str:\n    return f\"User: {user_id} - {user} registered\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Batch Subscriber in FastStream\nDESCRIPTION: Shows how to implement a basic batch subscriber using the broker.subscriber decorator with the batch parameter set to True.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Subscriber/batch_subscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test_batch\", batch=True)\nasync def consume(msgs: list[MyModel]):\n    return msgs\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Parser for Confluent Kafka in FastStream\nDESCRIPTION: Defines a custom parser function for Confluent Kafka messages in FastStream. It extracts a custom message_id from headers and creates a KafkaMessage object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom confluent_kafka import Message\nfrom faststream.confluent import KafkaMessage\n\ndef parser(msg: Message) -> KafkaMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with RabbitMQ in Python\nDESCRIPTION: Example of how to publish a message to a RabbitMQ queue using FastStream. The RabbitBroker is used as an async context manager for connection handling.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nasync with RabbitBroker() as br:\n    await br.publish(\"message\", \"queue\")\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Confluent\nDESCRIPTION: Command to install FastStream with Confluent support using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\npip install \"faststream[confluent]\"\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Kafka Topics with FastStream\nDESCRIPTION: Demonstrates how to create a basic Kafka subscriber using FastStream's KafkaBroker. The subscriber function handles messages from a specified topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(\"test\")  # topic name\nasync def handle_msg(msg_body):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with RabbitMQ in FastStream\nDESCRIPTION: This snippet illustrates how to create and use a Publisher object with RabbitMQ in FastStream. It shows the setup of the RabbitBroker and creation of a Publisher for the 'test' queue.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/direct.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"test\")\n\n@broker.subscriber(\"input\")\nasync def on_input(msg: str):\n    await publisher.publish(msg)\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with AIOKafka in Python\nDESCRIPTION: Example of how to publish a message to a Kafka topic using FastStream with AIOKafka. The broker is used as an async context manager for connection handling.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nasync with KafkaBroker() as br:\n    await br.publish(\"message\", \"topic\")\n```\n\n----------------------------------------\n\nTITLE: Initializing KafkaBroker and Processing Messages with FastStream\nDESCRIPTION: This code snippet demonstrates how to establish a connection to Kafka using FastStream's KafkaBroker module. It initializes a KafkaBroker instance, defines a processing function, and decorates it for subscribing to and publishing messages on Kafka topics.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\n\n@broker.subscriber(\"in-topic\")\n@broker.publisher(\"out-topic\")\nasync def on_message(body: str):\n    return f\"Processed: {body}\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Liveness and Readiness Probes in FastStream (Python)\nDESCRIPTION: This Python script demonstrates how to implement liveness and readiness probes in a FastStream application. It includes connections to Redis, RabbitMQ, and Postgres, with separate endpoints for liveness and readiness checks.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/healthcheks.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport logging\nfrom typing import Awaitable, Callable, Any\n\nimport asyncpg\nimport redis.asyncio as redis\nimport uvicorn\nfrom faststream import FastStream\nfrom faststream.asgi import AsgiResponse, get\nfrom faststream.rabbit import RabbitBroker\n\n\n@get\nasync def liveness(scope: dict[str, Any]) -> AsgiResponse:\n    return AsgiResponse(b\"\", status_code=204)\n\n\ndef readiness(\n    broker: RabbitBroker,\n    redis_connection: redis.Redis,\n    postgres_connection: asyncpg.Pool,\n) -> Callable[[dict[str, Any]], Awaitable[AsgiResponse]]:\n    healthy_response = AsgiResponse(b\"\", 204)\n    unhealthy_response = AsgiResponse(b\"\", 500)\n\n    @get\n    async def func(scope: dict[str, Any]) -> AsgiResponse:\n        try:\n            await redis_connection.ping()\n        except (redis.ConnectionError, Exception):\n            logging.exception(\"Redis not ready\")\n            return unhealthy_response\n\n        try:\n            await broker.ping(timeout=5.0)\n        except Exception:\n            logging.exception(\"RabbitMQ not ready\")\n            return unhealthy_response\n\n        try:\n            await postgres_connection.fetchval(\"SELECT 1\")\n        except (asyncpg.exceptions.PostgresConnectionError, Exception):\n            logging.exception(\"Postgres not ready\")\n            return unhealthy_response\n\n        return healthy_response\n\n    return func\n\n\nasync def main() -> None:\n    redis_connection = redis.Redis(host=\"redis\", port=6379)\n\n    postgres_connection = await asyncpg.create_pool(\n        \"postgresql://user:password@postgres/postgres\"\n    )\n\n    broker = RabbitBroker(\"amqp://guest:guest@rabbitmq:5672/\")\n    app = FastStream(broker)\n\n    asgi_routes = [\n        (\"/internal/alive\", liveness),\n        (\"/internal/ready\", readiness(broker, redis_connection, postgres_connection)),\n    ]\n\n    uvicorn_config = uvicorn.Config(\n        app.as_asgi(asgi_routes),\n        host=\"0.0.0.0\",\n        port=8000,\n    )\n    server = uvicorn.Server(uvicorn_config)\n    await server.serve()\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages to Topic Exchange in Python\nDESCRIPTION: This snippet shows how to publish messages to a Topic Exchange with different routing keys. It demonstrates the use of broker.publish() method to send messages that will be routed to specific consumers based on the routing patterns.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/topic.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\"Message 1\", exchange=\"exchange\", routing_key=\"test.info\")\nawait broker.publish(\"Message 2\", exchange=\"exchange\", routing_key=\"test.info\")\nawait broker.publish(\"Message 3\", exchange=\"exchange\", routing_key=\"test.info\")\nawait broker.publish(\"Message 4\", exchange=\"exchange\", routing_key=\"test.debug\")\n```\n\n----------------------------------------\n\nTITLE: Complete FastStream Application with Batch Kafka Subscriber\nDESCRIPTION: This snippet presents a complete FastStream application that demonstrates batch consumption of messages from a Kafka topic. It includes the necessary imports, broker configuration, and the implementation of a batch subscriber.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/batch_subscriber.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\nfrom faststream.utils import simple_pdb\nfrom faststream.kafka.message import Message\n\n\nbroker = KafkaBroker(\n    \"localhost:9092\",\n)\napp = FastStream(broker)\nlogger = Logger()\n\n\n@broker.subscriber(\"test_batch\", batch=True)\nasync def on_messages(msg: List[Message[str]]):\n    logger.info(f\"Received {len(msg)} messages\")\n    for m in msg:\n        logger.info(f\"Message: {m.content}\")\n\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(simple_pdb(app, logger=logger))\n```\n\n----------------------------------------\n\nTITLE: Defining FastStream Subscriber for Different Brokers\nDESCRIPTION: Examples of defining a FastStream subscriber for various message brokers including Kafka, Confluent, RabbitMQ, NATS, and Redis. The subscriber handles JSON messages with 'name' and 'user_id' fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/test.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-topic\")\nasync def handle(name: str, user_id: int, logger: Logger):\n    logger.info(f\"New user: {name} with id {user_id}\")\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-topic\")\nasync def handle(name: str, user_id: int, logger: Logger):\n    logger.info(f\"New user: {name} with id {user_id}\")\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-queue\")\nasync def handle(name: str, user_id: int, logger: Logger):\n    logger.info(f\"New user: {name} with id {user_id}\")\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-subject\")\nasync def handle(name: str, user_id: int, logger: Logger):\n    logger.info(f\"New user: {name} with id {user_id}\")\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-channel\")\nasync def handle(name: str, user_id: int, logger: Logger):\n    logger.info(f\"New user: {name} with id {user_id}\")\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream CLI\nDESCRIPTION: Command to install FastStream CLI for running FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_9\n\nLANGUAGE: console\nCODE:\n```\npip install \"faststream[cli]\"\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with FastAPI\nDESCRIPTION: This snippet demonstrates how to integrate a FastStream broker with FastAPI using lifecycle events. It initializes a Kafka broker and connects it during startup, then closes it during shutdown.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nimport uvicorn\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastAPI()\n\n@app.on_event(\"startup\")\nasync def startup():\n    await broker.start()\n\n@app.on_event(\"shutdown\")\nasync def shutdown():\n    await broker.close()\n\n\nif __name__ == \"__main__\":\n    uvicorn.run(\"integrations.http_frameworks_integrations.fastapi:app\")\n```\n\n----------------------------------------\n\nTITLE: FastStream with Pydantic Models for Message Validation\nDESCRIPTION: An example of using Pydantic BaseModel to define message structures in FastStream. This provides stronger typing, validation, and documentation through Pydantic's field definitions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field, PositiveInt\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\nclass User(BaseModel):\n    user: str = Field(..., examples=[\"John\"])\n    user_id: PositiveInt = Field(..., examples=[\"1\"])\n\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def handle_msg(data: User) -> str:\n    return f\"User: {data.user} - {data.user_id} registered\"\n```\n\n----------------------------------------\n\nTITLE: Binding RabbitMQ Queue to Exchange with FastStream\nDESCRIPTION: This code snippet shows how to bind a RabbitMQ queue to an exchange using FastStream's RabbitBroker. It demonstrates the process of creating a broker, declaring a queue and an exchange, and then binding them together using different routing keys.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/declare.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker, RabbitExchange, RabbitQueue\n\nbroker = RabbitBroker()\n\n\nasync def main():\n    async with broker:\n        # create a queue\n        queue = RabbitQueue(\"test-queue\")\n        # create an exchange\n        exchange = RabbitExchange(\"test-exchange\")\n\n        # declare queue\n        test_queue = await broker.declare_queue(queue)\n        # declare exchange\n        test_exchange = await broker.declare_exchange(exchange)\n\n        # bind queue to exchange\n        await test_queue.bind(test_exchange, routing_key=\"test.#\")\n        # bind queue to exchange with another routing key\n        await test_queue.bind(test_exchange, routing_key=\"demo.*\")\n\n        # bind queue to exchange with multiple routing keys\n        await test_queue.bind(\n            test_exchange,\n            routing_key=[\"test.#\", \"demo.*\", \"faststream\"]\n        )\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating a FastStream Kafka Application with Batch Publishing\nDESCRIPTION: This snippet demonstrates how to create a FastStream application that consumes messages from one Kafka topic and publishes batches to another. It includes the creation of a batch publisher and two methods of batch publishing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/batch_publisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input_data_1\")\nasync def base_handler(body: str, logger: Logger):\n    logger.info(f\"Got message: {body}\")\n    await process_data(body)\n\n\n@broker.publisher(\n    \"output_data\",\n    batch=True,\n)\nasync def process_data(body: str):\n    return body + \"_1\", body + \"_2\"\n\n\n@broker.subscriber(\"input_data_2\")\nasync def another_handler(body: str):\n    await process_data.publish(\n        body + \"_3\",\n        body + \"_4\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Confluent Kafka Topics with FastStream\nDESCRIPTION: Shows how to create a basic Confluent Kafka subscriber using FastStream's KafkaBroker. The subscriber function handles messages from a specified topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(\"test\")  # topic name\nasync def handle_msg(msg_body):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Complete FastStream Application with Publisher Decorator\nDESCRIPTION: A complete example of a FastStream application that consumes messages from one Kafka topic and publishes responses to another topic using the publisher decorator pattern.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/confluent/publish_example/app.py [ln:1-26] !}\n```\n\n----------------------------------------\n\nTITLE: Complete Kafka Consumer Application with FastStream\nDESCRIPTION: A complete example of a FastStream application that consumes HelloWorld messages from a Kafka topic named 'hello_world'. The code includes message structure definition, broker configuration, and a subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Subscriber/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/confluent/consumes_basics/app.py!}\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with FastAPI using AIOKafka StreamRouter\nDESCRIPTION: Using FastStream StreamRouter with FastAPI, allowing you to declare message handlers with subscriber and publisher decorators. FastStream integrates with FastAPI's dependency and serialization system, supporting Depends, BackgroundTasks, and other FastAPI tools.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom typing import Annotated\n\nfrom fastapi import FastAPI, Depends, BackgroundTasks\nfrom faststream.kafka.fastapi import KafkaRouter\n\n# Define FastAPI app\napp = FastAPI(title=\"My Service\")\n\n# Define StreamRouter\nkafka_router = KafkaRouter(\n    \"localhost:9092\",\n)\n\n# Define dependency\ndef get_user_id():\n    return \"user1\"\n\n# Define handler\n@kafka_router.subscriber(\"topic1\")\nasync def consume(\n    msg: dict,\n    tasks: BackgroundTasks,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> None:\n    tasks.add_task(print, f\"Processing message for {user_id}\")\n    await asyncio.sleep(1)\n    print(f\"Message processed: {msg}\")\n\n# Include StreamRouter in FastAPI\napp.include_router(kafka_router)\n```\n\n----------------------------------------\n\nTITLE: Implementing RabbitMQ Topic Exchange with FastStream in Python\nDESCRIPTION: This code snippet demonstrates how to set up a Topic Exchange in RabbitMQ using FastStream. It includes the declaration of the exchange, queue bindings with routing patterns, and multiple consumer handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/topic.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/topic.py !}\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Parser for Redis in FastStream\nDESCRIPTION: Defines a custom parser function for Redis messages in FastStream. It extracts a custom message_id from headers and creates a RedisMessage object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisMessage\nfrom faststream.redis.message import PubSubMessage\n\ndef parser(msg: PubSubMessage) -> RedisMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Accessing Raw Kafka Message in FastStream\nDESCRIPTION: Shows how to access the raw confluent_kafka.Message object within a FastStream Kafka subscriber function for advanced usage.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/message.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    msg: KafkaMessage,\n):\n    print(msg.raw_message.headers())\n```\n\n----------------------------------------\n\nTITLE: Implementing ML Model Loading with Lifespan Context Manager in FastStream\nDESCRIPTION: Shows how to use an async lifespan context manager to load a machine learning model at application startup and unload it at shutdown. The example demonstrates proper resource management across various message brokers like AIOKafka, Confluent, RabbitMQ, NATS, and Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/getting_started/lifespan/kafka/ml_context.py!}\n```\n\n----------------------------------------\n\nTITLE: Establishing Kafka Connection and Processing Messages with FastStream\nDESCRIPTION: This snippet demonstrates how to establish a connection to Kafka using FastStream's KafkaBroker module, define a message processing function, and set up subscribers and publishers for Kafka topics.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker=broker)\n\n@broker.subscriber(\"in_topic\")\n@broker.publisher(\"out-topic\")\nasync def on_message(msg: str, logger: Logger):\n    logger.info(f\"Got message: {msg}\")\n    return f\"Got: {msg}\"\n```\n\n----------------------------------------\n\nTITLE: Integrating AsyncAPI Documentation with FastStream's ASGI Support\nDESCRIPTION: Example of using FastStream's built-in ASGI support to serve both the application and AsyncAPI documentation on the same server.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/hosting.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber('topic')\nasync def my_handler(msg: str) -> None:\n    print(msg)\n\napp = FastStream(broker).as_asgi(\n    asyncapi_path=\"/docs/asyncapi\",\n)\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n```\n\n----------------------------------------\n\nTITLE: Using Annotated with Context in NATS\nDESCRIPTION: Shows how to use Python's Annotated feature with FastStream Context in NATS. This approach is similar to pytest fixtures, allowing for cleaner dependency injection with type hints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nfrom faststream import FastStream, Context, Logger\nfrom faststream.nats import NatsBroker\n\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n\n# inject application object from a Context\nLoggerDep = Annotated[Logger, Context()]\nBrokerDep = Annotated[NatsBroker, Context()]\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: BrokerDep,  # from context with annotation\n    logger: LoggerDep,  # from context with annotation\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Runtime Subscriber Registration in Python\nDESCRIPTION: Demonstrates how to dynamically register new subscribers during runtime with an already-started broker, including setup and lifecycle management.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nsubscriber = broker.subscriber(\"dynamic\")\nsubscriber(handler_method)\n...\nbroker.setup_subscriber(subscriber)\nawait subscriber.start()\n...\nawait subscriber.close()\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Basic KafkaBroker Method\nDESCRIPTION: Demonstrates how to publish messages to a Kafka topic using the basic publish method of the KafkaBroker instance, showing how to send different message types including strings, dictionaries, and Pydantic models.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/raw_publish/example.py [ln:25.9,26.7,27.9,28.9,29.9,30.9] !}\n```\n\n----------------------------------------\n\nTITLE: Pattern-based Redis Channel Subscription in FastStream\nDESCRIPTION: This snippet shows how to implement a pattern-based Redis channel subscription using FastStream. It uses the PubSub class to define a pattern subscription and create a message handler for matching channels.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/subscription.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker, PubSub\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(channel=PubSub(\"test.*\", pattern=True))\nasync def on_message(msg: str, logger):\n    logger.info(f\"Received: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Different Broker Support\nDESCRIPTION: Commands to install FastStream with support for different message brokers including Kafka, RabbitMQ, NATS, and Redis using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install faststream[kafka]\n# or\npip install faststream[rabbit]\n# or\npip install faststream[nats]\n# or\npip install faststream[redis]\n```\n\n----------------------------------------\n\nTITLE: Connecting and Processing Messages with Redis using FastStream\nDESCRIPTION: This code snippet demonstrates how to establish a connection to Redis using FastStream's RedisBroker, subscribe to an input channel, process messages, and publish results to an output channel. It includes error handling and logging setup.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom faststream import FastStream, Logger\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker(\"redis://localhost:6379\")\napp = FastStream(broker)\n\n@broker.subscriber(\"in-channel\")\n@broker.publisher(\"out-channel\")\nasync def on_message(msg: str) -> str:\n    return f\"Processed: {msg}\"\n\nif __name__ == \"__main__\":\n    asyncio.run(app.run())\n```\n\n----------------------------------------\n\nTITLE: Checking Configuration Parameter in FastStream NATS Subscriber\nDESCRIPTION: This code demonstrates how to retrieve a configuration parameter from the global context in a FastStream NATS subscriber. It uses the parameter to conditionally publish a message.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/nats/dynaconf.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Context\nfrom faststream.nats import NatsBroker, NatsMessage\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"order_service.order.filled.buy\")\nasync def handle_filled_buy(\n    message: NatsMessage,\n    create_sell: bool = Context(\"create_sell\"),\n):\n    if create_sell:\n        await broker.publish(b\"\", \"order_service.order.create.sell\")\n```\n\n----------------------------------------\n\nTITLE: Basic Dependency Injection in FastStream\nDESCRIPTION: Demonstrates how to implement basic dependency injection using the Depends class in FastStream for various message brokers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Depends\nfrom faststream.kafka import KafkaBroker\n\napp = FastStream()\nbroker = KafkaBroker()\n\ndef simple_dependency(a: int, b: int = 3) -> int:\n    return a + b\n\n@broker.subscriber(\"test\")\ndef method(a: int, d: int = Depends(simple_dependency)):\n    return a + d\n```\n\n----------------------------------------\n\nTITLE: Implementing Redis List Subscriber with FastStream\nDESCRIPTION: This snippet shows the complete implementation of a FastStream app that subscribes to a Redis list. It imports required modules, creates a RedisBroker, and defines a subscriber function to handle incoming messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/subscription.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-list\")\nasync def handle(msg: str):\n    print(f\"Received: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Complete Redis Stream Publishing Example with FastStream in Python\nDESCRIPTION: This is the full example demonstrating Redis Stream publishing using FastStream. It includes broker setup, data model definition, and a function for processing and publishing data.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/publishing.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom pydantic import BaseModel\n\n\nclass InputData(BaseModel):\n    field1: str\n    field2: int\n    field3: bool\n\n\nbroker = RedisBroker(\"redis://localhost:6379\")\napp = FastStream(broker)\n\n\n@broker.publisher(\"output-stream\")\n@broker.subscriber(\"input-stream\")\nasync def on_message(msg: InputData):\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Consuming RabbitMQ Stream with FastStream in Python\nDESCRIPTION: This code snippet demonstrates how to set up a FastStream application to consume messages from a RabbitMQ stream. It includes stream declaration, consumer setup with offset specification, and message handling.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/stream.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker(stream_max_length_bytes=10_000_000)\napp = FastStream(broker)\n\n\n@broker.subscriber(\n    \"some-stream\",\n    stream=True,\n    offset=\"next\",  # or `first`, `last`, or int\n)\nasync def on_message(msg: str, logger: Logger):\n    logger.info(f\"Received: {msg}\")\n\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Testing FastStream Services with AIOKafka\nDESCRIPTION: Testing a FastStream AIOKafka service using pytest and the TestBroker context manager, which puts the broker into 'testing mode' and redirects functions to InMemory brokers for testing without a running broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nimport asyncio\nimport pytest\nfrom faststream.kafka import TestKafkaBroker\n\nfrom basic import app, HandleMsg, publish\n\n\n@pytest.mark.asyncio\nasync def test_handle_msg():\n    async with TestKafkaBroker(app) as broker:\n        # Publish a message to the input topic\n        await broker.publish({\"message\": \"Hello World!\"}, \"input_data\")\n\n        # Check message has been processed correctly\n        call = broker.get_handler_call(HandleMsg, return_exceptions=True)\n        # or broker.get_by_topic(\"output_data\", return_exceptions=True)\n        assert call[0] == {\"message\": \"Hello World!\", \"processed\": True}\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with FastAPI using Redis StreamRouter\nDESCRIPTION: Using FastStream Redis StreamRouter with FastAPI, allowing you to declare message handlers with subscriber and publisher decorators. FastStream integrates with FastAPI's dependency and serialization system, supporting Depends, BackgroundTasks, and other FastAPI tools.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom typing import Annotated\n\nfrom fastapi import FastAPI, Depends, BackgroundTasks\nfrom faststream.redis.fastapi import RedisRouter\n\n# Define FastAPI app\napp = FastAPI(title=\"My Service\")\n\n# Define StreamRouter\nredis_router = RedisRouter(\n    \"redis://localhost:6379\",\n)\n\n# Define dependency\ndef get_user_id():\n    return \"user1\"\n\n# Define handler\n@redis_router.subscriber(\"topic1\")\nasync def consume(\n    msg: dict,\n    tasks: BackgroundTasks,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> None:\n    tasks.add_task(print, f\"Processing message for {user_id}\")\n    await asyncio.sleep(1)\n    print(f\"Message processed: {msg}\")\n\n# Include StreamRouter in FastAPI\napp.include_router(redis_router)\n```\n\n----------------------------------------\n\nTITLE: Implementing FastStream Kafka Consumer and Producer in Python\nDESCRIPTION: This code snippet creates a FastStream application that consumes messages from the 'input_data' Kafka topic, increments the 'data' value by 1, and produces new messages to the 'output_data' topic. It uses a localhost Kafka broker with the default port for testing purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs_src/index/app_description.txt#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n@broker.subscriber(\"input_data\")\n@broker.publisher(\"output_data\")\nasync def process_message(message: dict, logger: Logger):\n    message[\"data\"] += 1\n    logger.info(f\"Processed message: {message}\")\n    return message\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Key-Value Storage in FastStream with NATS\nDESCRIPTION: This snippet demonstrates how to create a Key-Value storage object in FastStream using NATS, and how to put a value into it. It uses the NatsBroker to create a key_value object for a specific bucket, then puts a string value into the storage.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/key-value.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\n\n@broker.on_startup\nasync def startup():\n    # highlight-next-line\n    key_value = await broker.key_value(bucket=\"bucket\")\n    # highlight-next-line\n    await key_value.put(\"key\", \"value\")\n```\n\n----------------------------------------\n\nTITLE: Using RPCWorker for Kafka RPC Requests in Python\nDESCRIPTION: This code snippet demonstrates how to use the RPCWorker class to send Kafka RPC requests and handle responses in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/rpc.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\nworker = RPCWorker(broker, reply_topic=\"responses\")\napp = FastStream(broker)\n\n@app.after_startup\nasync def send_request() -> None:\n    data = await worker.request(\"echo\", \"echo-topic\")\n    assert data == \"echo\"\n```\n\n----------------------------------------\n\nTITLE: Implementing a Basic FastStream Application in Python\nDESCRIPTION: This Python script demonstrates a FastStream application that consumes data from a topic, increments the value, and outputs to another topic. It uses the FastStream framework for stream processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/export.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input-topic\")\n@broker.publisher(\"output-topic\")\nasync def on_input(msg: int, logger: Logger) -> int:\n    logger.info(f\"Input: {msg}\")\n    result = msg + 1\n    logger.info(f\"Output: {result}\")\n    return result\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with AIOKafka in FastStream\nDESCRIPTION: This snippet demonstrates how to create and use a Publisher object with AIOKafka in FastStream. It shows the setup of the KafkaBroker and creation of a Publisher for the 'test' topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/direct.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"test\")\n\n@broker.subscriber(\"input\")\nasync def on_input(msg: str):\n    await publisher.publish(msg)\n```\n\n----------------------------------------\n\nTITLE: Creating a FastStream Kafka Application with Batch Publishing\nDESCRIPTION: This snippet demonstrates how to create a FastStream application that consumes from one Kafka topic and publishes batches to another. It includes the setup of the Kafka broker, defining a batch publisher, and implementing message processing functions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/batch_publisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\n\n@broker.subscriber(\"input_data_1\")\nasync def process_data(msg: str):\n    await output_data_batch(msg)\n\n@broker.publisher(\"output_data\", batch=True)\nasync def output_data_batch(msg: str, batch_size: int = 2):\n    return tuple([msg] * batch_size)\n\n@broker.subscriber(\"input_data_2\")\nasync def another_process(msg: str):\n    await output_data_batch.publish(\"msg1\", \"msg2\")\n\n@broker.subscriber(\"input_data_3\")\nasync def third_process(msg: str):\n    await broker.publish_batch(\"msg2\", \"msg2\", topic=\"output_data\")\n```\n\n----------------------------------------\n\nTITLE: Machine Learning Model Initialization with Lifecycle Hooks\nDESCRIPTION: Example showing how to initialize and properly clean up a machine learning model using startup and shutdown hooks in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/hooks.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@app.on_startup\nasync def setup_model():\n    model = MLModel()\n    await model.setup()\n    ContextRepo.get_context().add_global(model)\n    return broker\n\n@app.on_shutdown\nasync def close_model(model: MLModel = Context()):\n    await model.close()\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Kafka Subscriber with FastStream\nDESCRIPTION: This snippet demonstrates the full implementation of a basic Kafka subscriber using FastStream. It includes importing required modules, defining a message structure, creating a KafkaBroker, and setting up a consumer function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nfrom pydantic import BaseModel, Field\n\n\nclass HelloWorld(BaseModel):\n    name: str = Field(\n        ...,\n        examples=[\"John\", \"Mike\"],\n        description=\"User name\",\n    )\n\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"hello_world\")\nasync def on_hello_world(msg: HelloWorld):\n    print(f\"Got hello from: {msg.name}\")\n```\n\n----------------------------------------\n\nTITLE: Sending messages using the broker from FastAPI endpoints\nDESCRIPTION: Example of accessing the broker object from within a FastAPI endpoint to send messages to message queues. The broker object is accessible through the router instance.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/fastapi/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nfrom faststream.kafka.fastapi import KafkaRouter\n\nrouter = KafkaRouter(\"localhost:9092\")\napp = FastAPI(lifespan=router.lifespan_context)\napp.include_router(router)\n\n\n@app.get(\"/send\")\nasync def send():\n    await router.broker.publish(\"Hello World\", \"test_topic\")\n    return {\"message\": \"sent\"}\n```\n\n----------------------------------------\n\nTITLE: Implementing SSL/TLS Encryption with BaseSecurity in FastStream RabbitMQ\nDESCRIPTION: This code snippet demonstrates how to use the BaseSecurity object to enable SSL/TLS encryption when creating a RabbitMQ broker in FastStream. It includes setting up the SSL context and creating the broker with the security object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.security import BaseSecurity\nfrom faststream.rabbit import RabbitBroker\n\nssl_context = SSLContext(protocol=PROTOCOL_TLS_CLIENT)\nssl_context.load_verify_locations(\"path/to/ca_certificate.pem\")\n\nsecurity = BaseSecurity(ssl=ssl_context)\n\nbroker = RabbitBroker(\n    \"amqps://rmq.example.com:5671\",\n    security=security,\n)\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with RabbitBroker in Python\nDESCRIPTION: Demonstrates how to publish a message to a RabbitMQ queue using FastStream's RabbitBroker. The example shows asynchronous message publishing with queue and exchange specification.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/publishing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom faststream.rabbit import RabbitBroker\n\nasync def pub():\n    async with RabbitBroker() as broker:\n        await broker.publish(\n            \"Hi!\",\n            queue=\"test\",\n            exchange=\"test\"\n        )\n\nasyncio.run(pub())\n```\n\n----------------------------------------\n\nTITLE: Subscribing to NATS Subjects with FastStream\nDESCRIPTION: Demonstrates how to create a basic NATS subscriber using FastStream's NatsBroker. The subscriber function handles messages from a specified subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\n\n@broker.subscriber(\"test\")  # subject name\nasync def handle_msg(msg_body):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Applying Subscriber and Publisher Decorators\nDESCRIPTION: Shows how to connect a processing function to Kafka topics by decorating it with both subscriber and publisher decorators, creating a complete message processing pipeline.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/publish_example/app.py [ln:20-23] !}\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Litestar\nDESCRIPTION: Using FastStream MQBrokers with Litestar by starting and stopping them according to the application's lifespan, allowing for message broker interaction in a Litestar web application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom litestar import Litestar, get\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\n\n\n@broker.subscriber(\"input\")\nasync def handle(msg: str) -> None:\n    print(msg)\n\n\n@get(\"/\")\nasync def push() -> dict:\n    await broker.publish(\"Hello World!\", \"input\")\n    return {\"status\": \"sent\"}\n\n\nasync def on_startup() -> None:\n    # Startup the broker\n    await broker.start()\n\n\nasync def on_shutdown() -> None:\n    # Shutdown the broker\n    await broker.close()\n\n\napp = Litestar(\n    route_handlers=[push],\n    on_startup=[on_startup],\n    on_shutdown=[on_shutdown],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Publisher Object with RabbitMQ in Python\nDESCRIPTION: This example illustrates the use of the Publisher Object with RabbitMQ in FastStream. It initializes the broker, sets up a publisher, and defines a subscriber function that publishes messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/object.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"output\")\n\n@publisher\n@broker.subscriber(\"input\")\nasync def on_message(body: str, logger: Logger):\n    logger.info(f\"Got message: {body}\")\n    return f\"Processed: {body}\"\n```\n\n----------------------------------------\n\nTITLE: Adding Payload Information Using Pydantic Models in FastStream AsyncAPI\nDESCRIPTION: FastStream application using Pydantic models to define and document message payload structures. The models include descriptions and are used as argument types and return types in handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/getting_started/asyncapi/asyncapi_customization/payload_info.py !}\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Object Storage in FastStream with NATS\nDESCRIPTION: This snippet demonstrates how to create an Object Storage bucket, store a file in it, and retrieve the file content using FastStream with NATS. It uses BytesIO to emulate a file for reading.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/object.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom io import BytesIO\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\n\n@broker.subscriber(\"example-bucket\", obj_watch=True)\nasync def handler(filename: str):\n    assert filename == \"file.txt\"\n\nasync with NatsBroker() as broker:\n    object_storage = broker.object_storage(bucket=\"example-bucket\")\n    await object_storage.put(\"file.txt\", BytesIO(b\"Hello World!\"))\n```\n\n----------------------------------------\n\nTITLE: Implementing Reusable RPCWorker Class for Kafka in Python\nDESCRIPTION: This code snippet defines a reusable RPCWorker class for handling Kafka RPC requests. It encapsulates the logic for sending requests, handling responses, and managing correlation IDs.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/rpc.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom uuid import uuid4\nfrom asyncio import Future, wait_for\n\nfrom faststream.types import SendableMessage\nfrom faststream.kafka import KafkaMessage\n\nclass RPCWorker:\n    def __init__(self, broker: KafkaBroker, reply_topic: str) -> None:\n        self.responses: dict[str, Future[bytes]] = {}\n        self.broker = broker\n        self.reply_topic = reply_topic\n\n        self.subscriber = broker.subscriber(reply_topic)\n        self.subscriber(self._handle_responses)\n\n    def _handle_responses(self, msg: KafkaMessage) -> None:\n        \"\"\"Our replies subscriber.\"\"\"\n        if (future := self.responses.pop(msg.correlation_id, None)):\n            future.set_result(msg.body)\n\n    async def request(\n        self,\n        data: SendableMessage,\n        topic: str,\n        timeout: float = 10.0,\n    ) -> bytes:\n        correlation_id = str(uuid4())\n        future = self.responses[correlation_id] = Future[bytes]()\n\n        await broker.publish(\n            data, topic,\n            reply_to=self.reply_topic,\n            correlation_id=correlation_id,\n        )\n\n        try:\n            response: bytes = await wait_for(future, timeout=timeout)\n        except TimeoutError:\n            self.responses.pop(correlation_id, None)\n            raise\n        else:\n            return response\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with FastAPI for message handling\nDESCRIPTION: Example of integrating FastStream with FastAPI to handle messages from different brokers. The StreamRouter is used to declare message handlers and can also serve as an HTTP router for regular endpoints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/fastapi/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI, Depends\nfrom pydantic import BaseModel\n\nfrom faststream.kafka.fastapi import KafkaRouter\n\nrouter = KafkaRouter(\"localhost:9092\")\n\n\nclass Input(BaseModel):\n    message: str\n\n\ndef get_message_processor():\n    return \"processor\"\n\n\n@router.subscriber(\"test_topic\")\nasync def handle_message(\n    body: Input,\n    processor: str = Depends(get_message_processor),\n):\n    print(f\"Got message: {body.message} {processor}\")\n\n\napp = FastAPI(lifespan=router.lifespan_context)\n\n\n@router.get(\"/\")\nasync def main():\n    return {\"message\": \"Hello World\"}\n\n\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Accessing Django ORM from FastStream Consumer\nDESCRIPTION: Example script showing how to access Django ORM from within a FastStream consumer by properly initializing Django before using its models.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# serve_faststream.py\n# ruff: noqa: E402\n###############################################################################\nimport os\n\nimport django\n\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"app.settings\")\ndjango.setup()\n# These lines are necessary to set up Django, call them before any Django Related imports.\n###############################################################################\nfrom django.contrib.auth.models import User  # This line must be after django.setup()\n\nfrom faststream import FastStream\nfrom faststream.rabbit import RabbitBroker\n\n\nbroker = RabbitBroker(\"amqp://guest:guest@localhost:5672\")\n\n@broker.subscriber(\"demo\")\nasync def faststream_django_orm_demo_handler(message: str):\n    \"\"\"\n    This demonstrates how to access Django ORM from within a FastStream consumer.\n    \"\"\"\n    qs = User.objects.all()\n    async for user in qs:  # async django ORM is accessible\n        print(user)\n    print(message)\n\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Real Broker Testing in FastStream\nDESCRIPTION: Illustrates how to use TestClient for testing with a real broker environment in FastStream by using the 'with_real' parameter. This approach supports all testing features while using an unpatched broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/test.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pytest\nfrom faststream.kafka import TestKafkaBroker\n\n@pytest.mark.asyncio\nasync def test_handle():\n    async with TestKafkaBroker(broker, with_real=True) as client:\n        await client.publish(\n            {\"name\": \"John\", \"user_id\": 1},\n            \"test-topic\",\n        )\n        await handle.wait_call(1.0)\n\n    async with TestKafkaBroker(broker, with_real=True) as client:\n        with pytest.raises(ValueError):\n            await client.publish(\n                {\"name\": \"John\", \"user_id\": \"wrong\"},\n                \"test-topic\",\n            )\n            await handle.wait_call(1.0)\n```\n\n----------------------------------------\n\nTITLE: Using dependency injection to access broker objects in FastAPI\nDESCRIPTION: Example of creating a FastAPI dependency to access the broker object from different parts of the application. This allows for easy reuse of broker access across multiple endpoints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/fastapi/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI, Depends\n\nfrom faststream.kafka.fastapi import KafkaRouter\nfrom faststream.kafka import KafkaBroker\n\nrouter = KafkaRouter(\"localhost:9092\")\napp = FastAPI(lifespan=router.lifespan_context)\napp.include_router(router)\n\n\ndef get_broker():\n    return router.broker\n\n\n@app.get(\"/send\")\nasync def send(broker: KafkaBroker = Depends(get_broker)):\n    await broker.publish(\"Hello World\", \"test_topic\")\n    return {\"message\": \"sent\"}\n```\n\n----------------------------------------\n\nTITLE: FastStream Integration with FastAPI\nDESCRIPTION: Example of using FastStream as part of a FastAPI application using KafkaRouter\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nfrom faststream.kafka.fastapi import KafkaRouter\n\nrouter = KafkaRouter(\"localhost:9092\")\n\nclass Incoming(BaseModel):\n    m: dict\n\n@router.subscriber(\"test\")\n@router.publisher(\"response\")\nasync def hello(m: Incoming):\n    return {\"response\": \"Hello, world!\"}\n\napp = FastAPI()\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Basic FastStream Application with AIOKafka\nDESCRIPTION: A simple FastStream application using AIOKafka broker to consume and produce messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/kafka/basic.py!}\n```\n\n----------------------------------------\n\nTITLE: Implementing Reply-To Functionality in FastStream with NATS\nDESCRIPTION: This code shows how to set up a permanent request-reply data flow using NATS in FastStream. It defines a subscriber for response messages and demonstrates how to publish a message with a specified reply-to subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/rpc.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"response-subject\")\nasync def consume_responses(msg):\n    ...\n\nawait broker.publish(\n    \"Hi!\",\n    subject=\"test\",\n    reply_to=\"response-subject\",\n)\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Key-Value Changes with NATS in FastStream\nDESCRIPTION: This snippet shows how to subscribe to key-value changes in NATS using the KvWatch class. It updates the global context when a new value is received for the 'order_service' key.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/nats/dynaconf.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.nats import NatsBroker, KvWatch\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"create_sell\", kv_watch=KvWatch(\"order_service\"))\nasync def watch_kv_order_service(new_value: bool):\n    app.context.set_global(\"create_sell\", new_value)\n```\n\n----------------------------------------\n\nTITLE: Implementing Protobuf serialization in FastStream\nDESCRIPTION: This code snippet demonstrates how to use Protobuf serialization in a FastStream application, including message encoding and decoding.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, NoCast\nfrom faststream.nats import NatsMessage, NatsBroker\nfrom pydantic import BaseModel\n\nfrom message_pb2 import Person as ProtoPerson\n\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n\nclass ProtobufMsg(BaseModel):\n    body: NoCast[bytes]\n\n\nclass Person(BaseModel):\n    name: str\n    age: float\n\n\n@broker.subscriber(\"test\", response_model=ProtobufMsg)\nasync def on_message(msg: ProtobufMsg) -> Person:\n    proto_person = ProtoPerson()\n    proto_person.ParseFromString(msg.body)\n    return Person(name=proto_person.name, age=proto_person.age)\n\n\n@broker.publisher(\"test\")\nasync def publish(msg: Person) -> NatsMessage[ProtobufMsg]:\n    proto_person = ProtoPerson(name=msg.name, age=msg.age)\n    return NatsMessage(ProtobufMsg(body=proto_person.SerializeToString()))\n```\n\n----------------------------------------\n\nTITLE: Complete Example of Redis List Batch Subscriber in Python with FastStream\nDESCRIPTION: This comprehensive example illustrates the full implementation of a Redis List Batch Subscriber using FastStream. It includes the necessary imports, broker setup, subscriber definition, and the main execution logic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/batch.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom faststream.redis.annotations import ListSub\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(ListSub(\"test-list\", batch=True))\nasync def consume(msg: List[str]):\n    print(f\"Consumed batch: {msg}\")\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Complete Redis RPC Implementation with FastStream\nDESCRIPTION: This is the full example demonstrating how to set up Redis RPC with FastStream RedisBroker. It includes broker initialization, subscriber handlers, and the main function for sending RPC messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/rpc.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"channel\")\nasync def on_channel(msg: str) -> str:\n    return msg\n\n\n@broker.subscriber(\"list\")\nasync def on_list(msg: str) -> str:\n    return msg\n\n\n@broker.subscriber(\"stream\")\nasync def on_stream(msg: str) -> str:\n    return msg\n\n\n@app.on_startup\nasync def main():\n    async with broker:\n        msg = \"Hello Redis RPC!\"\n\n        channel_response = await broker.publish(\n            msg,\n            \"channel\",\n            rpc=True,\n            timeout=1,\n        )\n        assert channel_response == msg\n\n        list_response = await broker.publish(\n            msg,\n            \"list\",\n            rpc=True,\n            timeout=1,\n        )\n        assert list_response == msg\n\n        stream_response = await broker.publish(\n            msg,\n            \"stream\",\n            rpc=True,\n            timeout=1,\n        )\n        assert stream_response == msg\n```\n\n----------------------------------------\n\nTITLE: Manual Acknowledgement in Redis Stream Handler\nDESCRIPTION: Demonstrates how to manually acknowledge or not acknowledge a message in a Redis stream subscriber function using FastStream. It shows the usage of msg.ack() and msg.nack() methods.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/ack.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.annotations import RedisMessage, Redis\n\n# Setup broker and faststream app\n...\n\n@broker.subscriber(StreamSub(\"test-stream\", group=\"test-group\", consumer=\"1\"))\nasync def base_handler(body: dict, msg: RedisMessage, redis: Redis):\n    # Process the message\n    ...\n\n    # Manually acknowledge the message\n    await msg.ack(redis)\n    # or, if processing fails and you want to reprocess later\n    await msg.nack()\n```\n\n----------------------------------------\n\nTITLE: Implementing Publisher Object with NATS in Python\nDESCRIPTION: This code demonstrates how to use the Publisher Object with NATS in FastStream. It sets up the NATS broker, creates a publisher, and defines a subscriber function that publishes messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/object.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"output\")\n\n@publisher\n@broker.subscriber(\"input\")\nasync def on_message(body: str, logger: Logger):\n    logger.info(f\"Got message: {body}\")\n    return f\"Processed: {body}\"\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with AIOKafka Broker in Python\nDESCRIPTION: This code demonstrates how to publish messages using an AIOKafka broker in FastStream. It sets up a FastStream application, defines a startup event to publish a message, and includes a handler for processing messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/broker.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    await broker.publish(\n        {\"status\": \"Application started!\"},\n        topic=\"some-topic\",\n    )\n\n\n@broker.subscriber(\"some-topic\")\nasync def handler(msg: dict, logger: Logger):\n    logger.info(f\"Received: {msg}\")\n\n\n@app.after_startup\nasync def after_startup():\n    await broker.publish(\n        {\"status\": \"Application ready!\"},\n        topic=\"some-topic\",\n    )\n```\n\n----------------------------------------\n\nTITLE: In-Memory Testing with TestClient in FastStream\nDESCRIPTION: Demonstrates how to use TestClient for in-memory testing of FastStream subscribers. This approach allows testing without external dependencies and routes messages in-memory.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/test.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pytest\nfrom faststream.kafka import TestKafkaBroker\n\n@pytest.mark.asyncio\nasync def test_handle():\n    async with TestKafkaBroker(broker) as client:\n        await client.publish(\n            {\"name\": \"John\", \"user_id\": 1},\n            \"test-topic\",\n        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Message Consumption Function with Pydantic Models\nDESCRIPTION: A complete example showing batch consumption from a Kafka topic using Pydantic models for message validation and type safety.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Subscriber/batch_subscriber.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom faststream import FastStream\nfrom faststream.confluent import KafkaBroker\nfrom pydantic import BaseModel, Field\n\n\nclass MyModel(BaseModel):\n    number: int = Field(..., examples=[1])\n    text: str = Field(..., examples=[\"test\"])\n\n\n# Initialize broker and application\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n# Batch subscriber\n@broker.subscriber(\"test_batch\", batch=True)\nasync def consume(msgs: list[MyModel]):\n    return msgs\n```\n\n----------------------------------------\n\nTITLE: Importing and Creating Broker Router in FastStream\nDESCRIPTION: This snippet demonstrates how to import and create a Broker Router in FastStream for different message brokers (AIOKafka, Confluent, RabbitMQ, NATS, Redis). It shows the basic setup with a prefix applied to all subscribers and publishers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/routers/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker, KafkaRouter\n\napp = KafkaBroker()\nrouter = KafkaRouter(\"prefix_\")\n\n@router.subscriber(\"test\")\nasync def base_handler(msg: str) -> None:\n    print(msg)\n\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Creating Pydantic Models for User Data in FastStream\nDESCRIPTION: This code defines Pydantic models for handling user data validation and serialization. It includes a base UserBase model with common fields, a UserCreate model for creating users, and a User model for returning user information including the id.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Pydantic models\nclass UserBase(BaseModel):\n    name: str\n    email: str\n\n\nclass UserCreate(UserBase):\n    pass\n\n\nclass User(UserBase):\n    id: int\n    registered_at: datetime\n\n    class Config:\n        from_attributes = True\n```\n\n----------------------------------------\n\nTITLE: Full NATS Direct Subject Example with FastStream\nDESCRIPTION: Provides a complete example of using Direct Subjects in NATS with FastStream. It includes setting up the broker, declaring handlers, and publishing messages to different subjects.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/examples/direct.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.handler(\"test-subj-1\", \"group-1\")\nasync def handler1(body: str):\n    print(f\"handler1 got: {body}\")\n\n@broker.handler(\"test-subj-1\", \"group-1\")\nasync def handler2(body: str):\n    print(f\"handler2 got: {body}\")\n\n@broker.handler(\"test-subj-2\", \"group-1\")\nasync def handler3(body: str):\n    print(f\"handler3 got: {body}\")\n\n@app.on_startup\nasync def setup():\n    await broker.publish(\"1\", \"test-subj-1\")\n    await broker.publish(\"2\", \"test-subj-1\")\n    await broker.publish(\"3\", \"test-subj-2\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Redis Publishing with Decorators\nDESCRIPTION: Use decorators to define a data pipeline that processes incoming messages and publishes results to another channel. This example demonstrates how to create a publisher object and use it as a decorator.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/publishing.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker(\"redis://localhost:6379\")\napp = FastStream(broker)\n\npublisher = broker.publisher(\"output_data\")\n\n@broker.subscriber(\"input_data\")\n@publisher\ndef process_data(data: str) -> str:\n    return f\"Processed: {data}\"\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Using Annotated with Context in RabbitMQ\nDESCRIPTION: Shows how to use Python's Annotated feature with FastStream Context in RabbitMQ. This approach is similar to pytest fixtures, allowing for cleaner dependency injection with type hints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nfrom faststream import FastStream, Context, Logger\nfrom faststream.rabbit import RabbitBroker\n\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\n\n# inject application object from a Context\nLoggerDep = Annotated[Logger, Context()]\nBrokerDep = Annotated[RabbitBroker, Context()]\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: BrokerDep,  # from context with annotation\n    logger: LoggerDep,  # from context with annotation\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Accessing Full Redis Message in FastStream Python\nDESCRIPTION: This snippet demonstrates how to access the full Redis message, including headers, using the RedisMessage object in a FastStream subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisMessage\n\n@broker.subscriber(\"test-stream\")\nasync def stream_handler(msg: str, message: RedisMessage):\n    print(message.headers)\n```\n\n----------------------------------------\n\nTITLE: Accessing Full Kafka Message in FastStream Python\nDESCRIPTION: This snippet demonstrates how to access the full Kafka message object, including headers and other metadata, using the FastStream Context in a subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    msg: KafkaMessage,\n):\n    print(msg.headers)\n```\n\n----------------------------------------\n\nTITLE: Accessing Raw Message Fields with Context in FastStream Python\nDESCRIPTION: This snippet shows how to use the Context object to access fields directly from the raw message in a FastStream subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/message.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    cor_id: str = Context(\"message.raw_message.correlation_id\"),\n):\n    print(cor_id)\n```\n\n----------------------------------------\n\nTITLE: Implementing RabbitMQ Fanout Exchange in Python\nDESCRIPTION: This code snippet demonstrates how to set up a Fanout Exchange in RabbitMQ using Python. It includes the creation of the exchange, queue declarations, consumer subscriptions, and message publishing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/fanout.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/fanout.py !}\n```\n\n----------------------------------------\n\nTITLE: Implementing Async Context Manager Middlewares in Python\nDESCRIPTION: Shows the new required format for subscriber and publisher middlewares as async context managers, enabling exception handling and message modification capabilities.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nasync def subscriber_middleware(call_next, msg):\n    return await call_next(msg)\n\nasync def publisher_middleware(call_next, msg, **kwargs):\n    return await call_next(msg, **kwargs)\n\n@broker.subscriber(\n    \"in\",\n    middlewares=(subscriber_middleware,),\n)\n@broker.publisher(\n    \"out\",\n    middlewares=(publisher_middleware,),\n)\nasync def handler(msg):\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Multiple Subscriptions with FastStream\nDESCRIPTION: Demonstrates how to subscribe to multiple event streams using a single function in FastStream. The function is decorated with multiple @broker.subscriber(...) decorators.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"first_sub\")\n@broker.subscriber(\"second_sub\")\nasync def handler(msg):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Using Dependencies in FastStream\nDESCRIPTION: Example of using FastStream's dependency management system, which is similar to pytest fixtures and FastAPI Depends. Function arguments declare dependencies, and a special decorator delivers them from the global Context object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Depends, ContextRepo\n\n\ndef get_name() -> str:\n    return \"John\"\n\n\ndef greet(name: str = Depends(get_name)) -> str:\n    return f\"Hello, {name}!\"\n\n\ndef hello(greeting: str = Depends(greet)):\n    print(greeting)\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Fields in AIOKafka\nDESCRIPTION: Demonstrates how to access existing context fields like broker, context, logger, and message in AIOKafka implementations. The highlighted lines show the import statement and the function that uses these context fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\n# ...\n\n# ...\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: KafkaBroker,  # access to the broker\n    context,  # access to the context\n    logger,  # access to the logger\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n```\n\n----------------------------------------\n\nTITLE: Manual Acknowledgement of RabbitMQ Messages in FastStream (Python)\nDESCRIPTION: This code snippet shows how to manually acknowledge, nack, or reject a RabbitMQ message in FastStream by accessing the message object directly through the Context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/ack.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit.annotations import RabbitMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(body: str, msg: RabbitMessage):\n    await msg.ack()\n    # or\n    await msg.nack()\n    # or\n    await msg.reject()\n```\n\n----------------------------------------\n\nTITLE: Sending Blocking RPC Request with RabbitMQ in Python using FastStream\nDESCRIPTION: This snippet demonstrates how to send a blocking RPC request over RabbitMQ using FastStream. It utilizes the Direct Reply-To feature, allowing for synchronous response handling without creating separate queues.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/rpc.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitMessage\n\nmsg: RabbitMessage = await broker.request(\n    \"Hi!\",\n    queue=\"test\",\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL/TLS Encryption with BaseSecurity in FastStream (Python)\nDESCRIPTION: Demonstrates how to use the BaseSecurity object to enable SSL/TLS encryption for secure communication between FastStream services and Kafka brokers. It shows the creation of an SSLContext and its application to a KafkaBroker instance.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.security import BaseSecurity\nfrom faststream.kafka import KafkaBroker\n\nssl_context = ssl.create_default_context()\n\nbroker = KafkaBroker(\n    \"localhost:9092\",\n    security=BaseSecurity(ssl_context)\n)\n```\n\n----------------------------------------\n\nTITLE: Announcing RabbitMQ Header Exchange and Queues in Python\nDESCRIPTION: This code snippet shows how to declare a Header Exchange and multiple queues with different header matching arguments. It demonstrates the use of 'x-match' for whole or partial header matching.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/headers.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:7-23] !}\n```\n\n----------------------------------------\n\nTITLE: Testing Event Hooks with NATS in FastStream\nDESCRIPTION: This snippet demonstrates how to test lifespan hooks in a FastStream application using NATS broker. It shows the implementation of the TestApp context manager to verify startup and shutdown event handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/test.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.nats import NatsBroker\nfrom faststream.nats.testing import TestApp\n\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    print(\"started\")\n\n\n@app.on_shutdown\nasync def shutdown():\n    print(\"shutdown\")\n\n\nasync with TestApp(app):\n    # test that application started and `startup()` was called\n    pass\n# test that `shutdown()` was called\n```\n\n----------------------------------------\n\nTITLE: Testing Publisher with TestBroker for AIOKafka in Python\nDESCRIPTION: This code snippet shows how to test a Publisher using TestBroker for AIOKafka. It patches the broker with TestKafkaBroker, creates a test client, and asserts that the publish function was called with the correct message.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/test.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import TestKafkaBroker\n\nfrom your_module import app, publish\n\ndef test_publish():\n    with TestKafkaBroker(app):\n        client = app.test_client()\n        client.publish(publish, \"Hi!\")\n        publish.mock.assert_called_once_with(\"Hi!\")\n```\n\n----------------------------------------\n\nTITLE: Kubernetes Deployment with Liveness and Readiness Probes\nDESCRIPTION: This Kubernetes deployment YAML file defines a deployment for the FastStream application, including liveness and readiness probes that use the implemented healthcheck endpoints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/healthcheks.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dummy-app\n  labels:\n    app: dummy-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dummy-app\n  template:\n    metadata:\n      labels:\n        app: dummy-app\n    spec:\n      containers:\n        - name: dummy-app\n          image: \"dummy-app:latest\"\n          command: [\"/bin/sh\", \"-c\", 'python3 main.py']\n          ports:\n            - containerPort: 8000\n          livenessProbe:\n            httpGet:\n              path: /internal/alive\n              port: 8000\n            initialDelaySeconds: 5\n            periodSeconds: 20\n          readinessProbe:\n            httpGet:\n              path: /internal/ready\n              port: 8000\n            periodSeconds: 60\n```\n\n----------------------------------------\n\nTITLE: Implementing Publisher Object with AIOKafka in Python\nDESCRIPTION: This code snippet demonstrates how to use the Publisher Object with AIOKafka in FastStream. It includes broker initialization, publisher creation, and a subscriber function that publishes messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/object.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"output\")\n\n@publisher\n@broker.subscriber(\"input\")\nasync def on_message(body: str, logger: Logger):\n    logger.info(f\"Got message: {body}\")\n    return f\"Processed: {body}\"\n```\n\n----------------------------------------\n\nTITLE: Implementing a Kafka Topic Subscriber Function\nDESCRIPTION: Shows how to create a function that consumes messages from a Kafka topic using the @broker.subscriber decorator. The function receives and processes HelloWorld messages from the 'hello_world' topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Subscriber/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/confluent/consumes_basics/app.py [ln:19-21] !}\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with NatsBroker in Python\nDESCRIPTION: This code snippet demonstrates how to publish a message using FastStream's NatsBroker. It creates an asynchronous function that initializes a NatsBroker and publishes a message to a specified subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/publishing/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom faststream.nats import NatsBroker\n\nasync def pub():\n    async with NatsBroker() as broker:\n        await broker.publish(\n            \"Hi!\",\n            subject=\"test\",\n        )\n\nasyncio.run(pub())\n```\n\n----------------------------------------\n\nTITLE: Configuring Retry Logic for RabbitMQ Subscriber in FastStream (Python)\nDESCRIPTION: This snippet demonstrates how to set up retry logic for a RabbitMQ subscriber in FastStream. It shows three different configurations: no retries, infinite retries, and limited retries.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/ack.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\", retry=False) # don't handle exceptions\nasync def base_handler(body: str):\n    ...\n```\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\", retry=True)  # try again indefinitely\nasync def base_handler(body: str):\n    ...\n```\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\", retry=3)     # make up to 3 attempts\nasync def base_handler(body: str):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Testing Event Hooks with Confluent Kafka in FastStream\nDESCRIPTION: This snippet demonstrates how to test lifespan hooks in a FastStream application using Confluent Kafka broker. It shows how to use the TestApp context manager to trigger startup and shutdown events in tests.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/test.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.confluent import ConfluentKafkaBroker\nfrom faststream.confluent.testing import TestApp\n\n\nbroker = ConfluentKafkaBroker()\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    print(\"started\")\n\n\n@app.on_shutdown\nasync def shutdown():\n    print(\"shutdown\")\n\n\nasync with TestApp(app):\n    # test that application started and `startup()` was called\n    pass\n# test that `shutdown()` was called\n```\n\n----------------------------------------\n\nTITLE: Interrupting Message Processing in NATS Subscriber (Python)\nDESCRIPTION: This example demonstrates how to interrupt message processing at any point in the call stack by raising custom exceptions. It shows the use of AckMessage, NackMessage, and RejectMessage exceptions to control message acknowledgement.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/ack.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, NatsBroker\nfrom faststream.nats import NatsRouter\nfrom faststream.exceptions import AckMessage\n\nrouter = NatsRouter()\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@router.subscriber(\"test\")\nasync def handle(msg: str):\n    raise AckMessage()\n\n@app.on_startup\nclass TestPublisher:\n    def __init__(self) -> None:\n        raise AckMessage()\n\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Implementing SCRAM512 Authentication with SSL/TLS in FastStream\nDESCRIPTION: Shows how to configure SASL SCRAM-SHA-512 authentication mechanism with username, password, and optional SSL context for Kafka connections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/security.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.security import SASLScram512\nimport ssl\n\nssl_context = ssl.create_default_context()\nsecurity = SASLScram512(\n    username=\"admin\",\n    password=\"password\",\n    ssl_ctx=ssl_context,\n)\n\nbroker = KafkaBroker(\"localhost:9092\", security=security)\n```\n\n----------------------------------------\n\nTITLE: Using pydantic.BaseModel for Reusable Message Schemas in FastStream\nDESCRIPTION: This snippet demonstrates how to create a reusable message schema using pydantic.BaseModel in FastStream. It shows how to define a model and use it as a single message annotation across different subscribers and publishers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/pydantic.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass TestMessage(BaseModel):\n    msg: str\n    num: int = Field(42, title=\"Number\", description=\"Some number\")\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test_topic\")\nasync def on_message(\n    msg: TestMessage,\n    logger: Logger,\n):\n    logger.info(f\"Num: {msg.num}. Msg: {msg.msg}\")\n\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Creating Database Tables Asynchronously on Startup in FastStream\nDESCRIPTION: This function creates all database tables defined in the SQLAlchemy models when the application starts. It's registered as a startup event in FastAPI to ensure the database schema is ready before handling requests.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@app.on_event(\"startup\")\nasync def startup():\n    async with async_engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n```\n\n----------------------------------------\n\nTITLE: Integrating NatsRouter with FastAPI in FastStream\nDESCRIPTION: This code includes the NatsRouter in the FastAPI application, which enables the FastStream NATS integration with the FastAPI framework. It allows the application to handle NATS messages through the defined router.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Defining Subscriber Handlers for Redis Data Types\nDESCRIPTION: This code defines subscriber handlers for various Redis data types (channel, list, stream) that process incoming messages and return responses.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/rpc.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"channel\")\nasync def on_channel(msg: str) -> str:\n    return msg\n\n@broker.subscriber(\"list\")\nasync def on_list(msg: str) -> str:\n    return msg\n\n@broker.subscriber(\"stream\")\nasync def on_stream(msg: str) -> str:\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Parser for NATS in FastStream\nDESCRIPTION: Defines a custom parser function for NATS messages in FastStream. It extracts a custom message_id from headers and creates a NatsMessage object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom nats.aio.msg import Msg\nfrom faststream.nats import NatsMessage\n\ndef parser(msg: Msg) -> NatsMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Subscriber Middleware in FastStream\nDESCRIPTION: Code showing how to implement a subscriber middleware that intercepts messages before they reach handler functions. This middleware can modify the message content or handle exceptions from subscribers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Callable, Awaitable\n\nfrom faststream import BaseMiddleware\nfrom faststream.broker.message import StreamMessage\n\nclass MyMiddleware(BaseMiddleware):\n    async def consume_scope(\n        self,\n        call_next: Callable[[Any], Awaitable[Any]],\n        msg: StreamMessage[Any],\n    ) -> Any:\n        return await call_next(msg)\n\n\nBroker(middlewares=[MyMiddleware])\n```\n\n----------------------------------------\n\nTITLE: Subscribing Multiple Consumers to Direct Exchange in FastStream\nDESCRIPTION: This code demonstrates how to subscribe multiple consumers to a Direct Exchange using FastStream. It shows three handlers subscribed to different queues of the same exchange.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/direct.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test-q-1\", \"exchange\")\nasync def handler1(body: str):\n    print(f\"handler1 got {body}\")\n\n@broker.subscriber(\"test-q-1\", \"exchange\")\nasync def handler2(body: str):\n    print(f\"handler2 got {body}\")\n\n@broker.subscriber(\"test-q-2\", \"exchange\")\nasync def handler3(body: str):\n    print(f\"handler3 got {body}\")\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Objects by Name in Redis\nDESCRIPTION: This snippet shows how to access context objects by name in FastStream using Redis. It demonstrates retrieving the entire message object, accessing a specific field, and getting a dictionary key from the context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/fields.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisMessage\nfrom faststream import FastStream, Context, Logger\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def on_message(\n    msg: str,\n    message: RedisMessage = Context(),\n    logger: Logger = Context(),\n    channel: str = Context(\"message.channel\"),\n):\n    logger.info(f\"New message in channel: {channel}\")\n    return msg.upper()\n```\n\nLANGUAGE: python\nCODE:\n```\nmessage: RedisMessage = Context()\n```\n\n----------------------------------------\n\nTITLE: Initializing RedisBroker for Basic Redis Channel Publishing\nDESCRIPTION: Create a RedisBroker instance for publishing messages to Redis channels. This setup allows for direct message publishing using Python primitives or pydantic.BaseModel.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/publishing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nbroker = RedisBroker(\"redis://localhost:6379\")\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with NATS in Python\nDESCRIPTION: Demonstration of publishing a message to a NATS subject using FastStream. The NatsBroker is used as an async context manager for connection management.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nasync with NatsBroker() as br:\n    await br.publish(\"message\", \"subject\")\n```\n\n----------------------------------------\n\nTITLE: Using Settings Object in FastStream Application\nDESCRIPTION: Demonstrates how to use the settings object in a FastStream application. It imports the settings and uses its values in the application setup and handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.rabbit import RabbitBroker\nfrom .config import settings\n\n\nbroker = RabbitBroker(\"amqp://guest:guest@localhost:5672\")\napp = FastStream(broker=broker)\n\n\n@app.get(\"/{settings.app_name}\")\nasync def root() -> str:\n    return f\"Hello from {settings.app_name}\"\n\n\n@app.on_startup\ndef on_startup(logger: Logger) -> None:\n    logger.info(f\"Starting {settings.app_name}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL GSSAPI (Kerberos) Authentication with SSL/TLS in FastStream (Python)\nDESCRIPTION: Shows how to use the SASLGSSAPI object for authentication using Kerberos. It includes SSL/TLS configuration for secure communication and demonstrates setting up Kerberos authentication parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/security.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.security import SASLGSSAPI\nfrom faststream.kafka import KafkaBroker\n\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\n\nbroker = KafkaBroker(\n    \"localhost:9092\",\n    security=SASLGSSAPI(\n        ssl_context=ssl_context,\n        kerberos_service_name=\"kafka\",\n        kerberos_domain_name=\"example.com\",\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream with Prometheus Metrics\nDESCRIPTION: Example of setting up FastStream with Prometheus metrics collection and ASGI endpoint integration. Shows broker configuration with PrometheusMiddleware and metrics endpoint setup.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom prometheus_client import CollectorRegistry, make_asgi_app\nfrom faststream.asgi import AsgiFastStream\nfrom faststream.nats import NatsBroker\nfrom faststream.nats.prometheus import NatsPrometheusMiddleware\n\nregistry = CollectorRegistry()\n\nbroker = NatsBroker(\n    middlewares=(\n        NatsPrometheusMiddleware(registry=registry),\n    )\n)\n\napp = AsgiFastStream(\n    broker,\n    asgi_routes=[\n        (\"/metrics\", make_asgi_app(registry)),\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring At-Least-Once Consumption Strategy in FastStream\nDESCRIPTION: This snippet demonstrates how to set up a Kafka consumer with a group ID and disable auto-commit for at-least-once message processing strategy.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/ack.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\n    \"test\", group_id=\"group\", auto_commit=False\n)\nasync def base_handler(body: str):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Using multiple routers with FastStream and FastAPI\nDESCRIPTION: Example of using multiple routers with FastStream and FastAPI. Regular FastStream routers can be included in the FastAPI integration router, allowing for separation of message processing logic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/fastapi/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom faststream.kafka import KafkaRouter as KafkaStreamRouter\nfrom faststream.kafka.fastapi import KafkaRouter\n\napp = FastAPI()\n\nstream_router = KafkaStreamRouter()\n\n\n@stream_router.subscriber(\"test_topic1\")\nasync def handle1(msg: str):\n    print(f\"First router: {msg}\")\n\n\nfastapi_router = KafkaRouter(\"localhost:9092\", include=[stream_router])\napp.include_router(fastapi_router)\n\n\n@fastapi_router.subscriber(\"test_topic2\")\nasync def handle2(msg: str):\n    print(f\"Second router: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Kafka Consumer Function with Decorator\nDESCRIPTION: This code shows how to create a consumer function that processes messages from a Kafka topic. It uses the @broker.subscriber decorator to specify the topic and automatically parse incoming messages into the HelloWorld type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"hello_world\")\nasync def on_hello_world(msg: HelloWorld):\n    print(f\"Got hello from: {msg.name}\")\n```\n\n----------------------------------------\n\nTITLE: Defining Processing Logic with Publisher Decorator in Python\nDESCRIPTION: Creates a function that consumes incoming messages and produces a response to a defined topic. This function is decorated with both subscriber and publisher decorators.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef on_message(msg: InputModel) -> OutputModel:\n    return OutputModel(result=msg.content)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Parser for RabbitMQ in FastStream\nDESCRIPTION: Defines a custom parser function for RabbitMQ messages in FastStream. It extracts a custom message_id from headers and creates a RabbitMessage object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom aio_pika import IncomingMessage\nfrom faststream.rabbit import RabbitMessage\n\ndef parser(msg: IncomingMessage) -> RabbitMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Defining Batch Subscriber in FastStream for Kafka\nDESCRIPTION: This snippet shows how to define a subscriber that consumes messages in batches from a Kafka topic. It uses the @broker.subscriber decorator with the batch parameter set to True.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/batch_subscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test_batch\", batch=True)\nasync def on_messages(msg: List[Message[str]]):\n```\n\n----------------------------------------\n\nTITLE: Creating Subscriber-Specific Middleware in FastStream\nDESCRIPTION: Example of creating and applying middleware to a specific subscriber rather than globally. This allows for targeted message interception for individual handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync def subscriber_middleware(\n    call_next: Callable[[Any], Awaitable[Any]],\n    msg: StreamMessage[Any],\n) -> Any:\n    return await call_next(msg)\n\n\n@broker.subscriber(\n    ...,\n    middlewares=[subscriber_middleware],\n)\nasync def handler():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Implementing SSL/TLS Encryption with BaseSecurity Object in FastStream\nDESCRIPTION: Demonstrates how to create a BaseSecurity object using an SSL context for secure communication between FastStream and Kafka brokers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.security import BaseSecurity\nimport ssl\n\nssl_context = ssl.create_default_context()\nbroker = KafkaBroker(\"localhost:9092\", security=BaseSecurity(ssl_ctx=ssl_context))\n```\n\n----------------------------------------\n\nTITLE: Subscribing to RabbitMQ Queues with FastStream\nDESCRIPTION: Illustrates how to create a basic RabbitMQ subscriber using FastStream's RabbitBroker. The subscriber function handles messages from a specified queue.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker()\n\n@broker.subscriber(\"test\")  # queue name\nasync def handle_msg(msg_body):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Processing Middleware in FastStream\nDESCRIPTION: Example of creating a message processing middleware by extending BaseMiddleware and implementing on_receive and after_processed methods. This middleware can be used at the broker level to intercept messages during processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import BaseMiddleware\n\nclass MyMiddleware(BaseMiddleware):\n    async def on_receive(self):\n        print(f\"Received: {self.msg}\")\n        return await super().on_receive()\n\n    async def after_processed(self, exc_type, exc_val, exc_tb):\n        return await super().after_processed(exc_type, exc_val, exc_tb)\n```\n\n----------------------------------------\n\nTITLE: Accessing Raw Message Fields using Context in FastStream\nDESCRIPTION: This snippet shows how to access fields directly from the raw message using the Context feature in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/message.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    cor_id: str = Context(\"message.raw_message.correlation_id\"),\n):\n    print(cor_id)\n```\n\n----------------------------------------\n\nTITLE: Manual Acknowledgement of Kafka Messages in FastStream\nDESCRIPTION: This code shows how to manually acknowledge or not acknowledge (nack) a Kafka message using the message object obtained from the context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/ack.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.annotations import KafkaMessage\n\n\n@broker.subscriber(\n    \"test\", group_id=\"group\", auto_commit=False\n)\nasync def base_handler(body: str, msg: KafkaMessage):\n    await msg.ack()\n    # or\n    await msg.nack()\n```\n\n----------------------------------------\n\nTITLE: Configuring RabbitBroker with Custom Connection Parameters in Python\nDESCRIPTION: Example demonstrating how to merge RabbitMQ connection parameters by defining main connection data as a URL string while customizing it with additional kwargs.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_44\n\nLANGUAGE: python\nCODE:\n```\nbroker = RabbitBroker(\n    \"amqp://guest:guest@localhost:5672/\",\n    host=\"127.0.0.1\",\n)\n```\n\n----------------------------------------\n\nTITLE: Interrupting Message Processing in FastStream with RabbitMQ (Python)\nDESCRIPTION: This example demonstrates how to interrupt message processing at any point in the call stack by raising specific exceptions like AckMessage, NackMessage, or RejectMessage.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/ack.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.rabbit import RabbitBroker\nfrom faststream.exceptions import AckMessage\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test\")\nasync def handler(body: str):\n    if body == \"ack\":\n        raise AckMessage()\n\n    print(\"Message received:\", body)\n\n@app.after_startup\nasync def setup():\n    await broker.publish(\"ack\", \"test\")\n    await broker.publish(\"hello\", \"test\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Parser with Message ID Redefinition for AIOKafka\nDESCRIPTION: Example of a custom parser for AIOKafka that redefines the message_id to use a custom header. It demonstrates how to apply the custom parser at both broker and subscriber levels.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\nfrom aiokafka import ConsumerRecord\nfrom faststream.kafka import KafkaMessage\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\ndef parser(msg: ConsumerRecord) -> KafkaMessage:\n    message = KafkaMessage.from_message(msg)\n    if message.headers:\n        message_id = message.headers.get(\"custom_message_id\")\n        if message_id:\n            message.message_id = message_id.decode()\n    return message\n\n@broker.subscriber(\"test\", parser=parser)\nasync def handler(msg: KafkaMessage, logger: Logger):\n    logger.info(msg.message_id)\n\n@broker.subscriber(\"test2\")\nasync def handler2(msg: KafkaMessage, logger: Logger):\n    logger.info(msg.message_id)\n\nif __name__ == \"__main__\":\n    import asyncio\n    from faststream.security import Password\n\n    broker.add_parser(parser)\n\n    asyncio.run(\n        app.run(\n            kafka_url=\"localhost:9092\",\n            kafka_password=Password(\"test-password\"),\n        )\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing Default Handler in FastStream Subscriptions\nDESCRIPTION: This code shows how to implement a default handler in FastStream subscriptions. The default handler is defined without a filter and will process all messages that don't match other handlers. It's crucial to place the default handler last in the subscription chain.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/filtering.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsubscriber = broker.subscriber()\n\n@subscriber(filter=...)\nasync def handler(): ...\n\n@subscriber()\nasync def default_handler(): ...\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Redis Broker in Python\nDESCRIPTION: This code shows how to publish messages using a Redis broker in FastStream. It sets up a FastStream application, defines a startup event to publish a message, and includes a handler for processing messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/broker.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    await broker.publish(\n        {\"status\": \"Application started!\"},\n        channel=\"some-channel\",\n    )\n\n\n@broker.subscriber(\"some-channel\")\nasync def handler(msg: dict, logger: Logger):\n    logger.info(f\"Received: {msg}\")\n\n\n@app.after_startup\nasync def after_startup():\n    await broker.publish(\n        {\"status\": \"Application ready!\"},\n        channel=\"some-channel\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Advanced Key-Value Subscription with KvWatch in FastStream\nDESCRIPTION: This snippet demonstrates how to use the KvWatch object for more detailed settings when subscribing to Key-Value changes. It shows how to specify the bucket and declare options.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/key-value.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker, KvWatch\n\n@broker.subscriber(\n    \"key\",\n    kv_watch=KvWatch(\"bucket\", declare=False),\n)\nasync def handler(msg: str):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Using Context with AIOKafka in FastStream\nDESCRIPTION: Demonstrates how to access the application context in a FastStream application using AIOKafka. The example shows how to retrieve the broker and logger objects from the context in a message handler.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: KafkaBroker,  # from context\n    logger: Logger,  # from context\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using NATS JetStream in FastStream Application\nDESCRIPTION: This code snippet demonstrates how to configure a FastStream application with NATS JetStream, create a stream, publish messages, and consume messages using JetStream. It also shows how to access the JetStream object for advanced operations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import JStream\nfrom nats.js.api import StreamConfig\n\napp = FastStream()\nbroker = JStream(\n    \"nats://localhost:4222\",\n    stream=\"my_stream\",\n    consumer=\"my_consumer\",\n)\n\njs: nats.js.JetStreamContext = broker.js\n\n@broker.subscriber(\"some.subject\")\nasync def handler(msg, logger: Logger):\n    logger.info(f\"Received: {msg}\")\n\n@app.on_startup\nasync def publish():\n    await broker.publisher.publish({\"key\": \"value\"}, subject=\"some.subject\")\n\napp.include_router(broker)\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with FastAPI using Confluent StreamRouter\nDESCRIPTION: Using FastStream Confluent StreamRouter with FastAPI, allowing you to declare message handlers with subscriber and publisher decorators. FastStream integrates with FastAPI's dependency and serialization system, supporting Depends, BackgroundTasks, and other FastAPI tools.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom typing import Annotated\n\nfrom fastapi import FastAPI, Depends, BackgroundTasks\nfrom faststream.confluent.fastapi import KafkaRouter\n\n# Define FastAPI app\napp = FastAPI(title=\"My Service\")\n\n# Define StreamRouter\nkafka_router = KafkaRouter(\n    \"localhost:9092\",\n)\n\n# Define dependency\ndef get_user_id():\n    return \"user1\"\n\n# Define handler\n@kafka_router.subscriber(\"topic1\")\nasync def consume(\n    msg: dict,\n    tasks: BackgroundTasks,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> None:\n    tasks.add_task(print, f\"Processing message for {user_id}\")\n    await asyncio.sleep(1)\n    print(f\"Message processed: {msg}\")\n\n# Include StreamRouter in FastAPI\napp.include_router(kafka_router)\n```\n\n----------------------------------------\n\nTITLE: Defining a Kafka Publisher with Partition Key in FastStream\nDESCRIPTION: This snippet shows how to define a publisher using the KafkaBroker.publisher decorator, which allows configuration of message publishing including partition keys.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/using_a_key.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(\"output_data\")\nasync def publish(msg: str, key: str):\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Customizing Handler Information in FastStream AsyncAPI Documentation\nDESCRIPTION: FastStream application with enhanced handler descriptions, titles, and publishing schema. This provides users with detailed information about each message handler's purpose and behavior.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/getting_started/asyncapi/asyncapi_customization/custom_handler.py !}\n```\n\n----------------------------------------\n\nTITLE: Declaring Topic Exchange and Queues in Python\nDESCRIPTION: This snippet shows how to declare a Topic Exchange and multiple queues with specific routing patterns. It uses FastStream's broker.queue() method to create queues with different routing keys.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/topic.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nbroker.queue(\"queue1\", routing_key=\"*.info\")\nbroker.queue(\"queue2\", routing_key=\"#.error\")\nbroker.queue(\"queue3\", routing_key=\"*.debug\")\n```\n\n----------------------------------------\n\nTITLE: Per-Argument Message Serialization in FastStream (NATS)\nDESCRIPTION: Demonstrates per-argument message serialization for NATS in FastStream, allowing multiple arguments with different types to be unpacked from a single message.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/annotation.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle(\n    name: str,\n    user_id: int,\n):\n    print(f\"Got a message! User {name} has id {user_id}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring OAuth Bearer Authentication with SSL/TLS in FastStream\nDESCRIPTION: Shows how to set up SASL OAuth Bearer authentication for Kafka connections with username, password, and optional SSL context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/security.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.security import SASLOAuthBearer\nimport ssl\n\nssl_context = ssl.create_default_context()\nsecurity = SASLOAuthBearer(\n    username=\"admin\",\n    password=\"password\",\n    ssl_ctx=ssl_context,\n)\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with NATS in FastStream\nDESCRIPTION: Example of using the Publisher Decorator with NATS in FastStream. It shows how to subscribe to a subject and publish the processed message to another subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/decorator.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\n\n@broker.subscriber(\"input-subject\")\n@broker.publisher(\"output-subject\")\nasync def on_message(msg: str) -> str:\n    return f\"Processed: {msg}\"\n\nif __name__ == \"__main__\":\n    broker.run()\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Redis in FastStream\nDESCRIPTION: Example of using the Publisher Decorator with Redis in FastStream. It demonstrates how to subscribe to a channel and publish the processed message to another channel.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/decorator.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\n\n@broker.subscriber(\"input-channel\")\n@broker.publisher(\"output-channel\")\nasync def on_message(msg: str) -> str:\n    return f\"Processed: {msg}\"\n\nif __name__ == \"__main__\":\n    broker.run()\n```\n\n----------------------------------------\n\nTITLE: Publishing a Batch of Messages Directly in FastStream\nDESCRIPTION: This snippet demonstrates how to publish a batch of messages by directly calling the publisher with multiple messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/batch_publisher.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nawait process_data.publish(\n    body + \"_3\",\n    body + \"_4\",\n)\n```\n\n----------------------------------------\n\nTITLE: Using Annotated Aliases in AIOKafka\nDESCRIPTION: Shows how to use annotated aliases for accessing context objects in AIOKafka with proper typing. This approach provides more explicit type hints for the context objects being accessed.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\nfrom faststream.kafka.annotations import (\n    KafkaMessage,\n    KafkaBroker,\n    KafkaProducer,\n    Logger,\n    ContextRepo,\n)\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: KafkaBroker,  # access to the broker\n    context: ContextRepo,  # access to the context\n    logger: Logger,  # access to the logger\n    message: KafkaMessage,  # access to the raw message\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n\n    # access to message properties\n    print(message.offset)\n```\n\n----------------------------------------\n\nTITLE: Implementing Context Propagation in FastStream Handler\nDESCRIPTION: This code demonstrates how to propagate trace context in a FastStream handler, allowing the trace to continue across service boundaries when communicating with other services.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/tracing.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace, propagate\nfrom faststream.opentelemetry import CurrentSpan\n\n@broker.subscriber(\"symbol\")\nasync def handler(\n    msg: str,\n    span: CurrentSpan,\n) -> None:\n    headers = {}\n    propagate.inject(headers, context=trace.set_span_in_context(span))\n    price = await exchange_client.get_symbol_price(\n        msg,\n        headers=headers,\n    )\n```\n\n----------------------------------------\n\nTITLE: Sending RPC Messages and Awaiting Responses\nDESCRIPTION: This snippet demonstrates how to send RPC messages through RedisBroker and await responses on different Redis data types. It includes setting a timeout for the publisher to wait for a response.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/rpc.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nasync def main():\n    async with broker:\n        msg = \"Hello Redis RPC!\"\n\n        channel_response = await broker.publish(\n            msg,\n            \"channel\",\n            rpc=True,\n            timeout=1,\n        )\n        assert channel_response == msg\n\n        list_response = await broker.publish(\n            msg,\n            \"list\",\n            rpc=True,\n            timeout=1,\n        )\n        assert list_response == msg\n\n        stream_response = await broker.publish(\n            msg,\n            \"stream\",\n            rpc=True,\n            timeout=1,\n        )\n        assert stream_response == msg\n```\n\n----------------------------------------\n\nTITLE: Implementing In-Progress Sender with NATS JetStream in FastStream (Python)\nDESCRIPTION: This code demonstrates how to create an in-progress sender for NATS JetStream using FastStream. It utilizes asynchronous functions to handle long-running tasks and sends periodic in-progress updates to maintain the message's active status.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/nats/in-progress.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nfrom faststream import Depends, FastStream\nfrom faststream.nats import NatsBroker, NatsMessage\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\nasync def progress_sender(message: NatsMessage):\n    async def in_progress_task():\n        while True:\n            await asyncio.sleep(10.0)\n            await message.in_progress()\n\n    task = asyncio.create_task(in_progress_task())\n    yield\n    task.cancel()\n\n@broker.subscriber(\"test\", dependencies=[Depends(progress_sender)])\nasync def handler():\n    await asyncio.sleep(20.0)\n```\n\n----------------------------------------\n\nTITLE: Publishing a Batch of Messages via Function Return in FastStream\nDESCRIPTION: This snippet shows how to publish a batch of messages by returning a tuple of messages from a decorated function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/batch_publisher.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nasync def process_data(body: str):\n    return body + \"_1\", body + \"_2\"\n```\n\n----------------------------------------\n\nTITLE: Publishing a Kafka Message with a Partition Key in FastStream\nDESCRIPTION: This code demonstrates how to publish a message to a Kafka topic using a specific partition key by including the key parameter in the publish function call.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/using_a_key.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nawait publish(msg, key=msg[\"id\"])\n```\n\n----------------------------------------\n\nTITLE: Handling NATS RPC Responses in Python\nDESCRIPTION: Example showing NATS message handler with RPC response functionality using FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(...)\nasync def handler():\n    return NatsResponse(...)\n\nawait broker.publish(..., rpc=True)\n```\n\n----------------------------------------\n\nTITLE: Using Context with NATS in FastStream\nDESCRIPTION: Demonstrates how to access the application context in a FastStream application using NATS. The example shows how to retrieve the broker and logger objects from the context in a message handler.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: NatsBroker,  # from context\n    logger: Logger,  # from context\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: FastStream Dependency Management Example\nDESCRIPTION: Example showing how to use FastStream's dependency injection system with handlers\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Depends, Logger\n\nasync def base_dep(user_id: int) -> bool:\n    return True\n\n@broker.subscriber(\"in-test\")\nasync def base_handler(user: str,\n                       logger: Logger,\n                       dep: bool = Depends(base_dep)):\n    assert dep is True\n    logger.info(user)\n```\n\n----------------------------------------\n\nTITLE: Implementing NATS Pattern Subject Routing in Python\nDESCRIPTION: This code snippet demonstrates how to set up NATS Pattern Subject routing with multiple consumers and message distribution. It includes consumer announcements for different subject patterns and shows how messages are routed based on these patterns.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/examples/pattern.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsMessage, NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"*.info\", \"handler1\")\nasync def handler1(msg: NatsMessage, logger: Logger):\n    await logger.info(msg)\n\n@broker.subscriber(\"*.info\", \"handler2\")\nasync def handler2(msg: NatsMessage, logger: Logger):\n    await logger.info(msg)\n\n@broker.subscriber(\"*.error\", \"handler3\")\nasync def handler3(msg: NatsMessage, logger: Logger):\n    await logger.info(msg)\n\n@app.after_startup\nasync def publish():\n    await broker.publish(\"Hello\", subject=\"test.info\")\n    await broker.publish(\"World\", subject=\"dev.info\")\n    await broker.publish(\"!\", subject=\"test.error\")\n```\n\n----------------------------------------\n\nTITLE: Reading Settings from .env File\nDESCRIPTION: Updates the config.py to read settings from a .env file using Pydantic's env_file configuration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\nfrom pydantic import Field\n\n\nclass Settings(BaseSettings):\n    url: str = Field(..., alias=\"URL\")\n    queue: str = Field(..., alias=\"QUEUE\")\n\n    model_config = SettingsConfigDict(\n        env_file=\".env\", env_file_encoding=\"utf-8\", extra=\"ignore\"\n    )\n\n\nsettings = Settings()\n```\n\n----------------------------------------\n\nTITLE: Sending Messages to RabbitMQ Header Exchange in Python\nDESCRIPTION: These code snippets demonstrate how to send messages to a Header Exchange with different headers. Each message is routed based on the matching headers of the subscribed queues.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/headers.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:48.5] !}\n```\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:49.5]!}\n```\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:50.5]!}\n```\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:51.5]!}\n```\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:52.5]!}\n```\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:53.5,54.5,55.5]!}\n```\n\n----------------------------------------\n\nTITLE: Implementing Reply-To Functionality for RabbitMQ in Python with FastStream\nDESCRIPTION: This code shows how to set up a permanent request-reply data flow using RabbitMQ in FastStream. It demonstrates creating a subscriber for response handling and publishing a message with a specified reply-to queue.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/rpc.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"response-queue\")\nasync def consume_responses(msg):\n    ...\n\nawait broker.publish(\n    \"Hi!\",\n    queue=\"test\",\n    reply_to=\"response-queue\",\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Redis Stream Batch Subscriber in Python using FastStream\nDESCRIPTION: This snippet shows how to define a Redis stream batch subscriber using the @broker.subscriber decorator. It configures the subscriber to handle message consumption in batches from a specified Redis stream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/batch.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test-stream\", sub=StreamSub(batch=True))\ndef consume_batch(msg: List[str]):\n    print(f\"Received batch: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Consuming Function in FastStream\nDESCRIPTION: This code demonstrates how to implement a function that processes a batch of messages received from a Kafka topic. It logs the number of messages in the batch and processes each message individually.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/batch_subscriber.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test_batch\", batch=True)\nasync def on_messages(msg: List[Message[str]]):\n    logger.info(f\"Received {len(msg)} messages\")\n    for m in msg:\n        logger.info(f\"Message: {m.content}\")\n```\n\n----------------------------------------\n\nTITLE: Message Body Serialization with FastStream\nDESCRIPTION: Illustrates how FastStream uses function type annotations to serialize incoming message bodies with Pydantic. The example shows a subscriber expecting a string message body.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle_str(\n    msg_body: str,\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Connecting to Kafka using FastStream's KafkaBroker\nDESCRIPTION: This snippet demonstrates how to establish a connection to Kafka using FastStream's KafkaBroker module. It sets up a subscriber and publisher for handling messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n@broker.subscriber(\"in-topic\")\n@broker.publisher(\"out-topic\")\nasync def handle_msg(user: str, user_id: int) -> str:\n    return f\"User: {user_id} - {user} registered\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Echo Handler with FastStream in Python\nDESCRIPTION: This code snippet demonstrates a simple FastStream-based echo subscriber that publishes responses to all messages with the 'reply_to' header.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/rpc.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"echo-topic\")\nasync def echo_handler(msg: Any) -> Any:\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages to RabbitMQ Fanout Exchange in Python\nDESCRIPTION: This snippet illustrates how to publish messages to a Fanout exchange in RabbitMQ using Python. It shows that all subscribers will receive the messages regardless of routing keys.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/fanout.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/fanout.py [ln:30.5,31.5,32.5,33.5] !}\n```\n\n----------------------------------------\n\nTITLE: Creating Settings Object with Pydantic v2\nDESCRIPTION: Defines a Settings class using Pydantic v2, which inherits from BaseSettings. This class declares attributes for app configuration with type annotations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    app_name: str = \"Awesome API\"\n    items_per_user: int = 50\n\n\nsettings = Settings()\n```\n\n----------------------------------------\n\nTITLE: Subscribing Consumers to RabbitMQ Fanout Exchange in Python\nDESCRIPTION: This code demonstrates how to subscribe multiple consumers to a Fanout exchange in RabbitMQ using Python. It shows the setup for different handlers and queues.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/fanout.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/fanout.py [ln:13-25] !}\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Tornado\nDESCRIPTION: This code shows how to integrate a FastStream broker with the Tornado framework. It implements custom initialization and shutdown methods since Tornado doesn't provide lifecycle hooks.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nimport tornado.web\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n\nasync def init():\n    await broker.start()\n\n\nasync def close():\n    await broker.close()\n\n\nclass MainHandler(tornado.web.RequestHandler):\n    def get(self):\n        self.write(\"Hello, world\")\n\n\napp = tornado.web.Application([(r\"/\", MainHandler)])\n\n\nif __name__ == \"__main__\":\n    app.listen(8888)\n    loop = asyncio.get_event_loop()\n\n    try:\n        loop.run_until_complete(init())\n        loop.run_forever()\n    except KeyboardInterrupt:\n        pass\n    finally:\n        loop.run_until_complete(close())\n        loop.close()\n```\n\n----------------------------------------\n\nTITLE: Registering Handlers with Broker Router in FastStream\nDESCRIPTION: This code shows how to use a created Broker Router to register handlers in FastStream. It demonstrates the usage of the router for defining subscribers and publishers, similar to using a regular broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/routers/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@router.subscriber(\"test\")\nasync def base_handler(msg: str) -> None:\n    print(msg)\n\n@router.publisher(\"test\")\nasync def base_publisher() -> str:\n    return \"Hello!\"\n\n@app.after_startup\nasync def send_message(p=Depends(base_publisher)):\n    await p()\n```\n\n----------------------------------------\n\nTITLE: Creating KafkaBroker and FastStream App\nDESCRIPTION: This snippet demonstrates how to create a KafkaBroker instance and wrap it in a FastStream application. This setup allows for starting the app using CLI later.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nbroker = KafkaBroker()\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: FastAPI Integration with Redis Router in FastStream\nDESCRIPTION: This snippet demonstrates how to integrate FastStream's Redis router with FastAPI. It sets up a subscriber handler and includes the router in a FastAPI application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom faststream.redis.fastapi import RedisRouter, Logger\n\nrouter = RedisRouter()\n\n@router.subscriber(\"test\")\nasync def handler(msg, logger: Logger):\n    logger.info(msg)\n\napp = FastAPI(lifespan=router.lifespan_context)\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Redis in FastStream\nDESCRIPTION: This snippet shows how to create and use a Publisher object with Redis in FastStream. It demonstrates the setup of the RedisBroker and creation of a Publisher for the 'test' channel.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/direct.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"test\")\n\n@broker.subscriber(\"input\")\nasync def on_input(msg: str):\n    await publisher.publish(msg)\n```\n\n----------------------------------------\n\nTITLE: Creating Publisher Object for Redis Channel\nDESCRIPTION: Create a publisher instance for a specific Redis channel. This structured approach allows for better organization and documentation of publishers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/publishing.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npublish = broker.publisher(\"test\")\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Fields in RabbitMQ\nDESCRIPTION: Demonstrates how to access existing context fields like broker, context, logger, and message in RabbitMQ implementations. The highlighted lines show the import statement and the function that uses these context fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker\n\n# ...\n\n# ...\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: RabbitBroker,  # access to the broker\n    context,  # access to the context\n    logger,  # access to the logger\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n```\n\n----------------------------------------\n\nTITLE: Using Path for NATS Wildcard Subject Access\nDESCRIPTION: Shows how to use the Path object to access NATS wildcard subjects or RabbitMQ topic routing keys in a subscriber function. This provides a shortcut to access the message path context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_48\n\nLANGUAGE: python\nCODE:\n```\n@nats_broker.subscriber(\"logs.{level}\")\nasync def handler(\n  level: str = Path(),\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Concurrent Message Processing in Kafka\nDESCRIPTION: Example demonstrating how to set up concurrent message processing for Kafka broker with autocommit mode, allowing processing of up to 10 messages simultaneously.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(\"topic\", max_workers=10)\nasync def handler():\n    \"\"\"Using `max_workers` option you can process up to 10 messages by one subscriber concurrently\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Filtering with FastStream for Multiple Brokers\nDESCRIPTION: This code snippet demonstrates how to set up message filtering in FastStream for various message brokers (AIOKafka, Confluent, RabbitMQ, NATS, Redis). It shows how to define handlers for JSON and non-JSON messages using filters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/filtering.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-topic\", filter=lambda msg: msg.content_type == \"application/json\")\nasync def handle(msg: dict, logger: Logger):\n    logger.info(f\"Received JSON: {msg}\")\n    return msg\n\n@broker.subscriber(\"test-topic\")\nasync def default_handler(msg: str, logger: Logger):\n    logger.warning(f\"Received unknown format: {msg}\")\n    return msg\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Implementing Direct Exchange with FastStream and RabbitMQ\nDESCRIPTION: This code snippet demonstrates a complete implementation of Direct Exchange using FastStream and RabbitMQ. It includes the setup of the exchange, queues, and multiple consumers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/direct.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker, ExchangeType\n\nbroker = RabbitBroker()\n\n\nasync def main():\n    await broker.connect()\n    await broker.declare_exchange(\"exchange\", ExchangeType.DIRECT, auto_delete=True)\n    await broker.declare_queue(\"test-q-1\", auto_delete=True)\n    await broker.declare_queue(\"test-q-2\", auto_delete=True)\n\n    @broker.subscriber(\"test-q-1\", \"exchange\")\n    async def handler1(body: str):\n        print(f\"handler1 got {body}\")\n\n    @broker.subscriber(\"test-q-1\", \"exchange\")\n    async def handler2(body: str):\n        print(f\"handler2 got {body}\")\n\n    @broker.subscriber(\"test-q-2\", \"exchange\")\n    async def handler3(body: str):\n        print(f\"handler3 got {body}\")\n\n    await broker.start()\n\n    publisher = broker.publisher(\"exchange\")\n\n    await publisher.publish(\"1\", routing_key=\"test-q-1\")\n    await publisher.publish(\"2\", routing_key=\"test-q-1\")\n    await publisher.publish(\"3\", routing_key=\"test-q-1\")\n    await publisher.publish(\"4\", routing_key=\"test-q-2\")\n\n    await broker.close()\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Sending Blocking RPC Request over NATS in FastStream\nDESCRIPTION: This snippet demonstrates how to send a blocking RPC request over NATS using FastStream. It uses the broker.request method to send a message to a specific subject and await a response synchronously.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/rpc.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsMessage\n\nmsg: NatsMessage = await broker.request(\n    \"Hi!\",\n    subject=\"test\",\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing SCRAM256 Authentication with SSL/TLS in FastStream\nDESCRIPTION: Demonstrates how to configure SASL SCRAM-SHA-256 authentication mechanism with username, password, and optional SSL context for Kafka connections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/security.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.security import SASLScram256\nimport ssl\n\nssl_context = ssl.create_default_context()\nsecurity = SASLScram256(\n    username=\"admin\",\n    password=\"password\",\n    ssl_ctx=ssl_context,\n)\n\nbroker = KafkaBroker(\"localhost:9092\", security=security)\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Sanic\nDESCRIPTION: This example shows how to integrate a FastStream broker with the Sanic framework. It uses application lifecycle events to connect the broker at startup and disconnect during shutdown.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom sanic import Sanic\nfrom sanic.response import json\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n\napp = Sanic(\"MyHelloWorldApp\")\n\n\n@app.listener(\"before_server_start\")\nasync def connect_broker(app, loop):\n    await broker.start()\n\n\n@app.listener(\"before_server_stop\")\nasync def disconnect_broker(app, loop):\n    await broker.close()\n\n\n@app.route(\"/\")\nasync def test(request):\n    return json({\"hello\": \"world\"})\n```\n\n----------------------------------------\n\nTITLE: Publishing Message with KafkaBroker in Python\nDESCRIPTION: Demonstrates how to publish a message using the KafkaBroker's publish method. This is the most basic way to send a message to a Kafka topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\n    \"Hello, World!\",\n    topic=\"test_topic\",\n    key=\"test_key\",\n    headers={\"X-Custom-Header\": \"value\"},\n)\n```\n\n----------------------------------------\n\nTITLE: Returning a Batch of Messages from a FastStream Publisher\nDESCRIPTION: This snippet shows how to return a batch of messages from a decorated publisher function. The function returns a tuple containing the messages to be sent as a batch.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/batch_publisher.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(\"output_data\", batch=True)\nasync def output_data_batch(msg: str, batch_size: int = 2):\n    return tuple([msg] * batch_size)\n```\n\n----------------------------------------\n\nTITLE: Nested Dependencies in FastStream\nDESCRIPTION: Shows how to use nested dependencies in FastStream, demonstrating the dependency chain and caching behavior.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Depends\nfrom faststream.kafka import KafkaBroker\n\napp = FastStream()\nbroker = KafkaBroker()\n\ndef another_dependency() -> int:\n    return 42\n\ndef simple_dependency(a: int = Depends(another_dependency)) -> int:\n    return a + 3\n\n@broker.subscriber(\"test\")\ndef method(\n    a: int,\n    d: int = Depends(simple_dependency),\n    e: int = Depends(another_dependency)\n):\n    return a + d + e\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL Plaintext Authentication with SSL/TLS in FastStream (Python)\nDESCRIPTION: Shows how to use the SASLPlaintext object for authentication in SASL plaintext mode with SSL/TLS encryption. It demonstrates providing a username and password for authentication, along with SSL context configuration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/security.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.security import SASLPlaintext\nfrom faststream.kafka import KafkaBroker\n\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\n\nbroker = KafkaBroker(\n    \"localhost:9092\",\n    security=SASLPlaintext(\n        username=\"user\",\n        password=\"password\",\n        ssl_context=ssl_context,\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with RabbitMQ in FastStream\nDESCRIPTION: Example of using the Publisher Decorator with RabbitMQ in FastStream. It demonstrates how to subscribe to a queue and publish the processed message to another queue.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/decorator.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker()\n\n@broker.subscriber(\"input-queue\")\n@broker.publisher(\"output-queue\")\nasync def on_message(msg: str) -> str:\n    return f\"Processed: {msg}\"\n\nif __name__ == \"__main__\":\n    broker.run()\n```\n\n----------------------------------------\n\nTITLE: Implementing Lifespan Hook for Environment Settings in FastStream\nDESCRIPTION: Example of using the @app.on_startup decorator to initialize application settings from environment files and access them globally through FastStream's context system.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/hooks.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@app.on_startup\nasync def setup(env: str = \"development\"):\n    Settings.model_validate({**Settings().model_dump(), \"env\": env})\n    ContextRepo.get_context().add_global(Settings())\n    return broker\n```\n\n----------------------------------------\n\nTITLE: Generating Multiple Messages per Task\nDESCRIPTION: Example of using a generator function to send multiple messages in a single task.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nasync def collect_information_to_send():\n    \"\"\"Publish 10 messages per task call.\"\"\"\n    for i in range(10):\n        yield i\n\ntaskiq_broker.task(\n    message=collect_information_to_send,\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Avro serialization in FastStream\nDESCRIPTION: This code snippet demonstrates how to use Avro serialization in a FastStream application, including message encoding and decoding with schema definition.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, NoCast\nfrom faststream.nats import NatsMessage, NatsBroker\nfrom pydantic import BaseModel\nfrom io import BytesIO\nfrom fastavro import schemaless_reader, schemaless_writer\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\nschema = {\n    \"namespace\": \"example.avro\",\n    \"type\": \"record\",\n    \"name\": \"Person\",\n    \"fields\": [\n        {\"name\": \"name\", \"type\": \"string\"},\n        {\"name\": \"age\", \"type\": \"float\"}\n    ]\n}\n\n# Alternatively, load schema from file\n# schema = fastavro.schema.load_schema(\"person.avsc\")\n\nclass AvroMsg(BaseModel):\n    body: NoCast[bytes]\n\nclass Person(BaseModel):\n    name: str\n    age: float\n\n@broker.subscriber(\"test\", response_model=AvroMsg)\nasync def on_message(msg: AvroMsg) -> Person:\n    bytes_reader = BytesIO(msg.body)\n    return Person(**schemaless_reader(bytes_reader, schema))\n\n@broker.publisher(\"test\")\nasync def publish(msg: Person) -> NatsMessage[AvroMsg]:\n    bytes_writer = BytesIO()\n    schemaless_writer(bytes_writer, schema, msg.dict())\n    return NatsMessage(AvroMsg(body=bytes_writer.getvalue()))\n```\n\n----------------------------------------\n\nTITLE: Complete FastStream Application Using Kafka Partition Keys\nDESCRIPTION: This is a full example of a FastStream application that consumes messages from an 'input_data' topic and publishes them with a specified key to an 'output_data' topic, illustrating the use of partition keys in Kafka-based applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/using_a_key.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input_data\")\nasync def on_input_data(msg: dict, logger: Logger):\n    logger.info(f\"Received message: {msg}\")\n\n    # Publish the message to the output topic with a key\n    await publish(msg, key=msg[\"id\"])\n\n    logger.info(f\"Published message with key: {msg['id']}\")\n\n\n@broker.publisher(\"output_data\")\nasync def publish(msg: str, key: str):\n    return msg\n\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL SCRAM-SHA-512 Authentication with SSL/TLS in FastStream (Python)\nDESCRIPTION: Shows how to use the SASLScram512 object for authentication using the Salted Challenge Response Authentication Mechanism (SCRAM) with SHA-512. It includes SSL/TLS configuration for secure communication.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/security.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.security import SASLScram512\nfrom faststream.kafka import KafkaBroker\n\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\n\nbroker = KafkaBroker(\n    \"localhost:9092\",\n    security=SASLScram512(\n        username=\"user\",\n        password=\"password\",\n        ssl_context=ssl_context,\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Specific Message Fields in FastStream\nDESCRIPTION: Illustrates how to use the Context feature in FastStream to access specific message fields, such as headers, without needing the entire message object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/message.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    headers: str = Context(\"message.headers\"),\n):\n    print(headers)\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Application with Environment Variables\nDESCRIPTION: Shows how to run a FastStream application while passing configuration parameters as environment variables.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nURL=\"amqp://guest:guest@localhost:5672\" faststream run serve:app\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Rocketry Scheduler\nDESCRIPTION: Complete example of integrating FastStream with Rocketry for task scheduling, using NATS broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nfrom rocketry import Rocketry\nfrom rocketry.args import Arg\n\nfrom faststream.nats import NatsBroker\n\napp = Rocketry(execution=\"async\")\n\nbroker = NatsBroker()      # regular broker\napp.params(broker=broker)\n\nasync def start_app():\n    async with broker:     # connect broker\n        await app.serve()  # run rocketry\n\n@app.task(\"every 1 second\", execution=\"async\")\nasync def publish(br: NatsBroker = Arg(\"broker\")):\n    await br.publish(\"Hi, Rocketry!\", \"test\")\n\nif __name__ == \"__main__\":\n    asyncio.run(start_app())\n```\n\n----------------------------------------\n\nTITLE: Complete KafkaBroker Publisher Decorator Example in Python\nDESCRIPTION: Provides a complete example of using KafkaBroker with publisher decorators. This approach offers an AsyncAPI representation and is ideal for rapid application development.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\n\nclass InputModel(BaseModel):\n    content: str\n\n\nclass OutputModel(BaseModel):\n    result: str\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\npublisher = broker.publisher(\"output-topic\")\n\n\n@broker.subscriber(\"input-topic\")\n@publisher\ndef on_message(msg: InputModel) -> OutputModel:\n    return OutputModel(result=msg.content)\n\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Declaring Fanout Exchange and Queues in Python\nDESCRIPTION: This snippet shows how to declare a Fanout exchange and multiple queues in RabbitMQ using Python. It sets up the exchange structure for broadcasting messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/fanout.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/fanout.py [ln:7-10] !}\n```\n\n----------------------------------------\n\nTITLE: Testing Event Hooks with AIOKafka in FastStream\nDESCRIPTION: This snippet demonstrates how to test lifespan hooks in a FastStream application using AIOKafka broker. It shows the setup of a TestApp context manager to trigger startup and shutdown events during testing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/test.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream.kafka.testing import TestApp\n\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    print(\"started\")\n\n\n@app.on_shutdown\nasync def shutdown():\n    print(\"shutdown\")\n\n\nasync with TestApp(app):\n    # test that application started and `startup()` was called\n    pass\n# test that `shutdown()` was called\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Broker with Explicit Partition Assignment in Python\nDESCRIPTION: Example of setting up a Kafka broker with explicit partition assignment for a subscriber in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker, TopicPartition\n\nbroker = KafkaBroker()\n\ntopic_partition_first = TopicPartition(\"my_topic\", 1)\ntopic_partition_second = TopicPartition(\"my_topic\", 2)\n\n@broker.subscribe(partitions=[topic_partition_first, topic_partition_second])\nasync def some_consumer(msg):\n   ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Retry Behavior in NATS Subscriber (Python)\nDESCRIPTION: This snippet demonstrates how to set the retry flag in a NATS subscriber decorator to control error handling behavior. When set to False (default), messages are rejected on error. When set to True, messages are nack'ed and requeued on error.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/ack.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\", retry=False) # don't handle exceptions\nasync def base_handler(body: str):\n    ...\n```\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\", retry=True)  # try again indefinitely\nasync def base_handler(body: str):\n    ...\n```\n\n----------------------------------------\n\nTITLE: FastStream Integration with AIOHTTP\nDESCRIPTION: Example of integrating FastStream with AIOHTTP web framework\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom aiohttp import web\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\n\n@broker.subscriber(\"test\")\nasync def base_handler(body):\n    print(body)\n\nasync def start_broker(app):\n    await broker.start()\n\nasync def stop_broker(app):\n    await broker.close()\n\nasync def hello(request):\n    return web.Response(text=\"Hello, world\")\n\napp = web.Application()\napp.add_routes([web.get(\"/\", hello)])\napp.on_startup.append(start_broker)\napp.on_cleanup.append(stop_broker)\n\nif __name__ == \"__main__\":\n    web.run_app(app)\n```\n\n----------------------------------------\n\nTITLE: Registering Publishing Exception Handler with Initialization Option in FastStream\nDESCRIPTION: Example of registering a publishing exception handler using the publish_handlers initialization option. This approach provides a fallback value that will be published when an error occurs.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/exception.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef error_handler(exc: Exception) -> str:\n    print(repr(exc))\n    return \"error occurred\"\n\nexc_middleware = ExceptionMiddleware(\n    publish_handlers={\n        Exception: error_handler\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Using RPCWorker with Manual Start in FastStream Application\nDESCRIPTION: This code snippet shows how to use the RPCWorker with a manual start method in a FastStream application, allowing it to be initialized after the application has started.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/rpc.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@app.after_startup\nasync def send_request() -> None:\n    worker = RPCWorker(broker, reply_topic=\"responses\")\n    await worker.start()\n\n    data = await worker.request(\"echo\", \"echo-topic\")\n    assert data == \"echo\"\n```\n\n----------------------------------------\n\nTITLE: Using Publisher Object with Router in Python\nDESCRIPTION: Shows how to use the router.publisher() function which now returns a correct Publisher object that can be used after broker startup for message publishing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\npublisher = router.publisher(\"test\")\n\n@router.subscriber(\"in\")\nasync def handler():\n    await publisher.publish(\"msg\")\n```\n\n----------------------------------------\n\nTITLE: Declaring Direct Exchange and Queues in FastStream\nDESCRIPTION: This snippet shows how to declare a Direct Exchange and multiple queues in FastStream. It uses the 'declare_exchange' and 'declare_queue' methods of the RabbitBroker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/direct.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nawait broker.declare_exchange(\"exchange\", ExchangeType.DIRECT, auto_delete=True)\nawait broker.declare_queue(\"test-q-1\", auto_delete=True)\nawait broker.declare_queue(\"test-q-2\", auto_delete=True)\n```\n\n----------------------------------------\n\nTITLE: Using NATS Key-Value Store with FastStream\nDESCRIPTION: This snippet demonstrates how to use the new NATS Key-Value store feature in FastStream. It sets up a subscriber to watch for changes in a key-value bucket and publishes a value after startup.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"some-key\", kv_watch=\"bucket\")\nasync def handler(msg: int, logger: Logger):\n    logger.info(msg)\n\n@app.after_startup\nasync def test():\n    kv = await broker.key_value(\"bucket\")\n    await kv.put(\"some-key\", b\"1\")\n```\n\n----------------------------------------\n\nTITLE: Using NATS Object Store with FastStream\nDESCRIPTION: This example shows how to use the new NATS Object Store feature in FastStream. It sets up a subscriber to watch for changes in an object store bucket and publishes a file after startup.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"file-bucket\", obj_watch=True)\nasync def handler(filename: str, logger: Logger):\n    logger.info(filename)\n\n@app.after_startup\nasync def test():\n    object_store = await broker.object_storage(\"file-bucket\")\n    await object_store.put(\"some-file.txt\", b\"1\")\n```\n\n----------------------------------------\n\nTITLE: Testing FastStream Services with Redis\nDESCRIPTION: Testing a FastStream Redis service using pytest and the TestBroker context manager, which puts the broker into 'testing mode' and redirects functions to InMemory brokers for testing without a running broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nimport asyncio\nimport pytest\nfrom faststream.redis import TestRedisBroker\n\nfrom basic import app, HandleMsg, publish\n\n\n@pytest.mark.asyncio\nasync def test_handle_msg():\n    async with TestRedisBroker(app) as broker:\n        # Publish a message to the input topic\n        await broker.publish({\"message\": \"Hello World!\"}, \"input_data\")\n\n        # Check message has been processed correctly\n        call = broker.get_handler_call(HandleMsg, return_exceptions=True)\n        # or broker.get_by_topic(\"output_data\", return_exceptions=True)\n        assert call[0] == {\"message\": \"Hello World!\", \"processed\": True}\n```\n\n----------------------------------------\n\nTITLE: Initializing FastStream Application with RedisBroker\nDESCRIPTION: This snippet shows how to initiate a FastStream application using RedisBroker for Redis connectivity.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/rpc.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Using Request Method with NATS Broker in Python\nDESCRIPTION: Demonstrates the new broker.request(...) method that provides enhanced RPC functionality compared to the old rpc=True parameter. This allows full access to the response message including headers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.nats import NatsBroker, NatsResponse, NatsMessage\n\nbroker = NatsBroker()\n\n@broker.subscriber(\"test\")\nasync def echo_handler(msg):\n    return NatsResponse(msg, headers={\"x-token\": \"some-token\"})\n\n@app.after_startup\nasync def test():\n    # The old implementation was returning just a message body,\n    # so you wasn't be able to check response headers, etc\n    msg_body: str = await broker.publish(\"ping\", \"test\", rpc=True)\n    assert msg_body == \"ping\"\n\n    # Now request return the whole message and you can validate any part of it\n    # moreover it triggers all your middlewares\n    response: NatsMessage = await broker.request(\"ping\", \"test\")\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Consumer with Django ORM Access\nDESCRIPTION: Command to run the FastStream consumer that has access to Django ORM.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nfaststream run serve_faststream:app\n```\n\n----------------------------------------\n\nTITLE: Using TestApp Class for Asynchronous Application Testing in FastStream\nDESCRIPTION: The TestApp class provides functionality for testing asynchronous applications in FastStream. It allows for initializing the application context, sending test messages, publishing messages, and testing handlers. The class also supports context management for cleanup operations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/TestApp.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass TestApp:\n    \"\"\"Test application for async applications.\n\n    Example:\n        ```python\n        from faststream import FastStream\n        from faststream.kafka import KafkaBroker\n\n        broker = KafkaBroker()\n\n        app = FastStream(broker)\n\n\n        @broker.subscriber(\"test\")\n        async def handler(msg: str) -> None:\n            print(f\"Got message: {msg}\")\n\n\n        # in tests\n        from faststream.testing import TestApp\n\n        async def test_app_flow():\n            async with TestApp(app) as ta:\n                await ta.publish(\"Hello, world!\", \"test\")\n        ```\n    \"\"\"\n\n    _started: bool = False\n    _broker: object\n    _app: object\n\n    def __init__(\n        self,\n        app: object,\n        *,\n        include_global: bool = False,\n        include_kafka: bool = True,\n        include_rabbit: bool = True,\n        include_redis: bool = True,\n        include_nats: bool = True,\n        include_pulsar: bool = True,\n    ) -> None: ...\n\n    async def __aenter__(self) -> \"TestApp\": ...\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> None: ...\n\n    def _clean_test_dependencies(self) -> None: ...\n\n    async def start(self) -> None:\n        \"\"\"Start application in test mode.\"\"\"\n        ...\n\n    async def stop(self) -> None:\n        \"\"\"Stop application.\"\"\"\n        ...\n\n    async def publish(\n        self,\n        message: KafkaMessage | RabbitMessage | RedisMessage | NatsMessage | PulsarMessage | Any,\n        *topics: str,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Publish message to broker with applied patchers.\n\n        Args:\n            message: Message to publish\n            topics: Topics to publish to\n            **kwargs: Additional arguments for publisher\n        \"\"\"\n        ...\n\n    async def fake_subscriber_call(\n        self,\n        handler: Callable[..., Awaitable[Any]],\n        message: KafkaMessage | RabbitMessage | RedisMessage | NatsMessage | PulsarMessage | Any,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Pass message to handler without publishing to broker.\n\n        Args:\n            handler: Handler to call (broker.subscriber function)\n            message: Message or payload to pass to handler\n            **kwargs: Additional arguments for handler\n        \"\"\"\n        ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Redis List Publisher Function with FastStream in Python\nDESCRIPTION: This function demonstrates how to process incoming messages from one Redis list and publish results to another. It uses FastStream decorators to subscribe to 'input-list' and publish to 'output-list'.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/publishing.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(list=\"output-list\")\n@broker.subscriber(list=\"input-list\")\nasync def on_message(msg: Data) -> Data:\n    return Data(key=msg.key, value=msg.value * 2)\n```\n\n----------------------------------------\n\nTITLE: Complete Redis List Publishing Example with FastStream in Python\nDESCRIPTION: This comprehensive example demonstrates Redis list publishing using FastStream. It includes broker setup, application creation, data model definition, and a publish/subscribe function for processing messages between Redis lists.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/publishing.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom pydantic import BaseModel\n\n\nclass Data(BaseModel):\n    key: str\n    value: int\n\n\nbroker = RedisBroker(\"redis://localhost:6379\")\napp = FastStream(broker)\n\n\n@broker.publisher(list=\"output-list\")\n@broker.subscriber(list=\"input-list\")\nasync def on_message(msg: Data) -> Data:\n    return Data(key=msg.key, value=msg.value * 2)\n```\n\n----------------------------------------\n\nTITLE: Delayed Handler Registration in FastStream\nDESCRIPTION: This snippet illustrates how to separate core logic from FastStream's routing logic using delayed handler registration. It defines core functions that can be used as Broker Router handlers later.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/routers/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker, KafkaRouter\n\napp = KafkaBroker()\nrouter = KafkaRouter()\n\ndef process_message(msg: str) -> None:\n    print(f\"Processing: {msg}\")\n\ndef send_response() -> str:\n    return \"Response sent\"\n\nrouter.add_subscriber(\"incoming\", process_message)\nrouter.add_publisher(\"outgoing\", send_response)\n\n@app.after_startup\nasync def startup(publisher=Depends(router.publisher(\"outgoing\"))):\n    await publisher()\n\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Publishing Message with Partition Key in Python\nDESCRIPTION: Shows how to publish a message to a Kafka topic with a specific partition key by including the key parameter in the publish function call.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/using_a_key.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nawait publish(message, key=message.user_id)\n```\n\n----------------------------------------\n\nTITLE: Testing FastStream Services with Confluent\nDESCRIPTION: Testing a FastStream Confluent service using pytest and the TestBroker context manager, which puts the broker into 'testing mode' and redirects functions to InMemory brokers for testing without a running broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nimport asyncio\nimport pytest\nfrom faststream.confluent import TestConfluentKafkaBroker\n\nfrom basic import app, HandleMsg, publish\n\n\n@pytest.mark.asyncio\nasync def test_handle_msg():\n    async with TestConfluentKafkaBroker(app) as broker:\n        # Publish a message to the input topic\n        await broker.publish({\"message\": \"Hello World!\"}, \"input_data\")\n\n        # Check message has been processed correctly\n        call = broker.get_handler_call(HandleMsg, return_exceptions=True)\n        # or broker.get_by_topic(\"output_data\", return_exceptions=True)\n        assert call[0] == {\"message\": \"Hello World!\", \"processed\": True}\n```\n\n----------------------------------------\n\nTITLE: Interrupting Kafka Message Processing with Custom Exceptions in Python\nDESCRIPTION: This snippet shows how to use custom exceptions (AckMessage and NackMessage) to interrupt message processing and control acknowledgement in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/ack.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream.exceptions import AckMessage, NackMessage\n\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test\", group_id=\"group\", auto_commit=False)\nasync def base_handler(body: str):\n    print(body)\n    if body == \"Ack\":\n        raise AckMessage()\n    if body == \"Nack\":\n        raise NackMessage()\n    print(\"Not acked\")\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Publishers in FastStream\nDESCRIPTION: This snippet demonstrates how to use multiple Publisher objects in a single subscriber function. It shows publishing different messages to different outputs using separate publishers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/direct.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"in\")\nasync def handle(msg) -> str:\n    await publisher1.publish(\"Response-1\")\n    await publisher2.publish(\"Response-2\")\n```\n\n----------------------------------------\n\nTITLE: Defining Reference Class for AsyncAPI Schema in Python\nDESCRIPTION: This code defines a Reference class that represents a reference to an AsyncAPI schema component. It contains functionality to validate reference paths and construct proper reference strings in AsyncAPI format. The class includes path validation and supports JSON Schema references.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/utils/Reference.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional, Union\n\nfrom pydantic import Field, field_validator\n\nfrom faststream.asyncapi.schema.base import AsyncAPIObject\nfrom faststream.asyncapi.schema.shared.reference import Reference as CommonReference\n\n\nclass Reference(AsyncAPIObject):\n    \"\"\"Reference object, as defined by JSON Schema and AsyncAPI.\n\n    The reference string MUST be in the form of a URI.\n\n    More information: https://www.asyncapi.com/docs/reference/specification/v2.6.0#referenceObject\n    \"\"\"\n\n    ref: str = Field(\n        alias=\"$ref\",\n        description=\"Reference path\"\n    )\n\n    @field_validator('ref')\n    @classmethod\n    def validate_ref(cls, ref: str) -> str:\n        if not ref.startswith(\"#/components/\"):\n            raise ValueError(\n                \"Reference must start with #/components/ \"\n                \"(e.g. #/components/schemas/Pet)\"\n            )\n        return ref\n\n    @classmethod\n    def schema(cls, schema_name: str) -> \"Reference\":\n        \"\"\"Create a reference to a schema.\n\n        Args:\n            schema_name: The name of the schema\n\n        Returns:\n            a reference to the schema\n        \"\"\"\n        return cls(ref=f\"#/components/schemas/{schema_name}\")\n\n    @classmethod\n    def from_common(cls, ref: Union[str, CommonReference]) -> \"Optional[Reference]\":\n        \"\"\"Convert a common reference to a schema reference.\n\n        Args:\n            ref: The common reference\n\n        Returns:\n            a reference to the schema\n        \"\"\"\n        if isinstance(ref, str):\n            if ref.startswith(\"#/components/\"):\n                return cls(ref=ref)\n            return None\n\n        if isinstance(ref, CommonReference):\n            if ref.ref.startswith(\"#/components/\"):\n                return cls(ref=ref.ref)\n            return None\n\n        raise TypeError(f\"Cannot convert {ref} to Reference\")\n```\n\n----------------------------------------\n\nTITLE: Defining Protobuf schema for FastStream messages\nDESCRIPTION: This snippet defines a Protobuf schema for a Person message, which includes name and age fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_1\n\nLANGUAGE: proto\nCODE:\n```\nsyntax = \"proto3\";\n\nmessage Person {\n    string name = 1;\n    float age = 2;\n}\n```\n\n----------------------------------------\n\nTITLE: Publishing Detailed Response Messages in FastStream\nDESCRIPTION: Demonstrates using broker.Response to publish messages with additional metadata like headers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def handler(msg):\n    return Response(msg, headers={\"response_header\": \"Hi!\"})   # or KafkaResponse, etc\n```\n\n----------------------------------------\n\nTITLE: Retrieving AsyncAPI Schema in FastStream\nDESCRIPTION: The get_app_schema function is used to extract the AsyncAPI schema from a FastStream application. This function is part of the AsyncAPI module in FastStream that enables automatic API documentation generation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/get_app_schema.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_app_schema(app: \"FastStream\", *, context_url: str | None = None) -> dict[str, Any]:\n    \"\"\"Get app AsyncAPI schema.\n\n    Args:\n        app: FastStream app\n        context_url: AsyncAPI context URL\n\n    Returns:\n        AsyncAPI schema\n    \"\"\"\n    return AsyncAPIGenerator(app, context_url=context_url).get_schema()\n```\n\n----------------------------------------\n\nTITLE: Type Casting in FastStream Context\nDESCRIPTION: Shows how context fields are not automatically cast to their annotated types, and demonstrates the behavior with and without type casting enabled.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/extra.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\nctx = Context()\nctx.set_global(number=\"42\")\n\nclass ContextFields:\n    number: int\n\nfields = ContextFields(**ctx)\nprint(fields.number)  # \"42\"\nprint(type(fields.number))  # <class 'str'>\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\nctx = Context(cast=True)\nctx.set_global(number=\"42\")\n\nprint(ctx.number)  # 42\n```\n\n----------------------------------------\n\nTITLE: Testing FastStream Services with RabbitMQ\nDESCRIPTION: Testing a FastStream RabbitMQ service using pytest and the TestBroker context manager, which puts the broker into 'testing mode' and redirects functions to InMemory brokers for testing without a running broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nimport asyncio\nimport pytest\nfrom faststream.rabbit import TestRabbitBroker\n\nfrom basic import app, HandleMsg, publish\n\n\n@pytest.mark.asyncio\nasync def test_handle_msg():\n    async with TestRabbitBroker(app) as broker:\n        # Publish a message to the input topic\n        await broker.publish({\"message\": \"Hello World!\"}, \"input_data\")\n\n        # Check message has been processed correctly\n        call = broker.get_handler_call(HandleMsg, return_exceptions=True)\n        # or broker.get_by_topic(\"output_data\", return_exceptions=True)\n        assert call[0] == {\"message\": \"Hello World!\", \"processed\": True}\n```\n\n----------------------------------------\n\nTITLE: Using Annotated with Context in AIOKafka\nDESCRIPTION: Shows how to use Python's Annotated feature with FastStream Context in AIOKafka. This approach is similar to pytest fixtures, allowing for cleaner dependency injection with type hints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nfrom faststream import FastStream, Context, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n# inject application object from a Context\nLoggerDep = Annotated[Logger, Context()]\nBrokerDep = Annotated[KafkaBroker, Context()]\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: BrokerDep,  # from context with annotation\n    logger: LoggerDep,  # from context with annotation\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Serializing Basic Types in FastStream Subscribers\nDESCRIPTION: Demonstrates how FastStream serializes incoming messages to basic Python types like str, bytes, and int using function annotations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/annotation.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle(\n    msg: str,\n):\n    ...\n\n@broker.subscriber(\"test\")\nasync def handle(\n    msg: bytes,\n):\n    ...\n\n@broker.subscriber(\"test\")\nasync def handle(\n    msg: int,\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Including Router Handlers in FastStream Broker\nDESCRIPTION: This snippet demonstrates how to include all handlers declared using a Broker Router into the main FastStream broker. It's a crucial step to integrate the modularized components.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/routers/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\napp.include_router(router)\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Parser for Redis in FastStream\nDESCRIPTION: Demonstrates how to reuse the original parser function for Redis messages in FastStream, allowing for custom modifications while maintaining original functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom faststream.redis import RedisMessage\nfrom faststream.redis.message import PubSubMessage\n\nasync def parser(\n    msg: PubSubMessage,\n    original_parser: Callable[[PubSubMessage], Awaitable[RedisMessage]],\n) -> RedisMessage:\n    return await original_parser(msg)\n```\n\n----------------------------------------\n\nTITLE: Adding FastStream Lifespan to Django ASGI Application\nDESCRIPTION: Configuration that adds a FastStream broker lifespan to the Starlette application, allowing the broker to start and stop with the application lifecycle.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nfrom contextlib import asynccontextmanager\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@asynccontextmanager\nasync def broker_lifespan(app):\n    await broker.start()\n    try:\n        yield\n    finally:\n        await broker.close()\n\napplication = Starlette(\n    ...,\n    lifespan=broker_lifespan,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing SSL/TLS Encryption with BaseSecurity in FastStream Redis\nDESCRIPTION: This snippet demonstrates how to use the BaseSecurity object to enable SSL/TLS encryption for secure communication between FastStream services and Redis. It shows the creation of an SSLContext and its application to a RedisBroker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.redis import RedisBroker\nfrom faststream.security import BaseSecurity\n\nssl_context = ssl.create_default_context()\nredis_security = BaseSecurity(ssl=ssl_context)\n\nbroker = RedisBroker(\"redis://localhost:6379\", security=redis_security)\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Messages with Subscriber Object in Python\nDESCRIPTION: Demonstrates the new preferred syntax for message filtering using the broker.subscriber() function which returns a Subscriber object that can be used for multiple handler decorations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nsubscriber = broker.subscriber(\"test\")\n\n@subscriber(filter = lambda msg: msg.content_type == \"application/json\")\nasync def handler(msg: dict[str, Any]):\n    ...\n\n@subscriber()\nasync def handler(msg: dict[str, Any]):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Subscriber for Manual Acknowledgement in Python\nDESCRIPTION: This snippet shows how to set up a Kafka subscriber with manual acknowledgement by disabling auto_commit and specifying a group_id.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/ack.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\n    \"test\", group_id=\"group\", auto_commit=False\n)\nasync def base_handler(body: str):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Handling Headers in FastStream Handler\nDESCRIPTION: Demonstrates how to access header values in a FastStream handler function using the Header dependency. Shows both default and custom header name usage.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_47\n\nLANGUAGE: python\nCODE:\n```\nasync def handler(\n  user_id: int = Header(),\n  u_id: int = Header(\"user_id\"),  # with custom name\n): ...\n```\n\n----------------------------------------\n\nTITLE: Declaring RabbitMQ Queues and Exchanges with FastStream\nDESCRIPTION: This code snippet demonstrates how to declare RabbitMQ queues and exchanges using the RabbitBroker class from FastStream. It shows the process of creating a broker, declaring a queue and an exchange, and then accessing them.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/declare.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker, RabbitExchange, RabbitQueue\n\nbroker = RabbitBroker()\n\n\nasync def main():\n    async with broker:\n        # create a queue\n        queue = RabbitQueue(\"test-queue\")\n        # create an exchange\n        exchange = RabbitExchange(\"test-exchange\")\n\n        # declare queue\n        await broker.declare_queue(queue)\n        # declare exchange\n        await broker.declare_exchange(exchange)\n\n        # access queue\n        test_queue = await broker.declare_queue(queue)\n        # access exchange\n        test_exchange = await broker.declare_exchange(exchange)\n\n        # use test_queue and test_exchange\n        ...\n\n\nif __name__ == \"__main__\":\n    import asyncio\n\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Declaring NATS Direct Subject Handlers in FastStream\nDESCRIPTION: Shows how to declare message handlers for Direct Subjects in NATS using FastStream. It demonstrates subscribing to different subjects and using queue groups for load balancing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/examples/direct.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.handler(\"test_subject\")\nasync def handler():\n...\n```\n\nLANGUAGE: python\nCODE:\n```\n@broker.handler(\"test-subj-1\", \"group-1\")\nasync def handler1(body: str):\n    print(f\"handler1 got: {body}\")\n\n@broker.handler(\"test-subj-1\", \"group-1\")\nasync def handler2(body: str):\n    print(f\"handler2 got: {body}\")\n\n@broker.handler(\"test-subj-2\", \"group-1\")\nasync def handler3(body: str):\n    print(f\"handler3 got: {body}\")\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Confluent Kafka in Python\nDESCRIPTION: Demonstration of publishing a message to a Kafka topic using FastStream with Confluent Kafka. The broker is used as an async context manager.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nasync with KafkaBroker() as br:\n    await br.publish(\"message\", \"topic\")\n```\n\n----------------------------------------\n\nTITLE: Overriding Dependencies with Decorators in Python\nDESCRIPTION: This snippet demonstrates how to use decorators to override dependencies in FastDepends. It shows the use of @override and @injectable decorators to modify the behavior of dependency injection.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/testing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n@app.after_startup\ndef after_startup():\n    return \"Hello World!\"\n\n@app.on_startup\ndef on_startup():\n    return \"Hello World!\"\n\n@app.after_shutdown\ndef after_shutdown():\n    return \"Hello World!\"\n\n@app.on_shutdown\ndef on_shutdown():\n    return \"Hello World!\"\n\n@app.subscriber(\"test\")\nasync def handler():\n    return \"Hello World!\"\n```\n\n----------------------------------------\n\nTITLE: Exposing Prometheus metrics via HTTP endpoint with AIOKafka\nDESCRIPTION: Python code demonstrating how to expose Prometheus metrics via an HTTP endpoint using FastStream's ASGI support with an AIOKafka broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/prometheus.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream.prometheus import PrometheusMiddleware\nfrom prometheus_client import make_asgi_app\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\nprometheus = PrometheusMiddleware()\napp.add_middleware(prometheus)\n\nmetrics_app = make_asgi_app(prometheus.registry)\napp.add_route(\"/metrics\", metrics_app)\n```\n\n----------------------------------------\n\nTITLE: Implementing Concurrent Message Processing in Confluent Kafka\nDESCRIPTION: Example showing how to configure concurrent message processing for Confluent Kafka broker using the max_workers parameter to process up to 10 messages concurrently.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(\"topic\", max_workers=10)\nasync def handler():\n    \"\"\"Using `max_workers` option you can process up to 10 messages by one subscriber concurrently\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining Redis List Batch Subscriber in Python with FastStream\nDESCRIPTION: This snippet shows how to define a subscriber that consumes messages in batches from a Redis list using the FastStream library. It uses the @broker.subscriber decorator with a ListSub object configured for batch processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/batch.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(ListSub(\"test-list\", batch=True))\n```\n\n----------------------------------------\n\nTITLE: Complete Redis Stream Batch Subscriber Implementation in Python\nDESCRIPTION: This code demonstrates a full implementation of a Redis stream batch subscriber using FastStream. It includes the necessary imports, broker setup, subscriber definition, and the main execution block.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/batch.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\n\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom faststream.redis.annotations import StreamSub\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test-stream\", sub=StreamSub(batch=True))\ndef consume_batch(msg: List[str]):\n    print(f\"Received batch: {msg}\")\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Using Context with RabbitMQ in FastStream\nDESCRIPTION: Demonstrates how to access the application context in a FastStream application using RabbitMQ. The example shows how to retrieve the broker and logger objects from the context in a message handler.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.rabbit import RabbitBroker\n\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: RabbitBroker,  # from context\n    logger: Logger,  # from context\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Setting up AsyncAPI documentation with FastStream and FastAPI\nDESCRIPTION: Example configuration for setting up AsyncAPI documentation when using FastStream with FastAPI. The router automatically registers endpoints for hosting AsyncAPI documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/fastapi/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.fastapi import KafkaRouter\n\nrouter = KafkaRouter(\n    ...,\n    schema_url=\"/asyncapi\",\n    include_in_schema=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Batch Publisher in FastStream\nDESCRIPTION: This snippet shows how to create a batch publisher using the @broker.publisher decorator. The batch argument is set to True to enable batch publishing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/batch_publisher.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(\"output_data\", batch=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Kerberos Authentication with SASL GSSAPI in FastStream\nDESCRIPTION: Demonstrates how to configure SASL GSSAPI (Kerberos) authentication with various Kerberos parameters and optional SSL context for Kafka connections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/security.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.security import SASLGSSAPI\nimport ssl\n\nssl_context = ssl.create_default_context()\nsecurity = SASLGSSAPI(\n    principal=\"admin\",\n    service_name=\"service_name\",\n    keytab=\"client.keytab\",\n    ssl_ctx=ssl_context,\n)\n\nbroker = KafkaBroker(\"localhost:9092\", security=security)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry TracerProvider with gRPC Exporter\nDESCRIPTION: Python code to set up the OpenTelemetry TracerProvider with gRPC exporter for sending traces to a collector.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\nresource = Resource.create(attributes={\"service.name\": \"faststream\"})\ntracer_provider = TracerProvider(resource=resource)\ntrace.set_tracer_provider(tracer_provider)\nexporter = OTLPSpanExporter(endpoint=\"http://localhost:4317\")\nprocessor = BatchSpanProcessor(exporter)\ntracer_provider.add_span_processor(processor)\n```\n\n----------------------------------------\n\nTITLE: Integrating AsyncAPI with FastAPI Using Direct Response Method\nDESCRIPTION: Example of integrating AsyncAPI documentation with FastAPI by directly generating the schema and returning an HTML response at a specific endpoint.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/hosting.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import AsyncIterator\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI, responses\nfrom faststream import FastStream\nfrom faststream.asyncapi import get_asyncapi_html, get_app_schema\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber('topic')\nasync def my_handler(msg: str) -> None:\n    print(msg)\n\n@asynccontextmanager\nasync def broker_lifespan(app: FastAPI) -> AsyncIterator[None]:\n    async with broker:\n        await broker.start()\n        yield\n\napp = FastAPI(lifespan=broker_lifespan)\n\n@app.get('/docs/asyncapi')\nasync def asyncapi() -> responses.HTMLResponse:\n    schema = get_app_schema(FastStream(broker))\n    return responses.HTMLResponse(get_asyncapi_html(schema))\n```\n\n----------------------------------------\n\nTITLE: Publishing a Batch of Messages in FastStream\nDESCRIPTION: This snippet demonstrates how to publish a batch of messages by directly calling the publisher with multiple messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/batch_publisher.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nawait output_data_batch.publish(\"msg1\", \"msg2\")\n```\n\n----------------------------------------\n\nTITLE: Creating RedisBroker and FastStream App\nDESCRIPTION: This snippet demonstrates the creation of a RedisBroker instance and wrapping it in a FastStream app. This setup allows for starting the app using CLI later.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/subscription.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbroker = RedisBroker()\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Sending Kafka RPC Request and Handling Response in Python\nDESCRIPTION: This code snippet demonstrates how to send a Kafka RPC request, create a Future object, and wait for the response using FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/rpc.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@app.after_startup\nasync def send_request(\n    responses: Annotated[\n        dict[str, Future[bytes]],\n        Context(\"responses\", initial=dict),\n    ],\n) -> None:\n    correlation_id = str(uuid4())\n    future = responses[correlation_id] = Future[bytes]()\n\n    await broker.publish(\n        \"echo\", \"echo-topic\",\n        reply_to=\"responses\",\n        correlation_id=correlation_id,\n    )\n\n    data: bytes = await future\n    assert data == b\"echo\"  # returned from echo\n```\n\n----------------------------------------\n\nTITLE: Defining Publisher Decorator for AIOKafka in Python\nDESCRIPTION: This code snippet demonstrates how to define a Publisher decorator for AIOKafka in FastStream. It creates a FastKafka app and defines a publish function that sends a message to the 'test' topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/test.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import FastKafka\n\napp = FastKafka()\n\n@app.publisher(\"test\")\nasync def publish(msg: str):\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Message Broadcasting with FastStream Publisher Decorator\nDESCRIPTION: Example of using multiple Publisher Decorators to broadcast a message to multiple output topics in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/decorator.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"in\")\n@broker.publisher(\"first-out\")\n@broker.publisher(\"second-out\")\nasync def handle(msg) -> str:\n    return \"Response\"\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry TracerProvider in Python\nDESCRIPTION: This code snippet sets up the OpenTelemetry TracerProvider with a custom resource for service name identification, which is a crucial step in configuring tracing for FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/tracing.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace import TracerProvider\n\nresource = Resource.create(attributes={\"service.name\": \"faststream\"})\ntracer_provider = TracerProvider(resource=resource)\ntrace.set_tracer_provider(tracer_provider)\n```\n\n----------------------------------------\n\nTITLE: Customizing App Information in FastStream AsyncAPI Documentation\nDESCRIPTION: Enhanced FastStream application with customized title, version, and description for AsyncAPI documentation. The description field supports Markdown formatting.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/getting_started/asyncapi/asyncapi_customization/custom_info.py !}\n```\n\n----------------------------------------\n\nTITLE: Subscribing Consumers to RabbitMQ Header Exchange in Python\nDESCRIPTION: This code snippet illustrates how to subscribe multiple consumers to a Header Exchange using different queues. It shows the setup for four handlers with various header matching criteria.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/headers.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py [ln:26-43] !}\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages to Redis Stream in FastStream\nDESCRIPTION: This code shows how to publish a message to a Redis stream using the broker.publish method.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/groups.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\"Hello, Redis!\", \"test-stream\")\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration with Healthchecks\nDESCRIPTION: This docker-compose.yml file sets up services for RabbitMQ, Redis, Postgres, and the FastStream application. It includes healthchecks for each service and defines dependencies between them.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/healthcheks.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  rabbitmq:\n    image: rabbitmq:3.8-management\n    container_name: rabbitmq-local\n    environment:\n      RABBITMQ_DEFAULT_USER: guest\n      RABBITMQ_DEFAULT_PASS: guest\n    ports:\n      - \"15672:15672\"\n    healthcheck:\n      test: [ \"CMD\", \"rabbitmq-diagnostics\", \"-q\", \"ping\"]\n\n  redis:\n    image: redis:7.2\n    container_name: redis-local\n    healthcheck:\n      test: [ \"CMD\", \"redis-cli\", \"--raw\", \"incr\", \"ping\" ]\n\n  postgres:\n    image: postgres:14\n    container_name: postgres-local\n    environment:\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n    healthcheck:\n      test: [ \"CMD\", \"pg_isready\", \"-U\", \"user\" ]\n\n  app:\n    build: .\n    container_name: app-local\n    command: bash -c \"python main.py\"\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ./main.py:/app/main.py\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/internal/ready\"]\n      interval: 60s\n      timeout: 5s\n      retries: 5\n      start_period: 5s\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n      rabbitmq:\n        condition: service_healthy\n```\n\n----------------------------------------\n\nTITLE: Passing Custom Security Configurations to Kafka Broker in FastStream\nDESCRIPTION: Shows how to provide additional security configurations through the 'config' parameter when creating a Kafka broker, such as specifying custom certificate locations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/security.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.security import SASLPlaintext\n\nsecurity = SASLPlaintext(\n    username=\"admin\",\n    password=\"password\",\n)\n\nconfig = {\"ssl.ca.location\": \"~/my_certs/CRT_cacerts.pem\"}\n\nbroker = KafkaBroker(\"localhost:9092\", security=security, config=config)\n```\n\n----------------------------------------\n\nTITLE: Implementing Response Handler for Kafka RPC in Python\nDESCRIPTION: This code snippet shows how to create a response handler for Kafka RPC requests using FastStream. It maps incoming messages to their requests using the correlation_id field.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/rpc.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom asyncio import Future\nfrom typing import Annotated\n\nfrom faststream import FastStream, Context\nfrom faststream.kafka import KafkaBroker, KafkaMessage\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"responses\")\nasync def response_handler(\n    msg: KafkaMessage,\n    responses: Annotated[\n        dict[str, Future[bytes]],\n        Context(\"responses\", initial=dict),\n    ],\n) -> None:\n    if (future := responses.pop(msg.correlation_id, None)):\n        future.set_result(msg.body)\n```\n\n----------------------------------------\n\nTITLE: Implementing Redis Stream Consumer Groups with FastStream\nDESCRIPTION: This code snippet demonstrates a complete FastStream application that uses Redis Stream Consumer Groups. It includes imports, broker creation, consumer group subscription, and message processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/groups.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\n    \"test-stream\", group=\"test-group\"\n)\nasync def on_message(msg: str):\n    print(f\"Received: {msg}\")\n\n@app.on_startup\nasync def startup():\n    await broker.publish(\"Hello, Redis!\", \"test-stream\")\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages to NATS Direct Subjects\nDESCRIPTION: Demonstrates how to publish messages to different Direct Subjects in NATS using FastStream. This snippet shows the distribution of messages to various handlers based on the subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/examples/direct.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\"1\", \"test-subj-1\")\n```\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\"2\", \"test-subj-1\")\n```\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\"3\", \"test-subj-2\")\n```\n\n----------------------------------------\n\nTITLE: Defining SQLAlchemy Base Model and Database Dependency in FastStream\nDESCRIPTION: This snippet shows how to define a SQLAlchemy Base model and create a dependency function for asynchronous database sessions. The get_db dependency manages the session lifecycle ensuring proper connection handling and cleanup.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nBase = declarative_base()\n\n\nasync def get_db():\n    db = AsyncSessionLocal()\n    try:\n        yield db\n    finally:\n        await db.close()\n```\n\n----------------------------------------\n\nTITLE: Implementing SASL Plaintext Authentication with SSL/TLS in FastStream RabbitMQ\nDESCRIPTION: This code snippet shows how to use the SASLPlaintext object for authentication along with SSL/TLS encryption when creating a RabbitMQ broker in FastStream. It includes setting up both the authentication and SSL context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/security.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.security import SASLPlaintext\nfrom faststream.rabbit import RabbitBroker\n\nssl_context = SSLContext(protocol=PROTOCOL_TLS_CLIENT)\nssl_context.load_verify_locations(\"path/to/ca_certificate.pem\")\n\nsecurity = SASLPlaintext(\n    username=\"user\",\n    password=\"password\",\n    ssl=ssl_context,\n)\n\nbroker = RabbitBroker(\n    \"amqps://rmq.example.com:5671\",\n    security=security,\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Model for Redis Data in Python\nDESCRIPTION: This snippet shows the definition of a Pydantic model named 'Data' which represents the structure of data to be published to Redis lists. It includes 'key' and 'value' fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/publishing.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Data(BaseModel):\n    key: str\n    value: int\n```\n\n----------------------------------------\n\nTITLE: Importing Annotated Aliases for Confluent\nDESCRIPTION: Shows the import statement for all available annotated aliases specific to the Confluent Kafka broker. These provide type hints for broker-specific objects when used as function parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.annotations import (\n    Logger, ContextRepo, KafkaMessage,\n    KafkaBroker, KafkaProducer, NoCast,\n)\n```\n\n----------------------------------------\n\nTITLE: Full Example of Dynamic Config with NATS in FastStream\nDESCRIPTION: This comprehensive example demonstrates the complete setup for dynamic configuration with NATS in FastStream. It includes subscribing to key-value changes, handling filled buy orders, creating sell orders, and initializing the configuration on startup.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/nats/dynaconf.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom uuid import uuid4\n\nfrom faststream import FastStream, Context\nfrom faststream.nats import NatsMessage, NatsBroker, KvWatch\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"create_sell\", kv_watch=KvWatch(\"order_service\"))\nasync def watch_kv_order_service(new_value: bool):\n    app.context.set_global(\"create_sell\", new_value)\n\n@broker.subscriber(\"order_service.order.filled.buy\")\nasync def handle_filled_buy(\n    message: NatsMessage,\n    create_sell: bool = Context(\"create_sell\"),\n):\n    if create_sell:\n        await broker.publish(b\"\", \"order_service.order.create.sell\")\n\n@broker.subscriber(\"order_service.order.create.sell\")\nasync def handle_create_sell(message: NatsMessage): ...\n\n@app.on_startup\nasync def on_startup():\n    await broker.connect()\n\n    order_service_kv = await broker.key_value(\"order_service\")\n\n    initial_create_sell_value = b\"1\"\n    await order_service_kv.put(\"create_sell\", initial_create_sell_value)\n    app.context.set_global(\"create_sell\", bool(initial_create_sell_value))\n\n@app.after_startup\nasync def after_startup():\n    await broker.publish({\"order_id\": str(uuid4())}, \"order_service.order.filled.buy\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Consuming Function for Redis List in Python\nDESCRIPTION: This code demonstrates how to implement a consuming function that handles batches of messages from a Redis list. The function receives a list of messages as its parameter, allowing for efficient batch processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/batch.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(ListSub(\"test-list\", batch=True))\nasync def consume(msg: List[str]):\n    print(f\"Consumed batch: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Registering Multiple Lifecycle Hooks in FastStream\nDESCRIPTION: Example demonstrating how to register multiple startup hooks which will be executed in the order they are registered.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/hooks.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@app.on_startup\ndef first():\n    print(\"First hook called\")\n    return broker\n    \n@app.on_startup\ndef second():\n    print(\"Second hook called\")\n    return broker\n```\n\n----------------------------------------\n\nTITLE: Manual FastStream Application Execution\nDESCRIPTION: Python code snippet demonstrating how to run a FastStream application manually as an async function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nasync def main():\n    app = FastStream(...)\n    await app.run()  # blocking method\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Using pydantic.Field for Message Schema in FastStream\nDESCRIPTION: This snippet demonstrates how to use pydantic.Field as a function default argument to add extra validations and metadata to message schemas in FastStream. It's applicable across various message brokers like AIOKafka, Confluent, RabbitMQ, NATS, and Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/pydantic.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\nfrom pydantic import Field\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test_topic\")\nasync def on_message(\n    msg: str,\n    num: int = Field(\n        42,\n        title=\"Number\",\n        description=\"Some number\",\n        examples=[13, 42, 144],\n    ),\n    logger: Logger\n):\n    logger.info(f\"Num: {num}. Msg: {msg}\")\n\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Configuring NATS Broker with Path Parameter in Python\nDESCRIPTION: Example of setting up a NATS broker with a subscriber using Path parameter for dynamic routing in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import NatsBroker, PullSub\n\nbroker = NastBroker()\n\n@broker.subscriber(\n    \"logs.{level}\",\n    steam=\"test-stream\",\n    pull_sub=PullSub(batch=True),\n)\nasync def base_handler(\n    ...,\n    level: str = Path(),\n):\n  ...\n```\n\n----------------------------------------\n\nTITLE: Implementing TelemetryMiddleware with Confluent Broker\nDESCRIPTION: Example of adding TelemetryMiddleware to a Confluent broker for tracing message processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.confluent import KafkaBroker\nfrom faststream.telemetry import TelemetryMiddleware\n\n# Create broker\nbroker = KafkaBroker(middlewares=[TelemetryMiddleware()])\n\n# Create application\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input\")\nasync def handler_one(msg: str) -> None:\n    return {\"response\": msg}\n```\n\n----------------------------------------\n\nTITLE: Wrapping FastStream Broker for Taskiq Compatibility\nDESCRIPTION: Code snippet showing how to wrap a FastStream broker to make it compatible with Taskiq scheduling.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import BrokerWrapper\n\ntaskiq_broker = BrokerWrapper(broker)\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Context in Exception Handlers in FastStream\nDESCRIPTION: Example showing how to access the consumed message in an exception handler using FastStream's Context feature. This demonstrates the integration with FastDepends serialization mechanism.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/exception.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import ExceptionMiddleware, Context\n\nexc_middleware = ExceptionMiddleware()\n\n@exc_middleware.add_handler(Exception, publish=True)\ndef base_exc_handler(\n    exc: Exception,\n    message = Context(),\n) -> str:\n    print(exc, msg)\n    return \"default\"\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages to Direct Exchange in FastStream\nDESCRIPTION: This snippet shows how to publish messages to a Direct Exchange using FastStream. It demonstrates publishing multiple messages with different routing keys.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/direct.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nawait publisher.publish(\"1\", routing_key=\"test-q-1\")\nawait publisher.publish(\"2\", routing_key=\"test-q-1\")\nawait publisher.publish(\"3\", routing_key=\"test-q-1\")\nawait publisher.publish(\"4\", routing_key=\"test-q-2\")\n```\n\n----------------------------------------\n\nTITLE: Accessing CLI parameters in AIOKafka application\nDESCRIPTION: Python code showing how to access command-line arguments in a FastStream application using AIOKafka.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom faststream.kafka import KafkaBroker, KafkaRouter, FastKafka\n\nrouter = KafkaRouter()\n\n\n@router.subscriber(\"test\")\nasync def handle(msg: str):\n    print(msg)\n\n\nbroker = KafkaBroker()\napp = FastKafka(\n    broker=broker,\n    routers=[router],\n    setup=lambda env: print(\n        f\"env: {env}\"  # env: .env.dev\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing TelemetryMiddleware with NATS Broker\nDESCRIPTION: Example of adding TelemetryMiddleware to a NATS broker for tracing message processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.nats import NatsBroker\nfrom faststream.telemetry import TelemetryMiddleware\n\n# Create broker\nbroker = NatsBroker(middlewares=[TelemetryMiddleware()])\n\n# Create application\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input\")\nasync def handler_one(msg: str) -> None:\n    return {\"response\": msg}\n```\n\n----------------------------------------\n\nTITLE: Creating a KafkaBroker Instance\nDESCRIPTION: Demonstrates how to instantiate a KafkaBroker and wrap it in a FastStream application. This setup allows starting the application through command line interface.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Subscriber/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/confluent/consumes_basics/app.py [ln:15-16] !}\n```\n\n----------------------------------------\n\nTITLE: Using RabbitQueue and RabbitExchange Objects for Publishing in Python\nDESCRIPTION: Shows how to use RabbitQueue and RabbitExchange objects as arguments when publishing messages with RabbitBroker. This approach provides more control over the publishing process.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/publishing.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitExchange, RabbitQueue\n\nawait broker.publish(\n    \"Hi!\",\n    queue=RabbitQueue(\"test\"),\n    exchange=RabbitExchange(\"test\")\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Object Storage Watch with ObjWatch in FastStream\nDESCRIPTION: This snippet demonstrates how to use the ObjWatch object for more detailed settings when watching an Object Storage bucket in FastStream with NATS.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/object.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker, ObjWatch\n\n@broker.subscriber(\n    \"example-bucket\",\n    obj_watch=ObjWatch(declare=False),\n)\nasync def handler(filename: str):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Sanic\nDESCRIPTION: Using FastStream MQBrokers with Sanic by starting and stopping them according to the application's lifespan, allowing for message broker interaction in a Sanic web application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom sanic import Sanic\nfrom sanic.response import json\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = Sanic(\"fast-stream-app\")\n\n\n@broker.subscriber(\"input\")\nasync def handle(msg: str) -> None:\n    print(msg)\n\n\n@app.route(\"/\")\nasync def push(request):\n    await broker.publish(\"Hello World!\", \"input\")\n    return json({\"status\": \"sent\"})\n\n\n@app.before_server_start\nasync def startup(app, loop):\n    # Startup the broker\n    await broker.start()\n\n\n@app.before_server_stop\nasync def shutdown(app, loop):\n    # Shutdown the broker\n    await broker.close()\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Objects by Name in Confluent\nDESCRIPTION: This snippet shows how to access context objects by name in FastStream using Confluent. It demonstrates accessing the entire message object, a specific field, and a dictionary key from the context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/fields.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaMessage\nfrom faststream import FastStream, Context, Logger\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def on_message(\n    msg: str,\n    message: KafkaMessage = Context(),\n    logger: Logger = Context(),\n    topic: str = Context(\"message.topic\"),\n):\n    logger.info(f\"New message in topic: {topic}\")\n    return msg.upper()\n```\n\nLANGUAGE: python\nCODE:\n```\nmessage: KafkaMessage = Context()\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Processing Logic\nDESCRIPTION: Defines the core business logic function that processes incoming messages and returns a response to be published to another topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/publish_example/app.py [ln:22-23] !}\n```\n\n----------------------------------------\n\nTITLE: Catching Exceptions in FastStream TestClient\nDESCRIPTION: Shows how to catch exceptions that occur inside the handler when using TestClient for in-memory testing in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/test.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nasync with TestKafkaBroker(broker) as client:\n    with pytest.raises(ValueError):\n        await client.publish(\n            {\"name\": \"John\", \"user_id\": \"wrong\"},\n            \"test-topic\",\n        )\n```\n\n----------------------------------------\n\nTITLE: Using Context with Redis in FastStream\nDESCRIPTION: Demonstrates how to access the application context in a FastStream application using Redis. The example shows how to retrieve the broker and logger objects from the context in a message handler.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.redis import RedisBroker\n\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: RedisBroker,  # from context\n    logger: Logger,  # from context\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Subscribing Consumers to Topic Exchange in Python\nDESCRIPTION: This code demonstrates how to subscribe multiple consumers to a Topic Exchange using different queues. It shows the implementation of three handler functions, each listening to specific routing patterns.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/topic.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"exchange\", queue=\"queue1\")\nasync def handler1(msg: str):\n    print(f\"Handler 1 received: {msg}\")\n\n@broker.subscriber(\"exchange\", queue=\"queue1\")\nasync def handler2(msg: str):\n    print(f\"Handler 2 received: {msg}\")\n\n@broker.subscriber(\"exchange\", queue=\"queue3\")\nasync def handler3(msg: str):\n    print(f\"Handler 3 received: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Integrating Structlog with FastStream\nDESCRIPTION: Provides a comprehensive example of integrating Structlog, a production-ready logging solution, with FastStream. It includes setting up Structlog and configuring FastStream to use it.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport sys\nimport structlog\n\nshared_processors = (\n    structlog.processors.add_log_level,\n    structlog.processors.StackInfoRenderer(),\n    structlog.dev.set_exc_info,\n    structlog.processors.TimeStamper(fmt=\"iso\"),\n)\n\nif sys.stderr.isatty():\n    # terminal session\n    processors = [\n        *shared_processors,\n        structlog.dev.ConsoleRenderer(),\n    ]\nelse:\n    # Docker container session\n    processors = [\n        *shared_processors,\n        structlog.processors.dict_tracebacks,\n        structlog.processors.JSONRenderer(),\n    ]\n\nstructlog.configure(\n    processors=processors,\n    logger_factory=structlog.PrintLoggerFactory(),\n    cache_logger_on_first_use=False,\n)\n\nlogger = structlog.get_logger()\n```\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nimport structlog\n\nfrom faststream import FastStream, context\nfrom faststream.kafka import KafkaBroker\n\ndef merge_contextvars(\n    logger: structlog.types.WrappedLogger,\n    method_name: str,\n    event_dict: structlog.types.EventDict,\n) -> structlog.types.EventDict:\n    event_dict[\"extra\"] = event_dict.get(\n        \"extra\",\n        context.get_local(\"log_context\") or {},\n    )\n    return event_dict\n\nshared_processors = [\n    merge_contextvars,\n    ...\n]\n\n...\n\nbroker = KafkaBroker(logger=logger, log_level=logging.DEBUG)\napp = FastStream(broker, logger=logger)\n```\n\n----------------------------------------\n\nTITLE: Using Annotated with Context in Confluent\nDESCRIPTION: Shows how to use Python's Annotated feature with FastStream Context in Confluent. This approach is similar to pytest fixtures, allowing for cleaner dependency injection with type hints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nfrom faststream import FastStream, Context, Logger\nfrom faststream.confluent import KafkaBroker\n\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n# inject application object from a Context\nLoggerDep = Annotated[Logger, Context()]\nBrokerDep = Annotated[KafkaBroker, Context()]\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: BrokerDep,  # from context with annotation\n    logger: LoggerDep,  # from context with annotation\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Decoder for Confluent in FastStream\nDESCRIPTION: Defines a custom decoder function for Confluent Kafka messages in FastStream. It specifies the input message type and expected output type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.types import DecodedMessage\nfrom faststream.confluent import KafkaMessage\n\ndef decoder(msg: KafkaMessage) -> DecodedMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Setting Global Context Fields in FastStream\nDESCRIPTION: Shows how to declare application-level context fields using context.set_global method across different message brokers. The example sets a 'secret' global field that can be accessed throughout the application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/custom.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream import context\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\napp = FastStream(broker)\ncontext.set_global(\"secret\", \"my-secret-key\")\napp.run()\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Quart\nDESCRIPTION: Using FastStream MQBrokers with Quart by starting and stopping them according to the application's lifespan, allowing for message broker interaction in a Quart web application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom quart import Quart, jsonify\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = Quart(__name__)\n\n\n@broker.subscriber(\"input\")\nasync def handle(msg: str) -> None:\n    print(msg)\n\n\n@app.route(\"/\")\nasync def push():\n    await broker.publish(\"Hello World!\", \"input\")\n    return jsonify({\"status\": \"sent\"})\n\n\n@app.before_serving\nasync def startup():\n    # Startup the broker\n    await broker.start()\n\n\n@app.after_serving\nasync def shutdown():\n    # Shutdown the broker\n    await broker.close()\n```\n\n----------------------------------------\n\nTITLE: Defining Depends Class in FastStream's Dependency Injection System\nDESCRIPTION: The Depends class is used for declaring dependencies in FastStream applications. It takes a callable dependency and optional parameters that control how the dependency is resolved and injected.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/Depends.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Depends(_AnnotatedAlias, _DocsAliased, metaclass=_DependsMeta):  # noqa: N801\n    \"\"\"Create a dependency.\n\n    Args:\n        dependency: callable dependency that will be injected\n        dependency_name: unique name for current dependency\n            to prevent dependencies duplication\n        use_cache: if True the dependency will be cached and\n            reused within the same request\n        timeout: time limit for dependency evaluation\n\n    \"\"\"\n\n    __slots__ = ()\n\n    def __new__(\n        cls,\n        dependency: Callable[..., Any] = _empty,\n        *,\n        dependency_name: str | None = None,\n        use_cache: bool = True,\n        timeout: float | None = None,\n    ) -> Any:  # pragma: no cover\n        if dependency is _empty:\n            return partial(cls.__new__, cls)\n\n        default_marker: Any = _empty\n        default = default_marker\n\n        # __signature__ is needed for introspection\n        if inspect.isfunction(dependency) or inspect.ismethod(dependency):\n            if hasattr(dependency, \"__faststream_wrapped__\"):\n                original = dependency.__faststream_wrapped__  # type: ignore[attr-defined]\n\n                if hasattr(dependency, \"__signature__\"):\n                    signature = dependency.__signature__  # type: ignore[attr-defined]\n                else:\n                    signature = original.__signature__  # type: ignore[attr-defined]\n\n            else:\n                original = dependency\n\n                try:\n                    signature = inspect.signature(dependency)\n                except ValueError:\n                    signature = None\n\n                if signature and signature.return_annotation is not inspect.Signature.empty:\n                    return_annotation = signature.return_annotation\n                else:\n                    return_annotation = Any\n\n                if isinstance(original, (staticmethod, classmethod, partial)):\n                    obj = original.__func__  # type: ignore[attr-defined]\n                else:\n                    obj = original\n\n                if isinstance(obj, partial):\n                    while isinstance(obj, partial):\n                        obj = obj.func\n\n                    # TODO: perf - cache get_type_hints per function\n                    return_annotation = (  # pragma: no cover\n                        get_type_hints(obj).get(\"return\", Any)\n                    )\n        elif hasattr(dependency, \"__call__\") and not inspect.isclass(dependency):\n            call = dependency.__call__\n\n            original = dependency\n\n            try:\n                signature = inspect.signature(call)\n            except ValueError:  # pragma: no cover\n                signature = None\n\n            if signature and signature.return_annotation is not inspect.Signature.empty:\n                return_annotation = signature.return_annotation\n            else:\n                # TODO: perf - cache get_type_hints per class\n                return_annotation = get_type_hints(call).get(\"return\", Any)\n        elif inspect.isclass(dependency):\n            original = dependency\n\n            try:\n                signature = inspect.signature(dependency.__init__)\n                parameters = dict(signature.parameters)\n                parameters.pop(\"self\", None)\n                signature = signature.replace(parameters=parameters.values())\n            except ValueError:  # pragma: no cover\n                signature = None\n\n            return_annotation = dependency\n        else:  # pragma: no cover\n            original = dependency\n            signature = None\n            return_annotation = Any\n\n        if isinstance(original, partial):\n            has_defaults = False\n            for param_name, param in inspect.signature(  # type: ignore[arg-type]\n                original.func\n            ).parameters.items():\n                if param_name in original.keywords:\n                    has_defaults = True\n\n            if has_defaults:  # pragma: no cover\n                default = original\n                dependency = original.func\n                original = dependency\n\n        origin_dependency = original\n        if hasattr(origin_dependency, \"__faststream_wrapped__\"):\n            origin_dependency = origin_dependency.__faststream_wrapped__  # type: ignore[attr-defined]\n\n        self = super().__new__(\n            cls, _SpecialForm, return_annotation, cls._gen_metadata(original, signature)\n        )\n\n        if dependency_name is None:\n            if isinstance(dependency, partial):\n                dependency_name = _get_dependency_name(dependency.func)\n            else:\n                dependency_name = _get_dependency_name(dependency)\n\n        self.__dependency__ = dependency\n        self.__dependency_name__ = dependency_name\n        self.__use_cache__ = use_cache\n        self.__timeout__ = timeout\n\n        if default is not default_marker:\n            self.default = default  # type: ignore[attr-defined]\n\n        self.__origin__ = dependency  # type: ignore[attr-defined]\n\n        return self\n```\n\n----------------------------------------\n\nTITLE: Integrating AsyncAPI with FastAPI Using ASGI Mount Method\nDESCRIPTION: Example of integrating AsyncAPI documentation with FastAPI by mounting a dedicated ASGI application for serving the documentation at a specific path.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/hosting.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import AsyncIterator\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom faststream import FastStream\nfrom faststream.asgi import make_asyncapi_asgi\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\nfs_app = FastStream(broker)\n\n@broker.subscriber('topic')\nasync def my_handler(msg: str) -> None:\n    print(msg)\n\n@asynccontextmanager\nasync def broker_lifespan(app: FastAPI) -> AsyncIterator[None]:\n    async with broker:\n        await broker.start()\n        yield\n\napp = FastAPI(lifespan=broker_lifespan)\napp.mount(\"/docs/asyncapi\", make_asyncapi_asgi(fs_app))\n```\n\n----------------------------------------\n\nTITLE: Defining ABCBroker Abstract Base Class in Python\nDESCRIPTION: This code snippet defines the ABCBroker abstract base class, which serves as a template for broker implementations in FastStream. It includes abstract methods and properties that derived classes must implement.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/core/abc/ABCBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass ABCBroker(ABC):\n    \"\"\"Abstract base class for broker implementations.\"\"\"\n\n    @abstractmethod\n    def connect(self) -> None:\n        \"\"\"Establish a connection to the broker.\"\"\"\n        ...\n\n    @abstractmethod\n    def disconnect(self) -> None:\n        \"\"\"Close the connection to the broker.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def is_connected(self) -> bool:\n        \"\"\"Check if the broker is currently connected.\"\"\"\n        ...\n\n    @abstractmethod\n    async def publish(self, message: Any, topic: str) -> None:\n        \"\"\"Publish a message to the specified topic.\"\"\"\n        ...\n\n    @abstractmethod\n    async def subscribe(self, topic: str, callback: Callable) -> None:\n        \"\"\"Subscribe to a topic and register a callback function.\"\"\"\n        ...\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL Plaintext Authentication with SSL/TLS in FastStream\nDESCRIPTION: Shows how to set up SASL Plaintext authentication with a username and password for Kafka broker connections with optional SSL context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/security.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.security import SASLPlaintext\nimport ssl\n\nssl_context = ssl.create_default_context()\nsecurity = SASLPlaintext(\n    username=\"admin\",\n    password=\"password\",\n    ssl_ctx=ssl_context,\n)\n\nbroker = KafkaBroker(\"localhost:9092\", security=security)\n```\n\n----------------------------------------\n\nTITLE: Message Attribute Type Definitions\nDESCRIPTION: Type definitions for core message attributes in FastStream, including body content, headers, and message identifiers. These type hints define the expected data types for each message component.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/message/attrs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nbody: bytes\n```\n\nLANGUAGE: python\nCODE:\n```\ndecoded_body: Any\n```\n\nLANGUAGE: python\nCODE:\n```\ncontent_type: str\n```\n\nLANGUAGE: python\nCODE:\n```\nreply_to: str\n```\n\nLANGUAGE: python\nCODE:\n```\nheaders: dict[str, Any]\n```\n\nLANGUAGE: python\nCODE:\n```\npath: dict[str, Any]\n```\n\nLANGUAGE: python\nCODE:\n```\nmessage_id: str\n```\n\nLANGUAGE: python\nCODE:\n```\ncorrelation_id: str\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Confluent in FastStream\nDESCRIPTION: Example of using the Publisher Decorator with Confluent in FastStream. It shows how to subscribe to a topic and publish the processed message to another topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/decorator.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(\"input-topic\")\n@broker.publisher(\"output-topic\")\nasync def on_message(msg: str) -> str:\n    return f\"Processed: {msg}\"\n\nif __name__ == \"__main__\":\n    broker.run()\n```\n\n----------------------------------------\n\nTITLE: Implementing Data Processing and Publishing Function for Redis Stream in Python\nDESCRIPTION: This code defines a function that processes incoming data and publishes it to a Redis Stream. It uses the @broker.publisher and @broker.subscriber decorators to set up the data pipeline.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/publishing.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(\"output-stream\")\n@broker.subscriber(\"input-stream\")\nasync def on_message(msg: InputData):\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Initializing KafkaBroker for Publisher Decorator in Python\nDESCRIPTION: Creates a KafkaBroker instance for use with publisher decorators. This is part of the setup for using decorators in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nbroker = KafkaBroker(\"localhost:9092\")\n```\n\n----------------------------------------\n\nTITLE: Using Context with Regular Functions in FastStream\nDESCRIPTION: Demonstrates how to use FastStream's Context with regular functions using the @apply_types decorator. The context is automatically passed from the event handler to the called function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.utils import apply_types\n\n@apply_types\ndef logger(log: Logger):\n    log.info(\"I got a message!\")\n\n@broker.subscriber(\"test\")\nasync def second_handler(msg: str):\n    logger()  # Logger will be passed from current context!\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Decoder for NATS in FastStream\nDESCRIPTION: Defines a custom decoder function for NATS messages in FastStream. It specifies the input message type and expected output type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.types import DecodedMessage\nfrom faststream.nats import NatsMessage\n\ndef decoder(msg: NatsMessage) -> DecodedMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Registering General Exception Handler with Decorator in FastStream\nDESCRIPTION: Example of registering a general exception handler using the @add_handler decorator. This handler will process all sources of errors but cannot publish default values in response to requests.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/exception.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nexc_middleware = ExceptionMiddleware()\n\n@exc_middleware.add_handler(Exception)\ndef error_handler(exc: Exception) -> None:\n    print(repr(exc))\n```\n\n----------------------------------------\n\nTITLE: Testing Event Hooks with RabbitMQ in FastStream\nDESCRIPTION: This snippet demonstrates how to test lifespan hooks in a FastStream application using RabbitMQ broker. It uses the TestApp context manager to create a test environment that triggers application lifecycle events.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/test.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.rabbit import RabbitBroker\nfrom faststream.rabbit.testing import TestApp\n\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    print(\"started\")\n\n\n@app.on_shutdown\nasync def shutdown():\n    print(\"shutdown\")\n\n\nasync with TestApp(app):\n    # test that application started and `startup()` was called\n    pass\n# test that `shutdown()` was called\n```\n\n----------------------------------------\n\nTITLE: Implementing Msgpack serialization in FastStream\nDESCRIPTION: This code snippet demonstrates how to use Msgpack serialization in a FastStream application, including message encoding and decoding.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, NoCast\nfrom faststream.nats import NatsMessage, NatsBroker\nfrom pydantic import BaseModel\n\nimport msgpack\n\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n\nclass MsgpackMsg(BaseModel):\n    body: NoCast[bytes]\n\n\nclass Person(BaseModel):\n    name: str\n    age: float\n\n\n@broker.subscriber(\"test\", response_model=MsgpackMsg)\nasync def on_message(msg: MsgpackMsg) -> Person:\n    return Person(**msgpack.unpackb(msg.body))\n\n\n@broker.publisher(\"test\")\nasync def publish(msg: Person) -> NatsMessage[MsgpackMsg]:\n    return NatsMessage(MsgpackMsg(body=msgpack.packb(msg.dict())))\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Aiohttp\nDESCRIPTION: Using FastStream MQBrokers with Aiohttp by starting and stopping them according to the application's lifespan, allowing for message broker interaction in an Aiohttp web application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom aiohttp import web\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\n\n\n@broker.subscriber(\"input\")\nasync def handle(msg: str) -> None:\n    print(msg)\n\n\nasync def push(request):\n    await broker.publish(\"Hello World!\", \"input\")\n    return web.json_response({\"status\": \"sent\"})\n\n\nasync def startup(app):\n    # Startup the broker\n    await broker.start()\n\n\nasync def shutdown(app):\n    # Shutdown the broker\n    await broker.close()\n\n\napp = web.Application()\napp.router.add_get(\"/\", push)\napp.on_startup.append(startup)\napp.on_cleanup.append(shutdown)\n\n\nif __name__ == \"__main__\":\n    web.run_app(app)\n```\n\n----------------------------------------\n\nTITLE: Per-Argument Message Serialization in FastStream (AIOKafka)\nDESCRIPTION: Demonstrates per-argument message serialization for AIOKafka in FastStream, allowing multiple arguments with different types to be unpacked from a single message.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/annotation.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle(\n    name: str,\n    user_id: int,\n):\n    print(f\"Got a message! User {name} has id {user_id}\")\n```\n\n----------------------------------------\n\nTITLE: Synchronous Subscription for Kafka with FastStream\nDESCRIPTION: Demonstrates how to create a synchronous Kafka subscriber using FastStream's KafkaBroker. The subscriber function handles messages from a specified topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(\"test\")  # topic name\ndef handle_msg(msg_body):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Creating Publisher Object for Decorator in Python\nDESCRIPTION: Prepares a publisher object to be used as a decorator. This allows for more structured and documented publishing in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\npublisher = broker.publisher(\"output-topic\")\n```\n\n----------------------------------------\n\nTITLE: Per-Argument Message Serialization in FastStream (Confluent)\nDESCRIPTION: Shows per-argument message serialization for Confluent in FastStream, allowing multiple arguments with different types to be unpacked from a single message.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/annotation.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle(\n    name: str,\n    user_id: int,\n):\n    print(f\"Got a message! User {name} has id {user_id}\")\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Objects by Name in RabbitMQ\nDESCRIPTION: This snippet illustrates how to access context objects by name in FastStream using RabbitMQ. It shows how to retrieve the entire message object, access a specific field, and get a dictionary key from the context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/fields.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitMessage\nfrom faststream import FastStream, Context, Logger\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def on_message(\n    msg: str,\n    message: RabbitMessage = Context(),\n    logger: Logger = Context(),\n    routing_key: str = Context(\"message.routing_key\"),\n):\n    logger.info(f\"New message with routing key: {routing_key}\")\n    return msg.upper()\n```\n\nLANGUAGE: python\nCODE:\n```\nmessage: RabbitMessage = Context()\n```\n\n----------------------------------------\n\nTITLE: Using Local Context Scope in FastStream\nDESCRIPTION: Demonstrates how to use context.scope to create a local context that's only available within a specific message processing scope. Includes setting context values and accessing them in nested function calls.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/custom.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream import context\n\nbroker = KafkaBroker()\n\n\nasync def log_request():\n    # access local context value\n    request_id = context.get(\"request_id\")\n    print(f\"Processing request: {request_id}\")\n\n\n@broker.subscriber(\"test\")\nasync def handle_message(body: str):\n    async with context.scope(request_id=\"12345\"):\n        # inside this block `request_id` is available\n        # in the context\n        await log_request()\n    # outside the block `request_id` is not in the context\n    try:\n        request_id = context.get(\"request_id\")\n        print(f\"Request ID: {request_id}\")\n    except KeyError:\n        print(\"request_id not found in context\")\n\n\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Registering Dynamic Subscribers at Runtime\nDESCRIPTION: Example showing how to register new subscribers during runtime with an already-started broker in FastStream 0.5.0rc0.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nsubscriber = broker.subscriber(\"dynamic\")\nsubscriber(handler_method)\n...\nbroker.setup_subscriber(subscriber)\nawait subscriber.start()\n...\nawait subscriber.close()\n```\n\n----------------------------------------\n\nTITLE: Configuring Confluent Kafka Scheduled Task\nDESCRIPTION: Configures a scheduled task to publish messages to a Kafka topic every minute using Confluent Kafka broker. Implements TaskIQ scheduling with cron expression.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/taskiq_broker.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import StreamScheduler\nfrom taskiq.schedule_sources import LabelScheduleSource\n\ntaskiq_broker.task(\n    message={\"user\": \"John\", \"user_id\": 1},\n    topic=\"in-topic\",\n    schedule=[{\n        \"cron\": \"* * * * *\",\n    }],\n)\n\nscheduler = StreamScheduler(\n    broker=taskiq_broker,\n    sources=[LabelScheduleSource(taskiq_broker)],\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring AIOKafka Scheduled Task\nDESCRIPTION: Sets up a scheduled task to publish messages to a Kafka topic every minute using AIOKafka broker. Uses TaskIQ for scheduling with cron expression and StreamScheduler for execution.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/taskiq_broker.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import StreamScheduler\nfrom taskiq.schedule_sources import LabelScheduleSource\n\ntaskiq_broker.task(\n    message={\"user\": \"John\", \"user_id\": 1},\n    topic=\"in-topic\",\n    schedule=[{\n        \"cron\": \"* * * * *\",\n    }],\n)\n\nscheduler = StreamScheduler(\n    broker=taskiq_broker,\n    sources=[LabelScheduleSource(taskiq_broker)],\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing KafkaBroker for Basic Publishing in Python\nDESCRIPTION: Creates a KafkaBroker instance for basic message publishing. This is the first step in setting up a Kafka publishing system using FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nbroker = KafkaBroker(\"localhost:9092\")\n```\n\n----------------------------------------\n\nTITLE: Defining Data Model for Redis Stream Publishing in Python\nDESCRIPTION: This snippet defines a Pydantic BaseModel called 'InputData' for structuring the data to be published to Redis Streams.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/publishing.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass InputData(BaseModel):\n    field1: str\n    field2: int\n    field3: bool\n```\n\n----------------------------------------\n\nTITLE: Defining Redis Stream Subscriber Function\nDESCRIPTION: This snippet defines an asynchronous function that consumes messages from the 'test-stream' Redis stream. It uses the @broker.subscriber decorator to specify the stream key.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/subscription.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test-stream\")\nasync def handle(msg: str):\n    logger.info(msg)\n```\n\n----------------------------------------\n\nTITLE: Using Custom Logger in FastStream\nDESCRIPTION: Shows how to use a custom logger with FastStream by initializing the broker and app with a custom logging.Logger object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom faststream import FastStream\nfrom faststream.rabbit import RabbitBroker\n\nlogger = logging.getLogger(\"my_logger\")\n\nbroker = RabbitBroker(logger=logger)\napp = FastStream(broker, logger=logger)\n```\n\n----------------------------------------\n\nTITLE: FastStream Handler with Correlation ID (Python 3.9+)\nDESCRIPTION: Implements a FastStream message subscriber that extracts correlation ID from message context using native Python type annotations. Uses the built-in types.Annotated for type hints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/message/annotated.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Annotated\nfrom faststream import Context\n\nCorrelationId = Annotated[str, Context(\"message.correlation_id\")]\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    cor_id: CorrelationId,\n):\n    print(cor_id)\n```\n\n----------------------------------------\n\nTITLE: Creating Publisher-Specific Middleware in FastStream\nDESCRIPTION: Example of defining and applying middleware to a specific publisher. This allows customizing the publication process for individual publishing endpoints with targeted middleware functions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nasync def publisher_middleware(\n    call_next: Callable[..., Awaitable[Any]],\n    msg: Any,\n    **options: Any,\n) -> Any:\n    return await call_next(msg, **options)\n\n\n@broker.subscriber(...)\n@broker.publisher(\n    ...,\n    middlewares=[publisher_middleware],\n)\nasync def handler():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Headers Using Context in FastStream (Python)\nDESCRIPTION: This snippet demonstrates how to access a specific header field from a message using the Context class in FastStream. It shows how to retrieve the 'user' header within a subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/message/headers.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    user: str = Context(\"message.headers.user\"),\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Fields in Redis\nDESCRIPTION: Demonstrates how to access existing context fields like broker, context, logger, and message in Redis implementations. The highlighted lines show the import statement and the function that uses these context fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisBroker\n\n# ...\n\n# ...\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: RedisBroker,  # access to the broker\n    context,  # access to the context\n    logger,  # access to the logger\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n```\n\n----------------------------------------\n\nTITLE: Using Depends Class for Dependency Injection in Python\nDESCRIPTION: This code snippet illustrates the use of the Depends class for dependency injection in FastDepends. It shows how to define dependencies and use them in function parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/testing.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Depends\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\ndef get_value():\n    return \"Hello World!\"\n\n@app.subscriber(\"test\")\nasync def handler(value: str = Depends(get_value)):\n    return value\n```\n\n----------------------------------------\n\nTITLE: Creating FastStream Application with RedisBroker in Python\nDESCRIPTION: This code demonstrates how to initialize a FastStream application using the previously instantiated RedisBroker. This sets up the core application structure for Redis operations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/publishing.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Creating Publisher Object with KafkaBroker in Python\nDESCRIPTION: Demonstrates how to create a publisher object using KafkaBroker. This method allows for better AsyncAPI documentation of publishers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npublisher = broker.publisher(\"test_topic\")\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with FastAPI using RabbitMQ StreamRouter\nDESCRIPTION: Using FastStream RabbitMQ StreamRouter with FastAPI, allowing you to declare message handlers with subscriber and publisher decorators. FastStream integrates with FastAPI's dependency and serialization system, supporting Depends, BackgroundTasks, and other FastAPI tools.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom typing import Annotated\n\nfrom fastapi import FastAPI, Depends, BackgroundTasks\nfrom faststream.rabbit.fastapi import RabbitRouter\n\n# Define FastAPI app\napp = FastAPI(title=\"My Service\")\n\n# Define StreamRouter\nrabbit_router = RabbitRouter(\n    \"amqp://guest:guest@localhost:5672/\",\n)\n\n# Define dependency\ndef get_user_id():\n    return \"user1\"\n\n# Define handler\n@rabbit_router.subscriber(\"topic1\")\nasync def consume(\n    msg: dict,\n    tasks: BackgroundTasks,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> None:\n    tasks.add_task(print, f\"Processing message for {user_id}\")\n    await asyncio.sleep(1)\n    print(f\"Message processed: {msg}\")\n\n# Include StreamRouter in FastAPI\napp.include_router(rabbit_router)\n```\n\n----------------------------------------\n\nTITLE: Generating FastStream Project with Cookiecutter\nDESCRIPTION: Command to run cookiecutter and generate a new FastStream project from the template.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncookiecutter https://github.com/ag2ai/cookiecutter-faststream.git\n```\n\n----------------------------------------\n\nTITLE: Per-Argument Message Serialization in FastStream (RabbitMQ)\nDESCRIPTION: Illustrates per-argument message serialization for RabbitMQ in FastStream, allowing multiple arguments with different types to be unpacked from a single message.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/annotation.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle(\n    name: str,\n    user_id: int,\n):\n    print(f\"Got a message! User {name} has id {user_id}\")\n```\n\n----------------------------------------\n\nTITLE: Initiating FastStream Application with RedisBroker in Python\nDESCRIPTION: This code shows how to initiate a FastStream application using the previously created RedisBroker instance.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/publishing.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Aiogram\nDESCRIPTION: This snippet demonstrates how to integrate a FastStream broker with Aiogram, a non-HTTP framework for Telegram bots. It shows proper initialization and cleanup of the broker alongside the bot's dispatcher.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nfrom aiogram import Bot, Dispatcher, Router\nfrom aiogram.filters import Command\nfrom aiogram.types import Message\nfrom faststream.kafka import KafkaBroker\n\nrouter = Router()\nbroker = KafkaBroker()\n\n\nasync def init():\n    await broker.start()\n\n\n@router.message(Command(commands=[\"start\"]))\nasync def start_cmd(message: Message):\n    await message.answer(\n        \"Hello! This is echo bot! Send me any message and I'll send it back!\"\n    )\n\n\n@router.message()\nasync def echo_msg(message: Message):\n    await message.answer(message.text)\n\n\nasync def main() -> None:\n    dp = Dispatcher()\n    dp.include_router(router)\n\n    bot = Bot(\"BOT_TOKEN\")\n    await init()\n    await dp.start_polling(bot)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Serving Django via Starlette Router\nDESCRIPTION: Modified ASGI configuration to serve Django application through Starlette router, which provides better ASGI support and preparation for FastStream integration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# regular Djano stuff\nimport os\n\nfrom django.core.asgi import get_asgi_application\n\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"app.settings\")\n\ndjango_asgi = get_asgi_application()\n\n# Starlette serving\nfrom starlette.applications import Starlette\nfrom starlette.routing import Mount\n\napplication = Starlette(\n    routes=(\n        Mount(\"/\", django_asgi()),  # redirect all requests to Django\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Pattern Data in Kafka Topic Subscription\nDESCRIPTION: This snippet illustrates how to use pattern subscription to encode and access data directly from the topic name. It uses the Path() function to extract the 'level' parameter from the topic pattern.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Path\n\n@broker.subscriber(pattern=\"logs.{level}\")\nasync def base_handler(\n    body: str,\n    level: str = Path(),\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Validating Input with Mock Objects in FastStream TestClient\nDESCRIPTION: Demonstrates how to use mock objects to validate input and call counts when testing FastStream subscribers with TestClient.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/test.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nasync with TestKafkaBroker(broker) as client:\n    await client.publish(\n        {\"name\": \"John\", \"user_id\": 1},\n        \"test-topic\",\n    )\n    handle.mock.assert_called_with({\"name\": \"John\", \"user_id\": 1})\n```\n\n----------------------------------------\n\nTITLE: Implementing Publisher Middleware in FastStream\nDESCRIPTION: Code demonstrating a publisher middleware implementation that can modify outgoing messages. This middleware can be used for custom serialization, compression, or adding metadata to messages before publishing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Callable, Awaitable\n\nfrom faststream import BaseMiddleware\n\nclass MyMiddleware(BaseMiddleware):\n    async def publish_scope(\n        self,\n        call_next: Callable[..., Awaitable[Any]],\n        msg: Any,\n        **options: Any,\n    ) -> Any:\n        return await call_next(msg, **options)\n\n\nBroker(middlewares=[MyMiddleware])\n```\n\n----------------------------------------\n\nTITLE: Defining KafkaRoute Class in FastStream Confluent Kafka Module\nDESCRIPTION: This code snippet defines the KafkaRoute class, which is used for routing messages in a Confluent Kafka setup within the FastStream framework. It includes various attributes and methods for configuring the route.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/KafkaRoute.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.KafkaRoute\n```\n\n----------------------------------------\n\nTITLE: Implementing Asynchronous User Creation in FastStream\nDESCRIPTION: This endpoint handles user creation in the PostgreSQL database. It receives a UserCreate model, creates a new User instance, adds it to the database, commits the transaction, refreshes the model, and returns the created user.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@router.subscriber(\"create_user\")\nasync def create_user(\n    user: UserCreate, db: AsyncSession = Depends(get_db)\n) -> User:\n    db_user = User(name=user.name, email=user.email)\n    db.add(db_user)\n    await db.commit()\n    await db.refresh(db_user)\n    return User.from_orm(db_user)\n```\n\n----------------------------------------\n\nTITLE: Defining User Model with SQLAlchemy ORM in FastStream\nDESCRIPTION: This snippet defines a User model using SQLAlchemy ORM with columns for id, name, email, and registration date. It inherits from the declarative Base class and includes table mapping configuration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String, index=True)\n    email = Column(String, unique=True, index=True)\n    registered_at = Column(DateTime, default=datetime.utcnow)\n```\n\n----------------------------------------\n\nTITLE: Importing Message Type from Confluent\nDESCRIPTION: Shows how to import the KafkaMessage type directly from the confluent module, which is an alias to the annotated version. This provides a shorthand for accessing the message type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaMessage\n```\n\n----------------------------------------\n\nTITLE: Defining Message Structure with Pydantic\nDESCRIPTION: Shows how to define a message structure using Pydantic for automatic message validation and parsing. The HelloWorld class defines the expected structure of messages consumed from the Kafka topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Subscriber/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/confluent/consumes_basics/app.py [ln:7-12] !}\n```\n\n----------------------------------------\n\nTITLE: Wrapping FastStream Application for Taskiq Compatibility\nDESCRIPTION: Code snippet demonstrating how to wrap a FastStream application to preserve AsyncAPI schema and lifespans.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import AppWrapper\n\ntaskiq_broker = AppWrapper(app)\n```\n\n----------------------------------------\n\nTITLE: Publishing Message with Publisher Object in Python\nDESCRIPTION: Shows how to publish a message using a prepared publisher object. This method provides better AsyncAPI documentation for the publishing process.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nawait publisher.publish(\n    \"Hello, World!\",\n    key=\"test_key\",\n    headers={\"X-Custom-Header\": \"value\"},\n    partition=1,\n)\n```\n\n----------------------------------------\n\nTITLE: Serving AsyncAPI Documentation from JSON File\nDESCRIPTION: Command to serve AsyncAPI documentation from a JSON file using FastStream's CLI tool.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/hosting.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nfaststream asyncapi serve asyncapi.json\n```\n\n----------------------------------------\n\nTITLE: Handling Baggage in FastStream Subscribers and Publishers (Python)\nDESCRIPTION: This example shows how to work with baggage at the consumption level using the CurrentBaggage object. It demonstrates accessing, modifying, and clearing baggage across multiple message handlers in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/baggage.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.opentelemetry import CurrentBaggage\n\n@broker.subscriber(\"first\")\n@broker.publisher(\"second\")\nasync def response_handler_first(msg: str, baggage: CurrentBaggage):\n    print(baggage.get_all())  # {'hello': 'world'}\n    baggage.remove(\"hello\")\n    baggage.set(\"user-id\", 1)\n    baggage.set(\"request-id\", \"UUID\")\n    print(baggage.get(\"user-id\"))  # 1\n    return msg\n\n\n@broker.subscriber(\"second\")\n@broker.publisher(\"third\")\nasync def response_handler_second(msg: str, baggage: CurrentBaggage):\n    print(baggage.get_all())  # {'user-id': '1', 'request-id': 'UUID'}\n    baggage.clear()\n    return msg\n\n\n@broker.subscriber(\"third\")\nasync def response_handler_third(msg: str, baggage: CurrentBaggage):\n    print(baggage.get_all())  # {}\n```\n\n----------------------------------------\n\nTITLE: Implementing Timeout Context Manager in Python\nDESCRIPTION: A code example demonstrating how to use the timeout_scope context manager to execute code with a timeout limit. This allows operations to be cancelled if they exceed a specified time duration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/functions/timeout_scope.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\nfrom faststream.utils import timeout_scope\n\n# Run code with a 5 second timeout\nwith timeout_scope(5):\n    # This operation will be interrupted if it takes longer than 5 seconds\n    time.sleep(3)\n    print(\"Operation completed within timeout\")\n\n# Example of handling timeout exceptions\ntry:\n    with timeout_scope(1):\n        time.sleep(2)  # This will exceed the timeout\n        print(\"This won't be printed\")\nexcept TimeoutError:\n    print(\"Operation timed out\")\n```\n\n----------------------------------------\n\nTITLE: Manually Acknowledging Kafka Messages in Python using FastStream\nDESCRIPTION: This code demonstrates how to manually acknowledge or not acknowledge (nack) a Kafka message using the KafkaMessage object from the FastStream context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/ack.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.annotations import KafkaMessage\n\n\n@broker.subscriber(\n    \"test\", group_id=\"group\", auto_commit=False\n)\nasync def base_handler(body: str, msg: KafkaMessage):\n    await msg.ack()\n    # or\n    await msg.nack()\n```\n\n----------------------------------------\n\nTITLE: Generating AsyncAPI Specification in YAML Format\nDESCRIPTION: This shell command generates the AsyncAPI specification for the FastStream application and saves it as a YAML file named 'asyncapi.yaml'. It requires the PyYAML package to be installed.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/export.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nfaststream docs basic:app --output asyncapi.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating FastStream Application with AIOKafka\nDESCRIPTION: Example of creating a basic FastStream application using AIOKafka broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/kafka/basic.py!}\n```\n\n----------------------------------------\n\nTITLE: ASGI Integration with FastStream\nDESCRIPTION: Example showing how to integrate ASGI support with FastStream for documentation, health checks and metrics endpoints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker\nfrom faststream.asgi import AsgiFastStream, make_ping_asgi\n\nfrom prometheus_client import make_asgi_app\nfrom prometheus_client.registry import CollectorRegistry\n\nbroker = NatsBroker()\n\nprometheus_registry = CollectorRegistry()\n\napp = AsgiFastStream(\n    broker,\n    asyncapi_path=\"/docs\",\n    asgi_routes=[\n        (\"/health\", make_ping_asgi(broker, timeout=5.0)),\n        (\"/metrics\", make_asgi_app(registry=prometheus_registry))\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Headers Using Header Class in FastStream (Python)\nDESCRIPTION: This snippet shows an alternative and more convenient way to access message headers using the Header class in FastStream. The Header class is a shortcut to Context with default setup and includes Pydantic validation for header values.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/message/headers.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Header\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    user: str = Header(),\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Creating RedisBroker Instance for Publisher Object\nDESCRIPTION: Initialize a RedisBroker instance to be used for creating a structured publisher object. This approach is recommended for inclusion in AsyncAPI documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/publishing.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbroker = RedisBroker(\"redis://localhost:6379\")\n```\n\n----------------------------------------\n\nTITLE: Per-Argument Message Serialization in FastStream (Redis)\nDESCRIPTION: Shows per-argument message serialization for Redis in FastStream, allowing multiple arguments with different types to be unpacked from a single message.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/annotation.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle(\n    name: str,\n    user_id: int,\n):\n    print(f\"Got a message! User {name} has id {user_id}\")\n```\n\n----------------------------------------\n\nTITLE: Testing FastStream Services with NATS\nDESCRIPTION: Testing a FastStream NATS service using pytest and the TestBroker context manager, which puts the broker into 'testing mode' and redirects functions to InMemory brokers for testing without a running broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nimport asyncio\nimport pytest\nfrom faststream.nats import TestNatsBroker\n\nfrom basic import app, HandleMsg, publish\n\n\n@pytest.mark.asyncio\nasync def test_handle_msg():\n    async with TestNatsBroker(app) as broker:\n        # Publish a message to the input topic\n        await broker.publish({\"message\": \"Hello World!\"}, \"input_data\")\n\n        # Check message has been processed correctly\n        call = broker.get_handler_call(HandleMsg, return_exceptions=True)\n        # or broker.get_by_topic(\"output_data\", return_exceptions=True)\n        assert call[0] == {\"message\": \"Hello World!\", \"processed\": True}\n```\n\n----------------------------------------\n\nTITLE: Configuring NATS Broker with OpenTelemetry Middleware in Python\nDESCRIPTION: Example of setting up a NATS broker with OpenTelemetry middleware in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.nats import NatsBroker\nfrom faststream.nats.opentelemetry import NatsTelemetryMiddleware\n\nbroker = NatsBroker(\n    middlewares=(\n        NatsTelemetryMiddleware(),\n    )\n)\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Parser for AIOKafka in FastStream\nDESCRIPTION: Defines a custom parser function for AIOKafka messages in FastStream. It extracts a custom message_id from headers and creates a KafkaMessage object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom aiokafka import ConsumerRecord\nfrom faststream.kafka import KafkaMessage\n\ndef parser(msg: ConsumerRecord) -> KafkaMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Using Path for Subject Pattern Access in FastStream NATS\nDESCRIPTION: This code demonstrates how to use the Path object to access values from wildcard patterns in NATS subject subscriptions within FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/message.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Path\n\n@broker.subscriber(\"logs.{level}\")\nasync def base_handler(\n    body: str,\n    level: str = Path(),\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Disabling Pydantic Validation in FastStream Kafka Broker\nDESCRIPTION: Shows how to disable Pydantic validation in a FastStream Kafka broker by setting apply_types=False. This affects type casting and disables Depends and Context features.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(apply_types=False)\n\n@broker.subscriber(\"test\")\nasync def handle_msg(msg_body: str):  # just an annotation, has no real effect\n    ...\n```\n\n----------------------------------------\n\nTITLE: Subscribing to a Direct Exchange using FastStream\nDESCRIPTION: This snippet shows how to subscribe to a Direct Exchange in FastStream, which is the default exchange type. It demonstrates the basic syntax for declaring a subscriber.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/direct.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test_queue\", \"test_exchange\")\nasync def handler():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Decoder for Redis in FastStream\nDESCRIPTION: Demonstrates how to create a custom decoder that reuses the original decoder function for Redis messages. It includes type hints for the original decoder callback.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom faststream.types import DecodedMessage\nfrom faststream.redis import RedisMessage\n\nasync def decoder(\n    msg: RedisMessage,\n    original_decoder: Callable[[RedisMessage], Awaitable[DecodedMessage]],\n) -> DecodedMessage:\n    return await original_decoder(msg)\n```\n\n----------------------------------------\n\nTITLE: Basic Django ASGI Configuration\nDESCRIPTION: The default Django ASGI configuration file that sets up the ASGI application for serving Django using an ASGI server like uvicorn.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom django.core.asgi import get_asgi_application\n\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"app.settings\")\n\napplication = get_asgi_application()\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream SourceType Enum in Python\nDESCRIPTION: This code snippet imports and references the SourceType enum from the FastStream broker message module. It's likely used to specify the source of a message in the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/message/SourceType.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.message.SourceType\n```\n\n----------------------------------------\n\nTITLE: Running FastStream App with Specific .env File\nDESCRIPTION: Demonstrates how to run the FastStream application with different .env files for various environments.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nENV=.local.env faststream run serve:app\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaRouter from FastStream\nDESCRIPTION: This code snippet shows how to import the KafkaRouter class from the FastStream Kafka module. It's a crucial first step for using Kafka integration in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/KafkaRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaRouter\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Fields in NATS\nDESCRIPTION: Shows how to access existing context fields like broker, context, logger, and message in NATS implementations. The highlighted lines show the import statement and the function that uses these context fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker\n\n# ...\n\n# ...\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: NatsBroker,  # access to the broker\n    context,  # access to the context\n    logger,  # access to the logger\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Decoder for Confluent in FastStream\nDESCRIPTION: Demonstrates how to create a custom decoder that reuses the original decoder function for Confluent Kafka messages. It includes type hints for the original decoder callback.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom faststream.types import DecodedMessage\nfrom faststream.confluent import KafkaMessage\n\nasync def decoder(\n    msg: KafkaMessage,\n    original_decoder: Callable[[KafkaMessage], Awaitable[DecodedMessage]],\n) -> DecodedMessage:\n    return await original_decoder(msg)\n```\n\n----------------------------------------\n\nTITLE: Implementing Publisher Object with Confluent in Python\nDESCRIPTION: This code snippet shows how to implement the Publisher Object using Confluent in FastStream. It sets up the broker, creates a publisher, and defines a subscriber function that publishes messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/object.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"output\")\n\n@publisher\n@broker.subscriber(\"input\")\nasync def on_message(body: str, logger: Logger):\n    logger.info(f\"Got message: {body}\")\n    return f\"Processed: {body}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring TracerProvider with gRPC Exporter in Python\nDESCRIPTION: Python code to set up the TracerProvider with a gRPC exporter for OpenTelemetry. It creates a resource, sets up the tracer provider, and adds a span processor with the OTLP exporter.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/sentry.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\nresource = Resource.create(attributes={\"service.name\": \"faststream\"})\ntracer_provider = TracerProvider(resource=resource)\ntrace.set_tracer_provider(tracer_provider)\nexporter = OTLPSpanExporter(endpoint=\"http://localhost:4317\")\nprocessor = BatchSpanProcessor(exporter)\ntracer_provider.add_span_processor(processor)\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL OAuth Bearer Authentication with SSL/TLS in FastStream (Python)\nDESCRIPTION: Demonstrates the use of SASLOAuthBearer for authentication using the OAUTHBEARER SASL mechanism. It requires a custom token provider for completing the authentication flow, such as AWS's aws-msk-iam-sasl-signer-python.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/security.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.security import SASLOAuthBearer\nfrom faststream.kafka import KafkaBroker\n\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\n\nbroker = KafkaBroker(\n    \"localhost:9092\",\n    security=SASLOAuthBearer(\n        ssl_context=ssl_context,\n    ),\n    sasl_oauth_token_provider=your_token_provider,\n)\n```\n\n----------------------------------------\n\nTITLE: Suppressing Automatic RPC Responses in FastStream\nDESCRIPTION: This example shows how to use the new no_reply flag to suppress automatic RPC and reply_to responses in FastStream handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"tests\", no_reply=True)\nasync def handler():\n    ....\n\n# will fail with timeout, because there is no automatic response\nmsg = await broker.publish(\"msg\", \"test\", rpc=True)\n```\n\n----------------------------------------\n\nTITLE: Basic Redis Broker Usage in FastStream\nDESCRIPTION: Demonstrates how to set up a basic Redis broker and subscriber in FastStream, including channel, list, and stream subscription options.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\n    channel=\"test\",  # or\n    # list=\"test\",     or\n    # stream=\"test\",\n)\nasync def handle(msg: str, logger: Logger):\n    logger.info(msg)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Propagating Baggage in FastStream (Python)\nDESCRIPTION: This snippet demonstrates how to initialize baggage with key-value pairs and propagate it through headers when publishing a message. It uses the Baggage class from faststream.opentelemetry.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/baggage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.opentelemetry import Baggage\n\nheaders = Baggage({\"hello\": \"world\"}).to_headers()\nawait broker.publish(\"hello\", \"first\", headers=headers)\n```\n\n----------------------------------------\n\nTITLE: Defining Redis List Subscriber Function\nDESCRIPTION: This snippet shows how to create a consumer function that subscribes to a Redis list named \"test-list\". The function is decorated with @broker.subscriber and will be called when a message is pushed to the specified Redis list.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/subscription.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test-list\")\nasync def handle(msg: str):\n    print(f\"Received: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Kafka Pattern Subscription with Path Parameters\nDESCRIPTION: Demonstrates using pattern-based subscriptions in Kafka with path parameter extraction.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Path\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(pattern=\"logs.{level}\")\nasync def base_handler(\n    body: str,\n    level: str = Path(),\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for FastStream Application\nDESCRIPTION: This Dockerfile sets up a Python 3.12 environment, installs necessary dependencies, and copies the main application file for a FastStream application with healthchecks.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/healthcheks.md#2025-04-22_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM python:3.12-slim\n\nRUN apt-get update && apt-get install -y curl\n\nWORKDIR /app\nRUN pip install faststream[rabbit] uvicorn redis asyncpg\nCOPY main.py /app\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Decoder for NATS in FastStream\nDESCRIPTION: Demonstrates how to create a custom decoder that reuses the original decoder function for NATS messages. It includes type hints for the original decoder callback.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom faststream.types import DecodedMessage\nfrom faststream.nats import NatsMessage\n\nasync def decoder(\n    msg: NatsMessage,\n    original_decoder: Callable[[NatsMessage], Awaitable[DecodedMessage]],\n) -> DecodedMessage:\n    return await original_decoder(msg)\n```\n\n----------------------------------------\n\nTITLE: Testing FastAPI StreamRouter with TestClient\nDESCRIPTION: Example of testing a FastAPI application with a StreamRouter using TestClient. The StreamRouter can be mocked for testing purposes using the patch_broker context manager.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/fastapi/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom fastapi.testclient import TestClient\nfrom faststream.kafka.fastapi import KafkaRouter\nfrom faststream.kafka.test import TestKafkaBroker\n\nrouter = KafkaRouter(\"localhost:9092\")\napp = FastAPI(lifespan=router.lifespan_context)\napp.include_router(router)\n\n\n@router.subscriber(\"test_topic\")\nasync def consume(body: str) -> None:\n    print(body)\n\n\ndef test_app():\n    with TestKafkaBroker(router.broker) as test_broker:\n        with TestClient(app) as client:\n            response = client.get(\"/\")\n            assert response.status_code == 200\n```\n\n----------------------------------------\n\nTITLE: Watching and Retrieving Objects from Object Storage in FastStream\nDESCRIPTION: This code shows how to watch for new files in an Object Storage bucket and retrieve their content. It uses the ObjectStorage annotation to access the current bucket.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/object.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.annotations import ObjectStorage\n\n@broker.subscriber(\"example-bucket\", obj_watch=True)\nasync def handler(filename: str, object_storage: ObjectStorage):\n    assert filename == \"file.txt\"\n    \n    obj = await object_storage.get(filename)\n    content = await obj.get_data()\n    \n    assert content == b\"Hello World!\"\n```\n\n----------------------------------------\n\nTITLE: Importing RedisMessage Class from FastStream Redis Module\nDESCRIPTION: This code snippet shows how to import the RedisMessage class from the faststream.redis.message module. It's a key component for working with Redis messages in the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/message/RedisMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.message import RedisMessage\n```\n\n----------------------------------------\n\nTITLE: Basic Redis Channel Subscription in FastStream\nDESCRIPTION: This snippet demonstrates how to create a basic Redis channel subscription using FastStream. It includes importing necessary modules, creating a RedisBroker instance, and defining a message handler function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/subscription.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test\")\nasync def on_message(msg: str, logger):\n    logger.info(f\"Received: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Falcon\nDESCRIPTION: This snippet shows how to integrate a FastStream broker with the Falcon framework. It creates a custom FastStreamComponent that manages the broker's lifecycle within the Falcon application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nfrom falcon.asgi import App\nfrom falcon.asgi.app_helpers import RouteHandler\n\nfrom faststream.kafka import KafkaBroker\n\n\nasync def init():\n    await broker.start()\n\n\nbroker = KafkaBroker()\n\n\nclass FastStreamComponent:\n    def __init__(self, broker):\n        self.broker = broker\n\n    async def process_startup(self, scope, event):\n        await self.broker.start()\n\n    async def process_shutdown(self, scope, event):\n        await self.broker.close()\n\n\nclass HelloResource:\n    async def on_get(self, req, resp):\n        resp.text = json.dumps({\"greeting\": \"Hello, world!\"})\n\n\napp = App(middleware=[FastStreamComponent(broker)])\napp.add_route(\"/\", HelloResource())\n\n\nclass WelcomeHandler(RouteHandler):\n    async def on_get(self, req, resp):\n        resp.text = json.dumps({\"greeting\": \"Welcome!\"})\n\n\nwelcome = WelcomeHandler()\napp.add_route(\"/welcome\", welcome)\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Parser for AIOKafka in FastStream\nDESCRIPTION: Demonstrates how to reuse the original parser function for AIOKafka messages in FastStream, allowing for custom modifications while maintaining original functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom faststream.kafka import ConsumerRecord, KafkaMessage\n\nasync def parser(\n    msg: ConsumerRecord,\n    original_parser: Callable[[ConsumerRecord], Awaitable[KafkaMessage]],\n) -> KafkaMessage:\n    return await original_parser(msg)\n```\n\n----------------------------------------\n\nTITLE: Defining FastStream Handlers for Tracing Example in Python\nDESCRIPTION: This code snippet defines three FastStream handlers that form a chain of message processing, demonstrating how tracing can be applied to track the flow of requests through multiple services.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/tracing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"first\")\n@broker.publisher(\"second\")\nasync def first_handler(msg: str):\n    await asyncio.sleep(0.1)\n    return msg\n\n\n@broker.subscriber(\"second\")\n@broker.publisher(\"third\")\nasync def second_handler(msg: str):\n    await asyncio.sleep(0.05)\n    return msg\n\n\n@broker.subscriber(\"third\")\nasync def third_handler(msg: str):\n    await asyncio.sleep(0.075)\n```\n\n----------------------------------------\n\nTITLE: Installing pydantic-settings Package\nDESCRIPTION: Command to install the pydantic-settings package, which is required for settings management in Pydantic v2.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\npip install pydantic-settings\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Confluent Kafka Broker in Python\nDESCRIPTION: This code shows how to publish messages using a Confluent Kafka broker in FastStream. It sets up a FastStream application, defines a startup event to publish a message, and includes a handler for processing messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/broker.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.confluent import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    await broker.publish(\n        {\"status\": \"Application started!\"},\n        topic=\"some-topic\",\n    )\n\n\n@broker.subscriber(\"some-topic\")\nasync def handler(msg: dict, logger: Logger):\n    logger.info(f\"Received: {msg}\")\n\n\n@app.after_startup\nasync def after_startup():\n    await broker.publish(\n        {\"status\": \"Application ready!\"},\n        topic=\"some-topic\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Using Subscriber Objects in FastStream\nDESCRIPTION: Example showing how to use the new subscriber object returned by broker.subscriber() for message filtering. This is the preferred syntax for filtering messages in FastStream 0.5.0rc0.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nsubscriber = broker.subscriber(\"test\")\n\n@subscriber(filter = lambda msg: msg.content_type == \"application/json\")\nasync def handler(msg: dict[str, Any]):\n    ...\n\n@subscriber()\nasync def handler(msg: dict[str, Any]):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Creating RedisBroker Instance for Redis Stream in Python\nDESCRIPTION: This snippet demonstrates how to create a RedisBroker instance for interacting with Redis Streams using FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/publishing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nbroker = RedisBroker(\"redis://localhost:6379\")\n```\n\n----------------------------------------\n\nTITLE: Retrieving Broker Server Configuration in FastStream AsyncAPI Generation\nDESCRIPTION: The `get_broker_server` function extracts server information from broker configurations, determining the server URL based on the broker type and settings. It handles different broker types including Kafka, RabbitMQ, NATS, Redis, and Pulsar, generating appropriate server URLs based on their connection details.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/generate/get_broker_server.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_broker_server(broker) -> tuple[str, dict[str, Any]]:\n    \"\"\"Get broker server info.\"\"\"\n    broker_class = broker.__class__.__name__\n\n    if broker_class.lower() == \"kafka\":\n        bootstrap_servers = broker._bootstrap_servers\n        if isinstance(bootstrap_servers, list):\n            bootstrap_servers = \",\".join(bootstrap_servers)\n\n        return bootstrap_servers, {\n            \"protocol\": \"kafka\",\n            \"protocolVersion\": \"auto\",\n        }\n    elif broker_class.lower() == \"rabbitmq\":\n        return (\n            f\"{broker._protocol}://{broker._host}:{broker._port}{broker._vhost}\",\n            {\n                \"protocol\": broker._protocol,\n            },\n        )\n    elif broker_class.lower() == \"nats\":\n        return (\n            broker._servers[0] if len(broker._servers) == 1 else str(broker._servers),\n            {\n                \"protocol\": \"nats\",\n            },\n        )\n    elif broker_class.lower() == \"redis\":\n        return (\n            str(broker._dsn),\n            {\n                \"protocol\": \"redis\",\n            },\n        )\n    elif broker_class.lower() == \"pulsar\":\n        return (\n            broker._url,\n            {\n                \"protocol\": \"pulsar\",\n            },\n        )\n\n    raise NotImplementedError(f\"{broker_class} protocol not supported\")\n```\n\n----------------------------------------\n\nTITLE: Complete FastStream Application with Kafka Partition Keys in Python\nDESCRIPTION: A complete FastStream application that consumes messages from an input topic and publishes them to an output topic with partition keys. The example demonstrates how to integrate partition keys into Kafka-based applications for optimized message distribution.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/using_a_key.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom pydantic import BaseModel, Field\n\n\nclass InputData(BaseModel):\n    user_id: str\n    payload: str\n\n\nclass OutputData(BaseModel):\n    user_id: str\n    payload: str\n    processed: bool = Field(default=True)\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@broker.publisher(\"output_data\")\nasync def process_message(message: InputData, publish):\n    # convert the input message to the output format\n    output_message = OutputData(user_id=message.user_id, payload=message.payload)\n    \n    # publish the message with a key\n    await publish(output_message, key=message.user_id)\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Quart\nDESCRIPTION: This code demonstrates how to integrate a FastStream broker with the Quart framework. It uses application startup and shutdown events to manage the broker's lifecycle.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom quart import Quart\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n\napp = Quart(__name__)\n\n\n@app.before_serving\nasync def startup():\n    await broker.start()\n\n\n@app.after_serving\nasync def shutdown():\n    await broker.close()\n\n\n@app.route(\"/\")\nasync def hello():\n    return {\"hello\": \"world\"}\n```\n\n----------------------------------------\n\nTITLE: Initializing FastAPI and NatsRouter in FastStream\nDESCRIPTION: This snippet shows how to initialize a FastAPI application and a NatsRouter for FastStream. It sets up the router with a specific subject prefix and configures the FastAPI app.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# FastAPI setup\napp = FastAPI()\nrouter = NatsRouter(\"postgres_\")\n```\n\n----------------------------------------\n\nTITLE: Accessing RabbitMessage Attributes in FastStream Python\nDESCRIPTION: This snippet demonstrates how to access the correlation_id of a RabbitMessage object in a FastStream subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    msg: RabbitMessage,\n):\n    print(msg.correlation_id)\n```\n\n----------------------------------------\n\nTITLE: Creating a Batch Publisher in FastStream\nDESCRIPTION: This snippet shows how to create a batch publisher using the @broker.publisher decorator with the batch parameter set to True.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/batch_publisher.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(\n    \"output_data\",\n    batch=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Decoder for RabbitMQ in FastStream\nDESCRIPTION: Defines a custom decoder function for RabbitMQ messages in FastStream. It specifies the input message type and expected output type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.types import DecodedMessage\nfrom faststream.rabbit import RabbitMessage\n\ndef decoder(msg: RabbitMessage) -> DecodedMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Model Configuration in Python for FastStream\nDESCRIPTION: This snippet defines a Config class with specific settings for Pydantic models. It enables population by field name, allows arbitrary types, and sets the json_encoders dictionary for custom JSON encoding of datetime objects.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/sub.md#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass Config:\n    populate_by_field_name = True\n    arbitrary_types_allowed = True\n    json_encoders = {\n        datetime: lambda v: v.timestamp()\n    }\n```\n\n----------------------------------------\n\nTITLE: Adding TelemetryMiddleware to AIOKafka Broker in Python\nDESCRIPTION: This code demonstrates how to add TelemetryMiddleware to an AIOKafka broker in FastStream, enabling OpenTelemetry tracing for Kafka-based applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/tracing.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\nfrom faststream.opentelemetry import TelemetryMiddleware\n\nbroker = KafkaBroker(\"localhost:9092\")\nbroker.middlewares.append(TelemetryMiddleware())\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Blacksheep\nDESCRIPTION: This example demonstrates integrating a FastStream broker with the Blacksheep framework. It shows how to connect and disconnect the broker using application lifecycle events.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom blacksheep import Application\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n\napp = Application()\n\n\n@app.on_start\nasync def before_start() -> None:\n    await broker.start()\n\n\n@app.on_stop\nasync def on_stop() -> None:\n    await broker.close()\n\n\n@app.router.get(\"/\")\nasync def home():\n    return \"Hello, World!\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Synchronous Fake Context in Python for FastStream\nDESCRIPTION: This function creates a fake asynchronous context for testing purposes in FastStream. It allows for simulating asynchronous behavior in a synchronous environment, which is useful for unit testing and development.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/functions/sync_fake_context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef sync_fake_context(cm):\n    \"\"\"Create a fake async context for testing purposes.\"\"\"\n    try:\n        yield cm.__enter__()\n    finally:\n        cm.__exit__(None, None, None)\n```\n\n----------------------------------------\n\nTITLE: Manual Message Acknowledgement in NATS Subscriber (Python)\nDESCRIPTION: This code shows how to manually acknowledge, nack, or reject a message in a NATS subscriber by accessing the message object through the Context. This allows for more fine-grained control over message handling.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/ack.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.annotations import NatsMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(body: str, msg: NatsMessage):\n    await msg.ack()\n    # or\n    await msg.nack()\n    # or\n    await msg.reject()\n```\n\n----------------------------------------\n\nTITLE: Setting Initial Values in FastStream Context\nDESCRIPTION: Demonstrates how to set initial values for context fields without using set_global, using the 'initial' option.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/extra.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\nctx = Context(initial={\"number\": 42})\n\nprint(ctx.number)  # 42\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Various Broker Support\nDESCRIPTION: Commands to install FastStream with support for different message brokers like Kafka, RabbitMQ, NATS, and Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install faststream[kafka]\n```\n\nLANGUAGE: sh\nCODE:\n```\npip install faststream[confluent]\n```\n\nLANGUAGE: sh\nCODE:\n```\npip install faststream[rabbit]\n```\n\nLANGUAGE: sh\nCODE:\n```\npip install faststream[nats]\n```\n\nLANGUAGE: sh\nCODE:\n```\npip install faststream[redis]\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with OpenTelemetry Support\nDESCRIPTION: Command to install FastStream with OpenTelemetry dependencies using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\npip install faststream[otel]\n```\n\n----------------------------------------\n\nTITLE: Importing BrokerRouter Class in Python\nDESCRIPTION: This snippet shows how to import the BrokerRouter class from the faststream.broker.router module. The BrokerRouter is likely a key component for routing messages in the FastStream broker system.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/router/BrokerRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.router import BrokerRouter\n```\n\n----------------------------------------\n\nTITLE: Accessing Raw NATS Message in FastStream Subscriber\nDESCRIPTION: This code shows how to access the raw NATS message (nats.aio.msg.Msg) directly from the FastStream NatsMessage wrapper for complete message information.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/message.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom nats.aio.msg import Msg\nfrom faststream.nats import NatsMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(body: str, msg: NatsMessage):\n    raw: Msg = msg.raw_message\n    print(raw)\n```\n\n----------------------------------------\n\nTITLE: Defining LogicSubscriber Class for FastStream Confluent in Python\nDESCRIPTION: This code snippet defines the LogicSubscriber class, which is a part of the FastStream Confluent subscriber module. It inherits from BaseSubscriber and implements methods for handling Kafka message subscriptions and processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/subscriber/usecase/LogicSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass LogicSubscriber(BaseSubscriber):\n    def __init__(\n        self,\n        *args: Any,\n        topic: str = \"\",\n        group_id: str | None = None,\n        auto_offset_reset: Literal[\"earliest\", \"latest\"] = \"earliest\",\n        enable_auto_commit: bool = True,\n        max_poll_interval_ms: int = 300000,\n        **kwargs: Any,\n    ) -> None:\n        super().__init__(*args, **kwargs)\n        self.topic = topic\n        self.group_id = group_id\n        self.auto_offset_reset = auto_offset_reset\n        self.enable_auto_commit = enable_auto_commit\n        self.max_poll_interval_ms = max_poll_interval_ms\n\n    def setup(self) -> None:\n        self.consumer = Consumer(\n            {\n                \"bootstrap.servers\": self.client.bootstrap_servers,\n                \"group.id\": self.group_id or uuid4().hex,\n                \"auto.offset.reset\": self.auto_offset_reset,\n                \"enable.auto.commit\": self.enable_auto_commit,\n                \"max.poll.interval.ms\": self.max_poll_interval_ms,\n            },\n        )\n        self.consumer.subscribe([self.topic])\n\n    async def run(self) -> None:\n        while True:\n            msg = self.consumer.poll(1.0)\n            if msg is None:\n                continue\n            if msg.error():\n                if msg.error().code() == KafkaError._PARTITION_EOF:\n                    # End of partition event\n                    logger.error(\n                        \"%% %s [%d] reached end at offset %d\\n\",\n                        msg.topic(),\n                        msg.partition(),\n                        msg.offset(),\n                    )\n                elif msg.error():\n                    raise KafkaException(msg.error())\n            else:\n                await self.process_message(msg)\n\n    async def process_message(self, msg: Message) -> None:\n        await self.call_handle(msg.value(), msg=msg)\n\n    def __del__(self) -> None:\n        if hasattr(self, \"consumer\"):\n            self.consumer.close()\n```\n\n----------------------------------------\n\nTITLE: Initializing KafkaBroker for Publisher Object in Python\nDESCRIPTION: Creates a KafkaBroker instance for use with publisher objects. This approach allows for better documentation in AsyncAPI.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Publisher/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbroker = KafkaBroker(\"localhost:9092\")\n```\n\n----------------------------------------\n\nTITLE: Deploying FastStream Docker Container\nDESCRIPTION: Commands for pulling and running the Docker image from GitHub Container Registry. Replace <username>, <repo-name>, and /path/to/env-file with appropriate values.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull ghcr.io/<username>/<repo-name>:latest\ndocker run --rm --name faststream-app --env-file /path/to/env-file ghcr.io/<username>/<repo-name>:latest\n```\n\n----------------------------------------\n\nTITLE: NATS Concurrent Subscriber with FastStream\nDESCRIPTION: This example shows how to set up a NATS subscriber with concurrent message processing using FastStream. It allows processing up to 10 messages simultaneously from the same subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream()\n\n@broker.subscriber(\"test-subject\", max_workers=10)\nasync def handler(...):\n   \"\"\"Can process up to 10 messages in the same time.\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing SASL Plaintext Authentication with SSL/TLS in FastStream Redis\nDESCRIPTION: This code snippet illustrates the use of SASLPlaintext object for authentication in SASL plaintext mode, combined with SSL/TLS encryption. It demonstrates how to provide a username and password for authentication while also applying SSL/TLS security to a RedisBroker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/security.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.redis import RedisBroker\nfrom faststream.security import SASLPlaintext\n\nssl_context = ssl.create_default_context()\nredis_security = SASLPlaintext(\n    username=\"your-username\",\n    password=\"your-password\",\n    ssl=ssl_context\n)\n\nbroker = RedisBroker(\"redis://localhost:6379\", security=redis_security)\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Fields in Confluent\nDESCRIPTION: Shows how to access existing context fields like broker, context, logger, and message in Confluent Kafka implementations. The highlighted lines show the import statement and the function that uses these context fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\n\n# ...\n\n# ...\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: KafkaBroker,  # access to the broker\n    context,  # access to the context\n    logger,  # access to the logger\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n```\n\n----------------------------------------\n\nTITLE: Using Kafka Subscriber in Imperative Style\nDESCRIPTION: Demonstrates how to use a Kafka subscriber to get messages imperatively with a timeout.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsubscriber = broker.subscriber(\"in\")\n...\nmsg = await subscriber.get_one(timeout=5.0)\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Scheduled Task\nDESCRIPTION: Implements a scheduled task to publish messages to a Redis channel every minute. Uses TaskIQ scheduler with cron expression for periodic execution.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/taskiq_broker.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import StreamScheduler\nfrom taskiq.schedule_sources import LabelScheduleSource\n\ntaskiq_broker.task(\n    message={\"user\": \"John\", \"user_id\": 1},\n    channel=\"in-channel\",\n    schedule=[{\n        \"cron\": \"* * * * *\",\n    }],\n)\n\nscheduler = StreamScheduler(\n    broker=taskiq_broker,\n    sources=[LabelScheduleSource(taskiq_broker)],\n)\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Parser for Confluent Kafka in FastStream\nDESCRIPTION: Demonstrates how to reuse the original parser function for Confluent Kafka messages in FastStream, allowing for custom modifications while maintaining original functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom confluent_kafka import Message\nfrom types import Callable, Awaitable\nfrom faststream.confluent import KafkaMessage\n\nasync def parser(\n    msg: Message,\n    original_parser: Callable[[Message], Awaitable[KafkaMessage]],\n) -> KafkaMessage:\n    return await original_parser(msg)\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream CLI\nDESCRIPTION: Command to install FastStream CLI with required dependencies.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install faststream[cli]\n```\n\n----------------------------------------\n\nTITLE: Implementing Pull Subscriber with FastStream in Python\nDESCRIPTION: This code snippet demonstrates how to create a Pull Subscriber using FastStream for NATS JetStream. It shows the usage of the `pull_sub` argument to control batch size and block interval for consuming messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/pull.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/nats/js/pull_sub.py !}\n```\n\n----------------------------------------\n\nTITLE: Implementing TelemetryMiddleware with Redis Broker\nDESCRIPTION: Example of adding TelemetryMiddleware to a Redis broker for tracing message processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom faststream.telemetry import TelemetryMiddleware\n\n# Create broker\nbroker = RedisBroker(middlewares=[TelemetryMiddleware()])\n\n# Create application\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input\")\nasync def handler_one(msg: str) -> None:\n    return {\"response\": msg}\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Aiohttp\nDESCRIPTION: This code shows how to integrate a FastStream broker with Aiohttp using application startup and cleanup contexts. The broker is connected during application initialization and properly closed during shutdown.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom aiohttp import web\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n\nasync def init():\n    await broker.start()\n\n\nasync def close():\n    await broker.close()\n\n\nasync def setup_broker(app: web.Application) -> None:\n    app.on_startup.append(lambda _: init())\n    app.on_cleanup.append(lambda _: close())\n\n\nasync def handle(request: web.Request) -> web.Response:\n    return web.Response(text=\"Hello, world\")\n\n\napp = web.Application()\napp.router.add_get(\"/\", handle)\napp.on_startup.append(setup_broker)\n\n\nif __name__ == \"__main__\":\n    web.run_app(app)\n```\n\n----------------------------------------\n\nTITLE: Interrupting Message Processing with AckMessage Exception\nDESCRIPTION: Illustrates how to use the AckMessage exception to immediately interrupt message processing and acknowledge the message. It also shows the usage of NackMessage for preventing acknowledgement.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/ack.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom faststream.exceptions import AckMessage, NackMessage\n\nbroker = RedisBroker(\"redis://localhost:6379\")\napp = FastStream(broker)\n\n@broker.subscriber(\"test-stream\")\nasync def base_handler(body: dict):\n    if body[\"status\"] == \"success\":\n        raise AckMessage()\n    elif body[\"status\"] == \"error\":\n        raise NackMessage()\n\n    # do some work\n    ...\n\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Implementing Multiple Publishers for Message Broadcasting in Python\nDESCRIPTION: This code snippet demonstrates how to use multiple publisher decorators with a single function to broadcast messages to multiple output topics in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/object.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@publisher1\n@publisher2\n@broker.subscriber(\"in\")\nasync def handle(msg) -> str:\n    return \"Response\"\n```\n\n----------------------------------------\n\nTITLE: Importing OperationBinding Class from FastStream AsyncAPI Schema\nDESCRIPTION: This code snippet imports the OperationBinding class from the faststream.asyncapi.schema module. The OperationBinding class is likely used to define and manage operation bindings in AsyncAPI specifications within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/OperationBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.schema.OperationBinding\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Publishers in FastStream\nDESCRIPTION: Function signature for creating Kafka publishers in the FastStream framework. This method is part of the subscriber factory and likely allows for configuring publishers with various options.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/factory/create_publisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ncreate_publisher\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Tests Excluding Broker Dependencies\nDESCRIPTION: Executes tests while excluding those that require specific message brokers (RabbitMQ, Kafka, NATS, Redis, or Confluent), useful when local broker instances aren't available.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npytest -m 'not rabbit and not kafka and not nats and not redis and not confluent'\n```\n\n----------------------------------------\n\nTITLE: Defining Consumer Group Subscription in FastStream\nDESCRIPTION: This snippet demonstrates how to define a subscription to a Redis stream with a specific Consumer Group using the @broker.subscriber decorator.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/groups.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\n    \"test-stream\", group=\"test-group\"\n)\nasync def on_message(msg: str):\n    print(f\"Received: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Customizing Broker Information in FastStream AsyncAPI Documentation\nDESCRIPTION: FastStream application with customized broker description and asyncapi_url. This allows providing meaningful information about the messaging system while concealing sensitive broker URLs.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/getting_started/asyncapi/asyncapi_customization/custom_broker.py !}\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Prefix in FastStream\nDESCRIPTION: This code shows how to publish a message using the Broker Router in FastStream. It highlights the importance of specifying the same prefix used when creating the router.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/routers/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nawait app.publish(\n    \"Hello!\",\n    \"prefix_test\",\n)\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Applications via CLI\nDESCRIPTION: Commands for installing FastStream CLI and running FastStream applications, including options for hot reload and horizontal scaling with multiple workers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\npip install \"faststream[cli]\"\n```\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run basic:app\n```\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run basic:app --reload\n```\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run basic:app --workers 3\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Key-Value Changes in FastStream with NATS\nDESCRIPTION: This snippet shows how to subscribe to changes in a Key-Value storage using FastStream's subscriber decorator. It allows watching for changes to a specific key in the bucket.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/jetstream/key-value.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"key\", kv_watch=\"bucket\")\nasync def handler(msg: str):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Decoder for Redis in FastStream\nDESCRIPTION: Defines a custom decoder function for Redis messages in FastStream. It specifies the input message type and expected output type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.types import DecodedMessage\nfrom faststream.redis import RedisMessage\n\ndef decoder(msg: RedisMessage) -> DecodedMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring confluent-kafka-python Settings in FastStream\nDESCRIPTION: Example showing how to pass additional configuration parameters to the confluent-kafka-python client via FastStream's config parameter. This particular example modifies the topic.metadata.refresh.fast.interval.ms setting to 300ms instead of the default 100ms.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/additional-configuration.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/confluent/additional_config/app.py !}\n```\n\n----------------------------------------\n\nTITLE: Accessing Global Context Fields in FastStream\nDESCRIPTION: Demonstrates how to access a global context field within a message handler. The example retrieves the previously set 'secret' field from the context inside a Kafka handler function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/custom.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(\"test\")\nasync def handle_message(body: str):\n    # access global context value\n    secret = context.get_global(\"secret\")\n    print(f\"Secret from global context: {secret}\")\n```\n\n----------------------------------------\n\nTITLE: Creating RedisBroker and FastStream App\nDESCRIPTION: This code creates a RedisBroker instance and initializes a FastStream application with it.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/groups.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbroker = RedisBroker()\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Parser for NATS in FastStream\nDESCRIPTION: Demonstrates how to reuse the original parser function for NATS messages in FastStream, allowing for custom modifications while maintaining original functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom nats.aio.msg import Msg\nfrom faststream.nats import NatsMessage\n\nasync def parser(\n    msg: Msg,\n    original_parser: Callable[[Msg], Awaitable[NatsMessage]],\n) -> NatsMessage:\n    return await original_parser(msg)\n```\n\n----------------------------------------\n\nTITLE: Sample .env File Content\nDESCRIPTION: Example content of a .env file containing environment variables for URL and QUEUE settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nURL=\"amqp://guest:guest@localhost:5672\"\nQUEUE=\"test-queue\"\n```\n\n----------------------------------------\n\nTITLE: Running Asynchronous Functions in Python with run_async Utility\nDESCRIPTION: The run_async function provides a versatile way to execute asynchronous functions in different contexts. It can handle coroutines, check if they're already running in an event loop, and properly manage the event loop lifecycle based on the execution environment.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/functions/call_or_await.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef run_async(coroutine: Coroutine[Any, Any, T]) -> T:\n    \"\"\"Run coroutine in current or newly created event loop.\n\n    Args:\n        coroutine: Coroutine to run.\n\n    Returns:\n        Result of the coroutine execution.\n    \"\"\"\n    try:\n        loop = asyncio.get_running_loop()\n    except RuntimeError:\n        loop = asyncio.new_event_loop()\n        return loop.run_until_complete(coroutine)\n    else:\n        if loop.is_running():\n            return loop.create_task(coroutine)\n        else:\n            return loop.run_until_complete(coroutine)\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Decoder for RabbitMQ in FastStream\nDESCRIPTION: Demonstrates how to create a custom decoder that reuses the original decoder function for RabbitMQ messages. It includes type hints for the original decoder callback.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom faststream.types import DecodedMessage\nfrom faststream.rabbit import RabbitMessage\n\nasync def decoder(\n    msg: RabbitMessage,\n    original_decoder: Callable[[RabbitMessage], Awaitable[DecodedMessage]],\n) -> DecodedMessage:\n    return await original_decoder(msg)\n```\n\n----------------------------------------\n\nTITLE: Generating Python classes from Protobuf schema\nDESCRIPTION: This command generates Python classes from the Protobuf schema file for use in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_2\n\nLANGUAGE: console\nCODE:\n```\npython -m grpc_tools.protoc --python_out=. --pyi_out=. -I . message.proto\n```\n\n----------------------------------------\n\nTITLE: Accessing Specific Redis Message Fields in FastStream Python\nDESCRIPTION: This snippet shows how to access specific fields of a Redis message, such as headers, using the Context object in a FastStream subscriber function. This approach reduces boilerplate code.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/message.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test-stream\")\nasync def stream_handler(\n    msg: str,\n    headers: AnyDict = Context(\"message.headers\"),\n):\n    print(headers)\n```\n\n----------------------------------------\n\nTITLE: Creating Settings Object with Pydantic v1\nDESCRIPTION: Defines a Settings class using Pydantic v1, which imports BaseSettings directly from pydantic. This class declares attributes for app configuration with type annotations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseSettings\n\n\nclass Settings(BaseSettings):\n    app_name: str = \"Awesome API\"\n    items_per_user: int = 50\n\n\nsettings = Settings()\n```\n\n----------------------------------------\n\nTITLE: Importing EndpointProto from FastStream Broker Protocol\nDESCRIPTION: This code snippet imports the EndpointProto class from the FastStream broker protocol module. It is likely used to define or document the structure of communication endpoints in the FastStream messaging system.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/proto/EndpointProto.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.proto.EndpointProto\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Decorator in Python\nDESCRIPTION: This code snippet references a specific FastStream decorator used for marking FastAPI dependents. It imports the 'mark_faststream_decorated' function from the 'faststream.broker.fastapi.get_dependant' module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/get_dependant/mark_faststream_decorated.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.fastapi.get_dependant.mark_faststream_decorated\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with NATS Broker in Python\nDESCRIPTION: This code demonstrates how to publish messages using a NATS broker in FastStream. It sets up a FastStream application, defines a startup event to publish a message, and includes a handler for processing messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/broker.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    await broker.publish(\n        {\"status\": \"Application started!\"},\n        subject=\"some-subject\",\n    )\n\n\n@broker.subscriber(\"some-subject\")\nasync def handler(msg: dict, logger: Logger):\n    logger.info(f\"Received: {msg}\")\n\n\n@app.after_startup\nasync def after_startup():\n    await broker.publish(\n        {\"status\": \"Application ready!\"},\n        subject=\"some-subject\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Accessing Broker Logger in FastStream Handlers\nDESCRIPTION: Shows how to access the broker logger directly from the context within FastStream handler functions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Logger\n\n@broker.subscriber(...)\nasync def handler(\n    msg,\n    logger: Logger,  # <-- YOUR logger here\n):\n    logger.info(msg)\n```\n\n----------------------------------------\n\nTITLE: Logging Requests with FastStream Broker in Python\nDESCRIPTION: Demonstrates how to log requests using the broker's access_logger, which is available from the Context of the application. This approach includes the request context and message ID in the logs.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Logger\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker()\n\n@broker.subscriber(\"test\")\nasync def func(logger: Logger):\n    logger.info(\"message received\")\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream and RedisBroker\nDESCRIPTION: This snippet shows how to import the necessary modules from FastStream to create a Redis subscriber. It imports the FastStream base app and RedisBroker for Redis-specific functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/subscription.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n```\n\n----------------------------------------\n\nTITLE: Importing SubscriberRoute Class from FastStream Broker Router\nDESCRIPTION: This code snippet demonstrates how to import the SubscriberRoute class from the faststream.broker.router module. It's a key component for setting up subscriber routes in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/router/SubscriberRoute.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.router import SubscriberRoute\n```\n\n----------------------------------------\n\nTITLE: Using Context with Confluent in FastStream\nDESCRIPTION: Demonstrates how to access the application context in a FastStream application using Confluent. The example shows how to retrieve the broker and logger objects from the context in a message handler.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.confluent import KafkaBroker\n\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: KafkaBroker,  # from context\n    logger: Logger,  # from context\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Defining Context Class in FastStream Framework\nDESCRIPTION: The Context class is a core component of FastStream for managing context-bound variables, tracing, and logging state. It includes attributes for correlation IDs, tracing, context variables, and application state.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/Context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Context:\n    \"\"\"FastStream Context state.\n\n    It contains the current state of context variables, tracing and logging.\n    \"\"\"\n\n    correlation_id: str | None = None\n    \"\"\"Message correlation ID\"\"\"\n\n    extras: Dict[str, Any] = Field(default_factory=dict)\n    \"\"\"Context variables\"\"\"\n\n    call_next_hooks: bool = True\n    \"\"\"Call next hooks flag\"\"\"\n\n    call_next_watcher: bool = True\n    \"\"\"Call next watcher flag\"\"\"\n\n    scope: Dict[str, Any] = Field(default_factory=dict)\n    \"\"\"FastDepends scope\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with FastAPI using NATS StreamRouter\nDESCRIPTION: Using FastStream NATS StreamRouter with FastAPI, allowing you to declare message handlers with subscriber and publisher decorators. FastStream integrates with FastAPI's dependency and serialization system, supporting Depends, BackgroundTasks, and other FastAPI tools.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom typing import Annotated\n\nfrom fastapi import FastAPI, Depends, BackgroundTasks\nfrom faststream.nats.fastapi import NatsRouter\n\n# Define FastAPI app\napp = FastAPI(title=\"My Service\")\n\n# Define StreamRouter\nnats_router = NatsRouter(\n    \"nats://localhost:4222\",\n)\n\n# Define dependency\ndef get_user_id():\n    return \"user1\"\n\n# Define handler\n@nats_router.subscriber(\"topic1\")\nasync def consume(\n    msg: dict,\n    tasks: BackgroundTasks,\n    user_id: Annotated[str, Depends(get_user_id)],\n) -> None:\n    tasks.add_task(print, f\"Processing message for {user_id}\")\n    await asyncio.sleep(1)\n    print(f\"Message processed: {msg}\")\n\n# Include StreamRouter in FastAPI\napp.include_router(nats_router)\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Objects by Name in NATS\nDESCRIPTION: This snippet demonstrates how to access context objects by name in FastStream using NATS. It shows accessing the entire message object, a specific field, and a dictionary key from the context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/fields.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsMessage\nfrom faststream import FastStream, Context, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def on_message(\n    msg: str,\n    message: NatsMessage = Context(),\n    logger: Logger = Context(),\n    subject: str = Context(\"message.subject\"),\n):\n    logger.info(f\"New message in subject: {subject}\")\n    return msg.upper()\n```\n\nLANGUAGE: python\nCODE:\n```\nmessage: NatsMessage = Context()\n```\n\n----------------------------------------\n\nTITLE: Configuring SASL SCRAM-SHA-256 Authentication with SSL/TLS in FastStream (Python)\nDESCRIPTION: Demonstrates the use of SASLScram256 object for authentication using the Salted Challenge Response Authentication Mechanism (SCRAM) with SHA-256. It includes SSL/TLS configuration for secure communication.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/security.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\nfrom faststream.security import SASLScram256\nfrom faststream.kafka import KafkaBroker\n\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\n\nbroker = KafkaBroker(\n    \"localhost:9092\",\n    security=SASLScram256(\n        username=\"user\",\n        password=\"password\",\n        ssl_context=ssl_context,\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring RabbitMQ Scheduled Task\nDESCRIPTION: Implements a scheduled task to publish messages to a RabbitMQ queue every minute. Uses TaskIQ scheduler with cron expression for timing control.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/taskiq_broker.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import StreamScheduler\nfrom taskiq.schedule_sources import LabelScheduleSource\n\ntaskiq_broker.task(\n    message={\"user\": \"John\", \"user_id\": 1},\n    queue=\"in-queue\",\n    schedule=[{\n        \"cron\": \"* * * * *\",\n    }],\n)\n\nscheduler = StreamScheduler(\n    broker=taskiq_broker,\n    sources=[LabelScheduleSource(taskiq_broker)],\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Message Type from Redis\nDESCRIPTION: Shows how to import the RedisMessage type directly from the redis module, which is an alias to the annotated version. This provides a shorthand for accessing the message type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisMessage\n```\n\n----------------------------------------\n\nTITLE: Using TestApp Class for Testing FastStream Applications in Python\nDESCRIPTION: The TestApp class provides utilities for testing FastStream applications by simulating message publishing and consumption. It inherits from AsyncTestClient and implements methods for publishing messages, consuming them, and testing the application behavior.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/TestApp.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass TestApp(AsyncTestClient):\n    \"\"\"TestApp is a test client for the FastStream application.\n\n    It provides methods for publishing messages to the application and consuming\n    messages from it.\n\n    ### Example\n\n    ```python\n    from faststream.kafka import KafkaBroker\n\n    broker = KafkaBroker()\n\n\n    @broker.subscriber(\"test\")\n    async def base_handler(body: str):\n        return body\n\n\n    @broker.publisher(\"test-response\")\n    @broker.subscriber(\"test-request\")\n    async def publisher_handler(body: str, write=...):\n        response = await write(body)\n        return response\n\n\n    app = broker.app\n\n    # testing\n    from faststream.testing import TestApp\n\n    async def test_app():\n        async with TestApp(app) as client:\n            # test subscriber\n            response = await client.publish(\"hello\", \"test\")\n            assert response == [{\"payload\": \"hello\", \"handler\": base_handler}]\n\n            # test publisher\n            response = await client.publish(\"hello\", \"test-request\")\n            assert response == [{\"payload\": \"hello\", \"handler\": publisher_handler}]\n            assert client.history == [{\"to\": \"test-response\", \"message\": \"hello\"}]\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        app: _AppType,\n        include_in_schema: bool = True,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize a FastStream app for testing.\n\n        Args:\n            app: A FastStream app to test\n            include_in_schema: Whether to include the app in the OpenAPI schema\n            **kwargs: Additional arguments to pass to AsyncClient\n        \"\"\"\n        if \"debug\" not in kwargs:\n            kwargs[\"debug\"] = True\n\n        super().__init__(\n            app=app,\n            include_in_schema=include_in_schema,\n            **kwargs,\n        )\n```\n\n----------------------------------------\n\nTITLE: Initializing Exception Middleware in FastStream\nDESCRIPTION: Basic setup of the ExceptionMiddleware in FastStream. The middleware is created and then added to a Broker instance through the middlewares parameter.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/exception.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import ExceptionMiddleware\n\nexception_middleware = ExceptionMiddleware()\n\nBroker(middlewares=[exception_middleware])\n```\n\n----------------------------------------\n\nTITLE: Accessing Raw Message in FastStream Python\nDESCRIPTION: This code shows how to access the raw aio_pika.IncomingMessage object from a RabbitMessage in FastStream for complete message information.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/message.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom aio_pika import IncomingMessage\nfrom faststream.rabbit import RabbitMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(body: str, msg: RabbitMessage):\n    raw: IncomingMessage = msg.raw_message\n    print(raw)\n```\n\n----------------------------------------\n\nTITLE: Setting Log Level in FastStream CLI\nDESCRIPTION: This function sets the log level for FastStream CLI utilities. It takes a log level as an argument and configures the logging system accordingly. The function is part of the faststream.cli.utils.logs module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/logs/set_log_level.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.cli.utils.logs.set_log_level\n```\n\n----------------------------------------\n\nTITLE: Accessing Specific Message Fields in FastStream Python\nDESCRIPTION: This example shows how to access specific fields of a message, such as headers, using the Context Fields feature in FastStream. It demonstrates a more targeted approach to retrieving message metadata.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/message.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    headers: str = Context(\"message.headers\"),\n):\n    print(headers)\n```\n\n----------------------------------------\n\nTITLE: Using Publisher Objects in FastStream Routers\nDESCRIPTION: Example demonstrating how to use the publisher object returned by router.publisher() for later use after broker startup.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_29\n\nLANGUAGE: python\nCODE:\n```\npublisher = router.publisher(\"test\")\n\n@router.subscriber(\"in\")\nasync def handler():\n    await publisher.publish(\"msg\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Logger Format in FastStream\nDESCRIPTION: The set_logger_fmt function allows setting custom logging formats for different environments (development, production). It configures the logger with specific colors, date formats and patterns based on the environment.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/log/logging/set_logger_fmt.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef set_logger_fmt(fmt: str | None = None, scope: str = \"app\", level: int | None = None) -> None:\n    \"\"\"Set logging format.\n\n    `fmt`'s default value is set depending on the environment.\n    If `env(ENV_PREFIX + \"ENV\")` is set to \"development\" (case-insensitive),\n    the default value is `LOG_DEV_FMT`. Otherwise, the default value\n    is `LOG_PROD_FMT`.\n\n    Args:\n        fmt (str | None): logging format. Defaults to None.\n        scope (str, optional): logging scope. Defaults to \"app\".\n        level (int | None, optional): logging level. Defaults to None.\n    \"\"\"\n    import logging\n    import os\n    import sys\n\n    from colorlog import ColoredFormatter\n\n    from faststream.log.formatters import JSONFormatter\n\n    if not fmt:\n        fmt = _get_logging_config()[\"fmt\"]\n\n    handler = logging.StreamHandler(sys.stdout)\n\n    if fmt == LOG_DEV_FMT:\n        handler.setFormatter(\n            ColoredFormatter(\n                \"%(bold_white)s%(name)-30.30s%(reset)s | \"\n                \"%(log_color)s%(levelname)-8.8s%(reset)s | \"\n                \"%(bold_blue)s%(filename)s:%(lineno)d%(reset)s | \"\n                \"%(log_color)s%(message)s%(reset)s\",\n                log_colors={\n                    \"DEBUG\": \"thin\",\n                    \"INFO\": \"bold_green\",\n                    \"WARNING\": \"bold_yellow\",\n                    \"ERROR\": \"bold_red\",\n                    \"CRITICAL\": \"bold_red,bg_white\",\n                },\n            )\n        )\n    elif fmt == LOG_JSON_FMT:\n        handler.setFormatter(JSONFormatter())\n    else:\n        handler.setFormatter(logging.Formatter(fmt))\n\n    if level is None:\n        level = _get_logging_config()[\"level\"]\n\n    for cur_handler in logging.getLogger(scope).handlers:\n        logging.getLogger(scope).removeHandler(cur_handler)\n\n    logging.getLogger(scope).setLevel(level)\n    logging.getLogger(scope).addHandler(handler)\n```\n\n----------------------------------------\n\nTITLE: Importing ProducerProto Class from FastStream\nDESCRIPTION: This code snippet demonstrates how to import the ProducerProto class from the FastStream broker publisher module. It's used to access the producer protocol functionality in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/publisher/proto/ProducerProto.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.publisher.proto import ProducerProto\n```\n\n----------------------------------------\n\nTITLE: Defining Metadata in Markdown\nDESCRIPTION: This snippet defines metadata for the documentation page, including search boost and various version numbers for API, release, contributing, and template.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/subscription/Unsubscriptable.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Type Casting in Dependencies\nDESCRIPTION: Illustrates how type casting works with dependencies in FastStream, including double casting behavior.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Depends, apply_types\n\ndef simple_dependency(a: int, b: int = 3) -> str:\n    return a + b  # 'return' is cast to `str` for the first time\n\n@apply_types\ndef method(a: int, d: int = Depends(simple_dependency)):\n    # 'd' is cast to `int` for the second time\n    return a + d\n\nassert method(\"1\") == 5\n```\n\n----------------------------------------\n\nTITLE: Defining TopicPartition Class in FastStream Confluent Module (Python)\nDESCRIPTION: This code snippet defines the TopicPartition class, which represents a topic partition in a Confluent Kafka implementation. It likely includes properties for the topic name and partition number, and may have methods for partition management.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/TopicPartition.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.TopicPartition\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream and RedisBroker\nDESCRIPTION: This snippet shows the necessary imports to use FastStream and RedisBroker for creating a Redis stream subscriber.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/subscription.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n```\n\n----------------------------------------\n\nTITLE: Accessing CLI parameters in Confluent application\nDESCRIPTION: Python code showing how to access command-line arguments in a FastStream application using Confluent Kafka.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom faststream.confluent import KafkaBroker, KafkaRouter, FastKafka\n\nrouter = KafkaRouter()\n\n\n@router.subscriber(\"test\")\nasync def handle(msg: str):\n    print(msg)\n\n\nbroker = KafkaBroker()\napp = FastKafka(\n    broker=broker,\n    routers=[router],\n    setup=lambda env: print(\n        f\"env: {env}\"  # env: .env.dev\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Importing TestRedisBroker from FastStream Redis Module\nDESCRIPTION: This code snippet demonstrates how to import the TestRedisBroker class from the faststream.redis module. It's used to access the TestRedisBroker functionality for testing Redis-based message brokers in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/TestRedisBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import TestRedisBroker\n```\n\n----------------------------------------\n\nTITLE: Testing Event Hooks with Redis in FastStream\nDESCRIPTION: This snippet demonstrates how to test lifespan hooks in a FastStream application using Redis broker. It illustrates the use of TestApp context manager for triggering and testing application lifecycle events.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/test.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\nfrom faststream.redis.testing import TestApp\n\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    print(\"started\")\n\n\n@app.on_shutdown\nasync def shutdown():\n    print(\"shutdown\")\n\n\nasync with TestApp(app):\n    # test that application started and `startup()` was called\n    pass\n# test that `shutdown()` was called\n```\n\n----------------------------------------\n\nTITLE: Adding PrometheusMiddleware to AIOKafka broker\nDESCRIPTION: Python code snippet showing how to add PrometheusMiddleware to an AIOKafka broker in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/prometheus.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream.prometheus import PrometheusMiddleware\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\nprometheus = PrometheusMiddleware()\napp.add_middleware(prometheus)\n```\n\n----------------------------------------\n\nTITLE: Publishing Message using Prepared Publisher Object\nDESCRIPTION: Publish a message using the 'publish' method of the prepared publisher object. This method provides a more structured way to send messages to specific Redis channels.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/publishing.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nawait publish(\"Hello, Redis!\")\n```\n\n----------------------------------------\n\nTITLE: Using Annotated Aliases in NATS\nDESCRIPTION: Demonstrates how to use annotated aliases for accessing context objects in NATS with proper typing. This approach provides more explicit type hints for the context objects being accessed.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker\nfrom faststream.nats.annotations import (\n    NatsMessage,\n    NatsBroker,\n    NatsProducer,\n    Logger,\n    ContextRepo,\n)\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: NatsBroker,  # access to the broker\n    context: ContextRepo,  # access to the context\n    logger: Logger,  # access to the logger\n    message: NatsMessage,  # access to the raw message\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n\n    # access to message properties\n    print(message.reply)\n```\n\n----------------------------------------\n\nTITLE: Setting Broker Log Level in FastStream\nDESCRIPTION: Shows how to set the log level for the broker to control the level of logs published by FastStream without disabling logging completely.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom faststream.rabbit import RabbitBroker\n\n# Sets the broker logs to the DEBUG level\nbroker = RabbitBroker(log_level=logging.DEBUG)\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages to Redis List in Python\nDESCRIPTION: This method publishes a batch of messages to a Redis list. It takes the list name and a sequence of messages as parameters, then uses the Redis pipeline to efficiently push all messages to the list.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/publisher/usecase/ListBatchPublisher.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nasync def publish(self, list_name: str, messages: Sequence[Any]) -> None:\n    async with self.client.pipeline(transaction=False) as pipe:\n        for message in messages:\n            await pipe.lpush(list_name, message)\n        await pipe.execute()\n```\n\n----------------------------------------\n\nTITLE: Parsing NATS Security Credentials in FastStream\nDESCRIPTION: The parse_security function is used to process NATS security credentials from various sources including files, dictionaries, and predefined NATSCredentials objects. It validates input types and returns properly formatted security credentials for NATS connections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/security/parse_security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef parse_security(\n    security: Union[Dict[str, str], str, NATSCredentials, None],\n) -> Optional[NATSCredentials]:\n    \"\"\"Parse NATS security from files, dict or security object.\n\n    Parameters\n    ----------\n    security: `typing.Union[typing.Dict[str, str], str, NATSCredentials, None]`\n        NATS security credentials, path to CREDS file,\n        dict with security params,\n        or `None` if not security\n\n    Returns\n    -------\n    `typing.Optional[NATSCredentials]`\n        Security credentials for NATS\n\n    Raises\n    ------\n    TypeError\n        If security has wrong type\n    \"\"\"\n    if security is None:\n        return None\n\n    if isinstance(security, dict):\n        return NATSCredentials(**security)\n\n    if isinstance(security, str):\n        return NATSCredentials(nkeys_file=security)\n\n    if isinstance(security, NATSCredentials):\n        return security\n\n    raise TypeError(\n        \"security parameter should be a dict of params, path to creds \"\n        f\"file or {NATSCredentials.__name__} instance\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Interrupting Message Processing with Acknowledgement in FastStream\nDESCRIPTION: This snippet illustrates how to interrupt message processing at any point and acknowledge the message by raising a custom exception.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/ack.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream.exceptions import AckMessage\n\n\napp = FastStream()\nbroker = KafkaBroker()\n\n\n@broker.subscriber(\"test\")\nasync def handler(msg: str):\n    if msg == \"STOP\":\n        raise AckMessage()\n\n    print(f\"Received: {msg}\")\n\n\n@app.on_startup\nasync def startup():\n    await broker.publish(\"STOP\", \"test\")\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream Class in Python\nDESCRIPTION: This code snippet shows how to import the FastStream class from the faststream.app module. This is typically the first step in using the FastStream framework in a Python application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/app/FastStream.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.app.FastStream\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to camelCase in Python for FastStream AsyncAPI\nDESCRIPTION: This utility function converts a string from snake_case or other formats to camelCase by removing underscores and capitalizing the first letter of each word except the first. It's designed to standardize field naming in API schemas.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/utils/to_camelcase.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef to_camelcase(string: str) -> str:\n    \"\"\"Convert a string to camelcase.\n\n    Args:\n        string: String to convert\n\n    Returns:\n        String in camelcase\n    \"\"\"\n    string_split = string.split(\"_\")\n    if len(string_split) == 1:\n        return string_split[0]\n    return string_split[0] + \"\".join(word.capitalize() for word in string_split[1:])\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream CLI\nDESCRIPTION: Command to install FastStream CLI package with required dependencies\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npip install \"faststream[cli]\"\n```\n\n----------------------------------------\n\nTITLE: Importing make_asyncapi_asgi Function from FastStream ASGI Module\nDESCRIPTION: This code snippet imports the make_asyncapi_asgi function from the faststream.asgi.factories module. This function is likely used for creating ASGI applications with AsyncAPI capabilities in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asgi/factories/make_asyncapi_asgi.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.asgi.factories import make_asyncapi_asgi\n```\n\n----------------------------------------\n\nTITLE: Importing ServerBinding class from FastStream AsyncAPI AMQP schema bindings\nDESCRIPTION: This code snippet demonstrates how to import the ServerBinding class from the FastStream AsyncAPI AMQP schema bindings module. It's used to define AMQP-specific binding information for AsyncAPI servers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/amqp/ServerBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.schema.bindings.amqp.ServerBinding\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Parser for RabbitMQ in FastStream\nDESCRIPTION: Demonstrates how to reuse the original parser function for RabbitMQ messages in FastStream, allowing for custom modifications while maintaining original functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/parser.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom aio_pika import IncomingMessage\nfrom faststream.rabbit import RabbitMessage\n\nasync def parser(\n    msg: IncomingMessage,\n    original_parser: Callable[[IncomingMessage], Awaitable[RabbitMessage]],\n) -> RabbitMessage:\n    return await original_parser(msg)\n```\n\n----------------------------------------\n\nTITLE: Setting Graceful Timeout in FastStream Broker\nDESCRIPTION: Demonstrates how to set a graceful timeout for the FastStream Broker to wait for consumed messages to be processed before application shutdown.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nBroker(graceful_timeout=30.0)\n```\n\n----------------------------------------\n\nTITLE: Implementing TelemetryMiddleware with RabbitMQ Broker\nDESCRIPTION: Example of adding TelemetryMiddleware to a RabbitMQ broker for tracing message processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.rabbit import RabbitBroker\nfrom faststream.telemetry import TelemetryMiddleware\n\n# Create broker\nbroker = RabbitBroker(middlewares=[TelemetryMiddleware()])\n\n# Create application\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input\")\nasync def handler_one(msg: str) -> None:\n    return {\"response\": msg}\n```\n\n----------------------------------------\n\nTITLE: Importing Shared Aliases in FastStream\nDESCRIPTION: Shows how to import shared annotated aliases from the main FastStream module. These provide access to common context objects like Logger and ContextRepo across all broker implementations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Logger, ContextRepo\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream AsyncAPI HTML Generator\nDESCRIPTION: This code references the get_asyncapi_html function from the FastStream AsyncAPI site module, which is likely used to generate HTML documentation for AsyncAPI specifications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/site/get_asyncapi_html.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.asyncapi.site.get_asyncapi_html\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with RabbitMQ Broker in Python\nDESCRIPTION: This code illustrates how to publish messages using a RabbitMQ broker in FastStream. It sets up a FastStream application, defines a startup event to publish a message, and includes a handler for processing messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/broker.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker(\"amqp://guest:guest@localhost:5672/\")\napp = FastStream(broker)\n\n\n@app.on_startup\nasync def startup():\n    await broker.publish(\n        {\"status\": \"Application started!\"},\n        queue=\"some-queue\",\n    )\n\n\n@broker.subscriber(\"some-queue\")\nasync def handler(msg: dict, logger: Logger):\n    logger.info(f\"Received: {msg}\")\n\n\n@app.after_startup\nasync def after_startup():\n    await broker.publish(\n        {\"status\": \"Application ready!\"},\n        queue=\"some-queue\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Initializing KafkaBroker for Publisher Decorator Pattern\nDESCRIPTION: Creates a KafkaBroker instance configured for use with the publisher decorator pattern in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/publish_example/app.py [ln:13] !}\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Objects by Name in AIOKafka\nDESCRIPTION: This snippet demonstrates how to access context objects by name in FastStream using AIOKafka. It shows how to get the entire message object, access a specific field, and retrieve a dictionary key from the context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/fields.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaMessage\nfrom faststream import FastStream, Context, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"in\")\n@broker.publisher(\"out\")\nasync def on_message(\n    msg: str,\n    message: KafkaMessage = Context(),\n    logger: Logger = Context(),\n    topic: str = Context(\"message.topic\"),\n):\n    logger.info(f\"New message in topic: {topic}\")\n    return msg.upper()\n```\n\nLANGUAGE: python\nCODE:\n```\nmessage: KafkaMessage = Context()\n```\n\nLANGUAGE: python\nCODE:\n```\ntopic: str = Context(\"message.topic\")\n```\n\nLANGUAGE: python\nCODE:\n```\nlogger: Logger = Context()\n```\n\n----------------------------------------\n\nTITLE: Accessing Specific Message Fields using Context in FastStream\nDESCRIPTION: This example illustrates how to access specific message fields, such as correlation_id, using the Context feature in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/message.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    cor_id: str = Context(\"message.correlation_id\"),\n):\n    print(cor_id)\n```\n\n----------------------------------------\n\nTITLE: Building RabbitMQ Connection URLs in Python\nDESCRIPTION: The build_url function constructs a RabbitMQ connection URL string from various connection parameters including host, port, username, password, and virtual host. It handles URL encoding for special characters and supports both AMQP and AMQPS protocols.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/utils/build_url.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef build_url(\n    host: str = \"localhost\",\n    port: Optional[int] = None,\n    user: Optional[str] = None,\n    password: Optional[str] = None,\n    virtualhost: Optional[str] = None,\n    ssl: bool = False,\n) -> str:\n    \"\"\"Build RMQ url from parts.\n\n    Args:\n        host: broker host. Default: \"localhost\".\n        port: broker port. Default: None, means 5671 for secured connection\n            and 5672 for not.\n        user: username to auth. Default: None, means \"guest\".\n        password: password to auth. Default: None, means \"guest\".\n        virtualhost: rmq virtualhost. Default: \"/\".\n        ssl: use SSL for connection or not. Default: False.\n    \"\"\"\n    scheme = \"amqps\" if ssl else \"amqp\"\n\n    if port is None:\n        port = 5671 if ssl else 5672\n\n    if user is None:\n        auth = \"\"\n    else:\n        if password is None:\n            auth = f\"{quote(user)}@\"\n        else:\n            auth = f\"{quote(user)}:{quote(password)}@\"\n\n    if virtualhost is None:\n        virtualhost = \"/\"\n    elif not virtualhost.startswith(\"/\"):\n        virtualhost = f\"/{virtualhost}\"\n\n    return f\"{scheme}://{auth}{host}:{port}{quote(virtualhost)}\"\n```\n\n----------------------------------------\n\nTITLE: Parsing Redis Security Configuration in Python\nDESCRIPTION: This function parses Redis security configuration settings, supporting both password-only and username-password authentication. It accepts various input formats including strings, dictionaries, and specialized security objects.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/security/parse_security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef parse_security(\n    security: Optional[\n        Union[str, Dict[str, str], RedisSecurity, URLSecurity]\n    ] = None,\n) -> Tuple[Optional[str], Optional[str]]:\n    \"\"\"Parse security object.\"\"\"\n    username: Optional[str] = None\n    password: Optional[str] = None\n\n    if security is None:\n        return username, password\n\n    # Directly passed RedisSecurity\n    if isinstance(security, RedisSecurity):\n        return security.username, security.password\n\n    # Directly passed URLSecurity\n    if isinstance(security, URLSecurity):\n        return security.username, security.password\n\n    # String password\n    if isinstance(security, str):\n        password = security\n        return username, password\n\n    # Dict with username and password\n    if isinstance(security, dict):\n        username = security.get(\"username\")\n        password = security.get(\"password\")\n        return username, password\n\n    raise TypeError(f\"Unsupported security type: {type(security)}\")\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with AIOKafka in FastStream\nDESCRIPTION: Example of using the Publisher Decorator with AIOKafka in FastStream. It demonstrates how to subscribe to a topic and publish the processed message to another topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/decorator.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n@broker.subscriber(\"input-topic\")\n@broker.publisher(\"output-topic\")\nasync def on_message(msg: str) -> str:\n    return f\"Processed: {msg}\"\n\nif __name__ == \"__main__\":\n    broker.run()\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Context in FastAPI Plugin\nDESCRIPTION: Shows how to access the message context from the FastAPI plugin in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_39\n\nLANGUAGE: python\nCODE:\n```\ncontext.get_local(\"message\")\n```\n\n----------------------------------------\n\nTITLE: Importing NatsRouter from FastStream NATS FastAPI module\nDESCRIPTION: This code snippet shows how to import the NatsRouter class from the faststream.nats.fastapi module. The NatsRouter is likely used to create NATS-specific routing in a FastAPI application using FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/fastapi/NatsRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.fastapi import NatsRouter\n```\n\n----------------------------------------\n\nTITLE: Version Callback Function for FastStream CLI in Python\nDESCRIPTION: This function is used to display version information when the --version flag is used with the FastStream CLI. It prints the FastStream package version, Python version, and platform information, then exits the program.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/main/version_callback.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef version_callback(value: bool) -> None:\n    \"\"\"\n    Print package version and exit.\n\n    Args:\n        value (bool): Flag value.\n    \"\"\"\n    if value:\n        import platform\n        import sys\n\n        from ..__meta__ import __version__\n\n        info = platform.platform()\n        print(f\"FastStream: {__version__}\")\n        print(f\"Python: {sys.version}\")\n        print(f\"Platform: {info}\")\n        sys.exit(0)\n```\n\n----------------------------------------\n\nTITLE: Generating a FastStream project using CLI\nDESCRIPTION: Command to create a new FastStream project with specified application name and broker type using the CLI tool.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/yield.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nfaststream new my_project --broker kafka\n```\n\n----------------------------------------\n\nTITLE: FastStream Handler with Correlation ID (Python 3.6+)\nDESCRIPTION: Implements a FastStream message subscriber that extracts correlation ID from message context using backwards-compatible type annotations. Uses typing_extensions.Annotated for older Python versions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/message/annotated.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing_extensions import Annotated\nfrom faststream import Context\n\nCorrelationId = Annotated[str, Context(\"message.correlation_id\")]\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    cor_id: CorrelationId,\n):\n    print(cor_id)\n```\n\n----------------------------------------\n\nTITLE: Configuring NATS Pull Subscription in FastStream\nDESCRIPTION: This snippet demonstrates how to set up a NATS pull subscription using the simplified pull_sub=True syntax in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\n@broker.subscriber(\"test\", stream=\"stream\", pull_sub=True)\nasync def handler(msg, logger: Logger):\n    logger.info(msg)\n```\n\n----------------------------------------\n\nTITLE: Importing OneTryWatcher class from FastStream\nDESCRIPTION: This code snippet demonstrates how to import the OneTryWatcher class from the FastStream broker acknowledgement watcher module. The OneTryWatcher is likely used for handling message acknowledgements in a one-attempt scenario.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/acknowledgement_watcher/OneTryWatcher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.acknowledgement_watcher import OneTryWatcher\n```\n\n----------------------------------------\n\nTITLE: Applying Middleware at Broker Level in FastStream\nDESCRIPTION: Code snippet showing how to apply a middleware at the broker level in FastStream. This applies the middleware to all message processing within the broker.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nBroker(middlewares=[MyMiddleware])\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Stream Publisher with Max Length in Python\nDESCRIPTION: Demonstrates how to specify the maxlen option for a Redis Stream publisher using the @broker.publisher decorator. This allows limiting the number of entries in the stream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_34\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(stream=StreamSub(\"Output\", max_len=10))\nasync def on_input_data():\n    ....\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry OTLP Exporter in Python\nDESCRIPTION: This code snippet sets up the OpenTelemetry OTLP exporter for sending traces to a specified endpoint, and adds it to the TracerProvider using a BatchSpanProcessor.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/tracing.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\nexporter = OTLPSpanExporter(endpoint=\"http://127.0.0.1:4317\")\nprocessor = BatchSpanProcessor(exporter)\ntracer_provider.add_span_processor(processor)\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream Development Dependencies\nDESCRIPTION: Installs all required dependencies and the local FastStream package in development mode, allowing immediate code changes to take effect.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -e \".[dev]\"\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Falcon\nDESCRIPTION: Using FastStream MQBrokers with Falcon by starting and stopping them according to the application's lifespan, allowing for message broker interaction in a Falcon web application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nimport falcon.asgi\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\n\n\n@broker.subscriber(\"input\")\nasync def handle(msg: str) -> None:\n    print(msg)\n\n\nclass Push:\n    async def on_get(self, req, resp):\n        await broker.publish(\"Hello World!\", \"input\")\n        resp.text = json.dumps({\"status\": \"sent\"})\n        resp.content_type = falcon.MEDIA_JSON\n\n\napp = falcon.asgi.App()\napp.add_route(\"/\", Push())\n\n\n# Falcon doesn't support any specific hooks for startup or shutdown,\n# so we need to manage the broker differently depending on how you run your app.\n\n# For a typical ASGI server like uvicorn, you might wrap the app:\nclass LifespanMiddleware:\n    def __init__(self, app):\n        self.app = app\n\n    async def __call__(self, scope, receive, send):\n        if scope[\"type\"] == \"lifespan\":\n            message = await receive()\n            if message[\"type\"] == \"lifespan.startup\":\n                await broker.start()\n                await send({\"type\": \"lifespan.startup.complete\"})\n            elif message[\"type\"] == \"lifespan.shutdown\":\n                await broker.close()\n                await send({\"type\": \"lifespan.shutdown.complete\"})\n            return\n        await self.app(scope, receive, send)\n\n\napp = LifespanMiddleware(app)\n```\n\n----------------------------------------\n\nTITLE: Defining FastStream CLI Main Function in Python\nDESCRIPTION: This function serves as the entry point for FastStream's command-line interface. It handles command-line arguments and executes the appropriate actions based on user input.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/main/main.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef main(\n    url: str,\n    file: str,\n    app: str,\n    broker: str,\n    reload: bool = False,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n    workers: int = 1,\n    log_level: str = \"info\",\n    log_config: Optional[str] = None,\n    env_file: Optional[str] = None,\n) -> None:\n    \"\"\"Run a FastStream application.\n\n    Args:\n        url: Broker URL.\n        file: The file path of the FastStream application.\n        app: The variable name of the FastStream application.\n        broker: The broker type (e.g., 'kafka', 'rabbitmq').\n        reload: Enable auto-reload.\n        host: Bind socket to this host.\n        port: Bind socket to this port.\n        workers: Number of worker processes.\n        log_level: The log level.\n        log_config: The log config file path.\n        env_file: The .env file path.\n    \"\"\"\n    ...\n```\n\n----------------------------------------\n\nTITLE: Implementing RabbitMQ Header Exchange with FastStream in Python\nDESCRIPTION: This code snippet demonstrates how to set up a RabbitMQ Header Exchange using FastStream. It includes the creation of the exchange, queue bindings with different header matching criteria, and multiple consumer handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/examples/headers.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/rabbit/subscription/header.py !}\n```\n\n----------------------------------------\n\nTITLE: Accessing CLI parameters in RabbitMQ application\nDESCRIPTION: Python code showing how to access command-line arguments in a FastStream application using RabbitMQ.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom faststream.rabbit import RabbitBroker, RabbitRouter, FastRabbit\n\nrouter = RabbitRouter()\n\n\n@router.subscriber(\"test\")\nasync def handle(msg: str):\n    print(msg)\n\n\nbroker = RabbitBroker()\napp = FastRabbit(\n    broker=broker,\n    routers=[router],\n    setup=lambda env: print(\n        f\"env: {env}\"  # env: .env.dev\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Registering General Exception Handler with Initialization Option in FastStream\nDESCRIPTION: Example of registering a general exception handler using the handlers initialization option. This approach defines the exception-handler mapping during middleware creation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/exception.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef error_handler(exc: Exception) -> None:\n    print(repr(exc))\n\nexc_middleware = ExceptionMiddleware(\n    handlers={\n        Exception: error_handler\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Parsing Security Configuration for Confluent Kafka in Python\nDESCRIPTION: This function parses security-related parameters for Confluent Kafka connections, handling authentication mechanisms, SSL configurations, and security protocols. It returns a dictionary of configuration settings suitable for establishing secure Kafka connections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/security/parse_security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef parse_security(  # noqa: C901\n    bootstrap_servers: str | list[str],\n    security_protocol: str | None = None,\n    sasl_mechanism: str | None = None,\n    sasl_plain_username: str | None = None,\n    sasl_plain_password: str | None = None,\n    sasl_kerberos_service_name: str | None = None,\n    sasl_kerberos_domain_name: str | None = None,\n    sasl_oauth_token_provider: object | None = None,\n    ssl_context: object | None = None,\n    ssl_check_hostname: bool = True,\n    ssl_cafile: str | None = None,\n    ssl_certfile: str | None = None,\n    ssl_keyfile: str | None = None,\n    ssl_password: str | None = None,\n    ssl_crlfile: str | None = None,\n    ssl_ciphers: str | None = None,\n) -> dict[str, Any]:\n    \"\"\"\n    Parse security configuration.\n\n    Args:\n        bootstrap_servers: Kafka bootstrap servers.\n        security_protocol: Protocol used to communicate with brokers.\n            Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL.\n            Default: PLAINTEXT.\n        sasl_mechanism: Authentication mechanism when security_protocol\n            is SASL_PLAINTEXT or SASL_SSL. Valid values are: PLAIN,\n            GSSAPI, SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER.\n            Default: PLAIN\n        sasl_plain_username: username for SASL PLAIN authentication.\n        sasl_plain_password: password for SASL PLAIN authentication.\n        sasl_kerberos_service_name: Service name to include in GSSAPI\n            sasl mechanism handshake. Default: kafka\n        sasl_kerberos_domain_name: Kerberos domain name to use in GSSAPI\n            sasl mechanism handshake. Default: one of bootstrap servers host name\n        sasl_oauth_token_provider: OAuthBearer token provider instance.\n        ssl_context: Pre-configured OpenSSL context.\n        ssl_check_hostname: Flag to configure whether SSL handshake\n            should verify that the certificate matches the broker's hostname.\n        ssl_cafile: Optional filename of CA file to use in certificate\n            verification.\n        ssl_certfile: Optional filename of file in PEM format containing\n            the client certificate, as well as any CA certificates needed\n            to establish the certificate's authenticity.\n        ssl_keyfile: Optional filename containing the client private key.\n        ssl_password: Optional password to be used when loading the\n            certificate chain.\n        ssl_crlfile: Optional filename containing the CRL to check for\n            certificate expiration.\n        ssl_ciphers: Optional string specifying which OpenSSL cipher suites\n            to allow.\n\n    Returns:\n        Dict with security configuration parameters.\n    \"\"\"\n    conf: dict[str, Any] = {\"bootstrap.servers\": bootstrap_servers}\n\n    if security_protocol:\n        conf[\"security.protocol\"] = security_protocol\n\n    if sasl_mechanism:\n        conf[\"sasl.mechanism\"] = sasl_mechanism\n\n    if sasl_plain_username:\n        conf[\"sasl.username\"] = sasl_plain_username\n\n    if sasl_plain_password:\n        conf[\"sasl.password\"] = sasl_plain_password\n\n    if sasl_kerberos_service_name:\n        conf[\"sasl.kerberos.service.name\"] = sasl_kerberos_service_name\n\n    if sasl_kerberos_domain_name:\n        conf[\"sasl.kerberos.domain.name\"] = sasl_kerberos_domain_name\n\n    if sasl_oauth_token_provider:\n        conf[\"oauth_cb\"] = sasl_oauth_token_provider\n\n    if ssl_context:\n        conf[\"ssl.context\"] = ssl_context\n\n    if not ssl_check_hostname:\n        conf[\"ssl.check.hostname\"] = \"false\"\n\n    if ssl_cafile:\n        conf[\"ssl.ca.location\"] = ssl_cafile\n\n    if ssl_certfile:\n        conf[\"ssl.certificate.location\"] = ssl_certfile\n\n    if ssl_keyfile:\n        conf[\"ssl.key.location\"] = ssl_keyfile\n\n    if ssl_password:\n        conf[\"ssl.key.password\"] = ssl_password\n\n    if ssl_crlfile:\n        conf[\"ssl.crl.location\"] = ssl_crlfile\n\n    if ssl_ciphers:\n        conf[\"ssl.cipher.suites\"] = ssl_ciphers\n\n    return conf\n```\n\n----------------------------------------\n\nTITLE: Defining Content Types Enum in Python for FastStream Framework\nDESCRIPTION: An enum class that defines standard content types for messaging in the FastStream framework. It includes common MIME types like JSON, plain text, and binary formats to standardize content type handling.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/constants/ContentTypes.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom enum import Enum\n\n\nclass ContentTypes(str, Enum):\n    \"\"\"Content type identification used in the framework.\"\"\"\n\n    JSON = \"application/json\"\n    TEXT = \"text/plain\"\n    BINARY = \"application/octet-stream\"\n    URLENCODED = \"application/x-www-form-urlencoded\"\n    MULTIPART = \"multipart/form-data\"\n\n```\n\n----------------------------------------\n\nTITLE: Configuring NATS Subscriber with Concurrent Processing\nDESCRIPTION: Example of configuring a NATS subscriber with max_workers parameter to enable concurrent message processing. Setting max_workers=10 allows processing up to 10 messages simultaneously from the same subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/en/nats/scaling.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(..., max_workers=10)\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaPrometheusMiddleware in Python\nDESCRIPTION: This code snippet shows how to import the KafkaPrometheusMiddleware class from the FastStream Kafka Prometheus middleware module. This class is likely used for integrating Prometheus metrics with Kafka consumers in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/prometheus/middleware/KafkaPrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.prometheus.middleware import KafkaPrometheusMiddleware\n```\n\n----------------------------------------\n\nTITLE: Accessing CLI parameters in Redis application\nDESCRIPTION: Python code showing how to access command-line arguments in a FastStream application using Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom faststream.redis import RedisBroker, RedisRouter, FastRedis\n\nrouter = RedisRouter()\n\n\n@router.subscriber(\"test\")\nasync def handle(msg: str):\n    print(msg)\n\n\nbroker = RedisBroker()\napp = FastRedis(\n    broker=broker,\n    routers=[router],\n    setup=lambda env: print(\n        f\"env: {env}\"  # env: .env.dev\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Application Locally\nDESCRIPTION: Command to start the FastStream application locally.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nfaststream run <directory-name>.application:app --workers 1\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Object in FastStream NATS Subscriber\nDESCRIPTION: This snippet demonstrates how to access the message object in a FastStream NATS subscriber to retrieve additional message information such as correlation_id.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/nats/message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    msg: NatsMessage,\n):\n    print(msg.correlation_id)\n```\n\n----------------------------------------\n\nTITLE: Accessing Dictionary Key from Context Object\nDESCRIPTION: This snippet illustrates how to access a dictionary key from a context object in FastStream. It shows how to retrieve the 'logger' object from the context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/fields.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nlogger: Logger = Context()\n```\n\n----------------------------------------\n\nTITLE: Running FastStream app with multiprocessing\nDESCRIPTION: Command to scale a FastStream application by running it in a process pool with multiple workers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run serve:app --workers 2\n```\n\n----------------------------------------\n\nTITLE: Customizing Log Format in FastStream\nDESCRIPTION: Demonstrates how to customize the log format for FastStream applications by specifying a custom format string in the broker's constructor.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker\nbroker = RabbitBroker(log_fmt=\"%(asctime)s %(levelname)s - %(message)s\")\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with NATS\nDESCRIPTION: Command to install FastStream with NATS support using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_5\n\nLANGUAGE: console\nCODE:\n```\npip install \"faststream[nats]\"\n```\n\n----------------------------------------\n\nTITLE: Defining ExternalDocs Schema for FastStream AsyncAPI\nDESCRIPTION: This code snippet defines the ExternalDocs schema for FastStream's AsyncAPI implementation. It likely includes fields for external documentation URLs and descriptions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/ExternalDocs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.schema.ExternalDocs\n```\n\n----------------------------------------\n\nTITLE: RabbitMQ Basic Integration with FastStream\nDESCRIPTION: Basic setup for integrating RabbitMQ message queue with FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/app.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/rabbit/basic.py!}\n```\n\n----------------------------------------\n\nTITLE: Importing BatchStreamSubscriber from FastStream Redis Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the BatchStreamSubscriber class from the FastStream Redis subscriber module. It's used for batch processing of messages from Redis streams.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/subscriber/usecase/BatchStreamSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.subscriber.usecase import BatchStreamSubscriber\n```\n\n----------------------------------------\n\nTITLE: Importing PublisherUsecase in Python\nDESCRIPTION: This code snippet shows how to import the PublisherUsecase class from the FastStream broker publisher module. It's typically used at the beginning of a Python file to make the class available for use.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/publisher/usecase/PublisherUsecase.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.publisher.usecase import PublisherUsecase\n```\n\n----------------------------------------\n\nTITLE: Running with hot reload for specific file extensions\nDESCRIPTION: Command to run a FastStream app with hot reload watching for changes in Python, YAML, and YML files.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run serve:app --reload  --reload-ext .yml --realod-ext .yaml\n```\n\n----------------------------------------\n\nTITLE: Registering Publishing Exception Handler with Decorator in FastStream\nDESCRIPTION: Example of registering a publishing exception handler using the @add_handler decorator with publish=True. This handler can return a default value to be published in case of an error.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/exception.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nexc_middleware = ExceptionMiddleware()\n\n@exc_middleware.add_handler(Exception, publish=True)\ndef error_handler(exc: Exception) -> str:\n    print(repr(exc))\n    return \"error occurred\"\n```\n\n----------------------------------------\n\nTITLE: Creating Confluent Kafka Subscriber with FastStream\nDESCRIPTION: This function creates a Confluent Kafka subscriber using FastStream. It takes various parameters to configure the subscriber, including broker details, authentication, and topic information.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/subscriber/factory/create_subscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef create_subscriber(\n    broker: str,\n    group_id: str | None = None,\n    topics: list[str] | None = None,\n    auto_offset_reset: str = \"earliest\",\n    security_protocol: str = \"PLAINTEXT\",\n    sasl_mechanism: str | None = None,\n    sasl_username: str | None = None,\n    sasl_password: str | None = None,\n    schema_registry: str | None = None,\n    schema_registry_auth: tuple[str, str] | None = None,\n    batch_size: int | None = None,\n    batch_timeout_ms: int | None = None,\n    enable_auto_commit: bool = True,\n    auto_commit_interval_ms: int = 5000,\n    max_poll_interval_ms: int = 300000,\n    max_poll_records: int | None = None,\n    session_timeout_ms: int = 10000,\n    heartbeat_interval_ms: int = 3000,\n    client_id: str | None = None,\n    ssl_context: ssl.SSLContext | None = None,\n    deserializer: Callable[[Any], Any] | None = None,\n) -> ConfluentSubscriber:\n```\n\n----------------------------------------\n\nTITLE: Encoding Messages in FastStream Broker (Python)\nDESCRIPTION: This function encodes messages for transmission in the FastStream broker system. It likely takes a message object and converts it into a format suitable for sending between brokers or to clients.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/message/encode_message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.message.encode_message\n```\n\n----------------------------------------\n\nTITLE: Implementing Publisher Object with Redis in Python\nDESCRIPTION: This snippet shows the implementation of the Publisher Object using Redis in FastStream. It initializes the Redis broker, sets up a publisher, and defines a subscriber function that publishes messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/object.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream, Logger\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"output\")\n\n@publisher\n@broker.subscriber(\"input\")\nasync def on_message(body: str, logger: Logger):\n    logger.info(f\"Got message: {body}\")\n    return f\"Processed: {body}\"\n```\n\n----------------------------------------\n\nTITLE: Compiling NATS Wildcards in Python\nDESCRIPTION: Function that compiles a FastStream pattern to a NATS wildcard pattern. It replaces path parameters enclosed in curly braces with the NATS wildcard token (*).\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/schemas/js_stream/compile_nats_wildcard.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef compile_nats_wildcard(pattern: str) -> str:\n    \"\"\"\n    Compile FastStream pattern to NATS wildcard pattern.\n\n    Args:\n        pattern: FastStream pattern\n\n    Returns:\n        NATS wildcard pattern (with `*` instead of `{param}`)\n    \"\"\"\n    import re\n\n    return re.sub(r\"\\{[^\\}]+\\}\", \"*\", pattern)\n```\n\n----------------------------------------\n\nTITLE: Referencing AsyncAPIChannelSubscriber Class in Python\nDESCRIPTION: This code snippet shows how to reference the AsyncAPIChannelSubscriber class from the faststream.redis.subscriber.asyncapi module. It's likely used for subscribing to Redis channels using AsyncAPI in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/subscriber/asyncapi/AsyncAPIChannelSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.subscriber.asyncapi import AsyncAPIChannelSubscriber\n```\n\n----------------------------------------\n\nTITLE: Running FastStream with Multiple Workers\nDESCRIPTION: Command to run FastStream application with horizontal scaling using multiple workers\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run basic:app --workers 3\n```\n\n----------------------------------------\n\nTITLE: Creating a Publisher Object for Decorator Usage\nDESCRIPTION: Prepares a publisher object that will be used as a decorator to define where processed messages should be sent.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/publish_example/app.py [ln:17] !}\n```\n\n----------------------------------------\n\nTITLE: Using Context for Message Field Access in FastStream Python\nDESCRIPTION: This example demonstrates how to use the Context object to access specific message fields, such as correlation_id, in a FastStream subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/message.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    cor_id: str = Context(\"message.correlation_id\"),\n):\n    print(cor_id)\n```\n\n----------------------------------------\n\nTITLE: Including FastStream Confluent BatchSubscriber Documentation\nDESCRIPTION: A markdown directive that includes the documentation for the BatchSubscriber class from the FastStream Confluent integration package. This appears to be using MkDocs or similar documentation generator syntax.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/subscriber/usecase/BatchSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.confluent.subscriber.usecase.BatchSubscriber\n```\n\n----------------------------------------\n\nTITLE: Displaying Team Members using Jinja2 and HTML\nDESCRIPTION: This snippet uses Jinja2 templating to iterate through a list of team members and display their information in HTML. It includes conditionals to filter users based on their inclusion in the 'team' category.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream-people.md#2025-04-22_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n<div class=\"user-list user-list-center\">\n{% for user in people.people %}\n    {% if 'team' in user.include %}\n        <div class=\"user\">\n            <a href=\"{{ user.github }}\" target=\"_blank\">\n                <div class=\"avatar-wrapper\">\n                    <img src=\"{{ user.avatar }}\"/>\n                </div>\n                <div class=\"title\">\n                    {% if user.name %}{{user.name}}<br/>{% endif %}\n                    @{{user.username}}\n                </div>\n            </a>\n        </div>\n    {% endif %}\n{% endfor %}\n</div>\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Broker with Custom Settings in Python\nDESCRIPTION: This snippet demonstrates how to pass a custom config dictionary to the KafkaBroker to customize confluent-kafka-python settings. It sets the 'topic.metadata.refresh.fast.interval.ms' parameter to 300 milliseconds.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.confluent import KafkaBroker\n\nconfig = {\"topic.metadata.refresh.fast.interval.ms\": 300}\nbroker = KafkaBroker(\"localhost:9092\", config=config)\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Basic FastStream Application for AsyncAPI Documentation\nDESCRIPTION: A simple FastStream application that creates a Kafka broker connection with a publisher and consumer. This serves as the foundation for demonstrating AsyncAPI documentation customization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{! docs_src/getting_started/asyncapi/asyncapi_customization/basic.py !}\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Application\nDESCRIPTION: Command to run a FastStream application using the FastStream CLI.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nfaststream run serve:app\n```\n\n----------------------------------------\n\nTITLE: AIOKafka Basic Integration with FastStream\nDESCRIPTION: Basic setup for integrating AIOKafka message queue with FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/app.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/kafka/basic.py!}\n```\n\n----------------------------------------\n\nTITLE: Referencing RabbitMessage Class in FastStream RabbitMQ Module (Python)\nDESCRIPTION: This code snippet demonstrates how to reference the RabbitMessage class from the FastStream library's RabbitMQ module. It's typically used to import and work with RabbitMQ messages within a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/message/RabbitMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit.message import RabbitMessage\n```\n\n----------------------------------------\n\nTITLE: Defining WatchReloader Class for FastStream CLI Supervisor\nDESCRIPTION: This code snippet defines the WatchReloader class, which is likely used for monitoring file changes and triggering reloads in a FastStream application. It appears to be part of the CLI supervisor module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/supervisors/watchfiles/WatchReloader.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.cli.supervisors.watchfiles.WatchReloader\n```\n\n----------------------------------------\n\nTITLE: Using Annotated Aliases in Redis\nDESCRIPTION: Shows how to use annotated aliases for accessing context objects in Redis with proper typing. This approach provides more explicit type hints for the context objects being accessed.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisBroker\nfrom faststream.redis.annotations import (\n    RedisMessage,\n    RedisBroker,\n    Redis,\n    Logger,\n    ContextRepo,\n)\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: RedisBroker,  # access to the broker\n    context: ContextRepo,  # access to the context\n    logger: Logger,  # access to the logger\n    message: RedisMessage,  # access to the raw message\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n\n    # access to message properties\n    print(message.channel)\n```\n\n----------------------------------------\n\nTITLE: Checking if RabbitMQ Exchange Type Supports Routing in Python\nDESCRIPTION: This function determines whether a specified RabbitMQ exchange type supports message routing based on routing keys. It returns True for 'direct', 'topic', and 'headers' exchange types which support routing, and False for other types like 'fanout'.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/utils/is_routing_exchange.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef is_routing_exchange(exchange_type: str) -> bool:\n    \"\"\"Check if exchange is routing.\n\n    `direct`, `topic` and `headers` exchanges are routing exchanges.\n    It means you can provide routing key to send message to specific queue.\n\n    Args:\n        exchange_type: RabbitMQ exchange type\n\n    Returns:\n        True if exchange is routing\n    \"\"\"\n    return exchange_type in (\"direct\", \"topic\", \"headers\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Async Context Manager Middlewares\nDESCRIPTION: Example of the new requirement in FastStream 0.5.0rc0 that both subscriber and publisher middlewares should be async context manager types.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nfrom contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def subscriber_middleware(msg_body):\n    yield msg_body\n\n@asynccontextmanager\nasync def publisher_middleware(\n    msg_to_publish,\n    **publish_arguments,\n):\n    yield msg_to_publish\n\n@broker.subscriber(\"in\", middlewares=(subscriber_middleware,))\n@broker.publisher(\"out\", middlewares=(publisher_middleware,))\nasync def handler():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Defining ClassicQueueArgs for RabbitMQ Queue Configuration in Python\nDESCRIPTION: This code snippet defines the ClassicQueueArgs class, which encapsulates the configuration options for a classic RabbitMQ queue. It includes various parameters such as queue type, durability, auto-delete behavior, and more.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/queue/ClassicQueueArgs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass ClassicQueueArgs(QueueArgs):\n    \"\"\"Arguments for queue.declare (classic queues).\"\"\"\n\n    x_max_length: Optional[int] = None\n    x_max_length_bytes: Optional[int] = None\n    x_overflow: Optional[str] = None\n    x_dead_letter_exchange: Optional[str] = None\n    x_dead_letter_routing_key: Optional[str] = None\n    x_max_priority: Optional[int] = None\n    x_queue_mode: Optional[str] = None\n    x_queue_version: Optional[int] = None\n    x_max_in_memory_length: Optional[int] = None\n    x_max_in_memory_bytes: Optional[int] = None\n    x_dead_letter_strategy: Optional[str] = None\n    x_single_active_consumer: Optional[bool] = None\n\n    def __init__(\n        self,\n        queue_type: Literal[\"classic\", \"quorum\", \"stream\"] = \"classic\",\n        durable: bool = True,\n        auto_delete: bool = False,\n        exclusive: bool = False,\n        passive: bool = False,\n        **kwargs: Any,\n    ) -> None:\n        super().__init__(\n            queue_type=queue_type,\n            durable=durable,\n            auto_delete=auto_delete,\n            exclusive=exclusive,\n            passive=passive,\n            **kwargs,\n        )\n\n    def dict(self, *args: Any, **kwargs: Any) -> Dict[str, Any]:\n        d = super().dict(*args, **kwargs)\n        if self.queue_type != \"classic\":\n            raise ValueError(\"ClassicQueueArgs can only be used with classic queues\")\n        return d\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Prometheus MetricsSettingsProvider\nDESCRIPTION: This code snippet references the MetricsSettingsProvider class from the faststream.prometheus module. It's likely used to import or access the class for configuring Prometheus metrics in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/prometheus/MetricsSettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.prometheus.MetricsSettingsProvider\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Confluent Kafka Support\nDESCRIPTION: Command to install FastStream with Confluent Kafka support. This is available starting from version 0.4.0rc0.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/index.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"faststream[confluent]>=0.4.0\"\n```\n\n----------------------------------------\n\nTITLE: Accessing CLI parameters in NATS application\nDESCRIPTION: Python code showing how to access command-line arguments in a FastStream application using NATS.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom faststream.nats import NatsBroker, NatsRouter, FastNats\n\nrouter = NatsRouter()\n\n\n@router.subscriber(\"test\")\nasync def handle(msg: str):\n    print(msg)\n\n\nbroker = NatsBroker()\napp = FastNats(\n    broker=broker,\n    routers=[router],\n    setup=lambda env: print(\n        f\"env: {env}\"  # env: .env.dev\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Litestar\nDESCRIPTION: This snippet shows how to integrate a FastStream broker with the Litestar framework using lifecycle hooks. The broker is initialized at application startup and closed during shutdown.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/frameworks/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom litestar import Litestar\nfrom litestar.lifecycle import on_shutdown, on_startup\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\n\n\n@on_startup\nasync def startup() -> None:\n    await broker.start()\n\n\n@on_shutdown\nasync def shutdown() -> None:\n    await broker.close()\n\n\napp = Litestar(lifespan=[startup, shutdown])\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: YAML frontmatter configuration that sets up documentation priorities and search boost parameters. Includes section weights for API, Release, Contributing, Template and Default pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/OperationBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Integrating FastStream with Blacksheep\nDESCRIPTION: Using FastStream MQBrokers with Blacksheep by starting and stopping them according to the application's lifespan, allowing for message broker interaction in a Blacksheep web application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom blacksheep import Application, get\n\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = Application()\n\n\n@broker.subscriber(\"input\")\nasync def handle(msg: str) -> None:\n    print(msg)\n\n\n@get(\"/\")\nasync def push():\n    await broker.publish(\"Hello World!\", \"input\")\n    return {\"status\": \"sent\"}\n\n\n@app.on_start\nasync def startup(app):\n    # Startup the broker\n    await broker.start()\n\n\n@app.on_stop\nasync def shutdown(app):\n    # Shutdown the broker\n    await broker.close()\n```\n\n----------------------------------------\n\nTITLE: Stopping Test Environment for FastStream\nDESCRIPTION: Executes a script to stop the Docker containers used for testing with message broker dependencies.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/stop_test_env.sh\n```\n\n----------------------------------------\n\nTITLE: Defining a Publisher with KafkaBroker in Python\nDESCRIPTION: Defines a publisher using the KafkaBroker.publisher decorator to publish messages to a Kafka topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/using_a_key.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.publisher(\"output_data\")\n```\n\n----------------------------------------\n\nTITLE: Installing Msgpack dependencies for FastStream\nDESCRIPTION: This command installs the necessary dependencies for using Msgpack with FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_4\n\nLANGUAGE: console\nCODE:\n```\npip install msgpack\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaPrometheusMiddleware in Python\nDESCRIPTION: This code snippet shows how to import the KafkaPrometheusMiddleware class from the FastStream Confluent Prometheus middleware module. This middleware is used to integrate Prometheus metrics with Kafka consumers and producers in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/prometheus/middleware/KafkaPrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.prometheus.middleware import KafkaPrometheusMiddleware\n```\n\n----------------------------------------\n\nTITLE: Defining Server Schema in FastStream AsyncAPI\nDESCRIPTION: This code snippet defines the Server class for FastStream's AsyncAPI schema. It includes properties such as url, protocol, protocolVersion, description, variables, security, and bindings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/Server.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Server(BaseModel):\n    \"\"\"AsyncAPI server object.\"\"\"\n\n    url: str = Field(..., description=\"Server URL.\")\n    protocol: str = Field(..., description=\"Server protocol.\")\n    protocolVersion: Optional[str] = Field(\n        None, description=\"Version of the protocol used.\"\n    )\n    description: Optional[str] = Field(None, description=\"Server description.\")\n    variables: Optional[Dict[str, Any]] = Field(\n        None, description=\"Server variables.\"\n    )\n    security: Optional[List[Dict[str, List[str]]]] = Field(\n        None, description=\"Server security requirements.\"\n    )\n    bindings: Optional[Dict[str, Any]] = Field(\n        None, description=\"Protocol-specific information.\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Middleware for Broker and Publishers in Python\nDESCRIPTION: Illustrates how to pass middleware configurations to both broker and publisher decorators.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nbroker = Broker(..., middlewares=())\n\n@broker.subscriber(..., middlewares=())\n@broker.publisher(..., middlewares=())  # new feature\nasync def handler():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Instantiating RedisBroker in Python with FastStream\nDESCRIPTION: This snippet shows how to create an instance of RedisBroker using FastStream. It's the first step in setting up a Redis-based messaging system.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/list/publishing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nbroker = RedisBroker(\"redis://localhost:6379\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Middlewares for Subscribers and Publishers\nDESCRIPTION: Example showing how to configure middlewares at different levels in FastStream, including the new feature of adding middlewares to publishers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nbroker = Broker(..., middlewares=())\n\n@broker.subscriber(..., middlewares=())\n@broker.publisher(..., middlewares=())  # new feature\nasync def handler():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Publishing Message to Redis Channel using RedisBroker\nDESCRIPTION: Publish a message to a Redis channel using the 'publish' method of the RedisBroker. This demonstrates the basic way to send messages to Redis channels.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/publishing.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\"Hello, Redis!\", channel=\"test\")\n```\n\n----------------------------------------\n\nTITLE: Parsing Kafka Security Configuration in Python\nDESCRIPTION: The parse_security function processes security configurations for Kafka connections, handling different authentication mechanisms. It accepts security settings as input and returns a dictionary with properly formatted security configuration for Kafka client.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/security/parse_security.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef parse_security(\n    security: Optional[SecurityT] = None,\n) -> Dict[str, Any]:\n    \"\"\"Parse security settings.\"\"\"\n    if security is None:\n        return {}\n\n    if isinstance(security, dict):\n        return {**security}\n\n    if isinstance(security, str):\n        security = SecurityProtocol(security)\n\n    if isinstance(security, SecurityProtocol):\n        protocol = str(security.value).lower()\n\n        return {\"security_protocol\": protocol}\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream AsyncAPI HTML Generator\nDESCRIPTION: Reference to the get_asyncapi_html function from the faststream.asyncapi module. This function likely generates HTML documentation from AsyncAPI specifications for FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/get_asyncapi_html.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.asyncapi.get_asyncapi_html\n```\n\n----------------------------------------\n\nTITLE: NATS Basic Integration with FastStream\nDESCRIPTION: Basic setup for integrating NATS message queue with FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/app.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/nats/basic.py!}\n```\n\n----------------------------------------\n\nTITLE: Using apply_types with Regular Functions\nDESCRIPTION: Examples of using the apply_types decorator with regular synchronous and asynchronous functions in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Depends, apply_types\n\ndef simple_dependency(a: int, b: int = 3) -> int:\n    return a + b\n\n@apply_types\ndef method(a: int, d: int = Depends(simple_dependency)):\n    return a + d\n\nassert method(\"1\") == 5\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Depends, apply_types\nimport asyncio\n\nasync def simple_dependency(a: int, b: int = 3) -> int:\n    return a + b\n\n@apply_types\nasync def method(a: int, d: int = Depends(simple_dependency)):\n    return a + d\n\nassert asyncio.run(method(\"1\")) == 5\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Page\nDESCRIPTION: Frontmatter configuration block defining API weights, release status, and search boost parameters for a documentation page.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asgi/AsgiResponse.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring NATS Scheduled Task\nDESCRIPTION: Sets up a scheduled task to publish messages to a NATS subject every minute. Utilizes TaskIQ scheduling with cron expression for timing management.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/taskiq_broker.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import StreamScheduler\nfrom taskiq.schedule_sources import LabelScheduleSource\n\ntaskiq_broker.task(\n    message={\"user\": \"John\", \"user_id\": 1},\n    subject=\"in-subject\",\n    schedule=[{\n        \"cron\": \"* * * * *\",\n    }],\n)\n\nscheduler = StreamScheduler(\n    broker=taskiq_broker,\n    sources=[LabelScheduleSource(taskiq_broker)],\n)\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Redis\nDESCRIPTION: Command to install FastStream with Redis support using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_7\n\nLANGUAGE: console\nCODE:\n```\npip install \"faststream[redis]\"\n```\n\n----------------------------------------\n\nTITLE: Applying Middleware at Router Level in FastStream\nDESCRIPTION: Example of applying middleware at the router level in FastStream. This limits the middleware application to only objects created by this specific router.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/middlewares/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nBrokerRouter(middlewares=[MyMiddleware])\n```\n\n----------------------------------------\n\nTITLE: Configuring Static Files in Django Settings\nDESCRIPTION: Django settings configuration for static files to be used with Starlette static files serving.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nSTATIC_ROOT = \"static/\"\n```\n\n----------------------------------------\n\nTITLE: Running FastStream App Documentation Server\nDESCRIPTION: Shell command to serve the FastStream application's AsyncAPI documentation via web interface.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n{! docs_src/getting_started/asyncapi/serve.py [ln:17] !}\n```\n\n----------------------------------------\n\nTITLE: Starting Kafka Docker Container Locally\nDESCRIPTION: Command to start a Kafka Docker container locally using a provided script.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/start_kafka_broker_locally.sh\n```\n\n----------------------------------------\n\nTITLE: Defining RabbitPrometheusMiddleware Class in Python\nDESCRIPTION: This code snippet defines the RabbitPrometheusMiddleware class, which is likely used to integrate Prometheus metrics collection with RabbitMQ applications in the FastStream framework. The class is part of the faststream.rabbit.prometheus module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/prometheus/RabbitPrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.rabbit.prometheus.RabbitPrometheusMiddleware\n```\n\n----------------------------------------\n\nTITLE: Documenting ConsumerConnectionParams Class for Faststream Confluent in Python\nDESCRIPTION: This code snippet represents the documentation for the ConsumerConnectionParams class, which is used to configure connection parameters for a Confluent Kafka consumer in the Faststream library. It likely includes attributes for specifying connection details such as bootstrap servers, security settings, and consumer group information.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/schemas/params/ConsumerConnectionParams.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.schemas.params.ConsumerConnectionParams\n```\n\n----------------------------------------\n\nTITLE: Importing Application Module Dynamically in FastStream CLI\nDESCRIPTION: The `try_import_app` function attempts to import a FastStream application by its module path. It handles various import errors gracefully, providing specific error messages for different failure scenarios such as module not found or import errors.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/imports/try_import_app.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom importlib import import_module\nfrom pathlib import Path\nfrom types import ModuleType\nfrom typing import Any, Optional, Union\n\n\ndef try_import_app(app_path: str) -> Any:\n    \"\"\"Try to import application from file path.\n\n    Args:\n        app_path: string path to importing application\n\n    Raises:\n        ModuleNotFoundError: If application module can not be found\n        ImportError: If application module can not be imported\n\n    Returns:\n        Any: Imported application\n    \"\"\"\n    try:\n        if Path(app_path).exists():\n            app_name = app_path.rsplit(\"/\", 1)[-1]\n            if app_name.endswith(\".py\"):\n                app_name = app_name[:-3].replace(\"/\", \".\")\n                directory = str(Path(app_path).parent.absolute())\n                import sys\n\n                sys.path.insert(0, directory)\n                try:\n                    module = import_module(app_name)\n                finally:\n                    sys.path.pop(0)\n                return module\n            raise ImportError(\"Only `.py` files can be imported\")\n        else:\n            module = import_module(app_path)\n            return module\n    except (ImportError, ModuleNotFoundError) as e:\n        module_name = app_path.split(\":\")[0]\n        try:\n            import_module(module_name)\n        except ModuleNotFoundError:\n            raise ModuleNotFoundError(\n                f\"Module `{module_name}` not found.\"\n            ) from e\n        except ImportError:\n            raise ImportError(\n                f\"Can not import from `{module_name}` module\"\n            ) from e\n        raise ImportError(f\"Can not import from `{app_path}` path\") from e\n```\n\n----------------------------------------\n\nTITLE: Importing Message Type from NATS\nDESCRIPTION: Shows how to import the NatsMessage type directly from the nats module, which is an alias to the annotated version. This provides a shorthand for accessing the message type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsMessage\n```\n\n----------------------------------------\n\nTITLE: Importing RedisBatchStreamMessage from FastStream Redis Module\nDESCRIPTION: This code snippet shows how to import the RedisBatchStreamMessage class from the faststream.redis.message module. This class is likely used for handling batch messages in Redis streams within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/message/RedisBatchStreamMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.message import RedisBatchStreamMessage\n```\n\n----------------------------------------\n\nTITLE: Disabling FastStream Auto-Acknowledgement\nDESCRIPTION: Shows how to disable automatic message acknowledgement in FastStream by setting no_ack=True in the subscriber decorator. When disabled, the application must handle message acknowledgement, negative acknowledgement, or termination manually.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/en/no_ack.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(..., no_ack=True)\n```\n\n----------------------------------------\n\nTITLE: Importing and Using Depends Class in FastStream\nDESCRIPTION: This snippet demonstrates how to import and use the Depends class from the fast_depends.use module for dependency injection in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/Depends.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: fast_depends.use.Depends\n```\n\n----------------------------------------\n\nTITLE: Importing TestApp from FastStream Testing Module\nDESCRIPTION: This code snippet shows how to import the TestApp class from the FastStream testing module. TestApp is likely used for creating test instances of FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/TestApp.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.testing.app import TestApp\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream Development Dependencies\nDESCRIPTION: Installs FastStream and all its development dependencies in the virtual environment using pip's editable mode (-e), which allows changes to the source code to be immediately reflected without reinstallation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -e \".[dev]\"\n```\n\n----------------------------------------\n\nTITLE: Importing Annotated Aliases for RabbitMQ\nDESCRIPTION: Shows the import statement for all available annotated aliases specific to the RabbitMQ broker. These provide type hints for broker-specific objects when used as function parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit.annotations import (\n    Logger, ContextRepo, RabbitMessage,\n    RabbitBroker, RabbitProducer, NoCast,\n)\n```\n\n----------------------------------------\n\nTITLE: Returning Custom Response Object in FastStream Handler\nDESCRIPTION: This example shows how to use the new Response class to set specific parameters for outgoing messages in a FastStream handler function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Response\n\n@broker.subscriber(\"in\")\n@broker.subscriber(\"out\")\nasync def handler():\n    return Response(body=b\"\", headers={})\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search and Structure in YAML\nDESCRIPTION: YAML configuration defining documentation sections with weight priority and search boost settings. Includes sections for API, Release, Contributing, Template Page and Default sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/context/Context.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.fastapi.context.Context\n```\n\n----------------------------------------\n\nTITLE: Defining Avro schema for FastStream messages\nDESCRIPTION: This snippet defines an Avro schema for a Person message, which includes name and age fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"namespace\": \"example.avro\",\n    \"type\": \"record\",\n    \"name\": \"Person\",\n    \"fields\": [\n        {\"name\": \"name\", \"type\": \"string\"},\n        {\"name\": \"age\", \"type\": \"float\"}\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Log Level via FastStream CLI\nDESCRIPTION: Shows how to set the logging level for both the broker and FastStream app using the CLI. This affects default loggers and custom loggers used within FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nfaststream run serve:app --log-level debug\n```\n\n----------------------------------------\n\nTITLE: Serving Static Files with Starlette\nDESCRIPTION: Enhanced ASGI configuration that adds static file serving through Starlette's StaticFiles component.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nfrom starlette.staticfiles import StaticFiles\n\napplication = Starlette(\n    routes=(\n        # /static is your STATIC_URL setting\n        Mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\"),\n        Mount(\"/\", get_asgi_application()),  # regular Django ASGI\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for OpenTelemetry Collector\nDESCRIPTION: Docker Compose YAML configuration to run the OpenTelemetry Collector container. It specifies the image, command, volume mapping for the configuration file, and port mapping.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/sentry.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  otel-collector:\n    image: otel/opentelemetry-collector-contrib:latest\n    command: [ \"--config=/etc/otel.yaml\" ]\n    volumes:\n      - ./otel.yaml:/etc/otel.yaml\n    ports:\n      - \"4317:4317\"\n```\n\n----------------------------------------\n\nTITLE: Importing and Using FastStream's Header Utility in Python\nDESCRIPTION: Example showing how to import and use the Header utility from FastStream's utilities module for handling message headers in streaming applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/Header.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.utils.Header\n```\n\n----------------------------------------\n\nTITLE: Defining Context Class in FastStream\nDESCRIPTION: The Context class provides access to shared data during request processing, supporting dictionary-like access and isolation between request handlers. It allows managing various objects throughout the request lifecycle.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/context/Context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Context(ContextRepo):\n    \"\"\"Context provides access to shared data during request processing.\n\n    This class allows you to store and access objects through different\n    request handlers.\n\n    Context is designed to be used as dict-like object, which provides isolation\n    between request handlers and other parts of your application.\n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Specifying gRPC Tools Dependency for FastStream Project\nDESCRIPTION: This line specifies 'grpcio-tools' as a required dependency for the FastStream project. The grpcio-tools package provides necessary utilities for working with gRPC in Python, including code generation tools for creating gRPC service definitions from .proto files.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/examples/serialization/protobuf/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngrpcio-tools\n```\n\n----------------------------------------\n\nTITLE: Defining LogicPublisher Class for Redis in Python\nDESCRIPTION: This code snippet defines the LogicPublisher class, which is used for publishing messages to Redis streams in FastStream. It includes methods for publishing messages and managing the connection to Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/publisher/usecase/LogicPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass LogicPublisher(AsyncPublisher, BaseLogicPublisher):\n    \"\"\"Redis publisher.\"\"\"\n\n    def __init__(\n        self,\n        redis: Redis,\n        encoder: Optional[Callable[[Any], bytes]] = None,\n        serializer: Optional[Callable[[Any], Any]] = None,\n    ) -> None:\n        \"\"\"Initialize Redis publisher.\n\n        Args:\n            redis: Redis client\n            encoder: Message encoder\n            serializer: Message serializer\n        \"\"\"\n        self.redis = redis\n        self.encoder = encoder or self._encode\n        self.serializer = serializer or self._serialize\n\n    async def publish(\n        self,\n        message: Any,\n        *,\n        stream: str,\n        maxlen: Optional[int] = None,\n        approximate: bool = True,\n    ) -> bytes:\n        \"\"\"Publish message to Redis stream.\n\n        Args:\n            message: Message to publish\n            stream: Stream name\n            maxlen: Maximum length of the stream\n            approximate: Whether to use approximate trimming\n\n        Returns:\n            Message ID\n        \"\"\"\n        serialized = self.serializer(message)\n        encoded = self.encoder(serialized)\n        return await self.redis.xadd(\n            stream,\n            {b\"message\": encoded},\n            maxlen=maxlen,\n            approximate=approximate,\n        )\n\n    @staticmethod\n    def _encode(message: Any) -> bytes:\n        \"\"\"Encode message to bytes.\n\n        Args:\n            message: Message to encode\n\n        Returns:\n            Encoded message\n        \"\"\"\n        return orjson.dumps(message)\n\n    @staticmethod\n    def _serialize(message: Any) -> Any:\n        \"\"\"Serialize message.\n\n        Args:\n            message: Message to serialize\n\n        Returns:\n            Serialized message\n        \"\"\"\n        return message\n```\n\n----------------------------------------\n\nTITLE: Importing Message Type from AIOKafka\nDESCRIPTION: Shows how to import the KafkaMessage type directly from the kafka module, which is an alias to the annotated version. This provides a shorthand for accessing the message type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaMessage\n```\n\n----------------------------------------\n\nTITLE: Importing Context Class from FastStream Utils Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the Context class from the FastStream utils module. The Context class is likely used for managing contextual information within FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/context/types/Context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.utils.context.types.Context\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Headers in Kafka with FastStream\nDESCRIPTION: Demonstrates how to access message headers in a Kafka subscriber function using the FastStream KafkaMessage object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaMessage\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    body: str,\n    msg: KafkaMessage,\n):\n    print(msg.headers)\n```\n\n----------------------------------------\n\nTITLE: Accessing Pattern Data in Redis Channel Subscription with FastStream\nDESCRIPTION: This snippet demonstrates how to access pattern data encoded in Redis channel names using FastStream. It shows how to extract and use data from the channel name in the message handler function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/pubsub/subscription.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker, PubSub\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n@broker.subscriber(channel=PubSub(\"test.*\", pattern=True))\nasync def on_message(msg: str, logger, channel: str):\n    _, category = channel.split(\".\", 1)\n    logger.info(f\"Received message in category '{category}': {msg}\")\n\n@broker.subscriber(channel=PubSub(\"user.*.status\", pattern=True))\nasync def on_status_update(msg: str, logger, channel: str):\n    _, user_id, _ = channel.split(\".\", 2)\n    logger.info(f\"User {user_id} status updated: {msg}\")\n```\n\n----------------------------------------\n\nTITLE: Confluent Basic Integration with FastStream\nDESCRIPTION: Basic setup for integrating Confluent message queue with FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/app.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/confluent/basic.py!}\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Environment with venv for FastStream Development\nDESCRIPTION: Creates a Python virtual environment in a directory named 'venv' to isolate the FastStream development environment.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv venv\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Redis Support\nDESCRIPTION: Command to install FastStream with Redis support using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_40\n\nLANGUAGE: bash\nCODE:\n```\npip install \"faststream[redis]\"\n```\n\n----------------------------------------\n\nTITLE: Generating Dynamic Message Payload\nDESCRIPTION: Example of using a function to generate message payload dynamically before sending.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nasync def collect_information_to_send():\n    return \"Message to send\"\n\ntaskiq_broker.task(\n    message=collect_information_to_send,\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Taskiq Scheduler with AIOKafka\nDESCRIPTION: Example of setting up a Taskiq scheduler with AIOKafka, including task definition and scheduler initialization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom taskiq_faststream import StreamScheduler\nfrom taskiq.schedule_sources import LabelScheduleSource\n\ntaskiq_broker.task(\n    message={\"user\": \"John\", \"user_id\": 1},\n    topic=\"in-topic\",\n    schedule=[{\n        \"cron\": \"* * * * *\",\n    }],\n)\n\nscheduler = StreamScheduler(\n    broker=taskiq_broker,\n    sources=[LabelScheduleSource(taskiq_broker)],\n)\n```\n\n----------------------------------------\n\nTITLE: Viewing AsyncAPI Documentation for FastStream Project\nDESCRIPTION: Serve the AsyncAPI documentation locally to review changes. Replace <directory-name> with the appropriate directory containing app.py.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nfaststream docs serve <directory-name>.application:app\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost in FastStream Documentation\nDESCRIPTION: This YAML configuration sets the search boost parameter for the documentation page. It assigns a boost value of 0.5 to improve search relevance for this particular page.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/get_dependant/mark_faststream_decorated.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: Adding Manual Start Method to RPCWorker Class in Python\nDESCRIPTION: This code snippet adds a manual start method to the RPCWorker class, allowing it to be started after the FastStream application has initialized.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/rpc.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass RPCWorker:\n    async def start(self) -> None:\n        self.broker.setup_subscriber(self.subscriber)\n        await self.subscriber.start()\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with OpenTelemetry Support using pip\nDESCRIPTION: This command installs FastStream with OpenTelemetry SDK support, which is necessary for implementing tracing in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/tracing.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install faststream[otel]\n```\n\n----------------------------------------\n\nTITLE: Activating the Virtual Environment for FastStream Development\nDESCRIPTION: Activates the Python virtual environment to work in the isolated FastStream development environment.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsource ./venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Removing Global Context Fields in FastStream\nDESCRIPTION: Shows how to remove a field from the global context using the reset_global method.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/custom.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ncontext.reset_global(\"my_key\")\n```\n\n----------------------------------------\n\nTITLE: Importing Message Type from RabbitMQ\nDESCRIPTION: Shows how to import the RabbitMessage type directly from the rabbit module, which is an alias to the annotated version. This provides a shorthand for accessing the message type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitMessage\n```\n\n----------------------------------------\n\nTITLE: Creating RedisBroker and FastStream App\nDESCRIPTION: This code creates a RedisBroker instance and wraps it in a FastStream app, which allows starting the app using CLI later.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/subscription.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbroker = RedisBroker()\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncAPIApplication Class in Python\nDESCRIPTION: This code snippet shows how to import the AsyncAPIApplication class from the FastStream AsyncAPI proto module. It's a key class for working with AsyncAPI in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/proto/AsyncAPIApplication.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.asyncapi.proto import AsyncAPIApplication\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream AsyncAPI Schema Info Class in Python\nDESCRIPTION: This code snippet references the Info class from the FastStream AsyncAPI schema info module. It is likely used to include detailed information about the API in the generated documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/info/Info.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.schema.info.Info\n```\n\n----------------------------------------\n\nTITLE: Importing RedisRouter Class from FastStream Redis Module\nDESCRIPTION: This code snippet demonstrates how to import the RedisRouter class from the faststream.redis.router module. The RedisRouter class is likely used for handling Redis-related routing in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/router/RedisRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.router import RedisRouter\n```\n\n----------------------------------------\n\nTITLE: Accessing Specific Context Object Field\nDESCRIPTION: This snippet demonstrates how to access a specific field of a context object in FastStream. It shows how to retrieve the 'topic' field from the message object.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/fields.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntopic: str = Context(\"message.topic\")\n```\n\n----------------------------------------\n\nTITLE: Importing Annotated Aliases for AIOKafka\nDESCRIPTION: Shows the import statement for all available annotated aliases specific to the AIOKafka broker. These provide type hints for broker-specific objects when used as function parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.annotations import (\n    Logger, ContextRepo, KafkaMessage,\n    KafkaBroker, KafkaProducer, NoCast,\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Deployed AsyncAPI Documentation\nDESCRIPTION: URL format for viewing the AsyncAPI documentation hosted on GitHub Pages. Replace <username> and <repo-name> with appropriate values.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_16\n\nLANGUAGE: txt\nCODE:\n```\nhttps://<username>.github.io/<repo-name>/\n```\n\n----------------------------------------\n\nTITLE: Installing Cookiecutter Package\nDESCRIPTION: Command to install the cookiecutter package using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install cookiecutter\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream and RedisBroker\nDESCRIPTION: This snippet shows how to import the necessary classes from FastStream for working with Redis streams.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/redis/streams/groups.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.redis import RedisBroker\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream and KafkaBroker\nDESCRIPTION: This snippet shows how to import the necessary modules from FastStream to create a Kafka subscriber. It imports the FastStream base class and the KafkaBroker for Kafka-specific functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: Front matter configuration for FastStream documentation pages including API weightings, release info, and search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/middlewares/logging/CriticalLogMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with AIOKafka\nDESCRIPTION: Command to install FastStream with Kafka support using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\npip install \"faststream[kafka]\"\n```\n\n----------------------------------------\n\nTITLE: Running Taskiq Scheduler via CLI\nDESCRIPTION: Command to run the Taskiq scheduler using the CLI.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ntaskiq scheduler module:scheduler\n```\n\n----------------------------------------\n\nTITLE: Importing RedisRouter from FastStream Redis FastAPI Module\nDESCRIPTION: This code snippet shows how to import the RedisRouter class from the faststream.redis.fastapi module. The RedisRouter is likely used to integrate Redis functionality with FastAPI routes in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/fastapi/RedisRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.fastapi import RedisRouter\n```\n\n----------------------------------------\n\nTITLE: Defining Header Class for FastStream Context Management in Python\nDESCRIPTION: This code snippet defines the Header class, which is part of FastStream's context management utilities. It provides methods for managing request headers, including setting, getting, and deleting header values.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/context/Header.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Header:\n    \"\"\"Request header wrapper\"\"\"\n\n    def __init__(self, headers: dict[str, str] | None = None) -> None:\n        self._headers = headers or {}\n\n    def __getitem__(self, key: str) -> str:\n        return self._headers[key]\n\n    def __setitem__(self, key: str, value: str) -> None:\n        self._headers[key] = value\n\n    def __delitem__(self, key: str) -> None:\n        del self._headers[key]\n\n    def __contains__(self, key: str) -> bool:\n        return key in self._headers\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self._headers)\n\n    def __len__(self) -> int:\n        return len(self._headers)\n\n    def __repr__(self) -> str:\n        return f\"Header({self._headers})\"\n\n    def get(self, key: str, default: str | None = None) -> str | None:\n        return self._headers.get(key, default)\n\n    def items(self) -> ItemsView[str, str]:\n        return self._headers.items()\n\n    def keys(self) -> KeysView[str]:\n        return self._headers.keys()\n\n    def values(self) -> ValuesView[str]:\n        return self._headers.values()\n\n    def pop(self, key: str, default: str | None = None) -> str | None:\n        return self._headers.pop(key, default)\n\n    def clear(self) -> None:\n        self._headers.clear()\n\n    def update(self, other: dict[str, str] | None = None, **kwargs: str) -> None:\n        if other is not None:\n            self._headers.update(other)\n        self._headers.update(kwargs)\n```\n\n----------------------------------------\n\nTITLE: Referencing AsyncAPIDefaultPublisher Class in Python\nDESCRIPTION: This code snippet shows how to reference the AsyncAPIDefaultPublisher class from the FastStream Confluent publisher asyncapi module. It's used to import and potentially use this class in a FastStream project.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/publisher/asyncapi/AsyncAPIDefaultPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.publisher.asyncapi.AsyncAPIDefaultPublisher\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaRegistrator Class in Python\nDESCRIPTION: This code snippet shows how to import the KafkaRegistrator class from the FastStream Kafka broker registrator module. It's a key component for registering Kafka-related functionality in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/broker/registrator/KafkaRegistrator.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.broker.registrator import KafkaRegistrator\n```\n\n----------------------------------------\n\nTITLE: Importing StreamRouter from FastStream's FastAPI Integration\nDESCRIPTION: This code snippet demonstrates how to import the StreamRouter class from the faststream.broker.fastapi module. StreamRouter is likely a key component for integrating FastStream with FastAPI applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/StreamRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.fastapi import StreamRouter\n```\n\n----------------------------------------\n\nTITLE: Using Annotated Aliases in Confluent\nDESCRIPTION: Demonstrates how to use annotated aliases for accessing context objects in Confluent Kafka with proper typing. This approach provides more explicit type hints for the context objects being accessed.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nfrom faststream.confluent.annotations import (\n    KafkaMessage,\n    KafkaBroker,\n    KafkaProducer,\n    Logger,\n    ContextRepo,\n)\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: KafkaBroker,  # access to the broker\n    context: ContextRepo,  # access to the context\n    logger: Logger,  # access to the logger\n    message: KafkaMessage,  # access to the raw message\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n\n    # access to message properties\n    print(message.offset)\n```\n\n----------------------------------------\n\nTITLE: Using Annotated Aliases in RabbitMQ\nDESCRIPTION: Shows how to use annotated aliases for accessing context objects in RabbitMQ with proper typing. This approach provides more explicit type hints for the context objects being accessed.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker\nfrom faststream.rabbit.annotations import (\n    RabbitMessage,\n    RabbitBroker,\n    RabbitProducer,\n    Logger,\n    ContextRepo,\n)\n\n# ...\n\n@app.subscriber(\"test\")\nasync def publisher_handler(\n    body: dict,\n    broker: RabbitBroker,  # access to the broker\n    context: ContextRepo,  # access to the context\n    logger: Logger,  # access to the logger\n    message: RabbitMessage,  # access to the raw message\n) -> None:\n    # now, you can call all the broker methods\n    await broker.publish(\n        {\"hello\": \"world\"},\n        \"response\",\n    )\n\n    # also, you can access and write to context\n    context.my_field = body[\"data\"]\n\n    # logger already contains a `message_id` tag\n    # to link all your logs in one scope\n    logger.info(\"Publisher handler is called!\")\n\n    # access to message properties\n    print(message.routing_key)\n```\n\n----------------------------------------\n\nTITLE: Importing LogicSubscriber from FastStream Kafka Module\nDESCRIPTION: This code snippet demonstrates how to import the LogicSubscriber class from the FastStream Kafka subscriber module. It's a key component for implementing custom logic in Kafka subscribers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/usecase/LogicSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.subscriber.usecase import LogicSubscriber\n```\n\n----------------------------------------\n\nTITLE: Disabling Default Logging in FastStream\nDESCRIPTION: Demonstrates how to completely disable the default logging of FastStream by setting logger=None for both the broker and the FastStream app.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.rabbit import RabbitBroker\n\nbroker = RabbitBroker(logger=None)     # Disables broker logs\napp = FastStream(broker, logger=None)  # Disables application logs\n```\n\n----------------------------------------\n\nTITLE: Initializing KafkaBroker Instance for Basic Publishing\nDESCRIPTION: Creates a KafkaBroker instance configured to connect to a Kafka broker at the specified bootstrap server address.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/raw_publish/example.py [ln:7] !}\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream ASGI Search Parameters\nDESCRIPTION: YAML configuration block defining search boost settings and page hierarchy for FastStream ASGI documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asgi/AsgiFastStream.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asgi.AsgiFastStream\n```\n\n----------------------------------------\n\nTITLE: Configuring RabbitBroker with AsyncAPI Schema URL in Python\nDESCRIPTION: Example showing how to hide connection secrets in AsyncAPI schema by manually setting up the server URL. This allows for concealing sensitive information in public documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nbroker = RabbitBroker(\n    \"amqp://guest:guest@localhost:5672/\",  # Connection URL\n    asyncapi_url=\"amqp://****:****@localhost:5672/\",  # Public schema URL\n)\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Prometheus Support\nDESCRIPTION: Command to install FastStream with Prometheus metrics support via pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_2\n\nLANGUAGE: cmd\nCODE:\n```\npip install faststream[prometheus]\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream Context Documentation\nDESCRIPTION: Markdown directive that imports and displays the documentation for the Context class from the FastStream broker's FastAPI context module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/fastapi/Context.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.broker.fastapi.context.Context\n```\n\n----------------------------------------\n\nTITLE: Changing to Project Directory\nDESCRIPTION: Command to change the working directory to the newly created project directory.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd <directory-name>\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream via pip\nDESCRIPTION: Command for installing the FastStream library using pip package manager.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/yield.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install faststream\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Confluent Prometheus Provider Class in Markdown\nDESCRIPTION: This snippet references the BaseConfluentMetricsSettingsProvider class from the FastStream Confluent Prometheus module. It's likely used to generate or link to the class documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/prometheus/provider/BaseConfluentMetricsSettingsProvider.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.confluent.prometheus.provider.BaseConfluentMetricsSettingsProvider\n```\n\n----------------------------------------\n\nTITLE: Initializing KafkaBroker Instance for Publisher Objects\nDESCRIPTION: Creates a KafkaBroker instance for use with dedicated publisher objects that will be documented in AsyncAPI.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/publisher_object/example.py [ln:8] !}\n```\n\n----------------------------------------\n\nTITLE: Importing Context Management Utility in FastStream\nDESCRIPTION: This code snippet demonstrates how to import the get_watcher_context utility function from the FastStream broker utilities module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/utils/get_watcher_context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.utils import get_watcher_context\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncAPIPublisher from FastStream Redis module in Python\nDESCRIPTION: This code snippet shows how to import the AsyncAPIPublisher class from the faststream.redis.publisher.asyncapi module. It's likely used for publishing messages to Redis using AsyncAPI specifications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/publisher/asyncapi/AsyncAPIPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.publisher.asyncapi import AsyncAPIPublisher\n```\n\n----------------------------------------\n\nTITLE: Creating Redis Subscriber with FastStream\nDESCRIPTION: This code snippet shows the signature of the 'create_subscriber' function from the FastStream Redis subscriber factory. It is used to create a Redis subscriber instance with various configuration options.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/subscriber/factory/create_subscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef create_subscriber(\n    url: Optional[str] = None,\n    *,\n    host: str = \"localhost\",\n    port: int = 6379,\n    db: int = 0,\n    password: Optional[str] = None,\n    username: Optional[str] = None,\n    ssl: bool = False,\n    ssl_certfile: Optional[str] = None,\n    ssl_keyfile: Optional[str] = None,\n    ssl_keyfile_password: Optional[str] = None,\n    ssl_ca_certs: Optional[str] = None,\n    max_connections: int = 10,\n    client_name: Optional[str] = None,\n    auto_reconnect: bool = True,\n    decode_responses: bool = False,\n    redis_class: Type[Redis] = Redis,\n    **kwargs: Any,\n) -> RedisSubscriber:\n```\n\n----------------------------------------\n\nTITLE: Starting RabbitMQ Test Broker Container\nDESCRIPTION: Docker command to start a RabbitMQ test broker container for development purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --rm -p 5672:5672 --name test-mq rabbitmq:alpine\n```\n\n----------------------------------------\n\nTITLE: Running All FastStream Tests Including Slow Tests\nDESCRIPTION: Executes all tests including those marked as 'slow' by using the pytest marker 'all', which is useful for comprehensive testing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npytest -m 'all'\n```\n\n----------------------------------------\n\nTITLE: Header Object Usage Example\nDESCRIPTION: Shows syntax for using the Header object as a shortcut to access message header fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_46\n\nLANGUAGE: python\nCODE:\n```\n\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Tests with Pytest\nDESCRIPTION: Executes the test suite for FastStream using pytest, which can be done directly via pytest or through provided shell scripts with optional coverage output.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npytest tests\n# or\n./scripts/test.sh\n# with coverage output\n./scripts/test-cov.sh\n```\n\n----------------------------------------\n\nTITLE: Referencing CompressionCodec Configuration in FastStream Confluent\nDESCRIPTION: This code snippet references the CompressionCodec configuration class from the FastStream Confluent integration. It's likely used to specify compression settings for Kafka messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/config/CompressionCodec.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.config.CompressionCodec\n```\n\n----------------------------------------\n\nTITLE: Running FastStream app with environment file\nDESCRIPTION: Command to run a FastStream application with a specific environment file for configuration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run serve:app --env=.env.dev\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Application with Environment Configuration\nDESCRIPTION: Command to run a FastStream application with a specific environment configuration file.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/hooks.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nfaststream run serve:app --env .env.test\n```\n\n----------------------------------------\n\nTITLE: Referencing AsyncAPIBatchSubscriber Class in Python\nDESCRIPTION: This code snippet shows how to reference the AsyncAPIBatchSubscriber class from the FastStream Confluent subscriber module. It's used to import the class for use in AsyncAPI batch operations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/subscriber/asyncapi/AsyncAPIBatchSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.subscriber.asyncapi import AsyncAPIBatchSubscriber\n```\n\n----------------------------------------\n\nTITLE: Defining StreamQueueArgs Class for RabbitMQ Queue Configuration in Python\nDESCRIPTION: This code snippet defines the StreamQueueArgs class, which is used to specify parameters for RabbitMQ stream queues in FastStream. It includes various configuration options such as maximum age, maximum length bytes, and leader locator.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/queue/StreamQueueArgs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass StreamQueueArgs(BaseModel):\n    \"\"\"Arguments for declaring a stream.\"\"\"\n\n    max_age: Optional[str] = None\n    max_length_bytes: Optional[int] = None\n    max_segment_size_bytes: Optional[int] = None\n    leader_locator: Optional[Literal[\"client-local\", \"balanced\"]] = None\n    initial_cluster_size: Optional[int] = None\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncAPISubscriber from FastStream NATS Module\nDESCRIPTION: This code snippet shows how to import the AsyncAPISubscriber class from the FastStream NATS subscriber asyncapi module. It's a placeholder for the actual class documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/asyncapi/AsyncAPISubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.subscriber.asyncapi import AsyncAPISubscriber\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncAPIListSubscriber from FastStream Redis Module\nDESCRIPTION: This code snippet shows how to import the AsyncAPIListSubscriber class from the FastStream Redis subscriber module. It is used for handling asynchronous API list subscriptions in Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/subscriber/asyncapi/AsyncAPIListSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.subscriber.asyncapi import AsyncAPIListSubscriber\n```\n\n----------------------------------------\n\nTITLE: Checking Signature Parameter in FastStream FastAPI Integration\nDESCRIPTION: This code snippet is likely part of a function that checks if a parameter in a FastAPI dependency has a specific signature. It's used in the context of FastStream's integration with FastAPI for handling broker operations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/get_dependant/has_signature_param.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.broker.fastapi.get_dependant.has_signature_param\n```\n\n----------------------------------------\n\nTITLE: Initializing ListBatchPublisher for Redis in Python\nDESCRIPTION: This code snippet shows the initialization of a ListBatchPublisher object for Redis. It includes parameters for connection details, batch size, and other configuration options.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/publisher/usecase/ListBatchPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass ListBatchPublisher(BaseBatchPublisher):\n    def __init__(\n        self,\n        url: str = \"redis://localhost:6379\",\n        *,\n        max_batch_size: int = 10,\n        flush_interval: float = 1,\n        max_queue_size: int = 10_000,\n        client: Optional[Redis] = None,\n        **kwargs: Any,\n    ) -> None:\n        super().__init__(\n            max_batch_size=max_batch_size,\n            flush_interval=flush_interval,\n            max_queue_size=max_queue_size,\n        )\n        self.client = client or Redis.from_url(url, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Manual Local Context Management in FastStream\nDESCRIPTION: Shows manual management of local context using set_local, get_local, and reset_local methods within the current call stack, with logging function demonstrating context access.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/custom.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom contextlib import suppress\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream import context\n\nbroker = KafkaBroker()\n\n\nasync def log_request():\n    # access local context value\n    with suppress(KeyError):\n        request_id = context.get_local(\"request_id\")\n        print(f\"Processing request: {request_id}\")\n\n\n@broker.subscriber(\"test\")\nasync def handle_message(body: str):\n    # Set local context\n    context.set_local(\"request_id\", \"12345\")\n\n    # access local context value\n    await log_request()\n\n    # Clear local context\n    context.reset_local(\"request_id\")\n\n    # Context is cleared\n    await log_request()\n\n\napp = FastStream(broker)\n```\n\n----------------------------------------\n\nTITLE: Installing Taskiq-FastStream Package\nDESCRIPTION: Command to install the Taskiq-FastStream package using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/scheduling.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install taskiq-faststream\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Environment with venv for FastStream Development\nDESCRIPTION: Creates a Python virtual environment in a directory named 'venv' using Python's built-in venv module, which allows for isolated package installation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv venv\n```\n\n----------------------------------------\n\nTITLE: Running Static Analysis for FastStream Project\nDESCRIPTION: Execute static analysis tools mypy and bandit to identify potential issues in the codebase.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/static-analysis.sh\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation\nDESCRIPTION: Defines documentation metadata including search boost and page priority numbers for different sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/fastapi/fastapi/KafkaRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Defining LogLevels Enum for FastStream CLI in Python\nDESCRIPTION: This code defines a Python Enum class called LogLevels that represents standard logging levels. It maps human-readable log level names to their corresponding integer values as defined in the standard logging module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/logs/LogLevels.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"CLI Logs utilities.\"\"\"\nfrom enum import Enum\n\n\nclass LogLevels(str, Enum):\n    \"\"\"Standard log levels.\"\"\"\n\n    CRITICAL = \"CRITICAL\"\n    ERROR = \"ERROR\"\n    WARNING = \"WARNING\"\n    INFO = \"INFO\"\n    DEBUG = \"DEBUG\"\n```\n\n----------------------------------------\n\nTITLE: Importing filter_by_dict Function from FastStream Utils\nDESCRIPTION: This code snippet shows how to import the filter_by_dict function from the FastStream utils.data module. This function is likely used for filtering dictionaries based on specific criteria within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/data/filter_by_dict.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.utils.data.filter_by_dict\n```\n\n----------------------------------------\n\nTITLE: TestApp Class Definition in FastStream Testing Module\nDESCRIPTION: The TestApp class provides testing functionality for FastStream applications. It includes methods for initializing test applications, simulating message processing, and verifying application behavior during tests.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/testing/app/TestApp.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.testing.app.TestApp\n```\n\n----------------------------------------\n\nTITLE: Specifying fastavro Dependency for FastStream Project\nDESCRIPTION: This snippet declares 'fastavro' as a required dependency for the FastStream project. Fastavro is a fast Avro reader/writer implementation for Python, used for serializing and deserializing Avro data.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/examples/serialization/avro/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfastavro\n```\n\n----------------------------------------\n\nTITLE: Page Configuration YAML Definition\nDESCRIPTION: YAML frontmatter configuration defining page weights, categories and search boost settings for documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/KvWatch.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream HandlerException Class\nDESCRIPTION: This code snippet demonstrates how to reference or import the HandlerException class from the faststream.exceptions module. It's likely used to handle specific error conditions within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/exceptions/HandlerException.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.exceptions.HandlerException\n```\n\n----------------------------------------\n\nTITLE: Importing NatsResponse from FastStream NATS Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the NatsResponse class from the FastStream NATS response module. It's typically used to handle responses in NATS-based messaging systems within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/response/NatsResponse.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.response import NatsResponse\n```\n\n----------------------------------------\n\nTITLE: Importing BatchPullStreamSubscriber from FastStream NATS module in Python\nDESCRIPTION: This code snippet shows how to import the BatchPullStreamSubscriber class from the FastStream NATS subscriber usecase module. It's a key component for batch processing of messages from NATS streams.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/usecase/BatchPullStreamSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.subscriber.usecase import BatchPullStreamSubscriber\n```\n\n----------------------------------------\n\nTITLE: NatsMessage Class Reference Directive\nDESCRIPTION: Sphinx/documentation directive referencing the NatsMessage class from the faststream.nats.message module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/message/NatsMessage.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.nats.message.NatsMessage\n```\n\n----------------------------------------\n\nTITLE: Activating the Virtual Environment for FastStream Development\nDESCRIPTION: Activates the previously created virtual environment so that Python packages will be installed and used from this isolated environment rather than the system Python.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsource ./venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Dictionary Keys in Python\nDESCRIPTION: Demonstrates how to access inner dictionary keys from the Context object in FastStream handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_45\n\nLANGUAGE: python\nCODE:\n```\n# headers is a `dict`\nasync def handler(\n  user_id: int = Context(\"message.headers.user_id\", cast=True),\n): ...\n```\n\n----------------------------------------\n\nTITLE: Creating a basic Kafka consumer in FastStream\nDESCRIPTION: Example of creating a Kafka consumer service with a handler function that processes incoming messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/yield.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\n# Create a broker\nbroker = KafkaBroker(\"localhost:9092\")\n\n# Create a handler\n@broker.subscriber(\"test-topic\")\nasync def process_message(msg: str):\n    print(msg)\n    \n# Create service\napp = FastStream(broker)\n\n# Run application\nif __name__ == \"__main__\":\n    app.run()\n```\n\n----------------------------------------\n\nTITLE: Configuring search and page metadata in YAML\nDESCRIPTION: YAML front matter block defining page weights, categories and search boost settings for documentation site. Sets relative importance of different page types and configures search behavior.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/Channel.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Creating NATS Subscriber with FastStream in Python\nDESCRIPTION: This function creates a NATS subscriber using FastStream. It handles subscription to NATS subjects, message processing, and error handling. The function supports various parameters for customizing the subscriber behavior.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/factory/create_subscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef create_subscriber(\n    self,\n    subject: str,\n    stream: str | None = None,\n    durable: str | None = None,\n    queue: str | None = None,\n    manual_ack: bool = False,\n    ack_wait: float | None = None,\n    max_inflight: int | None = None,\n    replay_policy: NatsReplayPolicy | None = None,\n    deliver_policy: NatsDeliveryPolicy | None = None,\n    start_sequence: int | None = None,\n    start_time: datetime | None = None,\n    delay_js: bool = False,\n    consumer_name: str | None = None,\n    name: str | None = None,\n    description: str | None = None,\n    filter_subject: str | None = None,\n    rate_limit: int | None = None,\n    max_deliver: int | None = None,\n    max_waiting: int | None = None,\n    max_bytes: int | None = None,\n    consumer_inactive_threshold: str | None = None,\n    idle_heartbeat: str | None = None,\n    consumer_memory_storage: bool | None = None,\n    num_replicas: int | None = None,\n    max_ack_pending: int | None = None,\n) -> ContextManager[Callable[[Any], Awaitable[NatsMessage]]]:\n```\n\n----------------------------------------\n\nTITLE: Referencing AsyncAPIConcurrentDefaultSubscriber Class in Python\nDESCRIPTION: This code snippet shows how to reference the AsyncAPIConcurrentDefaultSubscriber class from the FastStream Kafka subscriber module. It's likely used for importing or documenting the class in API documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/asyncapi/AsyncAPIConcurrentDefaultSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.kafka.subscriber.asyncapi.AsyncAPIConcurrentDefaultSubscriber\n```\n\n----------------------------------------\n\nTITLE: Server Console Output When Serving AsyncAPI Documentation\nDESCRIPTION: Expected console output when the AsyncAPI documentation server is running successfully.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/hosting.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nINFO:     Started server process [2364992]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n```\n\n----------------------------------------\n\nTITLE: Defining LogicPublisher Class for FastStream Confluent Integration\nDESCRIPTION: The LogicPublisher class implementation that extends BasePublisher to provide Confluent Kafka-specific publishing capabilities. It manages connection to Kafka topics and handles message serialization and delivery.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/publisher/usecase/LogicPublisher.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass LogicPublisher(BasePublisher):\n    \"\"\"Confluent publisher that handles sending messages to Kafka.\"\"\"\n\n    def __init__(\n        self,\n        *,\n        topic: str,\n        serializer: ConfluentSerializer,\n        partition: Optional[int] = None,\n        key: Optional[str] = None,\n        headers: Optional[Dict[str, str]] = None,\n        middlewares: Optional[List] = None,\n        **__,\n    ) -> None:\n        \"\"\"Initialize a Confluent publisher.\n\n        Args:\n            topic: The topic to publish to.\n            serializer: The serializer to use for messages.\n            partition: The partition to publish to. Defaults to None, which means the partitioner will decide.\n            key: The key to use for messages. Defaults to None.\n            headers: The headers to use for messages. Defaults to None.\n            middlewares: List of middlewares to apply to the publisher.\n        \"\"\"\n        super().__init__(middlewares=middlewares)\n        self.topic = topic\n        self.partition = partition\n        self.key = key\n        self.headers = headers\n        self.serializer = serializer\n\n    async def publish(\n        self,\n        message: SendableMessage,\n        *,\n        topic: Optional[str] = None,\n        key: Optional[str] = None,\n        partition: Optional[int] = None,\n        headers: Optional[Dict[str, str]] = None,\n        **__,\n    ) -> None:\n        \"\"\"Publish a message to Kafka.\n\n        Args:\n            message: The message to publish.\n            topic: The topic to publish to. Defaults to the publisher's topic.\n            key: The key to use for the message. Defaults to the publisher's key.\n            partition: The partition to publish to. Defaults to the publisher's partition.\n            headers: The headers to use for the message. Defaults to the publisher's headers.\n        \"\"\"\n        to_publish = self.apply_middlewares(message)\n\n        serialized = await self.serializer.serialize(\n            to_publish if not isinstance(to_publish, ConfluentMessage) else to_publish.model_dump()\n            if hasattr(to_publish, \"model_dump\")\n            else model_to_dict(to_publish)\n            if hasattr(to_publish, \"__pydantic_fields_set__\")\n            else to_publish\n        )\n\n        kwargs = {}\n        if key or self.key:\n            kwargs[\"key\"] = key or self.key\n        if partition or self.partition:\n            kwargs[\"partition\"] = partition or self.partition\n        if headers or self.headers:\n            kwargs[\"headers\"] = headers or self.headers\n\n        await self.serializer.producer.send_and_wait(\n            topic or self.topic,\n            serialized,\n            **kwargs,\n        )\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Utils NoCast Class in Markdown\nDESCRIPTION: This snippet references the NoCast class from the FastStream utils module. It uses a specific documentation syntax to link or import the class definition.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/NoCast.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.utils.NoCast\n```\n\n----------------------------------------\n\nTITLE: Importing JStream from FastStream NATS module in Python\nDESCRIPTION: This code snippet demonstrates how to import the JStream class from the FastStream NATS module. It's likely used for working with NATS JetStream functionality within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/schemas/JStream.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.schemas import JStream\n```\n\n----------------------------------------\n\nTITLE: Importing ConsumerProtocol from faststream.confluent.message\nDESCRIPTION: This code snippet demonstrates how to import the ConsumerProtocol class from the faststream.confluent.message module. It is used to access the consumer protocol functionality for Confluent Kafka in the faststream library.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/message/ConsumerProtocol.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.message import ConsumerProtocol\n```\n\n----------------------------------------\n\nTITLE: Importing ignore_handler from FastStream Broker Middleware in Python\nDESCRIPTION: This code snippet demonstrates how to import the ignore_handler function from the FastStream broker middleware exception module. The ignore_handler is likely used for handling exceptions in a specific way within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/middlewares/exception/ignore_handler.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.middlewares.exception import ignore_handler\n```\n\n----------------------------------------\n\nTITLE: Defining KafkaRoute Class in FastStream Kafka Router\nDESCRIPTION: This code snippet defines the KafkaRoute class, which is likely used for routing messages in a Kafka-based messaging system within the FastStream framework. The class is imported from the faststream.kafka.router module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/router/KafkaRoute.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.kafka.router.KafkaRoute\n```\n\n----------------------------------------\n\nTITLE: Using Path for Topic Pattern Access in FastStream Python\nDESCRIPTION: This code demonstrates how to use the Path object to access variables from topic patterns in a FastStream RabbitMQ subscriber function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/rabbit/message.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Path\nfrom faststream import RabbitQueue, RabbitExchane, ExchangeType\n\n@broker.subscriber(\n    RabbitQueue(\n        \"test-queue\",\n        routing_key=\"logs.{level}\",\n    ),\n    RabbitExchange(\n        \"test-exchange\",\n        type=ExchangeType.TOPIC,\n    )\n)\nasync def base_handler(\n    body: str,\n    level: str = Path(),\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Defining TestApp Class in FastStream Testing Module\nDESCRIPTION: The TestApp class is part of the FastStream testing module. This code snippet shows the class definition and its import path. TestApp is likely a utility for testing FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/TestApp.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.testing.app.TestApp\n```\n\n----------------------------------------\n\nTITLE: Running FastStream CLI from Local Source\nDESCRIPTION: Executes the FastStream Command Line Interface using the local development version instead of an installed package.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m faststream ...\n```\n\n----------------------------------------\n\nTITLE: Importing Annotated Aliases for Redis\nDESCRIPTION: Shows the import statement for all available annotated aliases specific to the Redis broker. These provide type hints for broker-specific objects when used as function parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.annotations import (\n    Logger, ContextRepo, RedisMessage,\n    RedisBroker, Redis, NoCast,\n)\n```\n\n----------------------------------------\n\nTITLE: FastStream Search Configuration YAML\nDESCRIPTION: YAML configuration block defining search boost parameters and document structure sections with numeric weights for different documentation components.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asgi/make_asyncapi_asgi.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Contact Class Definition in FastStream AsyncAPI Schema\nDESCRIPTION: The Contact class defines contact information for an AsyncAPI specification. It extends Pydantic's BaseModel and includes fields for name, url, and email with their respective validators.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/info/Contact.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Contact(BaseModel):\n    \"\"\"Contact information for the exposed API.\"\"\"\n\n    name: Optional[str] = None\n    \"\"\"The identifying name of the contact person/organization.\"\"\"\n\n    url: Optional[AnyUrl] = None\n    \"\"\"The URL pointing to the contact information. MUST be in the format of a URL.\"\"\"\n\n    email: Optional[EmailStr] = None\n    \"\"\"The email address of the contact person/organization. MUST be in the format of an email address.\"\"\"\n\n    @field_validator(\"email\", mode=\"before\")\n    @classmethod\n    def validate_email(cls, email: str) -> str:\n        if not email:\n            return email\n\n        try:\n            validate_email(email)\n        except InvalidEmail as e:\n            raise ValueError(f\"Invalid email: {e}\") from e\n\n        return email\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream AsyncAPI Schema Utils in Python\nDESCRIPTION: This code snippet demonstrates how to import the ExternalDocs class from FastStream's AsyncAPI schema utilities module. It's likely used for documentation generation or reference purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/utils/ExternalDocs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.schema.utils.ExternalDocs\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream Release Candidate via pip\nDESCRIPTION: Command to install the FastStream release candidate version 0.5.0rc0 using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_27\n\nLANGUAGE: console\nCODE:\n```\npip install faststream==0.5.0rc0\n```\n\n----------------------------------------\n\nTITLE: Defining FastStream CLI Main Run Function in Python\nDESCRIPTION: This function is the entry point for the FastStream CLI. It sets up the application, handles command-line arguments, and initializes the FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/main/run.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef run(\n    app: str,\n    controller: str | None = None,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n    reload: bool = False,\n    workers: int = 1,\n    log_level: str = \"info\",\n    log_config: str | None = None,\n    env_file: str | None = None,\n) -> None:\n    \"\"\"Run the FastStream application.\n\n    Args:\n        app (str): The FastStream application to run.\n        controller (str | None, optional): The controller to use. Defaults to None.\n        host (str, optional): The host to bind to. Defaults to \"127.0.0.1\".\n        port (int, optional): The port to bind to. Defaults to 8000.\n        reload (bool, optional): Whether to reload the application on code changes. Defaults to False.\n        workers (int, optional): The number of worker processes. Defaults to 1.\n        log_level (str, optional): The log level. Defaults to \"info\".\n        log_config (str | None, optional): The log configuration file. Defaults to None.\n        env_file (str | None, optional): The environment file to load. Defaults to None.\n    \"\"\"\n    import uvicorn\n    from faststream.cli.utils import import_from_string, load_env\n\n    load_env(env_file)\n\n    app = import_from_string(app)\n    if controller:\n        controller = import_from_string(controller)\n        app = controller(app)\n\n    uvicorn.run(\n        app,\n        host=host,\n        port=port,\n        reload=reload,\n        workers=workers,\n        log_level=log_level,\n        log_config=log_config,\n    )\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Broker FastAPI Function\nDESCRIPTION: This code block references a specific function in the FastStream library, likely for getting FastAPI native dependants in the context of a message broker integration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/get_dependant/get_fastapi_native_dependant.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.fastapi.get_dependant.get_fastapi_native_dependant\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Settings in YAML\nDESCRIPTION: YAML front matter configuration for documentation page metadata, including search boost settings and page hierarchy numbers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/message/NatsBatchMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.nats.message.NatsBatchMessage\n```\n\n----------------------------------------\n\nTITLE: Importing Redis Schema Validation Options in FastStream\nDESCRIPTION: This code snippet imports the validate_options module from the faststream.redis.schemas.proto package. It provides access to Redis schema validation options for use in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/schemas/proto/validate_options.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.redis.schemas.proto.validate_options\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Metadata for FastStream Documentation\nDESCRIPTION: This YAML block defines metadata for the FastStream project documentation. It sets up search boost settings and outlines the main sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/middlewares/exception/ExceptionMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Running FastStream app with hot reload\nDESCRIPTION: Command to run a FastStream application with hot reload enabled to automatically restart the app when code changes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run serve:app --reload\n```\n\n----------------------------------------\n\nTITLE: Installing watchfiles for hot reload\nDESCRIPTION: Command to install the watchfiles package required for using the hot reload feature.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npip install watchfiles\n```\n\n----------------------------------------\n\nTITLE: Creating Virtual Environment for FastStream Documentation\nDESCRIPTION: Creates a Python virtual environment for FastStream documentation development to isolate dependencies.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/docs.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv venv\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with OpenTelemetry Dependencies\nDESCRIPTION: Command to install FastStream along with required OpenTelemetry SDK and exporter packages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/index.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install \"faststream[otel]\" opentelemetry-exporter-otlp\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost in YAML\nDESCRIPTION: This YAML snippet sets the search boost value for the page to 0.5. It's likely part of a configuration for a documentation or static site generator.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/get_dependant/get_fastapi_native_dependant.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaRouter from FastStream Confluent Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the KafkaRouter class from the FastStream Confluent router module. It's a key component for setting up Kafka routing in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/router/KafkaRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.router import KafkaRouter\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: YAML frontmatter configuration for documentation page, specifying API priorities, release status, and search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/asyncapi/AsyncAPIBatchPullStreamSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Defining Debug Configuration Class for Confluent Kafka in Python\nDESCRIPTION: The Debug class configures debugging parameters for Confluent Kafka consumers and producers. It includes settings for consumer and producer debugging, with configurable verbosity levels.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/config/Debug.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Debug(BaseModel):\n    \"\"\"Debug configuration for Kafka consumers and producers.\n\n    Attributes:\n        consumer: Debug options for consumers\n        producer: Debug options for producers\n\n    \"\"\"\n\n    consumer: str = \"\"\n    producer: str = \"\"\n```\n\n----------------------------------------\n\nTITLE: Running Django with Gunicorn and Uvicorn Workers\nDESCRIPTION: Command to run Django using Gunicorn with uvicorn workers for ASGI support.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngunicorn asgi:app --workers 4 --worker-class uvicorn.workers.UvicornWorker\n```\n\n----------------------------------------\n\nTITLE: Defining ServerVariable Class in FastStream AsyncAPI Schema (Python)\nDESCRIPTION: This code snippet shows the definition of the ServerVariable class, which is part of FastStream's AsyncAPI schema implementation. It likely includes properties and methods for handling server variables in AsyncAPI specifications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/servers/ServerVariable.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.schema.servers.ServerVariable\n```\n\n----------------------------------------\n\nTITLE: Importing ExchangeType Enumeration from FastStream RabbitMQ Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the ExchangeType enumeration from the FastStream RabbitMQ module. The ExchangeType likely defines constants for different RabbitMQ exchange types such as direct, fanout, topic, and headers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/constants/ExchangeType.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.rabbit.schemas.constants.ExchangeType\n```\n\n----------------------------------------\n\nTITLE: YAML Search Configuration\nDESCRIPTION: Simple YAML configuration block defining search boost parameter and document section weights using numerical prefixes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/wrapper/call/HandlerCallWrapper.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: Serving AsyncAPI Documentation from YAML File\nDESCRIPTION: Command to serve AsyncAPI documentation from a YAML file using FastStream's CLI tool.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/hosting.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nfaststream asyncapi serve asyncapi.yaml\n```\n\n----------------------------------------\n\nTITLE: Using typing.Annotated for Field Declaration in FastStream\nDESCRIPTION: This snippet shows how to use typing.Annotated (Python 3.9+) or typing_extensions.Annotated to declare handler fields in FastStream. It provides an alternative syntax for adding metadata and validations to message fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/pydantic.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n    num: Annotated[\n        int,\n        Field(\n            42,\n            title=\"Number\",\n            description=\"Some number\",\n            examples=[13, 42, 144],\n        ),\n    ],\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream Documentation Dependencies\nDESCRIPTION: Installs the necessary dependencies for FastStream documentation development using pip with the devdocs extra.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/docs.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install \".[devdocs]\"\n```\n\n----------------------------------------\n\nTITLE: Stopping FastStream Test Environment Docker Containers\nDESCRIPTION: Shuts down the Docker containers for message brokers and other dependencies after completing development or testing activities.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/stop_test_env.sh\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with Prometheus support\nDESCRIPTION: Command to install FastStream with the prometheus-client dependency.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/prometheus.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install faststream[prometheus]\n```\n\n----------------------------------------\n\nTITLE: Processing messages with context management in FastStream\nDESCRIPTION: The process_msg utility function handles the entire message processing workflow in FastStream, including setting up context, executing the handler function, managing acknowledgment and error handling. It supports both sync and async handler functions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/utils/process_msg.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nasync def process_msg(\n    message: AbstractMessage,\n    ctx: AbstractContext,\n    handler: object,\n    fn_args: list,\n    fn_kwargs: dict,\n    timeout: Optional[float] = None,\n    retry: Optional[Retry] = None,\n    middlewares: Optional[list[Callable]] = None,\n) -> None:\n    \"\"\"Process message by handler.\"\"\"\n    awaited = False\n\n    task_timeout: Any = False if timeout is None else timeout\n\n    def on_timeout() -> NoReturn:\n        msg = f\"Handler process timeout: {timeout} seconds\"\n        raise TimeoutError(msg)\n\n    async def handle_process() -> Any:\n        nonlocal awaited\n\n        try:\n            orig_ctx = context.set(ctx)\n            orig_msg = message_context.set(message)\n\n            try:\n                handler_result = None\n\n                middlewares_f = middlewares or []\n\n                # apply middlewares\n                chain = reduce(\n                    lambda x, f: wrap_fn(f, x),\n                    middlewares_f,\n                    handler,\n                )\n\n                # call functions\n                handler_result = chain(*fn_args, **fn_kwargs)\n\n                if isawaitable(handler_result):\n                    awaited = True\n                    return await handler_result\n                return handler_result\n            finally:\n                context.reset(orig_ctx)\n                message_context.reset(orig_msg)\n        except Exception:\n            if retry:\n                retry_count = message.retry_count + 1 if message.retry_count else 1\n\n                if retry_count <= retry.retries:\n                    message.retry_count = retry_count\n                    await message.nack()\n\n                    return\n\n            if message.decoded_error:\n                ctx._raise_for_status(message)  # noqa: SLF001\n            raise\n\n    try:\n        handler_result: Any = None\n\n        if task_timeout is not False:\n            try:\n                handler_result = await asyncio.wait_for(\n                    handle_process(),\n                    timeout=task_timeout,\n                    loop=asyncio.get_event_loop(),\n                )\n            except TimeoutError:\n                on_timeout()\n        else:\n            handler_result = await handle_process()\n\n        if not message.is_nacked and not message.is_acked:\n            await message.ack()\n\n        if isinstance(handler_result, tuple) and len(handler_result) == 2:\n            # In case handler returns response message and status\n            return handler_result\n        return handler_result, None\n    except Exception as e:\n        if not message.is_nacked and not message.is_acked:\n            await message.nack()\n        raise e\n```\n\n----------------------------------------\n\nTITLE: Serving AsyncAPI Documentation with CLI Command\nDESCRIPTION: Command to serve AsyncAPI documentation using FastStream's CLI tool, specifying a Python module path.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/hosting.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nfaststream asyncapi serve app:app\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream Search and Schema Settings\nDESCRIPTION: YAML configuration block defining search boost parameters and topic partition schema reference for a FastStream project.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/schemas/partition/TopicPartition.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.schemas.partition.TopicPartition\n```\n\n----------------------------------------\n\nTITLE: Referencing CompressionType Enum in FastStream Confluent Config\nDESCRIPTION: This code snippet references the CompressionType enum from the FastStream Confluent configuration module. It's likely used to specify compression options for Kafka message production or consumption.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/config/CompressionType.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.config.CompressionType\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: YAML frontmatter configuration specifying API priorities, release information, and search boost settings for documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/testing/build_message.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Stopping Test Broker Container\nDESCRIPTION: Docker command to stop the test broker container after use.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ndocker container stop test-mq\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaResponse from FastStream Confluent Module\nDESCRIPTION: Directive to import and document the KafkaResponse class from the faststream.confluent module. This appears to be a Sphinx or MkDocs documentation directive that automatically generates API documentation for this class.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/KafkaResponse.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.KafkaResponse\n```\n\n----------------------------------------\n\nTITLE: Running FastStream CLI from Local Source\nDESCRIPTION: Executes the FastStream command-line interface directly from the local source code rather than from an installed package, allowing for testing of CLI changes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m faststream ...\n```\n\n----------------------------------------\n\nTITLE: Referencing ExceptionMiddleware in FastStream Documentation\nDESCRIPTION: This code block references the ExceptionMiddleware class from the faststream.broker.middlewares.exception module. It's likely used to provide documentation or import the middleware in the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/middlewares/exception/ExceptionMiddleware.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.middlewares.exception.ExceptionMiddleware\n```\n\n----------------------------------------\n\nTITLE: Referencing RawMessage Class in FastStream Redis Parser\nDESCRIPTION: This code snippet references the RawMessage class from the faststream.redis.parser module. It's likely used for handling raw Redis messages in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/parser/RawMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.redis.parser.RawMessage\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Weights in YAML\nDESCRIPTION: YAML configuration block that defines page hierarchy and search boost settings for a documentation page. Sets priority levels for different documentation sections and a search boost value of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/router/KafkaPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.router.KafkaPublisher\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image Locally\nDESCRIPTION: Command to build the Docker image locally using a provided script.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/build_docker.sh <username> <repo-name>\n```\n\n----------------------------------------\n\nTITLE: Collecting Django Static Files\nDESCRIPTION: Command to collect all Django static files to the static directory for serving.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython manage.py collectstatic\n```\n\n----------------------------------------\n\nTITLE: Installing Avro dependencies for FastStream\nDESCRIPTION: This command installs the necessary dependencies for using Avro with FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_6\n\nLANGUAGE: console\nCODE:\n```\npip install fastavro\n```\n\n----------------------------------------\n\nTITLE: Redis Basic Integration with FastStream\nDESCRIPTION: Basic setup for integrating Redis message queue with FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/includes/scheduling/app.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/index/redis/basic.py!}\n```\n\n----------------------------------------\n\nTITLE: Importing Context Class from FastStream's FastAPI Broker Module\nDESCRIPTION: This code snippet demonstrates how to import the Context class from the faststream.broker.fastapi.context module. The Context class is likely a key component for managing context in FastStream applications using FastAPI.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/fastapi/Context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.fastapi.context.Context\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost in Markdown\nDESCRIPTION: This snippet sets the search boost value for the page in the YAML frontmatter. It's used to adjust the relevance of this page in search results.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/prometheus/provider/BaseConfluentMetricsSettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Defining KafkaPrometheusMiddleware Class in Python\nDESCRIPTION: This code snippet defines the KafkaPrometheusMiddleware class, which is likely used for integrating Prometheus metrics with Kafka in the FastStream framework. The class is empty, suggesting it may be a placeholder or that its implementation is defined elsewhere.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/prometheus/KafkaPrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass KafkaPrometheusMiddleware:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Tests Without Broker Dependencies\nDESCRIPTION: Executes tests that don't require messaging brokers (RabbitMQ, Kafka, NATS, Redis, Confluent) to be running.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npytest -m 'not rabbit and not kafka and not nats and not redis and not confluent'\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Pages\nDESCRIPTION: YAML front matter configuration defining page weights and search boost settings for different documentation sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/config/BrokerAddressFamily.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream CLI Documentation Generator Module\nDESCRIPTION: This code snippet imports the documentation generation module from the FastStream CLI application. It uses the ::: syntax, which is likely a custom documentation or import directive.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/docs/app/gen.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.cli.docs.app.gen\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost Settings in YAML\nDESCRIPTION: YAML configuration block that defines search boost parameters and references the FastStream Confluent subscriber implementation. Sets search boost value to 0.5 and includes priority numbering for different sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/subscriber/usecase/ConcurrentDefaultSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.subscriber.usecase.ConcurrentDefaultSubscriber\n```\n\n----------------------------------------\n\nTITLE: Stopping Kafka Docker Container\nDESCRIPTION: Command to stop the Kafka Docker container using a provided script.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/stop_kafka_broker_locally.sh\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Model for Kafka Message Structure\nDESCRIPTION: This code defines a Pydantic model 'HelloWorld' to structure the messages consumed from the Kafka topic. It includes a 'name' field with examples and a description.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/kafka/Subscriber/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass HelloWorld(BaseModel):\n    name: str = Field(\n        ...,\n        examples=[\"John\", \"Mike\"],\n        description=\"User name\",\n    )\n```\n\n----------------------------------------\n\nTITLE: Documenting PublishKwargs Class for FastStream RabbitMQ Publisher in Python\nDESCRIPTION: This code snippet represents the documentation for the PublishKwargs class, which is used in the FastStream library for RabbitMQ publishing. It likely includes details about the parameters used when publishing messages to RabbitMQ.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/publisher/usecase/PublishKwargs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.rabbit.publisher.usecase.PublishKwargs\n```\n\n----------------------------------------\n\nTITLE: Showing FastStream CLI help documentation\nDESCRIPTION: Command to display available CLI commands and options for FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nfaststream --help\n```\n\n----------------------------------------\n\nTITLE: Running Django with Uvicorn\nDESCRIPTION: Command to run Django application using uvicorn ASGI server with multiple workers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/django/index.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuvicorn asgi:app --workers 4\n```\n\n----------------------------------------\n\nTITLE: Defining Markdown Frontmatter for FastStream Documentation\nDESCRIPTION: This snippet defines the frontmatter for a Markdown document, specifying the title as 'FastStream' and setting the template to 'home.html'. This is typically used in static site generators to provide metadata and layout information for the page.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/index.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: FastStream\ntemplate: home.html\n---\n```\n\n----------------------------------------\n\nTITLE: Referencing NatsTelemetryMiddleware Class in Python\nDESCRIPTION: This code snippet shows how to reference the NatsTelemetryMiddleware class from the faststream.nats.opentelemetry.middleware module. It's used to import and potentially utilize the middleware for NATS OpenTelemetry integration in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/opentelemetry/middleware/NatsTelemetryMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.opentelemetry.middleware import NatsTelemetryMiddleware\n```\n\n----------------------------------------\n\nTITLE: FastStream YAML Configuration\nDESCRIPTION: YAML frontmatter configuration for documentation page settings, including search boost parameter and page metadata.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/parser/parse_cli_args.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Reusing Original Decoder for AIOKafka in FastStream\nDESCRIPTION: Demonstrates how to create a custom decoder that reuses the original decoder function for AIOKafka messages. It includes type hints for the original decoder callback.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom types import Callable, Awaitable\nfrom faststream.types import DecodedMessage\nfrom faststream.kafka import KafkaMessage\n\nasync def decoder(\n    msg: KafkaMessage,\n    original_decoder: Callable[[KafkaMessage], Awaitable[DecodedMessage]],\n) -> DecodedMessage:\n    return await original_decoder(msg)\n```\n\n----------------------------------------\n\nTITLE: Starting Kafka Test Broker Container\nDESCRIPTION: Docker command to start a Kafka test broker container for development purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --rm -p 9092:9092 --name test-mq \\\n-e KAFKA_ENABLE_KRAFT=yes \\\n-e KAFKA_CFG_NODE_ID=1 \\\n-e KAFKA_CFG_PROCESS_ROLES=broker,controller \\\n-e KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER \\\n-e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \\\n-e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \\\n-e KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092 \\\n-e KAFKA_BROKER_ID=1 \\\n-e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 \\\n-e ALLOW_PLAINTEXT_LISTENER=yes \\\nbitnami/kafka:3.5.0\n```\n\n----------------------------------------\n\nTITLE: YAML Search Configuration\nDESCRIPTION: YAML configuration block defining search boost parameters and numerical page priorities for different sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/prometheus/middleware/RabbitPrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream with RabbitMQ\nDESCRIPTION: Command to install FastStream with RabbitMQ support using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_3\n\nLANGUAGE: console\nCODE:\n```\npip install \"faststream[rabbit]\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Settings in YAML\nDESCRIPTION: YAML configuration block that sets up documentation page weights and search boost parameters for the FastStream framework documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/Contact.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Running Code Linting Script\nDESCRIPTION: Command to run the provided script for code formatting and linting.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/lint.sh\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream NATS JsParser Class\nDESCRIPTION: This code block references the JsParser class from the faststream.nats.parser module, likely for inclusion in the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/parser/JsParser.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.nats.parser.JsParser\n```\n\n----------------------------------------\n\nTITLE: Importing Redis Prometheus Settings Provider Factory in Python\nDESCRIPTION: This code snippet demonstrates how to import the Redis Prometheus settings provider factory from the FastStream library. It allows users to access and configure Redis Prometheus settings for their FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/prometheus/provider/settings_provider_factory.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.prometheus.provider.settings_provider_factory import *\n```\n\n----------------------------------------\n\nTITLE: FastStream Documentation Structure\nDESCRIPTION: Markdown navigation structure defining the documentation hierarchy and organization of the FastStream project documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/SUMMARY.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\nsearch:\n  exclude: true\n---\n- [Features](faststream.md)\n- Tutorial\n    - [Getting Started](getting-started/index.md)\n    - [Subscription and Serialization](getting-started/subscription/index.md)\n    ...\n- [Reference - Code API](api/index.md)\n    - Public API\n        - faststream\n            - [BaseMiddleware](public_api/faststream/BaseMiddleware.md)\n            ...\n```\n\n----------------------------------------\n\nTITLE: Defining ContextRepo Class in Python for FastStream\nDESCRIPTION: This code snippet defines the ContextRepo class, which is used for managing context in FastStream applications. It includes methods for getting, setting, and removing context, as well as handling context stacks.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/context/ContextRepo.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass ContextRepo:\n    \"\"\"Context repository.\n\n    Args:\n        context (dict): Initial context\n    \"\"\"\n\n    def __init__(self, context: dict[str, Any] | None = None) -> None:\n        self._context: dict[str, Any] = context or {}\n        self._context_stack: list[dict[str, Any]] = []\n\n    def get(self, key: str, default: Any = None) -> Any:\n        \"\"\"Get value from context.\n\n        Args:\n            key (str): Key to get\n            default (Any, optional): Default value. Defaults to None.\n\n        Returns:\n            Any: Value from context\n        \"\"\"\n        return self._context.get(key, default)\n\n    def set(self, key: str, value: Any) -> None:\n        \"\"\"Set value to context.\n\n        Args:\n            key (str): Key to set\n            value (Any): Value to set\n        \"\"\"\n        self._context[key] = value\n\n    def remove(self, key: str) -> None:\n        \"\"\"Remove value from context.\n\n        Args:\n            key (str): Key to remove\n        \"\"\"\n        self._context.pop(key, None)\n\n    def push(self) -> None:\n        \"\"\"Push context to stack.\"\"\"\n        self._context_stack.append(self._context.copy())\n\n    def pop(self) -> None:\n        \"\"\"Pop context from stack.\"\"\"\n        if self._context_stack:\n            self._context = self._context_stack.pop()\n\n    def clear(self) -> None:\n        \"\"\"Clear context.\"\"\"\n        self._context.clear()\n        self._context_stack.clear()\n\n    def update(self, context: dict[str, Any]) -> None:\n        \"\"\"Update context.\n\n        Args:\n            context (dict): Context to update\n        \"\"\"\n        self._context.update(context)\n\n    def copy(self) -> dict[str, Any]:\n        \"\"\"Copy context.\n\n        Returns:\n            dict: Copy of context\n        \"\"\"\n        return self._context.copy()\n\n    def __getitem__(self, key: str) -> Any:\n        return self._context[key]\n\n    def __setitem__(self, key: str, value: Any) -> None:\n        self._context[key] = value\n\n    def __delitem__(self, key: str) -> None:\n        del self._context[key]\n\n    def __contains__(self, key: str) -> bool:\n        return key in self._context\n\n    def __len__(self) -> int:\n        return len(self._context)\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self._context)\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}({self._context!r})\"\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Collector for Sentry in YAML\nDESCRIPTION: YAML configuration for the OpenTelemetry Collector, specifying receivers, exporters, and service pipelines. It includes the Sentry DSN for exporting traces to Sentry.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/sentry.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n\nexporters:\n  sentry:\n    dsn: \"https://your-secret-dsn.com\"\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      exporters: [sentry]\n```\n\n----------------------------------------\n\nTITLE: Importing BatchListMessage from FastStream Redis Module\nDESCRIPTION: This code snippet shows how to import the BatchListMessage class from the faststream.redis.message module. This class is likely used for handling batched list messages in Redis operations within FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/message/BatchListMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.message import BatchListMessage\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Document Settings\nDESCRIPTION: YAML front matter configuration that sets up document search boost and page sections including API, Release, Contributing, Template Page and Default priorities.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/QueueType.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.QueueType\n```\n\n----------------------------------------\n\nTITLE: Importing the cast_uvicorn_params function from FastStream ASGI module\nDESCRIPTION: References the cast_uvicorn_params function from the faststream.asgi.app module, which is likely responsible for converting or validating parameters for Uvicorn ASGI server.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asgi/app/cast_uvicorn_params.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.asgi.app.cast_uvicorn_params\n```\n\n----------------------------------------\n\nTITLE: Running Tests with pytest\nDESCRIPTION: Command to execute tests using pytest.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npytest\n```\n\n----------------------------------------\n\nTITLE: Referencing Kafka Documentation Directory in Markdown\nDESCRIPTION: Shows the Markdown link syntax for referencing the Kafka documentation directory in the FastStream GitHub repository.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/index.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[`docs/docs/en/howto/kafka`](https://github.com/ag2ai/faststream/tree/main/docs/docs/en/howto/kafka){.external-link target=\"_blank\"}\n```\n\n----------------------------------------\n\nTITLE: Installing FastStream 0.3.0rc0 with Redis Support\nDESCRIPTION: Command for installing FastStream version 0.3.0rc0 with Redis support, which is the main feature of the 0.3.x release.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_42\n\nLANGUAGE: bash\nCODE:\n```\npip install faststream==0.3.0rc0 && pip install \"faststream[redis]\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost and API Versioning in YAML\nDESCRIPTION: This YAML snippet defines metadata for a documentation page, including search boost settings and API versioning information. It also references a specific module or function related to message correlation ID generation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/message/gen_cor_id.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.message.gen_cor_id\n```\n\n----------------------------------------\n\nTITLE: Starting FastStream Test Environment with Docker\nDESCRIPTION: Launches the required Docker containers for message brokers and other dependencies needed for running the full FastStream test suite.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/start_test_env.sh\n```\n\n----------------------------------------\n\nTITLE: Sending Messages to Filtered Handlers in FastStream\nDESCRIPTION: These code snippets show examples of messages that would be delivered to specific handlers based on the filters set up in the previous example. The first message is JSON and will be handled by the 'handle' function, while the second is a string and will be processed by the 'default_handler'.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/filtering.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish({\"key\": \"value\"}, \"test-topic\")\n```\n\nLANGUAGE: python\nCODE:\n```\nawait broker.publish(\"plain text\", \"test-topic\")\n```\n\n----------------------------------------\n\nTITLE: Documentation Configuration YAML\nDESCRIPTION: YAML configuration block specifying page priority levels and search boost settings for documentation organization\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/prometheus/provider/RabbitMetricsSettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.prometheus.provider.RabbitMetricsSettingsProvider\n```\n\n----------------------------------------\n\nTITLE: Retrieving FastStream Documentation Application\nDESCRIPTION: Function that retrieves or generates FastStream documentation based on provided parameters. It handles importing documentation modules, creating temporary documentation files, and configuring FastAPI routes for serving the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/docs/app/serve.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef get_documentation_app(\n    docs_module: str | None,\n    app_path: str | None,\n    app_var: str | None,\n    title: str | None,\n    app: Any,\n    templates: Any,\n    tmpdir: str,\n) -> tuple[Any, str]:\n    \"\"\"Get documentation application.\n\n    Args:\n        docs_module: module with docs configuration\n        app_path: path to the application module\n        app_var: application variable name\n        title: API title\n        app: FastAPI application\n        templates: Jinja2Templates\n        tmpdir: temporary directory\n\n    Returns:\n        tuple with FastAPI application and url path\n    \"\"\"\n    import sys\n    from pathlib import Path\n    import importlib.util\n    import importlib\n    from typing import Dict, Any, List\n\n    from fastapi import Request\n\n    markdown_js = Path(__file__).parent / \"templates\" / \"static\" / \"js\" / \"markdown.js\"\n\n    url_path = \"/docs\"\n\n    if docs_module:\n        # If docs_module is provided, load it and use its documentation\n        try:\n            module = importlib.import_module(docs_module)\n        except ImportError:\n            module_path = Path(docs_module)\n            if not module_path.exists():\n                print(f\"Module {docs_module} not found\")\n                sys.exit(1)\n\n            module_name = module_path.stem\n            spec = importlib.util.spec_from_file_location(module_name, module_path)\n            if not spec or not spec.loader:\n                print(f\"Failed to load module {docs_module}\")\n                sys.exit(1)\n\n            module = importlib.util.module_from_spec(spec)\n            sys.modules[module_name] = module\n            spec.loader.exec_module(module)\n\n        url_path = getattr(module, \"URL_PATH\", url_path)\n\n        @app.get(url_path)\n        async def get_docs(request: Request) -> Any:\n            return templates.TemplateResponse(\n                \"docs.html\",\n                {\n                    \"request\": request,\n                    \"specs\": getattr(module, \"SPECS\", []),\n                    \"title\": getattr(module, \"TITLE\", \"FastStream API\"),\n                    \"description\": getattr(module, \"DESCRIPTION\", \"\"),\n                    \"favicon\": getattr(module, \"FAVICON\", None),\n                    \"swagger_js_url\": getattr(\n                        module, \"SWAGGER_JS_URL\", \"/static/js/swagger-ui-bundle.js\"\n                    ),\n                    \"swagger_css_url\": getattr(\n                        module, \"SWAGGER_CSS_URL\", \"/static/css/swagger-ui.css\"\n                    ),\n                    \"redoc_js_url\": getattr(\n                        module, \"REDOC_JS_URL\", \"/static/js/redoc.standalone.js\"\n                    ),\n                    \"markdown_js_url\": getattr(\n                        module, \"MARKDOWN_JS_URL\", \"/static/js/markdown.js\"\n                    ),\n                    \"markdown_css_url\": getattr(\n                        module, \"MARKDOWN_CSS_URL\", \"/static/css/markdown.css\"\n                    ),\n                    \"rapidoc_js_url\": getattr(\n                        module, \"RAPIDOC_JS_URL\", \"/static/js/rapidoc-min.js\"\n                    ),\n                    \"element_js_url\": getattr(\n                        module, \"ELEMENT_JS_URL\", \"/static/js/elements.js\"\n                    ),\n                },\n            )\n    elif app_path:\n        # If app_path is provided, create a temporary OpenAPI specs file\n        # and configure it in FastAPI\n        import json\n        import os\n        import sys\n        from faststream._compat import PYDANTIC_V2\n\n        if PYDANTIC_V2:\n            from pydantic import TypeAdapter\n        else:\n            from pydantic import parse_obj_as\n\n        from faststream.cli.run import load_app\n\n        imported_app = load_app(app_path, app_var)\n\n        if isinstance(title, str):\n            imported_app.title = title\n\n        specs = imported_app.schema.model_dump() if PYDANTIC_V2 else imported_app.schema.dict()\n\n        specs_path = os.path.join(tmpdir, \"openapi.json\")\n        with open(specs_path, \"w\") as f:\n            json.dump(specs, f)\n\n        @app.get(url_path)\n        async def get_docs(request: Request) -> Any:\n            with open(specs_path, \"r\") as f:\n                specs = json.load(f)\n\n            return templates.TemplateResponse(\n                \"docs.html\",\n                {\n                    \"request\": request,\n                    \"specs\": [{\n                        \"type\": \"openapi\",\n                        \"url\": \"/openapi.json\",\n                        \"title\": specs.get(\"title\", \"FastStream API\"),\n                    }],\n                    \"title\": specs.get(\"title\", \"FastStream API\"),\n                    \"description\": specs.get(\"description\", \"\"),\n                    \"favicon\": None,\n                    \"swagger_js_url\": \"/static/js/swagger-ui-bundle.js\",\n                    \"swagger_css_url\": \"/static/css/swagger-ui.css\",\n                    \"redoc_js_url\": \"/static/js/redoc.standalone.js\",\n                    \"markdown_js_url\": \"/static/js/markdown.js\",\n                    \"markdown_css_url\": \"/static/css/markdown.css\",\n                    \"rapidoc_js_url\": \"/static/js/rapidoc-min.js\",\n                    \"element_js_url\": \"/static/js/elements.js\",\n                },\n            )\n\n        @app.get(\"/openapi.json\")\n        async def get_openapi() -> Any:\n            with open(specs_path, \"r\") as f:\n                return json.load(f)\n    else:\n        # If no docs_module or app_path is provided, show default documentation page\n        @app.get(url_path)\n        async def get_docs(request: Request) -> Any:\n            return templates.TemplateResponse(\n                \"docs.html\",\n                {\n                    \"request\": request,\n                    \"specs\": [],\n                    \"title\": title or \"FastStream API\",\n                    \"description\": \"\",\n                    \"favicon\": None,\n                    \"swagger_js_url\": \"/static/js/swagger-ui-bundle.js\",\n                    \"swagger_css_url\": \"/static/css/swagger-ui.css\",\n                    \"redoc_js_url\": \"/static/js/redoc.standalone.js\",\n                    \"markdown_js_url\": \"/static/js/markdown.js\",\n                    \"markdown_css_url\": \"/static/css/markdown.css\",\n                    \"rapidoc_js_url\": \"/static/js/rapidoc-min.js\",\n                    \"element_js_url\": \"/static/js/elements.js\",\n                },\n            )\n\n    return app, url_path\n```\n\n----------------------------------------\n\nTITLE: Starting NATS Test Broker Container\nDESCRIPTION: Docker command to start a NATS test broker container with JetStream enabled for development purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/index.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --rm -p 4222:4222 --name test-mq nats -js\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Broker Subscriber Call Item in Python\nDESCRIPTION: This code snippet demonstrates how to reference the HandlerItem class from the FastStream broker subscriber call item module. It uses Python's import syntax to make the class available for use in the current scope.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/subscriber/call_item/HandlerItem.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.broker.subscriber.call_item.HandlerItem\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation\nDESCRIPTION: YAML frontmatter configuration block defining page weights and search boost parameters for documentation organization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/parser/ObjParser.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream Documentation Header with Page Weights\nDESCRIPTION: YAML configuration defining the navigation weights and search boost for FastStream documentation pages. The weights determine page ordering (lower numbers appear first) in the navigation structure, with specified weights for API, Release, Contributing, Template Page, and Default sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/Header.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.Header\n```\n\n----------------------------------------\n\nTITLE: Configuring documentation weights and search parameters in YAML\nDESCRIPTION: YAML configuration block that defines page weights for different sections of documentation (API, Release, Contributing, Template, Default) and sets search boost parameters. Used for organizing documentation hierarchy and search relevance.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/client/check_msg_error.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.client.check_msg_error\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Weights\nDESCRIPTION: YAML configuration that defines search boost weights for different sections of the documentation, including API, Release, Contributing, and Template pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/parser/AioKafkaParser.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing Annotated Aliases for NATS\nDESCRIPTION: Shows the import statement for all available annotated aliases specific to the NATS broker. These provide type hints for broker-specific objects when used as function parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/existed.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.annotations import (\n    Logger, ContextRepo, NatsMessage,\n    NatsBroker, NatsProducer, NatsJsProducer,\n    Client, JsClient, NoCast,\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Development Requirements\nDESCRIPTION: Command to install all development requirements using pip.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -e \".[dev]\"\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream NATS Subscriber Class\nDESCRIPTION: This snippet references the Unsubscriptable class from the FastStream NATS subscriber module, likely for documentation purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/subscription/Unsubscriptable.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.nats.subscriber.subscription.Unsubscriptable\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry OTLP Exporter using pip\nDESCRIPTION: This command installs the OpenTelemetry OTLP exporter, which is used to export traces via gRPC or HTTP protocols.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/tracing.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npip install opentelemetry-exporter-otlp\n```\n\n----------------------------------------\n\nTITLE: Search and Page Weight Configuration in YAML\nDESCRIPTION: YAML configuration that defines page weights for different sections (API, Release, Contributing, Template Page) and search boost settings\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/RetentionPolicy.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: nats.js.api.RetentionPolicy\n```\n\n----------------------------------------\n\nTITLE: FastStream Channel Configuration YAML\nDESCRIPTION: YAML configuration for FastStream channel documentation, specifying page weights and search boost settings\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/channels/Channel.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.schema.channels.Channel\n```\n\n----------------------------------------\n\nTITLE: Configuration YAML for Documentation Search Settings\nDESCRIPTION: YAML configuration block defining search boost settings and page metadata including priority numbers for different sections like API, Release, Contributing and Template pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/schemas/params/ConsumerConnectionParams.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining search boost and section weights for documentation organization. Sets weights for API, Release, Contributing, Template and Default sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/imports/import_from_string.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Upgrading pip in the Virtual Environment\nDESCRIPTION: Updates pip to the latest version within the activated virtual environment to ensure access to the newest package management features.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/CONTRIBUTING.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m pip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Kafka Topic\nDESCRIPTION: Command to subscribe to a Kafka topic using a provided script.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/subscribe_to_kafka_broker_locally.sh <topic_name>\n```\n\n----------------------------------------\n\nTITLE: RabbitMQ Queue Schema Reference\nDESCRIPTION: Markdown directive referencing the FastStream RabbitMQ queue specific arguments schema class.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/queue/ClassicQueueSpecificArgs.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.rabbit.schemas.queue.ClassicQueueSpecificArgs\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Logging Function in Python\nDESCRIPTION: This code snippet references the get_broker_logger function from the FastStream logging module. It is likely used to configure logging for FastStream brokers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/log/logging/get_broker_logger.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.log.logging.get_broker_logger\n```\n\n----------------------------------------\n\nTITLE: Serializing JSON to Dictionary in FastStream\nDESCRIPTION: Shows how to serialize a JSON message to a Python dictionary using type annotations in FastStream subscribers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/annotation.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, Any\n\n@broker.subscriber(\"test\")\nasync def handle(\n    msg: dict[str, Any],\n):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Kafka Prometheus Provider Settings Factory\nDESCRIPTION: This code snippet shows how to reference the settings provider factory for FastStream's Kafka Prometheus integration. It uses a specific documentation syntax to link to the module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/prometheus/provider/settings_provider_factory.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.kafka.prometheus.provider.settings_provider_factory\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for FastStream Test Environment\nDESCRIPTION: Defines the Docker containers needed for running FastStream tests with various message brokers including RabbitMQ, Kafka, NATS, and Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n{! includes/docker-compose.yaml !}\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Metadata in YAML\nDESCRIPTION: YAML frontmatter configuration block that defines document metadata and search settings. Sets priority levels for different documentation sections and configures search boost parameter.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/publisher/usecase/LogicPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Settings for FastStream Documentation\nDESCRIPTION: This YAML snippet defines the structure and search boost settings for the FastStream project documentation. It includes sections for API, release, contributing, and a template page, with a search boost value of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/ast/is_contains_context_name.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Boost Settings in YAML\nDESCRIPTION: YAML configuration block that defines documentation page hierarchy and search boost settings. Sets search boost value to 0.5 and lists documentation page priorities.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/publisher/usecase/BatchPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.kafka.publisher.usecase.BatchPublisher\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Metadata for FastStream Documentation\nDESCRIPTION: This YAML snippet defines the structure and search settings for FastStream project documentation. It includes API priority, release information, contributing guidelines, and a template page. It also sets a search boost value and references a specific FastStream module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/log/formatter/ColourizedFormatter.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.log.formatter.ColourizedFormatter\n```\n\n----------------------------------------\n\nTITLE: Contributing Changes to FastStream Project\nDESCRIPTION: Commands for adding, committing, and pushing changes to the GitHub repository.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ngit add .\ngit commit -m \"Your commit message\"\ngit push origin your-branch\n```\n\n----------------------------------------\n\nTITLE: Checking FastStream Decoration in Python\nDESCRIPTION: This code snippet appears to be a reference to a function or method that checks if a component is decorated with FastStream. It's likely part of the FastStream broker's FastAPI integration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/fastapi/get_dependant/is_faststream_decorated.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.broker.fastapi.get_dependant.is_faststream_decorated\n```\n\n----------------------------------------\n\nTITLE: Disabling Type Casting in FastStream Brokers\nDESCRIPTION: Examples of how to disable type casting when creating brokers for different message queue systems in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka import KafkaBroker\nbroker = KafkaBroker(..., apply_types=False)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import KafkaBroker\nbroker = KafkaBroker(..., apply_types=False)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.rabbit import RabbitBroker\nbroker = RabbitBroker(..., apply_types=False)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats import NatsBroker\nbroker = NatsBroker(..., apply_types=False)\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisBroker\nbroker = RedisBroker(..., apply_types=False)\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost Settings in YAML\nDESCRIPTION: YAML configuration block that sets search boost parameters and defines documentation section priorities. Includes numeric weights for different documentation sections and search boost value.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/KafkaBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.kafka.KafkaBroker\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Specific .env File\nDESCRIPTION: Shows how to run tests using a specific .env file for the test environment.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/config/index.md#2025-04-22_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nENV=.test.env pytest\n```\n\n----------------------------------------\n\nTITLE: Configuring Page Weights and Search Settings in YAML\nDESCRIPTION: YAML configuration block defining page weights for different sections of documentation and search boost settings. The configuration includes weights for API (0.5), Release (2), Contributing (3), Template Page (5), and Default (10) sections, along with a search boost value of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/info/License.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Settings for FastStream Documentation\nDESCRIPTION: Defines documentation section weights and search boost parameters for the FastStream project documentation system. Includes weightings for API, Release, Contributing, and Template sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/TestNatsBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.nats.TestNatsBroker\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Page Structure and Weights in YAML\nDESCRIPTION: YAML configuration for a documentation page in the FastStream project. It defines section weights for various documentation pages including API, Release, and Contributing sections, along with search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/TopicPartition.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: aiokafka.structs.TopicPartition\n```\n\n----------------------------------------\n\nTITLE: Installing Protobuf dependencies for FastStream\nDESCRIPTION: This command installs the necessary dependencies for using Protobuf with FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/examples.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\npip install grpcio-tools\n```\n\n----------------------------------------\n\nTITLE: Upgrading pip in the Virtual Environment\nDESCRIPTION: Updates pip to the latest version within the virtual environment to ensure compatibility with required packages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m pip install --upgrade pip\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container Locally\nDESCRIPTION: Command to run the Docker container locally, connecting to the host network.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm --name faststream-app --net=host ghcr.io/<username>/<repo-name>:latest\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration for Documentation\nDESCRIPTION: YAML configuration block defining API section weights and search boost settings for documentation pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/message/NatsMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Using Annotated with Context in Redis\nDESCRIPTION: Shows how to use Python's Annotated feature with FastStream Context in Redis. This approach is similar to pytest fixtures, allowing for cleaner dependency injection with type hints.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/index.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nfrom faststream import FastStream, Context, Logger\nfrom faststream.redis import RedisBroker\n\n\nbroker = RedisBroker()\napp = FastStream(broker)\n\n\n# inject application object from a Context\nLoggerDep = Annotated[Logger, Context()]\nBrokerDep = Annotated[RedisBroker, Context()]\n\n\n@broker.subscriber(\"test\")\nasync def base_handler(\n    broker: BrokerDep,  # from context with annotation\n    logger: LoggerDep,  # from context with annotation\n    msg: str,\n):\n    logger.info(\"I got a message!\")\n    await broker.publish(msg, \"answer\")\n```\n\n----------------------------------------\n\nTITLE: Documentation Configuration YAML\nDESCRIPTION: YAML configuration defining page weights and search settings for FastStream NATS documentation pages\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/asyncapi/AsyncAPIObjStoreWatchSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.nats.subscriber.asyncapi.AsyncAPIObjStoreWatchSubscriber\n```\n\n----------------------------------------\n\nTITLE: Starting Test Environment for FastStream\nDESCRIPTION: Executes a script to start the Docker containers required for running tests with message broker dependencies.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/start_test_env.sh\n```\n\n----------------------------------------\n\nTITLE: Displaying Section Experts using Jinja2 and HTML\nDESCRIPTION: This snippet demonstrates how to display experts for specific sections (Kafka, RabbitMQ, NATS, Redis) using Jinja2 templating and HTML. It filters users based on their inclusion in each section's category.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/faststream-people.md#2025-04-22_snippet_1\n\nLANGUAGE: jinja2\nCODE:\n```\n<div class=\"user-list user-list-center\">\n{% for user in people.people %}\n    {% if 'kafka' in user.include %}\n        <div class=\"user\">\n            <a href=\"{{ user.github }}\" target=\"_blank\">\n                <div class=\"avatar-wrapper\">\n                    <img src=\"{{ user.avatar }}\"/>\n                </div>\n                <div class=\"title\">\n                    {% if user.name %}{{user.name}}<br/>{% endif %}\n                    @{{user.username}}\n                </div>\n            </a>\n        </div>\n    {% endif %}\n{% endfor %}\n</div>\n```\n\n----------------------------------------\n\nTITLE: YAML Search Configuration for Documentation\nDESCRIPTION: YAML front matter configuration defining page priorities and search boost settings for documentation sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/schemas/js_stream/JStream.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: FastStream Documentation Page Configuration in YAML\nDESCRIPTION: YAML configuration for a documentation page, specifying API levels, release status, contributing sections, and search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/prometheus/types/ProcessingStatus.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.prometheus.types.ProcessingStatus\n```\n\n----------------------------------------\n\nTITLE: Running Tests for FastStream Project\nDESCRIPTION: Executes the test suite for FastStream using pytest, with options for running standard tests or tests with coverage reports.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npytest tests\n# or\n./scripts/test.sh\n# with coverage output\n./scripts/test-cov.sh\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream Utility Function in Python\nDESCRIPTION: This snippet references a Python function 'is_contains_context_name' from the FastStream utility module for AST (Abstract Syntax Tree) operations. The function likely checks if a given context name is present in an AST.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/ast/is_contains_context_name.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.utils.ast.is_contains_context_name\n```\n\n----------------------------------------\n\nTITLE: Initializing Git Repository and Pushing to GitHub\nDESCRIPTION: Series of Git commands to initialize a repository, add files, commit, and push to GitHub.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/template/index.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit init\ngit add .\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin git@github.com:<username>/<repo-name>.git\ngit push -u origin main\n```\n\n----------------------------------------\n\nTITLE: Configuring Markdown Frontmatter for Documentation Page\nDESCRIPTION: This snippet defines the frontmatter for a Markdown documentation page. It sets search boost and includes section weights for different parts of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/parser/JsParser.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Page Configuration in YAML\nDESCRIPTION: YAML frontmatter configuration specifying page weights, search boost settings, and FastStream Kafka telemetry provider reference.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/opentelemetry/provider/BaseKafkaTelemetrySettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.kafka.opentelemetry.provider.BaseKafkaTelemetrySettingsProvider\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with FastStream CLI\nDESCRIPTION: The `publish_message` function provides a command-line interface for publishing messages to a message broker. It supports multiple broker types, custom headers, and various payload formats including JSON.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/main/publish_message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef publish_message(\n    broker: str,\n    url: str,\n    target: str,\n    message: str = None,\n    file: IO[str] = None,\n    content_type: str = None,\n    header: list[str] = None,\n):\n    \"\"\"Publish message to broker.\n\n    Args:\n        broker: broker type\n        url: broker URL\n        target: broker target address\n        message: message to publish\n        file: file with message to publish\n        content_type: message content type\n        header: message headers\n    \"\"\"\n    from faststream.cli import serializers\n\n    if message and file:\n        typer.echo(\"You can't use both message and file\")\n        raise typer.Exit(1)\n\n    if not (message or file):\n        typer.echo(\"You must specify message or file\")\n        raise typer.Exit(1)\n\n    if file:\n        message = file.read()\n\n    # If the message is a json string, parse it\n    if content_type == \"application/json\":\n        try:\n            message = json.loads(message)\n        except json.JSONDecodeError:\n            typer.echo(\"Invalid JSON\")\n            raise typer.Exit(1)\n\n    # Parse headers\n    headers = {}\n    if header:\n        for h in header:\n            try:\n                k, v = h.split(\"=\")\n                headers[k] = v\n            except ValueError:\n                typer.echo(f\"Invalid header: {h}\")\n                raise typer.Exit(1)\n\n    # Fix types\n    payload = message\n    if content_type is not None and content_type in serializers.CONTENT_TYPES:\n        payload = serializers.CONTENT_TYPES[content_type](payload)\n\n    broker_package = import_module(f\"faststream.{broker}\")\n    with getattr(broker_package, pascalcase(broker))(url) as broker_client:\n        broker_client.publish(payload, target, headers=headers)\n```\n\n----------------------------------------\n\nTITLE: Serving FastStream API Documentation with FastAPI\nDESCRIPTION: Python function that creates a FastAPI application to serve FastStream API documentation. It accepts parameters for document handling and returns a configured FastAPI app with appropriate routes and templates.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/docs/app/serve.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef serve(\n    docs_module: str | None = None,\n    app_path: str | None = None,\n    app_var: str | None = None,\n    title: str | None = None,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n    reload: bool = True,\n    log_level: Literal[\"debug\", \"info\", \"warning\", \"error\", \"critical\"] = \"info\",\n) -> None:\n    \"\"\"Serve API documentation.\n\n    Args:\n        docs_module: module with docs configuration\n        app_path: path to the application module\n        app_var: application variable name\n        title: API title\n        host: host to serve on\n        port: port to serve on\n        reload: reload server on code changes\n        log_level: logging level\n    \"\"\"\n    import tempfile\n    from pathlib import Path\n\n    from fastapi import FastAPI\n    from fastapi.staticfiles import StaticFiles\n    from starlette.templating import Jinja2Templates\n    from uvicorn import Server, Config\n\n    app = FastAPI()\n\n    template_path = Path(__file__).parent / \"templates\"\n    app.mount(\"/static\", StaticFiles(directory=template_path / \"static\"), name=\"static\")\n    templates = Jinja2Templates(directory=template_path)\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        app, url_path = get_documentation_app(\n            docs_module, app_path, app_var, title, app, templates, tmpdir\n        )\n\n        config = Config(\n            app=app,\n            host=host,\n            port=port,\n            log_level=log_level,\n            reload=reload,\n        )\n        server = Server(config)\n\n        print(f\"Documentation server started at http://{host}:{port}{url_path}\")\n\n        import asyncio\n\n        asyncio.run(server.serve())\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Metadata in YAML\nDESCRIPTION: YAML configuration block that sets search boost parameter and defines page categorization numbers for various section types like API, Release, Contributing, Template Page and Default.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/schemas/proto/RedisAsyncAPIProtocol.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search and Navigation Settings in YAML\nDESCRIPTION: YAML configuration block that defines page weights for different sections and search boost parameters for the documentation system. The configuration includes weights for API, Release, Contributing, and Template pages, with search boost set to 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/utils/resolve_custom_func.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.utils.resolve_custom_func\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration\nDESCRIPTION: YAML configuration block defining search boost and page priorities for documentation organization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/security/OauthFlowObj.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Settings\nDESCRIPTION: YAML frontmatter configuration that sets documentation ordering priorities and search boost settings. Includes priority numbers for different documentation sections and a search boost value.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/queue/QueueType.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.schemas.queue.QueueType\n```\n\n----------------------------------------\n\nTITLE: Displaying AsyncAPI schema CLI help\nDESCRIPTION: Command to show available options for working with AsyncAPI schemas in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/cli/index.md#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nfaststream docs --help\n```\n\n----------------------------------------\n\nTITLE: Configuring Page Search Weights in YAML\nDESCRIPTION: YAML configuration block defining search boost weights for different documentation sections like API, Release, Contributing and Template pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/exceptions/BatchBufferOverflowException.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: Retrieving Log Context in FastStream\nDESCRIPTION: Demonstrates how to retrieve the log context from the FastStream context, which is useful when using custom loggers that don't have access to the request context.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/logging.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import context\nlog_context: dict[str, str] = context.get_local(\"log_context\")\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: YAML frontmatter configuration block defining article weights and search boost parameters for documentation pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/usecase/ConcurrentDefaultSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Search Boost\nDESCRIPTION: YAML frontmatter configuration that sets the search boost parameter and defines documentation sections weights for different page types.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/client/AsyncConfluentProducer.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Settings in YAML\nDESCRIPTION: YAML configuration block that defines documentation settings including search boost factor and page weights for different sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/Path.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Defining Search Boost and Documentation Reference in Markdown\nDESCRIPTION: This snippet sets up metadata for the page, including search boost settings and a reference to the BaseRMQInformation schema documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/BaseRMQInformation.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.schemas.BaseRMQInformation\n```\n\n----------------------------------------\n\nTITLE: Search Configuration in YAML\nDESCRIPTION: YAML configuration block defining search boost parameters and page section weights for documentation organization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/broker/logging/KafkaLoggingBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Documentation Settings\nDESCRIPTION: YAML configuration block defining documentation page weights and search boost parameters for FastStream documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/helpers/StreamBuilder.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.nats.helpers.StreamBuilder\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost Settings in YAML\nDESCRIPTION: YAML configuration block specifying search boost parameters and page weight values for documentation sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/utils/RabbitClientProperties.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuration YAML for FastStream Documentation Page\nDESCRIPTION: YAML configuration for a documentation page that references the WrapperProto class from the FastStream framework. The configuration includes search boost parameters and navigation priorities for different page types.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/wrapper/proto/WrapperProto.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.wrapper.proto.WrapperProto\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Front Matter for FastStream Documentation\nDESCRIPTION: This YAML block sets up the front matter for a documentation page in the FastStream project. It defines search boost settings and page priorities for different sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/subscriber/mixins/ConcurrentMixin.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Creating a Publisher Object for Kafka Topics\nDESCRIPTION: Creates a dedicated publisher object that can be used to publish messages to a specific Kafka topic, which will be properly documented in AsyncAPI.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/publisher_object/example.py [ln:17] !}\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Settings\nDESCRIPTION: YAML frontmatter configuration block defining page organization and search boost parameters. Sets search boost to 0.5 and includes section numbering for different documentation areas.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/publisher/proto/BasePublisherProto.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.publisher.proto.BasePublisherProto\n```\n\n----------------------------------------\n\nTITLE: Markdown Reference to FastStream NATS KeyValueWatchSubscriber Documentation\nDESCRIPTION: A markdown directive that references the documentation for the KeyValueWatchSubscriber class in the faststream.nats.subscriber.usecase module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/usecase/KeyValueWatchSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.nats.subscriber.usecase.KeyValueWatchSubscriber\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Structure\nDESCRIPTION: YAML frontmatter configuration defining page sections and search boost parameters for FastStream RabbitMQ documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/broker/RabbitBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.broker.RabbitBroker\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages Using Publisher Object\nDESCRIPTION: Demonstrates how to publish messages to a Kafka topic using a dedicated publisher object that was previously created, allowing for better AsyncAPI documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/confluent/Publisher/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n{!> docs_src/confluent/publisher_object/example.py [ln:26.9,27.7,28.9,29.9,30.9,31.9] !}\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter Configuration\nDESCRIPTION: YAML configuration block defining page metadata and search settings for documentation site\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/amqp/Queue.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Displaying LicenseDict Class Definition in FastStream AsyncAPI Schema\nDESCRIPTION: This code snippet refers to the LicenseDict class from the FastStream AsyncAPI schema information module. The snippet indicates there is a reference to this class in the documentation, likely showing its structure and attributes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/info/LicenseDict.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.asyncapi.schema.info.LicenseDict\n```\n\n----------------------------------------\n\nTITLE: Defining FastStream CLI Publish Function in Python\nDESCRIPTION: This function is part of the FastStream CLI and is responsible for publishing messages to a broker. It takes various parameters to configure the publishing process, including the broker type, message content, and routing options.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/main/publish.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef publish(\n    broker: str,\n    message: str,\n    routing_key: str = \"\",\n    content_type: str = \"application/json\",\n    exchange: str = \"\",\n    host: str = \"localhost\",\n    port: int = None,\n    username: str = None,\n    password: str = None,\n    ssl: bool = False,\n    ssl_ca_certs: str = None,\n    ssl_certfile: str = None,\n    ssl_keyfile: str = None,\n    ssl_ciphers: str = None,\n    **kwargs,\n) -> None:\n    \"\"\"Publish a message to a broker.\n\n    Args:\n        broker: The broker type (e.g., 'kafka', 'rabbitmq').\n        message: The message to publish.\n        routing_key: The routing key for the message.\n        content_type: The content type of the message.\n        exchange: The exchange to publish to (for RabbitMQ).\n        host: The broker host.\n        port: The broker port.\n        username: The username for authentication.\n        password: The password for authentication.\n        ssl: Whether to use SSL/TLS.\n        ssl_ca_certs: The CA certificate file for SSL/TLS.\n        ssl_certfile: The client certificate file for SSL/TLS.\n        ssl_keyfile: The client key file for SSL/TLS.\n        ssl_ciphers: The SSL/TLS ciphers to use.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        None\n    \"\"\"\n    ...\n```\n\n----------------------------------------\n\nTITLE: Installing OpenTelemetry Exporter for Python\nDESCRIPTION: Command to install the opentelemetry-exporter-otlp package using pip for exporting spans via gRPC.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/sentry.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install opentelemetry-exporter-otlp\n```\n\n----------------------------------------\n\nTITLE: Documentation YAML Configuration\nDESCRIPTION: YAML configuration block defining documentation section weights and search boost settings for the FastStream NATS project.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/publisher/producer/NatsJSFastProducer.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.nats.publisher.producer.NatsJSFastProducer\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with NATS in FastStream\nDESCRIPTION: This snippet demonstrates how to create and use a Publisher object with NATS in FastStream. It shows the setup of the NatsBroker and creation of a Publisher for the 'test' subject.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/direct.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.nats import NatsBroker\n\nbroker = NatsBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"test\")\n\n@broker.subscriber(\"input\")\nasync def on_input(msg: str):\n    await publisher.publish(msg)\n```\n\n----------------------------------------\n\nTITLE: YAML Search Configuration for FastStream Documentation\nDESCRIPTION: YAML front matter configuration that defines page sections and search boost settings. Sets search boost to 0.5 and defines hierarchical page sections including API, Release, Contributing, Template Page and Default.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/testing/build_message.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.testing.build_message\n```\n\n----------------------------------------\n\nTITLE: FastStream Documentation Page Configuration in YAML\nDESCRIPTION: YAML configuration file that defines page weights for different sections of FastStream documentation and sets search boost parameters. Includes weights for API, Release, Contributing, Template and Default pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/core/usecase/BrokerUsecase.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.core.usecase.BrokerUsecase\n```\n\n----------------------------------------\n\nTITLE: Checking FastStream Version for Security Reporting\nDESCRIPTION: This command retrieves the version information of FastStream, which is required when reporting security vulnerabilities to help maintainers understand the affected version.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/SECURITY.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nfaststream --version\n```\n\n----------------------------------------\n\nTITLE: Publishing Messages with Confluent in FastStream\nDESCRIPTION: This snippet shows how to create and use a Publisher object with Confluent in FastStream. It demonstrates the setup of the KafkaBroker and creation of a Publisher for the 'test' topic.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/publishing/direct.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker()\napp = FastStream(broker)\n\npublisher = broker.publisher(\"test\")\n\n@broker.subscriber(\"input\")\nasync def on_input(msg: str):\n    await publisher.publish(msg)\n```\n\n----------------------------------------\n\nTITLE: FastStream Documentation Configuration in YAML\nDESCRIPTION: YAML configuration defining documentation structure with section weights and search boost parameters. Includes weights for API (0.5), Release (2), Contributing (3), Template Page (5), and Default (10) sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/schemas/params/SecurityOptions.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.schemas.params.SecurityOptions\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Search\nDESCRIPTION: YAML front matter configuration block that defines documentation page weights and search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/router/ArgsContainer.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: YAML frontmatter configuration that defines documentation page weights, search settings, and external documentation references. Includes weighting for different sections like API, Release, Contributing, and Template pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/utils/ExternalDocsDict.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.schema.utils.ExternalDocsDict\n```\n\n----------------------------------------\n\nTITLE: YAML Page Configuration With Search Settings\nDESCRIPTION: YAML configuration block defining page weights for different sections and search boost settings. Used for documentation organization and search optimization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/prometheus/provider/NatsMetricsSettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Using Redis Streams with Batch Processing\nDESCRIPTION: Example demonstrating how to use Redis Stream with batch processing in FastStream 0.4.4, including setting the maximum number of records to process in a batch.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_33\n\nLANGUAGE: python\nCODE:\n```\n@broker.subscriber(stream=StreamSub(\"input\", batch=True, max_records=3))\nasync def on_input_data(msgs: list[str]):\n    assert len(msgs) <= 3\n```\n\n----------------------------------------\n\nTITLE: Checking If Subprocess Has Started in FastStream CLI\nDESCRIPTION: A utility function that checks if a subprocess has successfully started by comparing its logs against a predefined pattern or waiting for a specific process ID. It returns a boolean indicating whether the subprocess has started correctly.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/supervisors/utils/subprocess_started.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef subprocess_started(\n    output: list[str],\n    log_pattern: str = None,\n    pid: int = None,\n    stdout_pattern: str = None,\n    stderr_pattern: str = None,\n) -> bool:\n    \"\"\"Check if subprocess started.\"\"\"\n    # Process matching by pid\n    if pid is not None:\n        try:\n            # Check if process exists\n            psutil.Process(pid)\n            return True\n        except psutil.NoSuchProcess:\n            return False\n\n    # No logs\n    if not output:\n        return False\n\n    # Process matching by log pattern\n    if log_pattern is not None:\n        for line in output:\n            if re.search(log_pattern, line):\n                return True\n\n    if stdout_pattern is not None:\n        for line in output:\n            if re.search(stdout_pattern, line):\n                return True\n\n    if stderr_pattern is not None:\n        for line in output:\n            if re.search(stderr_pattern, line):\n                return True\n\n    # Default - no matches\n    return False\n```\n\n----------------------------------------\n\nTITLE: Parsing Handler Parameters for AsyncAPI Messages in Python\nDESCRIPTION: This function parses handler parameters for AsyncAPI message handlers. It extracts information about the parameters, including their names, types, and default values. The function handles various parameter types and annotations, including path parameters, query parameters, and body fields.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/message/parse_handler_params.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef parse_handler_params(func: Callable[..., Any]) -> Dict[str, Any]:\n    \"\"\"Parse handler parameters.\n\n    Args:\n        func (Callable[..., Any]): The handler function to parse.\n\n    Returns:\n        Dict[str, Any]: A dictionary containing parsed parameter information.\n    \"\"\"\n    signature = inspect.signature(func)\n    params = {}\n\n    for name, param in signature.parameters.items():\n        if name == \"self\":\n            continue\n\n        annotation = param.annotation\n        default = param.default\n\n        if isinstance(annotation, str):\n            annotation = eval(annotation)\n\n        if annotation == inspect.Parameter.empty:\n            annotation = Any\n\n        if default == inspect.Parameter.empty:\n            default = Required\n\n        params[name] = {\n            \"type\": annotation,\n            \"default\": default,\n        }\n\n    return params\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration Settings\nDESCRIPTION: YAML configuration block defining search boost parameters and page hierarchy numbers for different sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/publisher/asyncapi/AsyncAPIPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Creating and Using TestApp in FastStream Applications\nDESCRIPTION: The TestApp class provides testing utilities for FastStream applications, allowing simulation of messages, handling of responses, and verification of application behavior. It inherits from TestClient and serves as a core component in testing message-driven applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/TestApp.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass TestApp(TestClient):\n    \"\"\"TestApp for FastStream applications.\"\"\"\n\n    __test__ = False\n\n    def __init__(\n        self,\n        app: _AppT,\n        include_router: bool = True,\n        *,\n        apply_types: bool = False,\n        patch_all: bool = False,\n        broker_id: str | None = None,\n    ) -> None:\n        \"\"\"Initialize TestApp.\n\n        Args:\n            app: FastStream application instance\n            include_router: add router's handlers to test app\n            apply_types: apply types validation to handled message\n            patch_all: patch all publishers with test publishers\n            broker_id: specific broker to test\n        \"\"\"\n        self.app = app\n        self.include_router = include_router\n\n        super().__init__(\n            apply_types=apply_types,\n            patch_all=patch_all,\n            broker_id=broker_id,\n        )\n```\n\n----------------------------------------\n\nTITLE: Path Class Definition in FastStream's utils.context.builders Module\nDESCRIPTION: The Path class is part of FastStream's utilities for context building, providing functionality for handling path strings in routing. It maintains a base string value and supports various string operations and validations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/context/builders/Path.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Path(str):\n    \"\"\"A string that represents a path.\n\n    Attributes:\n        base (str): A base string value.\n    \"\"\"\n\n    def __new__(cls, base: str = \"\") -> \"Path\":\n        return super().__new__(cls, base)\n\n    def __init__(self, base: str = \"\") -> None:\n        self.base = base\n\n    def __truediv__(self, value: str) -> \"Path\":\n        return Path(\n            f\"{self.base.rstrip('/') if self.base else ''}/{value.lstrip('/')}\"\n            if value\n            else self.base\n        )\n\n    def __eq__(self, other) -> bool:\n        if isinstance(other, Path):\n            return self.base == other.base\n\n        return str(self) == other\n\n    def __hash__(self) -> int:\n        return hash(str(self))\n\n    def __bool__(self) -> bool:\n        return bool(self.base)\n```\n\n----------------------------------------\n\nTITLE: Configuring Search and Page Metadata in YAML\nDESCRIPTION: YAML configuration block that sets page metadata and search boost parameters for documentation pages. Defines a search boost value of 0.5 and includes section numbers for different documentation aspects.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/NatsRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Redis Channels with FastStream\nDESCRIPTION: Shows how to create a basic Redis subscriber using FastStream's RedisBroker. The subscriber function handles messages from a specified channel.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/index.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisBroker\n\nbroker = RedisBroker()\n\n@broker.subscriber(\"test\")  # channel name\nasync def handle_msg(msg_body):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Resolving Payload Schemas for AsyncAPI in Python\nDESCRIPTION: Function that converts various schema representations (pydantic models, dictionaries, AsyncAPI schemas) into properly formatted AsyncAPI payload objects. It handles type coercion and ensures schemas are in the correct format for AsyncAPI documentation generation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/utils/resolve_payloads.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef resolve_payloads(\n    payloads: dict[str, list[Any]],\n    *,\n    schema_registry: dict[str, Schema] | None = None,\n) -> dict[str, list[dict]]:\n    if not payloads:\n        return {}\n\n    schemas = {}\n    for message_type, lst in payloads.items():\n        if not lst:\n            continue\n\n        schemas[message_type] = []\n        for message in lst:\n            if isinstance(message, Schema) or (\n                isinstance(message, dict) and \"schema\" in message\n            ):\n                schemas[message_type].append(message)\n            elif schema := _to_Schema(message, schema_registry=schema_registry):\n                schemas[message_type].append(schema)\n\n    return schemas\n```\n\n----------------------------------------\n\nTITLE: Compiling Path Patterns in FastStream\nDESCRIPTION: This function compiles path patterns with dynamic parameters. It supports both regex-format and f-string-format path patterns, replacing named parameters with actual values. The function handles path normalization for both formats.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/path/compile_path.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef compile_path(\n    pattern: str, param_values: Dict[str, Any] = None\n) -> str:\n    \"\"\"Compile path pattern with dynamic parameters.\n\n    Supports both regex-format:\n        \"user/{user_id}/info\"\n    and f-string-format path:\n        \"user/{user_id}/info\"\n\n    Args:\n        pattern: Path pattern string\n        param_values: Path parameters values.\n            If not provided, the path pattern will be returned as is.\n\n    Returns:\n        Compiled path string.\n\n    \"\"\"\n    if not param_values:\n        return pattern\n\n    # Check if using regex-format pattern\n    if \"{\" in pattern and \"}\" in pattern:\n        formatted_path = pattern\n        for param_name, param_value in param_values.items():\n            formatted_path = formatted_path.replace(\n                f\"{{{param_name}}}\", str(param_value)\n            )\n        return formatted_path\n\n    return pattern\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Structure\nDESCRIPTION: Defines the documentation structure with weighted sections including API, Release, Contributing and Template pages. Includes search boost configuration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/KafkaPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.kafka.KafkaPublisher\n```\n\n----------------------------------------\n\nTITLE: FastStream Documentation Weight Configuration in YAML\nDESCRIPTION: YAML configuration that defines page weights and search boost settings for different documentation sections including API, Release, Contributing and Template pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/prometheus/provider/BatchKafkaMetricsSettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.kafka.prometheus.provider.BatchKafkaMetricsSettingsProvider\n```\n\n----------------------------------------\n\nTITLE: Defining Path Utility Class in Python for FastStream\nDESCRIPTION: This code snippet defines the Path utility class for FastStream. It includes methods for path manipulation and comparison, as well as special methods for representation and equality checking.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/Path.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Path(str):\n    def __new__(cls, *args: str) -> Self:\n        return str.__new__(cls, \"/\".join(args).strip(\"/\"))\n\n    def __truediv__(self, other: str) -> Self:\n        return type(self)(self, other)\n\n    def __rtruediv__(self, other: str) -> Self:\n        return type(self)(other, self)\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, (str, Path)):\n            return NotImplemented\n        return str(self) == str(other)\n\n    def __repr__(self) -> str:\n        return f\"Path('{self}')\"\n\n    @property\n    def parts(self) -> tuple[str, ...]:\n        return tuple(self.split(\"/\"))\n\n    def startswith(self, prefix: str, /) -> bool:\n        return str(self).startswith(prefix)\n\n    def endswith(self, suffix: str, /) -> bool:\n        return str(self).endswith(suffix)\n```\n\n----------------------------------------\n\nTITLE: FastStream Search Configuration in YAML\nDESCRIPTION: YAML configuration block defining search boost and section priorities for documentation navigation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/utils/Parameter.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream Documentation YAML Settings\nDESCRIPTION: YAML configuration block defining documentation page priorities, search boost settings, and middleware references for the FastStream project.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/middlewares/ExceptionMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.middlewares.ExceptionMiddleware\n```\n\n----------------------------------------\n\nTITLE: Defining ExchangeType Enum in Python for FastStream RabbitMQ\nDESCRIPTION: This code snippet defines an Enum class called ExchangeType which represents the different types of exchanges available in RabbitMQ. It includes DIRECT, FANOUT, TOPIC, and HEADERS as the enum members.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/ExchangeType.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass ExchangeType(str, Enum):\n    \"\"\"RabbitMQ exchange types.\"\"\"\n\n    DIRECT = \"direct\"\n    FANOUT = \"fanout\"\n    TOPIC = \"topic\"\n    HEADERS = \"headers\"\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Front Matter for FastStream Documentation\nDESCRIPTION: YAML configuration block defining search boost parameters and documentation page structure with numeric section weights for the FastStream NATS subscriber documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/usecase/ConcurrentPushStreamSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Frontmatter for FastStream Documentation\nDESCRIPTION: YAML frontmatter configuration for a FastStream documentation page, setting priority levels for API (0.5), Release (2), Contributing (3), Template Page (5), and Default (10) sections, along with search boost parameter of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/prometheus/provider/BatchNatsMetricsSettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Documentation Page Configuration in YAML\nDESCRIPTION: YAML frontmatter configuration for a documentation page, specifying section weights and search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/QueueType.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.schemas.QueueType\n```\n\n----------------------------------------\n\nTITLE: Applying Message Pattern in FastStream RabbitMQ Testing (Python)\nDESCRIPTION: The apply_pattern function modifies a message based on a specified pattern, supporting both simple string replacement and complex dictionary transformations. It checks whether a pattern exists and applies the pattern to the message content accordingly.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/testing/apply_pattern.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef apply_pattern(\n    message: bytes | bytearray,\n    pattern: str | dict[str, Any] | None,\n) -> RabbitPayload:\n    \"\"\"Modify message with a pattern.\n\n    Args:\n        message: message to modify\n        pattern: pattern to apply\n\n    Returns:\n        Modified message\n    \"\"\"\n    if pattern is None or message == b\"\":\n        return message\n\n    message_str = message.decode()\n\n    if isinstance(pattern, dict):\n        message_dict = json.loads(message_str)\n        message_dict.update(pattern)\n        message_str = json.dumps(message_dict)\n    else:\n        message_str = pattern\n\n    return message_str.encode()\n```\n\n----------------------------------------\n\nTITLE: Setting up PostgreSQL Async Connection with SQLAlchemy in FastStream\nDESCRIPTION: This snippet demonstrates how to set up an asynchronous connection to PostgreSQL using SQLAlchemy in a FastStream application. It includes configuring the database URL, creating the async engine, and initializing session management.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom datetime import datetime\nfrom typing import List\n\nfrom fastapi import Depends, FastAPI\nfrom faststream.nats.router import NatsRouter\nfrom pydantic import BaseModel\nfrom sqlalchemy import Column, DateTime, Integer, String, create_engine, select\nfrom sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\n# SQLAlchemy setup\nPOSTGRES_URL = \"postgresql+asyncpg://postgres:postgres@localhost:5432/postgres\"\n\nasync_engine = create_async_engine(POSTGRES_URL, future=True, echo=True)\nAsyncSessionLocal = sessionmaker(\n    bind=async_engine, class_=AsyncSession, expire_on_commit=False\n)\n```\n\n----------------------------------------\n\nTITLE: FastStream Search Configuration YAML\nDESCRIPTION: YAML configuration for documentation search settings and page weights, including boost values and section priorities.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/kafka/OperationBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: Extracting Function Calls from 'with' Statements using Python AST\nDESCRIPTION: A utility function that extracts function calls from 'with' statements in Python code using the Abstract Syntax Tree (AST). It parses provided source code and returns a list of call nodes found within 'with' statement contexts.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/ast/get_withitem_calls.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_withitem_calls(source: str) -> list[ast.Call]:\n    \"\"\"Get a list of call nodes from a with statement.\n\n    Args:\n        source: Python source code string\n\n    Returns:\n        list of call nodes\n    \"\"\"\n    module = ast.parse(source)\n    calls = []\n    for node in ast.walk(module):\n        if isinstance(node, ast.With):\n            for item in node.items:\n                if isinstance(item.context_expr, ast.Call):\n                    calls.append(item.context_expr)\n    return calls\n```\n\n----------------------------------------\n\nTITLE: Validating Binding Arguments in FastStream CLI\nDESCRIPTION: This function checks if a string matches a specific pattern to determine if it's a binding argument. It uses regular expressions to verify that the string follows the format 'key=value' where 'key' doesn't start with a hyphen (-). This is commonly used in command-line argument parsing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/parser/is_bind_arg.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef is_bind_arg(arg: str) -> bool:\n    \"\"\"\n    Check if argument is a binding argument.\n\n    Parameters\n    ----------\n    arg : str\n        The argument to check\n\n    Returns\n    -------\n    bool\n        True if argument is a binding argument\n    \"\"\"\n    return bool(arg) and \"=\" in arg and not arg.startswith(\"-\")\n```\n\n----------------------------------------\n\nTITLE: YAML Search Configuration\nDESCRIPTION: YAML front matter block that sets search boost parameter for documentation indexing\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/helpers/obj_storage_declarer/OSBucketDeclarer.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Search Parameters\nDESCRIPTION: YAML configuration block defining search boost settings and section weights for documentation pages in FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asgi/get.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: FastStream AsyncAPI Page Configuration\nDESCRIPTION: YAML configuration that defines page weights and search boost parameters for a FastStream documentation page. The configuration includes numeric priorities for different page types and a search boost value of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/ServerBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Testing FastStream Applications with TestKafkaBroker\nDESCRIPTION: Example of unit testing a FastStream application using TestKafkaBroker, which redirects subscribers and publishers to in-memory brokers for testing without requiring actual message broker infrastructure.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Code above omitted 👆\n\nimport pytest\nimport pydantic\nfrom faststream.kafka import TestKafkaBroker\n\n\n@pytest.mark.asyncio\nasync def test_correct():\n    async with TestKafkaBroker(broker) as br:\n        await br.publish({\n            \"user\": \"John\",\n            \"user_id\": 1,\n        }, \"in\")\n\n@pytest.mark.asyncio\nasync def test_invalid():\n    async with TestKafkaBroker(broker) as br:\n        with pytest.raises(pydantic.ValidationError):\n            await br.publish(\"wrong message\", \"in\")\n```\n\n----------------------------------------\n\nTITLE: Creating Prometheus Settings Provider Factory for Confluent in Python\nDESCRIPTION: Factory function that creates Prometheus settings for Confluent integration. It takes optional parameters including a registry, namespace, and subsystem to configure how metrics are collected and labeled in Prometheus.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/prometheus/provider/settings_provider_factory.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef settings_provider_factory(\n    registry: Optional[CollectorRegistry] = None,\n    namespace: str = \"\",\n    subsystem: str = \"\",\n) -> Dict[str, PrometheusMetricsProvider]:\n    \"\"\"Create confluent prometheus settings provider.\n\n    Args:\n        registry: metrics registry\n        namespace: metrics namespace\n        subsystem: metrics subsystem\n\n    Returns:\n        Dict with settings provider\n    \"\"\"\n    from prometheus_client import CollectorRegistry as PrometheusRegistry\n\n    from faststream.confluent.prometheus.provider import PrometheusMetricsProvider\n\n    return {\"provider\": PrometheusMetricsProvider(registry or PrometheusRegistry(), namespace, subsystem)}\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: Front matter configuration for a documentation page specifying API weights, release settings, contributing guidelines, template page and default settings along with search boost parameters.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/prometheus/ConsumeAttrs.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Setting Exit Handler in FastStream CLI\nDESCRIPTION: This function allows registering a callback to be executed when the application receives termination signals. It handles both SIGTERM and SIGINT signals for graceful shutdown, utilizing Python's signal module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/supervisors/utils/set_exit.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef set_exit(callback, *args, **kwargs):\n    \"\"\"Set an exit handler for graceful shutdown of an application.\n\n    Args:\n        callback (Callable): The function to be called when the application exits.\n        *args: Arguments to pass to the callback.\n        **kwargs: Keyword arguments to pass to the callback.\n    \"\"\"\n    def handler(signum, frame):\n        return callback(*args, **kwargs)\n\n    signal.signal(signal.SIGTERM, handler)\n    signal.signal(signal.SIGINT, handler)\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream Documentation YAML Settings\nDESCRIPTION: YAML configuration block defining page weights and search boost parameters for different documentation sections including API, Release, Contributing and Template pages\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/exceptions/SkipMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Documentation Frontmatter Configuration in YAML\nDESCRIPTION: YAML configuration block defining documentation weights and search boost parameters for different sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/ContactDict.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Page Configuration YAML Front Matter\nDESCRIPTION: YAML front matter that configures the documentation page with search settings and various numeric identifiers for different page types.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/fastapi/Context.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter Configuration\nDESCRIPTION: YAML configuration block defining page weights and search boost parameters for a documentation site structure. Includes numbered sections for API, Release, Contributing and Template pages along with a search boost value.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/middlewares/exception/BaseExceptionMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.broker.middlewares.exception.BaseExceptionMiddleware\n```\n\n----------------------------------------\n\nTITLE: Creating Kafka Topics with FastStream Confluent Client in Python\nDESCRIPTION: This code snippet demonstrates the use of the create_topics function from the FastStream Confluent client. It allows for the creation of Kafka topics programmatically.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/client/create_topics.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.confluent.client.create_topics\n```\n\n----------------------------------------\n\nTITLE: Documentation Page Metadata Configuration\nDESCRIPTION: YAML frontmatter configuration for a documentation page, defining priority numbers for different sections and search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/queue/ClassicQueueSpecificArgs.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configure Search Boost Settings\nDESCRIPTION: YAML configuration block that defines search boost settings and page priority numbers for different sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/main/Schema.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: FastStream Documentation Page Configuration\nDESCRIPTION: YAML configuration for a documentation page, specifying search boost settings and documentation sections including API, Release, Contributing, Template Page, and Default categories.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/broker/registrator/RabbitRegistrator.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.broker.registrator.RabbitRegistrator\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boosts in YAML\nDESCRIPTION: YAML configuration for setting search boost values and defining page hierarchy with API, Release, Contributing, Template and Default sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/parser/remove_prefix.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Generating AsyncAPI Specification in JSON Format\nDESCRIPTION: This shell command generates the AsyncAPI specification for the FastStream application and saves it as a JSON file named 'asyncapi.json'.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/export.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nfaststream docs basic:app --output asyncapi.json\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Metadata in YAML\nDESCRIPTION: YAML configuration block defining section weights and search boost parameter for documentation pages. Includes weights for API (0.5), Release (2), Contributing (3), Template Page (5), and Default (10) sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/ExceptionMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Using after_startup hook with FastAPI's StreamRouter\nDESCRIPTION: Example of using the after_startup hook with FastAPI's StreamRouter. This enables operations with the message broker after the connection is established, like publishing initial messages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/integrations/fastapi/index.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\n\nfrom faststream.kafka.fastapi import KafkaRouter\n\nrouter = KafkaRouter(\"localhost:9092\")\napp = FastAPI(lifespan=router.lifespan_context)\napp.include_router(router)\n\n\n@router.subscriber(\"test_topic\")\nasync def handle_message(msg: str) -> None:\n    print(msg)\n\n\n@router.after_startup\nasync def publish_initial_message():\n    await router.broker.publish(\"Application started!\", \"test_topic\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation Search and Template Settings\nDESCRIPTION: YAML configuration block specifying page priorities, search boost values and template hierarchy for documentation generation\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/subscriber/asyncapi/AsyncAPISubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost Settings in YAML\nDESCRIPTION: YAML configuration block that sets up document metadata and search boost parameters for documentation pages. Includes priority numbers for different documentation sections and a search boost value.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/publisher/usecase/DefaultPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Constructing Test Messages for Kafka in FastStream (Python)\nDESCRIPTION: The build_message function is used to create test messages for Kafka in FastStream applications. It allows developers to simulate Kafka messages with custom headers, key, and value for testing purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/testing/build_message.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef build_message(\n    value: Any | None = None,\n    *,\n    key: Any | None = None,\n    headers: list[tuple[str, bytes]] | None = None,\n    topic: str | None = None,\n    partition: int | None = None,\n    timestamp: float | None = None,\n) -> KafkaMessage:\n```\n\n----------------------------------------\n\nTITLE: Implementing Asynchronous User Retrieval in FastStream\nDESCRIPTION: This endpoint retrieves all users from the database using an asynchronous SQLAlchemy query. It executes a SELECT statement and returns the results as a list of User models.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/dependencies/class.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@router.subscriber(\"get_users\")\nasync def get_users(db: AsyncSession = Depends(get_db)) -> List[User]:\n    result = await db.execute(select(User))\n    users = result.scalars().all()\n    return [User.from_orm(user) for user in users]\n```\n\n----------------------------------------\n\nTITLE: Generating AsyncAPI Schema JSON for Manual Customization\nDESCRIPTION: Shell command to generate the initial AsyncAPI schema.json file which can be manually edited for further customization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n{! docs_src/getting_started/asyncapi/serve.py [ln:9] !}\n```\n\n----------------------------------------\n\nTITLE: Implementing Fake Asynchronous Context Manager in Python\nDESCRIPTION: The fake_context function creates a context manager that simulates an asynchronous operation. It's useful for testing scenarios where you need to mock asynchronous behavior without actually performing async operations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/functions/fake_context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@contextlib.contextmanager\ndef fake_context():\n    \"\"\"Create a fake async context manager.\"\"\"\n    yield\n```\n\n----------------------------------------\n\nTITLE: YAML Documentation Configuration with Page Weights\nDESCRIPTION: YAML configuration that defines page weights and search boost settings for documentation organization. Includes weight assignments for API, Release, Contributing, Template and Default pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/redis/OperationBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.schema.bindings.redis.OperationBinding\n```\n\n----------------------------------------\n\nTITLE: Defining NoCast Utility Class in Python for FastStream\nDESCRIPTION: This code snippet defines the NoCast class, which is used to prevent automatic type casting of values in FastStream. It includes a __repr__ method for string representation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/no_cast/NoCast.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass NoCast:\n    \"\"\"Prevent auto casting of value\"\"\"\n\n    def __init__(self, value: Any) -> None:\n        self.value = value\n\n    def __repr__(self) -> str:\n        return f\"NoCast({self.value!r})\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost and Page Weights in YAML\nDESCRIPTION: YAML configuration block defining page weights for different sections and search boost parameter settings. Sets relative importance of different documentation sections with numeric weights and search boost value of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/utils/build_virtual_host.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Core Filtering Logic Implementation in FastStream\nDESCRIPTION: This snippet demonstrates the core logic for message filtering in FastStream. It iterates through handlers, applies filters, and processes the message with the first matching handler. If no handler is found, it raises a HandlerNotFoundError.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/subscription/filtering.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfor handler in subscriber.handlers:\n    if await handler.filter(msg):\n        return await handler.process(msg)\n\nraise HandlerNotFoundError\n```\n\n----------------------------------------\n\nTITLE: Documenting SASLPlaintext Class in FastStream Security Module (Python)\nDESCRIPTION: This code snippet represents a documentation directive for the SASLPlaintext class within the FastStream security module. It uses a special syntax to indicate that the following content should describe the SASLPlaintext class and its functionality.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/security/SASLPlaintext.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.security.SASLPlaintext\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream Documentation Structure and Search\nDESCRIPTION: YAML configuration that defines documentation hierarchy with numbered sections for API, Release, Contributing, and Template pages. Includes search boost parameter and FastStream schema reference.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/Schema.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.schema.Schema\n```\n\n----------------------------------------\n\nTITLE: Configure Page Metadata in YAML\nDESCRIPTION: YAML frontmatter configuration block that sets search boost parameters and numerical keys for different documentation sections like API, Release, Contributing, and Template pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/asyncapi/AsyncAPIBatchSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Generating AsyncAPI Schema for FastStream Applications\nDESCRIPTION: The get_app_schema function creates an AsyncAPI schema from a FastStream application. It processes the application's context, routers, and handlers to generate a complete API specification that can be used for documentation or integration purposes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/generate/get_app_schema.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.generate.get_app_schema\n```\n\n----------------------------------------\n\nTITLE: Referencing ObjWatch Schema in FastStream NATS Module\nDESCRIPTION: This code snippet references the ObjWatch schema from the FastStream NATS module. It's likely used to import or display documentation for the ObjWatch class, which is probably related to object watching functionality in NATS.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/schemas/obj_watch/ObjWatch.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.nats.schemas.obj_watch.ObjWatch\n```\n\n----------------------------------------\n\nTITLE: Running FastStream with Hot Reload\nDESCRIPTION: Command to run FastStream application with hot reload feature for development\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run basic:app --reload\n```\n\n----------------------------------------\n\nTITLE: Importing BatchSubscriber from FastStream Kafka Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the BatchSubscriber class from the FastStream Kafka subscriber usecase module. It's a crucial step for using batch processing functionality with Kafka in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/usecase/BatchSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.subscriber.usecase import BatchSubscriber\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: YAML configuration block defining documentation structure with numbered sections for API, Release, Contributing, Template Page and Default sections. Includes search boost configuration of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/ReplyConfig.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.ReplyConfig\n```\n\n----------------------------------------\n\nTITLE: Importing NatsBaseParser from FastStream NATS Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the NatsBaseParser class from the faststream.nats.parser module. This class is likely used for parsing NATS-related data or configurations within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/parser/NatsBaseParser.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.nats.parser.NatsBaseParser\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncAPIListPublisher from FastStream Redis Module\nDESCRIPTION: This code snippet shows how to import the AsyncAPIListPublisher class from the faststream.redis.publisher.asyncapi module. It's a key component for publishing messages to Redis using AsyncAPI in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/publisher/asyncapi/AsyncAPIListPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.publisher.asyncapi import AsyncAPIListPublisher\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Boost in Markdown\nDESCRIPTION: This snippet defines search boost settings for a documentation page. It sets the boost value to 0.5, which may affect the ranking of this page in search results.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/NoCast.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream Documentation Search Weights\nDESCRIPTION: YAML configuration that sets search boost values and page weights for different sections of the FastStream documentation. Defines hierarchy of documentation pages with numeric weights.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/apply_types.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: fast_depends.use.inject\n```\n\n----------------------------------------\n\nTITLE: Defining Redis Channel Binding Schema in FastStream AsyncAPI\nDESCRIPTION: This code snippet defines the schema for Redis channel bindings in FastStream's AsyncAPI implementation. It likely includes properties specific to Redis channels such as pattern subscriptions or key-based addressing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/redis/ChannelBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.asyncapi.schema.bindings.redis.ChannelBinding\n```\n\n----------------------------------------\n\nTITLE: Page Configuration in YAML\nDESCRIPTION: YAML configuration defining page weights for API docs, releases, contributing guide and template pages. Includes search boost setting of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/ExternalDocsDict.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.schema.ExternalDocsDict\n```\n\n----------------------------------------\n\nTITLE: Documenting OauthFlows Class in FastStream AsyncAPI Schema Security\nDESCRIPTION: This code snippet represents the documentation for the OauthFlows class in FastStream's AsyncAPI schema security module. It likely contains information about various OAuth flow types and their configurations.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/security/OauthFlows.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.schema.security.OauthFlows\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream Broker Default Filter\nDESCRIPTION: This code snippet demonstrates how to import the default_filter module from FastStream's broker utilities. The default_filter is likely used for filtering messages or data within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/utils/default_filter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.broker.utils import default_filter\n```\n\n----------------------------------------\n\nTITLE: Defining FastStream Project Search Weights in YAML\nDESCRIPTION: YAML configuration block defining search boost weights for different sections of documentation including API, Release, Contributing, Template and Default pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/opentelemetry/provider/TelemetrySettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.opentelemetry.provider.TelemetrySettingsProvider\n```\n\n----------------------------------------\n\nTITLE: Importing FakeProducer from FastStream Confluent Testing Module\nDESCRIPTION: This code snippet demonstrates how to import the FakeProducer class from the FastStream Confluent testing module. FakeProducer is likely used for creating mock Kafka producers in unit tests.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/testing/FakeProducer.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.testing import FakeProducer\n```\n\n----------------------------------------\n\nTITLE: Importing BatchPublisher from FastStream Confluent Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the BatchPublisher class from the FastStream Confluent module. It's used to access the BatchPublisher functionality for batch publishing to Confluent Kafka.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/publisher/usecase/BatchPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.confluent.publisher.usecase.BatchPublisher\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncAPIStreamPublisher from FastStream Redis Module\nDESCRIPTION: This code snippet shows the import statement for the AsyncAPIStreamPublisher class from the FastStream Redis publisher module. It's used to create an asynchronous API stream publisher for Redis.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/publisher/asyncapi/AsyncAPIStreamPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.publisher.asyncapi import AsyncAPIStreamPublisher\n```\n\n----------------------------------------\n\nTITLE: Running FastStream Application\nDESCRIPTION: Basic command to run a FastStream application using CLI\nSOURCE: https://github.com/ag2ai/faststream/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nfaststream run basic:app\n```\n\n----------------------------------------\n\nTITLE: Search Configuration in YAML\nDESCRIPTION: YAML configuration block specifying search boost parameter and page hierarchy numbers for API, Release, Contributing, Template and Default sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/helpers/KVBucketDeclarer.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing StreamMessage Class from FastStream Redis Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the StreamMessage class from the FastStream Redis module. It uses Python's import syntax to make the StreamMessage class available for use in the current scope.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/message/StreamMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.redis.message.StreamMessage\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost Settings in YAML\nDESCRIPTION: YAML frontmatter configuration for page metadata and search behavior settings. Sets search boost value and defines page organization numbers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/fastapi/fastapi/KafkaRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Settings in YAML\nDESCRIPTION: YAML configuration block that defines documentation settings including search boost parameters and page priorities indicated by numeric prefixes (0.5 - 10).\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/message/get_response_schema.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.message.get_response_schema\n```\n\n----------------------------------------\n\nTITLE: FastStream Documentation YAML Configuration\nDESCRIPTION: YAML configuration block defining page weights for different sections and search boost parameter. Includes weights for API, Release, Contributing and Template pages.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/nats/ChannelBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.schema.bindings.nats.ChannelBinding\n```\n\n----------------------------------------\n\nTITLE: Importing PatchedMessage Class from FastStream NATS Testing Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the PatchedMessage class from the FastStream NATS testing module. It's likely used for handling or mocking NATS messages in a testing environment.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/testing/PatchedMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.nats.testing import PatchedMessage\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost - YAML\nDESCRIPTION: YAML configuration block that sets search boost parameters and page metadata for documentation. Includes search boost value and page hierarchy indicators.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/publisher/usecase/RequestPublishKwargs.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing BasePrometheusMiddleware in Python\nDESCRIPTION: This code snippet shows how to import the BasePrometheusMiddleware class from the faststream.prometheus module. This class is likely used as a base for implementing Prometheus metrics collection in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/prometheus/BasePrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.prometheus import BasePrometheusMiddleware\n```\n\n----------------------------------------\n\nTITLE: Configuring Search and Page Settings in YAML\nDESCRIPTION: YAML front matter configuration defining page weights, search boost settings, and navigation hierarchy for the FastStream documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/prometheus/NatsPrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Resolving Context by Name in FastStream (Python)\nDESCRIPTION: This code snippet represents the 'resolve_context_by_name' function from the FastStream library. It is likely used for resolving context objects based on their names within the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/context/types/resolve_context_by_name.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.utils.context.types.resolve_context_by_name\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream Redis PubSub in Python\nDESCRIPTION: This code snippet demonstrates how to import the PubSub class from the faststream.redis module. It's a key component for working with Redis publish/subscribe functionality in FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/PubSub.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import PubSub\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Page Weights and Search Settings in YAML\nDESCRIPTION: YAML configuration that defines page weights and search boost settings for a documentation site. Includes numeric weights for different page types and a search boost parameter of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/parser/BatchParser.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.nats.parser.BatchParser\n```\n\n----------------------------------------\n\nTITLE: Importing BasePrometheusMiddleware in Python\nDESCRIPTION: This code snippet shows how to import the BasePrometheusMiddleware class from the faststream.prometheus.middleware module. This class is likely used for integrating Prometheus metrics into FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/prometheus/middleware/BasePrometheusMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.prometheus.middleware import BasePrometheusMiddleware\n```\n\n----------------------------------------\n\nTITLE: Defining AioKafkaBatchParser Class in Python for FastStream Kafka\nDESCRIPTION: This code snippet defines the AioKafkaBatchParser class, which is likely used for parsing Kafka messages in batches asynchronously. The class is part of the faststream.kafka.parser module.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/parser/AioKafkaBatchParser.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.kafka.parser.AioKafkaBatchParser\n```\n\n----------------------------------------\n\nTITLE: Importing CorrelationId from FastStream AsyncAPI Schema\nDESCRIPTION: This code snippet demonstrates how to import the CorrelationId class from the FastStream AsyncAPI schema module. It's a key component for defining correlation IDs in AsyncAPI specifications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/CorrelationId.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.asyncapi.schema import CorrelationId\n```\n\n----------------------------------------\n\nTITLE: Importing ConfluentFastConfig from FastStream\nDESCRIPTION: This code snippet demonstrates how to import the ConfluentFastConfig class from the faststream.confluent.config module. It's used to configure Confluent-specific settings in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/config/ConfluentFastConfig.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.config import ConfluentFastConfig\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation Page\nDESCRIPTION: YAML front matter that configures documentation page properties including search boost and navigation hierarchy with section priorities.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/broker/acknowledgement_watcher/BaseWatcher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing MetricsContainer from FastStream Prometheus Module\nDESCRIPTION: This code snippet demonstrates how to import the MetricsContainer class from the FastStream Prometheus module. It's a key component for managing Prometheus metrics in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/prometheus/container/MetricsContainer.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.prometheus.container import MetricsContainer\n```\n\n----------------------------------------\n\nTITLE: Configuring Search Boost Settings in YAML\nDESCRIPTION: YAML configuration block defining search boost parameters and page metadata with numeric priorities for different sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/TestRabbitBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Serving FastStream App with Custom AsyncAPI Schema\nDESCRIPTION: Shell command to serve FastStream application using a manually modified AsyncAPI schema.json file, providing fine-tuned control over documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/asyncapi/custom.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n{! docs_src/getting_started/asyncapi/serve.py [ln:21] !}\n```\n\n----------------------------------------\n\nTITLE: Documenting return_input Function in FastStream Utils (Python)\nDESCRIPTION: This code snippet represents the documentation for the return_input function in the FastStream utils module. The function likely returns its input unchanged, serving as a pass-through or identity function.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/functions/return_input.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.utils.functions.return_input\n```\n\n----------------------------------------\n\nTITLE: Documentation Page Configuration in YAML\nDESCRIPTION: YAML configuration block that defines page sections with their weights and search boost settings for documentation organization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/ReplayPolicy.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: nats.js.api.ReplayPolicy\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Search and API Settings\nDESCRIPTION: YAML configuration block defining API version numbers, release info, contribution guidelines and search boost parameters for FastStream documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/servers/Server.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Metadata for FastStream Documentation\nDESCRIPTION: This YAML snippet defines metadata for the FastStream project documentation. It includes search boost settings and references to different sections of the documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/log/formatter/expand_log_field.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing RedisRouter from FastStream Redis Module\nDESCRIPTION: This code snippet demonstrates how to import the RedisRouter class from the faststream.redis module. The RedisRouter is likely used for handling Redis-related operations in a FastStream application.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/RedisRouter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis import RedisRouter\n```\n\n----------------------------------------\n\nTITLE: Referencing FastStream AsyncAPI Channel Generation Function\nDESCRIPTION: This code snippet references the get_broker_channels function from the faststream.asyncapi.generate module. It is likely used to generate channel information for AsyncAPI documentation in the FastStream framework.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/generate/get_broker_channels.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.asyncapi.generate.get_broker_channels\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Settings in YAML\nDESCRIPTION: YAML configuration block defining documentation section weights and search boost parameters for the FastStream project documentation.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/schemas/queue/SharedClassicAndQuorumQueueArgs.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.rabbit.schemas.queue.SharedClassicAndQuorumQueueArgs\n```\n\n----------------------------------------\n\nTITLE: Setting Default Values in FastStream Context\nDESCRIPTION: Demonstrates how to set default values for fields that don't exist in the global context, preventing pydantic.ValidationError exceptions.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/context/extra.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context\n\nctx = Context(default=42)\n\nprint(ctx.non_existent_field)  # 42\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Decoder for AIOKafka in FastStream\nDESCRIPTION: Defines a custom decoder function for AIOKafka messages in FastStream. It specifies the input message type and expected output type.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/serialization/decoder.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.types import DecodedMessage\nfrom faststream.kafka import KafkaMessage\n\ndef decoder(msg: KafkaMessage) -> DecodedMessage:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaTelemetryMiddleware from FastStream Kafka OpenTelemetry module\nDESCRIPTION: This code snippet imports the KafkaTelemetryMiddleware class from the FastStream Kafka OpenTelemetry module. This middleware is used to add OpenTelemetry instrumentation to Kafka operations in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/opentelemetry/KafkaTelemetryMiddleware.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.kafka.opentelemetry import KafkaTelemetryMiddleware\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: YAML configuration that defines documentation sections with weights (0.5 to 10) and search boost parameters for documentation organization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/supervisors/utils/get_subprocess.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.cli.supervisors.utils.get_subprocess\n```\n\n----------------------------------------\n\nTITLE: Implementing TelemetryMiddleware with AIOKafka Broker\nDESCRIPTION: Example of adding TelemetryMiddleware to an AIOKafka broker for tracing message processing.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/observability/opentelemetry/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import FastStream\nfrom faststream.kafka import KafkaBroker\nfrom faststream.telemetry import TelemetryMiddleware\n\n# Create broker\nbroker = KafkaBroker(middlewares=[TelemetryMiddleware()])\n\n# Create application\napp = FastStream(broker)\n\n\n@broker.subscriber(\"input\")\nasync def handler_one(msg: str) -> None:\n    return {\"response\": msg}\n```\n\n----------------------------------------\n\nTITLE: Referencing RejectMessage Exception in FastStream\nDESCRIPTION: This code snippet demonstrates how to reference the RejectMessage exception class from the faststream.exceptions module. It uses Python's import syntax within a documentation block.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/exceptions/RejectMessage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.exceptions.RejectMessage\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Front Matter\nDESCRIPTION: YAML front matter configuration for a documentation page, specifying project paths, section weights and search boost settings.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/subscriber/subscription/Watchable.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream Utility Function in Python\nDESCRIPTION: This code snippet imports the 'drop_response_type' function from the FastStream utility module. This function is likely used for manipulating response types in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/utils/functions/drop_response_type.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.utils.functions import drop_response_type\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream AsyncAPI Reference Class\nDESCRIPTION: This code snippet imports the Reference class from the FastStream AsyncAPI schema module. The Reference class is likely used for handling references within AsyncAPI specifications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/Reference.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.asyncapi.schema import Reference\n```\n\n----------------------------------------\n\nTITLE: YAML Search Configuration\nDESCRIPTION: Defines the page hierarchy and search boost settings for a documentation site. Includes section weights and search relevance configuration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/nats/opentelemetry/provider/telemetry_attributes_provider_factory.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: YAML Search Configuration\nDESCRIPTION: YAML configuration block defining search boost settings and content priority levels for different sections of documentation\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asgi/websocket/WebSocketClose.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Importing RedisPublisher Class from FastStream Redis Router\nDESCRIPTION: This code snippet demonstrates how to import the RedisPublisher class from the faststream.redis.router module. It's a core component for publishing messages to Redis channels in FastStream applications.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/redis/router/RedisPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.redis.router import RedisPublisher\n```\n\n----------------------------------------\n\nTITLE: FastStream Page Configuration in YAML\nDESCRIPTION: YAML configuration block defining page metadata, sections, and search boosting settings for a FastStream documentation page.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/factory/create_subscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: FastStream Search Configuration in YAML\nDESCRIPTION: YAML configuration block defining search boost settings and page weights for different documentation sections.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/bindings/amqp/OperationBinding.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.asyncapi.schema.bindings.amqp.OperationBinding\n```\n\n----------------------------------------\n\nTITLE: Importing Path Resolution Function from FastStream CLI Utils\nDESCRIPTION: Python import statement referencing the get_app_path function from FastStream CLI utilities module for resolving application paths.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/imports/get_app_path.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfaststream.cli.utils.imports.get_app_path\n```\n\n----------------------------------------\n\nTITLE: Importing FastStream CorrelationId from AsyncAPI Schema\nDESCRIPTION: Import directive for the CorrelationId class from the faststream.asyncapi.schema.message module. This is used to include the class documentation on the page.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/asyncapi/schema/message/CorrelationId.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.asyncapi.schema.message.CorrelationId\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Documentation\nDESCRIPTION: YAML front matter configuration for documentation page, setting search boost and page metadata.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/opentelemetry/baggage/Baggage.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n```\n\n----------------------------------------\n\nTITLE: Running All FastStream Tests Including Slow Tests\nDESCRIPTION: Executes the complete test suite including tests marked as 'slow' using pytest marks.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/CONTRIBUTING.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npytest -m 'all'\n```\n\n----------------------------------------\n\nTITLE: Confluent Kafka Topic Partition Assignment\nDESCRIPTION: Shows how to manually assign topic partitions in Confluent Kafka using FastStream.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent import TopicPartition\n\n@broker.subscriber(partitions=[\n    TopicPartition(\"test-topic\", partition=0),\n])\nasync def handler():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Importing LogicSubscriber from FastStream RabbitMQ Module in Python\nDESCRIPTION: This code snippet shows how to import the LogicSubscriber class from the FastStream RabbitMQ subscriber module. It's typically used at the beginning of a file to make the LogicSubscriber class available for use in the rest of the code.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/rabbit/subscriber/usecase/LogicSubscriber.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: faststream.rabbit.subscriber.usecase.LogicSubscriber\n```\n\n----------------------------------------\n\nTITLE: Referencing Navigation Template File in Markdown\nDESCRIPTION: Demonstrates the Markdown link syntax for referencing the navigation template file in the FastStream GitHub repository.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/howto/kafka/index.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[`navigation_template.txt`](https://github.com/ag2ai/faststream/blob/main/docs/docs/navigation_template.txt){.external-link target=\"_blank\"}\n```\n\n----------------------------------------\n\nTITLE: Configuring FastStream Search and Metrics Settings\nDESCRIPTION: YAML configuration block defining search boost parameters and referencing the FastStream Prometheus metrics settings provider.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/prometheus/provider/MetricsSettingsProvider.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsearch:\n  boost: 0.5\n```\n\n----------------------------------------\n\nTITLE: Accessing Context Settings in FastStream\nDESCRIPTION: Example of how to access settings stored in the global context within FastStream application handlers.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/lifespan/hooks.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream import Context, apply_types\n@apply_types\nasync def func(settings = Context()): ...\n```\n\n----------------------------------------\n\nTITLE: Starting FastStream Documentation Local Server\nDESCRIPTION: Launches a local development server for FastStream documentation using MkDocs, allowing real-time preview of documentation changes.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/docs.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmkdocs serve\n```\n\n----------------------------------------\n\nTITLE: Configuring Documentation Search Weights in YAML\nDESCRIPTION: YAML configuration that defines documentation page weights and search boost values. Includes section priorities for API (0.5), Release (2), Contributing (3), Template Page (5), and Default (10) pages, with a search boost value of 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/broker/KafkaBroker.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.kafka.broker.KafkaBroker\n```\n\n----------------------------------------\n\nTITLE: FastStream Kafka Subscriber Directive\nDESCRIPTION: Directive for including FastStream Kafka subscriber factory documentation using custom documentation syntax.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/subscriber/factory/create_subscriber.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: faststream.kafka.subscriber.factory.create_subscriber\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for FastStream Documentation\nDESCRIPTION: Defines page weights for different documentation sections and search boost configuration. Pages are weighted from 0.5 to 10 with API having lowest priority and Default having highest priority.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/kafka/KafkaResponse.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.kafka.KafkaResponse\n```\n\n----------------------------------------\n\nTITLE: Running ASGI FastStream Application\nDESCRIPTION: Command to run a FastStream ASGI application using uvicorn server.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/release.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nuvicorn main:app\n```\n\n----------------------------------------\n\nTITLE: Implementing LogicPublisher Class for FastStream Confluent Integration\nDESCRIPTION: A Python class that implements publishing functionality for Confluent Kafka. It provides methods to publish messages to Kafka topics with various configuration options and handles message serialization.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/publisher/usecase/LogicPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Dict, List, Optional\n\nfrom faststream.broker.publisher import BasePublisher\nfrom faststream.confluent.message import ConfluentMessage\nfrom faststream.confluent.serializer import ConfluentSerializer\nfrom faststream.types import SendableMessage\nfrom faststream._compat import model_to_dict\n```\n\n----------------------------------------\n\nTITLE: Importing AsyncAPIPublisher Class from FastStream Confluent Module\nDESCRIPTION: This code snippet demonstrates how to import the AsyncAPIPublisher class from the faststream.confluent.publisher.asyncapi module. This class is likely used for publishing AsyncAPI specifications for Confluent-based messaging systems.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/publisher/asyncapi/AsyncAPIPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom faststream.confluent.publisher.asyncapi import AsyncAPIPublisher\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Front Matter for FastStream Confluent Kafka Documentation\nDESCRIPTION: This YAML front matter configures metadata for the KafkaPublisher documentation page. It sets search boost and defines the class to be documented.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/KafkaPublisher.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.KafkaPublisher\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Page Metadata\nDESCRIPTION: Defines page metadata including weights for different sections and search boost configuration.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/confluent/config/ConfluentConfig.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.confluent.config.ConfluentConfig\n```\n\n----------------------------------------\n\nTITLE: Activating Virtual Environment for FastStream Documentation\nDESCRIPTION: Activates the Python virtual environment for FastStream documentation development, making its packages available in the current shell session.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/getting-started/contributing/docs.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsource venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: YAML Documentation Configuration\nDESCRIPTION: Defines documentation section weights and search boost parameter settings. Section weights range from 0.5 to 10 and a search boost parameter is set to 0.5.\nSOURCE: https://github.com/ag2ai/faststream/blob/main/docs/docs/en/api/faststream/cli/utils/logs/get_log_level.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\n# 0.5 - API\n# 2 - Release\n# 3 - Contributing\n# 5 - Template Page\n# 10 - Default\nsearch:\n  boost: 0.5\n---\n\n::: faststream.cli.utils.logs.get_log_level\n```"
  }
]