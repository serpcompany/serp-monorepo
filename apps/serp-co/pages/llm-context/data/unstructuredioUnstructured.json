[
  {
    "owner": "unstructured-io",
    "repo": "unstructured",
    "content": "TITLE: Parsing a Document with unstructured's partition Function\nDESCRIPTION: This code demonstrates how to use unstructured's auto partition function to parse an email file. The partition function automatically detects the file type and processes it accordingly, returning structured elements from the document.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom unstructured.partition.auto import partition\n\nelements = partition(filename=\"example-docs/eml/fake-email.eml\")\nprint(\"\\n\\n\".join([str(el) for el in elements]))\n```\n\n----------------------------------------\n\nTITLE: Using Unstructured Library to Parse PDF Documents\nDESCRIPTION: Python code demonstrating how to use the unstructured library to partition a PDF document into structured elements. This is the core functionality for processing PDF files.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom unstructured.partition.pdf import partition_pdf\nelements = partition_pdf(filename=\"example-docs/layout-parser-paper-fast.pdf\")\n```\n\n----------------------------------------\n\nTITLE: PDF Document Parsing with unstructured\nDESCRIPTION: This example shows how to parse a PDF document using the unstructured library's partition function. The code automatically detects the file type and routes it to the appropriate processing function, returning structured elements extracted from the PDF.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom unstructured.partition.auto import partition\n\nelements = partition(\"example-docs/layout-parser-paper.pdf\")\n```\n\n----------------------------------------\n\nTITLE: Using Unstructured Library to Parse Text Files\nDESCRIPTION: Python code showing how to use the unstructured library to partition a plain text file into structured elements. This demonstrates the library's ability to process simple text documents.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom unstructured.partition.text import partition_text\nelements = partition_text(filename=\"example-docs/fake-text.txt\")\n```\n\n----------------------------------------\n\nTITLE: Adding document level language detection functionality\nDESCRIPTION: This enhancement adds document-level language detection functionality. It introduces the 'auto' default for the languages parameter in all partitioners and detects the primary language using the `langdetect` package. An additional `detect_language_per_element` parameter is also added for partitioners that return multiple elements, defaulting to False.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n\"Add document level language detection functionality. Adds the \\\"auto\\\" default for the languages param to all partitioners. The primary language present in the document is detected using the `langdetect` package. Additional param `detect_language_per_element` is also added for partitioners that return multiple elements. Defaults to `False`.\"\n```\n\n----------------------------------------\n\nTITLE: Creating Hugging Face Dataset from Unstructured Document Elements\nDESCRIPTION: Defines a function to convert a list of processed document elements into a Hugging Face Dataset object. The function extracts text from elements and constructs a dataset with specified features.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/empty.txt#2025-04-19_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef build_dataset_from_elements(\n    documents: List[List[Element]],\n    feature_names: Optional[List[str]] = None,\n) -> Dataset:\n    \"\"\"Build a huggingface dataset from a list of documents.\n\n    Parameters\n    ----------\n    documents\n        A list of documents, where each document is represented as a list of Elements\n    feature_names\n        A list of feature names to include in the dataset for each element. Default value is\n        [\"text\"].\n\n    Returns\n    -------\n    Dataset\n        A huggingface dataset constructed from the list of documents.\n    \"\"\"\n    if feature_names is None:\n        feature_names = [\"text\"]\n\n    # Initialize empty dataset\n    data_dict: Dict[str, List] = {}\n    for feature_name in feature_names:\n        data_dict[feature_name] = []\n\n    # Add elements from documents\n    for document in documents:\n        for element in document:\n            if isinstance(element, Text):\n                # Extract values for all specified features\n                for feature_name in feature_names:\n                    if feature_name == \"text\":\n                        data_dict[feature_name].append(element.text)\n                    else:\n                        if hasattr(element, feature_name):\n                            data_dict[feature_name].append(getattr(element, feature_name))\n                        else:\n                            data_dict[feature_name].append(None)\n\n    return Dataset.from_dict(data_dict)\n```\n\n----------------------------------------\n\nTITLE: Detecting text in HTML Heading Tags as Titles\nDESCRIPTION: This change enhances HTML document parsing by categorizing text within HTML heading tags as Titles, improving hierarchy accuracy and element categorization. The condition is that the text should not be a list item, address, or narrative text.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n\"Detect text in HTML Heading Tags as Titles This will increase the accuracy of hierarchies in HTML documents and provide more accurate element categorization. If text is in an HTML heading tag and is not a list item, address, or narrative text, categorize it as a title.\"\n```\n\n----------------------------------------\n\nTITLE: Adding element type frequency and depth calculation\nDESCRIPTION: The code adds a function that calculates the frequency of the element type and its depth in the document. This captures the accuracy of element type extraction by counting occurrences of each unique element type with its depth for use in element metrics.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n\"Adds a function that calculates frequency of the element type and its depth To capture the accuracy of element type extraction, this function counts the occurrences of each unique element type with its depth for use in element metrics.\"\n```\n\n----------------------------------------\n\nTITLE: Adding bag of words and percent missing text functions\nDESCRIPTION: This feature adds `bag_of_words` and `percent_missing_text` functions to count word frequencies and calculate the percentage of missing text relative to the source document. These functions are used for text analysis and comparison.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n\"Adds `bag_of_words` and `percent_missing_text` functions In order to count the word frequencies in two input texts and calculate the percentage of text missing relative to the source document.\"\n```\n\n----------------------------------------\n\nTITLE: Pulling Docker Image for Unstructured Library\nDESCRIPTION: Commands to pull the latest Docker image of the unstructured library from the official repository. The image supports both x86_64 and Apple silicon architectures.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull downloads.unstructured.io/unstructured-io/unstructured:latest\n```\n\n----------------------------------------\n\nTITLE: Retry Logic for Source Connectors\nDESCRIPTION: Adds retry logic for all source connectors by wrapping HTTP calls with a SourceConnectionNetworkError custom error, which triggers the retry mechanism in the ingest pipeline.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n\"Add retry logic for all source connectors\\nAll http calls being made by the ingest source connectors have been isolated and wrapped by the `SourceConnectionNetworkError` custom error, which triggers the retry logic, if enabled, in the ingest pipeline.\"\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Development Environment for unstructured\nDESCRIPTION: This command starts a Docker container with the local repository mounted, providing a consistent development environment across different operating systems. It eliminates the need to worry about OS compatibility with the repository and its dependencies.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmake docker-start-dev\n```\n\n----------------------------------------\n\nTITLE: Adding Request Timeout to Partition\nDESCRIPTION: Adds the ability to pass a timeout for a request when partitioning via a URL. The partition function now accepts a new optional parameter request_timeout to prevent requests.get from hanging indefinitely.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n\"Adds ability to pass timeout for a request when partitioning via a `url`.`partition` now accepts a new optional parameter `request_timeout` which if set will prevent any `requests.get` from hanging indefinitely and instead will raise a timeout error. This is useful when partitioning a url that may be slow to respond or may not respond at all.\"\n```\n\n----------------------------------------\n\nTITLE: Downloading SEC XBRL 10-K Filing with curl in Bash\nDESCRIPTION: This command uses curl to download an example 10-K filing in inline XBRL format from the SEC website. It requires setting a user agent header with organization and email to avoid being rejected by the SEC server. The downloaded file can then be parsed using the HTML parser in the unstructured library.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/README.rst#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -O \\\n  -A '${organization} ${email}'\n  https://www.sec.gov/Archives/edgar/data/311094/000117184321001344/0001171843-21-001344.txt\n```\n\n----------------------------------------\n\nTITLE: Fix PDF Strategy\nDESCRIPTION: Fixes the logic that determines the PDF auto strategy. The hi_res strategy is now returned if either infer_table_structure or extract_images_in_pdf is true.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n\"Fix logic that determines pdf auto strategy. Previously, `_determine_pdf_auto_strategy` returned `hi_res` strategy only if `infer_table_structure` was true. It now returns the `hi_res` strategy if either `infer_table_structure` or `extract_images_in_pdf` is true.\"\n```\n\n----------------------------------------\n\nTITLE: PDF Error Handling\nDESCRIPTION: Adds exception handling to handle unexpected errors when extracting PDF text using pdfminer, allowing the partition_pdf function to proceed with an alternative strategy if text extraction fails.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n\"Handle errors when extracting PDF text\\nCertain pdfs throw unexpected errors when being opened by `pdfminer`, causing `partition_pdf()` to fail. We expect to be able to partition smoothly using an alternative strategy if text extraction doesn't work.  Added exception handling to handle unexpected errors when extracting pdf text and to help determine pdf strategy.\"\n```\n\n----------------------------------------\n\nTITLE: Running Profile Scripts in Unstructured Library\nDESCRIPTION: Commands to execute the profiling script for the Unstructured library on different operating systems. Linux users can run the script directly, while macOS users need to use sudo with the -E flag to preserve environment variables.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/scripts/performance/README.md#2025-04-19_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/performance/profile.sh\n```\n\nLANGUAGE: bash\nCODE:\n```\nsudo -E ./scripts/performance/profile.sh\n```\n\n----------------------------------------\n\nTITLE: Running Benchmark Scripts in Unstructured Library\nDESCRIPTION: Command to execute the benchmark script for the Unstructured library. The script supports various environment variables to configure the benchmarking process.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/scripts/performance/README.md#2025-04-19_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./scripts/performance/benchmark.sh\n```\n\n----------------------------------------\n\nTITLE: Downloading SEC XBRL 10-K Filing using cURL\nDESCRIPTION: Command to download a sample 10-K filing in inline XBRL format from the SEC website. Requires setting a user agent header to avoid request rejection by the SEC site.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/README-w-include.rst#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -O \\\n     -A '${organization} ${email}'\n     https://www.sec.gov/Archives/edgar/data/311094/000117184321001344/0001171843-21-001344.txt\n```\n\n----------------------------------------\n\nTITLE: Installing Profiling Dependencies for Unstructured Library\nDESCRIPTION: Commands to install the required dependencies for the profiling functionality. This includes Python dependencies from a requirements file and the speedscope npm package for visualizing profiling results.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/scripts/performance/README.md#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r scripts/performance/requirements.txt\nnpm install -g speedscope\n```\n\n----------------------------------------\n\nTITLE: Building and Starting a Docker Image Locally\nDESCRIPTION: Make commands to build the Docker image locally from source and start a bash shell in the container. This approach is useful for development or customizing the container.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmake docker-build\n\n# this will drop you into a bash shell where the Docker image is running\nmake docker-start-bash\n```\n\n----------------------------------------\n\nTITLE: Fixing duplicated elements in embeddings generation\nDESCRIPTION: This code change addresses an issue where elements were duplicated when embeddings were generated. This will allow users to generate embeddings for their list of Elements without duplicating/breaking the original content.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n\"Fixes duplicated elements Fixes issue where elements are duplicated when embeddings are generated. This will allow users to generate embeddings for their list of Elements without duplicating/breaking the orginal content.\"\n```\n\n----------------------------------------\n\nTITLE: Adding Table support for add_chunking_strategy decorator\nDESCRIPTION: This enhancement adds Table support for the `add_chunking_strategy` decorator in partition functions. Users can specify `max_characters=<n>` to chunk Table elements into TableChunk elements with `text` and `text_as_html` of length `<n>` characters.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n\"Adds Table support for the `add_chunking_strategy` decorator to partition functions. In addition to combining elements under Title elements, user's can now specify the `max_characters=<n>` argument to chunk Table elements into TableChunk elements with `text` and `text_as_html` of length `<n>` characters. This means partitioned Table results are ready for use in downstream applications without any post processing.\"\n```\n\n----------------------------------------\n\nTITLE: Adding XLSX document level language detection\nDESCRIPTION: The enhancement adds language detection within `.xlsx` file type at Element level, building upon previous language detection functionality.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n\"Adds XLSX document level language detection Enhancing on top of language detection functionality in previous release, we now support language detection within `.xlsx` file type at Element level.\"\n```\n\n----------------------------------------\n\nTITLE: Fixing category_depth None value for Title elements\nDESCRIPTION: This change fixes an issue where Title elements from chipper get `category_depth`= None even when Headline and/or Subheadline elements are present on the same page. All Title elements with `category_depth` = None are set to have a depth of 0 if there are Headline and/or Subheadline elements.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n\"Fixes category_depth None value for Title elements Problem: `Title` elements from `chipper` get `category_depth`= None even when `Headline` and/or `Subheadline` elements are present in the same page. Fix: all `Title` elements with `category_depth` = None should be set to have a depth of 0 instead iff there are `Headline` and/or `Subheadline` element-types present. Importance: `Title` elements should be equivalent html `H1` when nested headings are present; otherwise, `category_depth` metadata can result ambiguous within elements in a page.\"\n```\n\n----------------------------------------\n\nTITLE: Listing Dependencies for Unstructured Ingest Project in Python\nDESCRIPTION: This code snippet specifies the required Python packages and their versions for the Unstructured Ingest project. It includes a comprehensive list of integrations for unstructured-ingest and other essential libraries.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/ingest/ingest.txt#2025-04-19_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nunstructured-ingest[airtable, astradb, azure, azure-cognitive-search, bedrock, biomed, box, chroma, clarifai, confluence, couchbase, databricks-volumes, delta-table, discord, dropbox, elasticsearch, embed-huggingface, embed-octoai, embed-vertexai, embed-voyageai, gcs, github, gitlab, google-drive, hubspot, jira, kafka, kdbai, milvus, mongodb, notion, onedrive, openai, opensearch, outlook, pinecone, postgres, qdrant, reddit, remote, s3, salesforce, sftp, sharepoint, singlestore, slack, vectara, weaviate, wikipedia]==0.2.1\ns3fs>=2024.9.0\nurllib3>=1.26.20\nbackoff>=2.2.1\nhttpx>=0.27.2\n```\n\n----------------------------------------\n\nTITLE: Defining Global Dependency Constraints for Python Packages\nDESCRIPTION: This configuration specifies version constraints for various Python dependencies to prevent conflicts and ensure compatibility. It includes constraints for packages like weaviate-client, protobuf, grpcio, and others with specific version requirements and explanatory comments.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/deps/constraints.txt#2025-04-19_snippet_0\n\nLANGUAGE: plain\nCODE:\n```\n####################################################################################################\n# This file can house global constraints that aren't *direct* requirements of the package or any\n# extras. Putting a dependency here will only affect dependency sets that contain them -- in other\n# words, if something does not require a constraint, it will not be installed.\n####################################################################################################\n# we are using v3 client https://weaviate.io/developers/weaviate/client-libraries/python/python_v3\nweaviate-client>=3.26.7,<4.0.0\n# TODO: Constriant due to multiple versions being installed during pip-compile\nprotobuf>=6.30.0\n# TODO: Constriant due to multiple versions being installed during pip-compile\ngrpcio>=1.65.5\n# TODO: Pinned in transformers package, remove when that gets updated (https://github.com/huggingface/transformers/blob/main/setup.py)\ntokenizers>=0.21,<0.22\n# TODO: Constaint due to boto, with python before 3.10 not requiring openssl 1.1.1, remove when that gets\n# updated or we drop support for 3.9\nurllib3<1.27\n# TODO: Constriant due to aiobotocore, remove when that gets updates:\nbotocore<1.34.132\n# TODO: Constriant due to both 8.5.0 and 8.4.0 being installed during pip-compile\nimportlib-metadata>=8.5.0\n# (austin): Versions below this have a different interface for passing parameters\nunstructured-client>=0.23.0,<0.26.0\n# paddle constrains protobuf; maybe we should put paddle here since its version is pinned in .in file\nprotobuf>=6.30.0\n```\n\n----------------------------------------\n\nTITLE: Adding detection origin field to metadata\nDESCRIPTION: This feature adds the `detection_origin` field to the metadata of elements. This helps determine how an element was created, aiding developers and users in understanding element creation and usage. It requires setting `UNSTRUCTURED_INCLUDE_DEBUG_METADATA=true`.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n\"Adds detection_origin field to metadata Problem: Currently isn't an easy way to find out how an element was created. With this change that information is added. Importance: With this information the developers and users are now able to know how an element was created to make decisions on how to use it. In order tu use this feature\\n  setting UNSTRUCTURED_INCLUDE_DEBUG_METADATA=true is needed.\"\n```\n\n----------------------------------------\n\nTITLE: Pip Dependencies Configuration for PaddleOCR\nDESCRIPTION: A comprehensive pip requirements file generated via pip-compile, specifying exact versions of packages needed for PaddleOCR functionality. Includes dependencies like paddlepaddle, opencv, albumentations, and various image processing libraries with their version constraints and dependency chains.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-paddleocr.txt#2025-04-19_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\n#\n# This file is autogenerated by pip-compile with Python 3.9\n# by the following command:\n#\n#    pip-compile ./extra-paddleocr.in\n#\nalbucore==0.0.23\n    # via\n    #   albumentations\n    #   unstructured-paddleocr\nalbumentations==2.0.5\n    # via unstructured-paddleocr\nannotated-types==0.7.0\n    # via pydantic\nanyio==4.9.0\n    # via\n    #   -c ./base.txt\n    #   httpx\nastor==0.8.1\n    # via paddlepaddle\nbeautifulsoup4==4.13.3\n    # via\n    #   -c ./base.txt\n    #   unstructured-paddleocr\ncertifi==2025.1.31\n    # via\n    #   -c ./base.txt\n    #   httpcore\n    #   httpx\n    #   requests\n```\n\n----------------------------------------\n\nTITLE: PPTX Dependencies List with Version Specifications\nDESCRIPTION: A complete listing of required dependencies for PowerPoint processing functionality, including their exact versions and the packages that require them. Each dependency is pinned to a specific version for reproducibility.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-pptx.txt#2025-04-19_snippet_1\n\nLANGUAGE: pip\nCODE:\n```\nlxml==5.3.1\n    # via python-pptx\npillow==11.1.0\n    # via python-pptx\npython-pptx==1.0.2\n    # via -r ./extra-pptx.in\ntyping-extensions==4.13.0\n    # via python-pptx\nxlsxwriter==3.2.2\n    # via python-pptx\n```\n\n----------------------------------------\n\nTITLE: Pip-compiled requirements for XLSX processing in Python\nDESCRIPTION: This pip-compiled requirements file lists all dependencies needed for XLSX file processing. It includes direct dependencies like openpyxl, pandas, xlrd, and networkx, as well as their transitive dependencies with specific version constraints.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-xlsx.txt#2025-04-19_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\net-xmlfile==2.0.0\n    # via openpyxl\nnetworkx==3.2.1\n    # via -r ./extra-xlsx.in\nnumpy==2.0.2\n    # via\n    #   -c ./base.txt\n    #   pandas\nopenpyxl==3.1.5\n    # via -r ./extra-xlsx.in\npandas==2.2.3\n    # via -r ./extra-xlsx.in\npython-dateutil==2.9.0.post0\n    # via\n    #   -c ./base.txt\n    #   pandas\npytz==2025.2\n    # via pandas\nsix==1.17.0\n    # via\n    #   -c ./base.txt\n    #   python-dateutil\ntzdata==2025.2\n    # via pandas\nxlrd==2.0.1\n    # via -r ./extra-xlsx.in\n```\n\n----------------------------------------\n\nTITLE: Pip Dependencies Configuration for Markdown Processing\nDESCRIPTION: Defines exact package versions for Markdown processing functionality. Includes importlib-metadata 8.6.1, markdown 3.7, and zipp 3.21.0 as required dependencies, with constraints applied from an external constraints file.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-markdown.txt#2025-04-19_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\nimportlib-metadata==8.6.1\n    # via\n    #   -c ././deps/constraints.txt\n    #   markdown\nmarkdown==3.7\n    # via -r ./extra-markdown.in\nzipp==3.21.0\n    # via importlib-metadata\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Hugging Face Dataset Creation\nDESCRIPTION: Imports necessary libraries including datasets from Hugging Face and unstructured components for document processing.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/empty.txt#2025-04-19_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom typing import Dict, List, Optional, Union\n\nimport datasets\nfrom datasets import Dataset\nfrom unstructured.documents.elements import Element, Text\n```\n\n----------------------------------------\n\nTITLE: Setting default language to None in ingest CLI\nDESCRIPTION: The change sets the default language in the ingest CLI to None. This allows downstream language detection libraries to better detect the language of the processed document, avoiding potentially incorrect language injection.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n\"Fix default language in ingest CLI Previously the default was being set to english which injected potentially incorrect information to downstream language detection libraries. By setting the default to None allows those libraries to better detect what language the text is in the doc being processed.\"\n```\n\n----------------------------------------\n\nTITLE: Fix invalid Tesseract OCR coordinates\nDESCRIPTION: Fixes invalid bounding box coordinates in Tesseract OCR data when zoom is set to 0. A logical check is added to prevent the error.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n\"Fix invalid coordinates when parsing tesseract ocr data. Previously, when parsing tesseract ocr data, the ocr data had invalid bboxes if zoom was set to `0`. A logical check is now added to avoid such error.\"\n```\n\n----------------------------------------\n\nTITLE: Adding edit distance calculation metrics\nDESCRIPTION: This feature adds `edit_distance` (Levenshtein distance) calculation metrics. This is used to benchmark the cleaned, extracted text with unstructured text.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n\"Adds `edit_distance` calculation metrics In order to benchmark the cleaned, extracted text with unstructured, `edit_distance` (`Levenshtein distance`) is included.\"\n```\n\n----------------------------------------\n\nTITLE: Partition API Parameters\nDESCRIPTION: Fixes an issue where ingest partition parameters were not being passed to the API when using the --partition-by-api flag. All relevant partition arguments are now passed through to the API.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n\"Fix ingest partition parameters not being passed to the api. When using the --partition-by-api flag via unstructured-ingest, none of the partition arguments are forwarded, meaning that these options are disregarded. With this change, we now pass through all of the relevant partition arguments to the api. This allows a user to specify all of the same partition arguments they would locally and have them respected when specifying --partition-by-api.\"\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies for DOCX Processing\nDESCRIPTION: This snippet lists the required Python packages and their versions for DOCX processing. It includes lxml, python-docx, and typing-extensions, with references to other requirement files.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-docx.txt#2025-04-19_snippet_1\n\nLANGUAGE: Text\nCODE:\n```\nlxml==5.3.1\n    # via\n    #   -c ./base.txt\n    #   python-docx\npython-docx==1.1.2\n    # via -r ./extra-docx.in\ntyping-extensions==4.13.0\n    # via\n    #   -c ./base.txt\n    #   python-docx\n```\n\n----------------------------------------\n\nTITLE: Generating Python Dependencies with pip-compile\nDESCRIPTION: This code snippet shows the command used to generate the dependencies file using pip-compile. It specifies the input file and Python version used.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-docx.txt#2025-04-19_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\n#    pip-compile ./extra-docx.in\n```\n\n----------------------------------------\n\nTITLE: Pip-compile Command for CSV Requirements\nDESCRIPTION: The command used to auto-generate this requirements file using pip-compile. It compiles the ./extra-csv.in file with Python 3.9.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-csv.txt#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip-compile ./extra-csv.in\n```\n\n----------------------------------------\n\nTITLE: Email MIME Structure with Plain Text and HTML Content\nDESCRIPTION: A complete email message in MIME format with headers and multipart content including both plain text and HTML versions of the same message. The email contains metadata in headers followed by content boundaries and properly formatted message parts.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/fake-email.txt#2025-04-19_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nMIME-Version: 1.0\nDate: Fri, 16 Dec 2022 17:04:16 -0500\nMessage-ID: <CADc-_xaLB2FeVQ7mNsoX+NJb_7hAJhBKa_zet-rtgPGenj0uVw@mail.gmail.com>\nSubject: Test Email\nFrom: Matthew Robinson <mrobinson@unstructured.io>\nTo: Matthew Robinson <mrobinson@unstructured.io>\nContent-Type: multipart/alternative; boundary=\"00000000000095c9b205eff92630\"\n\n--00000000000095c9b205eff92630\nContent-Type: text/plain; charset=\"UTF-8\"\n\nThis is a test email to use for unit tests.\n\nImportant points:\n\n   - Roses are red\n   - Violets are blue\n   - \n\n--00000000000095c9b205eff92630\nContent-Type: text/html; charset=\"UTF-8\"\n\n<div dir=\"ltr\"><div>This is a test email to use for unit tests.</div><div><br></div><div>Important points:</div><div><ul><li>Roses are red</li><li>Violets are blue</li></ul></div></div>\n\n--00000000000095c9b205eff92630--\n```\n\n----------------------------------------\n\nTITLE: Pip Compile Command for PDF/Image Dependencies\nDESCRIPTION: The pip-compile command used to generate this requirements file from the extra-pdf-image.in input file using Python 3.9.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-pdf-image.txt#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip-compile ./extra-pdf-image.in\n```\n\n----------------------------------------\n\nTITLE: Pip-compile command for generating test dependencies\nDESCRIPTION: The command used to generate this requirements file. It uses pip-compile with Python 3.9 to compile the test.in file into a comprehensive requirements list with specific versions.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/test.txt#2025-04-19_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\npip-compile ./test.in\n```\n\n----------------------------------------\n\nTITLE: Fixing badly initialized Formula\nDESCRIPTION: This change addresses an issue where the Formula class was inheriting from Element instead of Text, causing problems when loading documents containing formulas. The fix involves changing the parent class for Formula to Text to ensure the element is created with the correct class.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n\"Fixes badly initialized Formula Problem: YoloX contain new types of elements, when loading a document that contain formulas a new element of that class\\n  should be generated, however the Formula class inherits from Element instead of Text. After this change the element is correctly created with the correct class\\n  allowing the document to be loaded. Fix: Change parent class for Formula to Text. Importance: Crucial to be able to load documents that contain formulas.\"\n```\n\n----------------------------------------\n\nTITLE: Generating Huggingface Dependencies with pip-compile\nDESCRIPTION: This code snippet shows the command used to generate the requirements file using pip-compile. It specifies the input file and Python version used for compilation.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/huggingface.txt#2025-04-19_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\n#    pip-compile ./huggingface.in\n```\n\n----------------------------------------\n\nTITLE: Specifying Pandoc Dependency in Python\nDESCRIPTION: This snippet specifies the pypandoc library as a dependency for the project. It includes the version number and indicates that it was sourced from the extra-pandoc.in file.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-pandoc.txt#2025-04-19_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\npypandoc==1.15\n    # via -r ./extra-pandoc.in\n```\n\n----------------------------------------\n\nTITLE: Compiling PPTX Dependencies with pip-compile for Python 3.9\nDESCRIPTION: This snippet shows the command used to generate the requirements file using pip-compile. It compiles dependencies from the extra-pptx.in input file for Python 3.9.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-pptx.txt#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip-compile ./extra-pptx.in\n```\n\n----------------------------------------\n\nTITLE: Pip Requirements File for ODT Support\nDESCRIPTION: A pip-compile generated requirements file that lists Python packages needed for ODT (OpenDocument Text) processing in the unstructured project. It includes version constraints and references to the base requirements file.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-odt.txt#2025-04-19_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\n#\n# This file is autogenerated by pip-compile with Python 3.9\n# by the following command:\n#\n#    pip-compile ./extra-odt.in\n#\nlxml==5.3.1\n    # via\n    #   -c ./base.txt\n    #   python-docx\npypandoc==1.15\n    # via -r ./extra-odt.in\npython-docx==1.1.2\n    # via -r ./extra-odt.in\ntyping-extensions==4.13.0\n    # via\n    #   -c ./base.txt\n    #   python-docx\n```\n\n----------------------------------------\n\nTITLE: Fixing ingest pipeline reformat nodes import error\nDESCRIPTION: The following change fixes an issue where reformat nodes in the ingest pipeline raised a ModuleNotFoundError on import. This issue was caused by a missing `__init__.py` file in the directory, preventing it from being discoverable as a module.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n\"Fix ingest pipeline reformat nodes not discoverable Fixes issue where  reformat nodes raise ModuleNotFoundError on import. This was due to the directory was missing `__init__.py` in order to make it discoverable.\"\n```\n\n----------------------------------------\n\nTITLE: Defining Python Profiling Package Requirements\nDESCRIPTION: Lists required Python packages for profiling and performance monitoring with their minimum version requirements. Includes flameprof for flame graphs, memray for memory monitoring, snakeviz for profiling visualization, and py-spy for sampling profiler.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/scripts/performance/requirements.txt#2025-04-19_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nflameprof>=0.4\nmemray>=1.7.0\nsnakeviz>=2.2.0\npy-spy>=0.3.14\n```\n\n----------------------------------------\n\nTITLE: Generating pip requirements file with pip-compile\nDESCRIPTION: Command used to generate the requirements file from base.in. This shows the pip-compile command that was used to create this comprehensive dependency list with exact versions.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/base.txt#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip-compile ./base.in\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Entries\nDESCRIPTION: Version history entries documenting changes, new features, and fixes across multiple releases of the Unstructured project.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CHANGELOG.md#2025-04-19_snippet_19\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n* Add `--metadata-include` and `--metadata-exclude` parameters to `unstructured-ingest`\n* Add `clean_non_ascii_chars` to remove non-ascii characters from unicode string\n\n### Fixes\n\n* Fix problem with PDF partition (duplicated test)\n\n## 0.5.4\n\n### Enhancements\n\n* Added Biomedical literature connector for ingest cli.\n* Add `FsspecConnector` to easily integrate any existing `fsspec` filesystem as a connector.\n* Rename `s3_connector.py` to `s3.py` for readability and consistency with the\n  rest of the connectors.\n* Now `S3Connector` relies on `s3fs` instead of on `boto3`, and it inherits\n  from `FsspecConnector`.\n* Adds an `UNSTRUCTURED_LANGUAGE_CHECKS` environment variable to control whether or not language\n  specific checks like vocabulary and POS tagging are applied. Set to `\"true\"` for higher\n  resolution partitioning and `\"false\"` for faster processing.\n* Improves `detect_filetype` warning to include filename when provided.\n* Adds a \"fast\" strategy for partitioning PDFs with PDFMiner. Also falls back to the \"fast\"\n  strategy if detectron2 is not available.\n* Start deprecation life cycle for `unstructured-ingest --s3-url` option, to be deprecated in\n  favor of `--remote-url`.\n```\n\n----------------------------------------\n\nTITLE: Defining Personal Information JSON Object\nDESCRIPTION: This JSON object defines a person's details including name, age, email, student status, address (city and zipcode), and an array of hobbies. It demonstrates nested objects and arrays within a JSON structure.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/fake-incomplete-json.txt#2025-04-19_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"name\": \"John Doe\",\n  \"age\": 30,\n  \"email\": \"johndoe@example.com\",\n  \"is_student\": true,\n  \"address\": {\n    \"city\": \"New York\",\n    \"zipcode\": \"10001\"\n  },\n  \"hobbies\": [\"reading\", \"running\", \"cooking\"]\n\n```\n\n----------------------------------------\n\nTITLE: Specifying pypandoc Dependency for EPUB Processing in pip-compile Generated File\nDESCRIPTION: This requirements file specifies that pypandoc version 1.15 is needed for EPUB functionality. The file is auto-generated by pip-compile from the extra-epub.in source file with Python 3.9.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/extra-epub.txt#2025-04-19_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n#\n# This file is autogenerated by pip-compile with Python 3.9\n# by the following command:\n#\n#    pip-compile ./extra-epub.in\n#\npypandoc==1.15\n    # via -r ./extra-epub.in\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Product Inventory Table in Markdown\nDESCRIPTION: A markdown table showing product inventory with three columns: Item, Price, and number in stock. The table includes two products with their respective details.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/simple-table.md#2025-04-19_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nItem | Price | # In stock\n---|---|---\nJuicy Apples | 1.99 | 739\nBananas | 1.89 | 6\n```\n\n----------------------------------------\n\nTITLE: Example of Python License Header for setup.py\nDESCRIPTION: This code snippet references the location of a license header example that should be included at the top of new setup.py files in Python projects.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/CONTRIBUTING.md#2025-04-19_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [Python license example](https://github.com/Unstructured-IO/unstructured/blob/main/setup.py)\n```\n\n----------------------------------------\n\nTITLE: HTML Email Content\nDESCRIPTION: The HTML version of the email message body with formatting\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/test_unstructured/file_utils/test-file-contents.txt#2025-04-19_snippet_1\n\nLANGUAGE: text/html\nCODE:\n```\n<div dir=3D\"ltr\">Hi,<div><br></div><div>The unstructured logo is attached t=\no this email.<br clear=3D\"all\"><div><br></div>-- <br><div dir=3D\"ltr\" class=\n=3D\"gmail_signature\" data-smartmail=3D\"gmail_signature\"><div dir=3D\"ltr\">Ma=\nllori Harrell<div>Unstructured Technologies<br><div>Data Scientist</div><di=\nv><br></div></div></div></div></div></div>\n```\n\n----------------------------------------\n\nTITLE: HTML Email Content with Formatted List\nDESCRIPTION: HTML portion of the email containing formatted text with a bulleted list. This HTML snippet demonstrates basic email formatting with div elements and an unordered list.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/example-docs/fake-email.txt#2025-04-19_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div dir=\"ltr\"><div>This is a test email to use for unit tests.</div><div><br></div><div>Important points:</div><div><ul><li>Roses are red</li><li>Violets are blue</li></ul></div></div>\n```\n\n----------------------------------------\n\nTITLE: Generating Python Dependencies with pip-compile\nDESCRIPTION: The command used to generate this requirements lock file. It shows pip-compile was used against the dev.in file to create a deterministic set of dependencies with specific versions.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/requirements/dev.txt#2025-04-19_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip-compile ./dev.in\n```\n\n----------------------------------------\n\nTITLE: Creating and Accessing Docker Container for Unstructured\nDESCRIPTION: Commands to create a Docker container from the unstructured image and access its bash shell for running the library. This provides an isolated environment with all dependencies pre-installed.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/README.md#2025-04-19_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# create the container\ndocker run -dt --name unstructured downloads.unstructured.io/unstructured-io/unstructured:latest\n\n# this will drop you into a bash shell where the Docker image is running\ndocker exec -it unstructured bash\n```\n\n----------------------------------------\n\nTITLE: Plain Text Email Content\nDESCRIPTION: The plain text version of the email message body\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/test_unstructured/file_utils/test-file-contents.txt#2025-04-19_snippet_0\n\nLANGUAGE: text/plain\nCODE:\n```\nHi,\n\nThe unstructured logo is attached to this email.\n\n-- \nMallori Harrell\nUnstructured Technologies\nData Scientist\n```\n\n----------------------------------------\n\nTITLE: Encoded Data Block\nDESCRIPTION: This snippet presents a large base64 encoded string. Without further context, its contents and original format are unknown. Decoding and further processing will be required to understand its purpose.\nSOURCE: https://github.com/unstructured-io/unstructured/blob/main/test_unstructured/file_utils/test-file-contents.txt#2025-04-19_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n\"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\"\n```"
  }
]