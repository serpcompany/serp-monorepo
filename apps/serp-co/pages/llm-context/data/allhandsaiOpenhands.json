[
  {
    "owner": "all-hands-ai",
    "repo": "openhands",
    "content": "TITLE: Implementing Agent Control Loop in Python\nDESCRIPTION: Core control loop that drives agent behavior, showing the cycle of prompt generation, LLM completion, action parsing, runtime execution, and state updates.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nwhile True:\n  prompt = agent.generate_prompt(state)\n  response = llm.completion(prompt)\n  action = agent.parse_response(response)\n  observation = runtime.run(action)\n  state = state.update(action, observation)\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Docker Container\nDESCRIPTION: Docker command to pull and run the OpenHands application container. Sets up environment variables, volume mounts, port forwarding, and network configuration needed for OpenHands to function properly.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/installation.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik\n\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -e LOG_ALL_EVENTS=true \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    -p 3000:3000 \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.33\n```\n\n----------------------------------------\n\nTITLE: Processing Evaluation Instance in OpenHands\nDESCRIPTION: This Python function processes each evaluation instance, initializing the runtime, running the controller, and evaluating the agent's actions to produce an EvalOutput object.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom openhands.utils.async_utils import call_async_from_sync\ndef process_instance(instance: pd.Series, metadata: EvalMetadata) -> EvalOutput:\n    config = get_config(instance, metadata)\n    runtime = create_runtime(config)\n    call_async_from_sync(runtime.connect)\n    initialize_runtime(runtime, instance)\n\n    instruction = get_instruction(instance, metadata)\n\n    state = run_controller(\n        config=config,\n        task_str=instruction,\n        runtime=runtime,\n        fake_user_response_fn=your_user_response_function,\n    )\n\n    # Evaluate the agent's actions\n    evaluation_result = await evaluate_agent_actions(runtime, instance)\n\n    return EvalOutput(\n        instance_id=instance.instance_id,\n        instruction=instruction,\n        test_result=evaluation_result,\n        metadata=metadata,\n        history=compatibility_for_eval_history_pairs(state.history),\n        metrics=state.metrics.get() if state.metrics else None,\n        error=state.last_error if state and state.last_error else None,\n    )\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Headless with Docker\nDESCRIPTION: Complete Docker command to run OpenHands in headless mode with proper environment variables, volume mounts, and networking configuration. Includes settings for sandbox runtime, workspace mounting, and API credentials.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/headless-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it \\\n    --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -e SANDBOX_USER_ID=$(id -u) \\\n    -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \\\n    -e LLM_API_KEY=$LLM_API_KEY \\\n    -e LLM_MODEL=$LLM_MODEL \\\n    -e LOG_ALL_EVENTS=true \\\n    -v $WORKSPACE_BASE:/opt/workspace_base \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app-$(date +%Y%m%d%H%M%S) \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.33 \\\n    python -m openhands.core.main -t \"write a bash script that prints hi\"\n```\n\n----------------------------------------\n\nTITLE: Agent Configuration TOML Structure\nDESCRIPTION: Agent configuration section defining LLM integration, action space settings, and microagent usage parameters.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/configuration-options.md#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[agent]\nllm_config = \"your-llm-config-group\"\nfunction_calling = true\nenable_browsing = false\nenable_llm_editor = false\nenable_jupyter = false\nenable_history_truncation = true\nenable_prompt_extensions = true\n```\n\n----------------------------------------\n\nTITLE: Refactoring Go Variables\nDESCRIPTION: An example of renaming single-letter variables in a Go file to more descriptive names. The exact changes would depend on the content of app.go.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_6\n\nLANGUAGE: go\nCODE:\n```\n// Before\nfunc f(x int) int {\n  return x * 2\n}\n\n// After\nfunc double(number int) int {\n  return number * 2\n}\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Evaluation Workflow\nDESCRIPTION: This Python code snippet demonstrates how to run the OpenHands evaluation workflow, preparing the dataset, setting up metadata, and executing the evaluation across multiple instances.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmetadata = make_metadata(llm_config, dataset_name, agent_class, max_iterations, eval_note, eval_output_dir)\noutput_file = os.path.join(metadata.eval_output_dir, 'output.jsonl')\ninstances = prepare_dataset(your_dataset, output_file, eval_n_limit)\n\nawait run_evaluation(\n    instances,\n    metadata,\n    output_file,\n    num_workers,\n    process_instance\n)\n```\n\n----------------------------------------\n\nTITLE: Core Configuration TOML Structure\nDESCRIPTION: Core configuration section containing API keys, workspace settings, debugging options, trajectory management, file store configuration, task management, and sandbox settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/configuration-options.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[core]\ne2b_api_key = \"\"\nmodal_api_token_id = \"\"\nmodal_api_token_secret = \"\"\nworkspace_base = \"./workspace\"\ncache_dir = \"/tmp/cache\"\ndebug = false\ndisable_color = false\nsave_trajectory_path = \"./trajectories\"\nfile_store_path = \"/tmp/file_store\"\nfile_store = \"memory\"\nmax_budget_per_task = 0.0\nmax_iterations = 100\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands CLI in Docker Container\nDESCRIPTION: Docker command to run OpenHands in CLI mode. Mounts necessary volumes, sets environment variables, and configures container networking. Includes sandbox user permissions matching to prevent root-owned files.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/cli-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it \\\n    --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -e SANDBOX_USER_ID=$(id -u) \\\n    -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \\\n    -e LLM_API_KEY=$LLM_API_KEY \\\n    -e LLM_MODEL=$LLM_MODEL \\\n    -v $WORKSPACE_BASE:/opt/workspace_base \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app-$(date +%Y%m%d%H%M%S) \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.33 \\\n    python -m openhands.core.cli\n```\n\n----------------------------------------\n\nTITLE: Modifying Bash Script to Accept Arguments\nDESCRIPTION: An enhanced version of the hello world script that accepts a name as an argument and defaults to 'world' if no argument is provided.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nname=${1:-world}\necho \"hello $name!\"\n```\n\n----------------------------------------\n\nTITLE: Printing User Name with Default in Shell Script\nDESCRIPTION: This shell script prints a greeting using the first command-line argument as the user's name. If no argument is provided, it defaults to 'world'. The script demonstrates basic argument handling and string manipulation in shell scripting.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/cases/hello-name/task.txt#2025-04-23_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\n#!/bin/bash\n\nname=${1:-world}\necho \"Hello, $name!\"\n```\n\n----------------------------------------\n\nTITLE: Defining Multiple Named LLM Configurations in TOML\nDESCRIPTION: Shows how to define a default LLM configuration along with custom named configurations in the config.toml file. Each named configuration inherits from the default and can override specific settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/custom-llm-configs.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Configuração padrão de LLM\n[llm]\nmodel = \"gpt-4\"\napi_key = \"your-api-key\"\ntemperature = 0.0\n\n# Configuração personalizada de LLM para um modelo mais barato\n[llm.gpt3]\nmodel = \"gpt-3.5-turbo\"\napi_key = \"your-api-key\"\ntemperature = 0.2\n\n# Outra configuração personalizada com parâmetros diferentes\n[llm.high-creativity]\nmodel = \"gpt-4\"\napi_key = \"your-api-key\"\ntemperature = 0.8\ntop_p = 0.9\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Locally with Docker\nDESCRIPTION: Docker command to run OpenHands on your local system. The command pulls the OpenHands Docker image, mounts necessary volumes, and exposes port 3000 for accessing the web interface. It also configures environment variables for the sandbox runtime container.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik\n\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -e LOG_ALL_EVENTS=true \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    -p 3000:3000 \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.33\n```\n\n----------------------------------------\n\nTITLE: Importing OpenHands Utilities for Evaluation Workflow\nDESCRIPTION: This Python code snippet shows the necessary imports from OpenHands utilities to create an evaluation workflow, including state management and configuration handling.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport openhands.agenthub\nfrom evaluation.utils.shared import (\n    EvalMetadata,\n    EvalOutput,\n    make_metadata,\n    prepare_dataset,\n    reset_logger_for_multiprocessing,\n    run_evaluation,\n)\nfrom openhands.controller.state.state import State\nfrom openhands.core.config import (\n    AppConfig,\n    SandboxConfig,\n    get_llm_config_arg,\n    parse_arguments,\n)\nfrom openhands.core.logger import openhands_logger as logger\nfrom openhands.core.main import create_runtime, run_controller\nfrom openhands.events.action import CmdRunAction\nfrom openhands.events.observation import CmdOutputObservation, ErrorObservation\nfrom openhands.runtime.runtime import Runtime\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands CLI Mode with Docker\nDESCRIPTION: Docker command to start an interactive OpenHands CLI session. This approach requires setting environment variables for workspace location, LLM model, and API key, and mounts necessary volumes for workspace access and state persistence.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it \\\n    --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -e SANDBOX_USER_ID=$(id -u) \\\n    -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \\\n    -e LLM_API_KEY=$LLM_API_KEY \\\n    -e LLM_MODEL=$LLM_MODEL \\\n    -v $WORKSPACE_BASE:/opt/workspace_base \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app-$(date +%Y%m%d%H%M%S) \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.33 \\\n    python -m openhands.core.cli\n```\n\n----------------------------------------\n\nTITLE: Starting OpenHands CLI with Python\nDESCRIPTION: Command to start an interactive OpenHands session using Python and Poetry. Requires completing development setup and configuring environment variables or config.toml file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/cli-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python -m openhands.core.cli\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Step Method in Python\nDESCRIPTION: Core method that every agent must implement to move forward one step towards its goal. Takes a State object as input and returns an Action. Typically involves sending a prompt to the LLM and parsing the response.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/agenthub/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef step(self, state: \"State\") -> \"Action\"\n```\n\n----------------------------------------\n\nTITLE: Specifying LLM Configuration for Agents in TOML\nDESCRIPTION: Demonstrates how to assign specific LLM configurations to different agents by using the llm_config parameter in the agent configuration section.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/custom-llm-configs.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[agent.RepoExplorerAgent]\n# Usa a configuração mais barata do GPT-3 para este agente\nllm_config = 'gpt3'\n\n[agent.CodeWriterAgent]\n# Usa a configuração de alta criatividade para este agente\nllm_config = 'high-creativity'\n```\n\n----------------------------------------\n\nTITLE: Loading and Using OpenHands Configuration in Python\nDESCRIPTION: Example demonstrating how to load the application configuration using load_app_config() and access various configuration settings for LLM, agent, and sandbox components\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/core/config/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom openhands.core.config import load_app_config\n\n# Load all configuration settings\nconfig = load_app_config()\n\n# Now you can access your configuration\nllm_config = config.get_llm_config()\nagent_config = config.get_agent_config()\nsandbox_config = config.sandbox\n\n# Use the configuration in your application\nprint(f\"Using LLM model: {llm_config.model}\")\nprint(f\"Agent memory enabled: {agent_config.memory_enabled}\")\nprint(f\"Sandbox timeout: {sandbox_config.timeout}\")\n```\n\n----------------------------------------\n\nTITLE: Running Python Code in CodeActAgent\nDESCRIPTION: This snippet shows how the CodeActAgent can execute Python code using an interactive Python interpreter, simulated through bash commands.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/agents.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nExecute any valid `Python` code with [an interactive Python interpreter](https://ipython.org/). This is simulated through `bash` command, see plugin system below for more details.\n```\n\n----------------------------------------\n\nTITLE: Cost Optimization Example with Multiple LLM Configurations\nDESCRIPTION: Practical example showing how to optimize costs by using different LLM configurations for various tasks like repository exploration and code generation.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/custom-llm-configs.md#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n# Default configuration using GPT-4 for high-quality responses\n[llm]\nmodel = \"gpt-4\"\napi_key = \"your-api-key\"\ntemperature = 0.0\n\n# Cheaper configuration for repository exploration\n[llm.repo-explorer]\nmodel = \"gpt-3.5-turbo\"\ntemperature = 0.2\n\n# Configuration for code generation\n[llm.code-gen]\nmodel = \"gpt-4\"\ntemperature = 0.0\nmax_output_tokens = 2000\n\n[agent.RepoExplorerAgent]\nllm_config = 'repo-explorer'\n\n[agent.CodeWriterAgent]\nllm_config = 'code-gen'\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Docker Image for OpenHands with Ruby\nDESCRIPTION: This Dockerfile extends the default OpenHands image to include Ruby installation. It demonstrates how to add additional software to the sandbox environment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_0\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM nikolaik/python-nodejs:python3.12-nodejs22\n\n# Instalar pacotes necessários\nRUN apt-get update && apt-get install -y ruby\n```\n\n----------------------------------------\n\nTITLE: Installing Docker on Debian/Ubuntu Systems\nDESCRIPTION: A series of bash commands to install Docker on Debian/Ubuntu systems. It includes updating package index, installing prerequisites, adding Docker's GPG key, setting up the repository, and installing Docker Engine.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/docker.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Update package index\nsudo apt-get update\n\n# Install prerequisites\nsudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release\n\n# Add Docker's official GPG key\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\n# Set up the stable repository\necho \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\n# Update package index again\nsudo apt-get update\n\n# Install Docker Engine\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io\n```\n\n----------------------------------------\n\nTITLE: Defining OpenHands Message Class Structure\nDESCRIPTION: Pydantic model definition for the Message class that supports rich content including text, images, and tool calls. Includes fields for role, content, and various feature flags.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/core/message_format.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Message(BaseModel):\n    role: Literal['user', 'system', 'assistant', 'tool']\n    content: list[TextContent | ImageContent] = Field(default_factory=list)\n    cache_enabled: bool = False\n    vision_enabled: bool = False\n    condensable: bool = True\n    function_calling_enabled: bool = False\n    tool_calls: list[ChatCompletionMessageToolCall] | None = None\n    tool_call_id: str | None = None\n    name: str | None = None\n    event_id: int = -1\n```\n\n----------------------------------------\n\nTITLE: Running Test Generation Inference\nDESCRIPTION: Script command for generating tests using the specified model configuration and parameters. Includes example usage with GPT-4 model.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/testgeneval/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit] [max_iter] [num_workers] [dataset] [dataset_split]\n\n# Example\n./evaluation/benchmarks/testgeneval/scripts/run_infer.sh llm.eval_gpt4_1106_preview HEAD CodeActAgent 100 30 1 kjain14/testgenevallite test\n```\n\n----------------------------------------\n\nTITLE: Définition de configurations LLM personnalisées en TOML\nDESCRIPTION: Exemple de configuration dans config.toml montrant comment définir une configuration LLM par défaut et des configurations personnalisées avec différents modèles et paramètres.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/llms/custom-llm-configs.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Configuration LLM par défaut\n[llm]\nmodel = \"gpt-4\"\napi_key = \"votre-clé-api\"\ntemperature = 0.0\n\n# Configuration LLM personnalisée pour un modèle moins coûteux\n[llm.gpt3]\nmodel = \"gpt-3.5-turbo\"\napi_key = \"votre-clé-api\"\ntemperature = 0.2\n\n# Une autre configuration personnalisée avec des paramètres différents\n[llm.haute-creativite]\nmodel = \"gpt-4\"\napi_key = \"votre-clé-api\"\ntemperature = 0.8\ntop_p = 0.9\n```\n\n----------------------------------------\n\nTITLE: Building Custom Docker Image for OpenHands\nDESCRIPTION: This bash command builds a custom Docker image named 'custom-image' from the Dockerfile in the current directory. It's used to create a personalized sandbox environment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t custom-image .\n```\n\n----------------------------------------\n\nTITLE: Defining Base Integration Test Classes in Python\nDESCRIPTION: Core classes for integration testing including TestResult model and abstract BaseIntegrationTest class that defines the structure for all test implementations. Tests must implement initialize_runtime and verify_result methods.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/integration_tests/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass TestResult(BaseModel):\n    success: bool\n    reason: str | None = None\n\n\nclass BaseIntegrationTest(ABC):\n    \"\"\"Base class for integration tests.\"\"\"\n\n    INSTRUCTION: str\n\n    @classmethod\n    @abstractmethod\n    def initialize_runtime(cls, runtime: Runtime) -> None:\n        \"\"\"Initialize the runtime for the test to run.\"\"\"\n        pass\n\n    @classmethod\n    @abstractmethod\n    def verify_result(cls, runtime: Runtime, histories: list[Event]) -> TestResult:\n        \"\"\"Verify the result of the test.\n\n        This method will be called after the agent performs the task on the runtime.\n        \"\"\"\n        pass\n```\n\n----------------------------------------\n\nTITLE: Task Definition in YAML for Test Fixing Automation\nDESCRIPTION: YAML configuration that defines a CodeActAgent task for automated test fixing. Specifies required inputs including branch name and test command, with optional parameters for targeting specific functions and files.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/tasks/get_test_to_pass.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: get_test_to_pass\ntype: task\nversion: 1.0.0\nauthor: openhands\nagent: CodeActAgent\ninputs:\n  - name: BRANCH_NAME\n    description: \"Branch for the agent to work on\"\n    required: true\n  - name: TEST_COMMAND_TO_RUN\n    description: \"The test command you want the agent to work on. For example, `pytest tests/unit/test_bash_parsing.py`\"\n    required: true\n  - name: FUNCTION_TO_FIX\n    description: \"The name of function to fix\"\n    required: false\n  - name: FILE_FOR_FUNCTION\n    description: \"The path of the file that contains the function\"\n    required: false\n```\n\n----------------------------------------\n\nTITLE: Memory Components Documentation\nDESCRIPTION: Documentation of two core memory management components - Short Term History handles event stream filtering and context injection, while Memory Condenser manages summarization of conversation chunks to optimize memory usage.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/memory/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Memory Component\n\n- Short Term History\n- Memory Condenser\n\n## Short Term History\n- Short term history filters the event stream and computes the messages that are injected into the context\n- It filters out certain events of no interest for the Agent, such as AgentChangeStateObservation or NullAction/NullObservation\n- When the context window or the token limit set by the user is exceeded, history starts condensing: chunks of messages into summaries.\n- Each summary is then injected into the context, in the place of the respective chunk it summarizes\n\n## Memory Condenser\n- Memory condenser is responsible for summarizing the chunks of events\n- It summarizes the earlier events first\n- It starts with the earliest agent actions and observations between two user messages\n- Then it does the same for later chunks of events between user messages\n- If there are no more agent events, it summarizes the user messages, this time one by one, if they're large enough and not immediately after an AgentFinishAction event (we assume those are tasks, potentially important)\n- Summaries are retrieved from the LLM as AgentSummarizeAction, and are saved in State.\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Model Settings\nDESCRIPTION: Example showing the format for specifying custom OpenAI models in the configuration, particularly when using non-standard or proxy models.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/openai-llms.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nopenai/<model-name> like `openai/gpt-4o`\n```\n\n----------------------------------------\n\nTITLE: Configuring LLMs for OpenHands Evaluation in TOML\nDESCRIPTION: Example TOML configuration file for defining and using multiple LLMs in OpenHands evaluation. It includes settings for API keys, model names, and custom parameters for different LLM configurations.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/README.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[llm]\n# IMPORTANT: add your API key here, and set the model to the one you want to evaluate\nmodel = \"gpt-4o-2024-05-13\"\napi_key = \"sk-XXX\"\n\n[llm.eval_gpt4_1106_preview_llm]\nmodel = \"gpt-4-1106-preview\"\napi_key = \"XXX\"\ntemperature = 0.0\n\n[llm.eval_some_openai_compatible_model_llm]\nmodel = \"openai/MODEL_NAME\"\nbase_url = \"https://OPENAI_COMPATIBLE_URL/v1\"\napi_key = \"XXX\"\ntemperature = 0.0\n```\n\n----------------------------------------\n\nTITLE: Defining Multiple LLM Configurations in TOML\nDESCRIPTION: Example showing how to define multiple LLM configurations in config.toml, including default settings and custom configurations with different parameters for various use cases.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/custom-llm-configs.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Default LLM configuration\n[llm]\nmodel = \"gpt-4\"\napi_key = \"your-api-key\"\ntemperature = 0.0\n\n# Custom LLM configuration for a cheaper model\n[llm.gpt3]\nmodel = \"gpt-3.5-turbo\"\napi_key = \"your-api-key\"\ntemperature = 0.2\n\n# Another custom configuration with different parameters\n[llm.high-creativity]\nmodel = \"gpt-4\"\napi_key = \"your-api-key\"\ntemperature = 0.8\ntop_p = 0.9\n```\n\n----------------------------------------\n\nTITLE: Runtime Configuration in TOML\nDESCRIPTION: Example TOML configuration for specifying a custom Runtime implementation in OpenHands. This allows users to extend the base Runtime class with their own implementation by adding it to the classpath.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/README.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nruntime = \"app.my.CustomRuntime\"\n```\n\n----------------------------------------\n\nTITLE: Using Ruby-specific Base Image for OpenHands\nDESCRIPTION: This Dockerfile shows an alternative approach to customizing the OpenHands sandbox by using a Ruby-specific base image instead of extending the default one.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM ruby:latest\n```\n\n----------------------------------------\n\nTITLE: Defining PR Comments Handler Task in YAML\nDESCRIPTION: Task configuration that specifies inputs and parameters for addressing pull request comments. Requires PR URL and branch name as mandatory inputs for the CodeActAgent to process.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/tasks/address_pr_comments.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: address_pr_comments\ntype: task\nversion: 1.0.0\nauthor: openhands\nagent: CodeActAgent\ninputs:\n  - name: PR_URL\n    description: \"URL of the pull request\"\n    required: true\n  - name: BRANCH_NAME\n    description: \"Branch name corresponds to the pull request\"\n    required: true\n```\n\n----------------------------------------\n\nTITLE: Creating a Hello World Bash Script\nDESCRIPTION: A simple bash script that prints 'hello world!' to the console.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\necho \"hello world!\"\n```\n\n----------------------------------------\n\nTITLE: Creating React Component for Widget List\nDESCRIPTION: A new React component that displays a list of Widgets. It assumes the existence of a Widget component and would be placed in the components directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nimport React from 'react';\nimport Widget from './Widget';\n\nconst WidgetList = ({ widgets }) => (\n  <div>\n    {widgets.map(widget => (\n      <Widget key={widget.id} {...widget} />\n    ))}\n  </div>\n);\n\nexport default WidgetList;\n```\n\n----------------------------------------\n\nTITLE: Example Inference Command for OpenHands Browsing Delegation Evaluation\nDESCRIPTION: An example bash command demonstrating how to run the inference script with specific parameters. It uses GPT-4 Turbo (1106 preview) as the model, the latest git version (HEAD), CodeActAgent as the agent, and limits evaluation to 300 instances.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/browsing_delegation/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/swe_bench/scripts/run_infer.sh llm.eval_gpt4_1106_preview_llm HEAD CodeActAgent 300\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM API Retry Settings in TOML\nDESCRIPTION: This TOML configuration snippet demonstrates how to set custom retry parameters for LLM API calls in OpenHands development mode. It includes settings for the number of retries, minimum and maximum wait times, and the retry multiplier.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/llms.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[llm]\nnum_retries = 4\nretry_min_wait = 5\nretry_max_wait = 30\nretry_multiplier = 2\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple LLMs in TOML for OpenHands Evaluation\nDESCRIPTION: This TOML configuration defines multiple LLM models for use in OpenHands evaluations, including API keys and model-specific settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[llm]\n# IMPORTANT: add your API key here, and set the model to the one you want to evaluate\nmodel = \"claude-3-5-sonnet-20241022\"\napi_key = \"sk-XXX\"\n\n[llm.eval_gpt4_1106_preview_llm]\nmodel = \"gpt-4-1106-preview\"\napi_key = \"XXX\"\ntemperature = 0.0\n\n[llm.eval_some_openai_compatible_model_llm]\nmodel = \"openai/MODEL_NAME\"\nbase_url = \"https://OPENAI_COMPATIBLE_URL/v1\"\napi_key = \"XXX\"\ntemperature = 0.0\n```\n\n----------------------------------------\n\nTITLE: Visualizing OpenHands Runtime Architecture with Mermaid\nDESCRIPTION: A flowchart diagram showing the architecture and interaction flow between different components of the OpenHands Runtime system, including the custom Docker image, backend, action executor, and various initialized components.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/architecture/runtime.md#2025-04-23_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    A[User-provided Custom Docker Image] --> B[OpenHands Backend]\n    B -->|Builds| C[OH Runtime Image]\n    C -->|Launches| D[Action Executor]\n    D -->|Initializes| E[Browser]\n    D -->|Initializes| F[Bash Shell]\n    D -->|Initializes| G[Plugins]\n    G -->|Initializes| L[Jupyter Server]\n\n    B -->|Spawn| H[Agent]\n    B -->|Spawn| I[EventStream]\n    I <--->|Execute Action to\n    Get Observation\n    via REST API\n    | D\n\n    H -->|Generate Action| I\n    I -->|Obtain Observation| H\n\n    subgraph \"Docker Container\"\n    D\n    E\n    F\n    G\n    L\n    end\n```\n\n----------------------------------------\n\nTITLE: LLM Configuration TOML Structure\nDESCRIPTION: LLM configuration section specifying API settings, model selection, message handling, and retry parameters for language model integration.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/configuration-options.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[llm]\naws_access_key_id = \"\"\naws_region_name = \"\"\naws_secret_access_key = \"\"\napi_key = \"\"\nbase_url = \"\"\nmodel = \"claude-3-5-sonnet-20241022\"\nnum_retries = 8\nretry_max_wait = 120\nmax_message_chars = 30000\n```\n\n----------------------------------------\n\nTITLE: Advanced Sandbox Configuration Options in OpenHands config.toml\nDESCRIPTION: This TOML configuration demonstrates additional options for customizing the OpenHands sandbox, including specifying extra dependencies, environment variables, and platform architecture.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[core]\n# Install additional dependencies when the runtime is built\n# Can contain any valid shell commands\n# If you need the path to the Python interpreter in any of these commands, you can use the $OH_INTERPRETER_PATH variable\nruntime_extra_deps = \"\"\"\npip install numpy pandas\napt-get update && apt-get install -y ffmpeg\n\"\"\"\n\n# Set environment variables for the runtime\n# Useful for configuration that needs to be available at runtime\nruntime_startup_env_vars = { DATABASE_URL = \"postgresql://user:pass@localhost/db\" }\n\n# Specify platform for multi-architecture builds (e.g., \"linux/amd64\" or \"linux/arm64\")\nplatform = \"linux/amd64\"\n```\n\n----------------------------------------\n\nTITLE: Creating Configuration for OpenHands Evaluation\nDESCRIPTION: This Python function creates an AppConfig object for OpenHands evaluation, setting up the agent, runtime, and sandbox configurations based on the provided metadata.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef get_config(instance: pd.Series, metadata: EvalMetadata) -> AppConfig:\n    config = AppConfig(\n        default_agent=metadata.agent_class,\n        runtime='docker',\n        max_iterations=metadata.max_iterations,\n        sandbox=SandboxConfig(\n            base_container_image='your_container_image',\n            enable_auto_lint=True,\n            timeout=300,\n        ),\n    )\n    config.set_llm_config(metadata.llm_config)\n    return config\n```\n\n----------------------------------------\n\nTITLE: Adding New Route in Express.js\nDESCRIPTION: Modifies an existing Express.js routes file to add a new route that returns a list of all tasks. The exact implementation would depend on how tasks are stored and retrieved in the application.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nrouter.get('/tasks', (req, res) => {\n  // Logic to fetch all tasks\n  res.json(tasks);\n});\n```\n\n----------------------------------------\n\nTITLE: Executing Logic Programs with LogicInferenceEngine in Python\nDESCRIPTION: This code snippet demonstrates how to instantiate a LogicInferenceEngine, execute a logic program, and retrieve the results. It adds the workspace to the system path, creates an engine instance, and uses the safe_execute_program method to process logic programs.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/logic_reasoning/instruction.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport sys\nsys.path.append('/workspace')\nengine = LogicInferenceEngine()\nanswer, flag, error_message = engine.safe_execute_program(logic_programs)\n```\n\n----------------------------------------\n\nTITLE: Example EDA Evaluation Command\nDESCRIPTION: This is an example command demonstrating how to run the EDA evaluation with specific parameters. It uses GPT-4 model configuration, OpenHands version 0.6.2, CodeActAgent, and evaluates on the 'things' dataset.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/EDA/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/EDA/scripts/run_infer.sh eval_gpt4o_2024_05_13 0.6.2 CodeActAgent things\n```\n\n----------------------------------------\n\nTITLE: Exemple d'optimisation des coûts avec configurations LLM personnalisées\nDESCRIPTION: Configuration complète montrant comment utiliser différents modèles pour différentes tâches afin d'optimiser les coûts, avec GPT-3.5 pour l'exploration de dépôt et GPT-4 pour la génération de code.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/llms/custom-llm-configs.md#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n# Configuration par défaut utilisant GPT-4 pour des réponses de haute qualité\n[llm]\nmodel = \"gpt-4\"\napi_key = \"votre-clé-api\"\ntemperature = 0.0\n\n# Configuration moins coûteuse pour l'exploration de dépôt\n[llm.repo-explorer]\nmodel = \"gpt-3.5-turbo\"\ntemperature = 0.2\n\n# Configuration pour la génération de code\n[llm.code-gen]\nmodel = \"gpt-4\"\ntemperature = 0.0\nmax_output_tokens = 2000\n\n[agent.RepoExplorerAgent]\nllm_config = 'repo-explorer'\n\n[agent.CodeWriterAgent]\nllm_config = 'code-gen'\n```\n\n----------------------------------------\n\nTITLE: Configuring YAML Frontmatter for OpenHands Microagent\nDESCRIPTION: YAML configuration block defining the metadata for a microagent, including name, type, version, agent type, and trigger words that activate the microagent.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/add_agent.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\nname: add_agent\ntype: knowledge\nversion: 1.0.0\nagent: CodeActAgent\ntriggers:\n  - new agent\n  - new microagent\n  - create agent\n  - create an agent\n  - create microagent\n  - create a microagent\n  - add agent\n  - add an agent\n  - add microagent\n  - add a microagent\n  - microagent template\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring VSCode Launch for OpenHands Debugging\nDESCRIPTION: This launch configuration allows debugging of the agent, controller, and server elements of OpenHands, excluding the sandbox. It includes settings for both the CLI and WebApp modules.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/debugging.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"OpenHands CLI\",\n            \"type\": \"debugpy\",\n            \"request\": \"launch\",\n            \"module\": \"openhands.core.cli\",\n            \"justMyCode\": false\n        },\n        {\n            \"name\": \"OpenHands WebApp\",\n            \"type\": \"debugpy\",\n            \"request\": \"launch\",\n            \"module\": \"uvicorn\",\n            \"args\": [\n                \"openhands.server.listen:app\",\n                \"--reload\",\n                \"--reload-exclude\",\n                \"${workspaceFolder}/workspace\",\n                \"--port\",\n                \"3000\"\n            ],\n            \"justMyCode\": false\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent in TOML for OpenHands (0.8.0+)\nDESCRIPTION: Updated agent configuration structure in config.toml for OpenHands version 0.8.0 and later. The default agent is now specified in the 'core' group, and agent-specific configurations can be added as subgroups.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/upgrade-guide.md#2025-04-23_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[core]\n# other configurations\ndefault_agent='CodeActAgent'\n\n[agent]\nllm_config='llm'\nmemory_max_threads=2\n\n[agent.CodeActAgent]\nllm_config='gpt-4o'\n```\n\n----------------------------------------\n\nTITLE: Configuring Agents with Custom LLM Settings\nDESCRIPTION: Demonstrates how to assign specific LLM configurations to different agents using the llm_config parameter in the agent's configuration section.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/custom-llm-configs.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[agent.RepoExplorerAgent]\n# Use the cheaper GPT-3 configuration for this agent\nllm_config = 'gpt3'\n\n[agent.CodeWriterAgent]\n# Use the high creativity configuration for this agent\nllm_config = 'high-creativity'\n```\n\n----------------------------------------\n\nTITLE: Criando Configuração para Avaliação em OpenHands\nDESCRIPTION: Função para criar uma configuração de aplicativo para avaliação no OpenHands, especificando o agente, runtime, número máximo de iterações e configurações da sandbox.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef get_config(instance: pd.Series, metadata: EvalMetadata) -> AppConfig:\n    config = AppConfig(\n        default_agent=metadata.agent_class,\n        runtime='docker',\n        max_iterations=metadata.max_iterations,\n        sandbox=SandboxConfig(\n            base_container_image='your_container_image',\n            enable_auto_lint=True,\n            timeout=300,\n        ),\n    )\n    config.set_llm_config(metadata.llm_config)\n    return config\n```\n\n----------------------------------------\n\nTITLE: Creating GitHub Action for Linting\nDESCRIPTION: A GitHub Actions workflow file that sets up a linting job for the repository. The specific linter and commands would depend on the project's language and structure.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nname: Lint\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Run linter\n        run: |\n```\n\n----------------------------------------\n\nTITLE: OpenHands Pull Request Commands\nDESCRIPTION: Instructions for interacting with OpenHands in pull requests using the @openhands mention. Shows how to request various types of assistance.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/cloud/cloud-github-resolver.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nTo get OpenHands to work on pull requests, use `@openhands` in top level or inline comments to:\n     - Ask questions\n     - Request updates\n     - Get code explanations\n```\n\n----------------------------------------\n\nTITLE: Running Commit0 Inference with Limited Instances\nDESCRIPTION: This bash command shows how to run Commit0 inference on a limited number of instances (10 in this case) using specific model config and agent settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/commit0/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/commit0/scripts/run_infer.sh lite llm.eval_sonnet HEAD CodeActAgent 10 30 1 wentingzhao/commit0_combined test\n```\n\n----------------------------------------\n\nTITLE: Draft Editor Configuration Example in TOML\nDESCRIPTION: Demonstrates how to set up a draft editor configuration using the reserved name 'draft_editor'. This configuration is used for preliminary code editing and refinement tasks.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/custom-llm-configs.md#2025-04-23_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[llm.draft_editor]\nmodel = \"gpt-4\"\ntemperature = 0.2\ntop_p = 0.95\npresence_penalty = 0.0\nfrequency_penalty = 0.0\n```\n\n----------------------------------------\n\nTITLE: Serving OpenHands LM 32B with vLLM\nDESCRIPTION: This command starts a vLLM server for the OpenHands LM 32B model. It configures the host, port, API key, tensor parallelism, and enables prefix caching.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/local-llms.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nvllm serve all-hands/openhands-lm-32b-v0.1 \\\n    --host 0.0.0.0 --port 8000 \\\n    --api-key mykey \\\n    --tensor-parallel-size 2 \\\n    --served-model-name openhands-lm-32b-v0.1\n    --enable-prefix-caching\n```\n\n----------------------------------------\n\nTITLE: Implementing New Tool Definition in Python using ChatCompletionToolParam\nDESCRIPTION: Example code showing how to define a new tool for the CodeAct agent using litellm's ChatCompletionToolParam. Demonstrates parameter specification, description formatting, and required field configuration.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/agenthub/codeact_agent/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nMyTool = ChatCompletionToolParam(\n    type='function',\n    function=ChatCompletionToolParamFunctionChunk(\n        name='my_tool',\n        description='Description of what the tool does and how to use it',\n        parameters={\n            'type': 'object',\n            'properties': {\n                'param1': {\n                    'type': 'string',\n                    'description': 'Description of parameter 1',\n                },\n                'param2': {\n                    'type': 'integer',\n                    'description': 'Description of parameter 2',\n                },\n            },\n            'required': ['param1'],  # List required parameters here\n        },\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Executando OpenHands via Linha de Comando\nDESCRIPTION: Comandos para executar o OpenHands a partir da linha de comando, especificando parâmetros como número máximo de iterações, descrição da tarefa, classe do agente e configuração do LLM.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python ./openhands/core/main.py \\\n        -i <max_iterations> \\\n        -t \"<task_description>\" \\\n        -c <agent_class> \\\n        -l <llm_config>\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python ./openhands/core/main.py \\\n        -i 10 \\\n        -t \"Write me a bash script that prints hello world.\" \\\n        -c CodeActAgent \\\n        -l llm\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Runtime in TOML Configuration File\nDESCRIPTION: Demonstrates how to configure the Local Runtime using the config.toml file. Sets the runtime type and workspace base directory in the core configuration section.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/local.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[core]\nruntime = \"local\"\nworkspace_base = \"/path/to/your/workspace\"\n```\n\n----------------------------------------\n\nTITLE: Example ToolQA Inference Command\nDESCRIPTION: Practical example showing how to run 10 evaluation instances using the llm config and CodeActAgent on the coffee dataset with easy difficulty level.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/toolqa/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbash evaluation/benchmarks/toolqa/scripts/run_infer.sh llm CodeActAgent 10 coffee easy\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands with Custom Docker Image\nDESCRIPTION: This Docker run command demonstrates how to start OpenHands using a custom sandbox image. It sets the SANDBOX_BASE_CONTAINER_IMAGE environment variable to specify the custom image.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_BASE_CONTAINER_IMAGE=custom-image \\\n    ...\n```\n\n----------------------------------------\n\nTITLE: Running Docker Development Environment for OpenHands\nDESCRIPTION: Commands to start the Docker development environment for OpenHands. It includes both the make command and the direct script execution method.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/dev/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmake docker-dev\n# same as:\ncd ./containers/dev\n./dev.sh\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenRouter in OpenHands UI\nDESCRIPTION: Steps to configure OpenRouter as the LLM provider in OpenHands settings. It includes setting the LLM Provider, LLM Model, and API Key. For custom models, it explains how to use the Advanced options.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/openrouter.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* `LLM Provider` to `OpenRouter`\n* `LLM Model` to the model you will be using.\n[Visit here to see a full list of OpenRouter models](https://openrouter.ai/models).\nIf the model is not in the list, toggle `Advanced` options, and enter it in `Custom Model` (e.g. openrouter/<model-name> like `openrouter/anthropic/claude-3.5-sonnet`).\n* `API Key` to your OpenRouter API key.\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Headless with Python\nDESCRIPTION: Command to execute OpenHands in headless mode using Python and Poetry package manager. Requires development setup and proper configuration via environment variables or config.toml file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/headless-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python -m openhands.core.main -t \"write a bash script that prints hi\"\n```\n\n----------------------------------------\n\nTITLE: Implementing User Response Function for SWE-Bench\nDESCRIPTION: A function that generates responses for agent interactions during SWE-Bench evaluation. It maintains a consistent message structure, tracks the number of user interactions, and provides an exit option after multiple attempts. The function takes an optional State parameter and returns a formatted string response.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef codeact_user_response(state: State | None) -> str:\n    msg = (\n        'Please continue working on the task on whatever approach you think is suitable.\\n'\n        'If you think you have solved the task, please first send your answer to user through message and then <execute_bash> exit </execute_bash>.\\n'\n        'IMPORTANT: YOU SHOULD NEVER ASK FOR HUMAN HELP.\\n'\n    )\n\n    if state and state.history:\n        # check if the agent has tried to talk to the user 3 times, if so, let the agent know it can give up\n        user_msgs = [\n            event\n            for event in state.history\n            if isinstance(event, MessageAction) and event.source == 'user'\n        ]\n        if len(user_msgs) >= 2:\n            # let the agent know that it can give up when it has tried 3 times\n            return (\n                msg\n                + 'If you want to give up, run: <execute_bash> exit </execute_bash>.\\n'\n            )\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Running ML-Bench Inference Command\nDESCRIPTION: Command for executing ML-Bench evaluation with configurable parameters including model config, git version, split type, agent, and evaluation limit.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/ml_bench/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/ml_bench/scripts/run_infer.sh [model_config] [git-version] [split] [agent] [eval_limit]\n```\n\n----------------------------------------\n\nTITLE: Example MINT Benchmark Evaluation Command in Bash\nDESCRIPTION: Specific example of running the MINT benchmark evaluation script. This command evaluates the GPT-4 model (version 1106 preview) on the GSM8K subset of MINT, using OpenHands version 0.6.2, and limiting the evaluation to the first 3 instances.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/mint/scripts/run_infer.sh eval_gpt4_1106_preview 0.6.2 gsm8k 3\n```\n\n----------------------------------------\n\nTITLE: Running Inference on Commit0 Instances with Bash Script\nDESCRIPTION: This bash command runs the inference script for Commit0 evaluation. It allows specifying various parameters like dataset split, model config, agent type, and evaluation limits.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/commit0/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/commit0/scripts/run_infer.sh [repo_split] [model_config] [git-version] [agent] [eval_limit] [max_iter] [num_workers] [dataset] [dataset_split]\n```\n\n----------------------------------------\n\nTITLE: Resolving Single Issue\nDESCRIPTION: Commands to resolve a specific issue in a repository using the OpenHands resolver module, with example usage.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m openhands.resolver.resolve_issue --selected-repo [OWNER]/[REPO] --issue-number [NUMBER]\n```\n\n----------------------------------------\n\nTITLE: Implementing User Response Function for SWE-Bench Evaluation in Python\nDESCRIPTION: This function handles agent interactions during SWE-Bench evaluation. It provides standard messages, tracks communication attempts, and offers an option to abandon after multiple attempts. It ensures consistent behavior across evaluation runs and prevents the agent from getting stuck waiting for human input.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef codeact_user_response(state: State | None) -> str:\n    msg = (\n        'Veuillez continuer à travailler sur la tâche avec l\\'approche que vous jugez appropriée.\\n'\n        'Si vous pensez avoir résolu la tâche, veuillez d\\'abord envoyer votre réponse à l\\'utilisateur via un message, puis <execute_bash> exit </execute_bash>.\\n'\n        'IMPORTANT : VOUS NE DEVEZ JAMAIS DEMANDER DE L\\'AIDE HUMAINE.\\n'\n    )\n\n    if state and state.history:\n        # vérifier si l'agent a essayé de parler à l'utilisateur 3 fois, si oui, faire savoir à l'agent qu'il peut abandonner\n        user_msgs = [\n            event\n            for event in state.history\n            if isinstance(event, MessageAction) and event.source == 'user'\n        ]\n        if len(user_msgs) >= 2:\n            # faire savoir à l'agent qu'il peut abandonner quand il a essayé 3 fois\n            return (\n                msg\n                + 'Si vous voulez abandonner, exécutez : <execute_bash> exit </execute_bash>.\\n'\n            )\n    return msg\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenHands Configuration\nDESCRIPTION: Example showing how to set environment variables for configuring different aspects of OpenHands, including LLM settings, agent memory, and sandbox timeout\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/core/config/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport LLM_API_KEY='your_api_key_here'\nexport LLM_MODEL='gpt-4'\nexport AGENT_MEMORY_ENABLED='true'\nexport SANDBOX_TIMEOUT='300'\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Sandbox Image in OpenHands config.toml\nDESCRIPTION: This TOML configuration snippet shows how to specify a custom base container image in the OpenHands config.toml file for the development workflow.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[core]\n...\n[sandbox]\nbase_container_image=\"custom-image\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up Repository Dependencies with OpenHands Setup Script\nDESCRIPTION: Example setup script (.openhands/setup.sh) that runs when OpenHands starts working with a repository. The script sets environment variables, updates system packages, and installs project dependencies.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/customization/repository.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\nexport MY_ENV_VAR=\"my value\"\nsudo apt-get update\nsudo apt-get install -y lsof\ncd frontend && npm install ; cd ..\n```\n\n----------------------------------------\n\nTITLE: Defining SQL Tables for California Schools Database\nDESCRIPTION: Creates tables for FRPM data, SAT scores, and school information with their respective fields and constraints. The tables are interconnected using foreign key relationships.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE frpm\n(\n    CDSCode                                       TEXT not null\n        primary key,\n    `Academic Year`                               TEXT  null,\n    `County Code`                                 TEXT  null,\n    `District Code`                               INTEGER         null,\n    `School Code`                                 TEXT  null,\n    `County Name`                                 TEXT null,\n    `District Name`                               TEXT null,\n    `School Name`                                 TEXT null,\n    `District Type`                               TEXT null,\n    `School Type`                                 TEXT null,\n    `Educational Option Type`                     TEXT null,\n    `NSLP Provision Status`                       TEXT null,\n    `Charter School (Y/N)`                        INTEGER    null,\n    `Charter School Number`                       TEXT  null,\n    `Charter Funding Type`                        TEXT null,\n    IRC                                           INTEGER    null,\n    `Low Grade`                                   TEXT  null,\n    `High Grade`                                  TEXT null,\n    `Enrollment (K-12)`                           REAL      null,\n    `Free Meal Count (K-12)`                      REAL       null,\n    `Percent (%) Eligible Free (K-12)`            REAL       null,\n    `FRPM Count (K-12)`                           REAL       null,\n    `Percent (%) Eligible FRPM (K-12)`            REAL       null,\n    `Enrollment (Ages 5-17)`                      REAL       null,\n    `Free Meal Count (Ages 5-17)`                 REAL       null,\n    `Percent (%) Eligible Free (Ages 5-17)`       REAL       null,\n    `FRPM Count (Ages 5-17)`                      REAL       null,\n    `Percent (%) Eligible FRPM (Ages 5-17)`       REAL       null,\n    `2013-14 CALPADS Fall 1 Certification Status` INTEGER    null,\n    foreign key (CDSCode) references schools (CDSCode)\n);\n\nCREATE TABLE satscores\n(\n    cds         TEXT not null\n        primary key,\n    rtype       TEXT  not null,\n    sname       TEXT null,\n    dname       TEXT null,\n    cname       TEXT null,\n    enroll12    INTEGER         not null,\n    NumTstTakr  INTEGER          not null,\n    AvgScrRead  INTEGER          null,\n    AvgScrMath  INTEGER          null,\n    AvgScrWrite INTEGER          null,\n    NumGE1500   INTEGER          null,\n--     PctGE1500   double      null,\n        foreign key (cds) references schools (CDSCode)\n);\n\nCREATE TABLE schools\n(\n    CDSCode     TEXT not null\n        primary key,\n    NCESDist    TEXT  null,\n    NCESSchool  TEXT  null,\n    StatusType  TEXT  not null,\n    County      TEXT not null,\n    District    TEXT not null,\n    School      TEXT null,\n    Street      TEXT null,\n    StreetAbr   TEXT null,\n    City        TEXT null,\n    Zip         TEXT null,\n    State       TEXT  null,\n    MailStreet  TEXT null,\n    MailStrAbr  TEXT null,\n    MailCity    TEXT null,\n    MailZip     TEXT null,\n    MailState   TEXT  null,\n    Phone       TEXT null,\n    Ext         TEXT  null,\n    Website     TEXT null,\n    OpenDate    DATE        null,\n    ClosedDate  DATE        null,\n    Charter     INTEGER    null,\n    CharterNum  TEXT  null,\n    FundingType TEXT null,\n    DOC         TEXT  not null,\n    DOCType     TEXT not null,\n    SOC         TEXT  null,\n    SOCType     TEXT null,\n    EdOpsCode   TEXT  null,\n    EdOpsName   TEXT null,\n    EILCode     TEXT  null,\n    EILName     TEXT null,\n    GSoffered   TEXT null,\n    GSserved    TEXT  null,\n    Virtual     TEXT  null,\n    Magnet      INTEGER   null,\n    Latitude    REAL      null,\n    Longitude   REAL      null,\n    AdmFName1   TEXT null,\n    AdmLName1   TEXT null,\n    AdmEmail1   TEXT null,\n    AdmFName2   TEXT null,\n    AdmLName2   TEXT null,\n    AdmEmail2   TEXT null,\n    AdmFName3   TEXT  null,\n    AdmLName3   TEXT null,\n    AdmEmail3   TEXT null,\n    LastUpdate  DATE        not null\n);\n```\n\n----------------------------------------\n\nTITLE: Example AgentBench Evaluation Command\nDESCRIPTION: Practical example of running AgentBench evaluation with specific parameters using GPT-3.5 Turbo model, HEAD version, CodeActAgent, and single evaluation limit.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/agent_bench/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/agent_bench/scripts/run_infer.sh eval_gpt35_turbo HEAD CodeActAgent 1\n```\n\n----------------------------------------\n\nTITLE: Running SWT-Bench Inference\nDESCRIPTION: Example command for running inference on SWT-Bench Verified dataset using CodeActAgent\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/swe_bench/scripts/run_infer.sh llm.eval_gpt4o-2024-11-20 HEAD CodeActAgent 500 100 1 princeton-nlp/SWE-bench_Verified test 1 swt\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Frontend with Actual Backend (Production Mode)\nDESCRIPTION: Commands to build and run the application with the actual backend, including options for running backend and frontend separately.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/frontend/README.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n# Build the application from the root directory\nmake build\n\n# Start the application\nmake run\n\n# Or to run backend and frontend seperately:\n\n# Start the backend from the root directory\nmake start-backend\n\n# Serve the frontend\nmake start-frontend or\ncd frontend && npm start -- --port 3001\n\n# Start frontend with Mock Service Worker (MSW)\nnpm run dev:mock or npm run dev:mock:saas\n```\n\n----------------------------------------\n\nTITLE: Generating 'Hello, World!' Python Script in OpenHands CLI\nDESCRIPTION: Example of a simple task in OpenHands CLI to generate a Python script that prints 'Hello, World!'. Shows the input command and expected output.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n>> \"Hello, World!\" と出力する Python スクリプトを書いてください\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Hello, World!\")\n```\n\n----------------------------------------\n\nTITLE: Installing Swift Dependencies on Debian\nDESCRIPTION: Commands to install required system dependencies for Swift on Debian 12. This includes development libraries and tools needed for Swift compilation and execution.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/swift-linux.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get update\nsudo apt-get install -y \\\n  binutils-gold \\\n  gcc \\\n  git \\\n  libcurl4-openssl-dev \\\n  libedit-dev \\\n  libicu-dev \\\n  libncurses-dev \\\n  libpython3-dev \\\n  libsqlite3-dev \\\n  libxml2-dev \\\n  pkg-config \\\n  tzdata \\\n  uuid-dev\n```\n\n----------------------------------------\n\nTITLE: Example AiderBench Evaluation Command\nDESCRIPTION: Complete example command for running AiderBench evaluation with specific parameters for GPT-3.5 Turbo model.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/aider_bench/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/aider_bench/scripts/run_infer.sh eval_gpt35_turbo HEAD CodeActAgent 100 1 \"1,3,10\"\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenHands for LM Studio in Development Mode\nDESCRIPTION: TOML configuration for setting up OpenHands to use LM Studio in development mode, specifying the workspace base and LM Studio-specific settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[core]\nworkspace_base=\"./workspace\"\n\n[llm]\nmodel=\"openai/lmstudio\"\nbase_url=\"http://localhost:1234/v1\"\ncustom_llm_provider=\"openai\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Security Settings in TOML\nDESCRIPTION: Configuration settings for enabling security features in config.toml file. Includes confirmation mode toggle and security analyzer selection.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/security/README.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[security]\n# Enable confirmation mode\nconfirmation_mode = true\n# The security analyzer to use\nsecurity_analyzer = \"your-security-analyzer\"\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM API Retry Parameters in OpenHands using TOML\nDESCRIPTION: This configuration snippet demonstrates how to set up API retry parameters for LLM providers in the config.toml file when running OpenHands in development mode. It controls retry behavior when encountering rate limits or connection errors.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/llms/llms.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[llm]\nnum_retries = 8\nretry_min_wait = 15\nretry_max_wait = 120\nretry_multiplier = 2\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Query with Python SQLite Connection\nDESCRIPTION: Python function that establishes a SQLite database connection and executes a SQL query to calculate the maximum ratio of free meal eligible students to total enrollment in Alameda County schools. The script includes a reusable execute_sql function and demonstrates its usage with a specific query.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport sqlite3\n\ndef execute_sql(db_path, sql):\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        cursor.execute(sql)\n        result = cursor.fetchall()\n        return result\n\nif __name__ == '__main__':\n    sql = \"SELECT MAX(`Free Meal Count (K-12)` / `Enrollment (K-12)`) AS highest_eligible_free_rate FROM frpm JOIN schools ON frpm.CDSCode = schools.CDSCode WHERE `County Name` = 'Alameda'\"\n    db_path = \"california_schools/california_schools.sqlite\"\n    print(db_path)\n    result = execute_sql(db_path, sql)\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Generated Patches with RemoteRuntime\nDESCRIPTION: Command to evaluate generated patches using OpenHands Remote Runtime, allowing parallel execution in the cloud.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/swe_bench/scripts/eval_infer_remote.sh [output.jsonl filepath] [num_workers]\n```\n\n----------------------------------------\n\nTITLE: Example Integration Test Execution\nDESCRIPTION: Example command showing how to run integration tests using Claude-35-sonnet model with the CodeActAgent on the HEAD version.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/integration_tests/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/integration_tests/scripts/run_infer.sh llm.claude-35-sonnet-eval HEAD CodeActAgent\n```\n\n----------------------------------------\n\nTITLE: Sandbox Configuration TOML Structure\nDESCRIPTION: Sandbox configuration section controlling execution environment, container settings, networking, and plugin management.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/configuration-options.md#2025-04-23_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[sandbox]\ntimeout = 120\nuser_id = 1000\nbase_container_image = \"nikolaik/python-nodejs:python3.12-nodejs22\"\nuse_host_network = false\nruntime_binding_address = \"0.0.0.0\"\nenable_auto_lint = false\ninitialize_plugins = true\n```\n\n----------------------------------------\n\nTITLE: Draft Editor Configuration Example\nDESCRIPTION: Shows how to configure a draft editor LLM with specific parameters for code editing and refinement tasks.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/custom-llm-configs.md#2025-04-23_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[llm.draft_editor]\nmodel = \"gpt-4\"\ntemperature = 0.2\ntop_p = 0.95\npresence_penalty = 0.0\nfrequency_penalty = 0.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Setting up required environment variables for GitHub/GitLab credentials and LLM configuration. Includes tokens, usernames, and LLM API settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# GitHub credentials\n\nexport GITHUB_TOKEN=\"your-github-token\"\nexport GIT_USERNAME=\"your-github-username\"  # Optional, defaults to token owner\n\n# GitLab credentials if you're using GitLab repo\n\nexport GITLAB_TOKEN=\"your-gitlab-token\"\nexport GIT_USERNAME=\"your-gitlab-username\"  # Optional, defaults to token owner\n\n# LLM configuration\n\nexport LLM_MODEL=\"anthropic/claude-3-5-sonnet-20241022\"  # Recommended\nexport LLM_API_KEY=\"your-llm-api-key\"\nexport LLM_BASE_URL=\"your-api-url\"  # Optional, for API proxies\n```\n\n----------------------------------------\n\nTITLE: Defining Security Analyzer Configuration in Markdown\nDESCRIPTION: Specifies the configuration for setting the security analyzer in OpenHands. It is a string parameter with an empty default value.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/configuration-options.md#2025-04-23_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n### Security Analyzer\n- `security_analyzer`\n  - Type: `str`\n  - Default: `\"\"`\n  - Description: The security analyzer to use\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands with Local Runtime Example\nDESCRIPTION: Shows how to start OpenHands using the Local Runtime in Headless Mode. Sets environment variables and launches the application with a sample task using Poetry.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/local.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Set the runtime type to local\nexport RUNTIME=local\n\n# Optionally set a workspace directory\nexport WORKSPACE_BASE=/path/to/your/project\n\n# Start OpenHands\npoetry run python -m openhands.core.main -t \"write a bash script that prints hi\"\n```\n\n----------------------------------------\n\nTITLE: Configuring VSCode launch.json for Debugging CodeAct in OpenHands\nDESCRIPTION: This configuration provides a more specific debug setup for the CodeAct module in OpenHands. It includes parameters for specifying the task, workspace directory, agent, LLM config, and session name.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/debugging.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n    {\n      \"name\": \"Debug CodeAct\",\n      \"type\": \"debugpy\",\n      \"request\": \"launch\",\n      \"module\": \"openhands.core.main\",\n      \"args\": [\n        \"-t\",\n        \"Ask me what your task is.\",\n        \"-d\",\n        \"${workspaceFolder}/workspace\",\n        \"-c\",\n        \"CodeActAgent\",\n        \"-l\",\n        \"llm.o1\",\n        \"-n\",\n        \"prompts\"\n      ],\n      \"justMyCode\": false\n    }\n```\n\n----------------------------------------\n\nTITLE: Configuring Triggers in YAML for Knowledge Microagents\nDESCRIPTION: Example showing how to define trigger keywords that activate a knowledge microagent. Includes both single words and multi-word phrases for matching.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-syntax.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntriggers:\n  - kubernetes\n  - k8s\n  - docker\n  - security\n  - containers cluster\n```\n\n----------------------------------------\n\nTITLE: GitHub Token Setup Instructions\nDESCRIPTION: Detailed steps for generating and configuring a GitHub Personal Access Token (PAT) for use with OpenHands, including required scopes and permissions for both classic and fine-grained tokens.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/gui-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n1. **Generate a Personal Access Token (PAT)**:\n - On GitHub, go to Settings > Developer Settings > Personal Access Tokens > Tokens (classic).\n - **New token (classic)**\n   - Required scopes:\n   - `repo` (Full control of private repositories)\n - **Fine-Grained Tokens**\n   - All Repositories (You can select specific repositories, but this will impact what returns in repo search)\n   - Minimal Permissions ( Select `Meta Data = Read-only` read for search, `Pull Requests = Read and Write` and `Content = Read and Write` for branch creation)\n2. **Enter Token in OpenHands**:\n - Click the Settings button (gear icon).\n - Paste your token in the `GitHub Token` field.\n - Click `Save` to apply the changes.\n```\n\n----------------------------------------\n\nTITLE: Running HumanEvalFix Inference with OpenHands\nDESCRIPTION: Shell command for executing HumanEvalFix inference using a configured model. The command accepts a model identifier that must be defined in config.toml.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/humanevalfix/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/humanevalfix/scripts/run_infer.sh eval_gpt4_1106_preview\n```\n\n----------------------------------------\n\nTITLE: Installing kubectl CLI Tool\nDESCRIPTION: Commands to download, make executable, and install the kubectl command-line tool for interacting with Kubernetes clusters.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/kubernetes.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Download kubectl\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n# Make it executable\nchmod +x kubectl\n# Move to a directory in your PATH\nsudo mv ./kubectl /usr/local/bin/\n```\n\n----------------------------------------\n\nTITLE: Docker Development Environment Setup\nDESCRIPTION: Commands for setting up and running OpenHands in a Docker development environment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/Development.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake docker-dev\nmake docker-run\ncd ./containers/dev\n./dev.sh\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq as LiteLLM Provider in OpenHands UI\nDESCRIPTION: This snippet describes the settings required in the OpenHands UI to use Groq as a provider through LiteLLM. It includes setting the LLM Provider, LLM Model, and API key.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/groq.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- `LLM Provider` to `Groq`\n- `LLM Model` to the model you will be using. [Visit here to see the list of\nmodels that Groq hosts](https://console.groq.com/docs/models). If the model is not in the list, toggle\n`Advanced` options, and enter it in `Custom Model` (e.g. groq/<model-name> like `groq/llama3-70b-8192`).\n- `API key` to your Groq API key. To find or create your Groq API Key, [see here](https://console.groq.com/keys).\n```\n\n----------------------------------------\n\nTITLE: Message Serialization Methods\nDESCRIPTION: Implementation of string and list serialization methods for converting rich content messages into formats compatible with litellm. Includes handling of text content, images, and tool calls.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/core/message_format.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef _string_serializer(self) -> dict:\n    # convert content to a single string\n    content = '\\n'.join(item.text for item in self.content if isinstance(item, TextContent))\n    message_dict: dict = {'content': content, 'role': self.role}\n    return self._add_tool_call_keys(message_dict)\n\ndef _list_serializer(self) -> dict:\n    content: list[dict] = []\n    for item in self.content:\n        d = item.model_dump()\n        if isinstance(item, TextContent):\n            content.append(d)\n        elif isinstance(item, ImageContent) and self.vision_enabled:\n            content.extend(d)\n    return {'content': content, 'role': self.role}\n```\n\n----------------------------------------\n\nTITLE: Initializing Runtime for OpenHands Evaluation\nDESCRIPTION: This Python function initializes the runtime environment for OpenHands evaluation, where custom setup steps can be added for each evaluation instance.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef initialize_runtime(runtime: Runtime, instance: pd.Series):\n    # Set up your evaluation environment here\n    # For example, setting environment variables, preparing files, etc.\n    pass\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenHands for Ollama in Development Mode\nDESCRIPTION: TOML configuration for setting up OpenHands to use Ollama in development mode. This includes specifying the workspace base and Ollama-specific settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[core]\nworkspace_base=\"./workspace\"\n\n[llm]\nembedding_model=\"local\"\nollama_base_url=\"http://localhost:11434\"\n```\n\n----------------------------------------\n\nTITLE: Processando Instância para Avaliação em OpenHands\nDESCRIPTION: Função para processar cada instância de avaliação, configurando o runtime, executando o controlador com a instrução específica e avaliando as ações do agente para gerar resultados da avaliação.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom openhands.utils.async_utils import call_async_from_sync\ndef process_instance(instance: pd.Series, metadata: EvalMetadata) -> EvalOutput:\n    config = get_config(instance, metadata)\n    runtime = create_runtime(config)\n    call_async_from_sync(runtime.connect)\n    initialize_runtime(runtime, instance)\n\n    instruction = get_instruction(instance, metadata)\n\n    state = run_controller(\n        config=config,\n        task_str=instruction,\n        runtime=runtime,\n        fake_user_response_fn=your_user_response_function,\n    )\n\n    # Avalie as ações do agente\n    evaluation_result = await evaluate_agent_actions(runtime, instance)\n\n    return EvalOutput(\n        instance_id=instance.instance_id,\n        instruction=instruction,\n        test_result=evaluation_result,\n        metadata=metadata,\n        history=compatibility_for_eval_history_pairs(state.history),\n        metrics=state.metrics.get() if state.metrics else None,\n        error=state.last_error if state and state.last_error else None,\n    )\n```\n\n----------------------------------------\n\nTITLE: Example Usage of The Agent Company Evaluation Script\nDESCRIPTION: This example demonstrates how to use the run_infer.sh script with specific parameters. It sets the LLM configs, output path, server hostname, version, and percentile range for task execution.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/the_agent_company/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/the_agent_company/scripts/run_infer.sh \\\n  --agent-llm-config claude-3-5-sonnet-20240620 \\\n  --env-llm-config claude-3-5-sonnet-20240620 \\\n  --outputs-path outputs \\\n  --server-hostname localhost \\\n  --version 1.0.0 \\\n  --start-percentile 10 \\\n  --end-percentile 20\n```\n\n----------------------------------------\n\nTITLE: Running GAIA Evaluation Script in Bash\nDESCRIPTION: Command structure for executing GAIA benchmark evaluation with configurable parameters including model config, git version, agent type, evaluation limit, and GAIA subset selection.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/gaia/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/gaia/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit] [gaia_subset]\n```\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/gaia/scripts/run_infer.sh eval_gpt4_1106_preview 0.6.2 CodeActAgent 300\n```\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/gaia/scripts/run_infer.sh eval_gpt4_1106_preview 0.6.2 CodeActAgent 10\n```\n\n----------------------------------------\n\nTITLE: Executando OpenHands com Runtime Local no Modo Headless\nDESCRIPTION: Exemplo de comando para iniciar o OpenHands com o Runtime Local no modo headless, incluindo a definição do tipo de runtime, diretório de workspace e a tarefa a ser executada.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n# Define o tipo de runtime como local\nexport RUNTIME=local\n\n# Opcionalmente, define um diretório de workspace\nexport WORKSPACE_BASE=/caminho/para/seu/projeto\n\n# Inicia o OpenHands\npoetry run python -m openhands.core.main -t \"escreva um script bash que imprima oi\"\n```\n\n----------------------------------------\n\nTITLE: Remote Runtime Evaluation Setup\nDESCRIPTION: Configuration and execution command for running AiderBench evaluation on remote runtime with API authentication.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/aider_bench/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nexport ALLHANDS_API_KEY=\"YOUR-API-KEY\"\nexport RUNTIME=remote\nexport SANDBOX_REMOTE_RUNTIME_API_URL=\"https://runtime.eval.all-hands.dev\"\n./evaluation/benchmarks/aider_bench/scripts/run_infer.sh llm.eval HEAD CodeActAgent 133 2\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Docker Container with Ollama Configuration\nDESCRIPTION: Docker run command with additional arguments to configure OpenHands for use with a local Ollama LLM. This includes setting up network access and environment variables.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    --add-host host.docker.internal:host-gateway \\\n    -e LLM_OLLAMA_BASE_URL=\"http://host.docker.internal:11434\" \\\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Example APIBench Inference Command\nDESCRIPTION: Example command showing how to run the inference script with specific parameters: llm configuration, version 0.6.2, CodeActAgent agent, 10 evaluation instances, and torch hub.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/gorilla/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/gorilla/scripts/run_infer.sh llm 0.6.2 CodeActAgent 10 th\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for VertexAI in Docker\nDESCRIPTION: This snippet shows how to set the required environment variables when running OpenHands with VertexAI through Google Cloud Platform. It includes the Google application credentials, GCP project ID, and GCP location.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/google-llms.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nGOOGLE_APPLICATION_CREDENTIALS=\"<json-dump-of-gcp-service-account-json>\"\nVERTEXAI_PROJECT=\"<your-gcp-project-id>\"\nVERTEXAI_LOCATION=\"<your-gcp-location>\"\n```\n\n----------------------------------------\n\nTITLE: Utilisation de configurations LLM personnalisées avec des agents\nDESCRIPTION: Exemple montrant comment spécifier quelle configuration LLM utiliser pour différents agents dans le fichier config.toml.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/llms/custom-llm-configs.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[agent.RepoExplorerAgent]\n# Utiliser la configuration GPT-3 moins coûteuse pour cet agent\nllm_config = 'gpt3'\n\n[agent.CodeWriterAgent]\n# Utiliser la configuration haute créativité pour cet agent\nllm_config = 'haute-creativite'\n```\n\n----------------------------------------\n\nTITLE: Remote Runtime Environment Configuration\nDESCRIPTION: Environment variable setup for running AgentBench evaluation in a remote runtime environment, including API key configuration and runtime settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/agent_bench/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Required environment variables\nexport ALLHANDS_API_KEY=\"your-api-key\"  # Contact the team to get an API key\nexport RUNTIME=remote\nexport SANDBOX_REMOTE_RUNTIME_API_URL=\"https://runtime.eval.all-hands.dev\"\n\n# Run the evaluation\n./evaluation/benchmarks/agent_bench/scripts/run_infer.sh llm.eval_gpt4_1106_preview HEAD CodeActAgent 1\n```\n\n----------------------------------------\n\nTITLE: Running Remote Inference for MiniWoB Evaluation\nDESCRIPTION: This bash script demonstrates how to run a remote inference evaluation for the MiniWoB benchmark. It sets environment variables for API key and runtime, then executes the run_infer.sh script with specific parameters for model configuration, git version, agent type, evaluation limit, and number of workers.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/miniwob/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ALLHANDS_API_KEY=\"YOUR-API-KEY\"\nexport RUNTIME=remote\nexport SANDBOX_REMOTE_RUNTIME_API_URL=\"https://runtime.eval.all-hands.dev\"\n./evaluation/benchmarks/miniwob/scripts/run_infer.sh llm.eval HEAD BrowsingAgent \"\" 125 2\n```\n\n----------------------------------------\n\nTITLE: Downloading Swift Binary for Debian\nDESCRIPTION: Command to download the Swift binary package for Debian 12 from the official Swift.org website. This example uses Swift version 6.0.3.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/swift-linux.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd /workspace\nwget https://download.swift.org/swift-6.0.3-release/debian12/swift-6.0.3-RELEASE/swift-6.0.3-RELEASE-debian12.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Running ScienceAgentBench Inference Command\nDESCRIPTION: Shell command for executing inference on ScienceAgentBench with configurable parameters including model config, git version, knowledge usage, agent type, evaluation limits, iterations, workers, and dataset settings.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/scienceagentbench/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/scienceagentbench/scripts/run_infer.sh [model_config] [git-version] [use_knowledge] [agent] [eval_limit] [max_iter] [num_workers] [dataset] [dataset_split]\\n\\n# Example\\n./evaluation/benchmarks/scienceagentbench/scripts/run_infer.sh llm.eval_gpt4o 0.9.3\n```\n\n----------------------------------------\n\nTITLE: Responding to PR Comments\nDESCRIPTION: Command to handle and respond to comments on pull requests using the OpenHands resolver.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m openhands.resolver.send_pull_request --issue-number PR_NUMBER --issue-type pr\n```\n\n----------------------------------------\n\nTITLE: Executing Bash Commands in CodeActAgent\nDESCRIPTION: This snippet demonstrates the CodeActAgent's ability to execute any valid Linux bash command as part of its CodeAct functionality.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/agents.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nExecute any valid Linux `bash` command\n```\n\n----------------------------------------\n\nTITLE: Advanced OpenHands Sandbox Configuration Options\nDESCRIPTION: This TOML configuration demonstrates additional options for customizing the OpenHands sandbox, including specifying extra dependencies, environment variables, and build platform.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[core]\n# Instalar dependências adicionais quando o runtime for construído\n# Pode conter quaisquer comandos shell válidos\n# Se você precisar do caminho para o interpretador Python em qualquer um desses comandos, pode usar a variável $OH_INTERPRETER_PATH\nruntime_extra_deps = \"\"\"\npip install numpy pandas\napt-get update && apt-get install -y ffmpeg\n\"\"\"\n\n# Definir variáveis de ambiente para o runtime\n# Útil para configuração que precisa estar disponível em tempo de execução\nruntime_startup_env_vars = { DATABASE_URL = \"postgresql://user:pass@localhost/db\" }\n\n# Especificar a plataforma para builds de várias arquiteturas (por exemplo, \"linux/amd64\" ou \"linux/arm64\")\nplatform = \"linux/amd64\"\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Docker Image for OpenHands with Ruby\nDESCRIPTION: This Dockerfile extends the default OpenHands sandbox image by installing Ruby. It demonstrates how to create a custom image with additional software.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_0\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM nikolaik/python-nodejs:python3.12-nodejs22\n\n# Install required packages\nRUN apt-get update && apt-get install -y ruby\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration\nDESCRIPTION: Example of supported environment variables for configuring the LLM API key, model and workspace\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/server/README.md#2025-04-23_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nLLM_API_KEY=sk-... # Your Anthropic API Key\nLLM_MODEL=claude-3-5-sonnet-20241022 # Default model for the agent to use\nWORKSPACE_BASE=/path/to/your/workspace # Default absolute path to workspace\n```\n\n----------------------------------------\n\nTITLE: Visualizing Resolver Output\nDESCRIPTION: Command to visualize the resolver output for a specific issue using JSON visualization method.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython -m openhands.resolver.visualize_resolver_output --issue-number ISSUE_NUMBER --vis-method json\n```\n\n----------------------------------------\n\nTITLE: Calculating Success Rate - Python Command\nDESCRIPTION: Shell command to run a Python script that calculates the success rate from WebArena evaluation output files.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/webarena/README.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npoetry run python evaluation/benchmarks/webarena/get_success_rate.py evaluation/evaluation_outputs/outputs/webarena/SOME_AGENT/EXP_NAME/output.jsonl\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenHands for Local LLM in Development Mode\nDESCRIPTION: This TOML configuration sets up OpenHands to use a local LLM. It defines the workspace path, model name, and the base URL for the Ollama API.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/local-llms.md#2025-04-23_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[core]\nworkspace_base=\"/path/to/your/workspace\"\n\n[llm]\nmodel=\"openhands-lm-32b-v0.1\"\nollama_base_url=\"http://localhost:8000\"\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands CLI Mode with Python\nDESCRIPTION: Command to start an interactive OpenHands session using Python. Requires following the development setup instructions and setting environment variables or using a config.toml file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python -m openhands.core.cli\n```\n\n----------------------------------------\n\nTITLE: Setting Workspace Base Path in Docker Environment\nDESCRIPTION: Example commands for setting the WORKSPACE_BASE environment variable on different operating systems to define the path for filesystem mounting.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/docker.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport WORKSPACE_BASE=/path/to/your/code\n\n# Linux and Mac Example\n# export WORKSPACE_BASE=$HOME/OpenHands\n# Will set $WORKSPACE_BASE to /home/<username>/OpenHands\n#\n# WSL on Windows Example\n# export WORKSPACE_BASE=/mnt/c/dev/OpenHands\n# Will set $WORKSPACE_BASE to C:\\dev\\OpenHands\n```\n\n----------------------------------------\n\nTITLE: Installing and Running OpenHands Frontend in Development Mode\nDESCRIPTION: Steps to clone the repository, install dependencies, and run the application in development mode with mocked backend using MSW.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/frontend/README.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# Clone the repository\ngit clone https://github.com/All-Hands-AI/OpenHands.git\n\n# Change the directory to the frontend\ncd OpenHands/frontend\n\n# Install the dependencies\nnpm install\n\n# Start the application in development mode\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Configuring Runloop Runtime in Bash\nDESCRIPTION: Sets the runtime environment variable to use Runloop as the execution environment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/runloop/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport RUNTIME=\"runloop\"\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Docker Image for OpenHands Based on Ruby\nDESCRIPTION: This Dockerfile uses a Ruby-specific base image as an alternative approach to creating a custom sandbox for OpenHands with Ruby support.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM ruby:latest\n```\n\n----------------------------------------\n\nTITLE: Testing WebSocket Connection\nDESCRIPTION: Example command using websocat to test the WebSocket server with a sample task request\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/server/README.md#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nwebsocat ws://127.0.0.1:3000/ws\n{\"action\": \"start\", \"args\": {\"task\": \"write a bash script that prints hello\"}}\n```\n\n----------------------------------------\n\nTITLE: Building Docker Containers Manually\nDESCRIPTION: Commands for manually building the OpenHands application and sandbox Docker containers from their respective Dockerfiles.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -f containers/app/Dockerfile -t openhands .\ndocker build -f containers/sandbox/Dockerfile -t sandbox .\n```\n\n----------------------------------------\n\nTITLE: Executando OpenHands com Runtime Daytona\nDESCRIPTION: Comando para baixar e executar o script de lançamento mais recente do OpenHands usando o runtime Daytona.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nbash -i <(curl -sL https://get.daytona.io/openhands)\n```\n\n----------------------------------------\n\nTITLE: GitLab Token Setup Instructions\nDESCRIPTION: Steps for generating and configuring a GitLab Personal Access Token for use with OpenHands, including required scopes and configuration steps.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/gui-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n1. **Generate a Personal Access Token (PAT)**:\n - On GitLab, go to User Settings > Access Tokens.\n - Create a new token with the following scopes:\n   - `api` (API access)\n   - `read_user` (Read user information)\n   - `read_repository` (Read repository)\n   - `write_repository` (Write repository)\n - Set an expiration date or leave it blank for a non-expiring token.\n2. **Enter Token in OpenHands**:\n - Click the Settings button (gear icon).\n - Paste your token in the `GitLab Token` field.\n - Enter your GitLab instance URL if using self-hosted GitLab.\n - Click `Save` to apply the changes.\n```\n\n----------------------------------------\n\nTITLE: Running GPQA Benchmark Inference with Bash\nDESCRIPTION: Command-line script to execute GPQA benchmark evaluation. Supports different model configurations, git versions, sample sizes, data splits, and agent classes. The script runs from the OpenHands repository root and requires proper environment setup.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/gpqa/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/gpqa/scripts/run_infer.sh [model_config_name] [git-version] [num_samples_eval] [data_split] [AgentClass]\n```\n\n----------------------------------------\n\nTITLE: Configuring Modal Runtime Environment Variables in Docker\nDESCRIPTION: Docker run command showing the required environment variable configuration for enabling Modal runtime in OpenHands. Includes settings for Modal API authentication tokens.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/modal.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    -e RUNTIME=modal \\\n    -e MODAL_API_TOKEN_ID=\"your-id\" \\\n    -e MODAL_API_TOKEN_SECRET=\"modal-api-key\" \\\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands from Command Line with Task Description\nDESCRIPTION: This bash command demonstrates how to run OpenHands from the command line, specifying iterations, task description, agent class, and LLM configuration.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/evaluation-harness.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python ./openhands/core/main.py \\\n        -i 10 \\\n        -t \"Write me a bash script that prints hello world.\" \\\n        -c CodeActAgent \\\n        -l llm\n```\n\n----------------------------------------\n\nTITLE: Configurando Runtime Local para OpenHands via Variáveis de Ambiente\nDESCRIPTION: Comandos para configurar o Runtime Local do OpenHands usando variáveis de ambiente, incluindo a definição do tipo de runtime e o diretório de workspace base.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Obrigatório\nexport RUNTIME=local\n\n# Opcional, mas recomendado\nexport WORKSPACE_BASE=/caminho/para/seu/workspace\n```\n\n----------------------------------------\n\nTITLE: Cost Optimization Example with Different LLM Configurations\nDESCRIPTION: A practical example showing how to optimize costs by using different LLM configurations for various agents, with cheaper models for simple tasks and more powerful models for complex tasks.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/custom-llm-configs.md#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n# Configuração padrão usando GPT-4 para respostas de alta qualidade\n[llm]\nmodel = \"gpt-4\"\napi_key = \"your-api-key\"\ntemperature = 0.0\n\n# Configuração mais barata para exploração de repositório\n[llm.repo-explorer]\nmodel = \"gpt-3.5-turbo\"\ntemperature = 0.2\n\n# Configuração para geração de código\n[llm.code-gen]\nmodel = \"gpt-4\"\ntemperature = 0.0\nmax_output_tokens = 2000\n\n[agent.RepoExplorerAgent]\nllm_config = 'repo-explorer'\n\n[agent.CodeWriterAgent]\nllm_config = 'code-gen'\n```\n\n----------------------------------------\n\nTITLE: Setting Daytona API Key as Environment Variable in Bash\nDESCRIPTION: This command sets the Daytona API key as an environment variable. Replace '<your-api-key>' with the actual API key obtained from the Daytona Dashboard.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/daytona.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport DAYTONA_API_KEY=\"<your-api-key>\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Directory Structure for Knowledge Microagents in Markdown\nDESCRIPTION: This snippet shows the recommended directory structure for implementing knowledge microagents in OpenHands. It illustrates the location of various knowledge-specific .md files within the .openhands/microagents/knowledge/ directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-repo.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nyour-repository/\n└── .openhands/\n    └── microagents/\n        └── knowledge/\n            └── git.md\n            └── docker.md\n            └── python.md\n            └── ...\n        └── repo.md\n```\n\n----------------------------------------\n\nTITLE: Mapping Host Credentials in Docker for OpenHands Development\nDESCRIPTION: YAML configuration showing how host credentials are mapped as read-only volumes in the Docker container for OpenHands development.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/dev/README.md#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# host credentials\n- $HOME/.git-credentials:/root/.git-credentials:ro\n- $HOME/.gitconfig:/root/.gitconfig:ro\n- $HOME/.npmrc:/root/.npmrc:ro\n```\n\n----------------------------------------\n\nTITLE: Running Local AgentBench Evaluation in Bash\nDESCRIPTION: Command structure for executing AgentBench evaluation with configurable parameters including model config, git version, agent type, and evaluation limit.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/agent_bench/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/agent_bench/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit]\n```\n\n----------------------------------------\n\nTITLE: Running Inference on The Agent Company Tasks with Bash Script\nDESCRIPTION: This bash script runs inference on The Agent Company tasks. It allows configuration of LLM settings, output paths, server details, and task percentiles. The script is idempotent and can resume from the last checkpoint if interrupted.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/the_agent_company/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/the_agent_company/scripts/run_infer.sh \\\n  --agent-llm-config <agent-llm-config, default to 'agent'>  \\\n  --env-llm-config <env-llm-config, default to 'env'> \\\n  --outputs-path <outputs-path, default to outputs> \\\n  --server-hostname <server-hostname, default to localhost> \\\n  --version <version, default to 1.0.0> \\\n  --start-percentile <integer from 0 to 99, default to 0> \\\n  --end-percentile <integer from 1 to 100, default to 100>\n```\n\n----------------------------------------\n\nTITLE: Running AiderBench Inference Script\nDESCRIPTION: Bash command for executing the AiderBench evaluation with configurable parameters including model config, git version, agent type, and evaluation limits.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/aider_bench/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/aider_bench/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit] [eval-num-workers] [eval_ids]\n```\n\n----------------------------------------\n\nTITLE: Secure Port Binding Configuration\nDESCRIPTION: Docker port binding configuration to restrict access to localhost only for improved security.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/docker.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ... \\\n    -p 127.0.0.1:3000:3000 \\\n```\n\n----------------------------------------\n\nTITLE: Configurando Runtime Modal para OpenHands\nDESCRIPTION: Comando Docker para executar o OpenHands usando o Runtime Modal, incluindo a definição do tipo de runtime e as credenciais da API Modal.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    -e RUNTIME=modal \\\n    -e MODAL_API_TOKEN_ID=\"seu-id\" \\\n    -e MODAL_API_TOKEN_SECRET=\"seu-segredo\" \\\n```\n\n----------------------------------------\n\nTITLE: Socket.io Event Handler Structure\nDESCRIPTION: Outlines the three main server-side event handlers used for managing client connections and communication: connect, oh_user_action, and disconnect events. The system allows for recoverable connection interruptions and handles session persistence.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/server/session/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* `connect` - Invoked when a new connection to the server is established. (This may be via http or WebSocket)\n* `oh_user_action` - Invoked when a connected client sends an event (such as a prompt for the Agent) -\n   this is distinct from the `oh_event` sent from the server to the client.\n* `disconnect` - Invoked when a connected client disconnects from the server.\n```\n\n----------------------------------------\n\nTITLE: Creating Isolated Docker Network\nDESCRIPTION: Commands for creating and using an isolated Docker network for OpenHands deployment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/docker.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Create an isolated network\ndocker network create openhands-network\n\n# Run OpenHands in the isolated network\ndocker run # ... \\\n    --network openhands-network \\\n```\n\n----------------------------------------\n\nTITLE: Setting Azure API Version for OpenHands Docker Container\nDESCRIPTION: This snippet shows how to set the LLM_API_VERSION environment variable when running the OpenHands Docker container. This is required for configuring Azure OpenAI integration.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/llms/azure-llms.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nLLM_API_VERSION=\"<api-version>\"              # 例如 \"2023-05-15\"\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Remote Runtime Resources\nDESCRIPTION: Command to clean up all existing remote runtime resources that have been started.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nALLHANDS_API_KEY=\"YOUR-API-KEY\" ./evaluation/utils/scripts/cleanup_remote_runtime.sh\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests Bash Script\nDESCRIPTION: Bash command for executing integration tests with configurable parameters including model config, git version, agent type, evaluation limits and worker count.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/integration_tests/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/integration_tests/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit] [eval-num-workers] [eval_ids]\n```\n\n----------------------------------------\n\nTITLE: Running ProofWriter Inference with GPT-4\nDESCRIPTION: Shell command to execute inference on the first example of the ProofWriter dataset using GPT-4 1106 preview model.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/logic_reasoning/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/logic_reasoning/scripts/run_infer.sh eval_gpt4_1106_preview_llm ProofWriter\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI Proxy Configuration\nDESCRIPTION: Example demonstrating the format for configuring OpenAI proxy settings, including the model name pattern and base URL structure.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/openai-llms.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nopenai/<model-name> (e.g. `openai/gpt-4o` or openai/<proxy-prefix>/<model-name>)\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM in TOML for OpenHands (0.8.0+)\nDESCRIPTION: Updated LLM configuration structure in config.toml for OpenHands version 0.8.0 and later. The configuration must now be under the 'llm' group.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/upgrade-guide.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[llm.gpt-4o]\nmodel=\"gpt-4o\"\napi_key=\"<your_api_key>\"\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Docker Container\nDESCRIPTION: Docker command to run OpenHands container with necessary environment variables and configurations.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/daytona/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:${OPENHANDS_VERSION}-nikolaik \\\n    -e LOG_ALL_EVENTS=true \\\n    -e RUNTIME=daytona \\\n    -e DAYTONA_API_KEY=${DAYTONA_API_KEY} \\\n    -v ~/.openhands-state:/.openhands-state \\\n    -p 3000:3000 \\\n    --name openhands-app \\\n    docker.all-hands.dev/all-hands-ai/openhands:${OPENHANDS_VERSION}\n```\n\n----------------------------------------\n\nTITLE: Implementing Python CLI for String Manipulation\nDESCRIPTION: This code snippet outlines the structure of a Python CLI for string manipulation. It includes a main function that parses command-line arguments and calls the appropriate string manipulation function based on the user's input. The specific implementations for each command are to be placed in separate files.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/cases/python-cli/task.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport argparse\nimport importlib\n\ndef main():\n    parser = argparse.ArgumentParser(description='String manipulation CLI')\n    parser.add_argument('command', choices=['reverse', 'uppercase', 'lowercase', 'spongebob', 'length', 'scramble'], help='The string manipulation command')\n    parser.add_argument('string', help='The string to manipulate')\n    args = parser.parse_args()\n\n    # Dynamically import the module for the specified command\n    module = importlib.import_module(f'{args.command}_string')\n    # Call the function with the same name as the command\n    result = getattr(module, args.command)(args.string)\n    print(result)\n\nif __name__ == '__main__':\n    main()\n```\n\n----------------------------------------\n\nTITLE: Mounting Local Filesystem in Docker Container\nDESCRIPTION: Docker run command options for mounting local filesystem into the container workspace with proper user permissions.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/docker.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    -e SANDBOX_USER_ID=$(id -u) \\\n    -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \\\n    -v $WORKSPACE_BASE:/opt/workspace_base \\\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Setting Optional Environment Variables\nDESCRIPTION: Environment variable configuration for enabling unit tests and skipping initial dataset instances.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/aider_bench/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport USE_UNIT_TESTS=true # if you want to allow the Agent to verify correctness using unittests. Default to false.\nexport SKIP_NUM=12 # skip the first 12 instances from the dataset\n```\n\n----------------------------------------\n\nTITLE: Importando Utilidades para Avaliação em OpenHands\nDESCRIPTION: Importação das bibliotecas e utilidades necessárias para criar um fluxo de trabalho de avaliação no OpenHands, incluindo módulos para metadados, configuração, runtime e eventos.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport openhands.agenthub\nfrom evaluation.utils.shared import (\n    EvalMetadata,\n    EvalOutput,\n    make_metadata,\n    prepare_dataset,\n    reset_logger_for_multiprocessing,\n    run_evaluation,\n)\nfrom openhands.controller.state.state import State\nfrom openhands.core.config import (\n    AppConfig,\n    SandboxConfig,\n    get_llm_config_arg,\n    parse_arguments,\n)\nfrom openhands.core.logger import openhands_logger as logger\nfrom openhands.core.main import create_runtime, run_controller\nfrom openhands.events.action import CmdRunAction\nfrom openhands.events.observation import CmdOutputObservation, ErrorObservation\nfrom openhands.runtime.runtime import Runtime\n```\n\n----------------------------------------\n\nTITLE: Running APIBench Inference Script\nDESCRIPTION: Bash script command for running inference on APIBench instances. Takes parameters for model configuration, git version, agent type, evaluation limit, and hub selection. Requires Docker daemon to be running.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/gorilla/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/gorilla/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit] [hubs]\n```\n\n----------------------------------------\n\nTITLE: Configuring PR Description Update Task in YAML\nDESCRIPTION: YAML configuration that defines a task for updating PR descriptions. Specifies task metadata and required inputs with validation patterns. The task requires a valid GitHub PR URL and corresponding branch name as inputs.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/tasks/update_pr_description.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: update_pr_description\ntype: task\nversion: 1.0.0\nauthor: openhands\nagent: CodeActAgent\ninputs:\n  - name: PR_URL\n    description: \"URL of the pull request\"\n    type: string\n    required: true\n    validation:\n      pattern: \"^https://github.com/.+/.+/pull/[0-9]+$\"\n  - name: BRANCH_NAME\n    description: \"Branch name corresponds to the pull request\"\n    type: string\n    required: true\n```\n\n----------------------------------------\n\nTITLE: Running SWE-Gym Evaluation Script\nDESCRIPTION: Bash command for running SWE-Gym evaluation with 16x parallelism using the AllHands API. Sets API key and executes the rollout script for model sampling.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/SWE-Gym.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport ALLHANDS_API_KEY=ah-yourkey  # You don't need to set this when running these in local docker container\n./evaluation/benchmarks/swe_bench/scripts/rollout_swegym.sh llm.mymodel-temp05 'train-t05' 16\n```\n\n----------------------------------------\n\nTITLE: Microagents Directory Structure Example\nDESCRIPTION: Demonstrates the directory structure for organizing microagents in OpenHands, showing both repository-specific and public locations\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-overview.md#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n.openhands/microagents/    # Repository-specific microagents\n/microagents              # Public microagents in OpenHands repository\n```\n\n----------------------------------------\n\nTITLE: Setting Daytona API Key Environment Variable\nDESCRIPTION: Command to set the Daytona API key as an environment variable for authentication purposes.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/daytona/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport DAYTONA_API_KEY=\"<your-api-key>\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Random Number API with Node.js and Express\nDESCRIPTION: This snippet sets up a basic Express server with a single endpoint that returns a random number. It uses the 'express' package to create the server and handle routing.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/cases/client-server/task.txt#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst express = require('express');\nconst app = express();\nconst port = 3000;\n\napp.get('/random', (req, res) => {\n  const randomNumber = Math.floor(Math.random() * 100) + 1;\n  res.json({ number: randomNumber });\n});\n\napp.listen(port, () => {\n  console.log(`Server running on port ${port}`);\n});\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Docker Container with LM Studio Configuration\nDESCRIPTION: Docker run command with environment variables set for LM Studio integration, allowing OpenHands to use LM Studio as the LLM provider.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    -e LLM_MODEL=\"openai/lmstudio\" \\\n    -e LLM_BASE_URL=\"http://host.docker.internal:1234/v1\" \\\n    -e CUSTOM_LLM_PROVIDER=\"openai\" \\\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Locally Using Docker via Daytona\nDESCRIPTION: This command downloads and executes the latest OpenHands release script, which automatically pulls and runs the OpenHands container using Docker. It requires the Daytona API key to be set as an environment variable.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/daytona.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbash -i <(curl -sL https://get.daytona.io/openhands)\n```\n\n----------------------------------------\n\nTITLE: Creating a KIND Cluster\nDESCRIPTION: Command to create a basic Kubernetes cluster using KIND, which will run inside Docker containers.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/kubernetes.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkind create cluster\n```\n\n----------------------------------------\n\nTITLE: OpenHands Test Case Directory Structure (Plaintext)\nDESCRIPTION: Illustrates the directory structure for OpenHands test cases, including task descriptions, output directories, and test scripts. This structure is used for organizing and running regression tests.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/README.md#2025-04-23_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\ncases/\n├── hello-world/\n│   ├── task.txt\n│   ├── outputs/\n│   │   └── codeact_agent/\n│   │       └── workspace/\n│   │           ├── hello_world.sh\n│   └── test_hello_world.py\n├── create_web_app/\n│   ├── task.txt\n│   ├── outputs/\n│   │   └── codeact_agent/\n│   │       └── workspace/\n│   │           ├── app.py\n│   │           ├── requirements.txt\n│   │           ├── static/\n│   │           └── templates/\n│   └── test_create_web_app.py\n└── ...\n```\n\n----------------------------------------\n\nTITLE: Running MINT Benchmark Evaluation in Bash\nDESCRIPTION: Command to start the MINT benchmark evaluation. It takes parameters for model configuration, git version, subset, and evaluation limit. The script uses these to configure and run the evaluation on specified subsets of the MINT dataset.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/mint/scripts/run_infer.sh [model_config] [git-version] [subset] [eval_limit]\n```\n\n----------------------------------------\n\nTITLE: Defining Test Update Task in YAML\nDESCRIPTION: YAML configuration that defines a task for updating and running tests. Specifies required inputs including branch name and test command, with optional parameters for function and file fixes.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/tasks/update_test_for_new_implementation.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: update_test_for_new_implementation\ntype: task\nversion: 1.0.0\nauthor: openhands\nagent: CodeActAgent\ninputs:\n  - name: BRANCH_NAME\n    description: \"Branch for the agent to work on\"\n    required: true\n  - name: TEST_COMMAND_TO_RUN\n    description: \"The test command you want the agent to work on. For example, `pytest tests/unit/test_bash_parsing.py`\"\n    required: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Runtime Environment Variables in Bash\nDESCRIPTION: Sets required and optional environment variables for configuring the OpenHands Local Runtime. The RUNTIME variable must be set to 'local', and WORKSPACE_BASE optionally specifies the working directory path.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/local.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Required\nexport RUNTIME=local\n\n# Optional but recommended\nexport WORKSPACE_BASE=/path/to/your/workspace\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Regression Test Suite (Bash)\nDESCRIPTION: Command to execute the OpenHands regression test suite using the provided test runner script. It requires specifying the OpenAI API key and optionally the model to use.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython evaluation/regression/run_tests.py --OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxx --model=gpt-4o\n```\n\n----------------------------------------\n\nTITLE: Configuring Specific Debug Settings for CodeAct in OpenHands\nDESCRIPTION: This launch configuration provides more specific debugging settings for the CodeAct module in OpenHands. It includes detailed arguments for specifying the task, workspace directory, agent, LLM config, and session name.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/how-to/debugging.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n    {\n      \"name\": \"Debug CodeAct\",\n      \"type\": \"debugpy\",\n      \"request\": \"launch\",\n      \"module\": \"openhands.core.main\",\n      \"args\": [\n        \"-t\",\n        \"Ask me what your task is.\",\n        \"-d\",\n        \"${workspaceFolder}/workspace\",\n        \"-c\",\n        \"CodeActAgent\",\n        \"-l\",\n        \"llm.o1\",\n        \"-n\",\n        \"prompts\"\n      ],\n      \"justMyCode\": false\n    }\n```\n\n----------------------------------------\n\nTITLE: Defining Input Schema for Task Microagents\nDESCRIPTION: Schema definition for specifying required user inputs when creating task microagents. Shows how to define input name, description and optional required flag.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-syntax.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ninputs:\n  - name: INPUT_NAME # Used with {{ INPUT_NAME }}\n    description: 'Description of what this input is for'\n    required: true # Optional, defaults to true\n```\n\n----------------------------------------\n\nTITLE: Reloading and Restarting Ollama Service\nDESCRIPTION: Commands to reload the systemd daemon and restart the Ollama service after configuration changes, ensuring the new settings take effect.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl daemon-reload\nsudo systemctl restart ollama\n```\n\n----------------------------------------\n\nTITLE: Defining Confirmation Mode Configuration in Markdown\nDESCRIPTION: Specifies the configuration for enabling confirmation mode in OpenHands. It is a boolean parameter defaulting to false.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/configuration-options.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n### Confirmation Mode\n- `confirmation_mode`\n  - Type: `bool`\n  - Default: `false`\n  - Description: Enable confirmation mode\n```\n\n----------------------------------------\n\nTITLE: Cleaning Docker Containers and Images\nDESCRIPTION: A command to remove unused Docker containers and images, helping to resolve caching issues that might be causing runtime build errors.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker container prune -f && docker image prune -f\n```\n\n----------------------------------------\n\nTITLE: Running BioCoder Evaluation Script\nDESCRIPTION: Command structure for running the BioCoder evaluation with configurable parameters including model config, git version, agent type, and evaluation limit.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/biocoder/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/biocoder/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit]\n```\n\n----------------------------------------\n\nTITLE: Running SWE-Bench Inference Locally with Docker\nDESCRIPTION: Command to run SWE-Bench inference locally using Docker. It pulls relevant SWE-Bench images and creates an OpenHands runtime image for the agent to operate on.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/swe_bench/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit] [max_iter] [num_workers] [dataset] [dataset_split]\n```\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/swe_bench/scripts/run_infer.sh llm.eval_gpt4_1106_preview HEAD CodeActAgent 500 100 1 princeton-nlp/SWE-bench_Verified test\n```\n\n----------------------------------------\n\nTITLE: Creating GitLab Merge Request with Git Branch\nDESCRIPTION: A bash script that demonstrates how to create a new git branch, commit changes, push to remote, and create a merge request using GitLab API in a single workflow. Uses GITLAB_TOKEN for authentication and PROJECT_ID for repository identification.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/gitlab.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\ncurl -X POST \"https://gitlab.com/api/v4/projects/$PROJECT_ID/merge_requests\" \\\n    -H \"Authorization: Bearer $GITLAB_TOKEN\" \\\n    -d '{\"source_branch\": \"create-widget\", \"target_branch\": \"openhands-workspace\", \"title\": \"Create widget\"}'\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Public Microagents\nDESCRIPTION: Shows the file organization for shareable microagents in the OpenHands repository, including knowledge and task-specific directories.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/README.md#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nOpenHands/microagents/\n├── knowledge/     # Keyword-triggered expertise\n│   ├── git.md      # Git operations\n│   ├── testing.md  # Testing practices\n│   └── docker.md   # Docker guidelines\n└── tasks/        # Interactive workflows\n    ├── pr_review.md   # PR review process\n    ├── bug_fix.md     # Bug fixing workflow\n    └── feature.md     # Feature implementation\n```\n\n----------------------------------------\n\nTITLE: Installing Development Dependencies with Mamba\nDESCRIPTION: Commands for installing Python, NodeJS, and Poetry using Mamba package manager when sudo access is unavailable.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/Development.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh\n\n# Install Python 3.12, nodejs, and poetry\nmamba install python=3.12\nmamba install conda-forge::nodejs\nmamba install conda-forge::poetry\n```\n\n----------------------------------------\n\nTITLE: Setting Azure OpenAI API Version in Docker Run Command\nDESCRIPTION: This snippet shows how to set the LLM_API_VERSION environment variable when running the OpenHands Docker container. This is required for Azure OpenAI integration.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/azure-llms.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nLLM_API_VERSION=\"<api-version>\"              # e.g. \"2023-05-15\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq as OpenAI-Compatible Endpoint in OpenHands UI\nDESCRIPTION: This snippet outlines the steps to configure Groq as an OpenAI-compatible endpoint in the OpenHands UI. It includes enabling advanced options and setting the Custom Model, Base URL, and API Key.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/groq.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n1. Enable `Advanced` options\n2. Set the following:\n   - `Custom Model` to the prefix `openai/` + the model you will be using (e.g. `openai/llama3-70b-8192`)\n   - `Base URL` to `https://api.groq.com/openai/v1`\n   - `API Key` to your Groq API key\n```\n\n----------------------------------------\n\nTITLE: Removing OpenHands Docker Images\nDESCRIPTION: A command to remove all Docker images whose names start with 'openhands-runtime-'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker rmi $(docker images --filter name=openhands-runtime- -q --no-trunc)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Component Communication Flow with Mermaid\nDESCRIPTION: Flowchart showing the communication paths between major system components including Agent, AgentController, EventStream, Runtime, and Frontend, illustrating the message passing architecture.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/README.md#2025-04-23_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n  Agent--Actions-->AgentController\n  AgentController--State-->Agent\n  AgentController--Actions-->EventStream\n  EventStream--Observations-->AgentController\n  Runtime--Observations-->EventStream\n  EventStream--Actions-->Runtime\n  Frontend--Actions-->EventStream\n```\n\n----------------------------------------\n\nTITLE: Running VisualWebArena Evaluation with OpenHands Agent\nDESCRIPTION: This bash script sets up environment variables and runs the evaluation for the VisualWebArena benchmark using an OpenHands browsing agent. It requires setting the VisualWebArena base URL, OpenAI API key, and OpenAI base URL.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/visualwebarena/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport VISUALWEBARENA_BASE_URL=<YOUR_SERVER_URL_HERE>\nexport OPENAI_API_KEY=\"yourkey\" # this OpenAI API key is required for some visualWebArena validators that utilize LLMs\nexport OPENAI_BASE_URL=\"https://api.openai.com/v1/\" # base URL for OpenAI model used for VisualWebArena evaluation\nbash evaluation/benchmarks/visualwebarena/scripts/run_infer.sh llm.claude HEAD VisualBrowsingAgent\n```\n\n----------------------------------------\n\nTITLE: Running SWE-Bench Inference with RemoteRuntime\nDESCRIPTION: Command to run SWE-Bench inference using OpenHands Remote Runtime, allowing parallel execution in the cloud without requiring a powerful local machine.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nALLHANDS_API_KEY=\"YOUR-API-KEY\" RUNTIME=remote SANDBOX_REMOTE_RUNTIME_API_URL=\"https://runtime.eval.all-hands.dev\" EVAL_DOCKER_IMAGE_PREFIX=\"us-central1-docker.pkg.dev/evaluation-092424/swe-bench-images\" \\\n./evaluation/benchmarks/swe_bench/scripts/run_infer.sh llm.eval HEAD CodeActAgent 300 30 16 \"princeton-nlp/SWE-bench_Lite\" test\n```\n\n----------------------------------------\n\nTITLE: Configurando Múltiplos LLMs em OpenHands com TOML\nDESCRIPTION: Exemplo de arquivo de configuração TOML para definir e utilizar múltiplos modelos de linguagem (LLMs) no OpenHands, incluindo configurações para o modelo principal e modelos de avaliação.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[llm]\n# IMPORTANTE: adicione sua chave de API aqui e defina o modelo para o que você deseja avaliar\nmodel = \"claude-3-5-sonnet-20241022\"\napi_key = \"sk-XXX\"\n\n[llm.eval_gpt4_1106_preview_llm]\nmodel = \"gpt-4-1106-preview\"\napi_key = \"XXX\"\ntemperature = 0.0\n\n[llm.eval_some_openai_compatible_model_llm]\nmodel = \"openai/MODEL_NAME\"\nbase_url = \"https://OPENAI_COMPATIBLE_URL/v1\"\napi_key = \"XXX\"\ntemperature = 0.0\n```\n\n----------------------------------------\n\nTITLE: Evaluating Generated Patches with Official SWE-Bench Harness\nDESCRIPTION: Command to evaluate generated patches using the official SWE-Bench dockerized evaluation harness, producing a fine-grained report.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/swe_bench/scripts/eval_infer.sh $YOUR_OUTPUT_JSONL [instance_id] [dataset_name] [split]\n```\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/swe_bench/scripts/eval_infer.sh evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Lite/CodeActAgent/gpt-4-1106-preview_maxiter_50_N_v1.0/output.jsonl\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Development Commands\nDESCRIPTION: Essential make commands for building, running, and testing the OpenHands application.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/Development.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmake build\nmake setup-config\nmake run\nmake start-backend\nmake start-frontend\nmake help\n```\n\n----------------------------------------\n\nTITLE: Serving OpenHands LM 32B with SGLang\nDESCRIPTION: This command launches an SGLang server for the OpenHands LM 32B model. It sets up tensor parallelism, defines the port, API key, and context length for the server.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/local-llms.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1 python3 -m sglang.launch_server \\\n    --model all-hands/openhands-lm-32b-v0.1 \\\n    --served-model-name openhands-lm-32b-v0.1 \\\n    --port 8000 \\\n    --tp 2 --dp 1 \\\n    --host 0.0.0.0 \\\n    --api-key mykey --context-length 131072\n```\n\n----------------------------------------\n\nTITLE: Configuring API Retry Settings in TOML for OpenHands Development Mode\nDESCRIPTION: Example TOML configuration for customizing LLM API retry behavior in development mode. This snippet sets the number of retries, minimum and maximum wait times between retries, and the multiplier that increases wait time between retry attempts.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/llms.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[llm]\nnum_retries = 4\nretry_min_wait = 5\nretry_max_wait = 30\nretry_multiplier = 2\n```\n\n----------------------------------------\n\nTITLE: Converting LaTeX to PDF\nDESCRIPTION: Basic command to convert a LaTeX source file to PDF format using PdfLatex\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/pdflatex.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npdflatex latex_source_name.tex\n```\n\n----------------------------------------\n\nTITLE: Installing Extra LaTeX Packages\nDESCRIPTION: Command to install additional LaTeX packages for extended functionality\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/pdflatex.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\napt-get install texlive-latex-extra\n```\n\n----------------------------------------\n\nTITLE: Running BIRD Inference with OpenHands\nDESCRIPTION: This bash command runs inference on the BIRD benchmark using OpenHands. It requires specifying a model configuration and a git version. The model_config refers to the LLM settings defined in config.toml, while git-version can be a commit hash or release tag.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/bird/scripts/run_infer.sh [model_config] [git-version]\n```\n\n----------------------------------------\n\nTITLE: Running ToolQA Inference with Parameters\nDESCRIPTION: Command syntax for running ToolQA inference with configurable parameters including model config, git version, agent type, evaluation limit, dataset selection, hardness level, and optional Wolfram Alpha integration.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/toolqa/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbash evaluation/benchmarks/toolqa/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit] [dataset] [hardness] [wolfram-alpha-appid]\n```\n\n----------------------------------------\n\nTITLE: Docker Container Configuration Example in Bash\nDESCRIPTION: Demonstrates the proper formatting for a multi-line docker run command with environment variables.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/DOC_STYLE_GUIDE.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it \\\n    -e THIS=this \\\n    -e THAT=that\n    ...\n```\n\n----------------------------------------\n\nTITLE: Rebuilding Docker Dev Image for OpenHands with Additional Options\nDESCRIPTION: Commands to rebuild the Docker development image for OpenHands, including an example of passing additional build options.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/dev/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake docker-dev OPTIONS=\"--build\"\n# or\n./containers/dev/dev.sh --build\n```\n\n----------------------------------------\n\nTITLE: Double Integral Calculation Using SymPy\nDESCRIPTION: Calculates a double integral using polar coordinates with SymPy's symbolic math capabilities. Uses symbols for r and theta, defines the integrand, and performs double integration over the specified region.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/tasks/in_context_examples/reasoning/with_tool.txt#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sympy import symbols, integrate, cos, sin, pi\n\nr, theta = symbols('r theta')\n\n# the integrand\nintegrand = (r*cos(theta) + r*sin(theta))**2 * r\n\n# perform the double integration\ndouble_integral = integrate(integrate(integrand, (r, 0, 701 ** 0.5)), (theta, 0, 2*pi))\nprint(double_integral)\n```\n\n----------------------------------------\n\nTITLE: Configuring LiteLLM Proxy in OpenHands UI\nDESCRIPTION: This snippet outlines the steps to configure OpenHands UI settings for using LiteLLM proxy. It includes enabling advanced options, setting the custom model with a specific prefix, configuring the base URL, and providing the API key.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/litellm-proxy.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n* Enable `Advanced` options\n* `Custom Model` to the prefix `litellm_proxy/` + the model you will be using (e.g. `litellm_proxy/anthropic.claude-3-5-sonnet-20241022-v2:0`)\n* `Base URL` to your LiteLLM proxy URL (e.g. `https://your-litellm-proxy.com`)\n* `API Key` to your LiteLLM proxy API key\n```\n\n----------------------------------------\n\nTITLE: Pruning Docker Containers and Images\nDESCRIPTION: A Docker command to remove all stopped containers and dangling images. This cleanup step is crucial in resolving Docker-related issues and freeing up system resources.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker container prune -f && docker image prune -f\n```\n\n----------------------------------------\n\nTITLE: Creating SAT Scores Table Schema in SQLite\nDESCRIPTION: Creates a table schema for storing SAT score data including reading, math, and writing scores with foreign key relationship to schools table\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE satscores (\n    cds TEXT not null primary key,\n    rtype TEXT not null,\n    sname TEXT null,\n    dname TEXT null,\n    cname TEXT null,\n    enroll12 INTEGER not null,\n    NumTstTakr INTEGER not null,\n    AvgScrRead INTEGER null,\n    AvgScrMath INTEGER null,\n    AvgScrWrite INTEGER null,\n    NumGE1500 INTEGER null,\n    foreign key (cds) references schools (CDSCode)\n);\n```\n\n----------------------------------------\n\nTITLE: Creating FRPM Table Schema in SQLite\nDESCRIPTION: Creates a table schema for storing Free/Reduced Price Meals program data with various school metrics and foreign key relationship to schools table\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE frpm (\n    CDSCode TEXT not null primary key,\n    `Academic Year` TEXT null,\n    `County Code` TEXT null,\n    `District Code` INTEGER null,\n    `School Code` TEXT null,\n    `County Name` TEXT null,\n    `District Name` TEXT null,\n    `School Name` TEXT null,\n    `District Type` TEXT null,\n    `School Type` TEXT null,\n    `Educational Option Type` TEXT null,\n    `NSLP Provision Status` TEXT null,\n    `Charter School (Y/N)` INTEGER null,\n    `Charter School Number` TEXT null,\n    `Charter Funding Type` TEXT null,\n    IRC INTEGER null,\n    `Low Grade` TEXT null,\n    `High Grade` TEXT null,\n    `Enrollment (K-12)` REAL null,\n    `Free Meal Count (K-12)` REAL null,\n    `Percent (%) Eligible Free (K-12)` REAL null,\n    `FRPM Count (K-12)` REAL null,\n    `Percent (%) Eligible FRPM (K-12)` REAL null,\n    `Enrollment (Ages 5-17)` REAL null,\n    `Free Meal Count (Ages 5-17)` REAL null,\n    `Percent (%) Eligible Free (Ages 5-17)` REAL null,\n    `FRPM Count (Ages 5-17)` REAL null,\n    `Percent (%) Eligible FRPM (Ages 5-17)` REAL null,\n    `2013-14 CALPADS Fall 1 Certification Status` INTEGER null,\n    foreign key (CDSCode) references schools (CDSCode)\n);\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands CLI Mode with Python\nDESCRIPTION: Command to start an interactive OpenHands session via Python and Poetry. This requires following the development setup instructions and configuring the model and API key through environment variables or config file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python -m openhands.core.cli\n```\n\n----------------------------------------\n\nTITLE: Running DiscoveryBench Inference with Advanced Options in Bash\nDESCRIPTION: This command provides more detailed options for running the DiscoveryBench inference, including specifying the model config, git commit, agent type, evaluation limit, and number of workers.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/discoverybench/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/discoverybench/scripts/run_infer.sh [MODEL_CONFIG] [GIT_COMMIT] [AGENT] [EVAL_LIMIT] [NUM_WORKERS]\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic Express.js Server\nDESCRIPTION: Creates a simple Express.js server that listens on port 3000 and responds with 'Hello World' on the root route. Includes basic Express setup, route definition, and server start.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/cases/express/task.txt#2025-04-23_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nconst express = require('express');\nconst app = express();\n\napp.get('/', (req, res) => {\n  res.send('Hello World');\n});\n\napp.listen(3000, () => {\n  console.log('Server is running on port 3000');\n});\n```\n\n----------------------------------------\n\nTITLE: Example BioCoder Evaluation Command\nDESCRIPTION: Specific example of running BioCoder evaluation with GPT-4 model configuration, using CodeActAgent and limiting to 1 instance.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/biocoder/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/biocoder/scripts/run_infer.sh eval_gpt4o_2024_05_13 HEAD CodeActAgent 1\n```\n\n----------------------------------------\n\nTITLE: Defining Combined Test IDs for Xarray in Python\nDESCRIPTION: This snippet defines a comprehensive list of test case IDs for the Xarray project, combining and sorting unique IDs from various testing approaches. It includes IDs from both CodaMOSA and Pynguin, as well as additional IDs.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/NOTES.md#2025-04-23_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nids = ['pydata__xarray-3114-16452', 'pydata__xarray-3151-16453', 'pydata__xarray-3156-16454', 'pydata__xarray-3239-16456', 'pydata__xarray-3239-16457', 'pydata__xarray-3239-16458', 'pydata__xarray-3302-16459', 'pydata__xarray-3364-16461', 'pydata__xarray-3677-16471', 'pydata__xarray-3905-16478', 'pydata__xarray-4182-16484', 'pydata__xarray-4248-16486', 'pydata__xarray-4339-16487', 'pydata__xarray-4419-16488', 'pydata__xarray-4629-16492', 'pydata__xarray-4750-16496', 'pydata__xarray-4802-16505', 'pydata__xarray-4966-16515', 'pydata__xarray-4994-16516', 'pydata__xarray-5033-16517', 'pydata__xarray-5126-16518', 'pydata__xarray-5126-16519', 'pydata__xarray-5131-16520', 'pydata__xarray-5365-16529', 'pydata__xarray-5455-16530', 'pydata__xarray-5662-16532', 'pydata__xarray-5731-16534', 'pydata__xarray-6135-16535', 'pydata__xarray-6135-16536', 'pydata__xarray-6386-16537', 'pydata__xarray-6394-16538', 'pydata__xarray-6400-16539', 'pydata__xarray-6461-16540', 'pydata__xarray-6548-16541', 'pydata__xarray-6599-16543', 'pydata__xarray-6601-16544', 'pydata__xarray-6882-16548', 'pydata__xarray-6889-16549', 'pydata__xarray-7003-16557', 'pydata__xarray-7147-16571', 'pydata__xarray-7150-16572', 'pydata__xarray-7203-16577', 'pydata__xarray-7229-16578', 'pydata__xarray-7393-16581', 'pydata__xarray-7400-16582']\n```\n\n----------------------------------------\n\nTITLE: Configuring VSCode launch.json for OpenHands Debugging\nDESCRIPTION: This configuration allows debugging of the agent, controller, and server elements of OpenHands, excluding the sandbox. It includes settings for both the CLI and WebApp modules.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/debugging.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"OpenHands CLI\",\n            \"type\": \"debugpy\",\n            \"request\": \"launch\",\n            \"module\": \"openhands.core.cli\",\n            \"justMyCode\": false\n        },\n        {\n            \"name\": \"OpenHands WebApp\",\n            \"type\": \"debugpy\",\n            \"request\": \"launch\",\n            \"module\": \"uvicorn\",\n            \"args\": [\n                \"openhands.server.listen:app\",\n                \"--reload\",\n                \"--reload-exclude\",\n                \"${workspaceFolder}/workspace\",\n                \"--port\",\n                \"3000\"\n            ],\n            \"justMyCode\": false\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Docker Client Launch Failure Error Message\nDESCRIPTION: The error message displayed when OpenHands fails to launch the Docker client, indicating that Docker may not be properly installed or running.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nLaunch docker client failed. Please make sure you have installed docker and started docker desktop/daemon.\n```\n\n----------------------------------------\n\nTITLE: Complete Results Summary Example\nDESCRIPTION: Full example command for summarizing results from a specific evaluation output file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/aider_bench/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python ./evaluation/benchmarks/aider_bench/scripts/summarize_results.py evaluation/evaluation_outputs/outputs/AiderBench/CodeActAgent/claude-3-5-sonnet@20240620_maxiter_30_N_v1.9/output.jsonl\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Raw Data from Gzipped JSONL Files in Python\nDESCRIPTION: This code loads raw data from gzipped JSONL files, processes it line by line, and converts it into a pandas DataFrame. It extracts specific fields and handles potential missing data.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/swegym/convert_data.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gzip\nimport json\n\nfrom tqdm import tqdm\n\nFILE_PATHS = [\n    'YOURPATH-no-hint-train-t05-run_1/output.with_completions.jsonl.gz',\n    'YOURPATH-no-hint-train-t05-run_2/output.with_completions.jsonl.gz',\n]\n\n# More memory efficient for large files\n# Initialize lists to store the data\ndata = []\n\n\n# Read file line by line\nfor FILE_PATH in FILE_PATHS:\n    with gzip.open(FILE_PATH, 'rb') as f:  # Use 'rb' for gzipped files\n        for i, line in tqdm(\n            enumerate(f), desc=f\"Processing {FILE_PATH.split('/')[-1]}\"\n        ):\n            # Parse only the fields we need\n            raw_data = json.loads(line)\n            data.append(\n                {\n                    'resolved': raw_data['report']['resolved'],\n                    'messages': raw_data['raw_completions']['messages']\n                    if raw_data['raw_completions'] is not None\n                    else None,\n                    'git_patch': raw_data['test_result'].get('git_patch', ''),\n                    'tools': raw_data['raw_completions']['tools']\n                    if raw_data['raw_completions'] is not None\n                    and 'tools' in raw_data['raw_completions']\n                    else None,\n                }\n            )\n\n# Convert to DataFrame after collecting all data\ndf = pd.DataFrame(data)\nprint(f'#total amount of data={len(df)}')\ndf = df[~df['messages'].isna()]\nprint(f'#total amount of data after removing nan={len(df)}')\n```\n\n----------------------------------------\n\nTITLE: Configuring Secure Network Binding in Docker\nDESCRIPTION: Docker runtime configuration for restricting network interface binding to localhost for enhanced security.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes/docker.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    -e SANDBOX_RUNTIME_BINDING_ADDRESS=127.0.0.1 \\\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Running DiscoveryBench Evaluation Script in Bash\nDESCRIPTION: This command executes a bash script to start the DiscoveryBench evaluation. It requires a model configuration to be specified.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/discoverybench/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/discoverybench/scripts/run_infer.sh [YOUR MODEL CONFIG]\n```\n\n----------------------------------------\n\nTITLE: Running WebArena Inference Evaluation - Bash Script\nDESCRIPTION: Command sequence for setting environment variables and executing the WebArena inference evaluation script. Requires setting the WebArena base URL and OpenAI API key for LLM validators.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/webarena/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport WEBARENA_BASE_URL=<YOUR_SERVER_URL_HERE>\nexport OPENAI_API_KEY=\"yourkey\" # this key is required for some WebArena validators that utilize LLMs\nbash evaluation/benchmarks/webarena/scripts/run_infer.sh\n```\n\n----------------------------------------\n\nTITLE: Example Commit0 Inference Command for Lite Split\nDESCRIPTION: An example bash command demonstrating how to run Commit0 inference on the lite split using specific parameters such as model config, agent type, and evaluation limits.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/commit0/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/commit0/scripts/run_infer.sh lite llm.eval_sonnet HEAD CodeActAgent 16 100 8 wentingzhao/commit0_combined test\n```\n\n----------------------------------------\n\nTITLE: Converting Function Call Messages to Non-Function Call Messages in Python\nDESCRIPTION: This code converts function calling messages to non-function calling messages using custom conversion functions. It handles errors and applies the conversion to the DataFrame, creating new columns for converted and non-function call messages.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/swegym/convert_data.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport copy\n\n# Convert function calling messages to non-function calling messages\nfrom openhands.llm.fn_call_converter import (\n    FunctionCallConversionError,\n    convert_fncall_messages_to_non_fncall_messages,\n    convert_from_multiple_tool_calls_to_single_tool_call_messages,\n)\n\ntotal_failed = 0\n\n\ndef _convert_messages(messages: list[dict], tools: list[dict]) -> list[dict]:\n    global total_failed\n    message_copy = copy.deepcopy(messages)\n    for message in message_copy:\n        if message['content'] is None:\n            message['content'] = ''\n    try:\n        return convert_fncall_messages_to_non_fncall_messages(\n            message_copy, tools, add_in_context_learning_example=False\n        )\n    except FunctionCallConversionError:\n        total_failed += 1\n        # print(f'Failed to convert messages: {messages}\\nTools: {tools}')\n        # traceback.print_exc()\n        return None\n\n\ndf['converted_messages'] = df.apply(\n    lambda row: convert_from_multiple_tool_calls_to_single_tool_call_messages(\n        row['messages'], ignore_final_tool_result=True\n    ),\n    axis=1,\n)\ndf['nonfncall_messages'] = df.apply(\n    lambda row: _convert_messages(row['converted_messages'], row['tools']), axis=1\n)\nprint('total nan', df['nonfncall_messages'].isna().sum())\ndf = df[~df['nonfncall_messages'].isna()]\nprint(f'Total failed: {total_failed}')\n```\n\n----------------------------------------\n\nTITLE: Filtering and Analyzing Tokenized Data in Python\nDESCRIPTION: This code filters the DataFrame based on token count, prints statistics, and generates plots to visualize token distribution. It uses matplotlib and seaborn for data visualization.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/swegym/convert_data.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(f'BEFORE: #total={len(df)}')\ndf_selected = df[df['n_tokens'] < 131072]\nprint(f'AFTER(truncated to 128k): #total={len(df_selected)}')\n\ndf_selected['n_tokens'].describe()\n\n# ecdf of n_tokens\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndisplay(df.groupby(['resolved'])['n_tokens'].describe())\nsns.ecdfplot(x='n_tokens', data=df, hue='resolved')\nplt.show()\n\nprint(f'#total={len(df)}')\ndf_selected = df[df['n_tokens'] < 131072]\nprint(f'#selected={len(df_selected)}')\ndisplay(df_selected.groupby(['resolved'])['n_tokens'].describe())\nsns.ecdfplot(x='n_tokens', data=df_selected, hue='resolved')\nplt.show()\n\ndf_selected[~df_selected['resolved']]['n_tokens'].describe()\n\ndf_selected['resolved'].value_counts()\n\ndf_selected.groupby(['resolved'])['n_tokens'].describe()\n```\n\n----------------------------------------\n\nTITLE: Using OpenHands Issue Label\nDESCRIPTION: Example of how to use the 'openhands' label to trigger automated issue resolution. When applied, OpenHands will comment, create a pull request if successful, and provide a summary.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/cloud/cloud-github-resolver.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n1. Comment on the issue to let you know it is working on it.\n    - You can click on the link to track the progress on OpenHands Cloud.\n2. Open a pull request if it determines that the issue has been successfully resolved.\n3. Comment on the issue with a summary of the performed tasks and a link to the pull request.\n```\n\n----------------------------------------\n\nTITLE: Academic Citation in BibTeX Format\nDESCRIPTION: BibTeX citation entry for the SWE-Gym research paper, including author information, title, year, and arXiv details.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/SWE-Gym.md#2025-04-23_snippet_1\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{pan2024trainingsoftwareengineeringagents,\n      title={Training Software Engineering Agents and Verifiers with SWE-Gym},\n      author={Jiayi Pan and Xingyao Wang and Graham Neubig and Navdeep Jaitly and Heng Ji and Alane Suhr and Yizhe Zhang},\n      year={2024},\n      eprint={2412.21139},\n      archivePrefix={arXiv},\n      primaryClass={cs.SE},\n      url={https://arxiv.org/abs/2412.21139},\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Trigger Configuration in YAML\nDESCRIPTION: YAML configuration that sets up a CodeActAgent to respond when users say 'flarglebargle'. The agent is configured to only respond with messages complimenting the user's intelligence.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/flarglebargle.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\nname: flarglebargle\ntype: knowledge\nversion: 1.0.0\nagent: CodeActAgent\ntriggers:\n- flarglebargle\n---\n```\n\n----------------------------------------\n\nTITLE: Executando Avaliação Completa no OpenHands\nDESCRIPTION: Código para executar o processo de avaliação completo, incluindo a preparação dos metadados, do dataset e a execução da avaliação com múltiplos workers em paralelo.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmetadata = make_metadata(llm_config, dataset_name, agent_class, max_iterations, eval_note, eval_output_dir)\noutput_file = os.path.join(metadata.eval_output_dir, 'output.jsonl')\ninstances = prepare_dataset(your_dataset, output_file, eval_n_limit)\n\nawait run_evaluation(\n    instances,\n    metadata,\n    output_file,\n    num_workers,\n    process_instance\n)\n```\n\n----------------------------------------\n\nTITLE: Running EDA Evaluation with OpenHands\nDESCRIPTION: This bash command exports the OpenAI API key and executes the evaluation script for the Entity-deduction-Arena benchmark. It allows specifying model config, git version, agent, dataset, and evaluation limit.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/EDA/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"sk-XXX\"; # This is required for evaluation (to simulate another party of conversation)\n./evaluation/benchmarks/EDA/scripts/run_infer.sh [model_config] [git-version] [agent] [dataset] [eval_limit]\n```\n\n----------------------------------------\n\nTITLE: Definindo Estrutura de Microagente em YAML e Markdown\nDESCRIPTION: Este snippet demonstra o formato padrão usado para definir microagentes no OpenHands. Inclui um cabeçalho YAML com metadados do microagente e um corpo em Markdown para instruções e diretrizes.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/prompting/microagents-overview.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\nname: <Nome do microagente>\ntype: <Tipo do Microagent>\nversion: <Versão do Microagent>\nagent: <O tipo de agente (normalmente CodeActAgent)>\ntriggers:\n- <Palavras-chave opcionais que acionam o microagente. Se os gatilhos forem removidos, ele sempre será incluído>\n---\n\n<Markdown com quaisquer diretrizes especiais, instruções e prompts que o OpenHands deve seguir.\nConfira a documentação específica para cada microagente sobre as melhores práticas para obter mais informações.>\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands with Custom Docker Image\nDESCRIPTION: This command demonstrates how to run OpenHands using a custom Docker image. It replaces the default sandbox image with the specified custom image.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_BASE_CONTAINER_IMAGE=custom-image \\\n    ...\n```\n\n----------------------------------------\n\nTITLE: Corrected Number Truncation Function in Python\nDESCRIPTION: This snippet shows the corrected implementation of the truncate_number function. The unnecessary addition of 1.0 has been removed to fix the function.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/humanevalfix/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef truncate_number(number: float) -> float:\n    return number % 1.0\n```\n\n----------------------------------------\n\nTITLE: Saving Resolved Messages for Supervised Fine-Tuning in Python\nDESCRIPTION: This code saves the resolved messages from the selected DataFrame to a JSONL file for use in Supervised Fine-Tuning (SFT). It renames the 'nonfncall_messages' column to 'messages' and saves only the resolved entries.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/swegym/convert_data.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf_selected[df_selected['resolved']][['nonfncall_messages']].rename(\n    columns={'nonfncall_messages': 'messages'}\n).to_json(\n    os.path.join(\n        'YOUR_OUTPUT_FOLDER',\n        f'policy_traj_128k_swegym_{df_selected[\"resolved\"].value_counts()[True]}i.jsonl',\n    ),\n    lines=True,\n    orient='records',\n)\n```\n\n----------------------------------------\n\nTITLE: Installing OpenHands Package\nDESCRIPTION: Command to install the OpenHands AI package using pip package manager.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install openhands-ai\n```\n\n----------------------------------------\n\nTITLE: ローカルランタイムを使用した OpenHands の起動 (Bash)\nDESCRIPTION: ヘッドレスモードでローカルランタイムを使用して OpenHands を起動する例です。環境変数を設定し、poetry を使用して OpenHands を実行します。\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/runtimes/local.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# ランタイムタイプをローカルに設定\nexport RUNTIME=local\n\n# オプションでワークスペースディレクトリを設定\nexport WORKSPACE_BASE=/path/to/your/project\n\n# OpenHands を起動\npoetry run python -m openhands.core.main -t \"hi と出力する bash スクリプトを書いてください\"\n```\n\n----------------------------------------\n\nTITLE: Running Inference for Browsing Delegation Evaluation in OpenHands\nDESCRIPTION: This bash command runs the inference for browsing delegation evaluation. It takes parameters for model configuration, git version, agent type, and evaluation limit. The script allows testing of CodeActAgent's ability to delegate browsing tasks to BrowsingAgent.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/browsing_delegation/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/browsing_delegation/scripts/run_infer.sh [model_config] [git-version] [agent] [eval_limit]\n```\n\n----------------------------------------\n\nTITLE: 環境変数を使用したローカルランタイムの設定 (Bash)\nDESCRIPTION: ローカルランタイムを使用するために必要な環境変数を設定します。RUNTIME を 'local' に設定し、オプションで WORKSPACE_BASE を指定します。\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/runtimes/local.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# 必須\nexport RUNTIME=local\n\n# オプションですが推奨\nexport WORKSPACE_BASE=/path/to/your/workspace\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for LM Studio Integration\nDESCRIPTION: Bash commands to set environment variables for integrating LM Studio with OpenHands, specifying the model, base URL, and custom LLM provider.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nLLM_MODEL=\"openai/lmstudio\"\nLLM_BASE_URL=\"http://localhost:1234/v1\"\nCUSTOM_LLM_PROVIDER=\"openai\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Basic File Operations with OpenHands Agent Skills\nDESCRIPTION: Shows how to use the agentskills package to perform basic file operations like opening and editing files through IPythonRunAction. Demonstrates file reading and content replacement functionality.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/plugins/agent_skills/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# In[1]\nfrom agentskills import open_file, edit_file\nopen_file(\"/workspace/a.txt\")\n# Out[1]\n[SWE-agent open output]\n\n# In[2]\nedit_file(\n    \"/workspace/a.txt\",\n    start=1, end=3,\n    content=(\n        (\"REPLACE TEXT\")\n))\n# Out[1]\n[SWE-agent edit output]\n```\n\n----------------------------------------\n\nTITLE: Example Python Task in OpenHands CLI\nDESCRIPTION: Example of a simple Python task request in the OpenHands CLI and its expected output. This demonstrates how to request a Python script that prints 'Hello, World!' and shows the expected response format.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n>> Escreva um script Python que imprima \"Hello, World!\"\n```\n\n----------------------------------------\n\nTITLE: Finding Successful PRs\nDESCRIPTION: Command to search and filter successful pull requests from the output logs.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngrep '\"success\":true' output/output.jsonl | sed 's/.*\\(\"number\":[0-9]*\\).*/\\1/g'\n```\n\n----------------------------------------\n\nTITLE: config.toml を使用したローカルランタイムの設定 (TOML)\nDESCRIPTION: config.toml ファイルを使用してローカルランタイムを設定します。core セクションで runtime を 'local' に設定し、workspace_base を指定します。\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/runtimes/local.md#2025-04-23_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[core]\nruntime = \"local\"\nworkspace_base = \"/path/to/your/workspace\"\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Headless Mode with Python\nDESCRIPTION: This command demonstrates how to run OpenHands in headless mode using Python. It requires following the development setup instructions and uses poetry to execute the main module with a specific task.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/how-to/headless-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python -m openhands.core.main -t \"write a bash script that prints hi\"\n```\n\n----------------------------------------\n\nTITLE: Backend Architecture Diagram Generation Command\nDESCRIPTION: Command for generating the backend architecture diagram using py2puml tool from the repository root directory. The command analyzes the type hints in the codebase to generate a PlantUML diagram.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/architecture/backend.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npy2puml openhands openhands > docs/architecture/backend_architecture.puml\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama Service for External Access\nDESCRIPTION: Systemd service configuration to allow Ollama to accept requests from outside localhost, necessary for Docker container access in WSL environments.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nEnvironment=\"OLLAMA_HOST=0.0.0.0:11434\"\nEnvironment=\"OLLAMA_ORIGINS=*\"\n```\n\n----------------------------------------\n\nTITLE: Running Automatic Translation Update Script\nDESCRIPTION: Bash commands to set the Anthropic API key and run the Python script for updating translations. This process uses the Claude 3 Sonnet model and consumes a significant number of tokens.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ export ANTHROPIC_API_KEY=<your_api_key>\n$ poetry run python docs/translation_updater.py\n```\n\n----------------------------------------\n\nTITLE: Example Bash Command in OpenHands CLI\nDESCRIPTION: Example of requesting a directory creation through the OpenHands CLI. This shows how to formulate a command to create a new directory named 'test_dir'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n>> Crie um diretório chamado \"test_dir\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Pushing GitHub Pull Request using Bash\nDESCRIPTION: A complete sequence of commands to create a new branch, commit changes, push to remote, and create a pull request using GitHub API. Uses GITHUB_TOKEN for authentication and performs the entire operation in a single chain of commands.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/github.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit remote -v && git branch # to find the current org, repo and branch\ngit checkout -b create-widget && git add . && git commit -m \"Create widget\" && git push -u origin create-widget\ncurl -X POST \"https://api.github.com/repos/$ORG_NAME/$REPO_NAME/pulls\" \\\n    -H \"Authorization: Bearer $GITHUB_TOKEN\" \\\n    -d '{\"title\":\"Create widget\",\"head\":\"create-widget\",\"base\":\"openhands-workspace\"}'\n```\n\n----------------------------------------\n\nTITLE: Definindo WORKSPACE_BASE para OpenHands\nDESCRIPTION: Comando para definir a variável de ambiente WORKSPACE_BASE, que especifica o caminho para o código do usuário no sistema de arquivos local.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport WORKSPACE_BASE=/caminho/para/seu/codigo\n\n# Exemplo no Linux e Mac\n# export WORKSPACE_BASE=$HOME/OpenHands\n# Definirá $WORKSPACE_BASE como /home/<username>/OpenHands\n#\n# Exemplo no WSL no Windows\n# export WORKSPACE_BASE=/mnt/c/dev/OpenHands\n# Definirá $WORKSPACE_BASE como C:\\dev\\OpenHands\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenHands Sandbox in config.toml\nDESCRIPTION: This TOML configuration snippet shows how to specify a custom base container image for the OpenHands sandbox in the config.toml file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[core]\n...\n[sandbox]\nbase_container_image=\"custom-image\"\n```\n\n----------------------------------------\n\nTITLE: Definindo Chave de API do Daytona para OpenHands\nDESCRIPTION: Comando para definir a variável de ambiente com a chave de API do Daytona, necessária para autenticação no runtime Daytona.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport DAYTONA_API_KEY=\"<sua-chave-de-api>\"\n```\n\n----------------------------------------\n\nTITLE: Running SWT-Bench Evaluation\nDESCRIPTION: Command to execute the SWT-Bench evaluation harness with converted results\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m src.main \\\n    --dataset_name princeton-nlp/SWE-bench_Verified \\\n    --predictions_path <pathTo>/OpenHands-gpt-4o-2024-11-20.jsonl \\\n    --max_workers 12 \\\n    --run_id OpenHands-CodeAct-gpt-4o-2024-11-20  --patch_types vanilla  --build_mode api\n```\n\n----------------------------------------\n\nTITLE: Building E2B Sandbox from Dockerfile\nDESCRIPTION: Command to build a custom E2B sandbox template named 'openhands' using a specified Dockerfile\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/e2b-sandbox/README.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ne2b template build --dockerfile ./Dockerfile --name \"openhands\"\n```\n\n----------------------------------------\n\nTITLE: Downloading OpenHands LM 32B Model from Huggingface\nDESCRIPTION: This command downloads the OpenHands LM 32B v0.1 model from Huggingface to a local directory using the Huggingface CLI.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/local-llms.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhuggingface-cli download all-hands/openhands-lm-32b-v0.1 --local-dir all-hands/openhands-lm-32b-v0.1\n```\n\n----------------------------------------\n\nTITLE: Message Serialization Selection\nDESCRIPTION: Model serializer that chooses between string and list serialization based on message capabilities like caching, vision, and function calling.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/core/message_format.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@model_serializer\ndef serialize_model(self) -> dict:\n    if self.cache_enabled or self.vision_enabled or self.function_calling_enabled:\n        return self._list_serializer()\n    return self._string_serializer()\n```\n\n----------------------------------------\n\nTITLE: Python Script for Querying Highest Free Meal Rate\nDESCRIPTION: Implements a Python script that connects to SQLite database and executes a query to find the highest eligible free meal rate for K-12 students in Alameda County schools.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\nimport sqlite3\n\ndef execute_sql(db_path, sql):\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        cursor.execute(sql)\n        result = cursor.fetchall()\n        return result\n\nif __name__ == '__main__':\n    sql = \"SELECT MAX(`Free Meal Count (K-12)` / `Enrollment (K-12)`) AS highest_eligible_free_rate FROM frpm JOIN schools ON frpm.CDSCode = schools.CDSCode WHERE `County Name` = 'Alameda'\"\n    db_path = \"california_schools/california_schools.sqlite\"\n    print(db_path)\n    result = execute_sql(db_path, sql)\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Visualizing OpenHands Runtime Architecture with Mermaid Diagram\nDESCRIPTION: A mermaid graph diagram illustrating the flow between user-provided Docker images, the OpenHands backend, runtime container components, and the communication between the agent and the runtime environment. The diagram shows how actions are executed and observations are returned in the isolated container.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/architecture/runtime.md#2025-04-23_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    A[Imagem Docker Personalizada Fornecida pelo Usuário] --> B[Backend do OpenHands]\n    B -->|Constrói| C[Imagem do OH Runtime]\n    C -->|Inicia| D[Executor de Ação]\n    D -->|Inicializa| E[Navegador]\n    D -->|Inicializa| F[Shell Bash]\n    D -->|Inicializa| G[Plugins]\n    G -->|Inicializa| L[Servidor Jupyter]\n\n    B -->|Gera| H[Agente]\n    B -->|Gera| I[EventStream]\n    I <--->|Executa Ação para\n    Obter Observação\n    via API REST\n    | D\n\n    H -->|Gera Ação| I\n    I -->|Obtém Observação| H\n\n    subgraph \"Contêiner Docker\"\n    D\n    E\n    F\n    G\n    L\n    end\n```\n\n----------------------------------------\n\nTITLE: Running Commit0 Inference on RemoteRuntime\nDESCRIPTION: This bash command demonstrates how to run Commit0 inference using a remote runtime. It includes environment variables for API key, runtime type, and Docker image prefix.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/commit0/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nALLHANDS_API_KEY=\"YOUR-API-KEY\" RUNTIME=remote SANDBOX_REMOTE_RUNTIME_API_URL=\"https://runtime.eval.all-hands.dev\" EVAL_DOCKER_IMAGE_PREFIX=\"docker.io/wentingzhao\" \\\n./evaluation/benchmarks/commit0/scripts/run_infer.sh lite llm.eval_sonnet HEAD CodeActAgent 10 30 1 wentingzhao/commit0_combined test\n```\n\n----------------------------------------\n\nTITLE: Inicializando Runtime para Ambiente de Avaliação\nDESCRIPTION: Função para inicializar o ambiente de execução e configurar o ambiente de avaliação no OpenHands, onde podem ser definidas variáveis de ambiente e preparados arquivos necessários.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/evaluation-harness.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef initialize_runtime(runtime: Runtime, instance: pd.Series):\n    # Configure seu ambiente de avaliação aqui\n    # Por exemplo, definindo variáveis de ambiente, preparando arquivos, etc.\n    pass\n```\n\n----------------------------------------\n\nTITLE: VS Code Integration Command Reference\nDESCRIPTION: Reference for the VS Code integration command used to modify and manage files in the workspace\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/key-features.md#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nOpen in VS Code\n```\n\n----------------------------------------\n\nTITLE: Running MiniWoB Evaluation with OpenHands Browsing Agents\nDESCRIPTION: This command runs the evaluation script for the MiniWoB benchmark using a specified LLM configuration. It executes the run_infer.sh script located in the evaluation/benchmarks/miniwob/scripts directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/miniwob/README.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n./evaluation/benchmarks/miniwob/scripts/run_infer.sh llm.claude-35-sonnet-eval\n```\n\n----------------------------------------\n\nTITLE: Finding Similar Elements in Two Tuples using Set Intersection in Python\nDESCRIPTION: This function takes two tuples as input and returns a tuple containing the common elements. It uses set intersection to efficiently find the similar elements.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/tasks/in_context_examples/mbpp/with_tool.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef similar_elements(test_tup1, test_tup2):\n    res = tuple(set(test_tup1) & set(test_tup2))\n    return res\n```\n\n----------------------------------------\n\nTITLE: Python Script Template for Executing SQL Queries\nDESCRIPTION: Provides a Python function to execute SQL queries on a SQLite database and a main block to run the query. The script connects to the database, executes the query, and prints the results.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nimport sqlite3\ndef execute_sql(db_path, sql):\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        cursor.execute(sql)\n        result = cursor.fetchall()\n        return result\n\nif __name__ == '__main__':\n    sql = \"\" # filling your SQL here\n    db_path = \"california_schools/california_schools.sqlite\"\n    print(db_path)\n    result = execute_sql(db_path, sql)\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Generating Runtime Dockerfile with Python and NodeJS\nDESCRIPTION: Command to generate a Dockerfile using nikolaik/python-nodejs as the base image. The script creates necessary runtime files in the containers/runtime directory including the Dockerfile, updated config.sh, and source distribution files.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/runtime/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python3 openhands/runtime/utils/runtime_build.py \\\n    --base_image nikolaik/python-nodejs:python3.12-nodejs22 \\\n    --build_folder containers/runtime\n```\n\n----------------------------------------\n\nTITLE: Creating Directory using OpenHands CLI\nDESCRIPTION: Example of using OpenHands CLI to generate a Bash command for creating a directory named 'test_dir'. Shows the input command and expected output.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n>> \"test_dir\" という名前のディレクトリを作成してください\n```\n\nLANGUAGE: bash\nCODE:\n```\nmkdir test_dir\n```\n\n----------------------------------------\n\nTITLE: Building Custom Docker Image for OpenHands\nDESCRIPTION: This bash command builds a custom Docker image for use with OpenHands. It should be run in the directory containing the Dockerfile.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/custom-sandbox-guide.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t custom-image .\n```\n\n----------------------------------------\n\nTITLE: Listing Installed Ollama Models\nDESCRIPTION: Command to list all Ollama models installed on the system, showing their names, IDs, sizes, and last modified dates.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n~$ ollama list\nNAME                            ID              SIZE    MODIFIED\ncodellama:7b                    8fdf8f752f6e    3.8 GB  6 weeks ago\nmistral:7b-instruct-v0.2-q4_K_M eb14864c7427    4.4 GB  2 weeks ago\nstarcoder2:latest               f67ae0f64584    1.7 GB  19 hours ago\n```\n\n----------------------------------------\n\nTITLE: Scoring ML-Bench Results Command\nDESCRIPTION: Command for generating evaluation scores from ML-Bench output directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/ml_bench/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/ml_bench/scripts/summarise_results.py [eval_output_dir]\n```\n\n----------------------------------------\n\nTITLE: Modifying Python Search Function\nDESCRIPTION: Updates a Python search function to perform a case-insensitive search. The exact implementation would depend on how the search is currently performed.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef search_widgets(query):\n    return [widget for widget in widgets if query.lower() in widget.name.lower()]\n```\n\n----------------------------------------\n\nTITLE: Defining and Testing a Number Truncation Function in Python\nDESCRIPTION: This snippet shows the initial implementation of a function to truncate a number, along with test cases. The function is incorrect and needs to be fixed.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/humanevalfix/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef truncate_number(number: float) -> float:\n    return number % 1.0 + 1.0\n\n\n\n\n\n\ndef check(truncate_number):\n    assert truncate_number(3.5) == 0.5\n    assert abs(truncate_number(1.33) - 0.33) < 1e-6\n    assert abs(truncate_number(123.456) - 0.456) < 1e-6\n\ncheck(truncate_number)\n```\n\n----------------------------------------\n\nTITLE: Using Help Discovery Function in OpenHands Agent Skills\nDESCRIPTION: Demonstrates the help_me function which provides contextual assistance in finding relevant tools for specific tasks. Shows how to discover tools for PDF processing and analysis.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/plugins/agent_skills/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# In[1]\nfrom agentskills import help_me\n\nhelp_me(\"I want to solve a task that involves reading a bunch of PDFs and reason about them\")\n\n# Out[1]\n\"Here are the top skills that may be helpful to you:\n- `pdf_to_text`: [documentation about the tools]\n...\n\"\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands with Quick Start Script\nDESCRIPTION: Command to download and execute the OpenHands quick start script using curl.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/daytona/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbash -i <(curl -sL https://get.daytona.io/openhands)\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Docker Container with Azure Configuration\nDESCRIPTION: This example demonstrates how to run the OpenHands Docker container with the necessary Azure API version configuration. It sets the LLM_API_VERSION environment variable.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/llms/azure-llms.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always \\\n    -e LLM_API_VERSION=\"2023-05-15\"\n    ...\n```\n\n----------------------------------------\n\nTITLE: Running Remote SWE-Bench Evaluation with CodeActAgent\nDESCRIPTION: Shell command for evaluating patches generated by CodeActAgent using Llama model on SWE-bench_Lite test set with parallel processing\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nALLHANDS_API_KEY=\"YOUR-API-KEY\" RUNTIME=remote SANDBOX_REMOTE_RUNTIME_API_URL=\"https://runtime.eval.all-hands.dev\" EVAL_DOCKER_IMAGE_PREFIX=\"us-central1-docker.pkg.dev/evaluation-092424/swe-bench-images\" \\\nevaluation/benchmarks/swe_bench/scripts/eval_infer_remote.sh evaluation/evaluation_outputs/outputs/swe-bench-lite/CodeActAgent/Llama-3.1-70B-Instruct-Turbo_maxiter_30_N_v1.9-no-hint/output.jsonl 16 \"princeton-nlp/SWE-bench_Lite\" \"test\"\n```\n\n----------------------------------------\n\nTITLE: Computing GAIA Evaluation Scores with Python\nDESCRIPTION: Python command to calculate and display statistics from the GAIA evaluation output file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/gaia/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython ./evaluation/benchmarks/gaia/get_score.py --file <path_to/output.json>\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Directory Structure for Tasks Microagents in Markdown\nDESCRIPTION: This snippet presents the recommended directory structure for implementing task microagents in OpenHands. It shows the location of various task-specific .md files within the .openhands/microagents/tasks/ directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-repo.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nyour-repository/\n└── .openhands/\n    └── microagents/\n        └── tasks/\n            └── update_pr_description.md\n            └── address_pr_comments.md\n            └── get_test_to_pass.md\n            └── ...\n        └── knowledge/\n            └── ...\n        └── repo.md\n```\n\n----------------------------------------\n\nTITLE: Finding Similar Elements in Tuples using Set Intersection in Python\nDESCRIPTION: This function takes two tuples of integers as input and returns a tuple containing the common elements. It uses set intersection to efficiently find the similar elements between the two input tuples.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/tasks/in_context_examples/humaneval/with_tool.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef similar_elements(test_tup1: Tuple[int], test_tup2: Tuple[int]) -> Tuple[int]:\n    res = tuple(set(test_tup1) & set(test_tup2))\n    return res\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Directory Structure for Repository Microagents in Markdown\nDESCRIPTION: This snippet illustrates the recommended directory structure for implementing repository-specific microagents in OpenHands. It shows the location of the main repo.md file within the .openhands/microagents/ directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-repo.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nyour-repository/\n└── .openhands/\n    └── microagents/\n        └── repo.md    # Repository-specific instructions\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Docker Container with Azure OpenAI Configuration\nDESCRIPTION: This example demonstrates how to run the OpenHands Docker container with the necessary Azure OpenAI configuration. It includes setting the LLM_API_VERSION environment variable.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/azure-llms.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --pull=always \\\n    -e LLM_API_VERSION=\"2023-05-15\"\n    ...\n```\n\n----------------------------------------\n\nTITLE: Django Docker Image Tags\nDESCRIPTION: List of Docker image tags for Django evaluation environments running on x86_64 architecture. Each tag follows the pattern swebench/sweb.eval.x86_64.django_1776_django-XXXXX:latest where XXXXX is a unique identifier.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nswebench/sweb.eval.x86_64.django_1776_django-12518:latest\nswebench/sweb.eval.x86_64.django_1776_django-12519:latest\nswebench/sweb.eval.x86_64.django_1776_django-12532:latest\n[...truncated for brevity...]\n```\n\n----------------------------------------\n\nTITLE: Resolving Issue with Poetry\nDESCRIPTION: Command to resolve an issue when OpenHands is installed from source using Poetry package manager.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python openhands/resolver/resolve_issue.py --selected-repo all-hands-ai/openhands --issue-number 100\n```\n\n----------------------------------------\n\nTITLE: Pulling BioCoder Docker Image\nDESCRIPTION: Command to pull the BioCoder evaluation Docker image from AWS ECR repository. This image contains testing scripts and dependencies required for evaluation.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/biocoder/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull public.ecr.aws/i5g0m1f6/eval_biocoder:v1.0\n```\n\n----------------------------------------\n\nTITLE: Linking to Microagent Syntax and Best Practices in Markdown\nDESCRIPTION: These code snippets provide Markdown links to the microagents syntax documentation and best practices within the OpenHands project.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-public.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n[syntax](./microagents-syntax.md)\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[best practices](./microagents-syntax.md#markdown-content-best-practices)\n```\n\n----------------------------------------\n\nTITLE: Creating React TODO List Component\nDESCRIPTION: This code snippet demonstrates how to create a basic TODO list component in React. It includes state management for tasks, functions to add and remove tasks, and rendering of the task list.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/cases/react-todo/task.txt#2025-04-23_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport React, { useState } from 'react';\n\nfunction TodoList() {\n  const [tasks, setTasks] = useState([]);\n  const [input, setInput] = useState('');\n\n  const addTask = () => {\n    if (input) {\n      setTasks([...tasks, input]);\n      setInput('');\n    }\n  };\n\n  const removeTask = (index) => {\n    const newTasks = tasks.filter((_, i) => i !== index);\n    setTasks(newTasks);\n  };\n\n  return (\n    <div>\n      <h1>TODO List</h1>\n      <input\n        type=\"text\"\n        value={input}\n        onChange={(e) => setInput(e.target.value)}\n        placeholder=\"Enter a task\"\n      />\n      <button onClick={addTask}>Add Task</button>\n      <ul>\n        {tasks.map((task, index) => (\n          <li key={index}>\n            {task}\n            <button onClick={() => removeTask(index)}>Remove</button>\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\nexport default TodoList;\n```\n\n----------------------------------------\n\nTITLE: Building OpenHands Documentation for Production\nDESCRIPTION: Command to generate static content for all language versions of the documentation, ready for deployment to a static hosting service.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ yarn build\n```\n\n----------------------------------------\n\nTITLE: Setting Up WSL Networking Mode\nDESCRIPTION: Python and WSL commands to configure the networking mode to mirrored in WSL, which may be necessary for proper network connectivity in some setups.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npython -c  \"print('[wsl2]\\nnetworkingMode=mirrored',file=open(r'%UserProfile%\\.wslconfig','w'))\"\nwsl --shutdown\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags for SymPy Evaluation\nDESCRIPTION: Collection of Docker image references for SymPy evaluations on x86_64 architecture. Each image is tagged as 'latest' and follows the pattern 'swebench/sweb.eval.x86_64.sympy_1776_sympy-{ID}'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_7\n\nLANGUAGE: docker\nCODE:\n```\nswebench/sweb.eval.x86_64.sympy_1776_sympy-13369:latest\nswebench/sweb.eval.x86_64.sympy_1776_sympy-13372:latest\nswebench/sweb.eval.x86_64.sympy_1776_sympy-13429:latest\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Local Development\nDESCRIPTION: Commands to set required environment variables for running OpenHands locally without Docker.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/daytona/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport RUNTIME=\"daytona\"\nexport DAYTONA_API_KEY=\"<your-api-key>\"\n```\n\n----------------------------------------\n\nTITLE: Installing TestGenEval Dependencies with Poetry\nDESCRIPTION: Command to install the required dependencies for TestGenEval using Poetry package manager.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry install --with testgeneval\n```\n\n----------------------------------------\n\nTITLE: Pulling Ollama Models\nDESCRIPTION: Command to pull a specific Ollama model (codellama:7b) for use with OpenHands. This step is necessary to have the model available locally.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nollama pull codellama:7b\n```\n\n----------------------------------------\n\nTITLE: Fetching and Displaying Random Numbers with React\nDESCRIPTION: This React component fetches a random number from the API and displays it. It uses the 'useState' and 'useEffect' hooks to manage state and side effects, and the Fetch API to make HTTP requests.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/cases/client-server/task.txt#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport React, { useState, useEffect } from 'react';\n\nfunction RandomNumber() {\n  const [number, setNumber] = useState(null);\n\n  useEffect(() => {\n    fetchRandomNumber();\n  }, []);\n\n  const fetchRandomNumber = async () => {\n    try {\n      const response = await fetch('http://localhost:3000/random');\n      const data = await response.json();\n      setNumber(data.number);\n    } catch (error) {\n      console.error('Error fetching random number:', error);\n    }\n  };\n\n  return (\n    <div>\n      <h1>Random Number: {number}</h1>\n      <button onClick={fetchRandomNumber}>Get Next Number</button>\n    </div>\n  );\n}\n\nexport default RandomNumber;\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests and Managing Dependencies\nDESCRIPTION: Commands for executing unit tests and updating project dependencies using Poetry.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/Development.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry run pytest ./tests/unit/test_*.py\n```\n\n----------------------------------------\n\nTITLE: ML-Bench Evaluation Output Example\nDESCRIPTION: Sample JSON output showing the structure of ML-Bench evaluation results, including instance details, history, metrics, and execution information.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/ml_bench/README.md#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"instance_id\": 3,\n  \"repo\": \"https://github.com/dmlc/dgl\",\n  \"instruction\": \"Please complete the Machine Learning task in the following repository: dgl\\n\\nThe task is: DGL Implementation of NGCF model\\n\\nI have a deep desire to embark on a journey brimming with knowledge and expertise. My objective is to train a cutting-edge NGCF Model, known for its unparalleled capabilities, on the illustrious dataset known as gowalla. To ensure swift execution, I kindly request your assistance in crafting the code, making use of the powerful GPU #3 and an embedding size of 32. Can you lend a helping hand to transform this dream into a reality?\\n\\nYou should create a script named `run.sh` under the specified path in the repo to run the task.\\n\\nYou can find the task repo at: /workspace/dgl/examples/pytorch/NGCF/NGCF\\n\\nYou should terminate the subprocess after running the task (e.g., call subprocess.Popen(args).wait()).When you think you have completed the task, please finish the interaction using the \\\"finish\\\" tool.\\n\",\n  \"metadata\": {\n    \"agent_class\": \"CodeActAgent\",\n    \"model_name\": \"gpt-4-1106-preview\",\n    \"max_iterations\": 10,\n    \"eval_output_dir\": \"evaluation/evaluation_outputs/outputs/ml_bench/CodeActAgent/gpt-4-1106-preview_maxiter_10_N_v1.5\",\n    \"start_time\": \"2024-05-26 17:39:59\",\n    \"git_commit\": \"dd8ee9044a94a213dc2e31d2085dbf2924ee80a1\"\n  },\n  \"history\": [\n    [\n      {\n        \"id\": 0,\n        \"timestamp\": \"2024-05-26T17:40:41.060009\",\n        \"source\": \"user\",\n        \"message\": \"Please complete the Machine Learning task in the following repository: dgl\\n\\nThe task is: DGL Implementation of NGCF model\\n\\nI have a deep desire to embark on a journey brimming with knowledge and expertise. My objective is to train a cutting-edge NGCF Model, known for its unparalleled capabilities, on the illustrious dataset known as gowalla. To ensure swift execution, I kindly request your assistance in crafting the code, making use of the powerful GPU #3 and an embedding size of 32. Can you lend a helping hand to transform this dream into a reality?\\n\\nYou should create a script named `run.sh` under the specified path in the repo to run the task.\\n\\nYou can find the task repo at: /workspace/dgl/examples/pytorch/NGCF/NGCF\\n\\nYou should terminate the subprocess after running the task (e.g., call subprocess.Popen(args).wait()).When you think you have completed the task, please finish the interaction using the \\\"finish\\\" tool.\\n\",\n        \"action\": \"message\",\n        \"args\": {\n          \"content\": \"Please complete the Machine Learning task in the following repository: dgl\\n\\nThe task is: DGL Implementation of NGCF model\\n\\nI have a deep desire to embark on a journey brimming with knowledge and expertise. My objective is to train a cutting-edge NGCF Model, known for its unparalleled capabilities, on the illustrious dataset known as gowalla. To ensure swift execution, I kindly request your assistance in crafting the code, making use of the powerful GPU #3 and an embedding size of 32. Can you lend a helping hand to transform this dream into a reality?\\n\\nYou should create a script named `run.sh` under the specified path in the repo to run the task.\\n\\nYou can find the task repo at: /workspace/dgl/examples/pytorch/NGCF/NGCF\\n\\nYou should terminate the subprocess after running the task (e.g., call subprocess.Popen(args).wait()).When you think you have completed the task, please finish the interaction using the \\\"finish\\\" tool.\\n\",\n          \"wait_for_response\": false\n        }\n      },\n      {\n        \"message\": \"No observation\",\n        \"observation\": \"null\",\n        \"content\": \"\",\n        \"extras\": {}\n      }\n    ]\n  ],\n  \"eval_exit_code\": 124,\n  \"eval_output\": \"\",\n  \"eval_script\": \"pip install Matplotlib==2.2.2\\r\\ncd /workspace/dgl/examples/pytorch/dgmg\\r\\npython main.py\",\n  \"metrics\": {\n    \"success\": 1\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Container Image Tag List\nDESCRIPTION: List of container image tags for scikit-learn and sphinx-doc packages showing version numbers for x86_64 architecture evaluation builds. Each entry follows the format sweb.eval.x86_64.[package]_s_[package]-[version]:latest.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nsweb.eval.x86_64.scikit-learn_s_scikit-learn-12760:latest\nsweb.eval.x86_64.scikit-learn_s_scikit-learn-12827:latest\nsweb.eval.x86_64.scikit-learn_s_scikit-learn-12834:latest\n[...truncated for brevity...]\nsweb.eval.x86_64.sphinx-doc_s_sphinx-9155:latest\n```\n\n----------------------------------------\n\nTITLE: Configurando Runtime Docker para OpenHands\nDESCRIPTION: Comando Docker para executar o OpenHands com um runtime baseado em Docker, incluindo a especificação da imagem do container e a montagem do socket do Docker.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Test Suite\nDESCRIPTION: Command to execute the test suite using pytest to run all test files matching the pattern test_*.py.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/prompts/repo_instructions/all-hands-ai___openhands-resolver.txt#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry run pytest tests/test_*.py\n```\n\n----------------------------------------\n\nTITLE: Testing Ollama API Access\nDESCRIPTION: Curl command to test API access to Ollama, generating a response from a specified model. This is useful for verifying Ollama's functionality and accessibility.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://localhost:11434/api/generate -d '{\"model\":\"[NAME]\",\"prompt\":\"hi\"}'\n```\n\n----------------------------------------\n\nTITLE: Splitting PHP Function\nDESCRIPTION: Demonstrates splitting a single PHP function into two separate functions for better modularity. The exact implementation would depend on the original function's content.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_7\n\nLANGUAGE: php\nCODE:\n```\nfunction build_widgets() {\n  // Logic to build widgets\n}\n\nfunction deploy_widgets() {\n  // Logic to deploy widgets\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Swift to System PATH\nDESCRIPTION: Commands to add Swift to the system PATH by modifying the .bashrc file. This ensures Swift commands are accessible from any directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/swift-linux.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\necho 'export PATH=/workspace/swift-6.0.3-RELEASE-debian12/usr/bin:$PATH' >> ~/.bashrc\nsource ~/.bashrc\n```\n\n----------------------------------------\n\nTITLE: Installing E2B CLI via NPM\nDESCRIPTION: Command to install the E2B Command Line Interface globally using NPM package manager.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/e2b/README.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpm install -g @e2b/cli@latest\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags for SymPy Evaluation\nDESCRIPTION: Docker image tag list for x86_64 SymPy evaluation containers. Each tag represents a different version of the SymPy container, with version numbers ranging from 22098 to 24909.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_3\n\nLANGUAGE: docker\nCODE:\n```\nsweb.eval.x86_64.sympy_s_sympy-22098:latest\nsweb.eval.x86_64.sympy_s_sympy-22098:latest\nsweb.eval.x86_64.sympy_s_sympy-22236:latest\nsweb.eval.x86_64.sympy_s_sympy-22383:latest\nsweb.eval.x86_64.sympy_s_sympy-22402:latest\nsweb.eval.x86_64.sympy_s_sympy-22456:latest\nsweb.eval.x86_64.sympy_s_sympy-22706:latest\nsweb.eval.x86_64.sympy_s_sympy-22714:latest\nsweb.eval.x86_64.sympy_s_sympy-22740:latest\nsweb.eval.x86_64.sympy_s_sympy-22914:latest\nsweb.eval.x86_64.sympy_s_sympy-22934:latest\nsweb.eval.x86_64.sympy_s_sympy-22969:latest\nsweb.eval.x86_64.sympy_s_sympy-23021:latest\nsweb.eval.x86_64.sympy_s_sympy-23117:latest\nsweb.eval.x86_64.sympy_s_sympy-23141:latest\nsweb.eval.x86_64.sympy_s_sympy-23191:latest\nsweb.eval.x86_64.sympy_s_sympy-23262:latest\nsweb.eval.x86_64.sympy_s_sympy-23296:latest\nsweb.eval.x86_64.sympy_s_sympy-23413:latest\nsweb.eval.x86_64.sympy_s_sympy-23534:latest\nsweb.eval.x86_64.sympy_s_sympy-23560:latest\nsweb.eval.x86_64.sympy_s_sympy-23729:latest\nsweb.eval.x86_64.sympy_s_sympy-23824:latest\nsweb.eval.x86_64.sympy_s_sympy-23950:latest\nsweb.eval.x86_64.sympy_s_sympy-24066:latest\nsweb.eval.x86_64.sympy_s_sympy-24102:latest\nsweb.eval.x86_64.sympy_s_sympy-24152:latest\nsweb.eval.x86_64.sympy_s_sympy-24213:latest\nsweb.eval.x86_64.sympy_s_sympy-24325:latest\nsweb.eval.x86_64.sympy_s_sympy-24370:latest\nsweb.eval.x86_64.sympy_s_sympy-24443:latest\nsweb.eval.x86_64.sympy_s_sympy-24455:latest\nsweb.eval.x86_64.sympy_s_sympy-24539:latest\nsweb.eval.x86_64.sympy_s_sympy-24562:latest\nsweb.eval.x86_64.sympy_s_sympy-24661:latest\nsweb.eval.x86_64.sympy_s_sympy-24723:latest\nsweb.eval.x86_64.sympy_s_sympy-24909:latest\n```\n\n----------------------------------------\n\nTITLE: Listing E2B Sandboxes\nDESCRIPTION: CLI command to list all running E2B sandboxes associated with the current API key.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/e2b/README.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ne2b sandbox list\n```\n\n----------------------------------------\n\nTITLE: Building Frontend Dependencies\nDESCRIPTION: Commands to build the frontend code distribution required for the server\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/server/README.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ncd frontend\nnpm install\nnpm run build\ncd ..\n```\n\n----------------------------------------\n\nTITLE: Calculating Success Rate for VisualWebArena Evaluation\nDESCRIPTION: This shell command runs a Python script to calculate the success rate of the VisualWebArena evaluation based on the output JSON file. It requires the path to the output file generated during the evaluation process.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/visualwebarena/README.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npoetry run python evaluation/benchmarks/visualwebarena/get_success_rate.py evaluation/evaluation_outputs/outputs/visualwebarena/SOME_AGENT/EXP_NAME/output.jsonl\n```\n\n----------------------------------------\n\nTITLE: Filtering Messages with Multiple Tool Calls in Python\nDESCRIPTION: This function checks if a message contains multiple tool calls and applies it to the DataFrame to create a new column. It then displays a summary of resolved messages grouped by this new column.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/swegym/convert_data.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef _contains_multiple_tool_calls(messages: list[dict]) -> bool:\n    return any(\n        message.get('tool_calls') and len(message['tool_calls']) > 1\n        for message in messages\n    )\n\n\ndf['contains_multiple_tool_calls'] = df['messages'].apply(_contains_multiple_tool_calls)\ndisplay(df.groupby(['contains_multiple_tool_calls'])['resolved'].sum())\n```\n\n----------------------------------------\n\nTITLE: Removing OpenHands Runtime Images\nDESCRIPTION: A Docker command to remove all images with names prefixed by 'openhands-runtime-'. This step helps in resolving Docker image build errors by clearing potentially corrupted or outdated images.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker rmi $(docker images --filter name=openhands-runtime- -q --no-trunc)\n```\n\n----------------------------------------\n\nTITLE: Connecting to E2B Sandbox\nDESCRIPTION: CLI command to connect to a specific running E2B sandbox using its sandbox ID.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/e2b/README.md#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ne2b sandbox connect <sandbox-id>\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags List\nDESCRIPTION: Collection of Docker image tags for SWEBench evaluation containers, primarily focused on Astropy and Django projects. Each tag follows the pattern 'swebench/sweb.eval.x86_64.[project]_1776_[project]-[id]:latest'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-verified-instance-images.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nswebench/sweb.eval.x86_64.astropy_1776_astropy-12907:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-13033:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-13236:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-13398:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-13453:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-13579:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-13977:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14096:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14182:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14309:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14365:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14369:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14508:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14539:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14598:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14995:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-7166:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-7336:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-7606:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-7671:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-8707:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-8872:latest\nswebench/sweb.eval.x86_64.django_1776_django-10097:latest\n[...]\n```\n\n----------------------------------------\n\nTITLE: Converting Results to SWT-Bench Format\nDESCRIPTION: Python command to convert evaluation results to SWT-Bench harness format\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython3 evaluation/benchmarks/swe_bench/scripts/swtbench/convert.py --prediction_file \"evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/gpt-4o-2024-11-20_maxiter_100_N_v0.31.0-no-hint-swt-run_1/output.jsonl\" > OpenHands-gpt-4o-2024-11-20.jsonl\n```\n\n----------------------------------------\n\nTITLE: Repository-Specific Microagents Structure\nDESCRIPTION: Demonstrates the directory structure for repository-specific microagents, including private instructions and custom agents.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/README.md#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nyour-repository/\n└── .openhands/\n    └── microagents/\n        └── repo.md    # Repository-specific instructions\n        └── knowledges/  # Private micro-agents that are only available inside this repo\n        └── tasks/       # Private micro-agents that are only available inside this repo\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Remote Runtime Resources\nDESCRIPTION: Script to clean up all existing runtime instances\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nALLHANDS_API_KEY=\"YOUR-API-KEY\" ./evaluation/utils/scripts/cleanup_remote_runtime.sh\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Data Processing in Python\nDESCRIPTION: This snippet imports necessary Python libraries for data processing, including pandas for data manipulation and tqdm for progress bars.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/swegym/convert_data.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport pandas as pd\nfrom tqdm import tqdm\n\ntqdm.pandas()\n```\n\n----------------------------------------\n\nTITLE: Setting OpenHands Version Environment Variable\nDESCRIPTION: Command to set the OpenHands version as an environment variable for deployment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/daytona/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENHANDS_VERSION=\"<openhands-release>\"\n```\n\n----------------------------------------\n\nTITLE: Evaluating Generated Tests\nDESCRIPTION: Command for evaluating the generated tests using the eval_infer.sh script. Includes example usage with optional parameters.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/testgeneval/scripts/eval_infer.sh $YOUR_OUTPUT_JSONL [instance_id] [dataset_name] [split] [num_workers] [skip_mutation]\n\n# Example\n./evaluation/benchmarks/testgeneval/scripts/eval_infer.sh evaluation/evaluation_outputs/outputs/kjain14__testgenevallite-test/CodeActAgent/gpt-4-1106-preview_maxiter_50_N_v1.0/output.jsonl\n```\n\n----------------------------------------\n\nTITLE: litellm Message Class Structure\nDESCRIPTION: Reference implementation of litellm's Message class showing its simpler structure with basic content types and tool support.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/core/message_format.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Message(OpenAIObject):\n    content: str | None\n    role: Literal[\"assistant\", \"user\", \"system\", \"tool\", \"function\"]\n    tool_calls: List[ChatCompletionMessageToolCall] | None\n    function_call: FunctionCall | None\n    audio: ChatCompletionAudioResponse | None = None\n```\n\n----------------------------------------\n\nTITLE: Generating SWT-Bench Evaluation Report\nDESCRIPTION: Command to generate evaluation report from SWT-Bench results\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/README.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython -m src.report run_instance_swt_logs/OpenHands-CodeAct-gpt-4o-2024-11-20/OpenHands__CodeActAgent__gpt-4o-2024-11-20 --dataset verified\n```\n\n----------------------------------------\n\nTITLE: Python Project Structure for DiscoveryBench Evaluation\nDESCRIPTION: File structure and organization of the DiscoveryBench evaluation utilities, including modules for hypothesis evaluation, LM utilities, OpenAI helpers, semantic generation prompts, and response parsing.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/discoverybench/eval_utils/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- eval_w_subhypo_gen.py: Implements the DiscoveryBench logic for evaluating agent-generated hypotheses.\n- lm_utils.py: Provides utility functions necessary for the evaluation process.\n- openai_helpers.py: Includes helper functions for OpenAI-related tasks.\n- openai_semantic_gen_prompts.py: Contains prompts used for semantic generation.\n- response_parser.py: Handles the parsing of agent-generated hypotheses.\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Remote Runtime for Commit0 Evaluation\nDESCRIPTION: This bash command cleans up all existing remote runtimes that have been started for Commit0 evaluation. It requires an API key for authentication.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/commit0/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nALLHANDS_API_KEY=\"YOUR-API-KEY\" ./evaluation/utils/scripts/cleanup_remote_runtime.sh\n```\n\n----------------------------------------\n\nTITLE: Example Output for Python Task in OpenHands CLI\nDESCRIPTION: Expected output from OpenHands CLI for a request to create a simple Python script. The output includes the AI's response with a Python code snippet to print 'Hello, World!'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n🤖 Claro! Aqui está um script Python que imprime \"Hello, World!\":\n\n❯ print(\"Hello, World!\")\n```\n\n----------------------------------------\n\nTITLE: Python SQLite Query Template\nDESCRIPTION: Template for executing SQL queries against the California schools SQLite database with basic connection handling and result fetching\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nimport sqlite3\ndef execute_sql(db_path, sql):\n    with sqlite3.connect(db_path) as conn:\n        cursor = conn.cursor()\n        cursor.execute(sql)\n        result = cursor.fetchall()\n        return result\n\nif __name__ == '__main__':\n    sql = \"\" # filling your SQL here\n    db_path = \"california_schools/california_schools.sqlite\"\n    print(db_path)\n    result = execute_sql(db_path, sql)\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Installing KIND on Debian/Ubuntu\nDESCRIPTION: Commands to download, make executable, and install the KIND binary on a Debian/Ubuntu system. Requires Docker to be pre-installed on the system.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/kubernetes.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Download KIND binary\ncurl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.22.0/kind-linux-amd64\n# Make it executable\nchmod +x ./kind\n# Move to a directory in your PATH\nsudo mv ./kind /usr/local/bin/\n```\n\n----------------------------------------\n\nTITLE: Defining Repository Paths for Public Microagents in Markdown\nDESCRIPTION: These code snippets define the repository paths for knowledge and task microagents in the OpenHands project. They use Markdown link syntax to provide clickable links to the respective directories on GitHub.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-public.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[`microagents/knowledge/`](https://github.com/All-Hands-AI/OpenHands/tree/main/microagents/knowledge)\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[`microagents/tasks/`](https://github.com/All-Hands-AI/OpenHands/tree/main/microagents/tasks)\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Embeddings for OpenHands\nDESCRIPTION: This snippet shows the environment variables that need to be set when running OpenHands to use Azure OpenAI for embeddings. It includes setting the embedding model, deployment name, and API version.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/llms/azure-llms.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nLLM_EMBEDDING_MODEL=\"azureopenai\"\nLLM_EMBEDDING_DEPLOYMENT_NAME=\"<your-embedding-deployment-name>\"   # 例如 \"TextEmbedding...<etc>\"\nLLM_API_VERSION=\"<api-version>\"                                    # 例如 \"2024-02-15-preview\"\n```\n\n----------------------------------------\n\nTITLE: Stopping Running OpenHands Runtime Containers\nDESCRIPTION: A Docker command to stop all running containers with names prefixed by 'openhands-runtime-'. This is part of the troubleshooting process for Docker image build errors.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker ps --filter name=openhands-runtime- --filter status=running -aq | xargs docker stop\n```\n\n----------------------------------------\n\nTITLE: Starting the WebSocket Server\nDESCRIPTION: Command to start the Uvicorn server with hot reload on port 3000\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/server/README.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nuvicorn openhands.server.listen:app --reload --port 3000\n```\n\n----------------------------------------\n\nTITLE: Running Individual Unit Test with Poetry\nDESCRIPTION: Command to execute a specific unit test case (test_coder_agent_with_summary) from a test file using Poetry and Pytest.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/tests/unit/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry run pytest ./tests/unit/test_micro_agents.py::test_coder_agent_with_summary\n```\n\n----------------------------------------\n\nTITLE: Creating Schools Table Schema in SQLite\nDESCRIPTION: Creates a comprehensive table schema for storing California school information including location, contact details, administrative information and school characteristics\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE schools (\n    CDSCode TEXT not null primary key,\n    NCESDist TEXT null,\n    NCESSchool TEXT null,\n    StatusType TEXT not null,\n    County TEXT not null,\n    District TEXT not null,\n    School TEXT null,\n    Street TEXT null,\n    StreetAbr TEXT null,\n    City TEXT null,\n    Zip TEXT null,\n    State TEXT null,\n    MailStreet TEXT null,\n    MailStrAbr TEXT null,\n    MailCity TEXT null,\n    MailZip TEXT null,\n    MailState TEXT null,\n    Phone TEXT null,\n    Ext TEXT null,\n    Website TEXT null,\n    OpenDate DATE null,\n    ClosedDate DATE null,\n    Charter INTEGER null,\n    CharterNum TEXT null,\n    FundingType TEXT null,\n    DOC TEXT not null,\n    DOCType TEXT not null,\n    SOC TEXT null,\n    SOCType TEXT null,\n    EdOpsCode TEXT null,\n    EdOpsName TEXT null,\n    EILCode TEXT null,\n    EILName TEXT null,\n    GSoffered TEXT null,\n    GSserved TEXT null,\n    Virtual TEXT null,\n    Magnet INTEGER null,\n    Latitude REAL null,\n    Longitude REAL null,\n    AdmFName1 TEXT null,\n    AdmLName1 TEXT null,\n    AdmEmail1 TEXT null,\n    AdmFName2 TEXT null,\n    AdmLName2 TEXT null,\n    AdmEmail2 TEXT null,\n    AdmFName3 TEXT null,\n    AdmLName3 TEXT null,\n    AdmEmail3 TEXT null,\n    LastUpdate DATE not null\n);\n```\n\n----------------------------------------\n\nTITLE: Automating npm Install Confirmations with Unix 'yes' Command\nDESCRIPTION: This snippet demonstrates how to use the Unix 'yes' command to automatically confirm npm install actions when an interactive shell is not available. This approach is useful in automated environments or when direct user input is not possible.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/npm.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyes | npm install <package-name>\n```\n\n----------------------------------------\n\nTITLE: Docker Container Shell Prompt for OpenHands Development\nDESCRIPTION: Example of the shell prompt inside the Docker container after successful build and run of the OpenHands development environment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/dev/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nBuild and run in Docker ...\nroot@93fc0005fcd2:/app#\n```\n\n----------------------------------------\n\nTITLE: Setting Azure OpenAI API Version for OpenHands\nDESCRIPTION: This snippet shows how to set the LLM_API_VERSION environment variable when running OpenHands. It uses a more recent API version and is part of the Azure OpenAI configuration process.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/llms/azure-llms.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nLLM_API_VERSION=\"<api-version>\"                                    # e.g. \"2024-02-15-preview\"\n```\n\n----------------------------------------\n\nTITLE: Docker Runtime Build Error Message\nDESCRIPTION: An error message that appears in logs when attempting to start a new session, indicating invalid signatures when accessing debian-security repositories.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndebian-security bookworm-security\nInRelease At least one invalid signature was encountered.\n```\n\n----------------------------------------\n\nTITLE: Starting OpenHands Mock Server - Python\nDESCRIPTION: Command to start the mock server after installing dependencies. The server will listen for incoming connections and reply to all received messages from the frontend.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/server/mock/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npython listen.py\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Verbose Output\nDESCRIPTION: Command to run tests with increased verbosity using the -v flag with Poetry and Pytest.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/tests/unit/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npoetry run pytest -v ./tests/unit/test_micro_agents.py\n```\n\n----------------------------------------\n\nTITLE: Creating Schools Master Table in SQLite\nDESCRIPTION: Creates the main schools table containing comprehensive school information including location details, contact information, administrative data, and various classification codes. Serves as the primary reference table with CDSCode as primary key.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_9\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE schools\n(\n    CDSCode     TEXT not null\n        primary key,\n    NCESDist    TEXT  null,\n    NCESSchool  TEXT  null,\n    StatusType  TEXT  not null,\n    County      TEXT not null,\n    District    TEXT not null,\n    School      TEXT null,\n    Street      TEXT null,\n    StreetAbr   TEXT null,\n    City        TEXT null,\n    Zip         TEXT null,\n    State       TEXT  null,\n    MailStreet  TEXT null,\n    MailStrAbr  TEXT null,\n    MailCity    TEXT null,\n    MailZip     TEXT null,\n    MailState   TEXT  null,\n    Phone       TEXT null,\n    Ext         TEXT  null,\n    Website     TEXT null,\n    OpenDate    DATE        null,\n    ClosedDate  DATE        null,\n    Charter     INTEGER    null,\n    CharterNum  TEXT  null,\n    FundingType TEXT null,\n    DOC         TEXT  not null,\n    DOCType     TEXT not null,\n    SOC         TEXT  null,\n    SOCType     TEXT null,\n    EdOpsCode   TEXT  null,\n    EdOpsName   TEXT null,\n    EILCode     TEXT  null,\n    EILName     TEXT null,\n    GSoffered   TEXT null,\n    GSserved    TEXT  null,\n    Virtual     TEXT  null,\n    Magnet      INTEGER   null,\n    Latitude    REAL      null,\n    Longitude   REAL      null,\n    AdmFName1   TEXT null,\n    AdmLName1   TEXT null,\n    AdmEmail1   TEXT null,\n    AdmFName2   TEXT null,\n    AdmLName2   TEXT null,\n    AdmEmail2   TEXT null,\n    AdmFName3   TEXT  null,\n    AdmLName3   TEXT null,\n    AdmEmail3   TEXT null,\n    LastUpdate  DATE        not null\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM in TOML for OpenHands (Pre-0.8.0)\nDESCRIPTION: Example of LLM configuration in config.toml before version 0.8.0. This structure is no longer supported in the new version.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/upgrade-guide.md#2025-04-23_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[gpt-4o]\nmodel=\"gpt-4o\"\napi_key=\"<your_api_key>\"\n```\n\n----------------------------------------\n\nTITLE: Uploading Pull Requests\nDESCRIPTION: Commands to upload pull requests, including options for creating draft PRs and uploading to forks.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython -m openhands.resolver.send_pull_request --issue-number ISSUE_NUMBER --username YOUR_GITHUB_OR_GITLAB_USERNAME --pr-type draft\n\npython -m openhands.resolver.send_pull_request --issue-number ISSUE_NUMBER --username YOUR_GITHUB_OR_GITLAB_USERNAME --pr-type draft --fork-owner YOUR_GITHUB_OR_GITLAB_USERNAME\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Reward for MiniWoB Evaluation\nDESCRIPTION: This command runs a Python script to calculate the average reward from the evaluation output. It uses the get_success_rate.py script and takes the path to the output.jsonl file as an argument.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/miniwob/README.md#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\npoetry run python evaluation/benchmarks/miniwob/get_success_rate.py evaluation/evaluation_outputs/outputs/miniwob/SOME_AGENT/EXP_NAME/output.jsonl\n```\n\n----------------------------------------\n\nTITLE: Starting Docker in Container Environments without Systemd\nDESCRIPTION: Bash commands to start Docker daemon in the background and wait for it to initialize. This is useful in container environments that don't have systemd available.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/docker.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Start Docker daemon in the background\nsudo dockerd > /tmp/docker.log 2>&1 &\n\n# Wait for Docker to initialize\nsleep 5\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for OpenHands Documentation\nDESCRIPTION: Commands to navigate to the docs directory and install required dependencies using Yarn.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ cd docs\n$ yarn\n```\n\n----------------------------------------\n\nTITLE: Running ML-Bench Error Analysis\nDESCRIPTION: Command for performing error analysis on ML-Bench evaluation results using specified output directory and model configuration.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/ml_bench/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./evaluation/benchmarks/ml_bench/scripts/run_analysis.sh [eval_output_dir] [model_config]\n```\n\n----------------------------------------\n\nTITLE: OpenHands Iteration Process JSON Example\nDESCRIPTION: This JSON object represents the complete process of OpenHands fixing the truncate_number function. It includes the initial task, agent metadata, and the history of interactions and code changes.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/humanevalfix/README.md#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"task_id\": \"Python/2\",\n    \"instruction\": \"Please fix the function in Python__2.py such that all test cases pass.\\nEnvironment has been set up for you to start working. You may assume all necessary tools are installed.\\n\\n# Problem Statement\\ndef truncate_number(number: float) -> float:\\n    return number % 1.0 + 1.0\\n\\n\\n\\n\\n\\n\\ndef check(truncate_number):\\n    assert truncate_number(3.5) == 0.5\\n    assert abs(truncate_number(1.33) - 0.33) < 1e-6\\n    assert abs(truncate_number(123.456) - 0.456) < 1e-6\\n\\ncheck(truncate_number)\\n\\nIMPORTANT: You should ONLY interact with the environment provided to you AND NEVER ASK FOR HUMAN HELP.\\nYou should NOT modify any existing test case files. If needed, you can add new test cases in a NEW file to reproduce the issue.\\nYou SHOULD INCLUDE PROPER INDENTATION in your edit commands.\\nWhen you think you have fixed the issue through code changes, please finish the interaction using the \\\"finish\\\" tool.\\n\",\n    \"metadata\": {\n        \"agent_class\": \"CodeActAgent\",\n        \"model_name\": \"gpt-4\",\n        \"max_iterations\": 10,\n        \"eval_output_dir\": \"evaluation/evaluation_outputs/outputs/humanevalfix/CodeActAgent/gpt-4_maxiter_10_N_v1.4\",\n        \"start_time\": \"2024-05-22 20:54:15\",\n        \"git_commit\": \"4d3253696f5a9d9de02ab86969fe9796fa40331f\"\n    },\n    \"history\": [\n        [\n            {\n                \"id\": 27,\n                \"timestamp\": \"2024-05-22T20:57:24.688651\",\n                \"source\": \"user\",\n                \"message\": \"Please fix the function in Python__2.py such that all test cases pass.\\nEnvironment has been set up for you to start working. You may assume all necessary tools are installed.\\n\\n# Problem Statement\\ndef truncate_number(number: float) -> float:\\n    return number % 1.0 + 1.0\\n\\n\\n\\n\\n\\n\\ndef check(truncate_number):\\n    assert truncate_number(3.5) == 0.5\\n    assert abs(truncate_number(1.33) - 0.33) < 1e-6\\n    assert abs(truncate_number(123.456) - 0.456) < 1e-6\\n\\ncheck(truncate_number)\\n\\nIMPORTANT: You should ONLY interact with the environment provided to you AND NEVER ASK FOR HUMAN HELP.\\nYou should NOT modify any existing test case files. If needed, you can add new test cases in a NEW file to reproduce the issue.\\nYou SHOULD INCLUDE PROPER INDENTATION in your edit commands.\\nWhen you think you have fixed the issue through code changes, please finish the interaction using the \\\"finish\\\" tool.\\n\",\n                \"action\": \"message\",\n                \"args\": {\n                    \"content\": \"Please fix the function in Python__2.py such that all test cases pass.\\nEnvironment has been set up for you to start working. You may assume all necessary tools are installed.\\n\\n# Problem Statement\\ndef truncate_number(number: float) -> float:\\n    return number % 1.0 + 1.0\\n\\n\\n\\n\\n\\n\\ndef check(truncate_number):\\n    assert truncate_number(3.5) == 0.5\\n    assert abs(truncate_number(1.33) - 0.33) < 1e-6\\n    assert abs(truncate_number(123.456) - 0.456) < 1e-6\\n\\ncheck(truncate_number)\\n\\nIMPORTANT: You should ONLY interact with the environment provided to you AND NEVER ASK FOR HUMAN HELP.\\nYou should NOT modify any existing test case files. If needed, you can add new test cases in a NEW file to reproduce the issue.\\nYou SHOULD INCLUDE PROPER INDENTATION in your edit commands.\\nWhen you think you have fixed the issue through code changes, please finish the interaction using the \\\"finish\\\" tool.\\n\",\n                    \"wait_for_response\": false\n                }\n            },\n            {\n                \"message\": \"No observation\",\n                \"observation\": \"null\",\n                \"content\": \"\",\n                \"extras\": {}\n            }\n        ],\n        [\n            {\n                \"id\": 32,\n                \"timestamp\": \"2024-05-22T20:57:28.413818\",\n                \"source\": \"agent\",\n                \"message\": \"Running command: open Python__2.py\",\n                \"action\": \"run\",\n                \"args\": {\n                    \"command\": \"open Python__2.py\",\n                    \"thought\": \"Let's start by opening the Python__2.py file to see the current implementation of the function.\"\n                }\n            },\n            {\n                \"id\": 33,\n                \"timestamp\": \"2024-05-22T20:57:28.803780\",\n                \"source\": \"agent\",\n                \"message\": \"Command `open Python__2.py` executed with exit code 0.\",\n                \"cause\": 32,\n                \"observation\": \"run\",\n                \"content\": \"[File: /workspace/Python__2.py (14 lines total)]\\r\\n1:def truncate_number(number: float) -> float:\\r\\n2:    return number % 1.0 + 1.0\\r\\n3:\\r\\n4:\\r\\n5:\\r\\n6:\\r\\n7:\\r\\n8:\\r\\n9:def check(truncate_number):\\r\\n10:    assert truncate_number(3.5) == 0.5\\r\\n11:    assert abs(truncate_number(1.33) - 0.33) < 1e-6\\r\\n12:    assert abs(truncate_number(123.456) - 0.456) < 1e-6\\r\\n13:\\r\\n14:check(truncate_number)\",\n                \"extras\": {\n                    \"command\": \"open Python__2.py\",\n                    \"exit_code\": 0\n                }\n            }\n        ],\n        [\n            {\n                \"id\": 34,\n                \"timestamp\": \"2024-05-22T20:57:36.605638\",\n                \"source\": \"agent\",\n                \"message\": \"Running command: edit 2:2 <<EOF\\n    return number % 1.0\\nEOF\",\n                \"action\": \"run\",\n                \"args\": {\n                    \"command\": \"edit 2:2 <<EOF\\n    return number % 1.0\\nEOF\",\n                    \"thought\": \"The current implementation of the function `truncate_number` is incorrect because it adds 1.0 to the fractional part of the number. This is not necessary and is causing the function to fail the test cases. \\n\\nThe correct implementation should only return the fractional part of the number. This can be achieved by using the modulus operator with 1.0, which will return the fractional part of the number.\\n\\nLet's correct the function implementation.\"\n                }\n            },\n            {\n                \"id\": 35,\n                \"timestamp\": \"2024-05-22T20:57:36.973592\",\n                \"source\": \"agent\",\n                \"message\": \"Command `edit 2:2 <<EOF\\n    return number % 1.0\\nEOF` executed with exit code 0.\",\n                \"cause\": 34,\n                \"observation\": \"run\",\n                \"content\": \"> > [File: /workspace/Python__2.py (14 lines total)]\\r\\n1:def truncate_number(number: float) -> float:\\r\\n2:    return number % 1.0\\r\\n3:\\r\\n4:\\r\\n5:\\r\\n6:\\r\\n7:\\r\\n8:\\r\\n9:def check(truncate_number):\\r\\n10:    assert truncate_number(3.5) == 0.5\\r\\n11:    assert abs(truncate_number(1.33) - 0.33) < 1e-6\\r\\n12:    assert abs(truncate_number(123.456) - 0.456) < 1e-6\\r\\n13:\\r\\n14:check(truncate_number)\\r\\nFile updated. Please review the changes and make sure they are correct (correct indentation, no duplicate lines, etc). Edit the file again if necessary.\",\n                \"extras\": {\n                    \"command\": \"edit 2:2 <<EOF\\n    return number % 1.0\\nEOF\",\n                    \"exit_code\": 0\n                }\n            }\n        ],\n        [\n            {\n                \"id\": 36,\n                \"timestamp\": \"2024-05-22T20:57:48.420415\",\n                \"source\": \"agent\",\n                \"message\": \"Running command: python3 Python__2.py\",\n                \"action\": \"run\",\n                \"args\": {\n                    \"command\": \"python3 Python__2.py\",\n                    \"thought\": \"The function `truncate_number` has been updated. Now, let's run the Python file to see if the test cases pass.\"\n                }\n            },\n            {\n                \"id\": 37,\n                \"timestamp\": \"2024-05-22T20:57:48.635312\",\n                \"source\": \"agent\",\n                \"message\": \"Command `python3 Python__2.py` executed with exit code 0.\",\n                \"cause\": 36,\n                \"observation\": \"run\",\n                \"content\": \"\",\n                \"extras\": {\n                    \"command\": \"python3 Python__2.py\",\n                    \"exit_code\": 0\n                }\n            }\n        ],\n        [\n            {\n                \"id\": 38,\n                \"timestamp\": \"2024-05-22T20:58:10.589252\",\n                \"source\": \"agent\",\n                \"message\": \"All done! What's next on the agenda?\",\n                \"action\": \"finish\",\n                \"args\": {\n                    \"outputs\": {},\n                    \"thought\": \"\"\n                }\n            },\n            {\n                \"message\": \"No observation\",\n                \"observation\": \"null\",\n                \"content\": \"\",\n                \"extras\": {}\n            }\n        ]\n    ],\n    \"error\": null,\n    \"test_result\": {\n        \"result\": {\n            \"pass@1\": 1.0\n        },\n        \"metadata\": {\n            \"logs\": {\n                \"0\": [\n                    [\n                        0,\n                        {\n                            \"task_id\": 0,\n                            \"passed\": true,\n                            \"result\": \"passed\",\n                            \"completion_id\": 0\n                        }\n                    ]\n                ]\n            },\n            \"timeout\": 10,\n            \"num_workers\": 4\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent in TOML for OpenHands (Pre-0.8.0)\nDESCRIPTION: Example of agent configuration in config.toml before version 0.8.0. The 'name' field is no longer used in the new version.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/upgrade-guide.md#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[agent]\nname=\"CodeActAgent\"\nmemory_max_threads=2\n```\n\n----------------------------------------\n\nTITLE: Updating Directory Permissions in Bash\nDESCRIPTION: This command updates the permissions of the .openhands-state directory to allow full access. It's an alternative solution to resolve permission issues.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo chmod 777 ~/.openhands-state\n```\n\n----------------------------------------\n\nTITLE: Running BrowserGym Agent with Poetry\nDESCRIPTION: Command line instruction for executing the browsing agent using Poetry. The command runs a task to search for information about the USA president using Google, with specified iterations and model parameters.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/agenthub/browsing_agent/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python ./openhands/core/main.py \\\n           -i 10 \\\n           -t \"tell me the usa's president using google search\" \\\n           -c BrowsingAgent \\\n           -m claude-3-5-sonnet-20241022\n```\n\n----------------------------------------\n\nTITLE: Example Error Output in OpenHands CLI\nDESCRIPTION: Expected error output from OpenHands CLI when attempting an invalid operation. This shows how the system reports errors and prompts the user to try again.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n🤖 Ocorreu um erro. Por favor, tente novamente.\n```\n\n----------------------------------------\n\nTITLE: Starting Local Development Server for Specific Languages\nDESCRIPTION: Commands to start a local development server for specific language versions of the documentation, including Brazilian Portuguese, French, and Simplified Chinese.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ yarn start --locale pt-BR # for the Brazilian Portuguese version\n$ yarn start --locale fr # for the French version\n$ yarn start --locale zh-Hans # for the Chinese Han (simplified variant) version\n```\n\n----------------------------------------\n\nTITLE: Post-Processing OpenHands Log\nDESCRIPTION: Python command to extract and process information from OpenHands output logs for evaluation purposes. The script converts the log file to a format suitable for evaluation.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/scienceagentbench/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython post_proc.py [log_fname]\n```\n\n----------------------------------------\n\nTITLE: Tokenizing Messages Using Hugging Face Transformers in Python\nDESCRIPTION: This snippet uses the Hugging Face Transformers library to tokenize messages. It initializes a tokenizer for the Qwen2.5-7B-Instruct model and applies it to the DataFrame in parallel.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/swegym/convert_data.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pandarallel import pandarallel\nfrom transformers import AutoTokenizer\n\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\npandarallel.initialize(progress_bar=True, verbose=1, nb_workers=16)\ntokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-7B-Instruct')\ndf['n_tokens'] = df['rm_conv'].parallel_apply(\n    lambda x: len(tokenizer.apply_chat_template(x))\n)\n```\n\n----------------------------------------\n\nTITLE: Example Repository Documentation Template in Markdown\nDESCRIPTION: A template showing how to document a repository's purpose, setup, and structure in the OpenHands format, including frontend and backend components, testing procedures, and CI workflow information.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/tasks/add_openhands_repo_instruction.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\nname: repo\ntype: repo\nagent: CodeActAgent\n---\n\nThis repository contains the code for OpenHands, an automated AI software engineer. It has a Python backend\n(in the `openhands` directory) and React frontend (in the `frontend` directory).\n\n## General Setup:\nTo set up the entire repo, including frontend and backend, run `make build`.\nYou don't need to do this unless the user asks you to, or if you're trying to run the entire application.\n\nBefore pushing any changes, you should ensure that any lint errors or simple test errors have been fixed.\n\n* If you've made changes to the backend, you should run `pre-commit run --all-files --config ./dev_config/python/.pre-commit-config.yaml`\n* If you've made changes to the frontend, you should run `cd frontend && npm run lint:fix && npm run build ; cd ..`\n\nIf either command fails, it may have automatically fixed some issues. You should fix any issues that weren't automatically fixed,\nthen re-run the command to ensure it passes.\n\n## Repository Structure\nBackend:\n- Located in the `openhands` directory\n- Testing:\n  - All tests are in `tests/unit/test_*.py`\n  - To test new code, run `poetry run pytest tests/unit/test_xxx.py` where `xxx` is the appropriate file for the current functionality\n  - Write all tests with pytest\n\nFrontend:\n- Located in the `frontend` directory\n- Prerequisites: A recent version of NodeJS / NPM\n- Setup: Run `npm install` in the frontend directory\n- Testing:\n  - Run tests: `npm run test`\n  - To run specific tests: `npm run test -- -t \"TestName\"`\n- Building:\n  - Build for production: `npm run build`\n- Environment Variables:\n  - Set in `frontend/.env` or as environment variables\n  - Available variables: VITE_BACKEND_HOST, VITE_USE_TLS, VITE_INSECURE_SKIP_VERIFY, VITE_FRONTEND_PORT\n- Internationalization:\n  - Generate i18n declaration file: `npm run make-i18n`\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for OpenHands Regression Tests (Bash)\nDESCRIPTION: Command to install the required dependencies for running OpenHands regression tests using pip. This should be executed before running the test suite.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Displaying Docker Image Build Error\nDESCRIPTION: Presents the error message encountered when building the runtime Docker image. This error suggests issues with package signatures, possibly due to changes in external library hashes.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\ndebian-security bookworm-security\nInRelease At least one invalid signature was encountered.\n```\n\n----------------------------------------\n\nTITLE: Interactive Python Environment Communication Format\nDESCRIPTION: Demonstrates the structured format for communicating with an interactive Python environment using specific XML-style tags for thoughts and solutions.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/prompts/template_with_tool.txt#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<execute_ipython>\\n# Python code goes here\\n</execute_ipython>\\n\\n<thought>\\nThought process goes here\\n</thought>\\n\\n<solution>\\nFinal answer goes here\\n</solution>\n```\n\n----------------------------------------\n\nTITLE: Running Specific Test File with Poetry\nDESCRIPTION: Command to run tests from a specific test file (test_micro_agents.py) using Poetry and Pytest.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/tests/unit/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry run pytest ./tests/unit/test_micro_agents.py\n```\n\n----------------------------------------\n\nTITLE: Building OpenHands Project\nDESCRIPTION: Command to build both frontend and backend components of the OpenHands project.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/prompts/repo_instructions/all-hands-ai___openhands.txt#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nmake build\n```\n\n----------------------------------------\n\nTITLE: Installing E2B CLI with NPM\nDESCRIPTION: Command to install the E2B command-line interface globally using NPM package manager\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/containers/e2b-sandbox/README.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpm install -g @e2b/cli@latest\n```\n\n----------------------------------------\n\nTITLE: Creating SAT Scores Table in SQLite\nDESCRIPTION: Creates a table to store SAT score statistics for schools including enrollment, number of test takers, and average scores for reading, math and writing sections. Links to schools table via CDS foreign key.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_8\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE satscores\n(\n    cds         TEXT not null\n        primary key,\n    rtype       TEXT  not null,\n    sname       TEXT null,\n    dname       TEXT null,\n    cname       TEXT null,\n    enroll12    INTEGER         not null,\n    NumTstTakr  INTEGER          not null,\n    AvgScrRead  INTEGER          null,\n    AvgScrMath  INTEGER          null,\n    AvgScrWrite INTEGER          null,\n    NumGE1500   INTEGER          null,\n    foreign key (cds) references schools (CDSCode)\n);\n```\n\n----------------------------------------\n\nTITLE: Results Summary Generation\nDESCRIPTION: Python command for generating a summary of evaluation results from the output JSON file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/aider_bench/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry run python ./evaluation/benchmarks/aider_bench/scripts/summarize_results.py [path_to_output_jsonl_file]\n```\n\n----------------------------------------\n\nTITLE: Displaying Docker Client Launch Failure Error in Bash\nDESCRIPTION: This snippet shows the error message displayed when the Docker client fails to launch in OpenHands. It indicates that Docker may not be installed or the Docker daemon may not be running.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nLaunch docker client failed. Please make sure you have installed docker and started docker desktop/daemon.\n```\n\n----------------------------------------\n\nTITLE: Wikipedia Search for Li Bai\nDESCRIPTION: Performs a Wikipedia search to find Li Bai's birth year\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/tasks/in_context_examples/reasoning/with_tool.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nprint(wikipedia_search('Li Bai'))\n```\n\n----------------------------------------\n\nTITLE: Changing Directory Ownership in Bash\nDESCRIPTION: This command changes the ownership of the .openhands-state directory to the current user. It's used to resolve permission issues when the directory is owned by root.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo chown <user>:<user> ~/.openhands-state\n```\n\n----------------------------------------\n\nTITLE: Installing OpenHands Dependencies with Poetry\nDESCRIPTION: Command to install project dependencies including test and development packages using Poetry package manager.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/prompts/repo_instructions/all-hands-ai___openhands-resolver.txt#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry install --with test --with dev\n```\n\n----------------------------------------\n\nTITLE: Installing TexLive Base Package\nDESCRIPTION: Command to install the base TexLive package required for PdfLatex functionality\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/pdflatex.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\napt-get install texlive-latex-base\n```\n\n----------------------------------------\n\nTITLE: Citation Formatting for OpenHands\nDESCRIPTION: BibTeX citation format for referencing the OpenHands project in academic papers. Includes author list, title, publication details, and arxiv information for proper attribution.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n@misc{openhands,\n      title={{OpenHands: An Open Platform for AI Software Developers as Generalist Agents}},\n      author={Xingyao Wang and Boxuan Li and Yufan Song and Frank F. Xu and Xiangru Tang and Mingchen Zhuge and Jiayi Pan and Yueqi Song and Bowen Li and Jaskirat Singh and Hoang H. Tran and Fuqiang Li and Ren Ma and Mingzhang Zheng and Bill Qian and Yanjun Shao and Niklas Muennighoff and Yizhe Zhang and Binyuan Hui and Junyang Lin and Robert Brennan and Hao Peng and Heng Ji and Graham Neubig},\n      year={2024},\n      eprint={2407.16741},\n      archivePrefix={arXiv},\n      primaryClass={cs.SE},\n      url={https://arxiv.org/abs/2407.16741},\n}\n```\n\n----------------------------------------\n\nTITLE: Running All Unit Tests with Poetry\nDESCRIPTION: Command to execute all unit tests in the tests/unit directory using Poetry and Pytest.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/tests/unit/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npoetry run pytest ./tests/unit\n```\n\n----------------------------------------\n\nTITLE: Creating FRPM Statistics Table in SQLite\nDESCRIPTION: Creates a table to store Free/Reduced Price Meal (FRPM) statistics for schools with various metrics including enrollment counts and eligibility percentages. Links to schools table via CDSCode foreign key.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/bird/README.md#2025-04-23_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE TABLE frpm\n(\n    CDSCode                                       TEXT not null\n        primary key,\n    `Academic Year`                               TEXT  null,\n    `County Code`                                 TEXT  null,\n    `District Code`                               INTEGER         null,\n    `School Code`                                 TEXT  null,\n    `County Name`                                 TEXT null,\n    `District Name`                               TEXT null,\n    `School Name`                                 TEXT null,\n    `District Type`                               TEXT null,\n    `School Type`                                 TEXT null,\n    `Educational Option Type`                     TEXT null,\n    `NSLP Provision Status`                       TEXT null,\n    `Charter School (Y/N)`                        INTEGER    null,\n    `Charter School Number`                       TEXT  null,\n    `Charter Funding Type`                        TEXT null,\n    IRC                                           INTEGER    null,\n    `Low Grade`                                   TEXT  null,\n    `High Grade`                                  TEXT null,\n    `Enrollment (K-12)`                           REAL      null,\n    `Free Meal Count (K-12)`                      REAL       null,\n    `Percent (%) Eligible Free (K-12)`            REAL       null,\n    `FRPM Count (K-12)`                           REAL       null,\n    `Percent (%) Eligible FRPM (K-12)`            REAL       null,\n    `Enrollment (Ages 5-17)`                      REAL       null,\n    `Free Meal Count (Ages 5-17)`                 REAL       null,\n    `Percent (%) Eligible Free (Ages 5-17)`       REAL       null,\n    `FRPM Count (Ages 5-17)`                      REAL       null,\n    `Percent (%) Eligible FRPM (Ages 5-17)`       REAL       null,\n    `2013-14 CALPADS Fall 1 Certification Status` INTEGER    null,\n    foreign key (CDSCode) references schools (CDSCode)\n);\n```\n\n----------------------------------------\n\nTITLE: Listing Docker Images for SWEBench Evaluation\nDESCRIPTION: This snippet provides a comprehensive list of Docker image tags used for SWEBench evaluation. Each line represents a specific image with details about the library, version, and associated issue number. The images are based on various Python libraries and frameworks, targeting x86_64 architecture.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-lite-instance-images.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nswebench/sweb.eval.x86_64.astropy_1776_astropy-12907:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14182:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14365:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-14995:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-6938:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-7746:latest\nswebench/sweb.eval.x86_64.django_1776_django-10914:latest\nswebench/sweb.eval.x86_64.django_1776_django-10924:latest\nswebench/sweb.eval.x86_64.django_1776_django-11001:latest\nswebench/sweb.eval.x86_64.django_1776_django-11019:latest\n# ... (truncated for brevity)\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-11143:latest\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for OpenHands Project\nDESCRIPTION: This snippet lists the required Python packages and their specific versions (where specified) for the OpenHands project. It includes popular libraries for data science, machine learning, and scientific computing.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas==1.4.4\nopencv-python\nnetworkx\nscipy==1.10.1\nipython\nmatplotlib\nnltk\npyyaml\npytz\nvisdom\nsympy\nseaborn\npython-dateutil\nstatsmodels\n```\n\n----------------------------------------\n\nTITLE: Installing LaTeX Font Packages\nDESCRIPTION: Commands to install recommended and extra font packages to ensure compatibility with various LaTeX documents\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/pdflatex.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\napt-get install texlive-fonts-recommended\napt-get install texlive-fonts-extra\n```\n\n----------------------------------------\n\nTITLE: Printing 'Hello, World!' in Bash\nDESCRIPTION: This Bash script prints the string 'Hello, World!' to the console. It demonstrates the basic structure of a Bash script and the use of the echo command for output.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/regression/cases/hello-world/task.txt#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n\necho \"Hello, World!\"\n```\n\n----------------------------------------\n\nTITLE: Starting Local Development Server for OpenHands Docs\nDESCRIPTION: Command to start a local development server for the default English version of the documentation. This allows for live updates as changes are made.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ yarn start # for the default English version\n```\n\n----------------------------------------\n\nTITLE: Running Python Unit Tests\nDESCRIPTION: Command for running specific unit tests using pytest within the Poetry environment. Tests are located in the tests/unit directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/prompts/repo_instructions/all-hands-ai___openhands.txt#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npoetry run pytest tests/unit/test_xxx.py\n```\n\n----------------------------------------\n\nTITLE: SWEBench Docker Image Tags\nDESCRIPTION: Collection of Docker image tags for SWEBench evaluation environment. Images are built for x86_64 architecture and include different versions of pytest, scikit-learn, sphinx-doc and sympy projects, each with specific build identifiers.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-lite-instance-images.txt#2025-04-23_snippet_1\n\nLANGUAGE: docker\nCODE:\n```\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-11148:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-5103:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-5221:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-5227:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-5413:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-5495:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-5692:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-6116:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-7168:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-7220:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-7373:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-7432:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-7490:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-8365:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-8906:latest\nswebench/sweb.eval.x86_64.pytest-dev_1776_pytest-9359:latest\n```\n\n----------------------------------------\n\nTITLE: Linking to Contributing Guidelines in Markdown\nDESCRIPTION: This code snippet provides a Markdown link to the CONTRIBUTING.md file in the OpenHands repository, which contains specific instructions for contributing to the project.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/prompting/microagents-public.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[CONTRIBUTING.md](https://github.com/All-Hands-AI/OpenHands/blob/main/CONTRIBUTING.md)\n```\n\n----------------------------------------\n\nTITLE: Example Test Structure for OpenHands Frontend Components\nDESCRIPTION: Demonstrates the structure of a component test using Vitest, React Testing Library, and user-event for simulating interactions.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/frontend/README.md#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { render, screen } from \"@testing-library/react\";\nimport userEvent from \"@testing-library/user-event\";\nimport { describe, it, expect, vi } from \"vitest\";\n\ndescribe(\"ComponentName\", () => {\n  it(\"should render correctly\", () => {\n    render(<Component />);\n    expect(screen.getByRole(\"button\")).toBeInTheDocument();\n  });\n\n  it(\"should handle user interactions\", async () => {\n    const mockCallback = vi.fn();\n    const user = userEvent.setup();\n\n    render(<Component onClick={mockCallback} />);\n    const button = screen.getByRole(\"button\");\n\n    await user.click(button);\n    expect(mockCallback).toHaveBeenCalledOnce();\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Pynguin Test IDs for Xarray in Python\nDESCRIPTION: This snippet defines a list of test case IDs generated by the Pynguin testing tool for the Xarray project. Each ID represents a specific test case with a unique identifier.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/NOTES.md#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\npynguin_ids = ['pydata__xarray-6548-16541', 'pydata__xarray-7003-16557', 'pydata__xarray-3114-16452', 'pydata__xarray-4339-16487', 'pydata__xarray-6889-16549', 'pydata__xarray-3239-16458', 'pydata__xarray-3364-16461', 'pydata__xarray-3239-16457', 'pydata__xarray-5365-16529', 'pydata__xarray-5131-16520', 'pydata__xarray-7229-16578', 'pydata__xarray-6461-16540', 'pydata__xarray-4419-16488', 'pydata__xarray-7147-16571', 'pydata__xarray-3151-16453', 'pydata__xarray-4966-16515', 'pydata__xarray-4629-16492', 'pydata__xarray-3239-16456', 'pydata__xarray-7400-16582', 'pydata__xarray-4994-16516', 'pydata__xarray-3302-16459', 'pydata__xarray-6601-16544', 'pydata__xarray-6882-16548', 'pydata__xarray-6135-16535', 'pydata__xarray-7393-16581', 'pydata__xarray-5731-16534', 'pydata__xarray-7203-16577']\n```\n\n----------------------------------------\n\nTITLE: Testing Ollama Access from Docker Container\nDESCRIPTION: Docker exec command to test Ollama API access from within a Docker container, simulating the OpenHands environment.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/llms/local-llms.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec [CONTAINER ID] curl http://host.docker.internal:11434/api/generate -d '{\"model\":\"[NAME]\",\"prompt\":\"hi\"}'\n```\n\n----------------------------------------\n\nTITLE: Rounding Final Result\nDESCRIPTION: Rounds the calculated value to three decimal places using Python's math module and round function\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/mint/tasks/in_context_examples/reasoning/with_tool.txt#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport math\nprint(round(245700.5*math.pi, 3))\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags for Django Evaluation\nDESCRIPTION: Collection of Docker image tags for Django testing environment. These images are built for x86_64 architecture and contain Django version 1776 with different build numbers, all marked as latest.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_1\n\nLANGUAGE: docker\nCODE:\n```\nswebench/sweb.eval.x86_64.django_1776_django-11270:latest\nswebench/sweb.eval.x86_64.django_1776_django-11276:latest\nswebench/sweb.eval.x86_64.django_1776_django-11278:latest\nswebench/sweb.eval.x86_64.django_1776_django-11279:latest\n# Additional tags omitted for brevity\n```\n\n----------------------------------------\n\nTITLE: Implementing Page Redirect in Docusaurus with React\nDESCRIPTION: Uses Docusaurus Router's Redirect component to redirect users from one URL path to another. The component is imported from @docusaurus/router and configured to redirect to the /modules/usage/runtimes-index path.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/runtimes.md#2025-04-23_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\nimport { Redirect } from '@docusaurus/router';\n\n<Redirect to=\"/modules/usage/runtimes-index\" />\n```\n\n----------------------------------------\n\nTITLE: Converting Bash Script to Ruby\nDESCRIPTION: A Ruby version of the hello world script that accepts an optional name argument.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/modules/usage/getting-started.mdx#2025-04-23_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\nname = ARGV[0] || \"world\"\nputs \"hello #{name}!\"\n```\n\n----------------------------------------\n\nTITLE: Setting Default Robot Access Permissions\nDESCRIPTION: Configures default access rules for web crawlers using the robots.txt standard format. This configuration allows all user agents (*) complete access to the site with no disallowed paths.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/frontend/public/robots.txt#2025-04-23_snippet_0\n\nLANGUAGE: robotstxt\nCODE:\n```\nUser-agent: *\nDisallow:\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Browser Tests Disabled\nDESCRIPTION: Command to run test suite while skipping browser-based tests using an environment variable\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/prompts/repo_instructions/rbren___rss-parser.txt#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nSKIP_BROWSER_TESTS=1 npm test\n```\n\n----------------------------------------\n\nTITLE: YAML Configuration for Security Knowledge Base\nDESCRIPTION: YAML frontmatter configuration block defining metadata for the security knowledge base document, including name, type, version, agent, and trigger keywords.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/security.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: security\ntype: knowledge\nversion: 1.0.0\nagent: CodeActAgent\ntriggers:\n  - security\n  - vulnerability\n  - authentication\n  - authorization\n  - permissions\n```\n\n----------------------------------------\n\nTITLE: Displaying Docker Error Message\nDESCRIPTION: Shows the error message that appears when the Docker client fails to launch. This error indicates that Docker may not be installed or running properly on the system.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/zh-Hans/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nLaunch docker client failed. Please make sure you have installed docker and started docker desktop/daemon.\n```\n\n----------------------------------------\n\nTITLE: Docker Image References for SWEBench Evaluation\nDESCRIPTION: Collection of Docker image references used for evaluating Astropy and Django projects on SWEBench. Images are tagged with specific version numbers corresponding to issues or pull requests.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_0\n\nLANGUAGE: dockerfile\nCODE:\n```\nswebench/sweb.eval.x86_64.astropy_1776_astropy-11693:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-12057:latest\nswebench/sweb.eval.x86_64.astropy_1776_astropy-12318:latest\n# ... additional image references omitted for brevity ...\n```\n\n----------------------------------------\n\nTITLE: Setting Runloop API Key in Bash\nDESCRIPTION: Sets the Runloop API key as an environment variable for authentication.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/runtime/impl/runloop/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport RUNLOOP_API_KEY=<your-api-key>\n```\n\n----------------------------------------\n\nTITLE: Example Error Handling in OpenHands CLI\nDESCRIPTION: Example of error handling in OpenHands CLI when requesting an impossible operation. This demonstrates how the system responds to an invalid request like trying to delete a non-existent file.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n>> Exclua um arquivo inexistente\n```\n\n----------------------------------------\n\nTITLE: Listing Docker Images for Python Package Testing\nDESCRIPTION: Collection of Docker image references used for evaluating different Python packages. Each image follows the naming pattern swebench/sweb.eval.x86_64.[package]_[id]_[package]-[number]:latest, targeting x86_64 architecture.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-verified-instance-images.txt#2025-04-23_snippet_1\n\nLANGUAGE: docker\nCODE:\n```\nswebench/sweb.eval.x86_64.django_1776_django-14855:latest\nswebench/sweb.eval.x86_64.django_1776_django-14915:latest\nswebench/sweb.eval.x86_64.django_1776_django-14999:latest\n...\n```\n\n----------------------------------------\n\nTITLE: Verifying Docker Installation with Hello-World Container\nDESCRIPTION: A simple bash command to verify that Docker is working correctly by running the hello-world container.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/docker.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo docker run hello-world\n```\n\n----------------------------------------\n\nTITLE: Verifying Swift Installation\nDESCRIPTION: Command to verify that Swift has been correctly installed by checking its version.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/microagents/knowledge/swift-linux.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nswift --version\n```\n\n----------------------------------------\n\nTITLE: Installing Node Dependencies\nDESCRIPTION: Command to automatically accept and install all required npm dependencies\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/openhands/resolver/prompts/repo_instructions/rbren___rss-parser.txt#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyes | npm install\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags for Django Evaluation\nDESCRIPTION: Collection of Docker image tags for Django evaluation environment running on x86_64 architecture. Each tag represents a different build variant of Django version 1776.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nswebench/sweb.eval.x86_64.django_1776_django-13773:latest\nswebench/sweb.eval.x86_64.django_1776_django-13774:latest\nswebench/sweb.eval.x86_64.django_1776_django-13786:latest\n# ... additional tags omitted for brevity\n```\n\n----------------------------------------\n\nTITLE: Defining CodaMOSA Test IDs for Xarray in Python\nDESCRIPTION: This snippet defines a list of test case IDs generated by the CodaMOSA testing tool for the Xarray project. Each ID represents a specific test case with a unique identifier.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/NOTES.md#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ncodamosa_ids = ['pydata__xarray-4750-16496', 'pydata__xarray-3239-16458', 'pydata__xarray-4966-16515', 'pydata__xarray-3302-16459', 'pydata__xarray-5126-16518', 'pydata__xarray-4994-16516', 'pydata__xarray-3905-16478', 'pydata__xarray-4182-16484', 'pydata__xarray-5131-16520', 'pydata__xarray-5662-16532', 'pydata__xarray-3364-16461', 'pydata__xarray-5731-16534', 'pydata__xarray-3239-16457', 'pydata__xarray-7203-16577', 'pydata__xarray-3156-16454', 'pydata__xarray-5126-16519', 'pydata__xarray-5365-16529', 'pydata__xarray-4629-16492', 'pydata__xarray-4248-16486', 'pydata__xarray-4339-16487', 'pydata__xarray-3151-16453', 'pydata__xarray-3114-16452', 'pydata__xarray-5033-16517', 'pydata__xarray-4802-16505', 'pydata__xarray-5455-16530', 'pydata__xarray-6400-16539', 'pydata__xarray-3239-16456', 'pydata__xarray-4419-16488']\n```\n\n----------------------------------------\n\nTITLE: BioCoder Citation Reference\nDESCRIPTION: BibTeX citation for the BioCoder benchmark paper.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/biocoder/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{tang2024biocoder,\n      title={BioCoder: A Benchmark for Bioinformatics Code Generation with Large Language Models},\n      author={Xiangru Tang and Bill Qian and Rick Gao and Jiakang Chen and Xinyun Chen and Mark Gerstein},\n      year={2024},\n      eprint={2308.16458},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands Headless Mode with Docker\nDESCRIPTION: This Docker command runs OpenHands in headless mode. It sets up environment variables, mounts necessary volumes, and executes the OpenHands main module with a specific task. The command includes various configuration options for sandbox runtime, workspace, and logging.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/how-to/headless-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it \\\n    --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -e SANDBOX_USER_ID=$(id -u) \\\n    -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \\\n    -e LLM_API_KEY=$LLM_API_KEY \\\n    -e LLM_MODEL=$LLM_MODEL \\\n    -e LOG_ALL_EVENTS=true \\\n    -v $WORKSPACE_BASE:/opt/workspace_base \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app-$(date +%Y%m%d%H%M%S) \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.33 \\\n    python -m openhands.core.main -t \"write a bash script that prints hi\"\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tag List\nDESCRIPTION: List of x86_64 architecture Docker image tags for Python packages including version numbers. All images are tagged as 'latest' and follow the format 'sweb.eval.x86_64.[organization]_s_[package]-[PR number]'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nsweb.eval.x86_64.mwaskom_s_seaborn-3010:latest\nsweb.eval.x86_64.mwaskom_s_seaborn-3190:latest\nsweb.eval.x86_64.mwaskom_s_seaborn-3202:latest\nsweb.eval.x86_64.mwaskom_s_seaborn-3202:latest\nsweb.eval.x86_64.mwaskom_s_seaborn-3216:latest\nsweb.eval.x86_64.mwaskom_s_seaborn-3217:latest\nsweb.eval.x86_64.mwaskom_s_seaborn-3276:latest\nsweb.eval.x86_64.mwaskom_s_seaborn-3394:latest\nsweb.eval.x86_64.pallets_s_flask-5014:latest\nsweb.eval.x86_64.pallets_s_flask-5063:latest\nsweb.eval.x86_64.pydata_s_xarray-3114:latest\n[...]\n```\n\n----------------------------------------\n\nTITLE: Running OpenHands CLI Mode with Docker\nDESCRIPTION: Docker command to run OpenHands in CLI mode. Requires setting environment variables for workspace, model, and API key. Mounts necessary volumes and sets up the Docker container for interactive use.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/ja/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it \\\n    --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.33-nikolaik \\\n    -e SANDBOX_USER_ID=$(id -u) \\\n    -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \\\n    -e LLM_API_KEY=$LLM_API_KEY \\\n    -e LLM_MODEL=$LLM_MODEL \\\n    -v $WORKSPACE_BASE:/opt/workspace_base \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands-state:/.openhands-state \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app-$(date +%Y%m%d%H%M%S) \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.33 \\\n    python -m openhands.core.cli\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags Listing\nDESCRIPTION: A comprehensive list of Docker image tags for evaluation builds of Python packages. Each tag follows the format swebench/sweb.eval.x86_64.[package]_[issue]_[commit]:latest where package is the repository name, issue is the tracking number, and commit is the specific commit or PR being tested.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_6\n\nLANGUAGE: docker\nCODE:\n```\nswebench/sweb.eval.x86_64.matplotlib_1776_matplotlib-23412:latest\nswebench/sweb.eval.x86_64.matplotlib_1776_matplotlib-23476:latest\n[...additional lines omitted for brevity...]\nswebench/sweb.eval.x86_64.psf_1776_requests-1776:latest\n```\n\n----------------------------------------\n\nTITLE: Listing Container Image Tags for Sphinx and SymPy\nDESCRIPTION: Container image tag list showing different versions of Sphinx documentation and SymPy mathematical library evaluations. Each tag follows the format sweb.eval.x86_64.[package]_s_[package]-[number]:latest, where package is either sphinx-doc or sympy.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nsweb.eval.x86_64.sphinx-doc_s_sphinx-9231:latest\nsweb.eval.x86_64.sphinx-doc_s_sphinx-9258:latest\n[...]\nsweb.eval.x86_64.sympy_s_sympy-22005:latest\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags for Django Evaluation\nDESCRIPTION: Collection of swebench Django evaluation Docker image tags for x86_64 architecture. Each tag follows the pattern 'swebench/sweb.eval.x86_64.django_1776_django-{build_number}:latest'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_4\n\nLANGUAGE: docker\nCODE:\n```\nswebench/sweb.eval.x86_64.django_1776_django-15103:latest\nswebench/sweb.eval.x86_64.django_1776_django-15104:latest\nswebench/sweb.eval.x86_64.django_1776_django-15108:latest\nswebench/sweb.eval.x86_64.django_1776_django-15111:latest\nswebench/sweb.eval.x86_64.django_1776_django-15127:latest\nswebench/sweb.eval.x86_64.django_1776_django-15128:latest\nswebench/sweb.eval.x86_64.django_1776_django-15135:latest\n```\n\n----------------------------------------\n\nTITLE: Creating a Repository Configuration File in Markdown\nDESCRIPTION: An example of a .openhands/microagents/repo.md file that provides repository context including structure, configuration instructions, and development guidelines for the OpenHands agent.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/prompting/customization.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nRepository: MonProjet\nDescription: Une application web pour la gestion des tâches\n\nStructure des répertoires :\n- src/ : Code principal de l'application\n- tests/ : Fichiers de test\n- docs/ : Documentation\n\nConfiguration :\n- Exécutez `npm install` pour installer les dépendances\n- Utilisez `npm run dev` pour le développement\n- Exécutez `npm test` pour les tests\n\nDirectives :\n- Suivez la configuration ESLint\n- Écrivez des tests pour toutes les nouvelles fonctionnalités\n- Utilisez TypeScript pour le nouveau code\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tag Listing\nDESCRIPTION: Collection of Docker image tags for x86_64 architecture, including base images, environment images, and evaluation images for various Python packages and their specific versions or PR numbers.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/testgeneval/scripts/docker/all-swebench-lite-instance-images.txt#2025-04-23_snippet_0\n\nLANGUAGE: docker\nCODE:\n```\nsweb.base.x86_64:latest\nsweb.env.x86_64.088a7e628bda9770f9757b:latest\nsweb.env.x86_64.0d80c7dec81ee2f2f513e2:latest\n# ... additional tags omitted for brevity\n```\n\n----------------------------------------\n\nTITLE: Docker Image Tags List\nDESCRIPTION: Collection of Docker image tags for SweBench evaluation containers. Images are organized by framework (Django and Matplotlib) with specific version numbers and architectures (x86_64).\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/evaluation/benchmarks/swe_bench/scripts/docker/all-swebench-full-instance-images.txt#2025-04-23_snippet_5\n\nLANGUAGE: docker\nCODE:\n```\nswebench/sweb.eval.x86_64.django_1776_django-16493:latest\nswebench/sweb.eval.x86_64.django_1776_django-16501:latest\n[...]\nswebench/sweb.eval.x86_64.matplotlib_1776_matplotlib-23348:latest\n```\n\n----------------------------------------\n\nTITLE: Creating a Customized Prompt for OpenHands\nDESCRIPTION: An example of a customized prompt for OpenHands that references project-specific standards, includes context, and specifies testing requirements for a new task completion feature.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/prompting/customization.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nAjoutez une nouvelle fonctionnalité d'achèvement des tâches à src/components/TaskList.tsx en suivant nos modèles de composants existants.\nIncluez des tests unitaires dans tests/components/ et mettez à jour la documentation dans docs/features/.\nLe composant doit utiliser notre style partagé de src/styles/components.\n```\n\n----------------------------------------\n\nTITLE: Montando Sistema de Arquivos Local no Docker para OpenHands\nDESCRIPTION: Comando Docker para montar o sistema de arquivos local no runtime do OpenHands, incluindo configurações de ID de usuário e caminho de montagem.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/runtimes.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run # ...\n    -e SANDBOX_USER_ID=$(id -u) \\\n    -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \\\n    -v $WORKSPACE_BASE:/opt/workspace_base \\\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Example Output for Bash Command in OpenHands CLI\nDESCRIPTION: Expected output from OpenHands CLI when requesting to create a directory. The response includes a bash command to create the requested directory.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/pt-BR/docusaurus-plugin-content-docs/current/usage/how-to/cli-mode.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n🤖 Criando um diretório chamado \"test_dir\":\n\n❯ mkdir test_dir\n```\n\n----------------------------------------\n\nTITLE: Stopping Running OpenHands Docker Containers\nDESCRIPTION: A command to stop all running Docker containers whose names start with 'openhands-runtime-'.\nSOURCE: https://github.com/all-hands-ai/openhands/blob/main/docs/i18n/fr/docusaurus-plugin-content-docs/current/usage/troubleshooting/troubleshooting.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker ps --filter name=openhands-runtime- --filter status=running -aq | xargs docker stop\n```"
  }
]