[
  {
    "owner": "lotus-data",
    "repo": "lotus",
    "content": "TITLE: Advanced Semantic Filtering with Approximation in Python\nDESCRIPTION: This example showcases sem_filter with approximation techniques using cascade arguments. It utilizes both GPT-4o-mini and GPT-4o models, and includes a larger dataset of course names. The function returns both filtered results and statistics.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_filter.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\nfrom lotus.types import CascadeArgs\n\n\ngpt_4o_mini = LM(\"gpt-4o-mini\")\ngpt_4o = LM(\"gpt-4o\")\n\nlotus.settings.configure(lm=gpt_4o, helper_lm=gpt_4o_mini)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\", \"Optimization Methods in Engineering\", \"Digital Design and Integrated Circuits\",\n        \"Computer Security\", \"Data Structures and Algorithms\", \"Machine Learning\", \"Artificial Intelligence\", \"Natural Language Processing\",\n        \"Introduction to Robotics\", \"Control Systems\", \"Linear Algebra and Differential Equations\", \"Database Systems\", \"Cloud Computing\",\n        \"Software Engineering\", \"Operating Systems\", \"Discrete Mathematics\", \"Numerical Methods\", \"Wireless Communication Systems\",\n        \"Embedded Systems\", \"Advanced Computer Architecture\", \"Graph Theory\", \"Cryptography and Network Security\",\n        \"Big Data Analytics\", \"Deep Learning\", \"Organic Chemistry\", \"Molecular Biology\", \"Environmental Science\",\n        \"Genetics and Evolution\", \"Human Physiology\", \"Introduction to Anthropology\", \"Cultural Studies\", \"Political Theory\",\n        \"Macroeconomics\", \"Microeconomics\", \"Introduction to Sociology\", \"Developmental Psychology\", \"Cognitive Science\",\n        \"Introduction to Philosophy\", \"Ethics and Moral Philosophy\", \"History of Western Civilization\", \"Art History: Renaissance to Modern\",\n        \"World Literature\", \"Introduction to Journalism\", \"Public Speaking and Communication\", \"Creative Writing\", \"Music Theory\",\n        \"Introduction to Theater\", \"Film Studies\", \"Environmental Policy and Law\", \"Sustainability and Renewable Energy\",\n        \"Urban Planning and Design\", \"International Relations\", \"Marketing Principles\", \"Organizational Behavior\",\n        \"Financial Accounting\", \"Corporate Finance\", \"Business Law\", \"Supply Chain Management\", \"Operations Research\",\n        \"Entrepreneurship and Innovation\", \"Introduction to Psychology\", \"Health Economics\", \"Biostatistics\",\n        \"Social Work Practice\", \"Public Health Policy\", \"Environmental Ethics\", \"History of Political Thought\", \"Quantitative Research Methods\",\n        \"Comparative Politics\", \"Urban Economics\", \"Behavioral Economics\", \"Sociology of Education\", \"Social Psychology\",\n        \"Gender Studies\", \"Media and Communication Studies\", \"Advertising and Brand Strategy\",\n        \"Sports Management\", \"Introduction to Archaeology\", \"Ecology and Conservation Biology\", \"Marine Biology\",\n        \"Geology and Earth Science\", \"Astronomy and Astrophysics\", \"Introduction to Meteorology\",\n        \"Introduction to Oceanography\", \"Quantum Physics\", \"Thermodynamics\", \"Fluid Mechanics\", \"Solid State Physics\",\n        \"Classical Mechanics\", \"Introduction to Civil Engineering\", \"Material Science and Engineering\", \"Structural Engineering\",\n        \"Environmental Engineering\", \"Energy Systems Engineering\", \"Aerodynamics\", \"Heat Transfer\",\n        \"Renewable Energy Systems\", \"Transportation Engineering\", \"Water Resources Management\", \"Principles of Accounting\",\n        \"Project Management\", \"International Business\", \"Business Analytics\",\n    ]\n}\ndf = pd.DataFrame(data)\nuser_instruction = \"{Course Name} requires a lot of math\"\n\ncascade_args = CascadeArgs(recall_target=0.9, precision_target=0.9, sampling_percentage=0.5, failure_probability=0.2)\n\ndf, stats = df.sem_filter(user_instruction=user_instruction, cascade_args=cascade_args, return_stats=True)\nprint(df)\nprint(stats)\n```\n\n----------------------------------------\n\nTITLE: Initializing LOTUS with Models and Performing Semantic Filter and Aggregation\nDESCRIPTION: This snippet demonstrates how to configure LOTUS with GPT-4o-mini as the language model and E5-base-v2 as the embedding model. It creates a dataset of courses, applies a semantic filter to find machine learning courses, and then performs a semantic aggregation to generate a study plan.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/examples.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import SentenceTransformersRM, LM\n\n# Configure models for LOTUS\nlm = LM(model=\"gpt-4o-mini\")\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n\nlotus.settings.configure(lm=lm, rm=rm)\n\n# Dataset containing courses and their descriptions/workloads\ndata = [\n    (\n        \"Probability and Random Processes\",\n        \"Focuses on markov chains and convergence of random processes. The workload is pretty high.\",\n    ),\n    (\n        \"Deep Learning\",\n        \"Fouces on theory and implementation of neural networks. Workload varies by professor but typically isn't terrible.\",\n    ),\n    (\n        \"Digital Design and Integrated Circuits\",\n        \"Focuses on building RISC-V CPUs in Verilog. Students have said that the workload is VERY high.\",\n    ),\n    (\n        \"Databases\",\n        \"Focuses on implementation of a RDBMS with NoSQL topics at the end. Most students say the workload is not too high.\",\n    ),\n]\ndf = pd.DataFrame(data, columns=[\"Course Name\", \"Description\"])\n\n# Applies semantic filter followed by semantic aggregation\nml_df = df.sem_filter(\"{Description} indicates that the class is relevant for machine learning.\")\ntips = ml_df.sem_agg(\n    \"Given each {Course Name} and its {Description}, give me a study plan to succeed in my classes.\"\n)._output[0]\n```\n\n----------------------------------------\n\nTITLE: Filtering DataFrames Using Semantic Operators in Python\nDESCRIPTION: Demonstrates how to use the sem_filter semantic operator to filter a DataFrame based on a natural language expression. The example filters research papers based on whether their abstracts suggest LLMs efficiently utilize long context.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/core_concepts.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nlangex = \"The {abstract} suggests that LLMs efficeintly utilize long context\"\nfiltered_df = papers_df.sem_filter(langex)\n```\n\n----------------------------------------\n\nTITLE: Basic Semantic Aggregation with Large Language Model\nDESCRIPTION: Demonstrates how to use sem_agg to summarize multiple article contents using GPT-4 mini model. The example shows initialization of the language model and performing semantic aggregation on a DataFrame containing article titles and content.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_agg.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\n\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\ndata = {\n    \"ArticleTitle\": [\n        \"Advancements in Quantum Computing\",\n        \"Climate Change and Renewable Energy\",\n        \"The Rise of Artificial Intelligence\",\n        \"A Journey into Deep Space Exploration\"\n    ],\n    \"ArticleContent\": [\n        \"\"\"Quantum computing harnesses the properties of quantum mechanics \n        to perform computations at speeds unimaginable with classical machines. \n        As research and development progress, emerging quantum algorithms show \n        great promise in solving previously intractable problems.\"\"\",\n        \n        \"\"\"Global temperatures continue to rise, and societies worldwide \n        are turning to renewable resources like solar and wind power to mitigate \n        climate change. The shift to green technology is expected to reshape \n        economies and significantly reduce carbon footprints.\"\"\",\n        \n        \"\"\"Artificial Intelligence (AI) has grown rapidly, integrating \n        into various industries. Machine learning models now enable systems to \n        learn from massive datasets, improving efficiency and uncovering hidden \n        patterns. However, ethical concerns about privacy and bias must be addressed.\"\"\",\n        \n        \"\"\"Deep space exploration aims to understand the cosmos beyond \n        our solar system. Recent missions focus on distant exoplanets, black holes, \n        and interstellar objects. Advancements in propulsion and life support systems \n        may one day enable human travel to far-off celestial bodies.\"\"\"\n    ]\n}\n\ndf = pd.DataFrame(data)\n\ndf = df.sem_agg(\"Provide a concise summary of all {ArticleContent} in a single paragraph, highlighting the key technological progress and its implications for the future.\")\nprint(df._output[0])\n```\n\n----------------------------------------\n\nTITLE: Basic Semantic Join Example in Python using Lotus\nDESCRIPTION: Demonstrates how to perform a basic semantic join between two dataframes using natural language instructions. This example joins course names with skills based on whether a course helps learn a particular skill using GPT-4o-mini as the language model.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_join.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\ndata = {\n    \"Course Name\": [\n        \"History of the Atlantic World\",\n        \"Riemannian Geometry\",\n        \"Operating Systems\",\n        \"Food Science\",\n        \"Compilers\",\n        \"Intro to computer science\",\n    ]\n}\n\ndata2 = {\"Skill\": [\"Math\", \"Computer Science\"]}\n\ndf1 = pd.DataFrame(data)\ndf2 = pd.DataFrame(data2)\njoin_instruction = \"Taking {Course Name:left} will help me learn {Skill:right}\"\nres = df1.sem_join(df2, join_instruction)\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Semantic Clustering with Lotus Framework in Python\nDESCRIPTION: Example demonstrating how to use sem_cluster_by to cluster course names based on semantic similarity. The code configures language and retrieval models, creates a sample dataframe with course names, and performs clustering to group similar courses together.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_cluster.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, SentenceTransformersRM\n\nlm = LM(model=\"gpt-4o-mini\")\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n\nlotus.settings.configure(lm=lm, rm=rm)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n        \"Cooking\",\n        \"Food Sciences\",\n    ]\n}\ndf = pd.DataFrame(data)\ndf = df.sem_index(\"Course Name\", \"course_name_index\").sem_cluster_by(\"Course Name\", 2)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Basic Semantic Filtering with Pandas DataFrame in Python\nDESCRIPTION: This snippet demonstrates how to use sem_filter with a Pandas DataFrame to filter course names based on a natural language predicate. It uses the GPT-4o-mini language model for evaluation.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_filter.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n    ]\n}\ndf = pd.DataFrame(data)\nuser_instruction = \"{Course Name} requires a lot of math\"\ndf = df.sem_filter(user_instruction)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Creating a Semantic Index in LOTUS with Customized Models\nDESCRIPTION: This example demonstrates how to create a semantic index on a DataFrame column using LOTUS. It showcases the full workflow: importing required libraries, configuring language, retrieval, and reranking models, creating a sample DataFrame, and applying the sem_index operator to build a semantic index stored in a specified directory.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_index.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, CrossEncoderReranker, SentenceTransformersRM\n\nlm = LM(model=\"gpt-4o-mini\")\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\nreranker = CrossEncoderReranker(model=\"mixedbread-ai/mxbai-rerank-large-v1\")\n\nlotus.settings.configure(lm=lm, rm=rm, reranker=reranker)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n        \"Introduction to Computer Science\",\n        \"Introduction to Data Science\",\n        \"Introduction to Machine Learning\",\n        \"Introduction to Artificial Intelligence\",\n        \"Introduction to Robotics\",\n        \"Introduction to Computer Vision\",\n        \"Introduction to Natural Language Processing\",\n        \"Introduction to Reinforcement Learning\",\n        \"Introduction to Deep Learning\",\n        \"Introduction to Computer Networks\",\n    ]\n}\ndf = pd.DataFrame(data)\n\ndf = df.sem_index(\"Course Name\", \"index_dir\")\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Implementing Semantic Search with Reranking in LOTUS\nDESCRIPTION: Example showing how to use semantic search with reranking in LOTUS. It demonstrates setting up language and reranking models, configuring LOTUS settings, and performing a semantic search on a dataset of course names with reranking functionality.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_search.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, CrossEncoderReranker, SentenceTransformersRM\n\nlm = LM(model=\"gpt-4o-mini\")\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\nreranker = CrossEncoderReranker(model=\"mixedbread-ai/mxbai-rerank-large-v1\")\n\nlotus.settings.configure(lm=lm, rm=rm, reranker=reranker)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n        \"Introduction to Computer Science\",\n        \"Introduction to Data Science\",\n        \"Introduction to Machine Learning\",\n        \"Introduction to Artificial Intelligence\",\n        \"Introduction to Robotics\",\n        \"Introduction to Computer Vision\",\n        \"Introduction to Natural Language Processing\",\n        \"Introduction to Reinforcement Learning\",\n        \"Introduction to Deep Learning\",\n        \"Introduction to Computer Networks\",\n    ]\n}\ndf = pd.DataFrame(data)\n\ndf = df.sem_index(\"Course Name\", \"index_dir\").sem_search(\n    \"Course Name\",\n    \"Which course name is most related to computer security?\",\n    K=8,\n    n_rerank=4,\n)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Implementing Semantic Deduplication with Lotus in Python\nDESCRIPTION: This code snippet demonstrates how to use the Lotus library to perform semantic deduplication on a pandas DataFrame. It uses a SentenceTransformersRM model for text embedding and applies semantic indexing and deduplication with a specified threshold.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_dedup.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import SentenceTransformersRM\n\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n\nlotus.settings.configure(rm=rm)\ndata = {\n    \"Text\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n        \"I don't know what day it is\",\n        \"I don't know what time it is\",\n        \"Harry potter and the Sorcerer's Stone\",\n    ]\n}\ndf = pd.DataFrame(data)\ndf = df.sem_index(\"Text\", \"index_dir\").sem_dedup(\"Text\", threshold=0.815)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Using sem_map for Semantic Projection with Pandas in Lotus\nDESCRIPTION: This example demonstrates how to use the sem_map operator to perform semantic projections on a DataFrame containing course names. It configures a GPT-4o-mini language model, creates a dataframe with course names, and applies a natural language instruction to generate similar courses for each entry.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_map.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\ndata = {\n\"Course Name\": [\n    \"Probability and Random Processes\",\n    \"Optimization Methods in Engineering\",\n    \"Digital Design and Integrated Circuits\",\n    \"Computer Security\",\n]\n}\ndf = pd.DataFrame(data)\nuser_instruction = \"What is a similar course to {Course Name}. Be concise.\"\ndf = df.sem_map(user_instruction)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Using sem_partition_by with Clustering for Semantic Aggregation in LOTUS\nDESCRIPTION: This example demonstrates how to use sem_partition_by with LOTUS's clustering utility to partition data before semantic aggregation. The code initializes language and retrieval models, configures LOTUS settings, creates a DataFrame of course names, indexes it for semantic operations, partitions it using clustering, and then performs semantic aggregation.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_partition.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, SentenceTransformersRM\n\nlm = LM(max_tokens=2048)\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n\nlotus.settings.configure(lm=lm, rm=rm)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n        \"Cooking\",\n        \"Food Sciences\",\n    ]\n}\ndf = pd.DataFrame(data)\ndf = df.sem_index(\"Course Name\", \"course_name_index\").sem_partition_by(lotus.utils.cluster(\"Course Name\", 2))\nout = df.sem_agg(\"Summarize all {Course Name}\")._output[0]\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Using sem_topk for Natural Language-Based Ranking in LOTUS\nDESCRIPTION: Example demonstrating how to use the sem_topk operator to rank course names based on math requirements using different sorting algorithms. The code initializes a language model, configures LOTUS settings, creates a DataFrame, and applies sem_topk with various methods, returning the top 2 courses requiring the least math.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_topk.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n    ]\n}\ndf = pd.DataFrame(data)\n\nfor method in [\"quick\", \"heap\", \"naive\"]:\n    sorted_df, stats = df.sem_topk(\n        \"Which {Course Name} requires the least math?\",\n        K=2,\n        method=method,\n        return_stats=True,\n    )\n    print(sorted_df)\n    print(stats)\n```\n\n----------------------------------------\n\nTITLE: Initializing LM with Ollama's Llama 3.2\nDESCRIPTION: Creates an instance of the LM class to use the Llama 3.2 model through Ollama. This demonstrates how to specify a different model provider using the provider prefix in the model name.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/llm.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nlm = LM(model=\"ollama/llama3.2\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Semantic Similarity Join with Lotus\nDESCRIPTION: Demonstrates how to perform a semantic similarity join between two DataFrames using Lotus. The code initializes language and embedding models, creates two sample DataFrames with course names and skills, and performs a semantic similarity join to match courses with related skills.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_sim_join.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, LiteLLMRM\n\nlm = LM(model=\"gpt-4o-mini\")\nrm = LiteLLMRM(model=\"text-embedding-3-small\")\n\nlotus.settings.configure(lm=lm, rm=rm)\ndata = {\n    \"Course Name\": [\n        \"History of the Atlantic World\",\n        \"Riemannian Geometry\",\n        \"Operating Systems\",\n        \"Food Science\",\n        \"Compilers\",\n        \"Intro to computer science\",\n    ]\n}\n\ndata2 = {\"Skill\": [\"Math\", \"Computer Science\"]}\n\ndf1 = pd.DataFrame(data)\ndf2 = pd.DataFrame(data2).sem_index(\"Skill\", \"skill_index\")\nres = df1.sem_sim_join(df2, left_on=\"Course Name\", right_on=\"Skill\", K=1)\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Configuring Language Model in Lotus Settings\nDESCRIPTION: This snippet demonstrates how to import necessary modules and configure a Language Model (LM) in Lotus settings.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/configurations.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n```\n\n----------------------------------------\n\nTITLE: Creating Semantic Index and Performing Search on Course Descriptions\nDESCRIPTION: This snippet shows how to create a semantic index on a column and then perform a semantic search to find the most relevant course for a specific topic (convolutional neural networks).\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/examples.rst#2025-04-11_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create a semantic index on the description column and save it to the index_dir directory\ndf = df.sem_index(\"Description\", \"index_dir\")\ntop_conv_df = df.sem_search(\"Description\", \"Convolutional Neural Network\", K=1)\n```\n\n----------------------------------------\n\nTITLE: Filtering DataFrame Using DeepSeek-R1 Reasoning Model\nDESCRIPTION: This code demonstrates how to filter a pandas DataFrame using the DeepSeek-R1 reasoning model with the Lotus framework. It creates a DataFrame with product reviews, configures the language model with appropriate temperature settings, and uses semantic filtering to identify positive reviews with explanations.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/reasoning_models.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"ollama/deepseek-r1:7b\", temperature=0.5)\n\nlotus.settings.configure(lm=lm)\n\ndata = {\n    \"Reviews\": [\n        \"I absolutely love this product. It exceeded all my expectations.\",\n        \"Terrible experience. The product broke within a week.\",\n        \"The quality is average, nothing special.\",\n        \"Fantastic service and high quality!\",\n        \"I would not recommend this to anyone.\",\n    ]\n}\ndf = pd.DataFrame(data)\nuser_instruction = \"{Reviews} are positive reviews\"\ndf = df.sem_filter(user_instruction, return_explanations=True, return_all=True)\n\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Join Between Courses and Skills\nDESCRIPTION: This snippet demonstrates how to use the semantic join operator to find connections between two dataframes. It joins a dataframe of skills with a dataframe of courses to find which courses would help improve specific skills.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/examples.rst#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nskills_df = pd.DataFrame(\n    [(\"SQL\"), (\"Chip Design\")], columns=[\"Skill\"]\n)\nclasses_for_skills = skills_df.sem_join(\n    df, \"Taking {Course Name} will make me better at {Skill}\"\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing ImageArray with Multiple Image Formats in Python\nDESCRIPTION: Demonstrates how to create an ImageArray instance using different image formats. The example shows initialization with a PIL image loaded from file and a random numpy array. The ImageArray class allows for None values as well.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/multimodal_models.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom PIL import Image\nimport numpy as np\nfrom lotus.utils import ImageArray\n\n# Example image inputs\nimage1 = Image.open(\"path_to_image1.jpg\")\nimage2 = np.random.randint(0, 255, (100, 100, 3), dtype=\"uint8\")\n\n# Create an ImageArray\nimages = ImageArray([image1, image2, None])\n```\n\n----------------------------------------\n\nTITLE: Implementing Chain of Thought with Examples in Semantic Filter\nDESCRIPTION: Demonstrates how to use Chain of Thought reasoning with example data in Lotus's Semantic Filter operator. This approach guides the model through step-by-step reasoning using a provided examples DataFrame to filter courses that require math.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/prompt_strategies.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\nfrom lotus.types import ReasoningStrategy\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n    ]\n}\ndf = pd.DataFrame(data)\nuser_instruction = \"{Course Name} requires a lot of math\"\n\nexample_data = {\n    \"Course Name\": [\"Machine Learning\", \"Reaction Mechanisms\", \"Nordic History\"], \n    \"Answer\": [True, True, False],\n    \"Reasoning\": [\"Machine Learning requires a solid understanding of linear alebra and calculus\",\n                  \"Reaction Engineering requires Ordinary Differential Equations to solve reactor design problems\",\n                  \"Nordic History has no math involved\"]\n}\nexamples = pd.DataFrame(example_data)\n\ndf = df.sem_filter(user_instruction, examples=examples, strategy=ReasoningStrategy.COT)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Configuring Combined LiteLLM and SentenceTransformers Models\nDESCRIPTION: Shows how to set up both a language model (LM) using gpt-4o-mini and a retrieval model using text-embedding-3-small through LiteLLM.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/retriever_models.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, LiteLLMRM\n\nlm = LM(model=\"gpt-4o-mini\")\nrm = LiteLLMRM(model=\"text-embedding-3-small\")\n\nlotus.settings.configure(lm=lm, rm=rm)\n```\n\n----------------------------------------\n\nTITLE: Using Zero-Shot Chain of Thought with Semantic Filter\nDESCRIPTION: Shows implementation of Zero-Shot Chain of Thought reasoning strategy with Lotus's Semantic Filter. This example filters product reviews to identify which ones suggest the user would recommend the product, without requiring example data.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/prompt_strategies.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\nfrom lotus.types import ReasoningStrategy\n\nlm = LM(model=\"ollama/deepseek-r1:7b\", temperature=0.6)\nlotus.settings.configure(lm=lm)\n\ndata = {\n    \"Review\": [\n        \"This vacuum cleaner is the best I've ever owned. Highly recommend it!\",\n        \"It's okay, not sure I would buy it again.\",\n        \"Terrible experience, broke after a few uses.\",\n        \"Amazing build quality and customer support. Would absolutely recommend.\",\n    ]\n}\ndf = pd.DataFrame(data)\n\nuser_instruction = \"{Review} suggests that the user would recommend the product to others\"\n\ndf = df.sem_filter(\n    user_instruction, \n    strategy=ReasoningStrategy.ZS_COT, \n    return_explanations=True,\n    return_all=True\n)\n\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Semantic Aggregation with Group-By Functionality\nDESCRIPTION: Shows how to perform semantic aggregation with group-by functionality using the sem_agg operator. The example demonstrates grouping articles by category and generating summaries for each group.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_agg.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\n# Example DataFrame\ndata = {\n    \"Category\": [\"Tech\", \"Env\", \"Tech\", \"Env\"],\n    \"ArticleContent\": [\n        \"Quantum computing shows promise in solving complex problems.\",\n        \"Renewable energy helps mitigate climate change.\",\n        \"AI improves efficiency but raises ethical concerns.\",\n        \"New holes in the ozone layer have been found.\"\n    ]\n}\n\ndf = pd.DataFrame(data)\n\n# Perform semantic aggregation with groupby\ndf = df.sem_agg(\n    \"Summarize the {ArticleContent} for each {Category}.\",\n    group_by=[\"Category\"]\n)\n\nprint(df._output)\n```\n\n----------------------------------------\n\nTITLE: Using sem_extract for Text Data Extraction in Python\nDESCRIPTION: Demonstrates how to use sem_extract to extract names and ages from text descriptions using the Lotus framework. Shows two approaches: one with column descriptions and quote extraction, and another with simple column naming. Uses GPT-4 Mini as the language model.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_extract.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\ndf = pd.DataFrame(\n    {\n        \"description\": [\n            \"Yoshi is 25 years old\",\n            \"Bowser is 45 years old\",\n            \"Luigi is 15 years old\",\n        ]\n    }\n)\ninput_cols = [\"description\"]\n\n# A description can be specified for each output column\noutput_cols = {\n    \"masked_col_1\": \"The name of the person\",\n    \"masked_col_2\": \"The age of the person\",\n}\n\n# you can optionally set extract_quotes=True to return quotes that support each output\nnew_df = df.sem_extract(input_cols, output_cols, extract_quotes=True) \nprint(new_df)\n\n# A description can also be omitted for each output column\noutput_cols = {\n    \"name\": None,\n    \"age\": None,\n}\nnew_df = df.sem_extract(input_cols, output_cols)\nprint(new_df)\n```\n\n----------------------------------------\n\nTITLE: Loading Data from Google BigQuery\nDESCRIPTION: Example demonstrating data loading from Google BigQuery with aggregation and sorting, plus semantic filtering.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/data_connectors.rst#2025-04-11_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus.data_connectors import DataConnector\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\nquery = \"SELECT date, MAX(title) as title, AVG(rating) as rating FROM movies GROUPBY date ORDERBY rating desc\"\ndf = DataConnector.load_from_db(\"bigquery://my-gcp-project/my_dataset\", query=query)\n\nuser_instruction = \"{title} that are science fiction\"\ndf = df.sem_filter(user_instruction)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Using Semantic Top-K Operation to Find Courses with High Workload\nDESCRIPTION: This snippet shows how to use the semantic top-k operator to rank and retrieve the top 2 courses with the highest workload based on their descriptions.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/examples.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntop_2_hardest = df.sem_topk(\"What {Description} indicates the highest workload?\", K=2)\n```\n\n----------------------------------------\n\nTITLE: Setting Primary and Helper Language Models in Lotus\nDESCRIPTION: This code demonstrates how to configure both a primary and a secondary helper language model in Lotus settings.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/configurations.rst#2025-04-11_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ngpt_4o_mini = LM(\"gpt-4o-mini\")\ngpt_4o = LM(\"gpt-4o\")\n\nlotus.settings.configure(lm=gpt_4o, helper_lm=gpt_4o_mini)\n```\n\n----------------------------------------\n\nTITLE: Using Semantic Map with Examples for Course Topic Recommendations\nDESCRIPTION: This snippet demonstrates the semantic map operator with examples for few-shot learning. It creates a dataframe of example mappings and then uses semantic mapping to generate next topic recommendations for each course.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/examples.rst#2025-04-11_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nexamples_df = pd.DataFrame(\n    [(\"Computer Graphics\", \"Computer Vision\"), (\"Real Analysis\", \"Complex Analysis\")],\n    columns=[\"Course Name\", \"Answer\"]\n)\nnext_topics = df.sem_map(\n    \"Given {Course Name}, list a topic that will be good to explore next. \\\n    Respond with just the topic name and nothing else.\", examples=examples_df, suffix=\"Next Topics\"\n)\n```\n\n----------------------------------------\n\nTITLE: Searching Tavily with LOTUS\nDESCRIPTION: Python code demonstrating how to use LOTUS to search Tavily for AI ethics in 2025, process the results, and identify the top 3 articles that best explain ethical concerns in AI.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus import WebSearchCorpus, web_search\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\n\ndf = web_search(WebSearchCorpus.TAVILY, \"AI ethics in 2025\", 10)[[\"title\", \"summary\"]]\nprint(f\"Results from Tavily:\\n{df}\\n\")\ntop_tavily_articles = df.sem_topk(\"Which {summary} best explains ethical concerns in AI?\", K=3)\nprint(f\"Top 3 articles from Tavily on AI ethics:\\n{top_tavily_articles}\")\n```\n\n----------------------------------------\n\nTITLE: Advanced Semantic Join with Approximation in Python using Lotus\nDESCRIPTION: Illustrates an advanced semantic join with approximation using both language and embedding models. This example uses a cascade approach with recall and precision targets to efficiently join a larger dataset, reducing the number of expensive language model calls required.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/sem_join.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, SentenceTransformersRM\nfrom lotus.types import CascadeArgs\n\nlm = LM(model=\"gpt-4o-mini\")\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n\nlotus.settings.configure(lm=lm, rm=rm)\ndata = {\n    \"Course Name\": [\n        \"Digital Design and Integrated Circuits\",\n        \"Data Structures and Algorithms\",\n        \"The History of Art\",\n        \"Natural Language Processing\",\n    ]\n}\n\nskills = [\n    \"Math\", \"Computer Science\", \"Management\", \"Creative Writing\", \"Data Analysis\", \"Machine Learning\", \"Project Management\",\n    \"Problem Solving\", \"Singing\", \"Critical Thinking\", \"Public Speaking\", \"Teamwork\", \"Adaptability\", \"Programming\",\n    \"Leadership\", \"Time Management\", \"Negotiation\", \"Decision Making\", \"Networking\", \"Painting\",\n    \"Customer Service\", \"Marketing\", \"Graphic Design\", \"Nursery\", \"SEO\", \"Content Creation\", \"Video Editing\", \"Sales\",\n    \"Financial Analysis\", \"Accounting\", \"Event Planning\", \"Foreign Languages\", \"Software Development\", \"Cybersecurity\",\n    \"Social Media Management\", \"Photography\", \"Writing & Editing\", \"Technical Support\", \"Database Management\", \"Web Development\",\n    \"Business Strategy\", \"Operations Management\", \"UI/UX Design\", \"Reinforcement Learning\", \"Data Visualization\",\n    \"Product Management\", \"Cloud Computing\", \"Agile Methodology\", \"Blockchain\", \"IT Support\", \"Legal Research\", \"Supply Chain Management\",\n    \"Copywriting\", \"Human Resources\", \"Quality Assurance\", \"Medical Research\", \"Healthcare Management\", \"Sports Coaching\",\n    \"Editing & Proofreading\", \"Legal Writing\", \"Human Anatomy\", \"Chemistry\", \"Physics\", \"Biology\",\n    \"Psychology\", \"Sociology\", \"Anthropology\", \"Political Science\", \"Public Relations\", \"Fashion Design\", \"Interior Design\",\n    \"Automotive Repair\", \"Plumbing\", \"Carpentry\", \"Electrical Work\", \"Welding\", \"Electronics\", \"Hardware Engineering\",\n    \"Circuit Design\", \"Robotics\", \"Environmental Science\", \"Marine Biology\", \"Urban Planning\", \"Geography\",\n    \"Agricultural Science\", \"Animal Care\", \"Veterinary Science\", \"Zoology\", \"Ecology\", \"Botany\", \"Landscape Design\",\n    \"Baking & Pastry\", \"Culinary Arts\", \"Bartending\", \"Nutrition\", \"Dietary Planning\", \"Physical Training\", \"Yoga\",\n]\ndata2 = pd.DataFrame({\"Skill\": skills})\n\n\ndf1 = pd.DataFrame(data)\ndf2 = pd.DataFrame(data2)\njoin_instruction = \"By taking {Course Name:left} I will learn {Skill:right}\"\n\ncascade_args = CascadeArgs(recall_target=0.7, precision_target=0.7)\nres, stats = df1.sem_join(df2, join_instruction, cascade_args=cascade_args, return_stats=True)\n\n\nprint(f\"Joined {df1.shape[0]} rows from df1 with {df2.shape[0]} rows from df2\")\nprint(f\"    Join cascade took {stats['join_resolved_by_large_model']} LM calls\")\nprint(f\"    Helper resolved {stats['join_resolved_by_helper_model']} LM calls\")\nprint(f\"Join cascade used {stats['total_LM_calls']} LM calls in total\")\nprint(f\"Naive join would require {df1.shape[0]*df2.shape[0]} LM calls\")\nprint(res)\n```\n\n----------------------------------------\n\nTITLE: Searching Bing with LOTUS\nDESCRIPTION: Python code showing how to use LOTUS to search Bing for state-of-the-art AI models, process the results, and identify the top 3 most insightful articles.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus import WebSearchCorpus, web_search\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\n\ndf = web_search(WebSearchCorpus.BING, \"state-of-the-art AI models\", 10)[[\"title\", \"snippet\"]]\nprint(f\"Results from Bing:\\n{df}\\n\")\ntop_bing_articles = df.sem_topk(\"Which {snippet} provides the best insight into AI models?\", K=3)\nprint(f\"Top 3 most insightful articles from Bing:\\n{top_bing_articles}\")\n```\n\n----------------------------------------\n\nTITLE: LOTUS Semantic Join Example\nDESCRIPTION: Sample code demonstrating how to use LOTUS for semantic join operations between two dataframes. The example joins course names with relevant skills using natural language expressions (langex) as the join predicate.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/README.md#2025-04-11_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport lotus\nfrom lotus.models import LM\n\n# configure the LM, and remember to export your API key\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\n# create dataframes with course names and skills\ncourses_data = {\n    \"Course Name\": [\n        \"History of the Atlantic World\",\n        \"Riemannian Geometry\",\n        \"Operating Systems\",\n        \"Food Science\",\n        \"Compilers\",\n        \"Intro to computer science\",\n    ]\n}\nskills_data = {\"Skill\": [\"Math\", \"Computer Science\"]}\ncourses_df = pd.DataFrame(courses_data)\nskills_df = pd.DataFrame(skills_data)\n\n# lotus sem join \nres = courses_df.sem_join(skills_df, \"Taking {Course Name} will help me learn {Skill}\")\nprint(res)\n\n# Print total LM usage\nlm.print_total_usage()\n```\n\n----------------------------------------\n\nTITLE: Searching You.com with LOTUS\nDESCRIPTION: Python code demonstrating how to use LOTUS to search You.com for the latest AI breakthroughs, process the results, and identify the top 3 most groundbreaking articles.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus import WebSearchCorpus, web_search\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\n\ndf = web_search(WebSearchCorpus.YOU, \"latest AI breakthroughs\", 10)[[\"title\", \"snippet\"]]\nprint(f\"Results from You.com:\\n{df}\\n\")\ntop_you_articles = df.sem_topk(\"Which {snippet} is the most groundbreaking?\", K=3)\nprint(f\"Top 3 most interesting articles from You.com:\\n{top_you_articles}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring LOTUS Language Models for Cascade Operations\nDESCRIPTION: Sets up the main and helper language models required for cascade operations. Configures GPT-4O as the main model and GPT-4O-mini as the helper model.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/approximation_cascades.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus.models import LM\nfrom lotus.types import CascadeArgs\n\n\ngpt_4o_mini = LM(\"gpt-4o-mini\")\ngpt_4o = LM(\"gpt-4o\")\n\nlotus.settings.configure(lm=gpt_4o, helper_lm=gpt_4o_mini)\n```\n\n----------------------------------------\n\nTITLE: Loading Data from S3/MinIO\nDESCRIPTION: Example showing how to load data from S3-compatible storage (MinIO) with custom configuration and semantic filtering.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/data_connectors.rst#2025-04-11_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus.data_connectors import DataConnector\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\nservice_configs = {\n    \"minio\": {\n        \"aws_access_key\": \"accesskey\",\n        \"aws_secret_key\": \"secretkey\",\n        \"region\": None,\n        \"bucket\": \"test-bucket\",\n        \"file_path\": \"data/test.csv\",\n        \"protocol\": \"http\",\n        \"endpoint_url\": \"http://localhost:9000\",\n    }\n}\n\n# Get configuration for selected service\nservice = \"minio\"\nservice_config = service_configs[service]\n\n# loading data from s3\ndf = DataConnector.load_from_s3(\n    aws_access_key=(service_config[\"aws_access_key\"]),\n    aws_secret_key=(service_config[\"aws_secret_key\"]),\n    region=str(service_config[\"region\"]),\n    bucket=str(service_config[\"bucket\"]),\n    file_path=str(service_config[\"file_path\"]),\n    endpoint_url=(service_config[\"endpoint_url\"]),\n    protocol=str(service_config[\"protocol\"]),\n)\nuser_instruction = \"{title} is science fiction movie\"\ndf = df.sem_filter(user_instruction)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Setting Cascade Parameters\nDESCRIPTION: Configures cascade parameters including recall target, precision target, sampling percentage, and failure probability using CascadeArgs.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/approximation_cascades.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ncascade_args = CascadeArgs(recall_target=0.9, precision_target=0.9, sampling_percentage=0.5, failure_probability=0.2)\n```\n\n----------------------------------------\n\nTITLE: Configuring SentenceTransformersRM Model\nDESCRIPTION: Demonstrates how to initialize and configure a basic SentenceTransformers retrieval model using the e5-base-v2 model from intfloat.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/retriever_models.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import SentenceTransformersRM\n\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\n\nlotus.settings.configure(rm=rm)\n```\n\n----------------------------------------\n\nTITLE: Applying Semantic Filter with Cascade\nDESCRIPTION: Applies the semantic filter operation using configured cascade parameters and returns both the filtered DataFrame and performance statistics.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/approximation_cascades.rst#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf, stats = df.sem_filter(user_instruction=user_instruction, cascade_args=cascade_args, return_stats=True)\n```\n\n----------------------------------------\n\nTITLE: Setting LM Usage Limits in Python\nDESCRIPTION: This snippet demonstrates how to set usage limits for the language model to control costs and token consumption. It includes setting limits for prompt tokens, completion tokens, total tokens, and total cost.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/usage.rst#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nfrom lotus.types import UsageLimit, LotusUsageLimitException\n\n# Set limits\nusage_limit = UsageLimit(\n    prompt_tokens_limit=4000,\n    completion_tokens_limit=1000,\n    total_tokens_limit=3000,\n    total_cost_limit=1.00\n)\nlm = LM(model=\"gpt-4o\", physical_usage_limit=usage_limit)\n\ntry:\n    course_df = pd.read_csv(\"course_df.csv\")\n    course_df = course_df.sem_filter(\"What {Course Name} requires a lot of math\")\nexcept LotusUsageLimitException as e:\n    print(f\"Usage limit exceeded: {e}\")\n    # Handle the exception as needed\n```\n\n----------------------------------------\n\nTITLE: Initializing LM with Meta-Llama-3 on vLLM\nDESCRIPTION: Creates an instance of the LM class to use Meta-Llama-3-8B-Instruct through vLLM. This example shows how to customize the API base URL and set context and token generation limits.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/llm.rst#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nlm = LM(model='hosted_vllm/meta-llama/Meta-Llama-3-8B-Instruct',\n    api_base='http://localhost:8000/v1',\n    max_ctx_len=8000,\n    max_tokens=1000)\n```\n\n----------------------------------------\n\nTITLE: Monitoring and Resetting LM Usage Statistics\nDESCRIPTION: Shows how to monitor token usage and costs with the print_total_usage method and how to reset usage statistics when needed. This is useful for tracking and managing LLM API costs over time.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/llm.rst#2025-04-11_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# After running operations\nlm.print_total_usage()\n\n# Reset stats if needed\nlm.reset_stats()\n```\n\n----------------------------------------\n\nTITLE: Initializing LM with OpenAI GPT-4o\nDESCRIPTION: Creates an instance of the LM class to use OpenAI's GPT-4o model. The LM class serves as a wrapper around LiteLLM to provide a consistent interface for different LLM providers.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/llm.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nlm = LM(model=\"gpt-4o\")\n```\n\n----------------------------------------\n\nTITLE: Processing PowerPoint Files with DirectoryReader in Python\nDESCRIPTION: Shows how to use DirectoryReader to download and extract content from PowerPoint files.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/DirectoryReader.rst#2025-04-11_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.file_extractors import DirectoryReader\n\nppt_url = \"https://nlp.csie.ntust.edu.tw/files/meeting/Attention_is_all_you_need_C48rGUj.pptx\"\n\ndf = DirectoryReader().add(ppt_url).to_df(per_page=True)\nprint(f\"PPT Slides Extracted:\\n{df[['page_label', 'content']]}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring LM, Retrieval, and ReRanker Models in Lotus\nDESCRIPTION: This code snippet demonstrates how to import necessary modules, initialize LM, Retrieval, and ReRanker models, and configure Lotus settings with these models. It uses specific model instances for each type: gpt-4o-mini for LM, e5-base-v2 for Retrieval, and mxbai-rerank-large-v1 for ReRanker.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/reranker_models.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM, CrossEncoderReranker, SentenceTransformersRM\n\nlm = LM(model=\"gpt-4o-mini\")\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\nreranker = CrossEncoderReranker(model=\"mixedbread-ai/mxbai-rerank-large-v1\")\n\nlotus.settings.configure(lm=lm, rm=rm, reranker=reranker)\n```\n\n----------------------------------------\n\nTITLE: Printing Total LM Usage in Python\nDESCRIPTION: This snippet demonstrates how to print the total usage statistics for the configured language model in Lotus.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/usage.rst#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nlotus.settings.lm.print_total_usage()\n```\n\n----------------------------------------\n\nTITLE: Configuring Retrieval Model in Lotus Settings\nDESCRIPTION: This snippet shows how to configure a retrieval model (RM) in Lotus settings using SentenceTransformersRM.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/configurations.rst#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nrm = SentenceTransformersRM(model=\"intfloat/e5-base-v2\")\nlotus.settings.configure(rm=rm)\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS Using Conda and Pip\nDESCRIPTION: Commands to create a conda environment, activate it, and install LOTUS via pip. Sets up Python 3.10 environment.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/installation.rst#2025-04-11_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ conda create -n lotus python=3.10 -y\n$ conda activate lotus\n$ pip install lotus-ai\n```\n\n----------------------------------------\n\nTITLE: Enabling Caching in Lotus Settings\nDESCRIPTION: This code shows how to set up caching in Lotus, including configuring cache type, size, and directory. It also demonstrates how to create a cache instance and configure it with the language model.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/configurations.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\nfrom lotus.cache import CacheFactory, CacheConfig, CacheType\n\ncache_config = CacheConfig(cache_type=CacheType.SQLITE, max_size=1000)\ncache = CacheFactory.create_cache(cache_config)\n\nlm = LM(model='gpt-4o-mini', cache=cache)\nlotus.settings.configure(lm=lm, enable_cache=True)\n```\n\n----------------------------------------\n\nTITLE: Setting up Lotus Development Environment (Bash)\nDESCRIPTION: This snippet shows how to create a conda environment, clone the Lotus repository, install the package and development dependencies, and set up pre-commit hooks.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/CONTRIBUTING.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n lotus python=3.10 -y\nconda activate lotus\ngit clone git@github.com:stanford-futuredata/lotus.git\npip install -e .\npip install -r requirements-dev.txt\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Searching Google with LOTUS\nDESCRIPTION: Python code showing how to use LOTUS to perform a Google search for deep learning research, process the results, and identify the most interesting articles.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus import WebSearchCorpus, web_search\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\n\ndf = web_search(WebSearchCorpus.GOOGLE, \"deep learning research\", 5)[[\"title\", \"snippet\"]]\nprint(f\"Results from Google\\n{df}\")\nmost_interesting_articles = df.sem_topk(\"Which {snippet} is the most exciting?\", K=1)\nprint(f\"Most interesting articles\\n{most_interesting_articles}\")\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS Data Connectors\nDESCRIPTION: Installation command for the LOTUS data connectors submodule using pip.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/data_connectors.rst#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install lotus[data_connectors]\n```\n\n----------------------------------------\n\nTITLE: Searching Arxiv with LOTUS\nDESCRIPTION: Python code demonstrating how to use LOTUS to search Arxiv for deep learning articles, process the results, and find the most interesting article.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus import WebSearchCorpus, web_search\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\n\nlotus.settings.configure(lm=lm)\n\ndf = web_search(WebSearchCorpus.ARXIV, \"deep learning\", 5)[[\"title\", \"abstract\"]]\nprint(f\"Results from Arxiv\\n{df}\\n\\n\")\n\nmost_interesting_articles = df.sem_topk(\"Which {abstract} is most exciting?\", K=1)\nprint(f\"Most interesting article: \\n{most_interesting_articles.iloc[0]}\")\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies with Version Specifications\nDESCRIPTION: Defines exact version requirements for Python packages needed for ML operations. Includes packages for backoff retries, vector similarity search (FAISS), LLM interactions, numerical computing (NumPy), data manipulation (Pandas), text embeddings (sentence-transformers), token counting (tiktoken), and progress bars (tqdm).\nSOURCE: https://github.com/lotus-data/lotus/blob/main/requirements.txt#2025-04-11_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nbackoff==2.2.1\nfaiss-cpu==1.8.0.post1\nlitellm==1.51.0,<2.0.0\nnumpy==1.26.4\npandas==2.2.2\nsentence-transformers==3.0.1\ntiktoken==0.7.0\ntqdm==4.66.4\n```\n\n----------------------------------------\n\nTITLE: Loading Data from PostgreSQL Database\nDESCRIPTION: Example demonstrating data loading from a PostgreSQL database with rating filter and semantic filtering capabilities.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/data_connectors.rst#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus.data_connectors import DataConnector\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\nquery = \"SELECT * FROM movies WHERE rating > 5.0\"\ndf = DataConnector.load_from_db(\"postgresql+psycopg2://user:password@host:port/database\", query=query)\n\nuser_instruction = \"{title} that are science fiction\"\ndf = df.sem_filter(user_instruction)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Requirements with Versions\nDESCRIPTION: This code snippet defines the exact versions of Python packages required for the Lotus project. It includes documentation tools (Sphinx), vector similarity search (FAISS), embedding generation (sentence-transformers), numerical processing (NumPy, pandas), LLM integration (litellm), and utility libraries for the project.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/requirements-docs.txt#2025-04-11_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nsphinx==7.3.7\nsphinx-rtd-theme==2.0.0\n\nbackoff==2.2.1\nfaiss-cpu==1.8.0.post1\nlitellm==1.51.0\nnumpy==1.26.4\npandas==2.2.2\nsentence-transformers==3.0.1\ntiktoken==0.7.0\ntqdm==4.66.4\n```\n\n----------------------------------------\n\nTITLE: Loading Data from SQLite Database\nDESCRIPTION: Example showing how to load data from a SQLite database using LOTUS DataConnector and apply semantic filtering on movie titles.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/data_connectors.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus.data_connectors import DataConnector\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\nquery = \"SELECT * FROM movies\"\ndf = DataConnector.load_from_db(\"sqlite:///example_movies.db\", query=query)\n\nuser_instruction = \"{title} that are science fiction\"\ndf = df.sem_filter(user_instruction)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Enabling Logging for LOTUS Web Search\nDESCRIPTION: Python code snippet to enable logging for the LOTUS web_search function, useful for debugging and seeing available columns in search results.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nlogging.basicConfig(level=logging.INFO)\n```\n\n----------------------------------------\n\nTITLE: Loading Data from Snowflake Database\nDESCRIPTION: Example showing data loading from a Snowflake database with genre filtering and semantic search functionality.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/data_connectors.rst#2025-04-11_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport lotus\nfrom lotus.data_connectors import DataConnector\nfrom lotus.models import LM\n\nlm = LM(model=\"gpt-4o-mini\")\nlotus.settings.configure(lm=lm)\n\nquery = \"SELECT * FROM movies WHERE genre = 'Horror'\"\ndf = DataConnector.load_from_db(\"snowflake://<user>:<password>@<account>/<database>/<schema>?warehouse=<warehouse>&role=<role>\", query=query)\n\nuser_instruction = \"{title} that are science fiction\"\ndf = df.sem_filter(user_instruction)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS Tavily Submodule\nDESCRIPTION: Command to install the LOTUS Tavily submodule for integration with the Tavily search engine.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\npip install lotus[tavily]\n```\n\n----------------------------------------\n\nTITLE: Integrating DirectoryReader with LOTUS Semantic Operators in Python\nDESCRIPTION: Example of using LOTUS semantic operators on data loaded with DirectoryReader.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/DirectoryReader.rst#2025-04-11_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfiltered_df = df.sem_filter(user_instruction=\"Filter instruction here\", cascade_args=cascade_args)\nranked_df = filtered_df.sem_topk(\"Ranking instruction here\", K=3)\nprint(f\"Top Ranked Results:\\n{ranked_df[['content']]}\")\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS Bing Submodule\nDESCRIPTION: Command to install the LOTUS Bing submodule for integration with the Bing search engine.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\npip install lotus[bing]\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing PDF Files with DirectoryReader in Python\nDESCRIPTION: Example of using DirectoryReader to load a PDF file, convert it to a DataFrame, and perform semantic analysis using LOTUS.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/DirectoryReader.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\n\nimport lotus\nfrom lotus.file_extractors import DirectoryReader\nfrom lotus.models import LM, LiteLLMRM\nfrom lotus.types import CascadeArgs, ProxyModel\n\ngpt_4o = LM(\"gpt-4o\")\nrm = LiteLLMRM(model=\"text-embedding-3-small\")\nlotus.settings.configure(lm=gpt_4o, rm=rm)\n\n# Load the PDF file\npdf_path = pathlib.Path(__file__).parent / \"Poems on Love and Life.pdf\"\ndf = DirectoryReader().add(pdf_path).to_df(per_page=True)\n\ntop_motivating_poems = df.sem_topk(\"Which {content} is the most motivating?\", K=1)\n\nprint(top_motivating_poems[\"content\"].values[0])\n```\n\n----------------------------------------\n\nTITLE: Example Cascade Statistics Output\nDESCRIPTION: Sample output showing key performance metrics including cascade thresholds and model resolution counts.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/approximation_cascades.rst#2025-04-11_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n{'pos_cascade_threshold': 0.62, \n'neg_cascade_threshold': 0.52, \n'filters_resolved_by_helper_model': 95, \n'filters_resolved_by_large_model': 8, \n'num_routed_to_helper_model': 95}\n```\n\n----------------------------------------\n\nTITLE: Processing Remote PDF Files with DirectoryReader in Python\nDESCRIPTION: Demonstrates how to download and process PDF files from URLs using DirectoryReader.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/DirectoryReader.rst#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.file_extractors import DirectoryReader\n\npdf_urls = [\n    \"https://arxiv.org/pdf/1706.03762\",\n    \"https://arxiv.org/pdf/2407.11418\"\n]\n\ndf = DirectoryReader().add_multiple(pdf_urls).to_df(per_page=False)\nprint(f\"Loaded PDFs:\\n{df[['file_path', 'content']]}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing RST Documentation Structure\nDESCRIPTION: ReStructuredText markup defining the documentation structure with table of contents (toctree) directives organizing content into major sections including Getting Started, Semantic Operators, Utility Operators, Models, Advanced Usage, and Data Loading.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/index.rst#2025-04-11_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :hidden:\n   :maxdepth: 1\n   :caption: Getting Started\n\n   installation\n   core_concepts\n   examples\n\n.. toctree::\n   :hidden:\n   :maxdepth: 1\n   :caption: Semantic Operators\n\n   sem_map\n   sem_extract\n   sem_filter\n   sem_agg\n   sem_topk\n   sem_join\n   sem_search\n   sem_sim_join\n   sem_cluster\n\n.. toctree::\n   :hidden:\n   :maxdepth: 1\n   :caption: Utility Operators\n\n   sem_partition\n   sem_index\n   sem_dedup\n   web_search\n\n.. toctree::\n   :hidden:\n   :maxdepth: 1\n   :caption: Models   \n\n   llm\n   retriever_models\n   reranker_models\n   multimodal_models\n   usage\n\n.. toctree::\n   :hidden:\n   :maxdepth: 1\n   :caption: Advanced Usage\n\n   approximation_cascades\n   prompt_strategies\n   configurations\n   reasoning_models\n\n.. toctree::\n   :hidden:\n   :maxdepth: 1\n   :caption: Data Loading and DB Connectors\n\n   data_connectors\n   DirectoryReader\n```\n\n----------------------------------------\n\nTITLE: Mapping DataFrame Using DeepSeek-R1 with Zero-Shot Chain-of-Thought Reasoning\nDESCRIPTION: This code shows how to use the DeepSeek-R1 model for semantic mapping on a pandas DataFrame. It configures the Lotus framework with the language model, creates a DataFrame of course names, and uses zero-shot chain-of-thought reasoning to generate similar course recommendations with explanations.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/reasoning_models.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nimport lotus\nfrom lotus.models import LM\nfrom lotus.types import ReasoningStrategy\n\nlm = LM(model=\"ollama/deepseek-r1:7b\", temperature=0.5)\n\nlotus.settings.configure(lm=lm)\ndata = {\n    \"Course Name\": [\n        \"Probability and Random Processes\",\n        \"Optimization Methods in Engineering\",\n        \"Digital Design and Integrated Circuits\",\n        \"Computer Security\",\n    ]\n}\ndf = pd.DataFrame(data)\nuser_instruction = \"What is a similar course to {Course Name}. Just give the course name.\"\ndf = df.sem_map(user_instruction, return_explanations=True, strategy=ReasoningStrategy.ZS_COT)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Setting Usage Limits for LM\nDESCRIPTION: Demonstrates how to set physical and virtual usage limits for the LM class to control costs and token consumption. Physical limits apply to actual API calls while virtual limits include cached responses. The example shows how to handle exceptions when limits are exceeded.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/llm.rst#2025-04-11_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nfrom lotus.types import UsageLimit, LotusUsageLimitException\n\n# Set physical limit (actual API calls)\nphysical_limit = UsageLimit(\n    prompt_tokens_limit=4000,\n    completion_tokens_limit=1000,\n    total_tokens_limit=5000,\n    total_cost_limit=1.00\n)\n\n# Set virtual limit (includes cached responses)\nvirtual_limit = UsageLimit(\n    prompt_tokens_limit=10000,\n    completion_tokens_limit=2000,\n    total_tokens_limit=12000,\n    total_cost_limit=5.00\n)\n\n# Apply both limits to the LM\nlm = LM(\n    model=\"gpt-4o\",\n    physical_usage_limit=physical_limit,\n    virtual_usage_limit=virtual_limit\n)\n\ntry:\n    course_df = pd.read_csv(\"course_df.csv\")\n    course_df = course_df.sem_filter(\"What {Course Name} requires a lot of math\")\nexcept LotusUsageLimitException as e:\n    print(f\"Usage limit exceeded: {e}\")\n    # Handle the exception as needed\n```\n\n----------------------------------------\n\nTITLE: Loading Images from Multiple Sources using fetch_image in Python\nDESCRIPTION: Shows how to load images from various sources using the fetch_image utility. Demonstrates loading from local file paths, HTTP URLs, and base64 encoded strings. The fetch_image function handles the appropriate conversion for each source type.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/multimodal_models.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.utils import fetch_image\nfrom PIL import Image\n\nimage_path = \"path_to_image.jpg\"\nimage_url = \"https://example.com/image.png\"\nbase64_image = \"data:image/png;base64,...\" \n\n# Load images\npil_image = fetch_image(image_path)\nurl_image = fetch_image(image_url)\nbase64_image_obj = fetch_image(base64_image)\n```\n\n----------------------------------------\n\nTITLE: Resetting LM Usage Stats in Python\nDESCRIPTION: This code shows how to reset the language model usage statistics in Lotus.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/usage.rst#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nlotus.settings.lm.reset_stats()\n```\n\n----------------------------------------\n\nTITLE: Initializing Meta-Llama-3-8B-Instruct on vLLM with Lotus (Python)\nDESCRIPTION: This example illustrates how to create an LM object to use the Meta-Llama-3-8B-Instruct model on vLLM, specifying custom parameters like API base, maximum context length, and maximum tokens.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/CONTRIBUTING.md#2025-04-11_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nlm = LM(model='hosted_vllm/meta-llama/Meta-Llama-3-8B-Instruct',\n        api_base='http://localhost:8000/v1',\n        max_ctx_len=8000,\n        max_tokens=1000)\n```\n\n----------------------------------------\n\nTITLE: Initializing Llama 3.2 on Ollama with Lotus (Python)\nDESCRIPTION: This snippet shows how to create an LM object to use the Llama 3.2 model on Ollama using the Lotus framework.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/CONTRIBUTING.md#2025-04-11_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nlm = LM(model=\"ollama/llama3.2\")\n```\n\n----------------------------------------\n\nTITLE: Initializing GPT-4 Language Model with Lotus (Python)\nDESCRIPTION: This example demonstrates how to create an LM object for the GPT-4 model using the Lotus framework.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/CONTRIBUTING.md#2025-04-11_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom lotus.models import LM\nlm = LM(model=\"gpt-4o\")\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS from GitHub\nDESCRIPTION: Instructions for installing the latest development version of LOTUS directly from GitHub repository for access to the newest features.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/README.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n lotus python=3.10 -y\nconda activate lotus\npip install git+https://github.com/lotus-data/lotus.git@main\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS via pip\nDESCRIPTION: Instructions for installing the latest stable release of LOTUS using pip. This requires Python 3.10 installed through conda.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n lotus python=3.10 -y\nconda activate lotus\npip install lotus-ai\n```\n\n----------------------------------------\n\nTITLE: Installing FAISS GPU version on Mac\nDESCRIPTION: Command to install the GPU-enabled version of FAISS via conda on Mac systems for accelerated performance with LOTUS.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/README.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c pytorch -c nvidia faiss-gpu=1.8.0\n```\n\n----------------------------------------\n\nTITLE: Installing FAISS CPU version on Mac\nDESCRIPTION: Command to install the CPU-only version of FAISS via conda on Mac systems, which is required for LOTUS functionality.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/README.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c pytorch faiss-cpu=1.8.0\n```\n\n----------------------------------------\n\nTITLE: Installing Faiss Dependency for MacOS\nDESCRIPTION: Commands to install Faiss library via conda, with options for CPU-only or GPU+CPU versions. Specifically required for MacOS users.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/installation.rst#2025-04-11_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n# CPU-only version\n$ conda install -c pytorch faiss-cpu=1.8.0\n\n# GPU(+CPU) version\n$ conda install -c pytorch -c nvidia faiss-gpu=1.8.0\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS SerpAPI Submodule\nDESCRIPTION: Command to install the LOTUS SerpAPI submodule for Google search integration.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npip install lotus[serpapi]\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS You.com Submodule\nDESCRIPTION: Command to install the LOTUS You.com submodule for integration with the You.com search engine.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npip install lotus[you]\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS Arxiv Submodule\nDESCRIPTION: Command to install the LOTUS Arxiv submodule using pip.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/web_search.rst#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install lotus[arxiv]\n```\n\n----------------------------------------\n\nTITLE: Installing LOTUS File Extractor Module\nDESCRIPTION: Command to install the LOTUS file extractor submodule using pip.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/docs/DirectoryReader.rst#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install lotus-ai[file_extractor]\n```\n\n----------------------------------------\n\nTITLE: Configuring Python Development Dependencies\nDESCRIPTION: Lists required development dependencies with pinned versions for Python project maintenance. Includes ruff for linting, mypy for static type checking, pytest for testing, and pre-commit for git hooks. References a base requirements.txt file for core dependencies.\nSOURCE: https://github.com/lotus-data/lotus/blob/main/requirements-dev.txt#2025-04-11_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n-r requirements.txt\n\n# Additional development dependencies\nruff==0.7.2\nmypy==1.13.0\npytest==8.3.3\npre-commit==4.0.1\n```"
  }
]