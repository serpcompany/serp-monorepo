[
  {
    "owner": "eksctl-io",
    "repo": "eksctl",
    "content": "TITLE: Creating an EKS Cluster with a Config File\nDESCRIPTION: YAML configuration for a basic EKS cluster with two nodegroups. The first nodegroup has 10 m5.large instances with SSH access using the default key, while the second has 2 m5.xlarge instances with a custom SSH key.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/creating-and-managing-clusters.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: basic-cluster\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.large\n    desiredCapacity: 10\n    volumeSize: 80\n    ssh:\n      allow: true # will use ~/.ssh/id_rsa.pub as the default ssh key\n  - name: ng-2\n    instanceType: m5.xlarge\n    desiredCapacity: 2\n    volumeSize: 100\n    ssh:\n      publicKeyPath: ~/.ssh/ec2_id_rsa.pub\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Karpenter Installation in eksctl ClusterConfig\nDESCRIPTION: YAML configuration for adding Karpenter to a new EKS cluster, specifying the cluster metadata, Karpenter version, and a managed node group. The configuration includes required OIDC setup and discovery tags.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eksctl-karpenter.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-with-karpenter\n  region: us-west-2\n  version: '1.32' # requires a version of Kubernetes compatible with Karpenter\n  tags:\n    karpenter.sh/discovery: cluster-with-karpenter # here, it is set to the cluster name\niam:\n  withOIDC: true # required\n\nkarpenter:\n  version: '1.2.1' # Exact version should be specified according to the Karpenter compatibility matrix\n\nmanagedNodeGroups:\n  - name: managed-ng-1\n    minSize: 1\n    maxSize: 2\n    desiredCapacity: 1\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic EKS Cluster with eksctl\nDESCRIPTION: Creates a basic EKS cluster with default parameters including auto-generated name, two m5.large worker nodes, using the official EKS AMI in us-west-2 region.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster\n```\n\n----------------------------------------\n\nTITLE: Bootstrapping EKS Nodes with Shell Script (Amazon Linux 2)\nDESCRIPTION: This bash script is used to bootstrap EKS nodes running Amazon Linux 2. It retrieves instance metadata, sets environment variables, and starts the kubelet service.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n\nset -o errexit\nset -o pipefail\nset -o nounset\n\nfunction get_max_pods() {\n  while read instance_type pods; do\n    if  [[ \"${instance_type}\" == \"${1}\" ]] && [[ \"${pods}\" =~ ^[0-9]+$ ]] ; then\n      echo ${pods}\n      return\n    fi\n  done < /etc/eksctl/max_pods.map\n}\n\n# Use IMDSv2 to get metadata\nTOKEN=\"$(curl --silent -X PUT -H \"X-aws-ec2-metadata-token-ttl-seconds: 600\" http://169.254.169.254/latest/api/token)\"\nfunction get_metadata() {\n  curl --silent -H \"X-aws-ec2-metadata-token: $TOKEN\" \"http://169.254.169.254/latest/meta-data/$1\"\n}\n\nNODE_IP=\"$(get_metadata local-ipv4)\"\nINSTANCE_ID=\"$(get_metadata instance-id)\"\nINSTANCE_TYPE=\"$(get_metadata instance-type)\"\nAWS_SERVICES_DOMAIN=\"$(get_metadata services/domain)\"\n\n\nsource /etc/eksctl/kubelet.env # this can override MAX_PODS\n\ncat > /etc/eksctl/kubelet.local.env  <<EOF\nNODE_IP=${NODE_IP}\nINSTANCE_ID=${INSTANCE_ID}\nINSTANCE_TYPE=${INSTANCE_TYPE}\nAWS_SERVICES_DOMAIN=${AWS_SERVICES_DOMAIN}\nMAX_PODS=${MAX_PODS:-$(get_max_pods \"${INSTANCE_TYPE}\")}\nEOF\n\nsystemctl daemon-reload\nsystemctl enable kubelet\nsystemctl start kubelet\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster Using a Configuration File\nDESCRIPTION: Creates an EKS cluster by applying a configuration from a YAML file which allows for custom specification of cluster properties.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster -f cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Fargate Support via CLI\nDESCRIPTION: This command creates an EKS cluster with Fargate support using the eksctl CLI tool. It sets up the cluster, creates a default Fargate profile, and provides information about the cluster creation process.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster --fargate\n```\n\n----------------------------------------\n\nTITLE: Creating a managed nodegroup for an existing cluster\nDESCRIPTION: Command to add a managed nodegroup to an existing EKS cluster using the eksctl CLI.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create nodegroup --managed\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubeconfig for EKS Nodes\nDESCRIPTION: This YAML file configures the kubeconfig for EKS nodes. It specifies the cluster, context, and user authentication details for connecting to the EKS cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nkind: Config\napiVersion: v1\n\nclusters:\n- cluster:\n    certificate-authority: /etc/eksctl/ca.crt\n    server: https://0A3....gr7.us-west-2.eks.amazonaws.com\n  name: my-cluster-1.us-west-2.eksctl.io\ncontexts:\n- context:\n    cluster: my-cluster-1.us-west-2.eksctl.io\n    user: kubelet@my-cluster-1.us-west-2.eksctl.io\n  name: kubelet@my-cluster-1.us-west-2.eksctl.io\ncurrent-context: kubelet@my-cluster-1.us-west-2.eksctl.io\n\npreferences: {}\n\nusers:\n- name: kubelet@my-cluster-1.us-west-2.eksctl.io\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      args:\n      - eks\n      - get-token\n      - --cluster-name\n      - my-cluster-1\n      - --region\n      - us-west-2\n      command: aws\n      env:\n      - name: AWS_STS_REGIONAL_ENDPOINTS\n        value: regional\n```\n\n----------------------------------------\n\nTITLE: Enabling SSH Access with Custom Key\nDESCRIPTION: Creates an EKS cluster with SSH access enabled using a custom SSH public key instead of the default ~/.ssh/id_rsa.pub.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_14\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --ssh-access --ssh-public-key=my_eks_node_id.pub\n```\n\n----------------------------------------\n\nTITLE: Sample EKS Cluster Configuration\nDESCRIPTION: YAML configuration file example for creating an EKS cluster in eu-north-1 region with two node groups of different instance types and capacities.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: basic-cluster\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.large\n    desiredCapacity: 10\n  - name: ng-2\n    instanceType: m5.xlarge\n    desiredCapacity: 2\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic EKS Cluster with eksctl\nDESCRIPTION: Simple command to create an EKS cluster in your default region with one managed nodegroup containing two m5.large nodes. This will use your AWS CLI configuration for the region setting.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/creating-and-managing-clusters.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster\n```\n\n----------------------------------------\n\nTITLE: Scaling a Nodegroup\nDESCRIPTION: This command scales a nodegroup to a desired number of nodes. It can optionally set minimum and maximum node counts and wait for the scaling operation to complete.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\neksctl scale nodegroup --cluster=<clusterName> --nodes=<desiredCount> --name=<nodegroupName> [ --nodes-min=<minSize> ] [ --nodes-max=<maxSize> ] --wait\n```\n\n----------------------------------------\n\nTITLE: Creating a new cluster with managed nodegroup\nDESCRIPTION: Command to create a new EKS cluster with a default managed nodegroup configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster\n```\n\n----------------------------------------\n\nTITLE: Installing eksctl on Unix Systems\nDESCRIPTION: Shell script for downloading and installing the latest release of eksctl on Unix systems, with optional checksum verification. The script detects architecture and platform automatically.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/installation.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`\nARCH=amd64\nPLATFORM=$(uname -s)_$ARCH\n\ncurl -sLO \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz\"\n\n# (Optional) Verify checksum\ncurl -sL \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt\" | grep $PLATFORM | sha256sum --check\n\ntar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz\n\nsudo mv /tmp/eksctl /usr/local/bin\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster with Managed Nodegroup Using Spot Instances via Command Line\nDESCRIPTION: Command to create an EKS cluster with a managed nodegroup using Spot instances by specifying instance types through the --spot flag.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster --spot --instance-types=c3.large,c4.large,c5.large\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubelet with YAML Configuration\nDESCRIPTION: This YAML file configures the kubelet for EKS nodes. It specifies various settings such as cluster DNS, authentication, authorization, and resource reservations.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nkind: KubeletConfiguration\napiVersion: kubelet.config.k8s.io/v1beta1\n\nclusterDNS:\n- 10.100.0.10\n\naddress: 0.0.0.0\nclusterDomain: cluster.local\nserverTLSBootstrap: true\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 2m0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/eksctl/ca.crt\n\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 5m0s\n    cacheUnauthorizedTTL: 30s\n\ncgroupDriver: cgroupfs\nkubeReserved:\n  cpu: 60m\n  ephemeral-storage: 1Gi\n  memory: 343Mi\n\nfeatureGates:\n  RotateKubeletServerCertificate: true\n```\n\n----------------------------------------\n\nTITLE: Configuring a cluster with two managed nodegroups\nDESCRIPTION: YAML configuration for creating an EKS cluster with two managed nodegroups, including configurations for sizing, SSH access, labels, tags, and IAM policies.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# cluster.yaml\n# A cluster with two managed nodegroups\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: managed-cluster\n  region: us-west-2\n\nmanagedNodeGroups:\n  - name: managed-ng-1\n    minSize: 2\n    maxSize: 4\n    desiredCapacity: 3\n    volumeSize: 20\n    ssh:\n      allow: true\n      publicKeyPath: ~/.ssh/ec2_id_rsa.pub\n      # new feature for restricting SSH access to certain AWS security group IDs\n      sourceSecurityGroupIds: [\"sg-00241fbb12c607007\"]\n    labels: {role: worker}\n    tags:\n      nodegroup-role: worker\n    iam:\n      withAddonPolicies:\n        externalDNS: true\n        certManager: true\n\n  - name: managed-ng-2\n    instanceType: t2.large\n    minSize: 2\n    maxSize: 3\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster with Config File\nDESCRIPTION: Creates an EKS cluster using a configuration file that contains all cluster specifications and settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --config-file=<path>\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom VPC Subnets in YAML for eksctl\nDESCRIPTION: This YAML snippet demonstrates how to configure custom VPC subnets in eksctl, including multiple subnets per availability zone and arbitrary subnet keys. It shows both public and private subnet configurations.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-subnet-settings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  id: \"vpc-11111\"\n  subnets:\n    public:\n      public-one:                           # arbitrary key\n          id: \"subnet-0153e560b3129a696\"\n      public-two:\n          id: \"subnet-0cc9c5aebe75083fd\"\n      us-west-2b:                           # or list by AZ\n          id: \"subnet-018fa0176ba320e45\"\n    private:\n      private-one:\n          id: \"subnet-0153e560b3129a696\"\n      private-two:\n          id: \"subnet-0cc9c5aebe75083fd\"\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS Cluster with Auto Scaling Configuration\nDESCRIPTION: Creates an EKS cluster with an Auto Scaling Group configured for 3-5 nodes, allowing the cluster to scale according to workload demands.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_13\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --name=cluster-5 --nodes-min=3 --nodes-max=5\n```\n\n----------------------------------------\n\nTITLE: Creating Spot Instances Using Managed Nodegroups via Config File\nDESCRIPTION: Example YAML configuration file for creating a cluster with both Spot and On-Demand instances using managed nodegroups.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# spot-cluster.yaml\n\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: spot-cluster\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: spot\n  instanceTypes: [\"c3.large\",\"c4.large\",\"c5.large\",\"c5d.large\",\"c5n.large\",\"c5a.large\"]\n  spot: true\n\n\n# `instanceTypes` defaults to [`m5.large`]\n- name: spot-2\n  spot: true\n\n# On-Demand instances\n- name: on-demand\n  instanceTypes: [\"c3.large\", \"c4.large\", \"c5.large\"]\n```\n\n----------------------------------------\n\nTITLE: Deleting an EKS Cluster\nDESCRIPTION: Deletes an EKS cluster by name, with optional region specification. This removes all associated resources and cleans up the kubernetes config file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_19\n\nLANGUAGE: sh\nCODE:\n```\neksctl delete cluster --name=<name> [--region=<region>]\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubelet Service with Systemd Unit (Amazon Linux 2)\nDESCRIPTION: This systemd unit file configures the kubelet service for Amazon Linux 2. It sets environment variables and specifies the command line arguments for starting the kubelet.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_1\n\nLANGUAGE: ini\nCODE:\n```\n# eksctl-specific systemd drop-in unit for kubelet, for Amazon Linux 2 (AL2)\n\n[Service]\nEnvironmentFile=/etc/eksctl/metadata.env\nEnvironmentFile=/etc/eksctl/kubelet.env\nEnvironmentFile=/etc/eksctl/kubelet.local.env\n\nExecStart=\nExecStart=/usr/bin/kubelet \\\n  --node-ip=${NODE_IP} \\\n  --node-labels=${NODE_LABELS},alpha.eksctl.io/instance-id=${INSTANCE_ID} \\\n  --max-pods=${MAX_PODS} \\\n  --register-node=true --register-with-taints=${NODE_TAINTS} \\\n  --cloud-provider=aws \\\n  --container-runtime=docker \\\n  --network-plugin=cni \\\n  --cni-bin-dir=/opt/cni/bin \\\n  --cni-conf-dir=/etc/cni/net.d \\\n  --pod-infra-container-image=${AWS_EKS_ECR_ACCOUNT}.dkr.ecr.${AWS_DEFAULT_REGION}.${AWS_SERVICES_DOMAIN}/eks/pause:3.1-eksbuild.1 \\\n  --kubeconfig=/etc/eksctl/kubeconfig.yaml \\\n  --config=/etc/eksctl/kubelet.yaml\n```\n\n----------------------------------------\n\nTITLE: ARM-based EKS Cluster Configuration with Managed Node Groups\nDESCRIPTION: YAML configuration for creating an EKS cluster with ARM architecture using managed node groups. Managed node groups simplify node lifecycle management as AWS handles the provisioning and lifecycle of nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/arm-support.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-arm-2\n  region: us-west-2\n\nmanagedNodeGroups:\n  - name: mng-arm-1\n    instanceType: m6g.medium\n    desiredCapacity: 1\n```\n\n----------------------------------------\n\nTITLE: Configuring Access Entries in YAML for eksctl\nDESCRIPTION: YAML configuration example showing various access entry configurations including standard users, role-based access with namespace scoping, cluster admin access, and EC2 Linux node access.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\naccessConfig:\n  authenticationMode: API_AND_CONFIG_MAP\n  accessEntries:\n    - principalARN: arn:aws:iam::111122223333:user/my-user-name\n      type: STANDARD\n      kubernetesGroups: # optional Kubernetes groups\n        - group1 # groups can used to give permissions via RBAC\n        - group2\n\n    - principalARN: arn:aws:iam::111122223333:role/role-name-1\n      accessPolicies: # optional access polices\n        - policyARN: arn:aws:eks::aws:cluster-access-policy/AmazonEKSViewPolicy\n          accessScope:\n            type: namespace\n            namespaces:\n              - default\n              - my-namespace\n              - dev-*\n\n    - principalARN: arn:aws:iam::111122223333:role/admin-role\n      accessPolicies: # optional access polices\n        - policyARN: arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy\n          accessScope:\n            type: cluster\n\n    - principalARN: arn:aws:iam::111122223333:role/role-name-2\n      type: EC2_LINUX\n```\n\n----------------------------------------\n\nTITLE: Creating a Named Cluster with Specific Node Count\nDESCRIPTION: Creates an EKS cluster with a custom name and specific number of nodes, overriding the default auto-generated name and node count.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --name=cluster-1 --nodes=4\n```\n\n----------------------------------------\n\nTITLE: Configuring an EKS Cluster with Existing VPC\nDESCRIPTION: YAML configuration for creating an EKS cluster using an existing VPC with specified private subnets. It defines two nodegroups with different instance types and IAM permissions for specific workloads.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/creating-and-managing-clusters.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-in-existing-vpc\n  region: eu-north-1\n\nvpc:\n  subnets:\n    private:\n      eu-north-1a: { id: subnet-0ff156e0c4a6d300c }\n      eu-north-1b: { id: subnet-0549cdab573695c03 }\n      eu-north-1c: { id: subnet-0426fb4a607393184 }\n\nnodeGroups:\n  - name: ng-1-workers\n    labels: { role: workers }\n    instanceType: m5.xlarge\n    desiredCapacity: 10\n    privateNetworking: true\n  - name: ng-2-builders\n    labels: { role: builders }\n    instanceType: m5.2xlarge\n    desiredCapacity: 2\n    privateNetworking: true\n    iam:\n      withAddonPolicies:\n        imageBuilder: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Additional EBS Volumes in EKS NodeGroup\nDESCRIPTION: YAML configuration example showing how to specify additional EBS volumes for EKS managed node groups. Demonstrates configuration of multiple volumes with different storage types (gp2, gp3) and various volume parameters including encryption, IOPS, throughput, and snapshot restoration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-additional-volume-mappings.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: dev-cluster\n  region: eu-north-1\n\nmanagedNodeGroups:\n  - name: ng-1-workers\n    labels: { role: workers }\n    instanceType: m5.xlarge\n    desiredCapacity: 10\n    volumeSize: 80\n    additionalVolumes:\n      - volumeName: '/tmp/mount-1' # required\n        volumeSize: 80\n        volumeType: 'gp3'\n        volumeEncrypted: true\n        volumeKmsKeyID: 'id'\n        volumeIOPS: 3000\n        volumeThroughput: 125\n      - volumeName: '/tmp/mount-2'  # required\n        volumeSize: 80\n        volumeType: 'gp2'\n        snapshotID: 'snapshot-id'\n```\n\n----------------------------------------\n\nTITLE: Adding Node Repair Enabled Nodegroup to Existing Cluster (Shell)\nDESCRIPTION: This command creates a new managed nodegroup with Node Repair enabled on an existing EKS cluster. It requires specifying the cluster name and using the --enable-node-repair flag.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-node-repair-config.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create nodegroup --cluster=<clusterName> --enable-node-repair\n```\n\n----------------------------------------\n\nTITLE: Listing EKS Clusters\nDESCRIPTION: Lists details about a specific EKS cluster or all clusters, with optional filtering by name and region.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\neksctl get cluster [--name=<name>] [--region=<region>]\n```\n\n----------------------------------------\n\nTITLE: Setting EKS Metadata Environment Variables\nDESCRIPTION: Metadata environment configuration stored in /etc/eksctl/metadata.env containing AWS region, cluster name, endpoint and ECR account information.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_5\n\nLANGUAGE: ini\nCODE:\n```\nAWS_DEFAULT_REGION=us-west-2\nAWS_EKS_CLUSTER_NAME=my-cluster-1\nAWS_EKS_ENDPOINT=https://0A123.....gr7.us-west-2.eks.amazonaws.com\nAWS_EKS_ECR_ACCOUNT=602401143452\n\n```\n\n----------------------------------------\n\nTITLE: Configuring EKS Cluster with Private Networking (YAML)\nDESCRIPTION: YAML configuration for creating an EKS cluster with private subnets and enabling private networking for the nodegroup.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: my-test\n  region: us-west-2\n\nvpc:\n  id: \"vpc-11111\"\n  subnets:\n    private:\n      us-west-2d:\n          id: \"subnet-0ff156e0c4a6d300c\"\n      us-west-2c:\n          id: \"subnet-0549cdab573695c03\"\n      us-west-2a:\n          id: \"subnet-0426fb4a607393184\"\n\nnodeGroups:\n  - name: ng-1\n    privateNetworking: true\n```\n\n----------------------------------------\n\nTITLE: EKS Cluster Config with IAM Service Accounts in YAML\nDESCRIPTION: Example YAML configuration file for creating an EKS cluster with IAM service accounts. This defines multiple service accounts with different policies, including using well-known policies for cluster-autoscaler and custom-named roles.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n# An example of ClusterConfig with IAMServiceAccounts:\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-13\n  region: us-west-2\n\niam:\n  withOIDC: true\n  serviceAccounts:\n  - metadata:\n      name: s3-reader\n      # if no namespace is set, \"default\" will be used;\n      # the namespace will be created if it doesn't exist already\n      namespace: backend-apps\n      labels: {aws-usage: \"application\"}\n    attachPolicyARNs:\n    - \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n    tags:\n      Owner: \"John Doe\"\n      Team: \"Some Team\"\n  - metadata:\n      name: cache-access\n      namespace: backend-apps\n      labels: {aws-usage: \"application\"}\n    attachPolicyARNs:\n    - \"arn:aws:iam::aws:policy/AmazonDynamoDBReadOnlyAccess\"\n    - \"arn:aws:iam::aws:policy/AmazonElastiCacheFullAccess\"\n  - metadata:\n      name: cluster-autoscaler\n      namespace: kube-system\n      labels: {aws-usage: \"cluster-ops\"}\n    wellKnownPolicies:\n      autoScaler: true\n    roleName: eksctl-cluster-autoscaler-role\n    roleOnly: true\n  - metadata:\n      name: some-app\n      namespace: default\n    attachRoleARN: arn:aws:iam::123:role/already-created-role-for-app\nnodeGroups:\n  - name: \"ng-1\"\n    tags:\n      # EC2 tags required for cluster-autoscaler auto-discovery\n      k8s.io/cluster-autoscaler/enabled: \"true\"\n      k8s.io/cluster-autoscaler/cluster-13: \"owned\"\n    desiredCapacity: 1\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS Cluster Using a Config File\nDESCRIPTION: Command to create an EKS cluster using a YAML configuration file (cluster.yaml) that defines the cluster specifications and nodegroups.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/creating-and-managing-clusters.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster -f cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Upgrading EKS Control Plane to Next Available Version\nDESCRIPTION: Command to upgrade the control plane of an EKS cluster to the next available version. This command will first show planned changes and requires a second run with the --approve flag to apply changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-upgrade.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl upgrade cluster --name=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: Default VPC CIDR Configuration for EKS Clusters\nDESCRIPTION: Configuration details for the default VPC setup in eksctl, using CIDR block 192.168.0.0/16 with 8 subnets divided into public, private and reserved segments. Includes special case for us-east-1 region and important versioning notes regarding public subnet configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-networking.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nBy default `eksctl create cluster` will create a dedicated VPC for the cluster.\nThis is done in order to avoid interference with existing resources for a\nvariety of reasons, including security, but also because it is challenging to detect all settings in an existing VPC.\n\nThe default VPC CIDR used by `eksctl` is `192.168.0.0/16`. It is divided into 8 (`/19`) subnets (3 private, 3 public & 2 reserved).\nThe initial nodegroup is created in public subnets, with SSH access disabled unless `--allow-ssh` is specified.\nThe nodegroup by default allows inbound traffic from the control plane security group on ports 1025 - 65535.\n```\n\n----------------------------------------\n\nTITLE: Creating Nodegroup with Additional Features\nDESCRIPTION: This command creates a nodegroup with additional features enabled, such as SSH access, ASG access, and full ECR access. It also demonstrates how to add custom labels to the nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --cluster=cluster-1 --node-labels=\"autoscaling=enabled,purpose=ci-worker\" --asg-access --full-ecr-access --ssh-access\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Managed Nodegroups with Launch Templates - YAML Configuration\nDESCRIPTION: YAML configuration example demonstrating how to create managed nodegroups using EC2 launch templates. Shows two nodegroup configurations: one with basic launch template settings and another with additional nodegroup specifications including size, labels, tags, and networking options.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/launch-template-support.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# managed-cluster.yaml\n# A cluster with two managed nodegroups\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: managed-cluster\n  region: us-west-2\n\nmanagedNodeGroups:\n  - name: managed-ng-1\n    launchTemplate:\n      id: lt-12345\n      version: \"2\" # optional (uses the default launch template version if unspecified)\n\n  - name: managed-ng-2\n    minSize: 2\n    desiredCapacity: 2\n    maxSize: 4\n    labels:\n      role: worker\n    tags:\n      nodegroup-name: managed-ng-2\n    privateNetworking: true\n    launchTemplate:\n      id: lt-12345\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubelet Local Environment Variables in EKS\nDESCRIPTION: Local environment configuration for kubelet stored in /etc/eksctl/kubelet.local.env containing node-specific information like IP, instance details and AWS domain settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\nNODE_IP=192.168.72.51\nINSTANCE_ID=i-0b704274a75a321a7\nINSTANCE_TYPE=m6g.medium\nAWS_SERVICES_DOMAIN=amazonaws.com\nMAX_PODS=8\n```\n\n----------------------------------------\n\nTITLE: Creating IAM Service Account with Policy in eksctl\nDESCRIPTION: Command to create an IAM role bound to a Kubernetes service account with specified policy attachments. This creates both the IAM role and the service account in the cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\neksctl create iamserviceaccount --cluster=<clusterName> --name=<serviceAccountName> --namespace=<serviceAccountNamespace> --attach-policy-arn=<policyARN>\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Add-Ons with IAM Permissions in eksctl\nDESCRIPTION: YAML configuration example for defining EKS add-ons with various IAM permission options. This snippet demonstrates how to specify add-ons with version, tags, and different IAM permission approaches including policy ARNs, service account role ARN, or inline policies.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n  name: example-cluster\n  region: us-west-2\n\niam:\n  withOIDC: true\n\naddons:\n- name: vpc-cni\n  # all below properties are optional\n  version: 1.7.5\n  tags:\n    team: eks\n  # you can specify at most one of:\n  attachPolicyARNs:\n  - arn:aws:iam::account:policy/AmazonEKS_CNI_Policy\n  # or\n  serviceAccountRoleARN: arn:aws:iam::account:role/AmazonEKSCNIAccess\n  # or\n  attachPolicy:\n    Statement:\n    - Effect: Allow\n      Action:\n      - ec2:AssignPrivateIpAddresses\n      - ec2:AttachNetworkInterface\n      - ec2:CreateNetworkInterface\n      - ec2:DeleteNetworkInterface\n      - ec2:DescribeInstances\n      - ec2:DescribeTags\n      - ec2:DescribeNetworkInterfaces\n      - ec2:DescribeInstanceTypes\n      - ec2:DetachNetworkInterface\n      - ec2:ModifyNetworkInterfaceAttribute\n      - ec2:UnassignPrivateIpAddresses\n      Resource: '*'\n```\n\n----------------------------------------\n\nTITLE: Installing eksctl on Windows using Git Bash\nDESCRIPTION: Shell script for downloading and installing the latest release of eksctl on Windows using Git Bash, with optional checksum verification.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/installation.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\n# for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`\nARCH=amd64\nPLATFORM=windows_$ARCH\n\ncurl -sLO \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.zip\"\n\n# (Optional) Verify checksum\ncurl -sL \"https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt\" | grep $PLATFORM | sha256sum --check\n\nunzip eksctl_$PLATFORM.zip -d $HOME/bin\n\nrm eksctl_$PLATFORM.zip\n```\n\n----------------------------------------\n\nTITLE: Creating a nodegroup with eksctl CLI\nDESCRIPTION: Basic command to create a managed nodegroup using the eksctl command-line interface.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create nodegroup\n```\n\n----------------------------------------\n\nTITLE: Nodegroup Configuration in YAML\nDESCRIPTION: This YAML configuration defines two managed nodegroups with specific settings such as instance type, capacity, volume size, and networking. It demonstrates how to structure a config file for nodegroup creation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# dev-cluster.yaml\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: dev-cluster\n  region: eu-north-1\n\nmanagedNodeGroups:\n  - name: ng-1-workers\n    labels: { role: workers }\n    instanceType: m5.xlarge\n    desiredCapacity: 10\n    volumeSize: 80\n    privateNetworking: true\n  - name: ng-2-builders\n    labels: { role: builders }\n    instanceType: m5.2xlarge\n    desiredCapacity: 2\n    volumeSize: 100\n    privateNetworking: true\n```\n\n----------------------------------------\n\nTITLE: Configuring VPC Details for Non-eksctl Clusters in YAML\nDESCRIPTION: Minimum required VPC configuration in YAML format for creating nodegroups on clusters not created by eksctl. Includes cluster metadata, VPC ID, security group, and subnet configurations for both private and public subnets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/unowned-clusters.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: non-eksctl-created-cluster\n  region: us-west-2\n\nvpc:\n  id: \"vpc-12345\"\n  securityGroup: \"sg-12345\"    # this is the ControlPlaneSecurityGroup\n  subnets:\n    private:\n      private1:\n          id: \"subnet-12345\"\n      private2:\n          id: \"subnet-67890\"\n    public:\n      public1:\n          id: \"subnet-12345\"\n      public2:\n          id: \"subnet-67890\"\n\n...\n```\n\n----------------------------------------\n\nTITLE: Creating Cluster from Instance Selector Config\nDESCRIPTION: Command to create a cluster using a YAML configuration file with instance selector criteria.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/instance-selector.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster -f instance-selector-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Setting Labels on EKS Managed Nodegroup using eksctl\nDESCRIPTION: Command to set new labels or update existing labels on an EKS Managed Nodegroup. It uses the 'set labels' subcommand of eksctl, specifying the cluster, nodegroup, and desired labels.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_14\n\nLANGUAGE: console\nCODE:\n```\neksctl set labels --cluster managed-cluster --nodegroup managed-ng-1 --labels kubernetes.io/managed-by=eks,kubernetes.io/role=worker\n```\n\n----------------------------------------\n\nTITLE: EKS Instance Type Max Pods Mapping\nDESCRIPTION: Configuration file mapping AWS instance types to their maximum pod capacity stored in /etc/eksctl/max_pods.map\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nt2.micro 4\nx1e.32xlarge 234\nc1.xlarge 58\ng4dn.2xlarge 29\nr5.24xlarge 737\nr5a.12xlarge 234\nr5ad.xlarge 58\nt3.2xlarge 58\nc1.medium 12\nm5d.16xlarge 737\n...\n```\n\n----------------------------------------\n\nTITLE: Configuring AMI Families in EKS Cluster YAML Configuration\nDESCRIPTION: YAML configuration example demonstrating how to specify different AMI families for nodegroups, including Amazon Linux 2 for unmanaged nodes and Ubuntu 22.04 for managed nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/custom-ami-support.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1\n    instanceType: m5.large\n    amiFamily: AmazonLinux2\nmanagedNodeGroups:\n  - name: m-ng-2\n    instanceType: m5.large\n    amiFamily: Ubuntu2204\n```\n\n----------------------------------------\n\nTITLE: Configuring a managed nodegroup with custom AMI and advanced settings\nDESCRIPTION: YAML configuration showing advanced customization options for a managed nodegroup, including custom AMI, security groups, volume settings, and bootstrap command override.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# cluster.yaml\n# A cluster with a managed nodegroup with customization.\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: managed-cluster\n  region: us-west-2\n\nmanagedNodeGroups:\n  - name: custom-ng\n    ami: ami-0e124de4755b2734d\n    securityGroups:\n      attachIDs: [\"sg-1234\"]\n    maxPodsPerNode: 80\n    ssh:\n      allow: true\n    volumeSize: 100\n    volumeName: /dev/xvda\n    volumeEncrypted: true\n    # defaults to true, which enforces the use of IMDSv2 tokens\n    disableIMDSv1: false  \n    overrideBootstrapCommand: |\n      #!/bin/bash\n      /etc/eks/bootstrap.sh managed-cluster --kubelet-extra-args '--node-labels=eks.amazonaws.com/nodegroup=custom-ng,eks.amazonaws.com/nodegroup-image=ami-0e124de4755b2734d'\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS Cluster with Auto Mode Enabled\nDESCRIPTION: Demonstrates a minimal YAML configuration for creating an EKS cluster with Auto Mode enabled. This configuration sets autoModeConfig.enabled to true, which causes eksctl to create a cluster with compute, networking, and storage managed by AWS.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# auto-mode-cluster.yaml\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n    name: auto-mode-cluster\n    region: us-west-2\n\nautoModeConfig:\n    enabled: true\n```\n\n----------------------------------------\n\nTITLE: Configuring a cluster with availability zones for specific instance types\nDESCRIPTION: YAML configuration for creating an EKS cluster with managed nodegroups that specify availability zones, useful for instance types that are only available in specific zones.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n# cluster.yaml\n# A cluster with a managed nodegroup with \"availabilityZones\"\n---\n\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: flux-cluster\n  region: us-east-2\n  version: \"1.23\"\n \navailabilityZones: [\"us-east-2b\", \"us-east-2c\"]\nmanagedNodeGroups:\n  - name: workers\n    instanceType: hpc6a.48xlarge\n    minSize: 64\n    maxSize: 64\n    labels: { \"fluxoperator\": \"true\" }\n    availabilityZones: [\"us-east-2b\"]   \n    efaEnabled: true\n    placement:\n      groupName: eks-efa-testing\n```\n\n----------------------------------------\n\nTITLE: Creating Nodegroup with eksctl CLI\nDESCRIPTION: This command creates a new nodegroup for an existing cluster using the eksctl CLI. It allows specifying the cluster name and optionally the nodegroup name.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --cluster=<clusterName> [--name=<nodegroupName>]\n```\n\n----------------------------------------\n\nTITLE: Defining EksAllAccess Custom Policy in JSON\nDESCRIPTION: This custom policy grants full access to EKS and related services. It allows all EKS actions, access to specific SSM parameters, KMS actions for key management, and setting log retention policies.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/minimum-iam-policies.md#2025-04-21_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"eks:*\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Action\": [\n                \"ssm:GetParameter\",\n                \"ssm:GetParameters\"\n            ],\n            \"Resource\": [\n                \"arn:aws:ssm:*:<account_id>:parameter/aws/*\",\n                \"arn:aws:ssm:*::parameter/aws/*\"\n            ],\n            \"Effect\": \"Allow\"\n        },\n        {\n             \"Action\": [\n               \"kms:CreateGrant\",\n               \"kms:DescribeKey\"\n             ],\n             \"Resource\": \"*\",\n             \"Effect\": \"Allow\"\n        },\n        {\n             \"Action\": [\n               \"logs:PutRetentionPolicy\"\n             ],\n             \"Resource\": \"*\",\n             \"Effect\": \"Allow\"\n        }        \n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Pod Identity Association Commands\nDESCRIPTION: Various commands for creating pod identity associations using eksctl\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster -f config.yaml\n```\n\nLANGUAGE: bash\nCODE:\n```\neksctl create podidentityassociation -f config.yaml\n```\n\nLANGUAGE: bash\nCODE:\n```\neksctl create podidentityassociation \\\n    --cluster my-cluster \\\n    --namespace default \\\n    --service-account-name s3-reader \\\n    --permission-policy-arns=\"arn:aws:iam::111122223333:policy/permission-policy-1, arn:aws:iam::111122223333:policy/permission-policy-2\" \\\n    --well-known-policies=\"autoScaler,externalDNS\" \\\n    --permissions-boundary-arn arn:aws:iam::111122223333:policy/permissions-boundary\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Custom VPC Subnets (Bash)\nDESCRIPTION: Command to create an EKS cluster using eksctl with specified private and public subnets in an existing VPC.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster \\\n  --vpc-private-subnets=subnet-0ff156e0c4a6d300c,subnet-0426fb4a607393184 \\\n  --vpc-public-subnets=subnet-0153e560b3129a696,subnet-009fa0199ec203c37\n```\n\n----------------------------------------\n\nTITLE: Standalone Nodegroup Configuration\nDESCRIPTION: Example of a standalone nodegroup configuration file that can be used to add additional nodegroups to an existing cluster. Shows the proposed NodeGroupConfig structure.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-003-extending-use-of-config-file.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha4\nkind: NodeGroupConfig\n\nmetadata:\n  cluster: cluster-5\n  region: eu-north-1\n  name: ng3-extra\n\nspec:\n  instanceType: c4.xlarge\n  minSize: 10\n  maxSize: 20\n  privateNetworking: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Single Custom DNS Server in eksctl YAML\nDESCRIPTION: This YAML snippet demonstrates how to set a single custom DNS server IP address using the 'clusterDNS' field in the eksctl cluster configuration. It specifies the cluster name, region, and a node group with a custom DNS server IP.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-customize-dns.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-1\n  region: eu-north-1\n\nnodeGroups:\n- name: ng-1\n  clusterDNS: 169.254.20.10\n```\n\n----------------------------------------\n\nTITLE: Configuring Nodegroups for Fully-Private EKS Cluster in YAML\nDESCRIPTION: YAML configuration for setting up nodegroups in a fully-private EKS cluster. This example includes both managed and self-managed nodegroups with private networking enabled.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-private-cluster.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n- name: ng1\n  instanceType: m5.large\n  desiredCapacity: 2\n  # privateNetworking must be explicitly set for a fully-private cluster\n  # Rather than defaulting this field to `true`,\n  # we require users to explicitly set it to make the behaviour\n  # explicit and avoid confusion.\n  privateNetworking: true\n\nmanagedNodeGroups:\n- name: m1\n  instanceType: m5.large\n  desiredCapacity: 2\n  privateNetworking: true\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS Cluster with KMS Encryption in YAML Configuration\nDESCRIPTION: YAML configuration for creating an EKS cluster with KMS envelope encryption enabled. The configuration specifies the cluster name, region, managed node group, and the KMS key ARN to be used for encrypting Kubernetes secrets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/kms-encryption.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# kms-cluster.yaml\n# A cluster with KMS encryption enabled\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: kms-cluster\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: ng\n# more config\n\nsecretsEncryption:\n  # KMS key used for envelope encryption of Kubernetes secrets\n  keyARN: arn:aws:kms:us-west-2:<account>:key/<key>\n\n```\n\n----------------------------------------\n\nTITLE: Upgrading a nodegroup to a specific Kubernetes version\nDESCRIPTION: Command to upgrade a managed nodegroup to a specific Kubernetes version, useful when upgrading from an older version to match the cluster's version.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\neksctl upgrade nodegroup --name=managed-ng-1 --cluster=managed-cluster --kubernetes-version=1.15\n```\n\n----------------------------------------\n\nTITLE: EKS Cluster Configuration with Fargate Profiles\nDESCRIPTION: This YAML configuration file defines an EKS cluster with both a nodegroup and Fargate profiles. It specifies the cluster metadata, nodegroup details, and two Fargate profiles with different selectors for pod scheduling.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: fargate-cluster\n  region: ap-northeast-1\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.large\n    desiredCapacity: 1\n\nfargateProfiles:\n  - name: fp-default\n    selectors:\n      - namespace: default\n      - namespace: kube-system\n  - name: fp-dev\n    selectors:\n      - namespace: dev\n        labels:\n          env: dev\n          checks: passed\n```\n\n----------------------------------------\n\nTITLE: Configuring SSH Access for EKS Nodegroups using YAML\nDESCRIPTION: This YAML configuration demonstrates four different methods of enabling SSH access for EKS nodegroups: importing a public key from a file, using an existing EC2 key, specifying an inline public key, and enabling SSH using AWS Systems Manager (SSM).\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\nmanagedNodeGroups:\n  - name: ng-1\n    instanceType: m5.large\n    desiredCapacity: 1\n    ssh: # import public key from file\n      publicKeyPath: ~/.ssh/id_rsa_tests.pub\n  - name: ng-2\n    instanceType: m5.large\n    desiredCapacity: 1\n    ssh: # use existing EC2 key\n      publicKeyName: ec2_dev_key\n  - name: ng-3\n    instanceType: m5.large\n    desiredCapacity: 1\n    ssh: # import inline public key\n      publicKey: \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDqZEdzvHnK/GVP8nLngRHu/GDi/3PeES7+Bx6l3koXn/Oi/UmM9/jcW5XGziZ/oe1cPJ777eZV7muEvXg5ZMQBrYxUtYCdvd8Rt6DIoSqDLsIPqbuuNlQoBHq/PU2IjpWnp/wrJQXMk94IIrGjY8QHfCnpuMENCucVaifgAhwyeyuO5KiqUmD8E0RmcsotHKBV9X8H5eqLXd8zMQaPl+Ub7j5PG+9KftQu0F/QhdFvpSLsHaxvBzA5nhIltjkaFcwGQnD1rpCM3+UnQE7Izoa5Yt1xoUWRwnF+L2TKovW7+bYQ1kxsuuiX149jXTCJDVjkYCqi7HkrXYqcC1sbsror someuser@hostname\"\n  - name: ng-4\n    instanceType: m5.large\n    desiredCapacity: 1\n    ssh: # enable SSH using SSM\n      enableSsm: true\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Private Networking (Bash)\nDESCRIPTION: Command to create an EKS cluster using eksctl with private subnets and enable private networking for the initial nodegroup.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster \\\n  --vpc-private-subnets=subnet-0ff156e0c4a6d300c,subnet-0549cdab573695c03,subnet-0426fb4a607393184 \\\n  --node-private-networking\n```\n\n----------------------------------------\n\nTITLE: Retrieving Pod Identity Associations in EKS Cluster\nDESCRIPTION: Command to get existing pod identity associations for a specific cluster and namespace in JSON format. Shows the relationship between service accounts and IAM roles.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\neksctl get podidentityassociation --cluster my-cluster --namespace opentelemetry-operator-system --output json\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Fargate Support via Config File\nDESCRIPTION: This command creates an EKS cluster using a configuration file that defines both nodegroups and Fargate profiles. It demonstrates the cluster creation process, including setting up Fargate profiles and scheduling CoreDNS on Fargate.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster -f cluster-fargate.yaml\n```\n\n----------------------------------------\n\nTITLE: Config File Based Cluster Update\nDESCRIPTION: Command to update cluster using a configuration file that specifies metadata version and other settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-005-upgrades.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neksctl update cluster --config-file=cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating a Managed Nodegroup Using Spot Instances on an Existing Cluster\nDESCRIPTION: Command to add a managed nodegroup using Spot instances to an existing EKS cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create nodegroup --cluster=<clusterName> --spot --instance-types=c3.large,c4.large,c5.large\n```\n\n----------------------------------------\n\nTITLE: Advanced Karpenter Configuration Options in eksctl\nDESCRIPTION: YAML configuration showing additional Karpenter options for eksctl including creating a service account, specifying a custom instance profile, and enabling Spot Interruption Queue support.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eksctl-karpenter.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nkarpenter:\n  version: '1.2.1'\n  createServiceAccount: true # default is false\n  defaultInstanceProfile: 'KarpenterNodeInstanceProfile' # default is to use the IAM instance profile created by eksctl\n  withSpotInterruptionQueue: true # adds all required policies and rules for supporting Spot Interruption Queue, default is false\n```\n\n----------------------------------------\n\nTITLE: Creating ARM-based EKS Cluster via Command Line\nDESCRIPTION: Simple command to create an EKS cluster with ARM-based instances using the a1.large instance type. This is the most direct way to create a Graviton-powered cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/arm-support.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster --node-type=a1.large\n```\n\n----------------------------------------\n\nTITLE: Configuring a cluster with both managed and unmanaged nodegroups\nDESCRIPTION: YAML configuration example showing how to create an EKS cluster with both unmanaged and managed nodegroups in the same cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# cluster.yaml\n# A cluster with an unmanaged nodegroup and two managed nodegroups.\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: managed-cluster\n  region: us-west-2\n\nnodeGroups:\n  - name: ng-1\n    minSize: 2\n\nmanagedNodeGroups:\n  - name: managed-ng-1\n    minSize: 2\n    maxSize: 4\n    desiredCapacity: 3\n    volumeSize: 20\n    ssh:\n      allow: true\n      publicKeyPath: ~/.ssh/ec2_id_rsa.pub\n      # new feature for restricting SSH access to certain AWS security group IDs\n      sourceSecurityGroupIds: [\"sg-00241fbb12c607007\"]\n    labels: {role: worker}\n    tags:\n      nodegroup-role: worker\n    iam:\n      withAddonPolicies:\n        externalDNS: true\n        certManager: true\n\n  - name: managed-ng-2\n    instanceType: t2.large\n    privateNetworking: true\n    minSize: 2\n    maxSize: 3\n```\n\n----------------------------------------\n\nTITLE: Resolving Conflicts During Add-On Creation in eksctl\nDESCRIPTION: YAML configuration example showing how to set the resolveConflicts option for handling potential configMap conflicts during add-on creation. This option controls how eksctl handles existing self-managed versions of the add-ons.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: vpc-cni\n  attachPolicyARNs:\n    - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\n  resolveConflicts: overwrite\n```\n\n----------------------------------------\n\nTITLE: Basic Cluster Configuration with Nodegroups in YAML\nDESCRIPTION: Example of a basic eksctl cluster configuration file defining two nodegroups - one public and one private. Shows the fundamental structure of a ClusterConfig object.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-003-extending-use-of-config-file.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha4\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-5\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng1-public\n    instanceType: m5.xlarge\n    desiredCapacity: 4\n  - name: ng2-private\n    instanceType: m5.large\n    desiredCapacity: 10\n    privateNetworking: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Karpenter NodePool Resource\nDESCRIPTION: YAML definition for a Karpenter NodePool resource that defines node provisioning criteria including architecture, OS, capacity type, and instance types. It references an EC2NodeClass for specific AWS configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eksctl-karpenter.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.sh/v1\nkind: NodePool\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/description: \"Example NodePool\"\nspec:\n  template:\n    spec:\n      requirements:\n        - key: kubernetes.io/arch\n          operator: In\n          values: [\"amd64\"]\n        - key: kubernetes.io/os\n          operator: In\n          values: [\"linux\"]\n        - key: karpenter.sh/capacity-type\n          operator: In\n          values: [\"on-demand\"]\n        - key: karpenter.k8s.aws/instance-category\n          operator: In\n          values: [\"c\", \"m\", \"r\"]\n        - key: karpenter.k8s.aws/instance-generation\n          operator: Gt\n          values: [\"2\"]\n      nodeClassRef:\n        group: karpenter.k8s.aws\n        kind: EC2NodeClass\n        name: example # must match the name of an EC2NodeClass\n```\n\n----------------------------------------\n\nTITLE: Listing Fargate Profiles in a Cluster\nDESCRIPTION: Command to list existing Fargate profiles in a cluster, showing details like namespace selectors, labels, execution role ARN, and subnets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl get fargateprofile --cluster fargate-example-cluster\nNAME         SELECTOR_NAMESPACE  SELECTOR_LABELS  POD_EXECUTION_ROLE_ARN                                                                   SUBNETS\nfp-9bfc77ad  dev                 <none>           arn:aws:iam::123456789012:role/eksctl-fargate-example-cluster-ServiceRole-1T5F78E5FSH79  subnet-00adf1d8c99f83381,subnet-04affb163ffab17d4,subnet-035b34379d5ef5473\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS Cluster with Specific Kubernetes Version\nDESCRIPTION: Creates an EKS cluster with a specific Kubernetes version (1.28 in this example). EKS supports versions from 1.23 to 1.31, with 1.30 as default.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --version=1.28\n```\n\n----------------------------------------\n\nTITLE: Configuring EKS Cluster with Custom VPC (YAML)\nDESCRIPTION: YAML configuration for creating an EKS cluster with a custom VPC, specifying private and public subnets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: my-test\n  region: us-west-2\n\nvpc:\n  id: \"vpc-11111\"\n  subnets:\n    private:\n      us-west-2a:\n          id: \"subnet-0ff156e0c4a6d300c\"\n      us-west-2c:\n          id: \"subnet-0426fb4a607393184\"\n    public:\n      us-west-2a:\n          id: \"subnet-0153e560b3129a696\"\n      us-west-2c:\n          id: \"subnet-009fa0199ec203c37\"\n\nnodeGroups:\n  - name: ng-1\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Managed Node Groups from Configuration File\nDESCRIPTION: Command to create an EKS cluster with managed node groups using a YAML configuration file. This allows AWS to manage the node group lifecycle, including upgrades and scaling.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/arm-support.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster -f cluster-arm-2.yaml\n```\n\n----------------------------------------\n\nTITLE: Updating an Existing Cluster to Use Auto Mode\nDESCRIPTION: Shows the YAML configuration and command for updating an existing EKS cluster to use Auto Mode. This allows clusters created without Auto Mode to be updated to leverage AWS-managed infrastructure components.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# cluster.yaml\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n    name: cluster\n    region: us-west-2\n\nautoModeConfig:\n    enabled: true\n```\n\n----------------------------------------\n\nTITLE: ARM-based EKS Cluster Configuration with Self-managed Node Groups\nDESCRIPTION: YAML configuration for creating an EKS cluster with ARM architecture using self-managed node groups. The configuration specifies m6g.medium instance type which is powered by Graviton2 processors.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/arm-support.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-arm-1\n  region: us-west-2\n\n\nnodeGroups:\n  - name: ng-arm-1\n    instanceType: m6g.medium\n    desiredCapacity: 1\n```\n\n----------------------------------------\n\nTITLE: Enabling KMS Encryption on Existing EKS Cluster Using Config File\nDESCRIPTION: Shell command to enable KMS envelope encryption on an existing EKS cluster using the eksctl CLI with a configuration file. This approach uses the same YAML file that would be used for cluster creation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/kms-encryption.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl utils enable-secrets-encryption -f kms-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring IPv6 Support in eksctl YAML Configuration\nDESCRIPTION: This YAML configuration demonstrates how to set up a cluster with IPv6 support using eksctl. It includes necessary settings like IP family, addons, and IAM configuration. The cluster version is set to 1.21 and the region to us-west-2.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-ip-family.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: my-test\n  region: us-west-2\n  version: \"1.21\"\n\nkubernetesNetworkConfig:\n  ipFamily: IPv6 # or IPv4\n\naddons:\n  - name: vpc-cni\n  - name: coredns\n  - name: kube-proxy\n\niam:\n  withOIDC: true\n```\n\n----------------------------------------\n\nTITLE: Attaching IAM Policies by ARN in eksctl\nDESCRIPTION: Example demonstrating how to attach policies by ARN to a node group, combining both default EKS policies and custom policies. This approach requires including the default node policies explicitly when using attachPolicyARNs.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-policies.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: my-special-nodegroup\n    iam:\n      attachPolicyARNs:\n        - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\n        - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\n        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\n        - arn:aws:iam::aws:policy/ElasticLoadBalancingFullAccess\n        - arn:aws:iam::1111111111:policy/kube2iam\n      withAddonPolicies:\n        autoScaler: true\n        imageBuilder: true\n```\n\n----------------------------------------\n\nTITLE: Creating Fargate Profiles from Config File\nDESCRIPTION: Command showing how to create multiple Fargate profiles defined in a YAML configuration file. This creates both profiles and schedules CoreDNS onto Fargate.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create fargateprofile -f fargate-example-cluster.yaml\n[]  creating Fargate profile \"fp-default\" on EKS cluster \"fargate-example-cluster\"\n[]  created Fargate profile \"fp-default\" on EKS cluster \"fargate-example-cluster\"\n[]  creating Fargate profile \"fp-dev\" on EKS cluster \"fargate-example-cluster\"\n[]  created Fargate profile \"fp-dev\" on EKS cluster \"fargate-example-cluster\"\n[]  \"coredns\" is now scheduled onto Fargate\n[]  \"coredns\" pods are now scheduled onto Fargate\n```\n\n----------------------------------------\n\nTITLE: Full YAML Configuration for Fully-Private EKS Cluster with Pre-existing VPC\nDESCRIPTION: Complete YAML configuration for creating a fully-private EKS cluster using a pre-existing VPC and subnets. This example includes private subnets, additional endpoint services, and both managed and self-managed nodegroups.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-private-cluster.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: private-cluster\n  region: us-west-2\n\nprivateCluster:\n  enabled: true\n  additionalEndpointServices:\n  - \"autoscaling\"\n\nvpc:\n  subnets:\n    private:\n      us-west-2b:\n        id: subnet-0818beec303f8419b\n      us-west-2c:\n        id: subnet-0d42ef09490805e2a\n      us-west-2d:\n        id: subnet-0da7418077077c5f9\n\n\nnodeGroups:\n- name: ng1\n  instanceType: m5.large\n  desiredCapacity: 2\n  # privateNetworking must be explicitly set for a fully-private cluster\n  # Rather than defaulting this field to true for a fully-private cluster, we require users to explicitly set it\n  # to make the behaviour explicit and avoid confusion.\n  privateNetworking: true\n\nmanagedNodeGroups:\n- name: m1\n  instanceType: m5.large\n  desiredCapacity: 2\n  privateNetworking: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Bottlerocket Custom AMI in EKS Cluster YAML Configuration\nDESCRIPTION: YAML configuration example for creating a Bottlerocket nodegroup with a custom AMI, showing how to enable the admin container and specify a custom bootstrap container instead of using an override command.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/custom-ami-support.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n  nodeGroups:\n  - name: bottlerocket-ng\n    ami: ami-custom1234\n    amiFamily: Bottlerocket\n    bottlerocket:\n      enableAdminContainer: true\n      settings:\n        bootstrap-containers:\n          bootstrap:\n            source: <MY-CONTAINER-URI>\n```\n\n----------------------------------------\n\nTITLE: Running Full Integration Test Suite for eksctl\nDESCRIPTION: Commands for running the complete integration test suite with verbose output. This is used to verify that changes work correctly with real AWS infrastructure.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nTEST_V=1 make integration-test\n```\n\n----------------------------------------\n\nTITLE: Extending an existing EKS cluster to AWS Outposts\nDESCRIPTION: YAML configuration for extending an existing EKS cluster to AWS Outposts by creating nodegroups on Outposts. This allows for hybrid deployments with the control plane in a region and worker nodes on Outposts.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\n# extended-cluster.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: existing-cluster\n  region: us-west-2\n\nnodeGroups:\n  # Nodegroup will be created in an AWS region.\n  - name: ng\n\n  # Nodegroup will be created on the specified Outpost.\n  - name: outpost-ng\n    privateNetworking: true\n    outpostARN: \"arn:aws:outposts:us-west-2:1234:outpost/op-1234\"\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster with Selected Default Add-Ons\nDESCRIPTION: YAML configuration example showing how to create an EKS cluster with only specific default add-ons (CoreDNS and kube-proxy, but not VPC CNI) by explicitly defining them while disabling automatic installation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\naddonsConfig:\n  disableDefaultAddons: true\naddons:\n  - name: kube-proxy\n  - name: coredns\n```\n\n----------------------------------------\n\nTITLE: Configuring Complex Fargate Profiles with YAML\nDESCRIPTION: YAML configuration file demonstrating how to create multiple Fargate profiles with complex namespace and label selectors. This approach allows for more granular control than the CLI flags.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: fargate-example-cluster\n  region: ap-northeast-1\n\nfargateProfiles:\n  - name: fp-default\n    selectors:\n      # All workloads in the \"default\" Kubernetes namespace will be\n      # scheduled onto Fargate:\n      - namespace: default\n      # All workloads in the \"kube-system\" Kubernetes namespace will be\n      # scheduled onto Fargate:\n      - namespace: kube-system\n  - name: fp-dev\n    selectors:\n      # All workloads in the \"dev\" Kubernetes namespace matching the following\n      # label selectors will be scheduled onto Fargate:\n      - namespace: dev\n        labels:\n          env: dev\n          checks: passed\n```\n\n----------------------------------------\n\nTITLE: Configuring Taints for Kubernetes Nodegroups in eksctl YAML\nDESCRIPTION: This snippet demonstrates how to apply Kubernetes taints to a specific nodegroup in an eksctl configuration file. It shows how to define multiple taints with different effects (NoSchedule and NoExecute) and custom domain keys.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-taints.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n    taints:\n      - key: your.domain.com/db\n        value: \"true\"\n        effect: NoSchedule\n      - key: your.domain.com/production\n        value: \"true\"\n        effect: NoExecute\n```\n\n----------------------------------------\n\nTITLE: Configuring Auto Scaling Policies in nodeGroup Definition\nDESCRIPTION: YAML configuration that adds the required IAM policies to a nodegroup for the Cluster Autoscaler to function properly. This enables the autoscaler to scale the nodegroup based on resource demand.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/autoscaling.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1-public\n    iam:\n      withAddonPolicies:\n        autoScaler: true\n```\n\n----------------------------------------\n\nTITLE: AmazonLinux2023 NodeConfig YAML Configuration Example\nDESCRIPTION: Example of the YAML configuration format used for AL2023 nodes. This format replaces the traditional bootstrap.sh script with a YAML-based nodeadm configuration that specifies cluster parameters and kubelet settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/nodebootstrap/README.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nMIME-Version: 1.0\nContent-Type: multipart/mixed; boundary=//\n\n--//\nContent-Type: application/node.eks.aws\n\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  cluster:\n    apiServerEndpoint: https://XXXX.us-west-2.eks.amazonaws.com\n    certificateAuthority: XXXX\n    cidr: 10.100.0.0/16\n    name: my-cluster\n  kubelet:\n    config:\n      clusterDNS:\n      - 10.100.0.10\n    flags:\n    - --node-labels=alpha.eksctl.io/cluster-name=my-cluster,alpha.eksctl.io/nodegroup-name=my-nodegroup\n    - --register-with-taints=special=true:NoSchedule (only for EKS-managed nodes)\n\n--//--\n```\n\n----------------------------------------\n\nTITLE: Zone-Aware NodeGroup Configuration\nDESCRIPTION: YAML configuration demonstrating how to create separate nodegroups for different availability zones. This approach is necessary for workloads with zone-specific storage or scheduling requirements.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/autoscaling.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1-public-2a\n    instanceType: m5.xlarge\n    availabilityZones: [\"eu-west-2a\"]\n  - name: ng1-public-2b\n    instanceType: m5.xlarge\n    availabilityZones: [\"eu-west-2b\"]\n```\n\n----------------------------------------\n\nTITLE: Enabling Flux using eksctl Command\nDESCRIPTION: Command to bootstrap Flux v2 components into an EKS cluster using eksctl. This requires a configuration file that specifies the desired Flux settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gitops-v2.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\neksctl enable flux --config-file <config-file>\n```\n\n----------------------------------------\n\nTITLE: Configuring IAM Addon Policies in eksctl YAML\nDESCRIPTION: Example of a nodeGroup configuration that enables various addon IAM policies for different AWS services including ECR, AutoScaler, ExternalDNS, and more. This grants the node group appropriate permissions to interact with these AWS services.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-policies.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.xlarge\n    desiredCapacity: 1\n    iam:\n      withAddonPolicies:\n        imageBuilder: true\n        autoScaler: true\n        externalDNS: true\n        certManager: true\n        appMesh: true\n        appMeshPreview: true\n        ebs: true\n        fsx: true\n        efs: true\n        awsLoadBalancerController: true\n        xRay: true\n        cloudWatch: true\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests with Output Logging\nDESCRIPTION: Command for running integration tests while saving output to a file. This is helpful for debugging test failures since the test output can be quite verbose.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nTEST_V=1 make integration-test 2>&1 | tee <some-name>.log\n```\n\n----------------------------------------\n\nTITLE: Creating Nodegroups from Config File\nDESCRIPTION: This command creates nodegroups defined in a YAML configuration file. It's used to apply the nodegroup definitions to an existing cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --config-file=dev-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring API Endpoint Access and CIDRs in YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure both API server endpoint access and public access CIDRs in a cluster config file for updating an EKS cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  clusterEndpoints:\n    publicAccess:  <true|false>\n    privateAccess: <true|false>\n  publicAccessCIDRs: [\"1.1.1.1/32\"]\n```\n\n----------------------------------------\n\nTITLE: Nodegroup Configuration with Load Balancers\nDESCRIPTION: This YAML configuration demonstrates how to attach existing classic load balancers and target groups to self-managed nodegroups. It also includes ASG metrics collection settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# dev-cluster-with-lb.yaml\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: dev-cluster\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng-1-web\n    labels: { role: web }\n    instanceType: m5.xlarge\n    desiredCapacity: 10\n    privateNetworking: true\n    classicLoadBalancerNames:\n      - dev-clb-1\n      - dev-clb-2\n    asgMetricsCollection:\n      - granularity: 1Minute\n        metrics:\n          - GroupMinSize\n          - GroupMaxSize\n          - GroupDesiredCapacity\n          - GroupInServiceInstances\n          - GroupPendingInstances\n          - GroupStandbyInstances\n          - GroupTerminatingInstances\n          - GroupTotalInstances\n  - name: ng-2-api\n    labels: { role: api }\n    instanceType: m5.2xlarge\n    desiredCapacity: 2\n    privateNetworking: true\n    targetGroupARNs:\n      - arn:aws:elasticloadbalancing:eu-north-1:01234567890:targetgroup/dev-target-group-1/abcdef0123456789\n```\n\n----------------------------------------\n\nTITLE: Combined YAML Config for EKS Subnets and Security Groups\nDESCRIPTION: A YAML configuration file that defines both control plane subnet IDs and security group IDs in a single configuration. This allows updating both aspects of the cluster's VPC configuration together.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n  name: cluster\n  region: us-west-2\n\nvpc:\n  controlPlaneSubnetIDs: [subnet-1234, subnet-5678]\n  controlPlaneSecurityGroupIDs: [sg-1234, sg-5678]\n```\n\n----------------------------------------\n\nTITLE: Creating S3 Read-Only IAM Service Account in eksctl\nDESCRIPTION: Example command that creates a service account with S3 read-only access in the default namespace. This allows pods using this service account to access S3 with read-only permissions.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\neksctl create iamserviceaccount --cluster=<clusterName> --name=s3-read-only --attach-policy-arn=arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n```\n\n----------------------------------------\n\nTITLE: Scaling EKS Managed Nodegroup using eksctl\nDESCRIPTION: Command to scale an EKS Managed Nodegroup. It uses the 'scale nodegroup' subcommand of eksctl, specifying the nodegroup name, cluster, desired number of nodes, and min/max node limits.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_17\n\nLANGUAGE: console\nCODE:\n```\neksctl scale nodegroup --name=managed-ng-1 --cluster=managed-cluster --nodes=4 --nodes-min=3 --nodes-max=5\n```\n\n----------------------------------------\n\nTITLE: Configuring Addon Pod Identity Associations\nDESCRIPTION: YAML configuration for updating addon pod identity associations, including creating new associations, updating permissions, and removing existing ones.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: adot\n  podIdentityAssociations:\n\n  # For the first association, the permissions policy of the role will be updated\n  - serviceAccountName: adot-col-prom-metrics\n    permissionPolicyARNs:\n    #- arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess\n    - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy\n\n  # The second association will be deleted, as it's been removed from the config file\n  #- serviceAccountName: adot-col-otlp-ingest\n  #  permissionPolicyARNs:\n  #  - arn:aws:iam::aws:policy/AWSXrayWriteOnlyAccess\n\n  # The third association will be created, as it's been added to the config file\n  - serviceAccountName: adot-col-container-logs\n    permissionPolicyARNs:\n    - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy\n```\n\n----------------------------------------\n\nTITLE: Associating IAM OIDC Provider with EKS Cluster in eksctl\nDESCRIPTION: Command to enable the IAM OIDC Provider for an EKS cluster, which is required for using IAM Roles for Service Accounts. This needs to be done before creating IAM service accounts.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\neksctl utils associate-iam-oidc-provider --cluster=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: Configuring Unmanaged Nodegroup with Capacity-Optimized-Prioritized Spot Allocation Strategy\nDESCRIPTION: YAML configuration for an unmanaged nodegroup using the capacity-optimized-prioritized spot allocation strategy, which balances instance availability with type preference.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-capacity-optimized-prioritized\n    minSize: 2\n    maxSize: 5\n    instancesDistribution:\n      maxPrice: 0.017\n      instanceTypes: [\"t3a.small\", \"t3.small\"] # At least two instance types should be specified\n      onDemandBaseCapacity: 0\n      onDemandPercentageAboveBaseCapacity: 0\n      spotAllocationStrategy: \"capacity-optimized-prioritized\"\n```\n\n----------------------------------------\n\nTITLE: Running Docker-based Tests for eksctl\nDESCRIPTION: Command for running tests in Docker containers, similar to how they run in CI environments. This is useful for troubleshooting CI-specific issues.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nmake -f Makefile.docker test\n```\n\n----------------------------------------\n\nTITLE: Updating aws-node Add-on in EKS Cluster\nDESCRIPTION: Command to update the aws-node (Amazon VPC CNI) add-on in an EKS cluster. This command runs in plan mode by default and requires the --approve flag to apply changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addon-upgrade.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-aws-node --cluster=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: Configuring Unmanaged Nodegroup with Mixed Spot and On-Demand Instances\nDESCRIPTION: YAML configuration for an unmanaged nodegroup with 50% Spot instances and 50% On-Demand instances using instancesDistribution.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-1\n    minSize: 2\n    maxSize: 5\n    instancesDistribution:\n      maxPrice: 0.017\n      instanceTypes: [\"t3.small\", \"t3.medium\"] # At least one instance type should be specified\n      onDemandBaseCapacity: 0\n      onDemandPercentageAboveBaseCapacity: 50\n      spotInstancePools: 2\n```\n\n----------------------------------------\n\nTITLE: Upgrading EKS Control Plane Using Config File\nDESCRIPTION: Command to upgrade an EKS cluster using settings defined in a YAML configuration file. This approach allows specifying the target version and other cluster parameters in the config file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-upgrade.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\neksctl upgrade cluster --config-file cluster1.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Unmanaged Nodegroup with Capacity-Optimized Spot Allocation Strategy\nDESCRIPTION: YAML configuration for an unmanaged nodegroup using the capacity-optimized spot allocation strategy, which prioritizes instance availability.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-capacity-optimized\n    minSize: 2\n    maxSize: 5\n    instancesDistribution:\n      maxPrice: 0.017\n      instanceTypes: [\"t3.small\", \"t3.medium\"] # At least one instance type should be specified\n      onDemandBaseCapacity: 0\n      onDemandPercentageAboveBaseCapacity: 50\n      spotAllocationStrategy: \"capacity-optimized\"\n```\n\n----------------------------------------\n\nTITLE: Defining IAM Identity Mappings in ClusterConfig YAML\nDESCRIPTION: This YAML snippet demonstrates how to specify IAM identity mappings in a ClusterConfig file. It includes examples of role, user, service, and account mappings with various options.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-identity-mappings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-with-iamidentitymappings\n  region: us-east-1\n\niamIdentityMappings:\n  - arn: arn:aws:iam::000000000000:role/myAdminRole\n    groups:\n      - system:masters\n    username: admin\n    noDuplicateARNs: true # prevents shadowing of ARNs\n\n  - arn: arn:aws:iam::000000000000:user/myUser\n    username: myUser\n    noDuplicateARNs: true # prevents shadowing of ARNs\n\n  - serviceName: emr-containers\n    namespace: emr # serviceName requires namespace\n\n  - account: \"000000000000\" # account must be configured with no other options\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.large\n    desiredCapacity: 1\n```\n\n----------------------------------------\n\nTITLE: Configuring Nodegroups with Specific Subnets in YAML for eksctl\nDESCRIPTION: This YAML snippet shows how to configure a nodegroup to use a specific subnet in eksctl. It demonstrates using the subnet's identifying key from the VPC configuration instead of the subnet ID.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-subnet-settings.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  id: \"vpc-11111\"\n  subnets:\n    public:\n      public-one:\n          id: \"subnet-0153e560b3129a696\"\n    ... # subnet spec continued\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.xlarge\n    desiredCapacity: 2\n    subnets:\n      - public-one\n```\n\n----------------------------------------\n\nTITLE: Extending an EKS cluster to AWS Outposts with a pre-existing VPC\nDESCRIPTION: YAML configuration for extending an existing EKS cluster to AWS Outposts when using a pre-existing VPC. It specifies the subnets on Outposts to use for the nodegroups.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n# extended-cluster-vpc.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: extended-cluster-vpc\n  region: us-west-2\n\nvpc:\n  id: vpc-1234\n    subnets:\n      private:\n        outpost-subnet-1:\n          id: subnet-1234\n\nnodeGroups:\n  # Nodegroup will be created in an AWS region.\n  - name: ng\n\n  # Nodegroup will be created on the specified Outpost.\n  - name: outpost-ng\n    privateNetworking: true\n    # Subnet IDs for subnets created on Outpost.\n    subnets: [subnet-5678]\n    outpostARN: \"arn:aws:outposts:us-west-2:1234:outpost/op-1234\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Windows Custom AMI in EKS Cluster YAML Configuration\nDESCRIPTION: YAML configuration example for creating a Windows Server nodegroup with a custom AMI, demonstrating how to specify the AMI family, custom AMI ID, and override bootstrap command for Windows nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/custom-ami-support.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: custom-windows\n    amiFamily: WindowsServer2022FullContainer\n    ami: ami-01579b74557facaf7\n    overrideBootstrapCommand: |\n      & $EKSBootstrapScriptFile -EKSClusterName \"$EKSClusterName\" -APIServerEndpoint \"$APIServerEndpoint\" -Base64ClusterCA \"$Base64ClusterCA\" -ContainerRuntime \"containerd\" -KubeletExtraArgs \"$KubeletExtraArgs\" 3>&1 4>&1 5>&1 6>&1\n```\n\n----------------------------------------\n\nTITLE: Upgrading a nodegroup to a new launch template version\nDESCRIPTION: Command to upgrade nodes to a new version of a launch template, used when updating a custom AMI for a managed nodegroup.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\neksctl upgrade nodegroup --name nodegroup-name --cluster cluster-name --launch-template-version new-template-version\n```\n\n----------------------------------------\n\nTITLE: Building eksctl Binary from Source on Windows\nDESCRIPTION: Commands for building the eksctl binary and running unit tests on Windows. This allows Windows users to develop and test eksctl without using make commands.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_4\n\nLANGUAGE: cmd\nCODE:\n```\ngo build .\\cmd\\eksctl\ngo test .\\pkg\\...\n```\n\n----------------------------------------\n\nTITLE: Default NodeConfig YAML for Amazon Linux 2023 in eksctl\nDESCRIPTION: This snippet shows the default minimal NodeConfig YAML that eksctl injects into the nodegroup's launch template userdata for self-managed nodes and EKS-managed nodes based on custom AMIs. It includes cluster information, kubelet configuration, and node labels.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/node-bootstrapping.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nMIME-Version: 1.0\nContent-Type: multipart/mixed; boundary=//\n\n--//\nContent-Type: application/node.eks.aws\n\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  cluster:\n    apiServerEndpoint: https://XXXX.us-west-2.eks.amazonaws.com\n    certificateAuthority: XXXX\n    cidr: 10.100.0.0/16\n    name: my-cluster\n  kubelet:\n    config:\n      clusterDNS:\n      - 10.100.0.10\n    flags:\n    - --node-labels=alpha.eksctl.io/cluster-name=my-cluster,alpha.eksctl.io/nodegroup-name=my-nodegroup\n    - --register-with-taints=special=true:NoSchedule\n\n--//--\n```\n\n----------------------------------------\n\nTITLE: Auto-propagating ASG Tags for Scale-up from Zero\nDESCRIPTION: YAML configuration using the propagateASGTags option to automatically add label and taint information as ASG tags. This simplifies configuration when scaling from zero is required.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/autoscaling.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1-public\n    ...\n    labels:\n      my-cool-label: pizza\n    taints:\n      feaster: \"true:NoSchedule\"\n    propagateASGTags: true\n```\n\n----------------------------------------\n\nTITLE: Defining AWSCloudFormationFullAccess AWS Managed Policy in JSON\nDESCRIPTION: This AWS managed policy grants full access to AWS CloudFormation. It allows all actions on CloudFormation resources.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/minimum-iam-policies.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"cloudformation:*\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Node Root Volume Size and Type\nDESCRIPTION: Creates an EKS cluster with customized node root volume size (50GB) and type (io1), allowing for different storage requirements compared to the default 80GB volume.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_18\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --node-volume-size=50 --node-volume-type=io1\n```\n\n----------------------------------------\n\nTITLE: Complete ClusterConfig YAML with CloudWatch logging\nDESCRIPTION: Complete YAML configuration for an EKS cluster with CloudWatch logging enabled for audit and authenticator logs with a 7-day retention period.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-11\n  region: eu-west-2\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.large\n    desiredCapacity: 1\n\ncloudWatch:\n  clusterLogging:\n    enableTypes: [\"audit\", \"authenticator\"]\n    logRetentionInDays: 7\n```\n\n----------------------------------------\n\nTITLE: Attaching Inline IAM Policies in eksctl\nDESCRIPTION: Example showing how to attach inline IAM policies to a node group. This specific example grants S3 GetObject permissions to access objects in a specific bucket, demonstrating custom policy attachment.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-policies.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: my-special-nodegroup\n    iam:\n      attachPolicy:\n        Version: \"2012-10-17\"\n        Statement:\n        - Effect: Allow\n          Action:\n          - 's3:GetObject'\n          Resource: 'arn:aws:s3:::example-bucket/*'\n```\n\n----------------------------------------\n\nTITLE: Minimal Unmanaged Nodegroup with Spot Instances Configuration\nDESCRIPTION: A minimal YAML configuration example for setting up an unmanaged nodegroup with Spot instances, specifying only the required parameters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-1\n    instancesDistribution:\n      instanceTypes: [\"t3.small\", \"t3.medium\"] # At least one instance type should be specified\n```\n\n----------------------------------------\n\nTITLE: Deleting a Nodegroup\nDESCRIPTION: This command deletes a nodegroup from a cluster. It automatically drains all pods from the nodegroup before deleting the instances.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\neksctl delete nodegroup --cluster=<clusterName> --name=<nodegroupName>\n```\n\n----------------------------------------\n\nTITLE: Configuring IAM Permissions Boundaries in EKS Cluster\nDESCRIPTION: Example configuration showing how to set permissions boundaries for different IAM entities in an EKS cluster including service roles, Fargate execution roles, service accounts, and node groups. The configuration uses eksctl's ClusterConfig format with various IAM settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-permissions-boundary.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-17\n  region: us-west-2\n\niam:\n  withOIDC: true\n  serviceRolePermissionsBoundary: \"arn:aws:iam::11111:policy/entity/boundary\"\n  fargatePodExecutionRolePermissionsBoundary: \"arn:aws:iam::11111:policy/entity/boundary\"\n  serviceAccounts:\n    - metadata:\n        name: s3-reader\n      attachPolicyARNs:\n      - \"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n      permissionsBoundary: \"arn:aws:iam::11111:policy/entity/boundary\"\n\nnodeGroups:\n  - name: \"ng-1\"\n    desiredCapacity: 1\n    iam:\n      instanceRolePermissionsBoundary: \"arn:aws:iam::11111:policy/entity/boundary\"\n```\n\n----------------------------------------\n\nTITLE: Building and Serving eksctl Documentation\nDESCRIPTION: Commands for building and locally serving the eksctl documentation website. This requires Python3 and pip to be installed on the local system.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# Requires python3 and pip3 installed in your local system\nmake install-site-deps\nmake build-pages\nmake serve-pages\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Custom AMI Configuration (CLI)\nDESCRIPTION: CLI examples showing how to create EKS clusters by specifying the AMI type using the --node-ami flag to either automatically select an appropriate AMI or specify a custom AMI ID.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/custom-ami-support.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --node-ami=auto\n\n# with a custom ami id\neksctl create cluster --node-ami=ami-custom1234\n```\n\n----------------------------------------\n\nTITLE: Configuring containerd for Managed Nodes using Bootstrap Override\nDESCRIPTION: YAML configuration for managed node groups using a custom bootstrap command to specify containerd as the container runtime. This approach requires specifying an AMI and overriding the bootstrap command.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/container-runtime.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmanagedNodeGroups:\n  - name: m-ng-1\n    ami: ami-XXXXXXXXXXXXXX\n    instanceType: m5.large\n    overrideBootstrapCommand: |\n      #!/bin/bash\n      /etc/eks/bootstrap.sh <cluster-name> <other flags> --container-runtime containerd\n```\n\n----------------------------------------\n\nTITLE: Using Existing IAM Instance Roles in eksctl\nDESCRIPTION: Example of a ClusterConfig that reuses an existing IAM Instance Role from another cluster by specifying instanceProfileARN and instanceRoleARN. This enables sharing IAM roles across multiple EKS clusters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-policies.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha4\nkind: ClusterConfig\nmetadata:\n  name: test-cluster-c-1\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng2-private\n    instanceType: m5.large\n    desiredCapacity: 1\n    iam:\n      instanceProfileARN: \"arn:aws:iam::123:instance-profile/eksctl-test-cluster-a-3-nodegroup-ng2-private-NodeInstanceProfile-Y4YKHLNINMXC\"\n      instanceRoleARN: \"arn:aws:iam::123:role/eksctl-test-cluster-a-3-nodegroup-NodeInstanceRole-DNGMQTQHQHBJ\"\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Node Repair Enabled (Shell)\nDESCRIPTION: This command creates an EKS cluster with a managed nodegroup that has Node Repair enabled. The --enable-node-repair flag activates the feature.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-node-repair-config.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster --enable-node-repair\n```\n\n----------------------------------------\n\nTITLE: Scheduling Kubernetes Pods on Fargate\nDESCRIPTION: This example demonstrates creating a namespace called 'dev', deploying an nginx pod in that namespace, and verifying that it runs on a Fargate node.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n$ kubectl create namespace dev\nnamespace/dev created\n\n$ kubectl run nginx --image=nginx --restart=Never --namespace dev\npod/nginx created\n\n$ kubectl get pods --all-namespaces --output wide\nNAMESPACE     NAME                       READY   STATUS    AGE   IP                NODE\ndev           nginx                      1/1     Running   75s   192.168.183.140   fargate-ip-192-168-183-140.ap-northeast-1.compute.internal\nkube-system   aws-node-44qst             1/1     Running   21m   192.168.70.246    ip-192-168-70-246.ap-northeast-1.compute.internal\nkube-system   aws-node-4vr66             1/1     Running   21m   192.168.23.122    ip-192-168-23-122.ap-northeast-1.compute.internal\nkube-system   coredns-699bb99bf8-84x74   1/1     Running   26m   192.168.2.95      ip-192-168-23-122.ap-northeast-1.compute.internal\nkube-system   coredns-699bb99bf8-f6x6n   1/1     Running   26m   192.168.90.73     ip-192-168-70-246.ap-northeast-1.compute.internal\nkube-system   kube-proxy-brxhg           1/1     Running   21m   192.168.23.122    ip-192-168-23-122.ap-northeast-1.compute.internal\nkube-system   kube-proxy-zd7s8           1/1     Running   21m   192.168.70.246    ip-192-168-70-246.ap-northeast-1.compute.internal\n```\n\n----------------------------------------\n\nTITLE: Updating API Endpoint Access and CIDRs in a Single Command\nDESCRIPTION: This console command shows how to update both API server endpoint access and public access CIDRs for an EKS cluster in a single eksctl command.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config --cluster=<cluster> --public-access=true --private-access=true --public-access-cidrs=1.1.1.1/32,2.2.2.0/24\n```\n\n----------------------------------------\n\nTITLE: Configuring Pre-existing IAM Role for Hybrid Nodes in YAML\nDESCRIPTION: This YAML snippet demonstrates how to specify a pre-existing IAM Role for Hybrid nodes in the eksctl config file. This is useful when you have an existing IAM Roles Anywhere configuration or are using SSM.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/hybrid-nodes.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nremoteNetworkConfig:\n  iam:\n    roleARN: arn:aws:iam::000011112222:role/HybridNodesRole\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Zonal Shift Configuration in YAML\nDESCRIPTION: YAML configuration file that defines an EKS cluster with zonal shift functionality enabled. The configuration specifies a highly available cluster in the us-west-2 region with zonal shift capabilities.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/zonal-shift.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# zonal-shift-cluster.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: highly-available-cluster\n  region: us-west-2\n\n\nzonalShiftConfig:\n  enabled: true\n\n```\n\n----------------------------------------\n\nTITLE: Updating kube-proxy Add-on in EKS Cluster\nDESCRIPTION: Command to update the kube-proxy add-on in an EKS cluster. This command runs in plan mode by default and requires the --approve flag to apply changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addon-upgrade.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-kube-proxy --cluster=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: Cloning a Forked Repository for eksctl Development in Go\nDESCRIPTION: Instructions for forking and cloning the eksctl repository to begin development. This is the first step in setting up a local development environment for contributing to eksctl.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:<yourusername>/eksctl.git\n```\n\n----------------------------------------\n\nTITLE: Enabling OIDC and Creating IAM Service Accounts with Config File in eksctl\nDESCRIPTION: Commands to enable IAM OIDC Provider and create IAM service accounts using a configuration file after a cluster has already been created without these settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_9\n\nLANGUAGE: console\nCODE:\n```\neksctl utils associate-iam-oidc-provider --config-file=<path>\neksctl create iamserviceaccount --config-file=<path>\n```\n\n----------------------------------------\n\nTITLE: Enabling AWS Systems Manager for Node Access\nDESCRIPTION: Creates an EKS cluster with AWS Systems Manager (SSM) enabled, allowing secure SSH access to nodes without exposing SSH ports.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_16\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --enable-ssm\n```\n\n----------------------------------------\n\nTITLE: Structure of autoModeConfig Field in eksctl YAML Configuration\nDESCRIPTION: Shows the schema for the autoModeConfig field used to enable and configure EKS Auto Mode. The field includes options for enabling Auto Mode, specifying node pools, and providing a node role ARN.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nautoModeConfig:\n    # defaults to false\n    enabled: boolean\n    # optional, defaults to [general-purpose, system].\n    # To disable creation of nodePools, set it to the empty array ([]).\n    nodePools: []string\n    # optional, eksctl creates a new role if this is not supplied\n    # and nodePools are present.\n    nodeRoleARN: string\n```\n\n----------------------------------------\n\nTITLE: Creating Access Entries After Cluster Creation\nDESCRIPTION: Command to add access entries to an existing EKS cluster using a configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\neksctl create accessentry -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with GPU Support\nDESCRIPTION: Command to create an EKS cluster with GPU support using a g5.xlarge instance type. The eksctl tool will automatically select the appropriate EKS optimized accelerated AMI and install the NVIDIA device plugin.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gpu-support.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster --node-type=g5.xlarge\n```\n\n----------------------------------------\n\nTITLE: Upgrading EKS Control Plane to Specific Version with CLI Flag\nDESCRIPTION: Command to upgrade the control plane of an EKS cluster to a specific version (1.16) using a CLI flag. Version must be at most one minor version higher than current.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-upgrade.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl upgrade cluster --name=<clusterName> --version=1.16\n```\n\n----------------------------------------\n\nTITLE: Creating a local cluster on AWS Outposts with YAML configuration\nDESCRIPTION: YAML configuration for creating an EKS cluster on AWS Outposts. It specifies the Outpost ARN for the control plane and optionally the instance type to use.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# outpost.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: outpost\n  region: us-west-2\n\noutpost:\n  # Required.\n  controlPlaneOutpostARN: \"arn:aws:outposts:us-west-2:1234:outpost/op-1234\"\n  # Optional, defaults to the smallest available instance type on the Outpost.\n  controlPlaneInstanceType: m5d.large\n```\n\n----------------------------------------\n\nTITLE: Release Notes in Markdown\nDESCRIPTION: Markdown formatted release notes detailing new features, documentation updates, and acknowledgments for eksctl v0.171.0. Highlights the addition of Ubuntu 22.04 EKS image support.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.171.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.171.0\n\n##  Features\n\n- Add support for Ubuntu 22.04 based EKS images (#7516)\n\n##  Documentation\n\n- Announce eksctl Support Status Update on eksctl.io (#7539)\n\n## Acknowledgments\nThe eksctl maintainers would like to sincerely thank:\n@toabctl\n```\n\n----------------------------------------\n\nTITLE: Creating Unmanaged Nodegroup with Instance Selector\nDESCRIPTION: Command to create a cluster with an unmanaged nodegroup using instance selector criteria.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/instance-selector.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster --managed=false --instance-selector-vcpus=2 --instance-selector-memory=4\n```\n\n----------------------------------------\n\nTITLE: Using Pre-existing EC2 Key Pair for SSH Access\nDESCRIPTION: Creates an EKS cluster using a pre-existing EC2 key pair in a specific region (us-east-1) for SSH access to nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_15\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --ssh-access --ssh-public-key=my_kubernetes_key --region=us-east-1\n```\n\n----------------------------------------\n\nTITLE: Configuring containerd for Unmanaged Nodes in eksctl\nDESCRIPTION: A YAML configuration example for setting up unmanaged nodes with containerd as the container runtime. This configuration creates a cluster with two nodes using Amazon Linux 2 AMI family and specifies containerd as the runtime.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/container-runtime.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: container-runtime-test\n  region: us-west-2\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.xlarge\n    desiredCapacity: 2\n    amiFamily: AmazonLinux2\n    containerRuntime: containerd\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Specific AMI Family (CLI)\nDESCRIPTION: CLI example showing how to create an EKS cluster with a specific AMI family using the --node-ami-family flag to select Amazon Linux 2.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/custom-ami-support.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --node-ami-family=AmazonLinux2\n```\n\n----------------------------------------\n\nTITLE: Instance Selector Configuration in YAML\nDESCRIPTION: YAML configuration example showing how to specify instance selector criteria in ClusterConfig for both managed and unmanaged nodegroups.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/instance-selector.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# instance-selector-cluster.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster\n  region: us-west-2\n\nnodeGroups:\n- name: ng\n  instanceSelector:\n    vCPUs: 2\n    memory: \"4\" # 4 GiB, unit defaults to GiB\n\nmanagedNodeGroups:\n- name: mng\n  instanceSelector:\n    vCPUs: 2\n    memory: 2GiB #\n    cpuArchitecture: x86_64 # default value\n```\n\n----------------------------------------\n\nTITLE: Creating Namespaced IAM Service Account in eksctl\nDESCRIPTION: Command to create a service account with S3 read-only access in a specific namespace. If the namespace doesn't exist, it will be created automatically.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\neksctl create iamserviceaccount --cluster=<clusterName> --name=s3-read-only --namespace=s3-app --attach-policy-arn=arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n```\n\n----------------------------------------\n\nTITLE: Upgrading EKS Nodegroup Launch Template Version - Shell Command\nDESCRIPTION: Shell command to upgrade a managed nodegroup to use a different launch template version. Demonstrates the basic upgrade command structure.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/launch-template-support.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\neksctl upgrade nodegroup --name=managed-ng-1 --cluster=managed-cluster --launch-template-version=3\n```\n\n----------------------------------------\n\nTITLE: Upgrading a nodegroup to a specific AMI release version\nDESCRIPTION: Command to upgrade a managed nodegroup to a specific AMI release version instead of using the latest available version.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\neksctl upgrade nodegroup --name=managed-ng-1 --cluster=managed-cluster --release-version=1.19.6-20210310\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubernetes API Endpoint Access in YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure public and private access to the Kubernetes API server endpoint when creating an EKS cluster using a cluster config file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  clusterEndpoints:\n    publicAccess:  <true|false>\n    privateAccess: <true|false>\n```\n\n----------------------------------------\n\nTITLE: Formatting Release Notes in Markdown\nDESCRIPTION: Structured changelog documenting improvements, bug fixes, maintenance updates and acknowledgments for eksctl v0.172.0 release.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.172.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.172.0\n\n##  Improvements\n\n- Fix checks for updated addon versions (#7471)\n- Check for empty region before invoking API in AWS SDK (#7523)\n\n##  Bug Fixes\n\n- Revert removing RetryMetricsHeader in presigned requests (#7563)\n\n##  Maintenance\n\n- Bump dependencies (#7554)\n- Extract common workflow steps to set up build environment (#7551)\n\n## Acknowledgments\nThe eksctl maintainers would like to sincerely thank:\n@a2ush and @mttrb\n```\n\n----------------------------------------\n\nTITLE: Creating a Nodegroup in Custom Subnets using eksctl CLI\nDESCRIPTION: Commands for creating a new nodegroup in custom subnets using the eksctl command line. Examples show how to specify either multiple subnet IDs or a single subnet ID.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-with-custom-subnet.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --cluster <cluster-name> --name my-new-subnet --subnet-ids subnet-0edeb3a04bec27141,subnet-0edeb3a04bec27142,subnet-0edeb3a04bec27143\n# or for a single subnet id\neksctl create nodegroup --cluster <cluster-name> --name my-new-subnet --subnet-ids subnet-0edeb3a04bec27141\n```\n\n----------------------------------------\n\nTITLE: CLI Commands for EKS Add-On Management\nDESCRIPTION: Collection of eksctl CLI commands for managing EKS add-ons, including creating, listing, discovering, and updating add-ons. These commands demonstrate various options for interacting with add-ons through the command line.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\neksctl create cluster -f config.yaml\n\neksctl create addon -f config.yaml\n\neksctl create addon --name vpc-cni --version 1.7.5 --service-account-role-arn <role-arn>\n\neksctl get addons --cluster <cluster-name>\n\neksctl get addons -f config.yaml\n\neksctl utils describe-addon-versions --cluster <cluster-name>\n\neksctl utils describe-addon-versions --kubernetes-version <version>\n\neksctl utils describe-addon-versions --kubernetes-version 1.22 --types \"infra-management, policy-management\" --owners \"aws-marketplace\"\n\neksctl utils describe-addon-configuration --name vpc-cni --version v1.12.0-eksbuild.1\n\neksctl get addon --cluster my-cluster --output yaml\n\neksctl update addon -f config.yaml\n\neksctl update addon --name vpc-cni --version 1.8.0 --service-account-role-arn <new-role>\n\neksctl delete addon --cluster <cluster-name> --name <addon-name>\n\neksctl create cluster -f cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubelet Resource Reservation in eksctl YAML\nDESCRIPTION: This YAML example demonstrates how to configure a nodegroup with custom kubelet settings. It reserves resources for both kubelet and system daemons, sets eviction hard thresholds for memory and filesystem, and enables server certificate rotation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/customizing-the-kubelet.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: dev-cluster-1\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5a.xlarge\n    desiredCapacity: 1\n    kubeletExtraConfig:\n        kubeReserved:\n            cpu: \"300m\"\n            memory: \"300Mi\"\n            ephemeral-storage: \"1Gi\"\n        kubeReservedCgroup: \"/kube-reserved\"\n        systemReserved:\n            cpu: \"300m\"\n            memory: \"300Mi\"\n            ephemeral-storage: \"1Gi\"\n        evictionHard:\n            memory.available:  \"200Mi\"\n            nodefs.available: \"10%\"\n        featureGates:\n            RotateKubeletServerCertificate: true # has to be enabled, otherwise it will be disabled\n```\n\n----------------------------------------\n\nTITLE: Creating IAM Identity Mapping for EMR in EKS using eksctl\nDESCRIPTION: This command creates the required RBAC resources for Amazon EMR and updates the aws-auth ConfigMap to bind the role with the Service Linked Role (SLR) for EMR. This grants EMR the necessary permissions to interact with the Kubernetes API.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/emr-access.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create iamidentitymapping --cluster dev --service-name emr-containers --namespace default\n```\n\n----------------------------------------\n\nTITLE: Creating Cluster with Instance Selector via Command Line\nDESCRIPTION: Command to create a cluster with a managed nodegroup using instance selector criteria for vCPUs and memory.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/instance-selector.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster --instance-selector-vcpus=2 --instance-selector-memory=4\n```\n\n----------------------------------------\n\nTITLE: Creating and Deleting Account Mappings with eksctl in Bash\nDESCRIPTION: These snippets show how to create and delete account mappings using eksctl. They require the cluster name, region, and account identifier as parameters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-identity-mappings.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\neksctl create iamidentitymapping --cluster  <clusterName> --region=<region> --account user-account\n```\n\nLANGUAGE: bash\nCODE:\n```\neksctl delete iamidentitymapping --cluster  <clusterName> --region=<region> --account user-account\n```\n\n----------------------------------------\n\nTITLE: Configuring a managed nodegroup with a launch template\nDESCRIPTION: YAML configuration snippet showing how to deploy a managed nodegroup using a launch template, which is required for custom AMI upgrades.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\nmanagedNodeGroups:\n  - name: launch-template-ng\n    launchTemplate:\n      id: lt-1234\n      version: \"2\" #optional (uses the default version of the launch template if unspecified)\n```\n\n----------------------------------------\n\nTITLE: ClusterConfig with Instance Selector for Mixed Nodegroups\nDESCRIPTION: Example YAML configuration showing instance selector usage for both managed and unmanaged nodegroups with resource criteria specifications.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: linux\n  instanceSelector:\n    vCPUs: 2\n    memory: 4\n    gpus: 2\n\nnodeGroups:\n- name: windows\n  amiFamily: WindowsServer2019CoreContainer\n  instanceSelector:\n    vCPUs: 2\n    memory: 4\n    gpus: 2\n  instancesDistribution:\n    maxPrice: 0.017\n    onDemandBaseCapacity: 0\n    onDemandPercentageAboveBaseCapacity: 50\n    spotInstancePools: 2\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster from the Spot Configuration File\nDESCRIPTION: Command to create an EKS cluster using the defined YAML configuration file for Spot instances.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster -f spot-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Documenting eksctl v0.117.0 Release Notes\nDESCRIPTION: Markdown formatted release notes detailing new features, improvements, and bug fixes for eksctl version 0.117.0, including regional support, addon management, networking updates, and nodegroup fixes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.117.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.117.0\n\n##  Features\n\n- Add support for me-central-1 (#5837)\n- Add option to preserve addon config during update (#5830)\n\n##  Improvements\n\n- Added networking.k8s.io api to allowlist ingress operations (#5834)\n- Add ready plugin to CoreDNS and use health.lameduck for a safer shutdown (#5695)\n\n##  Bug Fixes\n\n- Preserve existing version during addon update when a version is not provided (#5803)\n- Fix max-pods for managed nodegroups (#5808)\n- Fix adding taints and labels as ASG tags (#5781)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n@singhbhaskar, and @wind0r\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Custom DNS Servers in eksctl YAML\nDESCRIPTION: This YAML snippet shows how to configure multiple custom DNS server IP addresses using the 'kubeletExtraConfig' parameter in the eksctl cluster configuration. It allows specifying an array of IP addresses for the clusterDNS setting.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-customize-dns.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-1\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng-1\n    kubeletExtraConfig:\n      clusterDNS: [\"169.254.20.10\",\"172.20.0.10\"]\n```\n\n----------------------------------------\n\nTITLE: ClusterConfig YAML for enabling all CloudWatch logs\nDESCRIPTION: YAML configuration to enable all types of CloudWatch logs for an EKS cluster control plane using the wildcard syntax.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ncloudWatch:\n  clusterLogging:\n    enableTypes: [\"*\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring EKS Cluster with Node Repair Enabled Nodegroup (YAML)\nDESCRIPTION: This YAML configuration file defines an EKS cluster with a managed nodegroup that has Node Repair enabled. It specifies the cluster name, region, and nodegroup details including the Node Repair configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-node-repair-config.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n# node-repair-nodegroup-cluster.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-44\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: ng-1\n  nodeRepairConfig:\n    enabled: true\n```\n\n----------------------------------------\n\nTITLE: Registering a non-EKS cluster with an existing IAM role\nDESCRIPTION: Command to register an external Kubernetes cluster with EKS using an existing IAM role instead of creating a new one. This is useful when you have specific IAM roles with the necessary permissions already configured.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-connector.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl register cluster --name <name> --provider <provider> --role-arn=<role-arn>\n```\n\n----------------------------------------\n\nTITLE: Flux Configuration YAML for eksctl\nDESCRIPTION: Example YAML configuration for enabling Flux v2 on an EKS cluster. It specifies GitHub as the Git provider and includes various flags like repository details, branch name, and team access.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gitops-v2.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-12\n  region: eu-north-1\n\n# other cluster config ...\n\ngitops:\n  flux:\n    gitProvider: github      # required. options are github, gitlab or git\n    flags:                   # required. arbitrary map[string]string for all flux args.\n      owner: \"dr-who\"\n      repository: \"our-org-gitops-repo\"\n      private: \"true\"\n      branch: \"main\"\n      namespace: \"flux-system\"\n      path: \"clusters/cluster-12\"\n      team: \"team1,team2\"\n```\n\n----------------------------------------\n\nTITLE: Removing Labels from EKS Managed Nodegroup using eksctl\nDESCRIPTION: Command to unset or remove labels from an EKS Managed Nodegroup. It uses the 'unset labels' subcommand of eksctl, specifying the cluster, nodegroup, and labels to be removed.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_15\n\nLANGUAGE: console\nCODE:\n```\neksctl unset labels --cluster managed-cluster --nodegroup managed-ng-1 --labels kubernetes.io/managed-by,kubernetes.io/role\n```\n\n----------------------------------------\n\nTITLE: Installing NVIDIA Device Plugin (v0.15.0+)\nDESCRIPTION: Kubernetes command to manually install the NVIDIA device plugin for version 0.15.0 and above. Replace <VERSION> with the desired plugin version.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gpu-support.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/<VERSION>/deployments/static/nvidia-device-plugin.yml\n```\n\n----------------------------------------\n\nTITLE: Creating IAM Identity Mapping with eksctl in Bash\nDESCRIPTION: This snippet shows how to create an IAM identity mapping using eksctl. It maps an IAM role to a Kubernetes group and username, requiring cluster name, region, ARN, group, and username as parameters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-identity-mappings.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl create iamidentitymapping --cluster  <clusterName> --region=<region> --arn arn:aws:iam::123456:role/testing --group system:masters --username admin\n```\n\n----------------------------------------\n\nTITLE: Enabling KMS Encryption Without Re-encrypting Existing Secrets\nDESCRIPTION: Shell command to enable KMS envelope encryption on an existing EKS cluster without re-encrypting existing Kubernetes secrets. This uses the --encrypt-existing-secrets=false flag to prevent eksctl from updating existing secrets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/kms-encryption.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl utils enable-secrets-encryption --cluster=kms-cluster --key-arn=arn:aws:kms:us-west-2:<account>:key/<key> --encrypt-existing-secrets=false --region=<region>\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes for eksctl 0.102.0\nDESCRIPTION: Release notes detailing improvements and bug fixes for eksctl version 0.102.0, including EFA instance support, OIDC error handling, tainting updates, and Fargate-related fixes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.102.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.102.0\n\n## Improvements\n\n- Add additional EFA supported instances. (#5274)\n- Ignore IAM OIDC errors if no OIDC provider is associated with cluster (#5357)\n- Improved example and updated error message regarding taints (#5367)\n\n## Bug Fixes\n\n- Fix authorization error check from Fargate (#5383)\n- Return an error when container runtime and overrideBootstrapCommand are defined together (#5365)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n     @mhuguesaws\n```\n\n----------------------------------------\n\nTITLE: Listing Nodegroup Details\nDESCRIPTION: This command lists details about a specific nodegroup or all nodegroups in a cluster. It can output in default log table format or in YAML/JSON for more detailed information.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\neksctl get nodegroup --cluster=<clusterName> [--name=<nodegroupName>]\n```\n\n----------------------------------------\n\nTITLE: Creating Specific Nodegroups from Config\nDESCRIPTION: This command demonstrates how to create specific nodegroups from a config file using include and exclude patterns. It creates all nodegroups except 'ng-1-workers'.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --config-file=dev-cluster.yaml --exclude=ng-1-workers\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster with Auto Scaling Support in eksctl CLI\nDESCRIPTION: Command to create a Kubernetes cluster with the necessary IAM role for cluster autoscaler. This sets appropriate tags for nodegroup discovery by the autoscaler.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/autoscaling.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\neksctl create cluster --asg-access\n```\n\n----------------------------------------\n\nTITLE: Configuring Remote Network for EKS Hybrid Nodes in YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure the remoteNetworkConfig section in the eksctl config file. It includes setting up the VPC gateway ID, remote node networks, and remote pod networks for EKS Hybrid Nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/hybrid-nodes.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nremoteNetworkConfig:\n  vpcGatewayID: tgw-xxxx # either VGW or TGW to be attached to your VPC\n  remoteNodeNetworks:\n    # eksctl will create, behind the scenes, SG rules, routes, and a VPC gateway attachment,\n    # to facilitate communication between remote network(s) and EKS control plane, via the attached gateway\n    - cidrs: [\"10.80.146.0/24\"]\n  remotePodNetworks:\n    - cidrs: [\"10.86.30.0/23\"]\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Manual GPU Plugin Installation\nDESCRIPTION: Command to create an EKS cluster with GPU support while disabling automatic NVIDIA plugin installation. This allows for manual installation of a specific plugin version.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gpu-support.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster --node-type=g5.xlarge --install-nvidia-plugin=false\n```\n\n----------------------------------------\n\nTITLE: Skipping Endpoint Creation in YAML Configuration\nDESCRIPTION: YAML configuration to skip VPC endpoint creation when setting up a fully-private EKS cluster. This is useful when endpoints are already set up in the VPC.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-private-cluster.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nprivateCluster:\n  enabled: true\n  skipEndpointCreation: true\n```\n\n----------------------------------------\n\nTITLE: Updating Public API Endpoint Access Restrictions with eksctl\nDESCRIPTION: This console command demonstrates how to update the restrictions on public API endpoint access for an existing EKS cluster using eksctl.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config --cluster=<cluster> 1.1.1.1/32,2.2.2.0/24\n```\n\n----------------------------------------\n\nTITLE: Registering a non-EKS cluster with EKS Connector using eksctl\nDESCRIPTION: Command to register an external Kubernetes cluster with EKS. The command creates required IAM roles and generates Kubernetes manifests that need to be applied to the external cluster before registration expires.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-connector.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl register cluster --name <name> --provider <provider>\n2021-08-19 13:47:26 []  creating IAM role \"eksctl-20210819194112186040\"\n2021-08-19 13:47:26 []  registered cluster \"<name>\" successfully\n2021-08-19 13:47:26 []  wrote file eks-connector.yaml to <current directory>\n2021-08-19 13:47:26 []  wrote file eks-connector-clusterrole.yaml to <current directory>\n2021-08-19 13:47:26 []  wrote file eks-connector-console-dashboard-full-access-group.yaml to <current directory>\n2021-08-19 13:47:26 [!]  note: \"eks-connector-clusterrole.yaml\" and \"eks-connector-console-dashboard-full-access-group.yaml\" give full EKS Console access to IAM identity \"<aws-arn>\", edit if required; read https://eksctl.io/usage/eks-connector for more info\n2021-08-19 13:47:26 []  run `kubectl apply -f eks-connector.yaml,eks-connector-clusterrole.yaml,eks-connector-console-dashboard-full-access-group.yaml` before <expiry> to connect the cluster\n```\n\n----------------------------------------\n\nTITLE: Disabling Cluster Creator Admin Permissions in YAML\nDESCRIPTION: YAML configuration to disable granting cluster-admin permissions to the IAM identity creating the cluster by setting bootstrapClusterCreatorAdminPermissions to false.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\naccessConfig:\n  bootstrapClusterCreatorAdminPermissions: false\n```\n\n----------------------------------------\n\nTITLE: Release Notes in Markdown\nDESCRIPTION: Markdown formatted release notes for eksctl version 0.23.0 detailing new features, improvements, bug fixes and acknowledgments to contributors.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.23.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.23.0\n\n\n## Features\n\n- Add support for config file in scale nodegroup (#2257)\n- Mark `utils wait-nodes` as deprecated and hidden (#2344)\n\n## Improvements\n\n- Use IMDSv2 (#2354)\n- Config schema doc improvements (#2347)\n- Sort commands/subcommands by name in help (#2365)\n- Remove nodegroups from authconfigmap after deletion, not before (#2343)\n\n## Bug Fixes\n\n- Use compute-type of existing coredns on update (#2355)\n- Fix nodebootstrap asset generation (#2353)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n@TBBle, @rndstr and @sayboras\n```\n\n----------------------------------------\n\nTITLE: Migrating to Pod Identity Command\nDESCRIPTION: Command to migrate existing IAM Roles for service accounts to pod identity associations, with optional approval flag.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils migrate-to-pod-identity --cluster my-cluster --approve\n```\n\n----------------------------------------\n\nTITLE: Creating IAM Role Only for Service Account in eksctl\nDESCRIPTION: Command to create only the IAM role without managing the service account. This is useful when the service account is managed by another tool like Helm. The role will always be created regardless of --override-existing-serviceaccounts flag.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\neksctl create iamserviceaccount --cluster=<clusterName> --name=<serviceAccountName> --role-only --role-name=<customRoleName>\n```\n\n----------------------------------------\n\nTITLE: Creating Fargate Profile via Command Line\nDESCRIPTION: Command to create a Fargate profile for a specific namespace in an existing EKS cluster. This operation requires EKS platform version 'eks.5' or higher.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create fargateprofile --namespace dev --cluster fargate-example-cluster\n[]  creating Fargate profile \"fp-9bfc77ad\" on EKS cluster \"fargate-example-cluster\"\n[]  created Fargate profile \"fp-9bfc77ad\" on EKS cluster \"fargate-example-cluster\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Auto Mode in an EKS Cluster\nDESCRIPTION: Demonstrates the YAML configuration to disable Auto Mode on an existing cluster. Setting autoModeConfig.enabled to false will revert the cluster to standard (non-Auto) mode.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n# cluster.yaml\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n    name: auto-mode-cluster\n    region: us-west-2\n\nautoModeConfig:\n    enabled: false\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Pod Identity Agent Addon\nDESCRIPTION: Command to install the required eks-pod-identity-agent addon on an EKS cluster\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl create addon --cluster my-cluster --name eks-pod-identity-agent\n```\n\n----------------------------------------\n\nTITLE: Retrieving Access Entry for Hybrid Nodes Using eksctl\nDESCRIPTION: This bash command retrieves the access entry created by eksctl for the Hybrid Nodes IAM Role. This entry maps the role to a Kubernetes identity and authorizes remote nodes to join the EKS cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/hybrid-nodes.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\neksctl get accessentry --cluster my-cluster --principal-arn arn:aws:iam::000011112222:role/eksctl-my-cluster-clust-HybridNodesSSMRole-XiIAg0d29PkO --output json\n```\n\n----------------------------------------\n\nTITLE: Retrieving IAM Identity Mappings with eksctl in Bash\nDESCRIPTION: This snippet demonstrates how to get all identity mappings or mappings for a specific ARN using eksctl. It requires the cluster name and region as parameters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-identity-mappings.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl get iamidentitymapping --cluster <clusterName> --region=<region>\n```\n\nLANGUAGE: bash\nCODE:\n```\neksctl get iamidentitymapping --cluster <clusterName> --region=<region> --arn arn:aws:iam::123456:role/testing-role\n```\n\n----------------------------------------\n\nTITLE: Retrieving Hybrid Nodes Role ARN Using AWS CLI\nDESCRIPTION: This bash command retrieves the ARN of the Hybrid Nodes Role created by eksctl. This ARN is needed for setting up NodeConfig for nodeadm and creating activations when using SSM.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/hybrid-nodes.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naws cloudformation describe-stacks \\\n  --stack-name eksctl-<CLUSTER_NAME>-cluster \\\n  --query 'Stacks[].Outputs[?OutputKey==`RemoteNodesRoleARN`].[OutputValue]' \\\n  --output text\n```\n\n----------------------------------------\n\nTITLE: Updating Add-Ons with Conflict Resolution Strategy\nDESCRIPTION: YAML configuration example showing how to update an add-on with a specific conflict resolution strategy. The resolveConflicts field controls how configuration changes are handled during updates.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: vpc-cni\n  attachPolicyARNs:\n    - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\n  resolveConflicts: preserve\n```\n\n----------------------------------------\n\nTITLE: Documenting Release Notes for eksctl 0.111.0 in Markdown\nDESCRIPTION: This snippet outlines the release notes for eksctl version 0.111.0, including improvements, bug fixes, and acknowledgments to contributors. It uses Markdown formatting for structured presentation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.111.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.111.0\n\n## Improvements\n\n- Docs update for supported command (get fargate) for non-eksctl created cluster (#5659)\n\n## Bug Fixes\n\n- Add RBAC Permissions for PVC for emr-containers (#5660)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n@melodyyangaws and @surajnarwade\n```\n\n----------------------------------------\n\nTITLE: Updating EKS Control Plane Security Groups via Command Line\nDESCRIPTION: This command updates the security groups applied to the EKS control plane's cross-account network interfaces. The --approve flag is needed to actually apply the changes instead of just showing what would change.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config --cluster=<cluster> --control-plane-security-group-ids=sg-1234,sg-5678 --approve\n```\n\n----------------------------------------\n\nTITLE: Applying Combined EKS VPC Config Changes\nDESCRIPTION: This command applies both subnet and security group changes defined in a YAML configuration file to an EKS cluster using the eksctl utility.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Updating Authentication Mode with eksctl CLI\nDESCRIPTION: Command to update the cluster authentication mode using the eksctl CLI with direct flag parameters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils update-authentication-mode --cluster my-cluster --authentication-mode API_AND_CONFIG_MAP\n```\n\n----------------------------------------\n\nTITLE: Generating ClusterConfig with Dry Run in Shell\nDESCRIPTION: Demonstrates using the dry-run flag with eksctl create cluster command, which outputs a complete ClusterConfig YAML file with the matched instance types based on instance selector criteria.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/dry-run.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster --name development --dry-run\n\n\napiVersion: eksctl.io/v1alpha5\ncloudWatch:\n  clusterLogging: {}\niam:\n  vpcResourceControllerPolicy: true\n  withOIDC: false\nkind: ClusterConfig\nmanagedNodeGroups:\n- amiFamily: AmazonLinux2\n  desiredCapacity: 2\n  disableIMDSv1: true\n  disablePodIMDS: false\n  iam:\n    withAddonPolicies:\n      albIngress: false\n      appMesh: false\n      appMeshPreview: false\n      autoScaler: false\n      certManager: false\n      cloudWatch: false\n      ebs: false\n      efs: false\n      externalDNS: false\n      fsx: false\n      imageBuilder: false\n      xRay: false\n  instanceSelector: {}\n  instanceType: m5.large\n  labels:\n    alpha.eksctl.io/cluster-name: development\n    alpha.eksctl.io/nodegroup-name: ng-4aba8a47\n  maxSize: 2\n  minSize: 2\n  name: ng-4aba8a47\n  privateNetworking: false\n  securityGroups:\n    withLocal: null\n    withShared: null\n  ssh:\n    allow: false\n    enableSsm: false\n    publicKeyPath: \"\"\n  tags:\n    alpha.eksctl.io/nodegroup-name: ng-4aba8a47\n    alpha.eksctl.io/nodegroup-type: managed\n  volumeIOPS: 3000\n  volumeSize: 80\n  volumeThroughput: 125\n  volumeType: gp3\nmetadata:\n  name: development\n  region: us-west-2\n  version: \"1.24\"\nprivateCluster:\n  enabled: false\nvpc:\n  autoAllocateIPv6: false\n  cidr: 192.168.0.0/16\n  clusterEndpoints:\n    privateAccess: false\n    publicAccess: true\n  manageSharedNodeSecurityGroupRules: true\n  nat:\n    gateway: Single\n```\n\n----------------------------------------\n\nTITLE: Executing eksctl Command to Create an Auto Mode Cluster\nDESCRIPTION: Shows the shell command to create an EKS cluster using a YAML configuration file with Auto Mode enabled.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster -f auto-mode-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Karpenter EC2NodeClass Resource\nDESCRIPTION: YAML definition for a Karpenter EC2NodeClass that specifies AWS-specific configurations including IAM role, subnets, security groups, and AMI information for nodes provisioned by Karpenter.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eksctl-karpenter.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: karpenter.k8s.aws/v1\nkind: EC2NodeClass\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/description: \"Example EC2NodeClass\"\nspec:\n  role: \"eksctl-KarpenterNodeRole-${CLUSTER_NAME}\" # replace with your cluster name\n  subnetSelectorTerms:\n    - tags:\n        karpenter.sh/discovery: \"${CLUSTER_NAME}\" # replace with your cluster name\n  securityGroupSelectorTerms:\n    - tags:\n        karpenter.sh/discovery: \"${CLUSTER_NAME}\" # replace with your cluster name\n  amiSelectorTerms:\n    - alias: al2023@latest # Amazon Linux 2023\n```\n\n----------------------------------------\n\nTITLE: Updating EKS Addon Configuration\nDESCRIPTION: Command to update an EKS addon using the specified configuration file, which processes pod identity association changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\neksctl update addon -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Custom NodeConfig YAML for Amazon Linux 2023 in eksctl\nDESCRIPTION: This snippet demonstrates how to specify a custom NodeConfig using the overrideBootstrapCommand in eksctl. It shows an example of configuring the instance's local storage strategy to RAID0.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/node-bootstrapping.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmanagedNodeGroups:\n  - name: mng-1\n    amiFamily: AmazonLinux2023\n    ami: ami-0253856dd7ab7dbc8\n    overrideBootstrapCommand: |\n      apiVersion: node.eks.aws/v1alpha1\n      kind: NodeConfig\n      spec:\n        instance:\n          localStorage:\n            strategy: RAID0\n```\n\n----------------------------------------\n\nTITLE: ClusterConfig YAML for setting CloudWatch log retention period\nDESCRIPTION: YAML configuration to set the retention period for CloudWatch logs to 7 days, controlling how long logs are stored.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\ncloudWatch:\n  clusterLogging:\n    logRetentionInDays: 7\n```\n\n----------------------------------------\n\nTITLE: Documenting Release Notes in Markdown\nDESCRIPTION: Markdown formatted release notes documenting improvements and bug fixes for eksctl version 0.43.0. Includes updates to core components, documentation improvements, and acknowledgments.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.43.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.43.0\n\n## Improvements\n\n- Add managed-by label to eksctl created service accounts (#3463)\n- Deprecate WindowsServer1909CoreContainer AMI Family and improve error messages (#3455)\n- Added missing Bottlerocket option in docs for custom AMI (#3478)\n- Update maxpods (#3474)\n- Update aws-node (#3475)\n- Update EFA device plugin to 0.3.3 (#3466)\n- Add docs for non eksctl-created clusters (#3471)\n\n## Bug Fixes\n\n- Attach EFA SG to network interfaces (#3467)\n- Fix service principal for cluster and Fargate profile role (#3473)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n   @sotoiwa\n```\n\n----------------------------------------\n\nTITLE: Configuring VPC Subnets with Correct AZ Mapping\nDESCRIPTION: Example of correct VPC subnet configuration with proper Availability Zone mapping for public and private subnets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/troubleshooting.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  subnets:\n    public:\n      us-east-1a: {id: subnet-22222222}\n      us-east-1b: {id: subnet-11111111}\n    private:\n      us-east-1a: {id: subnet-33333333}\n      us-east-1b: {id: subnet-44444444}\n```\n\n----------------------------------------\n\nTITLE: Applying EKS Security Group Config Changes via Config File\nDESCRIPTION: This command applies the security group configuration changes defined in a YAML file to an EKS cluster using the eksctl utility.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Private Access to Additional AWS Services in YAML\nDESCRIPTION: YAML configuration for enabling private access to additional AWS services in a fully-private EKS cluster. This example adds VPC endpoints for Autoscaling and CloudWatch logging.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-private-cluster.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nprivateCluster:\n  enabled: true\n  additionalEndpointServices:\n  # For Cluster Autoscaler\n  - \"autoscaling\"\n  # CloudWatch logging\n  - \"logs\"\n```\n\n----------------------------------------\n\nTITLE: Disabling all EKS control plane log types\nDESCRIPTION: Command to disable all types of CloudWatch logs for an EKS cluster control plane.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-cluster-logging --disable-types all\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS cluster on AWS Outposts using an existing VPC\nDESCRIPTION: YAML configuration for creating an EKS cluster on AWS Outposts using an existing VPC. It specifies the VPC ID and subnet configuration to use for the cluster's resources.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n# outpost-existing-vpc.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: outpost\n  region: us-west-2\n\nvpc:\n  id: vpc-1234\n  subnets:\n    private:\n      outpost-subnet-1:\n        id: subnet-1234\n\nnodeGroups:\n  - name: outpost-ng\n    privateNetworking: true\n\noutpost:\n    # Required.\n    controlPlaneOutpostARN: \"arn:aws:outposts:us-west-2:1234:outpost/op-1234\"\n    # Optional, defaults to the smallest available instance type on the Outpost.\n    controlPlaneInstanceType: m5d.large\n```\n\n----------------------------------------\n\nTITLE: Deleting an Existing Nodegroup in eksctl\nDESCRIPTION: Command to delete an old nodegroup after creating a new one. This will drain all pods from the nodegroup before deleting the instances, unless the '--disable-eviction' flag is used.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\neksctl delete nodegroup --cluster=<clusterName> --region=<region> --name=<oldNodeGroupName>\n```\n\n----------------------------------------\n\nTITLE: Configuring IAM for EKS Hybrid Nodes with IAM Roles Anywhere in YAML\nDESCRIPTION: This YAML snippet shows how to configure the IAM section within remoteNetworkConfig for EKS Hybrid Nodes. It sets up the credentials provider as IAM Roles Anywhere and includes a certificate authority bundle for node authentication.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/hybrid-nodes.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nremoteNetworkConfig:\n  iam:\n    # the provider for temporary IAM credentials. Default is SSM.\n    provider: IRA\n    # the certificate authority bundle that serves as the root of trust,\n    # used to validate the X.509 certificates provided by your nodes.\n    # can only be set when provider is IAMRolesAnywhere.\n    caBundleCert: xxxx\n```\n\n----------------------------------------\n\nTITLE: Configuring a Fully-Private EKS Cluster in YAML\nDESCRIPTION: Minimal YAML configuration to enable a fully-private EKS cluster using eksctl. This snippet sets the 'privateCluster.enabled' field to true.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-private-cluster.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nprivateCluster:\n  enabled: true\n```\n\n----------------------------------------\n\nTITLE: Retrieving Access Entries with Config File\nDESCRIPTION: Command to get all access entries associated with a cluster using a configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\neksctl get accessentry -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes for eksctl v0.189.0\nDESCRIPTION: Release notes documenting three bug fixes and acknowledgments for version 0.189.0 of the eksctl tool. Includes fixes for OIDC manager in Outposts clusters, VPC CNI segfault prevention, and SSM unit test corrections.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.189.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.189.0\n\n##  Bug Fixes\n\n- Skip creating OIDC manager for Outposts clusters (#7934)\n- Fixes segfault when VPC CNI is disabled (#7927)\n- Fix SSM unit tests (#7935)\n\n## Acknowledgments\n\nThe eksctl maintainers would like to sincerely thank @EmmEff.\n```\n\n----------------------------------------\n\nTITLE: Deleting an EKS Cluster with PDB Policy Bypass\nDESCRIPTION: Command to delete a cluster with nodegroups while bypassing Pod Disruption Budget (PDB) policies, which can sometimes prevent nodes from being removed successfully during deletion.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/creating-and-managing-clusters.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\neksctl delete cluster -f cluster.yaml --disable-nodegroup-eviction\n```\n\n----------------------------------------\n\nTITLE: Checking nodegroup health issues\nDESCRIPTION: Command to view health issues for a managed nodegroup, which helps identify configuration problems with the nodegroup or nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_13\n\nLANGUAGE: console\nCODE:\n```\neksctl utils nodegroup-health --name=managed-ng-1 --cluster=managed-cluster\n```\n\n----------------------------------------\n\nTITLE: Enabling Automatic Kubeconfig Management\nDESCRIPTION: Creates an EKS cluster and allows eksctl to manage cluster credentials under the ~/.kube/eksctl/clusters directory, organizing credentials by cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --name=cluster-3 --nodes=4 --auto-kubeconfig\n```\n\n----------------------------------------\n\nTITLE: Creating IAM Service Account with Custom Role Name in eksctl\nDESCRIPTION: Command to create an IAM service account with a predetermined role name instead of the auto-generated name with random string that CloudFormation normally creates.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\neksctl create iamserviceaccount --cluster=<clusterName> --name=<serviceAccountName> --role-name \"custom-role-name\"\n```\n\n----------------------------------------\n\nTITLE: Restricting Public API Endpoint Access in YAML\nDESCRIPTION: This YAML snippet shows how to restrict access to the public API endpoint to a set of CIDRs when creating an EKS cluster using a cluster config file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  publicAccessCIDRs: [\"1.1.1.1/32\", \"2.2.2.0/24\"]\n```\n\n----------------------------------------\n\nTITLE: Updating Zonal Shift Config Using Command Line Parameters\nDESCRIPTION: Shell command to enable zonal shift on an existing cluster using direct command line parameters instead of a configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/zonal-shift.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils update-zonal-shift-config --cluster=zonal-shift-cluster --enabled\n```\n\n----------------------------------------\n\nTITLE: EKS Addon Pod Identity Configuration\nDESCRIPTION: YAML configuration examples for configuring pod identity associations with EKS addons\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: vpc-cni\n  podIdentityAssociations:\n  - serviceAccountName: aws-node\n    permissionPolicyARNs: [\"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\"]\n```\n\nLANGUAGE: yaml\nCODE:\n```\naddonsConfig:\n  autoApplyPodIdentityAssociations: true\naddons:\n- name: vpc-cni\n```\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: vpc-cni\n  useDefaultPodIdentityAssociations: true\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster without Storing Credentials\nDESCRIPTION: Creates an EKS cluster without storing the credentials locally, which can be useful for security or automation scenarios.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --name=cluster-3 --nodes=4 --write-kubeconfig=false\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Error Wrapping in Go\nDESCRIPTION: This snippet shows the recommended way to wrap errors in eksctl using fmt.Errorf with %w. It emphasizes avoiding wrapping errors that are already meaningful.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/guidelines/design-conventions.md#2025-04-21_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nfmt.Errorf(\"some context: %w\", err)\n```\n\n----------------------------------------\n\nTITLE: Checking Flux System Pods\nDESCRIPTION: Command to verify that Flux controllers are running correctly in the flux-system namespace after installation. This shows the default toolkit components that Flux installs.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gitops-v2.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nkubectl get pods --namespace flux-system\nNAME                                       READY   STATUS    RESTARTS   AGE\nhelm-controller-7cfb98d895-zmmfc           1/1     Running   0          3m30s\nkustomize-controller-557986cf44-2jwjh      1/1     Running   0          3m35s\nnotification-controller-65694dc94d-rhbxk   1/1     Running   0          3m20s\nsource-controller-7f856877cf-jgwdk         1/1     Running   0          3m39s\n```\n\n----------------------------------------\n\nTITLE: Migrating IAM Identity Mappings to Access Entries\nDESCRIPTION: Command to migrate existing IAM identities from aws-auth ConfigMap to access entries, specifying the target authentication mode.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils migrate-to-access-entry --cluster my-cluster --target-authentication-mode <API or API_AND_CONFIG_MAP>\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster Without Default Networking Add-Ons\nDESCRIPTION: YAML configuration example showing how to create an EKS cluster without the default networking add-ons. This allows for the use of alternative CNI plugins like Cilium and Calico.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\naddonsConfig:\n  disableDefaultAddons: true\n```\n\n----------------------------------------\n\nTITLE: Creating Tagged IAM Service Account in eksctl\nDESCRIPTION: Command to create an IAM service account with custom tags. These tags are applied to the IAM role that gets created, which can be useful for resource organization and cost tracking.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\neksctl create iamserviceaccount --cluster=<clusterName> --name=<serviceAccountName> --tags \"Owner=John Doe,Team=Some Team\"\n```\n\n----------------------------------------\n\nTITLE: Attaching Existing IAM Role to Service Account in eksctl\nDESCRIPTION: Command to use an existing IAM role with a service account instead of creating a new role. The existing role should have an appropriate trust relationship policy document to allow the service account to assume it.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iamserviceaccounts.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\neksctl create iamserviceaccount --cluster=<clusterName> --name=<serviceAccountName> --attach-role-arn=<customRoleARN>\n```\n\n----------------------------------------\n\nTITLE: eksctl Command for Updating Auto Mode Configuration\nDESCRIPTION: Shows the shell command to update an existing cluster's Auto Mode configuration using a YAML definition file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl update auto-mode-config -f cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Updating kube-proxy Add-on in eksctl\nDESCRIPTION: Command to update the kube-proxy add-on in an EKS cluster. This runs in plan mode by default and requires '--approve' to apply changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils update-kube-proxy --cluster=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: Retrieving Nodegroup Userdata from Launch Template\nDESCRIPTION: Bash script to extract and decode the userdata configuration from an EKS nodegroup's launch template. Uses AWS CLI and jq to query CloudFormation and EC2 APIs.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/faq.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nNG_STACK=eksctl-scrumptious-monster-1595247364-nodegroup-ng-29b8862f # your stack here\nLAUNCH_TEMPLATE_ID=$(aws cloudformation describe-stack-resources --stack-name $NG_STACK \\\n| jq -r '.StackResources | map(select(.LogicalResourceId == \"NodeGroupLaunchTemplate\")\n| .PhysicalResourceId)[0]')\naws ec2 describe-launch-template-versions --launch-template-id $LAUNCH_TEMPLATE_ID \\\n| jq -r '.LaunchTemplateVersions[0].LaunchTemplateData.UserData' \\\n| base64 -d | gunzip\n```\n\n----------------------------------------\n\nTITLE: Illustrating CLI Command Structure in eksctl\nDESCRIPTION: This example demonstrates the CLI command structure convention used in eksctl, following a similar pattern to kubectl. It shows how verbs, resources, and flags are organized.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/guidelines/design-conventions.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl <verb> <resource> <flags...>\n```\n\n----------------------------------------\n\nTITLE: Creating Cluster with Disabled Admin Permissions\nDESCRIPTION: Command to create an EKS cluster with disabled cluster creator admin permissions using a configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\neksctl create cluster -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring EKS Cluster with Public Subnets (YAML)\nDESCRIPTION: YAML configuration for creating an EKS cluster with public subnets in an existing VPC.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: my-test\n  region: us-west-2\n\nvpc:\n  id: \"vpc-11111\"\n  subnets:\n    public:\n      us-west-2d:\n          id: \"subnet-0153e560b3129a696\"\n      us-west-2c:\n          id: \"subnet-0cc9c5aebe75083fd\"\n      us-west-2a:\n          id: \"subnet-009fa0199ec203c37\"\n      us-west-2b:\n          id: \"subnet-018fa0176ba320e45\"\n\nnodeGroups:\n  - name: ng-1\n```\n\n----------------------------------------\n\nTITLE: Configuring Authentication Mode in YAML Config for eksctl\nDESCRIPTION: YAML configuration snippet for specifying the authentication mode in eksctl. This setting determines how cluster access management is handled, with options being CONFIG_MAP, API, or API_AND_CONFIG_MAP.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\naccessConfig:\n  authenticationMode: <>\n```\n\n----------------------------------------\n\nTITLE: Upgrading EKS Nodegroup with Kubernetes Version - Shell Command\nDESCRIPTION: Shell command showing how to upgrade both the launch template version and Kubernetes version for a nodegroup that isn't using a custom AMI.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/launch-template-support.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\neksctl upgrade nodegroup --name=managed-ng-1 --cluster=managed-cluster --launch-template-version=3 --kubernetes-version=1.17\n```\n\n----------------------------------------\n\nTITLE: Configuring placement groups for EKS clusters on AWS Outposts\nDESCRIPTION: YAML configuration demonstrating how to specify a placement group for a control plane on AWS Outposts. This helps satisfy high-availability requirements based on your Outpost deployment topology.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n# outpost.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: outpost\n  region: us-west-2\n\noutpost:\n  # Required.\n  controlPlaneOutpostARN: \"arn:aws:outposts:us-west-2:1234:outpost/op-1234\"\n  # Optional, defaults to the smallest available instance type on the Outpost.\n  controlPlaneInstanceType: m5d.large\n\n  controlPlanePlacement:\n    groupName: placement-group-name\n```\n\n----------------------------------------\n\nTITLE: Creating nodegroups using a ClusterConfig file with dry-run\nDESCRIPTION: Example showing how to use 'eksctl create nodegroup' with a ClusterConfig file in dry-run mode. This demonstrates how the instance selector criteria are expanded into specific instance types.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncat cluster.yaml\n```\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: dev\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: m1\n  instanceSelector:\n    vCPUs: 2\n    memory: 4\n\n- name: m2\n  desiredCapacity: 5\n```\n\nLANGUAGE: shell\nCODE:\n```\neksctl create nodegroup -f cluster.yaml --dry-run\n```\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: dev\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: m1\n  instanceTypes: [\"c3.large\", \"c4.large\", \"c5.large\", \"c5d.large\", \"c5n.large\", \"c5a.large\"]\n  instanceSelector:\n    vCPUs: 2\n    memory: 4\n\n- name: m2\n  desiredCapacity: 5\n```\n\n----------------------------------------\n\nTITLE: Viewing AmazonLinux2 Kubelet Logs\nDESCRIPTION: Command to view the kubelet service logs on AmazonLinux2 nodes using journalctl, which is useful for diagnosing bootstrap and runtime issues.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/nodebootstrap/README.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\njournalctl -u kubelet.service\n```\n\n----------------------------------------\n\nTITLE: Accessing Environment Properties in eksctl Bootstrap Helper\nDESCRIPTION: List of environment properties available when sourcing the bootstrap helper script in eksctl. These properties can be used in custom bootstrap commands for nodegroups using custom AMIs.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/announcements/nodegroup-override-announcement.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nAPI_SERVER_URL\nB64_CLUSTER_CA\nINSTANCE_ID\nINSTANCE_LIFECYCLE\nCLUSTER_DNS\nNODE_TAINTS\nMAX_PODS\nNODE_LABELS\nCLUSTER_NAME\nCONTAINER_RUNTIME # default is docker\nKUBELET_EXTRA_ARGS # for details, look at the script\n```\n\n----------------------------------------\n\nTITLE: Documenting Release Changes for EKSctl v0.73.0\nDESCRIPTION: Markdown documentation detailing the changes and improvements in EKSctl version 0.73.0, including new features, improvements, bug fixes, and acknowledgments to contributors.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.73.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.73.0\n\n## Features\n\n- Support CloudWatch log retention (#4295)\n- Add support for Windows Server 20H2 (#4390)\n\n## Improvements\n\n- Make kubernetes 1.21 default (#4394)\n- Reduce API calls in upgrade cluster (#4366)\n\n## Bug Fixes\n\n- Fix wait for managed nodegroups (#4401)\n- Scale managed nodegroup with --name flag (#4383)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n @abhipth and @adammw\n```\n\n----------------------------------------\n\nTITLE: Updating Authentication Mode with Config File\nDESCRIPTION: Command to update the cluster authentication mode using a configuration file with eksctl.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils update-authentication-mode -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Tags to EKS Cluster Resources\nDESCRIPTION: Creates an EKS cluster with custom tags applied to all resources, useful for resource organization, cost allocation, and access control.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_17\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --tags environment=staging --region=us-east-1\n```\n\n----------------------------------------\n\nTITLE: Creating Cluster with Access Entries\nDESCRIPTION: Command to create an EKS cluster with access entries defined in a configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\neksctl create cluster -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Deleting Old Nodegroups with Config File in eksctl\nDESCRIPTION: Command to delete old nodegroups using a configuration file with the '--only-missing' flag. This deletes nodegroups that are not defined in the config file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\neksctl delete nodegroup --config-file=<path> --only-missing\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Shared Node Security Group (YAML)\nDESCRIPTION: YAML configuration for specifying a custom shared node security group in the VPC settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  sharedNodeSecurityGroup: sg-0123456789\n```\n\n----------------------------------------\n\nTITLE: Deregistering a cluster from EKS Connector using eksctl\nDESCRIPTION: Command to deregister or disconnect a previously registered external cluster from EKS. This removes the AWS resources associated with the registration, but requires manual cleanup of EKS Connector resources from the Kubernetes cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eks-connector.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl deregister cluster --name <name>\n2021-08-19 16:04:09 []  unregistered cluster \"<name>\" successfully\n2021-08-19 16:04:09 []  run `kubectl delete namespace eks-connector` and `kubectl delete -f eks-connector-binding.yaml` on your cluster to remove EKS Connector resources\n```\n\n----------------------------------------\n\nTITLE: Showing eksctl Nodegroup Creation Command\nDESCRIPTION: This snippet provides an example of creating a nodegroup in eksctl, illustrating the use of the command structure and the optional --name flag for resource naming.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/guidelines/design-conventions.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup ng-1\n```\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --name ng-1\n```\n\n----------------------------------------\n\nTITLE: Marshalling Go structs to CloudFormation YAML/JSON\nDESCRIPTION: Example demonstrating how to programmatically build a CloudFormation template using Go structs and output the resulting JSON and YAML. The example creates an SNS topic with a unique name and a subscription that forwards notifications to an email address.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/goformation/README.md#2025-04-21_snippet_0\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/awslabs/goformation/v4/cloudformation\"\n\t\"github.com/awslabs/goformation/v4/cloudformation/sns\"\n\n\n)\n\nfunc main() {\n\n\t// Create a new CloudFormation template\n\ttemplate := cloudformation.NewTemplate()\n\n\t// Create an Amazon SNS topic, with a unique name based off the current timestamp\n\ttemplate.Resources[\"MyTopic\"] = &sns.Topic{\n\t\tTopicName: \"my-topic-\" + strconv.FormatInt(time.Now().Unix(), 10),\n\t}\n\n\t// Create a subscription, connected to our topic, that forwards notifications to an email address\n\ttemplate.Resources[\"MyTopicSubscription\"] = &sns.Subscription{\n\t\tTopicArn: cloudformation.Ref(\"MyTopic\"),\n\t\tProtocol: \"email\",\n\t\tEndpoint: \"some.email@example.com\",\n\t}\n\n\t// Let's see the JSON AWS CloudFormation template\n\tj, err := template.JSON()\n\tif err != nil {\n\t\tfmt.Printf(\"Failed to generate JSON: %s\\n\", err)\n\t} else {\n\t\tfmt.Printf(\"%s\\n\", string(j))\n\t}\n\n\t// and also the YAML AWS CloudFormation template\n\ty, err := template.YAML()\n\tif err != nil {\n\t\tfmt.Printf(\"Failed to generate YAML: %s\\n\", err)\n\t} else {\n\t\tfmt.Printf(\"%s\\n\", string(y))\n\t}\n\n}\n```\n\n----------------------------------------\n\nTITLE: Updating aws-node Add-on in eksctl\nDESCRIPTION: Command to update the aws-node (Amazon VPC CNI) add-on in an EKS cluster. This runs in plan mode by default and requires '--approve' to apply changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils update-aws-node --cluster=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: Creating Cluster with Flux Bootstrap\nDESCRIPTION: Command to create a new EKS cluster and bootstrap Flux in one operation. This requires including the Flux configuration in the same config file used for cluster creation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gitops-v2.md#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\neksctl create cluster --config-file <config-file>\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Public Subnets (Bash)\nDESCRIPTION: Command to create an EKS cluster using eksctl with specified public subnets in an existing VPC.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster \\\n  --vpc-public-subnets=subnet-0153e560b3129a696,subnet-0cc9c5aebe75083fd,subnet-009fa0199ec203c37,subnet-018fa0176ba320e45\n```\n\n----------------------------------------\n\nTITLE: AmazonLinux2 Node Troubleshooting Commands\nDESCRIPTION: Shell commands for troubleshooting AmazonLinux2 node bootstrapping issues. These commands check service status and logs for kubelet and docker services.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/nodebootstrap/README.md#2025-04-21_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nsystemctl status kubelet\nsystemctl status docker\n```\n\n----------------------------------------\n\nTITLE: Deleting Specific Nodegroup from Config\nDESCRIPTION: This command shows how to delete a specific nodegroup (ng-2-builders) defined in a config file. The --approve flag is required to confirm the deletion.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\neksctl delete nodegroup --config-file=dev-cluster.yaml --include=ng-2-builders --approve\n```\n\n----------------------------------------\n\nTITLE: Updating EKS Cluster Version Command\nDESCRIPTION: CLI command to update cluster version and append new resources to the cluster stack. Supports dry-run by default and allows version specification.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-005-upgrades.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl update cluster --name=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: NodeGroup Replacement Commands\nDESCRIPTION: Commands for creating a replacement nodegroup and deleting the current nodegroup during cluster upgrade process.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-005-upgrades.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl create ng --cluster=<clusterName> --name=<replacementNodeGroup>\neksctl delete ng --cluster=<clusterName> --name=<currentNodeGroup>\n```\n\n----------------------------------------\n\nTITLE: Demonstrating SSH Key Configuration in YAML for eksctl\nDESCRIPTION: This YAML snippet shows how to configure SSH keys in the eksctl configuration file. It demonstrates the new structure for specifying SSH parameters, including options for local file, uploaded EC2 key, or direct key content.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.1.31.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nexamples/07-ssh-keys.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating kops Cluster (Bash)\nDESCRIPTION: Commands to create a Kubernetes cluster using kops, which can later be used as a reference for creating an EKS cluster in the same VPC.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport KOPS_STATE_STORE=s3://kops\nkops create cluster cluster-1.k8s.local --zones=us-west-2c,us-west-2b,us-west-2a --networking=weave --yes\n```\n\n----------------------------------------\n\nTITLE: Enabling all EKS control plane log types\nDESCRIPTION: Command to enable all types of CloudWatch logs for an EKS cluster control plane.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-cluster-logging --enable-types all\n```\n\n----------------------------------------\n\nTITLE: ClusterConfig YAML for enabling specific CloudWatch logs\nDESCRIPTION: YAML configuration to enable specific types of CloudWatch logs (audit and authenticator) for an EKS cluster control plane.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\ncloudWatch:\n  clusterLogging:\n    enableTypes:\n      - \"audit\"\n      - \"authenticator\"\n```\n\n----------------------------------------\n\nTITLE: Defining EKS Control Plane Subnets in YAML Config\nDESCRIPTION: A YAML configuration file that specifies the control plane subnet IDs to be used when updating a cluster's VPC configuration. This defines which subnets the EKS control plane will use for its network interfaces.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n  name: cluster\n  region: us-west-2\n\nvpc:\n  controlPlaneSubnetIDs: [subnet-1234, subnet-5678]\n```\n\n----------------------------------------\n\nTITLE: Updating Cluster VPC Config with YAML File\nDESCRIPTION: This console command shows how to update the cluster VPC configuration using a YAML config file with eksctl.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config --cluster=<cluster> -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating a New Unmanaged Nodegroup in eksctl\nDESCRIPTION: Command to create a new unmanaged nodegroup in an existing cluster. The '--managed=false' flag specifies that this is an unmanaged nodegroup.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\neksctl create nodegroup --cluster=<clusterName> --region=<region> --name=<newNodeGroupName> --managed=false\n```\n\n----------------------------------------\n\nTITLE: IAM Trust Policy for Pod Identity\nDESCRIPTION: JSON configuration for IAM trust policy that allows pods.eks.amazonaws.com service principal to assume roles\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Principal\": {\n                \"Service\": \"pods.eks.amazonaws.com\"\n            },\n            \"Action\": [\n                \"sts:AssumeRole\",\n                \"sts:TagSession\"\n            ]\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Displaying Cost Estimation Output in EKSctl Calculator\nDESCRIPTION: Example output of the eksctl calculator command showing a monthly cost breakdown for an EKS cluster with 2 m5.large nodes in the eu-west-1 region. The output includes costs for EC2 instances, EBS volumes, and the EKS cluster management fee.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-004_cost-estimation.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n[]  using region eu-west-1\n[]  using \"ami-0ce0ec06e682ee10e\" for nodes\n[]  2 nodes m5.large\n[]  EBS volumes 20go\n[]  free tier \"yes\"\n[]  usage type \"utilization\"\n[]  usage value \"100%\"\n[]  estimation (per month):\n     - Amazon EC2 Service (EU (Ireland)): $ 158.86\n     -- Compute: $ 156.66\n     -- EBS Volumes: $ 2.20\n     - EKS Cluster: $ 146.4\n     total: $ 305.26\n```\n\n----------------------------------------\n\nTITLE: Updating dependencies to address security vulnerabilities in eksctl\nDESCRIPTION: Two maintenance updates are performed to address potential DoS vulnerabilities: upgrading the cloudflare/cfssl package and the goproxy component.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.158.0.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Bump `github.com/cloudflare/cfssl` to fix indirect deps DOS vulnerability (#7067)\n- Upgrade goproxy to fix DoS vulnerability (#7068)\n```\n\n----------------------------------------\n\nTITLE: Enabling all except specific EKS control plane log types\nDESCRIPTION: Command to enable all log types except controllerManager logs for an EKS cluster control plane.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-cluster-logging --enable-types=all --disable-types=controllerManager\n```\n\n----------------------------------------\n\nTITLE: Updating cluster logging using eksctl config file\nDESCRIPTION: Command to update EKS cluster logging settings using a configuration file with CloudWatch logging options.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-cluster-logging --config-file=<path>\n```\n\n----------------------------------------\n\nTITLE: Defining EKS Control Plane Security Groups in YAML Config\nDESCRIPTION: A YAML configuration file that specifies the security group IDs to be used for the EKS control plane. These security groups manage traffic between the control plane and worker nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n  name: cluster\n  region: us-west-2\n\nvpc:\n  controlPlaneSecurityGroupIDs: [sg-1234, sg-5678]\n```\n\n----------------------------------------\n\nTITLE: Proposed Flux Configuration with Flags Map\nDESCRIPTION: The final proposed configuration structure that includes a map of flags, allowing for arbitrary configuration options to be passed to Flux.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-008-flux2.md#2025-04-21_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n  gitops:\n    flux:\n      gitProvider: github|gitlab|git\n+     flags:\n+\tbranch: main\n+\tnamespace: default\n+\tcomponents: \"helm-controller,source-controller\"\n+\tpersonal: true\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster from YAML Configuration (Shell)\nDESCRIPTION: This command creates an EKS cluster using the YAML configuration file that includes Node Repair settings. It uses the -f flag to specify the configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-node-repair-config.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster -f node-repair-nodegroup-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Minimum Required Bootstrap Override Command for eksctl\nDESCRIPTION: The bare minimum bootstrap override command needed for eksctl to successfully initialize nodes with custom AMIs. This ensures proper node labeling for eksctl to identify nodes as part of the nodegroup.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/announcements/nodegroup-override-announcement.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n    overrideBootstrapCommand: |\n      #!/bin/bash\n\n      source /var/lib/cloud/scripts/eksctl/bootstrap.helper.sh\n\n      # Note \"--node-labels=${NODE_LABELS}\" needs the above helper sourced to work, otherwise will have to be defined manually.\n      /etc/eks/bootstrap.sh ${CLUSTER_NAME} --container-runtime containerd --kubelet-extra-args \"--node-labels=${NODE_LABELS}\"\n```\n\n----------------------------------------\n\nTITLE: Pod IMDS Control Configuration Reference\nDESCRIPTION: Configuration reference for disablePodIMDS option that prevents non-host networking pods in a nodegroup from making IMDS requests. This option enhances security by controlling pod access to instance metadata.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/security.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\ndisablePodIMDS\n```\n\n----------------------------------------\n\nTITLE: Retrieving EKS Configuration Schema Using eksctl CLI\nDESCRIPTION: Command to retrieve the raw JSON schema for eksctl configuration files using the eksctl utility command. This allows users to view the complete schema structure.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/schema.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils schema\n```\n\n----------------------------------------\n\nTITLE: Updating Zonal Shift Config with Configuration File\nDESCRIPTION: Shell command to enable or disable zonal shift on an existing cluster using a configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/zonal-shift.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils update-zonal-shift-config -f zonal-shift-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Enabling Credential Caching for eksctl\nDESCRIPTION: Enables credential caching for eksctl to avoid re-entering MFA tokens for each command. Cached credentials are stored by default in ~/.eksctl/cache/credentials.yaml.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\nexport EKSCTL_ENABLE_CREDENTIAL_CACHE=1\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster with Zonal Shift Using eksctl\nDESCRIPTION: Shell command to create an EKS cluster using the zonal shift configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/zonal-shift.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\neksctl create cluster -f zonal-shift-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Deleting an EKS Cluster with Custom Subnets\nDESCRIPTION: Command to delete an EKS cluster after manually removing custom subnets. This is necessary because CloudFormation cannot remove the cluster if there are dependencies outside the stack.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-with-custom-subnet.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\neksctl delete cluster -n <cluster-name> --wait\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Access Entries for Deletion\nDESCRIPTION: YAML configuration for specifying multiple access entries to be deleted, listing principal ARNs under the accessEntry field.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\n...\naccessEntry:\n  - principalARN: arn:aws:iam::111122223333:user/my-user-name\n  - principalARN: arn:aws:iam::111122223333:role/role-name-1\n  - principalARN: arn:aws:iam::111122223333:role/admin-role\n```\n\n----------------------------------------\n\nTITLE: Defining Kubelet Node Labels and Taints\nDESCRIPTION: Kubelet environment configuration stored in /etc/eksctl/kubelet.env specifying node labels and taints for the EKS cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_6\n\nLANGUAGE: ini\nCODE:\n```\nNODE_LABELS=alpha.eksctl.io/cluster-name=my-cluster-1,alpha.eksctl.io/nodegroup-name=ng-1\nNODE_TAINTS=\n```\n\n----------------------------------------\n\nTITLE: IAM Policies Configuration Reference\nDESCRIPTION: Reference to withAddonPolicies configuration option, noting its incompatibility with disablePodIMDS option.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/security.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nwithAddonPolicies\n```\n\n----------------------------------------\n\nTITLE: Configuring Unmanaged Nodegroup with GPU Spot Instances\nDESCRIPTION: YAML configuration for an unmanaged nodegroup using mixed GPU instance types with Spot pricing.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/spot-instances.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-gpu\n    instanceType: mixed\n    desiredCapacity: 1\n    instancesDistribution:\n      instanceTypes:\n        - g5.xlarge\n        - g5.8xlarge\n        - g5.16xlarge\n      maxPrice: 0.50\n```\n\n----------------------------------------\n\nTITLE: Creating nodegroups on AWS Outposts for an existing cluster\nDESCRIPTION: Shell command to create nodegroups on AWS Outposts for an existing EKS cluster. This extends a regional EKS cluster to include worker nodes running on Outposts.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create nodegroup -f extended-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Non-Zone-Aware NodeGroup Configuration\nDESCRIPTION: YAML configuration showing a single nodegroup that would span multiple availability zones. This approach works for workloads without zone-specific requirements.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/autoscaling.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1-public\n    instanceType: m5.xlarge\n    # availabilityZones: [\"eu-west-2a\", \"eu-west-2b\"]\n```\n\n----------------------------------------\n\nTITLE: Enabling KMS Encryption on Existing EKS Cluster Using CLI Parameters\nDESCRIPTION: Shell command to enable KMS envelope encryption on an existing EKS cluster using explicit CLI parameters. This approach specifies the cluster name, KMS key ARN, and region directly in the command.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/kms-encryption.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl utils enable-secrets-encryption --cluster=kms-cluster --key-arn=arn:aws:kms:us-west-2:<account>:key/<key> --region=<region>\n```\n\n----------------------------------------\n\nTITLE: Configuring VPC CNI Permission Boundary\nDESCRIPTION: Example configuration for setting up a permission boundary specifically for the VPC-CNI IAM service account in the kube-system namespace. This is necessary when creating a cluster with OIDC enabled.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-permissions-boundary.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\niam:\n  serviceAccounts:\n    - metadata:\n        name: aws-node\n        namespace: kube-system\n      attachPolicyARNs:\n      - \"arn:aws:iam::<arn>:policy/AmazonEKS_CNI_Policy\"\n      permissionsBoundary: \"arn:aws:iam::11111:policy/entity/boundary\"\n```\n\n----------------------------------------\n\nTITLE: Creating Cluster from Generated Config\nDESCRIPTION: Command to create a cluster using the configuration generated from a dry run.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/instance-selector.md#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster -f generated-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Extended Cluster Configuration with Multiple Nodegroups\nDESCRIPTION: Enhanced version of the cluster configuration with four nodegroups, demonstrating how to define multiple nodegroups with different specifications in a single config file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-003-extending-use-of-config-file.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha4\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-5\n  region: eu-north-1\n\nnodeGroups:\n  - name: ng1-public\n    instanceType: m5.xlarge\n    desiredCapacity: 4\n  - name: ng2-private\n    instanceType: m5.large\n    desiredCapacity: 10\n    privateNetworking: true\n  - name: ng3-dev\n    instanceType: m4.large\n    desiredCapacity: 2\n    privateNetworking: true\n  - name: ng2-test\n    instanceType: m5.large\n    desiredCapacity: 4\n    privateNetworking: true\n```\n\n----------------------------------------\n\nTITLE: IAM Service Account Management\nDESCRIPTION: Service account name preservation fix in delete operations\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.48.0.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\ndelete iamserviceaccount\n```\n\n----------------------------------------\n\nTITLE: Configuring Private Networking for Nodegroups in YAML for eksctl\nDESCRIPTION: This YAML snippet demonstrates how to configure a nodegroup to use private networking in eksctl. It shows setting the 'privateNetworking' flag to true and specifying a private subnet for the nodegroup.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-subnet-settings.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  id: \"vpc-11111\"\n  subnets:\n    public:\n      private-one:\n          id: \"subnet-0153e560b3129a696\"\n    ... # subnet spec continued\n\nnodeGroups:\n  - name: ng-1\n    instanceType: m5.xlarge\n    desiredCapacity: 2\n    privateNetworking: true\n    subnets:\n      - private-one\n```\n\n----------------------------------------\n\nTITLE: Creating a fully-private EKS cluster on AWS Outposts\nDESCRIPTION: YAML configuration for creating a fully-private EKS cluster on AWS Outposts. This setup enables a private-only access to the cluster's API server.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# outpost-fully-private.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: outpost-fully-private\n  region: us-west-2\n\nprivateCluster:\n  enabled: true\n\noutpost:\n  # Required.\n  controlPlaneOutpostARN: \"arn:aws:outposts:us-west-2:1234:outpost/op-1234\"\n  # Optional, defaults to the smallest available instance type on the Outpost.\n  controlPlaneInstanceType: m5d.large\n```\n\n----------------------------------------\n\nTITLE: eksctl Command for Disabling Auto Mode\nDESCRIPTION: Shows the shell command to disable Auto Mode on an existing cluster using the update auto-mode-config command.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl update auto-mode-config -f cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: ClusterConfig YAML for Custom Subnet Nodegroups\nDESCRIPTION: Example YAML configuration for eksctl that specifies custom subnets for a nodegroup. The configuration includes cluster metadata and nodegroup specifications with custom subnet IDs.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-with-custom-subnet.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# A simple example of ClusterConfig object with two nodegroups:\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-3\n  region: eu-north-1\n\nnodeGroups:\n  - name: new-subnet-nodegroup\n    instanceType: m5.large\n    desiredCapacity: 1\n    subnets:\n      - subnet-id1\n      - subnet-id2\n```\n\n----------------------------------------\n\nTITLE: Pod Identity Associations YAML Configuration\nDESCRIPTION: YAML structure for defining pod identity associations in eksctl configuration\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\niam:\n  podIdentityAssociations:\n  - namespace: <string> #required\n    serviceAccountName: <string> #required\n    createServiceAccount: true #optional, default is false\n    roleARN: <string> #required if none of permissionPolicyARNs, permissionPolicy and wellKnownPolicies is specified\n    roleName: <string> #optional, generated automatically if not provided\n    permissionPolicy: {} #optional\n    permissionPolicyARNs: [] #optional\n    wellKnownPolicies: {} #optional\n    permissionsBoundaryARN: <string> #optional\n    tags: {} #optional\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster from Configuration File\nDESCRIPTION: Command to create an EKS cluster using a YAML configuration file. This approach allows for more customized cluster configurations compared to using command line parameters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/arm-support.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster -f cluster-arm-1.yaml\n```\n\n----------------------------------------\n\nTITLE: Release Notes Content in Markdown\nDESCRIPTION: Structured release notes documenting changes in eksctl v0.192.0, including new features, improvements, bug fixes, and acknowledgments.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.192.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.192.0\n\n##  Features\n\n- Add support for EKS accelerated AMIs based on AL2023 (#7996)\n\n##  Improvements\n\n- cleanup efa installer archive before install (#6870)\n\n##  Bug Fixes\n\n- Disallow `overrideBootstrapCommand` and `preBootstrapCommands` for MNG AL2023 (#7990)\n\n## Acknowledgments\n\nThe eksctl maintainers would like to sincerely thank @vsoch.\n```\n\n----------------------------------------\n\nTITLE: Loading JavaScript Schema Module in HTML\nDESCRIPTION: HTML script tag that loads a JavaScript module (schema.js) which likely contains the schema definition or rendering logic for the configuration table.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/schema.md#2025-04-21_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<script type=\"module\" src=\"../schema.js\"></script>\n```\n\n----------------------------------------\n\nTITLE: Creating EKS Cluster in Existing kops VPC (Bash)\nDESCRIPTION: Command to create an EKS cluster using eksctl in the same VPC as a previously created kops cluster.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster --name=cluster-2 --region=us-west-2 --vpc-from-kops-cluster=cluster-1.k8s.local\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS cluster on AWS Outposts using eksctl\nDESCRIPTION: Shell command to create an EKS cluster on AWS Outposts using a YAML configuration file. This initializes the cluster based on the specified configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster -f outpost.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating a nodegroup using a config file\nDESCRIPTION: Command to create a nodegroup using a ClusterConfig YAML file, which provides more control over the configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create nodegroup --config-file=YOUR_CLUSTER.yaml\n```\n\n----------------------------------------\n\nTITLE: Enabling specific EKS control plane log type (audit)\nDESCRIPTION: Command to enable only audit logs for an EKS cluster control plane.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-cluster-logging --enable-types audit\n```\n\n----------------------------------------\n\nTITLE: Unmarshalling CloudFormation YAML/JSON into Go structs\nDESCRIPTION: Example demonstrating how to parse JSON/YAML CloudFormation/SAM templates into Go structs. The code opens a template file, extracts resources of a specific type, and demonstrates searching for resources by their logical ID.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/goformation/README.md#2025-04-21_snippet_1\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"log\"\n\n\t\"github.com/awslabs/goformation/v4\"\n)\n\nfunc main() {\n\n\t// Open a template from file (can be JSON or YAML)\n\ttemplate, err := goformation.Open(\"template.yaml\")\n\tif err != nil {\n\t\tlog.Fatalf(\"There was an error processing the template: %s\", err)\n\t}\n\n\t// You can extract all resources of a certain type\n\t// Each AWS CloudFormation resource is a strongly typed struct\n\tfunctions := template.GetAllServerlessFunctionResources()\n\tfor name, function := range functions {\n\n\t\t// E.g. Found a AWS::Serverless::Function named GetHelloWorld (runtime: nodejs6.10)\n\t\tlog.Printf(\"Found a %s named %s (runtime: %s)\\n\", function.AWSCloudFormationType(), name, function.Runtime)\n\n\t}\n\n\t// You can also search for specific resources by their logicalId\n\tsearch := \"GetHelloWorld\"\n\tfunction, err := template.GetServerlessFunctionWithName(search)\n\tif err != nil {\n\t\tlog.Fatalf(\"Function not found\")\n\t}\n\n\t// E.g. Found a AWS::Serverless::Function named GetHelloWorld (runtime: nodejs6.10)\n\tlog.Printf(\"Found a %s named %s (runtime: %s)\\n\", function.AWSCloudFormationType(), search, function.Runtime)\n\n}\n```\n\n----------------------------------------\n\nTITLE: Ubuntu Node Troubleshooting Commands\nDESCRIPTION: Shell commands for troubleshooting Ubuntu node bootstrapping issues. These commands help check service status and logs for the kubelet and docker services.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/nodebootstrap/README.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nsudo snap logs kubelet-eks [-n=all/20]\nsystemctl status docker.service\n```\n\n----------------------------------------\n\nTITLE: Release Notes Documentation in Markdown\nDESCRIPTION: Changelog detailing improvements to addon creation workflow, IAM policy updates for AWS load balancer controller, and fixes for nodegroup management issues including taints support and private cluster connectivity.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.52.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.52.0\n\n## Improvements\n\n- create addons (except vpc-cni) after nodegroups are created (#3736)\n- update IAM policy for aws-load-balancer-controller #3734\n\n## Bug Fixes\n\n- Fix taints support in unmanaged nodegroups (#3702)\n- Fix bug preventing nodegroups from joining fully-private clusters (#3737)\n- Reset cgroup drivers back to cgroupfs (#3637)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n @M00nF1sh\n```\n\n----------------------------------------\n\nTITLE: Using OIDC Configuration Option Reference\nDESCRIPTION: Configuration reference for withOIDC option that enables IRSA for amazon CNI plugin and manages node permissions. This enhances security by limiting node permissions and granting necessary access only to CNI service account.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/security.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nwithOIDC\n```\n\n----------------------------------------\n\nTITLE: Deleting a Fargate Profile\nDESCRIPTION: Command to delete a Fargate profile with the --wait flag, which makes eksctl wait until the profile is completely deleted. Fargate profiles are immutable, so they must be deleted and recreated to make changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_12\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl delete fargateprofile --cluster fargate-example-cluster --name fp-9bfc77ad --wait\n2019-11-27T19:04:26+09:00 []  deleting Fargate profile \"fp-9bfc77ad\"\n  ClusterName: \"fargate-example-cluster\",\n  FargateProfileName: \"fp-9bfc77ad\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating IAM Identity Mappings from ClusterConfig with eksctl in Bash\nDESCRIPTION: This snippet shows how to create IAM identity mappings using a ClusterConfig file with eksctl. It requires the path to the YAML configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-identity-mappings.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\neksctl create iamidentitymapping -f cluster-with-iamidentitymappings.yaml\n```\n\n----------------------------------------\n\nTITLE: Enabling and disabling specific EKS control plane log types simultaneously\nDESCRIPTION: Command to enable controllerManager logs while disabling scheduler logs for an EKS cluster control plane in a single operation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cloudwatch-cluster-logging.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-cluster-logging --enable-types=controllerManager --disable-types=scheduler\n```\n\n----------------------------------------\n\nTITLE: Alternative Design with String Arguments List\nDESCRIPTION: An alternative YAML configuration approach using a list of strings to pass arguments directly to Flux. This would be used if a map cannot cover all possible Flux flags.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-008-flux2.md#2025-04-21_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n  gitops:\n    flux:\n      gitProvider: github\n+     args:\n+       - \"--flag-one=value\"\n+       - \"--flag-two value\"\n+       - \"--bool-flag\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Managed Security Group Rules (YAML)\nDESCRIPTION: YAML configuration to prevent eksctl from managing security group rules for the shared node security group.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  sharedNodeSecurityGroup: sg-0123456789\n  manageSharedNodeSecurityGroupRules: false\n```\n\n----------------------------------------\n\nTITLE: Describing EKS Cluster Stacks in Console\nDESCRIPTION: Command to list and describe CloudFormation stacks associated with an EKS cluster in a specific region.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/faq.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl utils describe-stacks --region=us-west-2 --cluster NAME\n```\n\n----------------------------------------\n\nTITLE: Alternative Design with Explicit Provider Configuration\nDESCRIPTION: A more comprehensive YAML configuration that includes explicit options for different Git providers (GitLab, GitHub, Git) along with common configuration parameters and arbitrary arguments.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-008-flux2.md#2025-04-21_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ngitops:\n  flux:\n    # gitlab, github and git would not be specified all at once ofc, but you get the idea\n    gitlab:\n      branch: main\n      namespace: \"flux-system\"\n      components:\n      - \"source-controller\"\n      - \"kustomise-controller\"\n      fluxExtraArgs:\n\t- \"--flag-one=value\"\n\t- \"--flag-two value\"\n\t- \"--bool-flag\"\n      interval: 1m0s\n      path: \"clusters/cluster-27\"\n      owner: dr-who\n      repository: my-cluster-gitops\n      personal: true\n      hostname: \"gh-enterprise.com\"\n      interval: 1m0s\n      private: true\n      readWriteKey: true\n      reconcile: true\n      teams:\n      - \"team1\"\n      - \"team2\"\n    github:\n      ... would be same as gitlag\n    git:\n      branch: main\n      namespace: \"flux-system\"\n      components:\n      - \"source-controller\"\n      - \"kustomise-controller\"\n      fluxExtraArgs:\n\t- \"--flag-one=value\"\n\t- \"--flag-two value\"\n\t- \"--bool-flag\"\n      interval: 1m0s\n      path: \"clusters/cluster-27\"\n      username: \"dr-who\"\n      passwordFile: /basic/auth/pass\n      url: https://<host>/<org>/<repository>\n```\n\n----------------------------------------\n\nTITLE: Getting Fargate Profiles in YAML Format\nDESCRIPTION: Command to display existing Fargate profiles in a cluster in YAML format, showing details about execution role, namespace selectors, and subnets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_10\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl get fargateprofile --cluster fargate-example-cluster -o yaml\n- name: fp-9bfc77ad\n  podExecutionRoleARN: arn:aws:iam::123456789012:role/eksctl-fargate-example-cluster-ServiceRole-1T5F78E5FSH79\n  selectors:\n  - namespace: dev\n  subnets:\n  - subnet-00adf1d8c99f83381\n  - subnet-04affb163ffab17d4\n  - subnet-035b34379d5ef5473\n```\n\n----------------------------------------\n\nTITLE: Creating Nodegroup from Config File\nDESCRIPTION: This command creates a nodegroup using a configuration file. It's useful for creating multiple nodegroups or specifying detailed nodegroup settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --config-file=<path>\n```\n\n----------------------------------------\n\nTITLE: Upgrading a managed nodegroup to latest AMI version\nDESCRIPTION: Command to upgrade a managed nodegroup to the latest EKS-optimized AMI release version for the current Kubernetes version.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\neksctl upgrade nodegroup --name=managed-ng-1 --cluster=managed-cluster\n```\n\n----------------------------------------\n\nTITLE: Building eksctl from Source with Make\nDESCRIPTION: Commands for installing dependencies and building the eksctl binary using make. This is the standard build process for Linux/Unix systems.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake install-build-deps\nmake build\n```\n\n----------------------------------------\n\nTITLE: Defining NodeGroups in eksctl Config File (YAML)\nDESCRIPTION: A basic eksctl configuration example showing how to define nodegroups in the config file. This snippet demonstrates the authoritative list approach where only the specified nodegroups should exist.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-apply.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-2\n    desiredCapacity: 1\n```\n\n----------------------------------------\n\nTITLE: Defining the Bootstrapper Interface in Go\nDESCRIPTION: Interface declaration for the Bootstrapper type which must be implemented by all AMI families. The UserData method is responsible for generating the appropriate bootstrap script for each node type.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/nodebootstrap/README.md#2025-04-21_snippet_0\n\nLANGUAGE: go\nCODE:\n```\ntype Bootstrapper interface {\n  UserData() (string, error)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS cluster on AWS Outposts with existing VPC using eksctl\nDESCRIPTION: Shell command to create an EKS cluster on AWS Outposts with an existing VPC configuration. This initializes the cluster using the pre-defined VPC and subnet settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster -f outpost-existing-vpc.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating Named Fargate Profile\nDESCRIPTION: Command to create a Fargate profile with a custom name. The profile name must not start with the prefix 'eks-'.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create fargateprofile --namespace dev --cluster fargate-example-cluster --name fp-development\n[]  created Fargate profile \"fp-development\" on EKS cluster \"fargate-example-cluster\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Fargate Profile Information\nDESCRIPTION: This command retrieves and displays information about the Fargate profile created for an EKS cluster, including the profile name, pod execution role ARN, selectors, and subnets.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl get fargateprofile --cluster ridiculous-painting-1574859263 -o yaml\n```\n\n----------------------------------------\n\nTITLE: Updating Cluster VPC Config Using YAML File\nDESCRIPTION: This console command demonstrates how to update the cluster VPC configuration using a ClusterConfig YAML file with eksctl.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config -f config.yaml --approve\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests for eksctl\nDESCRIPTION: Commands for running the unit test suite for eksctl. This verifies that code changes don't break existing functionality.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nmake test\n```\n\n----------------------------------------\n\nTITLE: Dry Run Configuration Example\nDESCRIPTION: Example YAML configuration showing the output of a dry run command with instance selector criteria.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: linux\n  instanceTypes: [\"c3.large\", \"c4.large\", \"c5.large\", \"c5d.large\", \"c5n.large\", \"c5a.large\"]\n  instanceSelector:\n    vCPUs: 2\n    memory: 4\n\nnodeGroups:\n- name: windows\n  amiFamily: WindowsServer2019CoreContainer\n  instanceSelector:\n    vCPUs: 1\n    memory: 2\n  instancesDistribution:\n    maxPrice: 0.017\n    instanceTypes: [\"c3.large\", \"c4.large\", \"c5.large\", \"c5d.large\", \"c5n.large\", \"c5a.large\"]\n    onDemandBaseCapacity: 0\n    onDemandPercentageAboveBaseCapacity: 50\n    spotInstancePools: 2\n```\n\n----------------------------------------\n\nTITLE: Release Notes Documentation in Markdown\nDESCRIPTION: Markdown formatted release notes detailing new features in eksctl v0.106.0, specifically the addition of instance availability lookup functionality across all Availability Zones.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.106.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.106.0\n\n## Features\n\n- Lookup instance availability for all AZs (#5454)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n@vflaux\n```\n\n----------------------------------------\n\nTITLE: Viewing Labels on EKS Managed Nodegroup using eksctl\nDESCRIPTION: Command to view all labels set on an EKS Managed Nodegroup. It uses the 'get labels' subcommand of eksctl, specifying the cluster and nodegroup.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-managed.md#2025-04-21_snippet_16\n\nLANGUAGE: console\nCODE:\n```\neksctl get labels --cluster managed-cluster --nodegroup managed-ng-1\n```\n\n----------------------------------------\n\nTITLE: Writing EKS Cluster Credentials to Custom Location\nDESCRIPTION: Creates an EKS cluster and writes the kubeconfig credentials to a specified file instead of the default location.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --name=cluster-2 --nodes=4 --kubeconfig=./kubeconfig.cluster-2.yaml\n```\n\n----------------------------------------\n\nTITLE: Updating coredns Add-on in EKS Cluster\nDESCRIPTION: Command to update the coredns add-on in an EKS cluster. This command runs in plan mode by default and requires the --approve flag to apply changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addon-upgrade.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neksctl utils update-coredns --cluster=<clusterName>\n```\n\n----------------------------------------\n\nTITLE: Deleting IAM Identity Mapping with eksctl in Bash\nDESCRIPTION: This snippet demonstrates how to delete an IAM identity mapping using eksctl. It requires the cluster name, region, and ARN of the mapping to be deleted.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/iam-identity-mappings.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\neksctl delete iamidentitymapping --cluster  <clusterName> --region=<region> --arn arn:aws:iam::123456:role/testing\n```\n\n----------------------------------------\n\nTITLE: Running a Specific Integration Test Suite for eksctl\nDESCRIPTION: Command for running a specific integration test suite using Ginkgo. This allows focused testing of just the components relevant to your changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nginkgo -tags integration -v --progress integration/tests/<suite name>/... -- -test.v -ginkgo.v\n```\n\n----------------------------------------\n\nTITLE: Verifying Add-on Status in Kubernetes\nDESCRIPTION: Command to check if all addon pods are in ready state after upgrading. This command lists all pods in the kube-system namespace.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get pods -n kube-system\n```\n\n----------------------------------------\n\nTITLE: Documenting Release Notes in Markdown\nDESCRIPTION: Markdown formatted release notes detailing major changes including support for EKS Managed Nodegroups, addition of NodeInstanceRoleARN to NodeGroupSummary, and SSH access fixes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.10.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.10.0\n\n## Features\n\n- support for EKS Managed Nodegroups (#1566)\n\n## Improvements\n\n- add NodeInstanceRoleARN to NodeGroupSummary (#1500)\n\n## Bug Fixes\n\n- fix enabling SSH when allow is not set (#1545)\n```\n\n----------------------------------------\n\nTITLE: Updating Kubernetes API Endpoint Access with eksctl\nDESCRIPTION: This console command shows how to update the Kubernetes API endpoint access configuration for an existing EKS cluster using the eksctl utils sub-command.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-cluster-access.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config --cluster=<clustername> --private-access=true --public-access=false\n```\n\n----------------------------------------\n\nTITLE: Writing Cluster Credentials to Kubeconfig\nDESCRIPTION: Retrieves and writes EKS cluster credentials to kubeconfig at any time, useful for accessing existing clusters or refreshing credentials.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\neksctl utils write-kubeconfig --cluster=<name> [--kubeconfig=<path>] [--set-kubeconfig-context=<bool>]\n```\n\n----------------------------------------\n\nTITLE: Retrieving Access Entry for Specific IAM Principal\nDESCRIPTION: Command to get a specific access entry by providing both cluster name and principal ARN.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\neksctl get accessentry --cluster my-cluster --principal-arn arn:aws:iam::111122223333:user/admin\n```\n\n----------------------------------------\n\nTITLE: Updating EKS Control Plane Subnets via Command Line\nDESCRIPTION: This command updates the subnets used by the EKS control plane. The control plane uses these subnets for its elastic network interfaces (ENIs) to communicate with your VPC.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config --cluster=<cluster> --control-plane-subnet-ids=subnet-1234,subnet-5678\n```\n\n----------------------------------------\n\nTITLE: Instance Selector Schema Definition\nDESCRIPTION: YAML schema showing the structure of the instanceSelector configuration block for nodegroups.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ninstanceSelector:\n  vCPUs: <integer>\n  memory: <integer>\n  gpus: <integer>\n```\n\n----------------------------------------\n\nTITLE: Adding InstanceSelector field to NodeGroupBase struct\nDESCRIPTION: Extension of the NodeGroupBase struct to include the new InstanceSelector field, making it available for both NodeGroup and ManagedNodeGroup through embedding.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_7\n\nLANGUAGE: go\nCODE:\n```\ntype NodeGroupBase struct {\n\tInstanceSelector *InstanceSelector `json:\"instanceSelector\"`\n}\n```\n\n----------------------------------------\n\nTITLE: EKSctl Release Notes v0.29.2\nDESCRIPTION: Release notes documenting bug fix for kubernetesNetworkConfig functionality when adding new nodegroups to existing clusters. Includes acknowledgment to contributors.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.29.2.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.29.2\n\n## Bug Fixes\n\n- Fix kubernetesNetworkConfig with new nodegroups for existing clusters (#2713)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank our contributors!\n```\n\n----------------------------------------\n\nTITLE: Fixed Commands for eksctl Nodegroup Operations\nDESCRIPTION: Commands that were fixed in this release, specifically 'eksctl get ng' for getting nodegroup information and the cluster creation flag '--without-nodegroup'.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.4.2.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\neksctl get ng\n```\n\nLANGUAGE: bash\nCODE:\n```\neksctl create cluster --without-nodegroup\n```\n\n----------------------------------------\n\nTITLE: Configuring Add-Ons with Custom Configuration Values in YAML Format\nDESCRIPTION: YAML example showing how to provide custom configuration values for an add-on using the configurationValues field with YAML formatting. This allows customizing add-on behavior, such as setting the replica count for CoreDNS.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: coredns\n  configurationValues: |-\n    replicaCount: 2\n```\n\n----------------------------------------\n\nTITLE: Configuring NAT Gateway (YAML)\nDESCRIPTION: YAML configuration for specifying the NAT Gateway mode in the VPC settings.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/vpc-configuration.md#2025-04-21_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  nat:\n    gateway: HighlyAvailable # other options: Disable, Single (default)\n```\n\n----------------------------------------\n\nTITLE: Updating Both Subnets and Security Groups via Command Line\nDESCRIPTION: This command updates both the subnet IDs and security group IDs for an EKS cluster's control plane in a single operation. The --approve flag is required to apply the changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config --cluster=<cluster> --control-plane-subnet-ids=<> --control-plane-security-group-ids=<> --approve\n```\n\n----------------------------------------\n\nTITLE: Config File Based NodeGroup Management\nDESCRIPTION: Commands for creating new nodegroups and deleting old ones using configuration file approach.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-005-upgrades.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\neksctl create ng --config-file=cluster.yaml --only=<replacementNodeGroup>\neksctl delete ng --cluster=<clusterName> --name=<currentNodeGroup>\n```\n\n----------------------------------------\n\nTITLE: Defining InstanceSelector type in Go for API changes\nDESCRIPTION: The Go struct definition for the new InstanceSelector type that represents instance selector options with fields for vCPUs, memory, and GPUs.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_6\n\nLANGUAGE: go\nCODE:\n```\ntype InstanceSelector struct {\n\tVCPUs  int `json:\"vCPUs\"`\n\tMemory int `json:\"memory\"`\n\tGPUs int `json:\"gpus\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Defining AmazonEC2FullAccess AWS Managed Policy in JSON\nDESCRIPTION: This AWS managed policy grants full access to EC2 and related services. It allows actions on EC2, Elastic Load Balancing, CloudWatch, Auto Scaling, and creation of service-linked roles for specific AWS services.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/minimum-iam-policies.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"ec2:*\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"elasticloadbalancing:*\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"cloudwatch:*\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"autoscaling:*\",\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"iam:CreateServiceLinkedRole\",\n            \"Resource\": \"*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"iam:AWSServiceName\": [\n                        \"autoscaling.amazonaws.com\",\n                        \"ec2scheduled.amazonaws.com\",\n                        \"elasticloadbalancing.amazonaws.com\",\n                        \"spot.amazonaws.com\",\n                        \"spotfleet.amazonaws.com\",\n                        \"transitgateway.amazonaws.com\"\n                    ]\n                }\n            }\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Draining a Nodegroup\nDESCRIPTION: This command drains all pods from a nodegroup without deleting it. It's useful for maintenance or preparing for nodegroup updates.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\neksctl drain nodegroup --cluster=<clusterName> --name=<nodegroupName>\n```\n\n----------------------------------------\n\nTITLE: Configuring Add-Ons with Custom Configuration Values in JSON Format\nDESCRIPTION: YAML example showing how to provide custom configuration values for an add-on using the configurationValues field with JSON formatting. This demonstrates setting configuration values with conflict resolution strategy.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addons.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: coredns\n  version: latest\n  configurationValues: \"{\\\"replicaCount\\\":3}\"\n  resolveConflicts: overwrite\n```\n\n----------------------------------------\n\nTITLE: Creating a Nodegroup from YAML Configuration\nDESCRIPTION: Command to create a nodegroup using a YAML configuration file instead of command line arguments.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-with-custom-subnet.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup -f cluster-managed.yaml\n```\n\n----------------------------------------\n\nTITLE: Retrieving Access Entries with Cluster Name\nDESCRIPTION: Command to get all access entries for a specified cluster using the cluster name.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\neksctl get accessentry --cluster my-cluster\n```\n\n----------------------------------------\n\nTITLE: Configure cloudWatch Cluster Logging Types in EKSctl\nDESCRIPTION: Valid configuration entries for cloudWatch cluster logging enable types in the schema configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.48.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ncloudWatch.clusterLogging.enableTypes\n```\n\n----------------------------------------\n\nTITLE: GitOps and Flux Type Definitions in Go\nDESCRIPTION: Defines the Go struct types for GitOps configuration in eksctl. The GitOps struct contains a reference to Flux configuration, while the Flux struct defines properties for the Git provider and arbitrary configuration flags.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-008-flux2.md#2025-04-21_snippet_4\n\nLANGUAGE: go\nCODE:\n```\n// GitOps groups all configuration options related to enabling GitOps Toolkit on a\n// cluster and linking it to a Git repository.\n// Note: this will replace the older Git types\ntype GitOps struct {\n\t// [Enable Toolkit](/usage/gitops/#experimental-installing-gitops-toolkit-flux-v2)\n\tFlux *Flux `json:\"flux,omitempty\"`\n}\n\n// Flux groups all configuration options related to a Git repository used for\n// GitOps Toolkit (Flux v2).\ntype Flux struct {\n\t// The repository hosting service. Can be either Github, Gitlab or Git. Required.\n\tGitProvider string `json:\"gitProvider,omitempty\"`\n\n\t// Arbitrary map of key value pairs which will be passed to Flux bootstrap as flags\n\tFlags map[string]string `json:\"namespace,omitempty\"`\n}\n```\n\n----------------------------------------\n\nTITLE: Kubectl Run Authorization Error Example\nDESCRIPTION: Error message displayed when kubectl run command fails due to internal authorization errors in private subnet deployments.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/troubleshooting.md#2025-04-21_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nError from server (InternalError): Internal error occurred: Authorization error (user=kube-apiserver-kubelet-client, verb=get, resource=nodes, subresource=proxy)\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS cluster on AWS Outposts without nodegroups\nDESCRIPTION: Shell command to create an EKS cluster on AWS Outposts without nodegroups. This is necessary because initially there's no connectivity to the API server until the VPC is associated with a local gateway.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/outposts.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\neksctl create cluster -f outpost.yaml --without-nodegroup\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Nodegroups with Config File in eksctl\nDESCRIPTION: Command to create multiple nodegroups defined in a configuration file. This is useful when upgrading multiple nodegroups at once.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\neksctl create nodegroup --config-file=<path>\n```\n\n----------------------------------------\n\nTITLE: Applying EKS Subnet Config Changes via Config File\nDESCRIPTION: This command applies the subnet configuration changes defined in a YAML file to an EKS cluster. It uses the eksctl utility to update the cluster's VPC configuration based on the specified file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-subnets-security-groups.md#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\neksctl utils update-cluster-vpc-config -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Deleting a Single Access Entry\nDESCRIPTION: Command to delete a specific access entry by providing cluster name and principal ARN.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\neksctl delete accessentry --cluster my-cluster --principal-arn arn:aws:iam::111122223333:user/admin\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic IPv6 Block Allocation in YAML\nDESCRIPTION: YAML configuration snippet showing how to enable automatic IPv6 block allocation to all subnets in eksctl using the vpc.autoAllocateIPv6 property.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.1.32.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nvpc:\n  autoAllocateIPv6: true\n```\n\n----------------------------------------\n\nTITLE: Release Notes Documentation in Markdown\nDESCRIPTION: Markdown formatted release notes for eksctl version 0.34.0, documenting new features including EMR container access support (#2913) and improved fargate profile status display (#2886).\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.34.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.34.0\n\n## Features\n\n- Support enabling access for EMR containers (#2913)\n\n## Improvements\n\n- Show status of fargate profile in get command (#2886)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n  @hvydya\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests with a Pre-created Cluster\nDESCRIPTION: Commands for creating a development cluster, running integration tests against it, and then deleting the cluster. This workflow provides faster test iteration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nTEST_CLUSTER=<name> make create-integration-test-dev-cluster\nTEST_CLUSTER=<name> make integration-test-dev\nTEST_CLUSTER=<name> make delete-integration-test-dev-cluster\n```\n\n----------------------------------------\n\nTITLE: Configuring VPC Subnets with Incorrect AZ Mapping\nDESCRIPTION: Example of incorrect VPC subnet configuration where subnet IDs are mapped to wrong Availability Zones, causing deployment errors.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/troubleshooting.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: test\n  region: us-east-1\n\nvpc:\n  subnets:\n    public:\n      us-east-1a: {id: subnet-11111111}\n      us-east-1b: {id: subnet-22222222}\n    private:\n      us-east-1a: {id: subnet-33333333}\n      us-east-1b: {id: subnet-44444444}\n\nnodeGroups: []\n```\n\n----------------------------------------\n\nTITLE: Deleting Multiple Access Entries\nDESCRIPTION: Command to delete multiple access entries using a configuration file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/access-entries.md#2025-04-21_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\neksctl delete accessentry -f config.yaml\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster without Initial Nodegroups\nDESCRIPTION: Creates an EKS cluster from a configuration file but skips creating nodegroups until later, allowing for staged deployment.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/getting-started.md#2025-04-21_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\neksctl create cluster --config-file=<path> --without-nodegroup\n```\n\n----------------------------------------\n\nTITLE: Disabling Default Node Pools in Auto Mode Configuration\nDESCRIPTION: Demonstrates how to disable the creation of default node pools when enabling Auto Mode. This allows users to configure their own node pools with custom subnet configurations.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/auto-mode.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n    name: auto-mode-cluster\n    region: us-west-2\n\nautoModeConfig:\n    enabled: true\n    nodePools: [] # disables creation of default node pools.\n```\n\n----------------------------------------\n\nTITLE: Dry Run with Instance Selector\nDESCRIPTION: Command to preview the cluster configuration with expanded instance types based on selector criteria.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/instance-selector.md#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster --name development --instance-selector-vcpus=2 --instance-selector-memory=4 --dry-run\n```\n\n----------------------------------------\n\nTITLE: Release Notes Documentation in Markdown\nDESCRIPTION: Structured changelog documenting new features, improvements, bug fixes, and acknowledgments for eksctl version 0.21.0. Includes references to pull request numbers for tracking changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.21.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.21.0\n\n\n## Features\n\n- Ability of changing the node instance name (#1796)\n- Lock kubeconfig file before accessing (#2230)\n\n## Improvements\n\n- Use apps/v1 for Deployment for all K8s versions (#2238)\n- Propagate SSH_AUTH_SOCK environment variable to git executor (#2083)\n\n## Bug Fixes\n\n- Try to delete nodegroup for any nodegroup state (#2252)\n- Fix bug in supporting non-default branches for gitops repos (#2246)\n- Don't run extra cluster tasks and nodegroup creation in parallel (#2248)\n- Fix update-cluster-endpoints panic when using a cluster config with missing VPC section (#2253)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n@aaronjwood,  @danil-smirnov, @hiddeco,  @mikestef9, @rndstr, @rodrigc and @spaghettifunk\n```\n\n----------------------------------------\n\nTITLE: EKS Cluster CA Certificate\nDESCRIPTION: Certificate Authority (CA) certificate for the EKS cluster stored in /etc/eksctl/ca.crt\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/current-001-node_bootstrap.md#2025-04-21_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n-----BEGIN CERTIFICATE-----\n1231231231231231231231231231231231231231231231231231231231231233\nABCABCABCABCABCABCABCABCABCABCABCABCABCABCABCABCABCABCABCABCABCA\n........\n-----END CERTIFICATE-----\n```\n\n----------------------------------------\n\nTITLE: Using Ignore Flag in NodeGroups Configuration (YAML)\nDESCRIPTION: An example of how an 'ignore' flag could be implemented in the config to tell eksctl about resources that should be preserved and not reconciled or deleted during apply operations.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-apply.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng-1\n    ignore: true\n  - name: ng-2\n    desiredCapacity: 1\n```\n\n----------------------------------------\n\nTITLE: Adding ASG Tags for Scale-up from Zero with Labels and Taints\nDESCRIPTION: YAML configuration that manually adds the required Auto Scaling Group tags to preserve labels and taints when scaling up from zero. The specific tag format enables the Cluster Autoscaler to apply these properties to new nodes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/autoscaling.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1-public\n    ...\n    labels:\n      my-cool-label: pizza\n    taints:\n      feaster: \"true:NoSchedule\"\n    tags:\n      k8s.io/cluster-autoscaler/node-template/label/my-cool-label: pizza\n      k8s.io/cluster-autoscaler/node-template/taint/feaster: \"true:NoSchedule\"\n```\n\n----------------------------------------\n\nTITLE: Deleting an EKS Cluster Using a Config File\nDESCRIPTION: Command to delete an EKS cluster that was created using a YAML configuration file. Without the --wait flag, this only initiates deletion without waiting for completion.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/creating-and-managing-clusters.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\neksctl delete cluster -f cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Checking EKS Anywhere Version in Shell\nDESCRIPTION: Demonstrates how to verify the installation and check the version of EKS Anywhere using the eksctl command-line interface. This command displays the current version of the eksctl-anywhere binary that needs to be installed on your PATH.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/eksctl-anywhere.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\neksctl anywhere version\nv0.5.0\n```\n\n----------------------------------------\n\nTITLE: Refactoring CloudFormation Resource Methods in Go\nDESCRIPTION: This snippet shows the refactoring of CloudFormation resource methods to new field names to avoid conflicts with resource properties. Methods like DependsOn and Metadata are renamed to AWSCloudFormationDependsOn and AWSCloudFormationMetadata respectively.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/goformation/CHANGELOG.md#2025-04-21_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nresource.DependsOn() -> resource.AWSCloudFormationDependsOn\nresource.SetDependsOn() -> resource.AWSCloudFormationDependsOn\nresource.Metadata() -> resource.AWSCloudFormationMetadata\nresource.SetMetadata() -> resource.AWSCloudFormationMetadata\nresource.CreationPolicy() -> resource.AWSCloudFormationCreationPolicy\nresource.SetCreationPolicy() -> resource.AWSCloudFormationCreationPolicy\nresource.UpdatePolicy() -> resource.AWSCloudFormationUpdatePolicy\nresource.SetUpdatePolicy() -> resource.AWSCloudFormationUpdatePolicy\nresource.DeletionPolicy() -> resource.AWSCloudFormationDeletionPolicy\nresource.SetDeletionPolicy() -> resource.AWSCloudFormationDeletionPolicy\n```\n\n----------------------------------------\n\nTITLE: Release Notes Documentation in Markdown\nDESCRIPTION: Markdown formatted release notes detailing features, improvements, and fixes for eksctl v0.15.0. Includes references to pull request numbers and issue fixes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.15.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.15.0\n\n\n## Features\n\n- Add support for KMS encryption provider (#1897)\n- Add support for China regions (#1860)\n- Add region Beijing (cn-north-1) (#1741)\n- Add region Ningxia (#1720)\n- Support addons for China regions, refactor setting container image for addons (#1867)\n- Add support for Kubernetes 1.15 (#1917 #1916)\n- Add support for Bottlerocket NodeGroups (#1918 #1919)\n\n\n## Improvements\n\n- Remove integration tests timeout (#1857)\n- Store artifacts created during release and rc jobs in circleci (#1864)\n\n## Fixes\n- Fix null pointer dereference in cluster access validation (#1855)\n- [IRSA] Set default audience based on AWS partition (#1877)\n- Fix #1871, add partition check(aws-cn,aws) for OpenIDConnectProviderArn (#1872)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Cluster Flag Usage in eksctl\nDESCRIPTION: This example shows how to specify a cluster when working with non-cluster resources in eksctl, using the --cluster flag.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/guidelines/design-conventions.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\neksctl create nodegroup --cluster clus1 ng-1\n```\n\n----------------------------------------\n\nTITLE: CLI Commands for Instance Selector Usage\nDESCRIPTION: Example shell commands demonstrating the use of instance selector flags with eksctl create cluster and nodegroup commands.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster --name development --managed --instance-selector-vcpus=2 --instance-selector-memory=4\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create nodegroup --cluster development --managed --instance-selector-vcpus=1 --instance-selector-memory=2\n```\n\n----------------------------------------\n\nTITLE: Configuring NodeGroup with Labels and Taints\nDESCRIPTION: YAML configuration for a nodegroup with custom labels and taints. These properties help control pod scheduling but require additional configuration to work with auto scaling from zero.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/autoscaling.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1-public\n    ...\n    labels:\n      my-cool-label: pizza\n    taints:\n      key: feaster\n      value: \"true\"\n      effect: NoSchedule\n```\n\n----------------------------------------\n\nTITLE: Defining Cluster Upgrade Version in YAML Config File\nDESCRIPTION: YAML configuration file defining cluster metadata including the target upgrade version (1.16) for an EKS cluster in eu-north-1 region.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/cluster-upgrade.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ncat cluster1.yaml\n---\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: cluster-1\n  region: eu-north-1\n  version: \"1.16\"\n```\n\n----------------------------------------\n\nTITLE: Getting Nodegroups in eksctl\nDESCRIPTION: Command to retrieve the list of nodegroups in a cluster. This is used to identify the name of the old nodegroup before upgrading.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\neksctl get nodegroups --cluster=<clusterName> --region=<region>\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes for EksCtl 0.38.0\nDESCRIPTION: Structured changelog documenting new features, improvements, bug fixes, and acknowledgments for EksCtl version 0.38.0. Includes major updates like Flux v2 support, OIDC integration, and various nodegroup management enhancements.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.38.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.38.0\n\n## Features\n\n- Support sourceSecurityGroupIds for unmanaged nodegroups (#3254)\n- Add RoleOnly option for iamserviceaccounts (#3122)\n- Flux v2 support (#3066)\n- Add support for well known policies with IRSA (#3045)\n- OIDC support (#3265)\n- Add support for kubernetes 1.19 (#3285)\n\n## Improvements\n\n- Add option to pass kubeconfig path to Flux 2 installer (#3256)\n- Always enable log timestamps (#3251)\n- Add deprecation notice to enable repo command (#3206)\n- Detect and log unsupported region error for fully-private clusters (#3186)\n- Ignore ResourceNotFoundException error during cluster deletion (#3210)\n- Set/Unset/Get labels on unowned nodegroups (#3168)\n- Add x-kubernetes-group-version-kind to Schema (#3169)\n- Don't install nvidia for inf1 instances, reenable inf1 integration tests (#3162)\n\n## Bug Fixes\n\n- Support secondary CIDR blocks for VPCs (#3232)\n- Fix creating private cluster in some regions (#3228)\n- Fix suspend ASG processes for nodegroups (#3218)\n- Support position name in get iamserviceaccount (#3205)\n- Support parsing YAML Cloudformation templates (#3170)\n- Refactor iamserviceaccounts  (#3135)\n- Do not error for empty get nodegroups if output is yaml or json (#3178)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n @Legion2, @dbluxo and @tkms0106\n```\n\n----------------------------------------\n\nTITLE: Changelog entries in Markdown\nDESCRIPTION: Markdown formatted changelog entries documenting new features, improvements and acknowledgments for eksctl version 0.68.0. Includes references to pull request numbers.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.68.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.68.0\n\n## Features\n\n- Add support for EC2 detailed monitoring in nodeGroup (#4231)\n\n## Improvements\n\n- Gracefully delete vpc-cni during cluster deletion (#4244)\n- Drain nodegroups during cluster deletion (#4205)\n- Remove support for 1.16 (#3944)\n- Fix typo in warning message for existing service accounts. (#4233)\n- Update documentation for EKS Connector (#4232)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n  @igorakkerman, and @mmasaki\n```\n\n----------------------------------------\n\nTITLE: Creating a Feature Branch in Git for eksctl Development\nDESCRIPTION: This command creates a new git branch from main to work on a feature. This is the first step in the eksctl contribution workflow after setting up your environment.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b <feature-name>\n```\n\n----------------------------------------\n\nTITLE: Proposed Flux Configuration with gitProvider Only\nDESCRIPTION: The proposal maintains only the gitProvider field while removing all other specific configuration options.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-008-flux2.md#2025-04-21_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n  gitops:\n    flux:\n      gitProvider: github|gitlab|git\n```\n\n----------------------------------------\n\nTITLE: Installing NVIDIA Device Plugin (pre-v0.15.0)\nDESCRIPTION: Kubernetes command to manually install the NVIDIA device plugin for versions before 0.15.0. Replace <VERSION> with the desired plugin version.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/gpu-support.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nkubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/<VERSION>/nvidia-device-plugin.yml\n```\n\n----------------------------------------\n\nTITLE: Getting Fargate Profiles in JSON Format\nDESCRIPTION: Command to display existing Fargate profiles in a cluster in JSON format, showing the same information as the YAML output but in JSON structure.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/fargate-support.md#2025-04-21_snippet_11\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl get fargateprofile --cluster fargate-example-cluster -o json\n[\n    {\n        \"name\": \"fp-9bfc77ad\",\n        \"podExecutionRoleARN\": \"arn:aws:iam::123456789012:role/eksctl-fargate-example-cluster-ServiceRole-1T5F78E5FSH79\",\n        \"selectors\": [\n            {\n                \"namespace\": \"dev\"\n            }\n        ],\n        \"subnets\": [\n            \"subnet-00adf1d8c99f83381\",\n            \"subnet-04affb163ffab17d4\",\n            \"subnet-035b34379d5ef5473\"\n        ]\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Updating Node Labels with kubectl\nDESCRIPTION: This command uses kubectl to update labels on nodes belonging to a specific nodegroup. It demonstrates how to modify nodegroup properties post-creation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroups.md#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nkubectl label nodes -l alpha.eksctl.io/nodegroup-name=ng-1 new-label=foo\n```\n\n----------------------------------------\n\nTITLE: Changelog Documentation - Markdown\nDESCRIPTION: Structured changelog documenting new features, improvements, bug fixes, and acknowledgments for eksctl version 0.35.0. Includes major changes like managed nodegroup support, cluster upgrades, and system improvements.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.35.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.35.0\n\n## Features\n\n- get/delete/drain support for non-eksctl created managed nodegroups (#2911)\n- Support upgrading non eksctl clusters (#2815)\n\n## Improvements\n\n- Have kubelet use systemd cgroup driver on al2 and ubuntu (#2962)\n- Update maxpods (#2957)\n- Update aws-node (#2958)\n- Add AutoscalingGroupName to nodegroupsummary (#2820)\n- add sub condition to vpc-cni addon policy (#2948)\n- Deprecate v1.14 (#2941)\n- Bump `eks/pause` infra container image (#2932)\n- Bump k8s dependencies (#2907)\n- Update ALB policy, now AWS load balancer controller policy (#2914)\n- Deprecate static AMI resolver (#2661)\n- Update aws-node and make tests less brittle (#2920)\n\n## Bug Fixes\n\n- encrypt bottlerocket os volume (#2952)\n- Don't run bootstrap scripts twice and before preBootstrap (#2924)\n- fix panic in VPC loading (#2933)\n- treat remote VPC as source of truth (#2928)\n- Do not set a default value for nodeGroup.ami (#2927)\n- Only use aws-node service account on cluster creation (#2917)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n@hacker65536,  @neha-viswanathan and @reegnz\n```\n\n----------------------------------------\n\nTITLE: Executing kubectl version command with JSON output in eksctl\nDESCRIPTION: This update modifies the kubectl version command to use the --output=json flag, ensuring structured output for better parsing and handling.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.158.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- Call `kubectl version` command with `--output=json` flag (#7032)\n```\n\n----------------------------------------\n\nTITLE: Example YAML with Team Configuration\nDESCRIPTION: An example of a problematic configuration with team flags that would not work correctly with the map structure due to how Flux implements StringArrayVar flags.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-008-flux2.md#2025-04-21_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n...\n     flags:\n       team: one\n       team: two\n```\n\n----------------------------------------\n\nTITLE: Creating a nodegroup with instance selector using CLI options\nDESCRIPTION: Example of using the 'eksctl create nodegroup' command with CLI parameters for instance selection criteria in dry-run mode. This generates a ClusterConfig YAML that can be used for actual nodegroup creation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-007-instance-selector-dry-run.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\neksctl create nodegroup --cluster=dev --managed --spot --instance-selector-vcpus=2 --instance-selector-memory=4 --dry-run\n```\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: dev\n  region: us-west-2\n\nmanagedNodeGroups:\n- name: <name>\n  spot: true\n  instanceTypes: [\"c3.large\", \"c4.large\", \"c5.large\", \"c5d.large\", \"c5n.large\", \"c5a.large\"]\n  instanceSelector:\n    vCPUs: 2\n    memory: 4\n```\n\n----------------------------------------\n\nTITLE: Running eksctl from Docker Container\nDESCRIPTION: Command to run eksctl from a Docker container image hosted on AWS ECR public repository. This example shows how to check the eksctl version.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/installation.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm -it public.ecr.aws/eksctl/eksctl version\n```\n\n----------------------------------------\n\nTITLE: Defining IamLimitedAccess Custom Policy in JSON\nDESCRIPTION: This custom policy grants limited access to IAM resources specifically for eksctl. It allows actions on IAM roles, instance profiles, policies, and OIDC providers with specific resource constraints.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/minimum-iam-policies.md#2025-04-21_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:CreateInstanceProfile\",\n                \"iam:DeleteInstanceProfile\",\n                \"iam:GetInstanceProfile\",\n                \"iam:RemoveRoleFromInstanceProfile\",\n                \"iam:GetRole\",\n                \"iam:CreateRole\",\n                \"iam:DeleteRole\",\n                \"iam:AttachRolePolicy\",\n                \"iam:PutRolePolicy\",\n                \"iam:UpdateAssumeRolePolicy\",\n                \"iam:AddRoleToInstanceProfile\",\n                \"iam:ListInstanceProfilesForRole\",\n                \"iam:PassRole\",\n                \"iam:DetachRolePolicy\",\n                \"iam:DeleteRolePolicy\",\n                \"iam:GetRolePolicy\",\n                \"iam:GetOpenIDConnectProvider\",\n                \"iam:CreateOpenIDConnectProvider\",\n                \"iam:DeleteOpenIDConnectProvider\",\n                \"iam:TagOpenIDConnectProvider\",\n                \"iam:ListAttachedRolePolicies\",\n                \"iam:TagRole\",\n                \"iam:UntagRole\",\n                \"iam:GetPolicy\",\n                \"iam:CreatePolicy\",\n                \"iam:DeletePolicy\",\n                \"iam:ListPolicyVersions\"\n            ],\n            \"Resource\": [\n                \"arn:aws:iam::<account_id>:instance-profile/eksctl-*\",\n                \"arn:aws:iam::<account_id>:role/eksctl-*\",\n                \"arn:aws:iam::<account_id>:policy/eksctl-*\",\n                \"arn:aws:iam::<account_id>:oidc-provider/*\",\n                \"arn:aws:iam::<account_id>:role/aws-service-role/eks-nodegroup.amazonaws.com/AWSServiceRoleForAmazonEKSNodegroup\",\n                \"arn:aws:iam::<account_id>:role/eksctl-managed-*\"\n            ]\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:GetRole\",\n                \"iam:GetUser\"\n            ],\n            \"Resource\": [\n                \"arn:aws:iam::<account_id>:role/*\",\n                \"arn:aws:iam::<account_id>:user/*\"\n            ]\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"iam:CreateServiceLinkedRole\"\n            ],\n            \"Resource\": \"*\",\n            \"Condition\": {\n                \"StringEquals\": {\n                    \"iam:AWSServiceName\": [\n                        \"eks.amazonaws.com\",\n                        \"eks-nodegroup.amazonaws.com\",\n                        \"eks-fargate.amazonaws.com\"\n                    ]\n                }\n            }\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Extending VPC with New CIDR Range in AWS\nDESCRIPTION: Example of adding a new CIDR range to an existing VPC to support additional subnets. This diff shows adding a 192.169.0.0/19 CIDR block alongside the existing 192.168.0.0/19 range.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-with-custom-subnet.md#2025-04-21_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n192.168.0.0/19 -> existing CIDR\n+ 192.169.0.0/19 -> new CIDR\n```\n\n----------------------------------------\n\nTITLE: Documenting Release Notes for eksctl v0.120.0 in Markdown\nDESCRIPTION: This markdown snippet outlines the release notes for eksctl version 0.120.0. It includes a new feature for EKS 1.24 support and a maintenance update for the build container base image.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.120.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.120.0\n\n##  Features\n\n- Add support for EKS 1.24 (#5807)\n\n##  Maintenance\n\n- Update base image in the build container (#5907)\n```\n\n----------------------------------------\n\nTITLE: Correcting Chocolatey installation command for eksctl\nDESCRIPTION: A documentation update is made to fix the Chocolatey install command, ensuring users can correctly install eksctl using this package manager.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.158.0.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- Corrected Chocolatey Install Command (#7063)\n```\n\n----------------------------------------\n\nTITLE: Pushing Changes to Remote Repository for eksctl PR Submission\nDESCRIPTION: This command pushes your feature branch to your remote fork, preparing it for pull request submission to the main eksctl repository.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ngit push <remote-name> <feature-name>\n```\n\n----------------------------------------\n\nTITLE: Current Flux API Configuration in eksctl\nDESCRIPTION: The existing configuration structure for Flux integration in eksctl that will be modified according to the proposal.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-008-flux2.md#2025-04-21_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n  gitops:\n    flux:\n      gitProvider: github\n-     owner: dr-who\n-     repository: my-cluster-gitops\n-     personal: true\n-     path: \"clusters/cluster-27\"\n-     kubeconfig: /foo/bar\n-     branch: main\n-     namespace: \"flux-system\"\n```\n\n----------------------------------------\n\nTITLE: Verifying eksctl Checksum on Windows with PowerShell\nDESCRIPTION: PowerShell command that automates the verification of the eksctl executable checksum by comparing the calculated hash with the expected value from the checksum file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/installation.md#2025-04-21_snippet_2\n\nLANGUAGE: pwsh\nCODE:\n```\n# Replace amd64 with armv6, armv7 or arm64\n (Get-FileHash -Algorithm SHA256 .\\eksctl_Windows_amd64.zip).Hash -eq ((Get-Content .\\eksctl_checksums.txt) -match 'eksctl_Windows_amd64.zip' -split ' ')[0]\n```\n\n----------------------------------------\n\nTITLE: Verifying eksctl Checksum on Windows with Command Prompt\nDESCRIPTION: Command to verify the checksum of the downloaded eksctl executable on Windows using CertUtil from Command Prompt.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/installation.md#2025-04-21_snippet_1\n\nLANGUAGE: cmd\nCODE:\n```\nREM Replace amd64 with armv6, armv7 or arm64\nCertUtil -hashfile eksctl_Windows_amd64.zip SHA256\n```\n\n----------------------------------------\n\nTITLE: Creating a Cluster from Generated ClusterConfig File\nDESCRIPTION: Shows how to create a cluster using the generated ClusterConfig YAML file from a previous dry-run operation.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/dry-run.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n$ eksctl create cluster -f generated-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes for eksctl v0.156.0\nDESCRIPTION: Release notes organized into three sections: Features, Bug Fixes, and Maintenance. Documents the addition of adopters feature, subnet cleanup improvements, and dependency updates.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.156.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.156.0\n\n##  Features\n\n- Adopters for eksctl (#7027)\n\n##  Bug Fixes\n\n- Cleanup subnets with invalid AZs before importing VPC from CFN stack (#6935)\n\n##  Maintenance\n\n- Bump dependencies (#7025)\n```\n\n----------------------------------------\n\nTITLE: Escaping AWS_PROFILE Variable Reference in Markdown\nDESCRIPTION: This code snippet shows how to properly escape the AWS_PROFILE environment variable reference in markdown using backticks with backslash escaping.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.119.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n\\`AWS\\_PROFILE\\`\n```\n\n----------------------------------------\n\nTITLE: Previewing eksctl Documentation Locally with MkDocs\nDESCRIPTION: This command demonstrates how to serve and preview the eksctl documentation locally using the 'make serve-pages' command. The output shows the MkDocs server starting and displaying information about the build process.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/README.md#2025-04-21_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n $ make serve-pages\nINFO    -  Building documentation...\nINFO    -  Cleaning site directory\nINFO    -  The following pages exist in the docs directory, but are not included in the \"nav\" configuration:\n  - index.md\n[I 191218 10:16:30 server:296] Serving on http://127.0.0.1:8000\n[I 191218 10:16:30 handlers:62] Start watching changes\n[I 191218 10:16:30 handlers:64] Start detecting changes\n[I 191218 10:16:33 handlers:135] Browser Connected: http://127.0.0.1:8000/introduction/\n...\n```\n\n----------------------------------------\n\nTITLE: Creating an EKS Cluster with KMS Encryption Using eksctl CLI\nDESCRIPTION: Shell command to create an EKS cluster using the eksctl CLI and a YAML configuration file that has KMS encryption enabled. This command applies the configuration defined in the kms-cluster.yaml file.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/kms-encryption.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ eksctl create cluster -f kms-cluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Description of Docker-based Caching Approach\nDESCRIPTION: Outlines the Docker-based caching approach that replaces CircleCI's native caching mechanism, showing how dependencies are managed through Docker images.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-006-build-improvements.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Present approach:\n- restore cache from previous build\n- mount cache as docker volume\n- run tests and build new binary\n\n# Proposed improvement:\n- pull docker image\n- run tests and build new binary\n```\n\n----------------------------------------\n\nTITLE: Verifying Add-on Pod Status in EKS Cluster\nDESCRIPTION: Example output from kubectl command showing the expected status of add-on pods after successful updates. All pods should be in Running state with READY status of 1/1.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/addon-upgrade.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nNAME                       READY   STATUS    RESTARTS   AGE\naws-node-g5ghn             1/1     Running   0          2m\naws-node-zfc9s             1/1     Running   0          2m\ncoredns-7bcbfc4774-g6gg8   1/1     Running   0          1m\ncoredns-7bcbfc4774-hftng   1/1     Running   0          1m\nkube-proxy-djkp7           1/1     Running   0          3m\nkube-proxy-mpdsp           1/1     Running   0          3m\n```\n\n----------------------------------------\n\nTITLE: Documenting eksctl 0.49.0 Release Notes in Markdown\nDESCRIPTION: Markdown formatted release notes documenting the changes, improvements and fixes in eksctl version 0.49.0. Includes updates to managed nodegroup documentation, regex version matching for addons, neuron device plugin image source changes, and nodegroup taint parsing fixes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.49.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.49.0\n\n- Update managed nodegroup documentation (#3653)\n\n## Features\n\n- Support regex version matching for addons (#3646)\n\n## Improvements\n\n- Use public repo for neuron device plugin image (#3661)\n\n## Bug Fixes\n\n- Parse ng taints correctly (#3659)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n  @aws-vrnatham, and @lboix\n```\n\n----------------------------------------\n\nTITLE: Code Block Elements in Markdown\nDESCRIPTION: Code formatting instructions for submitting issues and documentation, demonstrating verbosity flag usage and command examples.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n-v=4\n```\n\n----------------------------------------\n\nTITLE: Comparing Makefile Complexity Before and After Changes\nDESCRIPTION: Shows the difference in Makefile complexity before and after the proposed build improvements, highlighting the simplified approach.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-006-build-improvements.md#2025-04-21_snippet_1\n\nLANGUAGE: makefile\nCODE:\n```\n# Before: Complex Makefile configuration\nMakefile#L188-L204\n\n# After: Simplified test target\nMakefile#L68-L73\n```\n\n----------------------------------------\n\nTITLE: Environment Variable Bug Fix in eksctl\nDESCRIPTION: References a bug fix for AWS_REGION and AWS_DEFAULT_REGION environment variables support in eksctl commands.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.149.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nAWS\\_REGION\\` and \\`AWS\\_DEFAULT\\_REGION\n```\n\n----------------------------------------\n\nTITLE: Removing Pod Identity Associations Configuration\nDESCRIPTION: YAML configuration showing how to explicitly remove all pod identity associations from an addon.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/pod-identity-associations.md#2025-04-21_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\naddons:\n- name: vpc-cni\n  # omitting the `podIdentityAssociations` field from the config file,\n  # instead of explicitly setting it to [], will result in a validation error\n  podIdentityAssociations: []\n```\n\n----------------------------------------\n\nTITLE: Markdown Release Notes\nDESCRIPTION: Structured release notes documenting improvements, bug fixes and acknowledgments for eksctl version 0.64.0\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.64.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.64.0\n\n## Improvements\n\n- Fail early when instance selector returns too many instances (#4139)\n- Bump vpc-resource-controller/webhook dep to v0.2.6 (#4104)\n\n## Bug Fixes\n\n- Do not create nodegroup if --fargate is set and --managed is not provided (#4135)\n- Fix creating Windows nodegroups in fully-private clusters (#4128)\n- Add preBootstrapCommands to userdata when using customAMI (#4065)\n- Fix deprecation warning (#4148)\n\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n @EHJ-52n, @abhipth, @brsolomon-deloitte, and @kishoregv\n```\n\n----------------------------------------\n\nTITLE: Project License Reference\nDESCRIPTION: Reference to eksctl's Apache 2.0 license in markdown format.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\neksctl is [Apache 2.0 licensed](LICENSE)\n```\n\n----------------------------------------\n\nTITLE: Importing CloudFormation Resources in Go (Old vs New)\nDESCRIPTION: This snippet demonstrates the changes in importing CloudFormation resources in Go code between versions 2 and 3 of goformation. The resources are now grouped by AWS service name.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/pkg/goformation/CHANGELOG.md#2025-04-21_snippet_1\n\nLANGUAGE: go\nCODE:\n```\n// Old usage:\nimport \"github.com/awslabs/goformation/v2/cloudformation/resources\"\n\n... snip ...\n\ntopic := &resources.AWSSNSTopic{}\n\n// New usage:\nimport \"github.com/awslabs/goformation/v4/cloudformation/sns\"\n\n...snip...\n\ntopic := &sns.Topic{}\n```\n\n----------------------------------------\n\nTITLE: Kubectl Logs Authorization Error Example\nDESCRIPTION: Error message shown when kubectl logs command fails due to authorization issues, typically related to private subnet deployments without proper DNS hostname configuration.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/troubleshooting.md#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nError attaching, falling back to logs: unable to upgrade connection: Authorization error (user=kube-apiserver-kubelet-client, verb=create, resource=nodes, subresource=proxy)\n```\n\n----------------------------------------\n\nTITLE: HTML Table Element for Schema Display\nDESCRIPTION: Empty HTML table with ID 'config' that will be populated with the schema information, likely by the JavaScript module referenced above.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/schema.md#2025-04-21_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n<table id=\"config\"></table>\n```\n\n----------------------------------------\n\nTITLE: Formatting Release Notes in Markdown\nDESCRIPTION: Markdown formatted changelog containing release information for EksCtl version 0.58.0, including features, improvements, and acknowledgments.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.58.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.58.0\n\n## Features\n- Add support for configuring extra CIDRs for Control Plane SG (#3953)\n- Add support for kubernetes 1.21 (#3937)\n\n## Improvements\n\n- Make managed nodegroups the default (#3897)\n\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n     @MrBones757\n```\n\n----------------------------------------\n\nTITLE: Project Name Reference\nDESCRIPTION: Inline code formatting for the project name in markdown.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/CONTRIBUTING.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n`eksctl`\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom AMIs in EKS Cluster YAML Configuration\nDESCRIPTION: YAML configuration example demonstrating how to specify AMI settings for both unmanaged and managed node groups in an EKS cluster, including custom AMI IDs and bootstrap commands.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/custom-ami-support.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nnodeGroups:\n  - name: ng1\n    instanceType: g5.xlarge\n    amiFamily: AmazonLinux2\n    ami: auto\n  - name: ng2\n    instanceType: m5.large\n    amiFamily: AmazonLinux2\n    ami: ami-custom1234\nmanagedNodeGroups:\n  - name: m-ng-2\n    amiFamily: AmazonLinux2\n    ami: ami-custom1234\n    instanceType: m5.large\n    overrideBootstrapCommand: |\n      #!/bin/bash\n      /etc/eks/bootstrap.sh <cluster-name>\n```\n\n----------------------------------------\n\nTITLE: Release Notes Formatting in Markdown\nDESCRIPTION: Structured release notes documenting version 0.40.0 changes including features, improvements, bug fixes and acknowledgments for the eksctl tool.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.40.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.40.0\n\n## Features\n- Add EFA support (#2688)\n- Add support for Asia Pacific (Osaka) region (#3347)\n- Add disable-eviction flag for nodegroup drain and delete (#3330)\n- Allow referring to subnets by ID in nodegroups (#3331)\n- Create nodegroups/managed-nodegroups on unowned clusters (#3388)\n\n\n## Improvements\n- Update back to upstream kris-nova/logger (#3359)\n- Update aws-node to v1.7.9 (#3353)\n- Create the FargatePodExecutionRole resource only when podExecutionRoleARN is unspecified (#3346)\n- Improve error when nodegroup is missing privateNetworking (#3342)\n- Also check managed groups for plugin requirements (#3337)\n- Ignore fields in JSON schema that are explicitly hidden\n- Log suggestion to delete IRSA when create stack fails (#3332)\n- Add sample template for new nodegroup CFN format (#3294)\n\n\n## Bug Fixes\n- Prevent setting internal NodeGroup fields via ClusterConfig (#3339)\n- Fix 3393: fully-private clusters are not supported in region \"\" (#3394)\n- Set systemd cgroupdriver when HasMixedInstances (fix 3391) (#3398)\n\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n    @saada\n```\n\n----------------------------------------\n\nTITLE: Release Notes in Markdown\nDESCRIPTION: Markdown formatted changelog detailing bug fixes, maintenance updates, and documentation changes for eksctl version 0.135.0. Includes acknowledgments to contributors.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.135.0.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release v0.135.0\n\n##  Bug Fixes\n\n- [Upgrade nodegroup via EKS API] Make AMI release version customisable (#6340)\n- Add m7g and r7g as ARM instance types (#6436)\n- Handle deprecated AMIs when scaling self-managed nodegroups (#6401)\n\n##  Maintenance\n\n- Fix typo in SharedNodeSecurityGroup validation error message (#6431)\n\n##  Documentation\n\n- Updated cloudwatch log descriptions (#6346)\n- Update addon example with ebs addon (#6438)\n\n## Acknowledgments\nWeaveworks would like to sincerely thank:\n@Jennas-Lee, @tomr-jet, @tucktuck9 and @rothgar\n```\n\n----------------------------------------\n\nTITLE: Documenting Bug Fixes for eksctl Release 0.1.37\nDESCRIPTION: This markdown snippet lists the bug fixes included in eksctl release 0.1.37. It addresses issues with listing clusters across regions and integration test failures.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/release_notes/0.1.37.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Release 0.1.37\n\n## Bug fixes\n- List clusters in all regions despite regional errors (#908)\n- Fix an issue with integration tests (#901)\n```\n\n----------------------------------------\n\nTITLE: Comparing CircleCI Config Before and After Simplification\nDESCRIPTION: Compares the complexity of CircleCI configuration before and after the proposed changes, showing how the configuration has been significantly simplified.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-006-build-improvements.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Before: More complex configuration\n.circleci/config.yml#L3-L38\n\n# After: Simplified configuration\n.circleci/config.yml#L3-L24\n```\n\n----------------------------------------\n\nTITLE: Markdown Table of Contents Comment Directive\nDESCRIPTION: HTML comment directive for generating and updating the table of contents using mdtoc tool. Must be wrapped with specific tags for proper processing.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/docs/proposal-000-template.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- toc --> and <!-- /toc -->\n```\n\n----------------------------------------\n\nTITLE: Bootstrap Override Command for Nodegroups without Internet Access\nDESCRIPTION: Bootstrap override command for nodegroups that lack outbound internet access. This configuration includes API server endpoint and cluster CA certificate parameters required for private clusters.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/announcements/nodegroup-override-announcement.md#2025-04-21_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n    overrideBootstrapCommand: |\n      #!/bin/bash\n\n      source /var/lib/cloud/scripts/eksctl/bootstrap.helper.sh\n\n      # Note \"--node-labels=${NODE_LABELS}\" needs the above helper sourced to work, otherwise will have to be defined manually.\n      /etc/eks/bootstrap.sh ${CLUSTER_NAME} --container-runtime containerd --kubelet-extra-args \"--node-labels=${NODE_LABELS}\" \\\n        --apiserver-endpoint ${API_SERVER_URL} --b64-cluster-ca ${B64_CLUSTER_CA}\n```\n\n----------------------------------------\n\nTITLE: Adding Organization Logo HTML Element Example in eksctl Documentation\nDESCRIPTION: Example HTML code showing how to add a new organization logo as a list item in the copyright.html file. The example demonstrates adding 'Acme Corp' with its logo image as a glide slide.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/adopters.md#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<li class=\"glide__slide\"><img src=\"/assets/adopters/acme-logo.png\" alt=\"Acme Corp\"></li>\n```\n\n----------------------------------------\n\nTITLE: Updating coredns Add-on in eksctl\nDESCRIPTION: Command to update the coredns add-on in an EKS cluster. This runs in plan mode by default and requires '--approve' to apply changes.\nSOURCE: https://github.com/eksctl-io/eksctl/blob/main/userdocs/src/usage/nodegroup-unmanaged.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\neksctl utils update-coredns --cluster=<clusterName>\n```"
  }
]