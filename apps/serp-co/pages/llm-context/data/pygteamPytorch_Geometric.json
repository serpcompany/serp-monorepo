[
  {
    "owner": "pyg-team",
    "repo": "pytorch_geometric",
    "content": "TITLE: Training a GCN on Cora Dataset with PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to implement a Graph Convolutional Network (GCN) for node classification on the Cora citation dataset. It defines a simple two-layer GCN model that processes node features and graph connectivity information.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.nn import GCNConv\nfrom torch_geometric.datasets import Planetoid\n\ndataset = Planetoid(root='.', name='Cora')\n\nclass GCN(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, out_channels)\n\n    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n        # x: Node feature matrix of shape [num_nodes, in_channels]\n        # edge_index: Graph connectivity matrix of shape [2, num_edges]\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x\n\nmodel = GCN(dataset.num_features, 16, dataset.num_classes)\n```\n\n----------------------------------------\n\nTITLE: Defining GPS Model Architecture (Python)\nDESCRIPTION: This class defines the architecture of the Graph Positional and Structural (GPS) model. It includes node and edge embeddings, multiple GPS convolution layers, and a final MLP for prediction.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass GPS(torch.nn.Module):\n    def __init__(self, channels: int, pe_dim: int, num_layers: int,\n                attn_type: str, attn_kwargs: Dict[str, Any]):\n        super().__init__()\n\n        self.node_emb = Embedding(28, channels - pe_dim)\n        self.pe_lin = Linear(20, pe_dim)\n        self.pe_norm = BatchNorm1d(20)\n        self.edge_emb = Embedding(4, channels)\n\n        self.convs = ModuleList()\n        for _ in range(num_layers):\n            nn = Sequential(\n                Linear(channels, channels),\n                ReLU(),\n                Linear(channels, channels),\n            )\n            conv = GPSConv(channels, GINEConv(nn), heads=4,\n                        attn_type=attn_type, attn_kwargs=attn_kwargs)\n            self.convs.append(conv)\n\n        self.mlp = Sequential(\n            Linear(channels, channels // 2),\n            ReLU(),\n            Linear(channels // 2, channels // 4),\n            ReLU(),\n            Linear(channels // 4, 1),\n        )\n        self.redraw_projection = RedrawProjection(\n            self.convs,\n            redraw_interval=1000 if attn_type == 'performer' else None)\n\n    def forward(self, x, pe, edge_index, edge_attr, batch):\n        x_pe = self.pe_norm(pe)\n```\n\n----------------------------------------\n\nTITLE: Implementing GCN Layer with PyTorch Geometric's MessagePassing API\nDESCRIPTION: A complete implementation of the Graph Convolutional Network (GCN) layer using PyTorch Geometric's MessagePassing base class. The implementation follows steps including adding self-loops to the adjacency matrix, linearly transforming node features, computing normalization coefficients, normalizing and aggregating node features, and applying a final bias vector.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_gnn.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch.nn import Linear, Parameter\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.utils import add_self_loops, degree\n\nclass GCNConv(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n        self.lin = Linear(in_channels, out_channels, bias=False)\n        self.bias = Parameter(torch.empty(out_channels))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        self.lin.reset_parameters()\n        self.bias.data.zero_()\n\n    def forward(self, x, edge_index):\n        # x has shape [N, in_channels]\n        # edge_index has shape [2, E]\n\n        # Step 1: Add self-loops to the adjacency matrix.\n        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n\n        # Step 2: Linearly transform node feature matrix.\n        x = self.lin(x)\n\n        # Step 3: Compute normalization.\n        row, col = edge_index\n        deg = degree(col, x.size(0), dtype=x.dtype)\n        deg_inv_sqrt = deg.pow(-0.5)\n        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n\n        # Step 4-5: Start propagating messages.\n        out = self.propagate(edge_index, x=x, norm=norm)\n\n        # Step 6: Apply a final bias vector.\n        out = out + self.bias\n\n        return out\n\n    def message(self, x_j, norm):\n        # x_j has shape [E, out_channels]\n\n        # Step 4: Normalize node features.\n        return norm.view(-1, 1) * x_j\n```\n\n----------------------------------------\n\nTITLE: Implementing and Training a GCN on Cora Dataset using PyTorch Geometric\nDESCRIPTION: This comprehensive example demonstrates loading the Cora dataset, implementing a two-layer Graph Convolutional Network (GCN), and training it for node classification. It includes the model definition, training loop, and evaluation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import Planetoid\n\ndataset = Planetoid(root='/tmp/Cora', name='Cora')\n>>> Cora()\n```\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass GCN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = GCNConv(dataset.num_node_features, 16)\n        self.conv2 = GCNConv(16, dataset.num_classes)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n\n        return F.log_softmax(x, dim=1)\n```\n\nLANGUAGE: python\nCODE:\n```\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GCN().to(device)\ndata = dataset[0].to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n\nmodel.train()\nfor epoch in range(200):\n    optimizer.zero_grad()\n    out = model(data)\n    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n```\n\nLANGUAGE: python\nCODE:\n```\nmodel.eval()\npred = model(data).argmax(dim=1)\ncorrect = (pred[data.test_mask] == data.y[data.test_mask]).sum()\nacc = int(correct) / int(data.test_mask.sum())\nprint(f'Accuracy: {acc:.4f}')\n>>> Accuracy: 0.8150\n```\n\n----------------------------------------\n\nTITLE: Training Loop for Heterogeneous GNN in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates a basic training loop for a heterogeneous GNN model. It includes forward pass, loss calculation, and optimization steps.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x_dict, data.edge_index_dict)\n    mask = data['paper'].train_mask\n    loss = F.cross_entropy(out['paper'][mask], data['paper'].y[mask])\n    loss.backward()\n    optimizer.step()\n    return float(loss)\n```\n\n----------------------------------------\n\nTITLE: Implementing Heterogeneous Graph Attention Network in PyTorch Geometric\nDESCRIPTION: This code snippet shows how to implement a heterogeneous graph attention network with learnable skip-connections. It defines a GAT class and then converts it to a heterogeneous model using to_hetero.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.nn import GATConv, Linear, to_hetero\n\nclass GAT(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n        self.lin1 = Linear(-1, hidden_channels)\n        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n        self.lin2 = Linear(-1, out_channels)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index) + self.lin1(x)\n        x = x.relu()\n        x = self.conv2(x, edge_index) + self.lin2(x)\n        return x\n\n\nmodel = GAT(hidden_channels=64, out_channels=dataset.num_classes)\nmodel = to_hetero(model, data.metadata(), aggr='sum')\n```\n\n----------------------------------------\n\nTITLE: Training Loop for GNN with NeighborLoader in PyTorch Geometric\nDESCRIPTION: This code demonstrates a training loop for a Graph Neural Network using NeighborLoader for mini-batch training. It includes forward pass, loss calculation, and backpropagation steps.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/neighbor_loader.rst#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nimport torch.nn.functional as F\n\nfor batch in loader:\n    optimizer.zero_grad()\n    batch = batch.to(device)\n    out = model(batch.x, batch.edge_index)\n\n    # NOTE Only consider predictions and labels of seed nodes:\n    y = batch.y[:batch.batch_size]\n    out = out[:batch.batch_size]\n\n    loss = F.cross_entropy(out, y)\n    loss.backward()\n    optimizer.step()\n```\n\n----------------------------------------\n\nTITLE: Using HeteroConv Wrapper for Custom Heterogeneous GNN in PyTorch Geometric\nDESCRIPTION: This code demonstrates how to use the HeteroConv wrapper to create a custom heterogeneous GNN. It defines different convolution operations for different edge types in the graph.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import OGB_MAG\nfrom torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear\n\n\ndataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected())\ndata = dataset[0]\n\nclass HeteroGNN(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels, num_layers):\n        super().__init__()\n\n        self.convs = torch.nn.ModuleList()\n        for _ in range(num_layers):\n            conv = HeteroConv({\n                ('paper', 'cites', 'paper'): GCNConv(-1, hidden_channels),\n                ('author', 'writes', 'paper'): SAGEConv((-1, -1), hidden_channels),\n                ('paper', 'rev_writes', 'author'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n            }, aggr='sum')\n            self.convs.append(conv)\n\n        self.lin = Linear(hidden_channels, out_channels)\n\n    def forward(self, x_dict, edge_index_dict):\n        for conv in self.convs:\n            x_dict = conv(x_dict, edge_index_dict)\n            x_dict = {key: x.relu() for key, x in x_dict.items()}\n        return self.lin(x_dict['author'])\n\nmodel = HeteroGNN(hidden_channels=64, out_channels=dataset.num_classes,\n                  num_layers=2)\n```\n\n----------------------------------------\n\nTITLE: Initializing NeighborLoader for Heterogeneous Graph Sampling in PyG\nDESCRIPTION: Demonstrates how to initialize and configure a NeighborLoader for sampling from a heterogeneous graph. The code loads the OGB_MAG dataset, applies a transform to make it undirected, and sets up a neighbor sampler with specific batch size and sampling parameters for training on paper nodes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import OGB_MAG\nfrom torch_geometric.loader import NeighborLoader\n\ntransform = T.ToUndirected()  # Add reverse edge types.\ndata = OGB_MAG(root='./data', preprocess='metapath2vec', transform=transform)[0]\n\ntrain_loader = NeighborLoader(\n    data,\n    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n    num_neighbors=[15] * 2,\n    # Use a batch size of 128 for sampling training nodes of type \"paper\":\n    batch_size=128,\n    input_nodes=('paper', data['paper'].train_mask),\n)\n\nbatch = next(iter(train_loader))\n```\n\n----------------------------------------\n\nTITLE: Creating a PyTorch Geometric Data Object for Graph Representation\nDESCRIPTION: This snippet shows how to create a Data object in PyTorch Geometric to represent a graph. It defines the edge_index and node features x, then combines them into a Data object.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_gnn.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.data import Data\n\nedge_index = torch.tensor([[0, 1],\n                           [1, 0],\n                           [1, 2],\n                           [2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n\ndata = Data(x=x, edge_index=edge_index.t().contiguous())\n```\n\n----------------------------------------\n\nTITLE: Creating a Graph with PyTorch Geometric in Python\nDESCRIPTION: Demonstrates how to create a simple unweighted and undirected graph with three nodes and four edges using PyTorch Geometric's Data class, where each node contains a single feature.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.data import Data\n\nedge_index = torch.tensor([[0, 1, 1, 2],\n                           [1, 0, 2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n\ndata = Data(x=x, edge_index=edge_index)\n>>> Data(edge_index=[2, 4], x=[3, 1])\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom EdgeConv Layer in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to create a custom Graph Neural Network layer by implementing the EdgeConv layer from Wang et al. The implementation uses PyG's MessagePassing base class and defines the message computation and aggregation for edge features.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch import Tensor\nfrom torch.nn import Sequential, Linear, ReLU\nfrom torch_geometric.nn import MessagePassing\n\nclass EdgeConv(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr=\"max\")  # \"Max\" aggregation.\n        self.mlp = Sequential(\n            Linear(2 * in_channels, out_channels),\n            ReLU(),\n            Linear(out_channels, out_channels),\n        )\n\n    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n        # x: Node feature matrix of shape [num_nodes, in_channels]\n        # edge_index: Graph connectivity matrix of shape [2, num_edges]\n        return self.propagate(edge_index, x=x)  # shape [num_nodes, out_channels]\n\n    def message(self, x_j: Tensor, x_i: Tensor) -> Tensor:\n        # x_j: Source node features of shape [num_edges, in_channels]\n        # x_i: Target node features of shape [num_edges, in_channels]\n        edge_features = torch.cat([x_i, x_j - x_i], dim=-1)\n        return self.mlp(edge_features)  # shape [num_edges, out_channels]\n```\n\n----------------------------------------\n\nTITLE: Implementing PointNet++ Architecture in PyTorch Geometric\nDESCRIPTION: Defines the complete PointNet++ architecture using the custom PointNetLayer. The network includes two layers of message passing, global max pooling, and a final classifier layer.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/point_cloud.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.nn import global_max_pool\n\n\nclass PointNet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.conv1 = PointNetLayer(3, 32)\n        self.conv2 = PointNetLayer(32, 32)\n        self.classifier = Linear(32, dataset.num_classes)\n\n    def forward(self,\n        pos: Tensor,\n        edge_index: Tensor,\n        batch: Tensor,\n    ) -> Tensor:\n\n        # Perform two-layers of message passing:\n        h = self.conv1(h=pos, pos=pos, edge_index=edge_index)\n        h = h.relu()\n        h = self.conv2(h=h, pos=pos, edge_index=edge_index)\n        h = h.relu()\n\n        # Global Pooling:\n        h = global_max_pool(h, batch)  # [num_examples, hidden_channels]\n\n        # Classifier:\n        return self.classifier(h)\n\n\nmodel = PointNet()\n\nprint(model)\n>>> PointNet(\n...   (conv1): PointNetLayer()\n...   (conv2): PointNetLayer()\n```\n\n----------------------------------------\n\nTITLE: Implementing Distributed Training Loop in PyG\nDESCRIPTION: Defines the training loop for multi-GPU training, including optimization, forward pass, and backpropagation. The DistributedDataParallel wrapper handles gradient synchronization.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_gpu_vanilla.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport torch.nn.functional as F\n\ndef run(rank: int, world_size: int, dataset: Reddit):\n    ...\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(1, 11):\n        model.train()\n        for batch in train_loader:\n            batch = batch.to(rank)\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index)[:batch.batch_size]\n            loss = F.cross_entropy(out, batch.y[:batch.batch_size])\n            loss.backward()\n            optimizer.step()\n```\n\n----------------------------------------\n\nTITLE: Training a Heterogeneous GNN with Mini-Batch Sampling in PyG\nDESCRIPTION: Implements a training function for heterogeneous graph neural networks using mini-batch sampling. The function iterates through batches from a NeighborLoader, processes them on GPU, computes loss on the original mini-batch nodes only, and performs backpropagation and optimization steps.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef train():\n    model.train()\n\n    total_examples = total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        batch = batch.to('cuda:0')\n        batch_size = batch['paper'].batch_size\n        out = model(batch.x_dict, batch.edge_index_dict)\n        loss = F.cross_entropy(out['paper'][:batch_size],\n                               batch['paper'].y[:batch_size])\n        loss.backward()\n        optimizer.step()\n\n        total_examples += batch_size\n        total_loss += float(loss) * batch_size\n\n    return total_loss / total_examples\n```\n\n----------------------------------------\n\nTITLE: Loading and Transforming Geometric Shapes Dataset in PyTorch Geometric\nDESCRIPTION: Loads the GeometricShapes dataset and transforms meshes into point clouds using SamplePoints transformation. It then converts the point cloud into a graph using KNNGraph.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/point_cloud.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import GeometricShapes\n\ndataset = GeometricShapes(root='data/GeometricShapes')\nprint(dataset)\n>>> GeometricShapes(40)\n\ndata = dataset[0]\nprint(data)\n>>> Data(pos=[32, 3], face=[3, 30], y=[1])\n```\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\n\ndataset.transform = T.SamplePoints(num=256)\n\ndata = dataset[0]\nprint(data)\n>>> Data(pos=[256, 3], y=[1])\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.transforms import SamplePoints, KNNGraph\n\ndataset.transform = T.Compose([SamplePoints(num=256), KNNGraph(k=6)])\n\ndata = dataset[0]\nprint(data)\n>>> Data(pos=[256, 3], edge_index=[2, 1536], y=[1])\n```\n\n----------------------------------------\n\nTITLE: Implementing HGT (Heterogeneous Graph Transformer) in PyTorch Geometric\nDESCRIPTION: This snippet shows how to implement a Heterogeneous Graph Transformer (HGT) model using PyTorch Geometric's HGTConv. It defines a custom HGT class with multiple layers of HGTConv.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import OGB_MAG\nfrom torch_geometric.nn import HGTConv, Linear\n\n\ndataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected())\ndata = dataset[0]\n\nclass HGT(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):\n        super().__init__()\n\n        self.lin_dict = torch.nn.ModuleDict()\n        for node_type in data.node_types:\n            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n\n        self.convs = torch.nn.ModuleList()\n        for _ in range(num_layers):\n            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(),\n                           num_heads, group='sum')\n            self.convs.append(conv)\n\n        self.lin = Linear(hidden_channels, out_channels)\n\n    def forward(self, x_dict, edge_index_dict):\n        for node_type, x in x_dict.items():\n            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n\n        for conv in self.convs:\n            x_dict = conv(x_dict, edge_index_dict)\n\n        return self.lin(x_dict['author'])\n\nmodel = HGT(hidden_channels=64, out_channels=dataset.num_classes,\n            num_heads=2, num_layers=2)\n```\n\n----------------------------------------\n\nTITLE: Data Loading and Model Initialization in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to load the GeometricShapes dataset, apply transformations (sampling points and constructing KNN graphs), create data loaders, instantiate the PointNet model, define the Adam optimizer, and set up the CrossEntropyLoss criterion for training. It prepares the data and model for the training loop.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/point_cloud.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.loader import DataLoader\n\ntrain_dataset = GeometricShapes(root='data/GeometricShapes', train=True)\ntrain_dataset.transform = T.Compose([SamplePoints(num=256), KNNGraph(k=6)])\ntest_dataset = GeometricShapes(root='data/GeometricShapes', train=False)\ntest_dataset.transform = T.Compose([SamplePoints(num=256), KNNGraph(k=6)])\n\ntrain_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=10)\n\nmodel = PointNet()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ncriterion = torch.nn.CrossEntropyLoss()\n```\n\n----------------------------------------\n\nTITLE: Implementing GINConv with SparseTensor Support in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to implement the GINConv layer with SparseTensor support in PyTorch Geometric. It uses the message_and_aggregate method for efficient sparse matrix multiplication.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport torch_sparse\n\nclass GINConv(MessagePassing):\n    def __init__(self):\n        super().__init__(aggr=\"add\")\n\n    def forward(self, x, edge_index):\n        out = self.propagate(edge_index, x=x)\n        return MLP((1 + eps) x + out)\n\n    def message(self, x_j):\n        return x_j\n\n    def message_and_aggregate(self, adj_t, x):\n        return torch_sparse.matmul(adj_t, x, reduce=self.aggr)\n```\n\n----------------------------------------\n\nTITLE: GraphMaskExplainer Example for Node Classification in PyTorch Geometric\nDESCRIPTION: This example demonstrates the use of `GraphMaskExplainer` for explaining node classification. `GraphMaskExplainer` aims to identify a subgraph that is critical for the prediction of a specific node.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/README.md#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n\"./graphmask_explainer.py\"\n```\n\n----------------------------------------\n\nTITLE: Implementing GNN with HGAM Trimming in PyTorch Geometric\nDESCRIPTION: Example showing how to implement a GNN model that uses the trim_to_layer function to optimize computation by trimming the adjacency matrix at each layer.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/hgam.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import Reddit\nfrom torch_geometric.loader import NeighborLoader\nfrom torch_geometric.nn import SAGEConv\nfrom torch_geometric.utils import trim_to_layer\n\ndataset = Reddit(path)\nloader = NeighborLoader(data, num_neighbors=[10, 5, 5], ...)\n\nclass GNN(torch.nn.Module):\n    def __init__(self, in_channels: int, out_channels: int, num_layers: int):\n        super().__init__()\n\n        self.convs = ModuleList([SAGEConv(in_channels, 64)])\n        for _ in range(num_layers - 1):\n            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n        self.lin = Linear(hidden_channels, out_channels)\n\n    def forward(\n        self,\n        x: Tensor,\n        edge_index: Tensor,\n        num_sampled_nodes_per_hop: List[int],\n        num_sampled_edges_per_hop: List[int],\n    ) -> Tensor:\n\n        for i, conv in enumerate(self.convs):\n            # Trim edge and node information to the current layer `i`.\n            x, edge_index, _ = trim_to_layer(\n                i, num_sampled_nodes_per_hop, num_sampled_edges_per_hop,\n                x, edge_index)\n\n            x = conv(x, edge_index).relu()\n\n        return self.lin(x)\n```\n\n----------------------------------------\n\nTITLE: Testing Function for PointNet Model in PyTorch Geometric\nDESCRIPTION: This snippet defines the testing function for evaluating the PointNet model. It iterates through the test data loader, performs a forward pass, predicts the class labels using argmax, and calculates the accuracy by comparing the predictions with the ground truth labels. The function disables gradient calculation using `@torch.no_grad()` and returns the overall accuracy on the test dataset.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/point_cloud.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@torch.no_grad()\ndef test():\n    model.eval()\n\n    total_correct = 0\n    for data in test_loader:\n        logits = model(data.pos, data.edge_index, data.batch)\n        pred = logits.argmax(dim=-1)\n        total_correct += int((pred == data.y).sum())\n\n    return total_correct / len(test_loader.dataset)\n```\n\n----------------------------------------\n\nTITLE: Implementing EdgeConv Forward and Message Functions in PyTorch Geometric\nDESCRIPTION: This snippet shows the forward and message functions of the EdgeConv layer. The forward function propagates the input through the graph, while the message function concatenates and transforms node features for each edge.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_gnn.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef forward(self, x, edge_index):\n    # x has shape [N, in_channels]\n    # edge_index has shape [2, E]\n\n    return self.propagate(edge_index, x=x)\n\ndef message(self, x_i, x_j):\n    # x_i has shape [E, in_channels]\n    # x_j has shape [E, in_channels]\n\n    tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n    return self.mlp(tmp)\n```\n\n----------------------------------------\n\nTITLE: Creating a HeteroData Object in PyTorch Geometric\nDESCRIPTION: Demonstrates how to create a HeteroData object to represent a heterogeneous graph with different node and edge types. Node features, edge indices, and edge features are defined for each type.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import HeteroData\n\ndata = HeteroData()\n\ndata['paper'].x = ... # [num_papers, num_features_paper]\ndata['author'].x = ... # [num_authors, num_features_author]\ndata['institution'].x = ... # [num_institutions, num_features_institution]\ndata['field_of_study'].x = ... # [num_field, num_features_field]\n\ndata['paper', 'cites', 'paper'].edge_index = ... # [2, num_edges_cites]\ndata['author', 'writes', 'paper'].edge_index = ... # [2, num_edges_writes]\ndata['author', 'affiliated_with', 'institution'].edge_index = ... # [2, num_edges_affiliated]\ndata['paper', 'has_topic', 'field_of_study'].edge_index = ... # [2, num_edges_topic]\n\ndata['paper', 'cites', 'paper'].edge_attr = ... # [num_edges_cites, num_features_cites]\ndata['author', 'writes', 'paper'].edge_attr = ... # [num_edges_writes, num_features_writes]\ndata['author', 'affiliated_with', 'institution'].edge_attr = ... # [num_edges_affiliated, num_features_affiliated]\ndata['paper', 'has_topic', 'field_of_study'].edge_attr = ... # [num_edges_topic, num_features_topic]\n```\n\n----------------------------------------\n\nTITLE: Creating a GraphSAGE Model for Node Classification in PyTorch Geometric\nDESCRIPTION: This snippet shows how to create a simple two-layer GraphSAGE model for node classification using PyTorch Geometric. It sets up the model architecture and optimizer.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/neighbor_loader.rst#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nfrom torch_geometric.nn import GraphSAGE\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = GraphSAGE(\n    in_channels=32,\n    hidden_channels=64,\n    out_channels=4,\n    num_layers=2\n).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n```\n\n----------------------------------------\n\nTITLE: Importing GAT in PyTorch Geometric\nDESCRIPTION: Example of importing and using the GATConv layer from PyTorch Geometric. GATConv implements the Graph Attention Network model as described by Veličković et al.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nfrom torch_geometric.nn import GATConv\n\n# Usage example (pseudo-code)\nself.conv1 = GATConv(in_channels, hidden_channels)\nself.conv2 = GATConv(hidden_channels, out_channels)\n```\n\n----------------------------------------\n\nTITLE: Implementing PGExplainer for Graph Regression on Homogeneous Graphs\nDESCRIPTION: Example illustrating the use of PGExplainer algorithm for explaining graph regression tasks. The code demonstrates how to train the parametric explainer and then use it to generate explanations that identify the most important edges for prediction.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/explain.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import Data\nfrom torch_geometric.explain import Explainer, PGExplainer\n\ndataset = ...\nloader = DataLoader(dataset, batch_size=1, shuffle=True)\n\nexplainer = Explainer(\n    model=model,\n    algorithm=PGExplainer(epochs=30, lr=0.003),\n    explanation_type='phenomenon',\n    edge_mask_type='object',\n    model_config=dict(\n        mode='regression',\n        task_level='graph',\n        return_type='raw',\n    ),\n    # Include only the top 10 most important edges:\n    threshold_config=dict(threshold_type='topk', value=10),\n)\n\n# PGExplainer needs to be trained separately since it is a parametric\n# explainer i.e it uses a neural network to generate explanations:\nfor epoch in range(30):\n    for batch in loader:\n        loss = explainer.algorithm.train(\n            epoch, model, batch.x, batch.edge_index, target=batch.target)\n\n# Generate the explanation for a particular graph:\nexplanation = explainer(dataset[0].x, dataset[0].edge_index)\nprint(explanation.edge_mask)\n```\n\n----------------------------------------\n\nTITLE: Captum-based Explainer Example for Heterogeneous Link Prediction in PyTorch Geometric\nDESCRIPTION: This example showcases a Captum-based explainer for heterogeneous link prediction. It highlights how to use Captum to explain link predictions in heterogeneous graphs, where different node and edge types exist.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/README.md#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n\"./captum_explainer_hetero_link.py\"\n```\n\n----------------------------------------\n\nTITLE: Implementing EdgeConv Layer with PyTorch Geometric's MessagePassing API\nDESCRIPTION: A partial implementation of the Edge Convolution layer from Wang et al. using PyTorch Geometric's MessagePassing base class. This layer processes graphs or point clouds using max aggregation and a multi-layer perceptron to transform node features.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_gnn.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch.nn import Sequential as Seq, Linear, ReLU\nfrom torch_geometric.nn import MessagePassing\n\nclass EdgeConv(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr='max') #  \"Max\" aggregation.\n        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n                       ReLU(),\n```\n\n----------------------------------------\n\nTITLE: Training Loop for GNN Model Optimization in PyTorch Geometric\nDESCRIPTION: This snippet shows how to implement a training loop for optimizing a Graph Neural Network model using PyTorch's optimization techniques. It includes forward pass computation, loss calculation with cross-entropy, and standard backpropagation for weight updates.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch.nn.functional as F\n\ndata = dataset[0]\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\nfor epoch in range(200):\n    pred = model(data.x, data.edge_index)\n    loss = F.cross_entropy(pred[data.train_mask], data.y[data.train_mask])\n\n    # Backpropagation\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n```\n\n----------------------------------------\n\nTITLE: Implementing Large-Scale Dataset in PyTorch Geometric\nDESCRIPTION: Example implementation of a custom Dataset class for handling larger datasets that don't fit in memory. Shows implementation of len and get methods for loading individual graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_dataset.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os.path as osp\n\nimport torch\nfrom torch_geometric.data import Dataset, download_url\n\n\nclass MyOwnDataset(Dataset):\n    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n        super().__init__(root, transform, pre_transform, pre_filter)\n\n    @property\n    def raw_file_names(self):\n        return ['some_file_1', 'some_file_2', ...]\n\n    @property\n    def processed_file_names(self):\n        return ['data_1.pt', 'data_2.pt', ...]\n\n    def download(self):\n        # Download to `self.raw_dir`.\n        path = download_url(url, self.raw_dir)\n        ...\n\n    def process(self):\n        idx = 0\n        for raw_path in self.raw_paths:\n            # Read data from `raw_path`.\n            data = Data(...)\n\n            if self.pre_filter is not None and not self.pre_filter(data):\n                continue\n\n            if self.pre_transform is not None:\n                data = self.pre_transform(data)\n\n            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n            idx += 1\n\n    def len(self):\n        return len(self.processed_file_names)\n\n    def get(self, idx):\n        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n        return data\n```\n\n----------------------------------------\n\nTITLE: Using GINEConv with Edge Attributes in PyTorch Geometric\nDESCRIPTION: Example of using GINEConv with multi-dimensional edge feature information for message passing in PyTorch Geometric. This demonstrates how to use edge attributes in the convolution.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/gnn_cheatsheet.rst#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nGINEConv(...).forward(x, edge_index, edge_attr)\n```\n\n----------------------------------------\n\nTITLE: Using GraphConv with Edge Weights in PyTorch Geometric\nDESCRIPTION: Example of using GraphConv with edge weight information for message passing in PyTorch Geometric. This shows how to incorporate one-dimensional edge weights.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/gnn_cheatsheet.rst#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nGraphConv(...).forward(x, edge_index, edge_weight)\n```\n\n----------------------------------------\n\nTITLE: Implementing RandomLinkSplit for Link Prediction in PyTorch Geometric\nDESCRIPTION: Demonstrates how to use RandomLinkSplit transformation to divide edges into training, validation, and test sets. This transform is useful for tasks where the goal is to predict new connections between nodes in a graph.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/dataset_splitting.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.transforms import RandomLinkSplit\n\nx = torch.randn(8, 32)  # Node features of shape [num_nodes, num_features]\ny = torch.randint(0, 4, (8, ))  # Node labels of shape [num_nodes]\nedge_index = torch.tensor([\n    [2, 3, 3, 4, 5, 6, 7],\n    [0, 0, 1, 1, 2, 3, 4]],\n)\n\nedge_y = torch.tensor([0, 0, 0, 0, 1, 1, 1])\n#   0  1\n#  / \\/ \\\n# 2  3  4\n# |  |  |\n# 5  6  7\n\ndata = Data(x=x, y=y, edge_index=edge_index, edge_y=edge_y)\nedge_transform = RandomLinkSplit(num_val=0.2, num_test=0.2, key='edge_y',\n                                is_undirected=False, add_negative_train_samples=False)\ntrain_data, val_data, test_data = edge_transform(data)\n```\n\n----------------------------------------\n\nTITLE: Data Object Validation and Utilities in PyTorch Geometric\nDESCRIPTION: Demonstrates various utility functions provided by the Data class in PyTorch Geometric, including validation, key access, property inspection, and device transfer.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndata.validate(raise_on_error=True)\n\nprint(data.keys())\n>>> ['x', 'edge_index']\n\nprint(data['x'])\n>>> tensor([[-1.0],\n            [0.0],\n            [1.0]])\n\nfor key, item in data:\n    print(f'{key} found in data')\n>>> x found in data\n>>> edge_index found in data\n\n'edge_attr' in data\n>>> False\n\ndata.num_nodes\n>>> 3\n\ndata.num_edges\n>>> 4\n\ndata.num_node_features\n>>> 1\n\ndata.has_isolated_nodes()\n>>> False\n\ndata.has_self_loops()\n>>> False\n\ndata.is_directed()\n>>> False\n\n# Transfer data object to GPU.\ndevice = torch.device('cuda')\ndata = data.to(device)\n```\n\n----------------------------------------\n\nTITLE: Sample training and validation output logs\nDESCRIPTION: This snippet shows sample output logs from the training process, including epoch number, loss, validation MAE, and test MAE, providing an example of how the model's performance changes over epochs. It demonstrates how to monitor the training process and potentially detect overfitting or convergence.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_10\n\nLANGUAGE: text\nCODE:\n```\nEpoch: 01, Loss: 0.7216, Val: 0.5316, Test: 0.5454\n    Epoch: 02, Loss: 0.5519, Val: 0.5895, Test: 0.6288\n    Epoch: 03, Loss: 0.5009, Val: 0.5029, Test: 0.4924\n    Epoch: 04, Loss: 0.4751, Val: 0.4801, Test: 0.4786\n    Epoch: 05, Loss: 0.4363, Val: 0.4438, Test: 0.4352\n    Epoch: 06, Loss: 0.4276, Val: 0.4931, Test: 0.4994\n    Epoch: 07, Loss: 0.3956, Val: 0.3502, Test: 0.3439\n    Epoch: 08, Loss: 0.4021, Val: 0.3143, Test: 0.3296\n    Epoch: 09, Loss: 0.3761, Val: 0.4012, Test: 0.3858\n    Epoch: 10, Loss: 0.3739, Val: 0.3343, Test: 0.3032\n    Epoch: 11, Loss: 0.3532, Val: 0.3679, Test: 0.3334\n    Epoch: 12, Loss: 0.3683, Val: 0.3094, Test: 0.2754\n    Epoch: 13, Loss: 0.3457, Val: 0.4007, Test: 0.4023\n    Epoch: 14, Loss: 0.3460, Val: 0.3986, Test: 0.3589\n    Epoch: 15, Loss: 0.3369, Val: 0.3478, Test: 0.3124\n    Epoch: 16, Loss: 0.3222, Val: 0.3043, Test: 0.2651\n    Epoch: 17, Loss: 0.3190, Val: 0.4496, Test: 0.4070\n    Epoch: 18, Loss: 0.3317, Val: 0.3803, Test: 0.3450\n    Epoch: 19, Loss: 0.3179, Val: 0.2671, Test: 0.2408\n    Epoch: 20, Loss: 0.3143, Val: 0.4168, Test: 0.3901\n    Epoch: 21, Loss: 0.3238, Val: 0.3183, Test: 0.2926\n    Epoch: 22, Loss: 0.3132, Val: 0.9534, Test: 1.0879\n    Epoch: 23, Loss: 0.3088, Val: 0.3705, Test: 0.3360\n    Epoch: 24, Loss: 0.3032, Val: 0.3051, Test: 0.2692\n    Epoch: 25, Loss: 0.2968, Val: 0.2829, Test: 0.2571\n    Epoch: 26, Loss: 0.2915, Val: 0.3145, Test: 0.2820\n    Epoch: 27, Loss: 0.2871, Val: 0.3127, Test: 0.2965\n    Epoch: 28, Loss: 0.2953, Val: 0.4415, Test: 0.4144\n    Epoch: 29, Loss: 0.2916, Val: 0.3118, Test: 0.2733\n    Epoch: 30, Loss: 0.3074, Val: 0.4497, Test: 0.4418\n```\n\n----------------------------------------\n\nTITLE: Implementing InMemoryDataset in PyTorch Geometric\nDESCRIPTION: Example implementation of a custom InMemoryDataset class that loads the entire dataset into memory. Shows required method implementations including raw_file_names, processed_file_names, download, and process.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_dataset.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.data import InMemoryDataset, download_url\n\n\nclass MyOwnDataset(InMemoryDataset):\n    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n        super().__init__(root, transform, pre_transform, pre_filter)\n        self.load(self.processed_paths[0])\n        # For PyG<2.4:\n        # self.data, self.slices = torch.load(self.processed_paths[0])\n\n    @property\n    def raw_file_names(self):\n        return ['some_file_1', 'some_file_2', ...]\n\n    @property\n    def processed_file_names(self):\n        return ['data.pt']\n\n    def download(self):\n        # Download to `self.raw_dir`.\n        download_url(url, self.raw_dir)\n        ...\n\n    def process(self):\n        # Read data into huge `Data` list.\n        data_list = [...]\n\n        if self.pre_filter is not None:\n            data_list = [data for data in data_list if self.pre_filter(data)]\n\n        if self.pre_transform is not None:\n            data_list = [self.pre_transform(data) for data in data_list]\n\n        self.save(data_list, self.processed_paths[0])\n        # For PyG<2.4:\n        # torch.save(self.collate(data_list), self.processed_paths[0])\n```\n\n----------------------------------------\n\nTITLE: Setting Up NeighborLoader for Distributed Training in PyG\nDESCRIPTION: Initializes the NeighborLoader for distributed training, splitting the training indices across GPUs. This ensures each GPU works on a distinct subset of the data.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_gpu_vanilla.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.loader import NeighborLoader\n\ndef run(rank: int, world_size: int, dataset: Reddit):\n    ...\n\n    data = dataset[0]\n\n    train_index = data.train_mask.nonzero().view(-1)\n    train_index = train_index.split(train_index.size(0) // world_size)[rank]\n\n    train_loader = NeighborLoader(\n        data,\n        input_nodes=train_index,\n        num_neighbors=[25, 10],\n        batch_size=1024,\n        num_workers=4,\n        shuffle=True,\n    )\n```\n\n----------------------------------------\n\nTITLE: Using the Implemented GCN Layer in Models\nDESCRIPTION: Example of initializing and using the custom GCNConv layer in a graph neural network model. This snippet demonstrates how to create an instance of the layer and process node features and edge indices through it.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_gnn.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nconv = GCNConv(16, 32)\nx = conv(x, edge_index)\n```\n\n----------------------------------------\n\nTITLE: Initializing Lazy Modules in Heterogeneous GNN Models\nDESCRIPTION: This code snippet demonstrates how to initialize lazy modules in heterogeneous GNN models by performing a forward pass with torch.no_grad(). This is necessary due to the varying input feature sizes in heterogeneous graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith torch.no_grad():  # Initialize lazy modules.\n     out = model(data.x_dict, data.edge_index_dict)\n```\n\n----------------------------------------\n\nTITLE: Initializing NeighborLoader for Graph Sampling in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to initialize a NeighborLoader object to perform neighbor sampling on a graph. It sets up a sample graph data structure and configures the loader with specific sampling parameters.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/neighbor_loader.rst#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import NeighborLoader\n\nx = torch.randn(8, 32)  # Node features of shape [num_nodes, num_features]\ny = torch.randint(0, 4, (8, ))  # Node labels of shape [num_nodes]\nedge_index = torch.tensor([\n    [2, 3, 3, 4, 5, 6, 7],\n    [0, 0, 1, 1, 2, 3, 4]],\n)\n\n#   0  1\n#  / \\/ \\\n# 2  3  4\n# |  |  |\n# 5  6  7\n\ndata = Data(x=x, y=y, edge_index=edge_index)\n\nloader = NeighborLoader(\n    data,\n    input_nodes=torch.tensor([0, 1]),\n    num_neighbors=[2, 1],\n    batch_size=1,\n    replace=False,\n    shuffle=False,\n)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Graph Explanations\nDESCRIPTION: Code showing how to visualize the explanation results using the Explanation object's built-in visualization methods. The example demonstrates both feature importance visualization and graph visualization of the explanation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/explain.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nexplanation.visualize_feature_importance(top_k=10)\n\nexplanation.visualize_graph()\n```\n\n----------------------------------------\n\nTITLE: Applying Transformations to Heterogeneous Graphs in PyTorch Geometric\nDESCRIPTION: Demonstrates how to apply common graph transformations to a heterogeneous graph, including converting to undirected, adding self-loops, and normalizing features.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\n\ndata = T.ToUndirected()(data)\ndata = T.AddSelfLoops()(data)\ndata = T.NormalizeFeatures()(data)\n```\n\n----------------------------------------\n\nTITLE: Synchronizing and Evaluating Model in Distributed PyG Training\nDESCRIPTION: Demonstrates how to synchronize processes, evaluate the model on a single GPU, and report validation metrics in a multi-GPU training setup.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_gpu_vanilla.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n        dist.barrier()\n\n        if rank == 0:\n            print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n\n        if rank == 0:\n            model.eval()\n            count = correct = 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    batch = batch.to(rank)\n                    out = model(batch.x, batch.edge_index)[:batch.batch_size]\n                    pred = out.argmax(dim=-1)\n                    correct += (pred == batch.y[:batch.batch_size]).sum()\n                    count += batch.batch_size\n            print(f'Validation Accuracy: {correct/count:.4f}')\n\n        dist.barrier()\n```\n\n----------------------------------------\n\nTITLE: Initializing HeteroData Object in PyTorch Geometric\nDESCRIPTION: This snippet creates a HeteroData object and adds user and movie node types to it, demonstrating how to handle nodes with and without features in a heterogeneous graph.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import HeteroData\n\ndata = HeteroData()\n\ndata['user'].num_nodes = len(user_mapping)  # Users do not have any features.\ndata['movie'].x = movie_x\n\nprint(data)\n```\n\n----------------------------------------\n\nTITLE: Implementing Local MPNN in GPS Layer (Python)\nDESCRIPTION: This snippet shows the implementation of the local Message Passing Neural Network (MPNN) part in the GPS layer. It applies a graph convolution, dropout, residual connection, and normalization.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nh = self.conv(x, edge_index, **kwargs)\nh = F.dropout(h, p=self.dropout, training=self.training)\nh = h + x\nif self.norm1 is not None:\n    if self.norm_with_batch:\n        h = self.norm1(h, batch=batch)\n    else:\n        h = self.norm1(h)\nhs.append(h)\n```\n\n----------------------------------------\n\nTITLE: Training loop execution and logging in PyTorch\nDESCRIPTION: This code snippet executes the training and evaluation loops for a specified number of epochs. It calls the `train()` and `test()` functions, updates the learning rate scheduler based on the validation performance, and prints the epoch number, training loss, validation MAE, and test MAE. This allows for monitoring the training progress and evaluating the model's performance on separate validation and test datasets.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfor epoch in range(1, 101):\n        loss = train()\n        val_mae = test(val_loader)\n        test_mae = test(test_loader)\n        scheduler.step(val_mae)\n        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_mae:.4f}, '\n            f'Test: {test_mae:.4f}')\n```\n\n----------------------------------------\n\nTITLE: Creating a BipartiteData Class for Bipartite Graphs\nDESCRIPTION: Definition of a BipartiteData class for handling bipartite graphs, which have two distinct node types and directed edges between them. This class structure is essential for properly representing relationships between different entity types.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import Data\n\nclass BipartiteData(Data):\n    pass\n\ndata = BipartiteData(x_s=x_s, x_t=x_t, edge_index=edge_index)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Concatenation Dimension in PyTorch Geometric\nDESCRIPTION: This snippet shows how to implement a custom __cat_dim__ method to batch certain attributes along a new dimension. It demonstrates this for a 'foo' attribute in a custom MyData class.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\nclass MyData(Data):\n    def __cat_dim__(self, key, value, *args, **kwargs):\n        if key == 'foo':\n            return None\n        return super().__cat_dim__(key, value, *args, **kwargs)\n\nedge_index = torch.tensor([\n   [0, 1, 1, 2],\n   [1, 0, 2, 1],\n])\nfoo = torch.randn(16)\n\ndata = MyData(num_nodes=3, edge_index=edge_index, foo=foo)\n\ndata_list = [data, data]\nloader = DataLoader(data_list, batch_size=2)\nbatch = next(iter(loader))\n\nprint(batch)\n>>> MyDataBatch(num_nodes=6, edge_index=[2, 8], foo=[2, 16])\n```\n\n----------------------------------------\n\nTITLE: Initializing Distributed Process Group in PyTorch\nDESCRIPTION: Sets up the distributed process group for inter-GPU communication using the NCCL backend. This is necessary for coordinating training across multiple GPUs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_gpu_vanilla.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport torch.distributed as dist\nimport torch\n\ndef run(rank: int, world_size: int, dataset: Reddit):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12345'\n    dist.init_process_group('nccl', rank=rank, world_size=world_size)\n```\n\n----------------------------------------\n\nTITLE: Automatically Converting GNN Models to Heterogeneous in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to use the to_hetero function to automatically convert a homogeneous GNN model to a heterogeneous one. It defines a simple GNN class and then converts it using the dataset metadata.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import OGB_MAG\nfrom torch_geometric.nn import SAGEConv, to_hetero\n\n\ndataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected())\ndata = dataset[0]\n\nclass GNN(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels):\n        super().__init__()\n        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n        self.conv2 = SAGEConv((-1, -1), out_channels)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index).relu()\n        x = self.conv2(x, edge_index)\n        return x\n\n\nmodel = GNN(hidden_channels=64, out_channels=dataset.num_classes)\nmodel = to_hetero(model, data.metadata(), aggr='sum')\n```\n\n----------------------------------------\n\nTITLE: Splitting Training Data Across Processes\nDESCRIPTION: This code snippet demonstrates how to split the training data across multiple processes for distributed training. It uses the global rank to determine which chunk of data each process should use.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntrain_idx = data.train_mask.nonzero(as_tuple=False).view(-1)\ntrain_idx = train_idx.split(train_idx.size(0) // world_size)[rank]\n```\n\n----------------------------------------\n\nTITLE: Implementing Global Attention in GPS Layer (Python)\nDESCRIPTION: This code implements the global attention mechanism in the GPS layer. It handles both regular MultiheadAttention and PerformerAttention, applying dropout, residual connection, and normalization.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nh, mask = to_dense_batch(x, batch)\n\nif isinstance(self.attn, torch.nn.MultiheadAttention):\n    h, _ = self.attn(h, h, h, key_padding_mask=~mask,\n                    need_weights=False)\nelif isinstance(self.attn, PerformerAttention):\n    h = self.attn(h, mask=mask)\n\nh = h[mask]\nh = F.dropout(h, p=self.dropout, training=self.training)\nh = h + x  # Residual connection.\nif self.norm2 is not None:\n    if self.norm_with_batch:\n        h = self.norm2(h, batch=batch)\n    else:\n        h = self.norm2(h)\nhs.append(h)\n```\n\n----------------------------------------\n\nTITLE: Using ToSparseTensor Transform in PyTorch Geometric\nDESCRIPTION: This code snippet demonstrates how to use the ToSparseTensor transform to convert the edge_index format to SparseTensor. It also shows a complete example of training a GNN model using the SparseTensor format.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn.functional as F\n\nfrom torch_geometric.nn import GCNConv\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import Planetoid\n\ndataset = Planetoid(\"Planetoid\", name=\"Cora\", transform=T.ToSparseTensor())\ndata = dataset[0]\n>>> Data(adj_t=[2708, 2708, nnz=10556], x=[2708, 1433], y=[2708], ...)\n\n\nclass GNN(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = GCNConv(dataset.num_features, 16, cached=True)\n        self.conv2 = GCNConv(16, dataset.num_classes, cached=True)\n\n    def forward(self, x, adj_t):\n        x = self.conv1(x, adj_t)\n        x = F.relu(x)\n        x = self.conv2(x, adj_t)\n        return F.log_softmax(x, dim=1)\n\nmodel = GNN()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\ndef train(data):\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x, data.adj_t)\n    loss = F.nll_loss(out, data.y)\n    loss.backward()\n    optimizer.step()\n    return float(loss)\n\nfor epoch in range(1, 201):\n    loss = train(data)\n```\n\n----------------------------------------\n\nTITLE: Training loop for a PyTorch Graph Neural Network\nDESCRIPTION: This function implements the training loop for the GNN model. It iterates through the training data, moves the data to the specified device, performs a forward pass, calculates the loss, performs backpropagation, and updates the model's parameters using the optimizer. The `redraw_projection.redraw_projections()` call suggests a specific technique being employed within the GPS model for handling projections.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef train():\n        model.train()\n\n        total_loss = 0\n        for data in train_loader:\n            data = data.to(device)\n            optimizer.zero_grad()\n            model.redraw_projection.redraw_projections()\n            out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n                        data.batch)\n            loss = (out.squeeze() - data.y).abs().mean()\n            loss.backward()\n            total_loss += loss.item() * data.num_graphs\n            optimizer.step()\n        return total_loss / len(train_loader.dataset)\n```\n\n----------------------------------------\n\nTITLE: Accessing Sampled Subgraph Data from NeighborLoader in PyTorch Geometric\nDESCRIPTION: This code shows how to access and interpret the sampled subgraph data returned by the NeighborLoader. It demonstrates accessing edge indices, node IDs, and batch size from the loader output.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/neighbor_loader.rst#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nbatch = next(iter(loader))\n\nbatch.edge_index\n>>> tensor([[1, 2, 3, 4],\n            [0, 0, 1, 2]])\n\n batch.n_id\n >>> tensor([0, 2, 3, 5, 6])\n\n batch.batch_size\n >>> 1\n\nbatch.n_id[batch.edge_index]\n>>> tensor([[2, 3, 5, 6],\n            [0, 0, 2, 3]])\n\nbatch.n_id[:batch.batch_size]\n>>> tensor([0])\n```\n\n----------------------------------------\n\nTITLE: RST Table Definition for Synthetic Datasets in PyTorch Geometric\nDESCRIPTION: Defines a reStructuredText table for synthetic datasets with statistics including graph count, node count, edge count, feature count, and class/task count. Uses Jinja2 templating to dynamically populate dataset information.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/data_cheatsheet.rst#2025-04-21_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. list-table::\n    :widths: 50 10 10 10 10 10\n    :header-rows: 1\n\n    * - Name\n      - #graphs\n      - #nodes\n      - #edges\n      - #features\n      - #classes/#tasks\n{% for cls in torch_geometric.datasets.synthetic_datasets %}\n    * - :class:`~torch_geometric.datasets.{{ cls }}` {% if torch_geometric.datasets.utils.paper_link(cls) %}(`Paper <{{ torch_geometric.datasets.utils.paper_link(cls) }}>`__){% endif %}\n      - {%if torch_geometric.datasets.utils.has_stats(cls) %}{{ torch_geometric.datasets.utils.get_stat(cls, '#graphs', default=1) }}{% else %}{{ torch_geometric.datasets.utils.get_stat(cls, '#graphs', default='') }}{% endif %}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#nodes', default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#edges', default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#features', default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#classes', default='') }}{{ torch_geometric.datasets.utils.get_stat(cls, '#tasks', default='') }}\n    {% for child in torch_geometric.datasets.utils.get_children(cls) %}\n    * - └─ {{ child }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#graphs', child, default=1) }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#nodes', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#edges', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#features', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#classes', child, default='') }}{{ torch_geometric.datasets.utils.get_stat(cls, '#tasks', child, default='') }}\n    {% endfor %}\n{% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Distributed Training (Bash)\nDESCRIPTION: This snippet sets up environment variables for torch.distributed to perform the rendezvous procedure. It sets the MASTER_PORT and MASTER_ADDR variables.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport MASTER_PORT=$(expr 10000 + $(echo -n $SLURM_JOBID | tail -c 4))\nexport MASTER_ADDR=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\necho \"MASTER_ADDR:MASTER_PORT=${MASTER_ADDR}:${MASTER_PORT}\"\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom MessagePassing Layer in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to create a custom MessagePassing layer in PyTorch Geometric. It implements a simple message passing operation that subtracts the central node features from the neighboring node features.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.nn import MessagePassing\n\nx = ...           # Node features of shape [num_nodes, num_features]\nedge_index = ...  # Edge indices of shape [2, num_edges]\n\nclass MyConv(MessagePassing):\n    def __init__(self):\n        super().__init__(aggr=\"add\")\n\n    def forward(self, x, edge_index):\n        return self.propagate(edge_index, x=x)\n\n    def message(self, x_i, x_j):\n        return MLP(x_j - x_i)\n```\n\n----------------------------------------\n\nTITLE: Evaluation function for a PyTorch Graph Neural Network\nDESCRIPTION: This function evaluates the trained GNN model on a given data loader. It iterates through the data, moves it to the specified device, performs a forward pass, and calculates the total error based on the absolute difference between the model's output and the ground truth values. The `@torch.no_grad()` decorator disables gradient calculation during evaluation, improving efficiency.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@torch.no_grad()\n    def test(loader):\n        model.eval()\n\n        total_error = 0\n        for data in loader:\n            data = data.to(device)\n            out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n                        data.batch)\n            total_error += (out.squeeze() - data.y).abs().sum().item()\n        return total_error / len(loader.dataset)\n```\n\n----------------------------------------\n\nTITLE: Underlying Implementation of MessagePassing in PyTorch Geometric\nDESCRIPTION: This code snippet shows the underlying implementation of the MessagePassing interface in PyTorch Geometric. It demonstrates how the gather-scatter scheme is used to aggregate messages from neighboring nodes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.utils import scatter\n\nx = ...           # Node features of shape [num_nodes, num_features]\nedge_index = ...  # Edge indices of shape [2, num_edges]\n\nx_j = x[edge_index[0]]  # Source node features [num_edges, num_features]\nx_i = x[edge_index[1]]  # Target node features [num_edges, num_features]\n\nmsg = MLP(x_j - x_i)  # Compute message for each edge\n\n# Aggregate messages based on target node indices\nout = scatter(msg, edge_index[1], dim=0, dim_size=x.size(0), reduce='sum')\n```\n\n----------------------------------------\n\nTITLE: Implementing HGAM with Homogeneous Data in PyTorch Geometric\nDESCRIPTION: Example showing how to use NeighborLoader with homogeneous data to enable HGAM functionality. Demonstrates loading the Cora dataset and accessing the num_sampled_nodes and num_sampled_edges attributes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/hgam.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.loader import NeighborLoader\n\ndata = Planetoid(path, name='Cora')[0]\n\nloader = NeighborLoader(\n    data,\n    num_neighbors=[10] * 3,\n    batch_size=128,\n)\n\nbatch = next(iter(loader))\nprint(batch)\nprint(batch.num_sampled_nodes)\nprint(batch.num_sampled_edges)\n```\n\n----------------------------------------\n\nTITLE: Generating Class Documentation for PyTorch Geometric in reStructuredText\nDESCRIPTION: This template uses Sphinx directives to create comprehensive documentation for a PyTorch Geometric class. It includes the class name, inheritance information, all members, inherited members, and special methods __cat_dim__ and __inc__.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/_templates/autosummary/inherited_class.rst#2025-04-21_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n{{ fullname | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n   :show-inheritance:\n   :members:\n   :inherited-members:\n   :special-members: __cat_dim__, __inc__\n```\n\n----------------------------------------\n\nTITLE: Loading Movie Data with Encoders in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to use the load_node_csv function with custom encoders to load movie data and create feature representations for titles and genres.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmovie_x, movie_mapping = load_node_csv(\n    movie_path, index_col='movieId', encoders={\n        'title': SequenceEncoder(),\n        'genres': GenresEncoder()\n    })\n```\n\n----------------------------------------\n\nTITLE: Implementing DynamicEdgeConv with k-NN Graph Generation in PyTorch Geometric\nDESCRIPTION: This snippet defines the DynamicEdgeConv class, which extends EdgeConv by dynamically computing the k-nearest neighbors graph for each layer. It uses the knn_graph function from PyTorch Geometric to generate the graph.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_gnn.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.nn import knn_graph\n\nclass DynamicEdgeConv(EdgeConv):\n    def __init__(self, in_channels, out_channels, k=6):\n        super().__init__(in_channels, out_channels)\n        self.k = k\n\n    def forward(self, x, batch=None):\n        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n        return super().forward(x, edge_index)\n```\n\n----------------------------------------\n\nTITLE: Mini-batch Processing with DataLoader in PyTorch Geometric\nDESCRIPTION: Demonstrates how to use PyTorch Geometric's DataLoader to create mini-batches for training neural networks, handling different sized graphs by creating sparse block diagonal adjacency matrices.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.loader import DataLoader\n\ndataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nfor batch in loader:\n    batch\n    >>> DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32])\n\n    batch.num_graphs\n    >>> 32\n```\n\n----------------------------------------\n\nTITLE: Initializing Node2Vec Model in Python\nDESCRIPTION: This code initializes the Node2Vec model with specific parameters, including embedding dimension, walk length, and sampling strategy. It also sets up the optimizer for training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/shallow_node_embeddings.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.nn import Node2Vec\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = Node2Vec(\n    data.edge_index,\n    embedding_dim=128,\n    walks_per_node=10,\n    walk_length=20,\n    context_size=10,\n    p=1.0,\n    q=1.0,\n    num_negative_samples=1,\n).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n```\n\n----------------------------------------\n\nTITLE: Using GraphConv with Edge Weights\nDESCRIPTION: Example of message passing with one-dimensional edge weight information\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/cheatsheet.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nGraphConv(...).forward(x, edge_index, edge_weight)\n```\n\n----------------------------------------\n\nTITLE: GNNExplainer Example for Node Classification in PyTorch Geometric\nDESCRIPTION: This example demonstrates the use of `GNNExplainer` for explaining node classification predictions in a GNN model. It shows how to apply `GNNExplainer` to understand which parts of the graph are most important for a specific node's classification.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n\"./gnn_explainer.py\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom __inc__ Method for PairData\nDESCRIPTION: Customization of the __inc__ method for the PairData class to properly handle edge indices from source and target graphs. This ensures that edge_index_s and edge_index_t are incremented by the correct number of nodes during batching.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass PairData(Data):\n    def __inc__(self, key, value, *args, **kwargs):\n        if key == 'edge_index_s':\n            return self.x_s.size(0)\n        if key == 'edge_index_t':\n            return self.x_t.size(0)\n        return super().__inc__(key, value, *args, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Generating Class Summaries in RST for torch_geometric.graphgym.utils\nDESCRIPTION: This RST code snippet produces an autosummary of classes in the torch_geometric.graphgym.utils module. It uses a Jinja2 template to iterate through the classes and list them without signatures.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/graphgym.rst#2025-04-21_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :nosignatures:\n    {% for cls in torch_geometric.graphgym.utils.classes %}\n     {{ cls }}\n    {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Running Training Benchmarks\nDESCRIPTION: Example commands for running training benchmarks with different models (GCN, SAGE) and datasets (Reddit, ogbn-products), with options for sparse tensor usage.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/training/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython training_benchmark.py --models=gcn --datasets=Reddit --num-workers=0 --batch-sizes=512 --num-layers=2 --num-hidden-channels=64 --num-steps=50\npython training_benchmark.py --models=gcn --datasets=Reddit --num-workers=0 --batch-sizes=512 --num-layers=2 --num-hidden-channels=64 --num-steps=50 --use-sparse-tensor\npython training_benchmark.py --models=sage --datasets=ogbn-products --num-workers=0 --batch-sizes=512 --num-layers=2 --num-hidden-channels=64 --num-steps=50\npython training_benchmark.py --models=sage --datasets=ogbn-products --num-workers=0 --batch-sizes=512 --num-layers=2 --num-hidden-channels=64 --num-steps=50 --use-sparse-tensor\n```\n\n----------------------------------------\n\nTITLE: Using CaptumExplainer for Heterogeneous Graph Node Classification\nDESCRIPTION: Example showing how to use the CaptumExplainer with IntegratedGradients method to explain node classification on heterogeneous graphs. The code demonstrates generating batch-wise explanations for multiple nodes across different node and edge types.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/explain.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import HeteroData\nfrom torch_geometric.explain import Explainer, CaptumExplainer\n\nhetero_data = HeteroData(...)  # A heterogeneous graph data object.\n\nexplainer = Explainer(\n    model,  # It is assumed that model outputs a single tensor.\n    algorithm=CaptumExplainer('IntegratedGradients'),\n    explanation_type='model',\n    node_mask_type='attributes',\n    edge_mask_type='object',\n    model_config = dict(\n        mode='multiclass_classification',\n        task_level=task_level,\n        return_type='probs',  # Model returns probabilities.\n    ),\n)\n\n# Generate batch-wise heterogeneous explanations for\n# the nodes at index `1` and `3`:\nhetero_explanation = explainer(\n    hetero_data.x_dict,\n    hetero_data.edge_index_dict,\n    index=torch.tensor([1, 3]),\n)\nprint(hetero_explanation.edge_mask_dict)\nprint(hetero_explanation.node_mask_dict)\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom PairData Class for Graph Matching\nDESCRIPTION: Definition of a PairData class that extends the Data class for storing pairs of graphs (source and target) in a single object. This is useful for applications like graph matching where relationships between two graphs need to be maintained.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import Data\n\nclass PairData(Data):\n    pass\n\ndata = PairData(x_s=x_s, edge_index_s=edge_index_s,  # Source graph.\n                x_t=x_t, edge_index_t=edge_index_t)  # Target graph.\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-Split Graph Datasets for Graph Prediction in PyTorch Geometric\nDESCRIPTION: Demonstrates how to load datasets that are already divided into training, validation, and test splits, using the PPI dataset as an example. This approach is useful for graph-level prediction tasks.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/dataset_splitting.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import PPI\n\npath = './data/PPI'\ntrain_dataset = PPI(path, split='train')\nval_dataset = PPI(path, split='val')\ntest_dataset = PPI(path, split='test')\n```\n\n----------------------------------------\n\nTITLE: Initializing NodeLoader with FeatureStore and GraphStore in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to initialize a NodeLoader using a FeatureStore and GraphStore instead of PyG data objects. It sets up batch processing for 'paper' nodes with a specified batch size and node sampler.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/remote.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nloader = NodeLoader(\n    data=(feature_store, graph_store),\n    node_sampler=node_sampler,\n    batch_size=20,\n    input_nodes='paper',\n)\n\nfor batch in loader:\n    pass\n```\n\n----------------------------------------\n\nTITLE: Generating Class Summaries in RST for torch_geometric.graphgym\nDESCRIPTION: This RST code snippet generates an autosummary of classes in the torch_geometric.graphgym module. It uses a Jinja2 template to iterate through the classes and list them without signatures.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/graphgym.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n   :nosignatures:\n   {% for cls in torch_geometric.graphgym.classes %}\n     {{ cls }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: GNNExplainer Example on BAShapes Dataset in PyTorch Geometric\nDESCRIPTION: This example demonstrates how to use `GNNExplainer` on the `BAShapes` dataset.  It applies `GNNExplainer` to understand the underlying patterns or structures in the `BAShapes` dataset that contribute to the GNN's performance.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/README.md#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n\"./gnn_explainer_ba_shapes.py\"\n```\n\n----------------------------------------\n\nTITLE: Implementing PointNet++ Layer in PyTorch Geometric\nDESCRIPTION: Defines a custom PointNetLayer class that implements the neighborhood aggregation phase of PointNet++. It uses the MessagePassing interface from PyG to handle message propagation and aggregation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/point_cloud.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom torch import Tensor\nfrom torch.nn import Sequential, Linear, ReLU\n\nfrom torch_geometric.nn import MessagePassing\n\n\nclass PointNetLayer(MessagePassing):\n    def __init__(self, in_channels: int, out_channels: int):\n        # Message passing with \"max\" aggregation.\n        super().__init__(aggr='max')\n\n        # Initialization of the MLP:\n        # Here, the number of input features correspond to the hidden\n        # node dimensionality plus point dimensionality (=3).\n        self.mlp = Sequential(\n            Linear(in_channels + 3, out_channels),\n            ReLU(),\n            Linear(out_channels, out_channels),\n        )\n\n    def forward(self,\n        h: Tensor,\n        pos: Tensor,\n        edge_index: Tensor,\n    ) -> Tensor:\n        # Start propagating messages.\n        return self.propagate(edge_index, h=h, pos=pos)\n\n    def message(self,\n        h_j: Tensor,\n        pos_j: Tensor,\n        pos_i: Tensor,\n    ) -> Tensor:\n        # h_j: The features of neighbors as shape [num_edges, in_channels]\n        # pos_j: The position of neighbors as shape [num_edges, 3]\n        # pos_i: The central node position as shape [num_edges, 3]\n\n        edge_feat = torch.cat([h_j, pos_j - pos_i], dim=-1)\n        return self.mlp(edge_feat)\n```\n\n----------------------------------------\n\nTITLE: Loading Node Data from CSV in PyTorch Geometric\nDESCRIPTION: This function loads node data from a CSV file, creates a mapping for indices, and applies encoders to generate node features. It's used for both movie and user data in the heterogeneous graph.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\ndef load_node_csv(path, index_col, encoders=None, **kwargs):\n    df = pd.read_csv(path, index_col=index_col, **kwargs)\n    mapping = {index: i for i, index in enumerate(df.index.unique())}\n\n    x = None\n    if encoders is not None:\n        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n        x = torch.cat(xs, dim=-1)\n\n    return x, mapping\n```\n\n----------------------------------------\n\nTITLE: Loading OGB-MAG Dataset in PyTorch Geometric\nDESCRIPTION: Shows how to load the OGB-MAG dataset, a heterogeneous graph dataset, using PyTorch Geometric's built-in dataset class. The dataset is automatically downloaded and processed.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import OGB_MAG\n\ndataset = OGB_MAG(root='./data', preprocess='metapath2vec')\ndata = dataset[0]\n```\n\n----------------------------------------\n\nTITLE: Implementing Genres Encoder for Categorical Data in PyTorch\nDESCRIPTION: This class implements an encoder for movie genres, converting the pipe-separated genre strings into a multi-hot encoded tensor representation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass GenresEncoder:\n    def __init__(self, sep='|'):\n        self.sep = sep\n\n    def __call__(self, df):\n        genres = set(g for col in df.values for g in col.split(self.sep))\n        mapping = {genre: i for i, genre in enumerate(genres)}\n\n        x = torch.zeros(len(df), len(mapping))\n        for i, col in enumerate(df.values):\n            for genre in col.split(self.sep):\n                x[i, mapping[genre]] = 1\n        return x\n```\n\n----------------------------------------\n\nTITLE: Applying Transforms to ShapeNet Dataset in PyTorch Geometric\nDESCRIPTION: This example shows how to apply transforms to the ShapeNet dataset. It demonstrates using pre_transform to convert point clouds into graphs using KNNGraph, and transform for data augmentation using RandomJitter.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import ShapeNet\n\ndataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n\ndataset[0]\n>>> Data(pos=[2518, 3], y=[2518])\n```\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import ShapeNet\n\ndataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n                    pre_transform=T.KNNGraph(k=6))\n\ndataset[0]\n>>> Data(edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n```\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import ShapeNet\n\ndataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n                    pre_transform=T.KNNGraph(k=6),\n                    transform=T.RandomJitter(0.01))\n\ndataset[0]\n>>> Data(edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n```\n\n----------------------------------------\n\nTITLE: Running CUDA GPU Benchmark for PyTorch Geometric\nDESCRIPTION: Command to run a training benchmark on CUDA GPUs using PyTorch Geometric. It specifies the dataset, model, number of epochs, and number of GPUs to use.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/multi_gpu/training/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython training_benchmark_cuda.py --dataset ogbn-products --model edge_cnn --num-epochs 3 --n_gpus <n>\n```\n\n----------------------------------------\n\nTITLE: GNNExplainer Example for Link Prediction in PyTorch Geometric\nDESCRIPTION: This example showcases the application of `GNNExplainer` for explaining link prediction tasks. It illustrates how to identify the crucial connections or patterns in the graph that contribute to the prediction of a link between two nodes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/README.md#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n\"./gnn_explainer_link_pred.py\"\n```\n\n----------------------------------------\n\nTITLE: Loading Edge Data from CSV in PyTorch Geometric\nDESCRIPTION: This function loads edge data from a CSV file, mapping source and destination indices, and applying encoders for edge attributes. It's used to create the user-movie rating connections.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping,\n                  encoders=None, **kwargs):\n    df = pd.read_csv(path, **kwargs)\n\n    src = [src_mapping[index] for index in df[src_index_col]]\n    dst = [dst_mapping[index] for index in df[dst_index_col]]\n    edge_index = torch.tensor([src, dst])\n\n    edge_attr = None\n    if encoders is not None:\n        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n        edge_attr = torch.cat(edge_attrs, dim=-1)\n\n    return edge_index, edge_attr\n```\n\n----------------------------------------\n\nTITLE: Exploring Graph Data in PyTorch Geometric\nDESCRIPTION: Demonstrates how to access and analyze individual graphs from a dataset, showing properties like number of nodes, edges, and graph class.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndata = dataset[0]\n>>> Data(edge_index=[2, 168], x=[37, 3], y=[1])\n\ndata.is_undirected()\n>>> True\n```\n\n----------------------------------------\n\nTITLE: Registering Custom GraphGym Modules in PyTorch Geometric\nDESCRIPTION: This code snippet demonstrates how to register custom modules for GraphGym using the torch_geometric.graphgym.register method. It's a placeholder for actual implementation details that would be found in example files within each customizable module directory.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/graphgym.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.graphgym import register\n\n# Example of registering a custom module\nregister.register_act('custom_activation')\n```\n\n----------------------------------------\n\nTITLE: Using SparseTensor in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to use the SparseTensor class in PyTorch Geometric. It shows various operations such as creating SparseTensor instances, obtaining different representations, and performing matrix operations.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_sparse import SparseTensor\n\nadj = SparseTensor(row=edge_index[0], col=edge_index[1], value=...,\n                   sparse_sizes=(num_nodes, num_nodes))\n# value is optional and can be None\n\n# Obtain different representations (COO, CSR, CSC):\nrow,    col, value = adj.coo()\nrowptr, col, value = adj.csr()\ncolptr, row, value = adj.csc()\n\nadj = adj[:100, :100]  # Slicing, indexing and masking support\nadj = adj.set_diag()   # Add diagonal entries\nadj_t = adj.t()        # Transpose\nout = adj.matmul(x)    # Sparse-dense matrix multiplication\nadj = adj.matmul(adj)  # Sparse-sparse matrix multiplication\n\n# Creating SparseTensor instances:\nadj = SparseTensor.from_dense(mat)\nadj = SparseTensor.eye(100, 100)\nadj = SparseTensor.from_scipy(mat)\n```\n\n----------------------------------------\n\nTITLE: Setting OMP Threads for Baseline Configuration in PyTorch Geometric\nDESCRIPTION: This snippet shows the baseline configuration for running the training benchmark, where only the OMP_NUM_THREADS environment variable is set based on the number of workers.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nOMP_NUM_THREADS=(N-num_workers) python training_benchmark.py --num-workers …\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Data.__inc__ and Data.__cat_dim__ Methods in PyG\nDESCRIPTION: Default implementation of the __inc__ and __cat_dim__ methods in the Data class that control how tensors are incremented and concatenated during batching. These methods determine how edge indices and other attributes are handled when combining multiple graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef __inc__(self, key, value, *args, **kwargs):\n    if 'index' in key:\n        return self.num_nodes\n    else:\n        return 0\n\ndef __cat_dim__(self, key, value, *args, **kwargs):\n    if 'index' in key:\n        return 1\n    else:\n        return 0\n```\n\n----------------------------------------\n\nTITLE: Initializing Multi-GPU Training Setup in PyTorch\nDESCRIPTION: Sets up the main script to spawn multiple processes for multi-GPU training. It initializes the dataset and uses torch.multiprocessing to run the training function across all available GPUs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_gpu_vanilla.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import Reddit\nimport torch.multiprocessing as mp\n\ndef run(rank: int, world_size: int, dataset: Reddit):\n    pass\n\nif __name__ == '__main__':\n    dataset = Reddit('./data/Reddit')\n    world_size = torch.cuda.device_count()\n    mp.spawn(run, args=(world_size, dataset), nprocs=world_size, join=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing HGAM with Heterogeneous Data in PyTorch Geometric\nDESCRIPTION: Example demonstrating NeighborLoader usage with heterogeneous data using the OGB_MAG dataset. Shows how to access sampling information for different node and edge types.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/hgam.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import OGB_MAG\nfrom torch_geometric.loader import NeighborLoader\n\ndata = OGB_MAG(path)[0]\n\nloader = NeighborLoader(\n    data,\n    num_neighbors=[10] * 3,\n    batch_size=128,\n    input_nodes='paper',\n)\n\nbatch = next(iter(loader))\nprint(batch)\nprint(batch['paper'].num_sampled_nodes)\nprint(batch['author', 'writes', 'paper'].num_sampled_edges)\n```\n\n----------------------------------------\n\nTITLE: Loading Planetoid Dataset (Cora) in PyTorch Geometric\nDESCRIPTION: Demonstrates how to load the Cora citation network dataset, which is a standard benchmark for semi-supervised node classification, and shows how to access its properties.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import Planetoid\n\ndataset = Planetoid(root='/tmp/Cora', name='Cora')\n>>> Cora()\n\nlen(dataset)\n>>> 1\n\ndataset.num_classes\n>>> 7\n\ndataset.num_node_features\n>>> 1433\n```\n\n----------------------------------------\n\nTITLE: Assigning Model to Local GPU and Wrapping with DistributedDataParallel\nDESCRIPTION: This snippet shows how to assign the model to a node-local GPU using the local_rank, and then wrap it with DistributedDataParallel for distributed training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel = SAGE(dataset.num_features, 256, dataset.num_classes).to(local_rank)\nmodel = DistributedDataParallel(model, device_ids=[local_rank])\n```\n\n----------------------------------------\n\nTITLE: Implementing RandomNodeSplit for Node Prediction in PyTorch Geometric\nDESCRIPTION: Demonstrates how to use RandomNodeSplit transformation to divide nodes into training, validation, and test sets. This example creates a simple graph with 8 nodes, then splits them into 3 nodes for training, 2 for validation, and 3 for testing.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/dataset_splitting.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.transforms import RandomNodeSplit\n\nx = torch.randn(8, 32)  # Node features of shape [num_nodes, num_features]\ny = torch.randint(0, 4, (8, ))  # Node labels of shape [num_nodes]\nedge_index = torch.tensor([\n    [2, 3, 3, 4, 5, 6, 7],\n    [0, 0, 1, 1, 2, 3, 4]],\n)\n\n#   0  1\n#  / \\/ \\\n# 2  3  4\n# |  |  |\n# 5  6  7\n\ndata = Data(x=x, y=y, edge_index=edge_index)\nnode_transform = RandomNodeSplit(num_val=2, num_test=3)\nnode_splits = node_transform(data)\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Graph Sampler in Python\nDESCRIPTION: Demonstrates how to create a custom graph sampler that is compatible with a specific GraphStore implementation. It shows initializing the sampler with the graph store and sampling parameters.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/remote.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# `CustomGraphSampler` knows how to sample on `CustomGraphStore`:\nnode_sampler = CustomGraphSampler(\n    graph_store=graph_store,\n    num_neighbors=[10, 20],\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Installing OGB Dataset Package for PyG Benchmarks\nDESCRIPTION: Installs the Open Graph Benchmark (OGB) dataset package required for running PyG benchmarks.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/inference/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install ogb\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple Aggregations for Enhanced GNN Representation\nDESCRIPTION: Demonstrates how to combine multiple aggregation functions using the MultiAggregation module to enhance the representational power of GNNs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass MyConv(MessagePassing):\n    def __init__(self, ...):\n        # Combines a set of aggregations and concatenates their results,\n        # i.e. its output will be `[num_nodes, 3 * out_channels]` here.\n        # Note that the interface also supports automatic resolution.\n        super().__init__(aggr=aggr.MultiAggregation(\n            ['mean', 'std', aggr.SoftmaxAggregation(learn=True)]))\n```\n\n----------------------------------------\n\nTITLE: Epoch Loop for Training and Testing PointNet in PyTorch\nDESCRIPTION: This snippet demonstrates the epoch loop, where the training and testing functions are called iteratively. It prints the epoch number, training loss, and test accuracy for each epoch. It iterates for 50 epochs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/point_cloud.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfor epoch in range(1, 51):\n    loss = train()\n    test_acc = test()\n    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')\n```\n\n----------------------------------------\n\nTITLE: Defining a GNN Model in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to define a simple Graph Neural Network (GNN) model using PyTorch Geometric. The model consists of two GCNConv layers with ReLU activation and log softmax output.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/jit.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass GNN(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv1 = GCNConv(in_channels, 64)\n        self.conv2 = GCNConv(64, out_channels)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)\n\nmodel = GNN(dataset.num_features, dataset.num_classes)\n```\n\n----------------------------------------\n\nTITLE: Defining RedrawProjection Class for Performer Attention (Python)\nDESCRIPTION: This class implements the redraw projection functionality for Performer attention in the GraphGPS model. It redraws projection matrices at specified intervals during training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass RedrawProjection:\n    def __init__(self, model: torch.nn.Module,\n                redraw_interval: Optional[int] = None):\n        self.model = model\n        self.redraw_interval = redraw_interval\n        self.num_last_redraw = 0\n\n    def redraw_projections(self):\n        if not self.model.training or self.redraw_interval is None:\n            return\n        if self.num_last_redraw >= self.redraw_interval:\n            fast_attentions = [\n                module for module in self.model.modules()\n                if isinstance(module, PerformerAttention)\n            ]\n            for fast_attention in fast_attentions:\n                fast_attention.redraw_projection_matrix()\n            self.num_last_redraw = 0\n            return\n        self.num_last_redraw += 1\n```\n\n----------------------------------------\n\nTITLE: Using SparseTensor with Edge Attributes in PyTorch Geometric\nDESCRIPTION: This snippet shows how to use SparseTensor with edge attributes in PyTorch Geometric. It demonstrates the difference in how edge attributes are passed to GNN layers when using SparseTensor compared to the edge_index format.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconv = GMMConv(16, 32, dim=3)\nout = conv(x, edge_index, edge_attr)\n\nconv = GMMConv(16, 32, dim=3)\nadj = SparseTensor(row=edge_index[0], col=edge_index[1], value=edge_attr)\nout = conv(x, adj.t())\n```\n\n----------------------------------------\n\nTITLE: Including Colab Notebooks in RST Documentation for PyTorch Geometric\nDESCRIPTION: This RST directive includes the content of another RST file containing Colab notebooks for PyTorch Geometric. The ':orphan:' directive indicates that this page should not be included in the table of contents.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/colabs.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../get_started/colabs.rst\n```\n\n----------------------------------------\n\nTITLE: Configuring CPU Affinity for PyTorch Geometric Training Benchmark\nDESCRIPTION: This snippet demonstrates an advanced configuration for running the training benchmark with CPU affinity settings. It uses jemalloc, sets various environment variables for OpenMP and memory allocation, and uses numactl for CPU core assignment.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nLD_PRELOAD=(path)/libjemalloc.so (path)/libiomp5.so MALLOC_CONF=oversize_threshold:1,background_thread:true,metadata_thp:auto OMP_NUM_THREADS=(N-num_workers) KMP_AFFINITY=granularity=fine,compact,1,0 KMP_BLOCKTIME=0 numactl -C <num_workers-(N-1)> --localalloc python training_benchmark.py --cpu-affinity --num-workers …\n```\n\n----------------------------------------\n\nTITLE: Configuring GNNExplainer for Node Classification on Homogeneous Graphs\nDESCRIPTION: Example demonstrating how to set up an Explainer with GNNExplainer algorithm to explain node classification on a homogeneous graph. The configuration includes both node and edge mask types to identify important nodes, features, and edges for prediction.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/explain.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import Data\nfrom torch_geometric.explain import Explainer, GNNExplainer\n\ndata = Data(...)  # A homogeneous graph data object.\n\nexplainer = Explainer(\n    model=model,\n    algorithm=GNNExplainer(epochs=200),\n    explanation_type='model',\n    node_mask_type='attributes',\n    edge_mask_type='object',\n    model_config=dict(\n        mode='multiclass_classification',\n        task_level='node',\n        return_type='log_probs',  # Model returns log probabilities.\n    ),\n)\n\n# Generate explanation for the node at index `10`:\nexplanation = explainer(data.x, data.edge_index, index=10)\nprint(explanation.edge_mask)\nprint(explanation.node_mask)\n```\n\n----------------------------------------\n\nTITLE: Using follow_batch for Tracking Batch Assignments\nDESCRIPTION: Extension of the PairData example to track batch assignments using the follow_batch parameter. This creates additional tensors that map each node to its original graph, enabling operations like global pooling on multiple graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nloader = DataLoader(data_list, batch_size=2, follow_batch=['x_s', 'x_t'])\nbatch = next(iter(loader))\n\nprint(batch)\n>>> PairDataBatch(x_s=[10, 16], edge_index_s=[2, 8], x_s_batch=[10],\n                  x_t=[8, 16], edge_index_t=[2, 6], x_t_batch=[8])\n\nprint(batch.x_s_batch)\n>>> tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n\nprint(batch.x_t_batch)\n>>> tensor([0, 0, 0, 0, 1, 1, 1, 1])\n```\n\n----------------------------------------\n\nTITLE: Accessing Link Split Data in PyTorch Geometric\nDESCRIPTION: Shows the structure of the train, validation, and test datasets after applying the RandomLinkSplit transformation. Each split contains the necessary information for training and evaluating link prediction models.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/dataset_splitting.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_data\n>>> Data(x=[8, 32], edge_index=[2, 5], y=[8], edge_y=[5], edge_y_index=[2, 5])\nval_data\n>>> Data(x=[8, 32], edge_index=[2, 5], y=[8], edge_y=[2], edge_y_index=[2, 2])\ntest_data\n>>> Data(x=[8, 32], edge_index=[2, 6], y=[8], edge_y=[2], edge_y_index=[2, 2])\n```\n\n----------------------------------------\n\nTITLE: Testing BipartiteData Batching in PyTorch Geometric\nDESCRIPTION: This code demonstrates how to create and batch BipartiteData objects using PyTorch Geometric's DataLoader. It shows the creation of sample data and the resulting batched output.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.loader import DataLoader\n\nx_s = torch.randn(2, 16)  # 2 nodes.\nx_t = torch.randn(3, 16)  # 3 nodes.\nedge_index = torch.tensor([\n    [0, 0, 1, 1],\n    [0, 1, 1, 2],\n])\n\ndata = BipartiteData(x_s=x_s, x_t=x_t, edge_index=edge_index)\n\ndata_list = [data, data]\nloader = DataLoader(data_list, batch_size=2)\nbatch = next(iter(loader))\n\nprint(batch)\n>>> BipartiteDataBatch(x_s=[4, 16], x_t=[6, 16], edge_index=[2, 8])\n\nprint(batch.edge_index)\n>>> tensor([[0, 0, 1, 1, 2, 2, 3, 3],\n            [0, 1, 1, 2, 3, 4, 4, 5]])\n```\n\n----------------------------------------\n\nTITLE: Interacting with a Custom FeatureStore in Python\nDESCRIPTION: Demonstrates how to add and access features in a custom FeatureStore implementation. It shows adding paper and author features, and then retrieving them using different access patterns.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/remote.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfeature_store = CustomFeatureStore()\n\npaper_features = ...  # [num_papers, num_paper_features]\nauthor_features = ...  # [num_authors, num_author_features]\n\n# Add features:\nfeature_store['paper', 'x', None] = paper_features\nfeature_store['author', 'x', None] = author_features\n\n# Access features:\nassert torch.equal(feature_store['paper', 'x'], paper_features)\nassert torch.equal(feature_store['paper'].x, paper_features)\nassert torch.equal(feature_store['author', 'x', 0:20], author_features[0:20])\n```\n\n----------------------------------------\n\nTITLE: Dynamic Shape Tracing Configuration\nDESCRIPTION: Shows how to enable dynamic shape tracing for handling variable-sized mini-batches in PyG models.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/compile.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ntorch.compile(model, dynamic=True)\n```\n\n----------------------------------------\n\nTITLE: Including External Resources in Sphinx Documentation\nDESCRIPTION: A Sphinx directive that includes content from an external resources file. This directive brings in content from '../external/resources.rst' to be displayed in the current document.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/resources.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../external/resources.rst\n```\n\n----------------------------------------\n\nTITLE: Executing PyG Inference Benchmarks\nDESCRIPTION: Provides examples of running PyG inference benchmarks with various configurations, including different datasets, models, and tensor types.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/inference/README.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython -u inference_benchmark.py --datasets=Reddit --models=gcn --eval-batch-sizes=512 --num-layers=2 --num-hidden-channels=64\npython -u inference_benchmark.py --datasets=Reddit --models=gcn --eval-batch-sizes=512 --num-layers=2 --num-hidden-channels=64 --use-sparse-tensor\npython -u inference_benchmark.py --datasets=ogbn-products --models=sage --eval-batch-sizes=512 --num-layers=2 --num-hidden-channels=64\npython -u inference_benchmark.py --datasets=ogbn-products --models=sage --eval-batch-sizes=512 --num-layers=2 --num-hidden-channels=64 --use-sparse-tensor\n```\n\n----------------------------------------\n\nTITLE: Converting PyG Model to TorchScript\nDESCRIPTION: This code snippet shows how to convert a PyTorch Geometric model to a TorchScript program using torch.jit.script. This allows for serialization and optimization of the model.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/jit.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmodel = torch.jit.script(model)\n```\n\n----------------------------------------\n\nTITLE: Obtaining Node Embeddings from Node2Vec in Python\nDESCRIPTION: This code snippet shows how to extract the learned node embeddings from the trained Node2Vec model, either for all nodes or for specific nodes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/shallow_node_embeddings.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nz = model()  # Full node-level embeddings.\nz = model(torch.tensor([0, 1, 2]))  # Embeddings of first three nodes.\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Multihop Dataset in Python\nDESCRIPTION: This Python script preprocesses the dataset to pair questions and answers with components in the knowledge graph. It includes documentation describing the preprocessing process, which is essential for preparing the data for LLM and GNN co-training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/multihop_rag/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nmultihop_preprocess.py\n```\n\n----------------------------------------\n\nTITLE: Lazy Initialization of SAGEConv in PyTorch Geometric\nDESCRIPTION: Example of lazy initialization of SAGEConv layer in PyTorch Geometric. This demonstrates how to use lazy initialization when the input channel size is unknown at initialization time.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/gnn_cheatsheet.rst#2025-04-21_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nSAGEConv(in_channels=-1, out_channels=64)\n```\n\n----------------------------------------\n\nTITLE: Using Basic Aggregation Operations in PyTorch Geometric\nDESCRIPTION: Demonstrates how to initialize and use different types of aggregation operations in PyTorch Geometric, including simple, advanced, learnable, and exotic aggregations.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.nn import aggr\n\n# Simple aggregations:\nmean_aggr = aggr.MeanAggregation()\nmax_aggr = aggr.MaxAggregation()\n\n# Advanced aggregations:\nmedian_aggr = aggr.MedianAggregation()\n\n# Learnable aggregations:\nsoftmax_aggr = aggr.SoftmaxAggregation(learn=True)\npowermean_aggr = aggr.PowerMeanAggregation(learn=True)\n\n# Exotic aggregations:\nlstm_aggr = aggr.LSTMAggregation(in_channels=..., out_channels=...)\nsort_aggr = aggr.SortAggregation(k=4)\n```\n\n----------------------------------------\n\nTITLE: Including External RST Documentation\nDESCRIPTION: An RST include directive that imports compile.rst documentation from the advanced directory.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/compile.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../advanced/compile.rst\n```\n\n----------------------------------------\n\nTITLE: Minimal InMemoryDataset Implementation Example\nDESCRIPTION: Example of a minimal InMemoryDataset implementation that processes a predefined list of Data objects.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_dataset.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MyDataset(InMemoryDataset):\n    def __init__(self, root, data_list, transform=None):\n        self.data_list = data_list\n        super().__init__(root, transform)\n        self.load(self.processed_paths[0])\n\n    @property\n    def processed_file_names(self):\n        return 'data.pt'\n\n    def process(self):\n        self.save(self.data_list, self.processed_paths[0])\n```\n\n----------------------------------------\n\nTITLE: Configuring Edge-Specific Neighbor Sampling in PyG\nDESCRIPTION: Shows how to configure fine-grained control over the number of neighbors sampled for each edge type in a heterogeneous graph using the NeighborLoader. This snippet demonstrates setting up sampling parameters for individual edge types.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nnum_neighbors = {key: [15] * 2 for key in data.edge_types}\n```\n\n----------------------------------------\n\nTITLE: Enabling CPU Affinity with PyG's NeighborLoader\nDESCRIPTION: Demonstrates how to enable CPU affinity on a NeighborLoader with multiple workers. The example assigns specific cores (0, 1, 2) to each of the three worker processes using the enable_cpu_affinity context manager.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nloader = NeigborLoader(\n    data,\n    num_workers=3,\n    ...,\n)\n\nwith loader.enable_cpu_affinity(loader_cores=[0, 1, 2]):\n    for batch in loader:\n        pass\n```\n\n----------------------------------------\n\nTITLE: Creating Data Loader for Node2Vec in Python\nDESCRIPTION: This snippet demonstrates how to create a data loader for the Node2Vec model, which will generate positive and negative random walks for training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/shallow_node_embeddings.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nloader = model.loader(batch_size=128, shuffle=True, num_workers=4)\n\npos_rw, neg_rw = next(iter(loader))\n```\n\n----------------------------------------\n\nTITLE: Starting an Implementation of __inc__ for BipartiteData\nDESCRIPTION: Beginning of the implementation for the __inc__ method in BipartiteData class. This method needs to separately handle the source and target nodes in the edge_index to account for the bipartite structure.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass BipartiteData(Data):\n    def __inc__(self, key, value, *args, **kwargs):\n        if key == 'edge_index':\n```\n\n----------------------------------------\n\nTITLE: Initializing SAGEConv for Bipartite Graphs in PyTorch Geometric\nDESCRIPTION: Example of initializing SAGEConv for message passing in bipartite graphs with different feature dimensionalities for source and destination nodes in PyTorch Geometric.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/gnn_cheatsheet.rst#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nSAGEConv(in_channels=(16, 32), out_channels=64)\n```\n\n----------------------------------------\n\nTITLE: Running GNN/LLM Benchmark on GRetriever - Python\nDESCRIPTION: This script benchmarks various GNN/LLM architectures on GRetriever while performing grid searches across relevant architecture parameters and datasets.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/g_retriever_utils/README.md#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nbenchmark_model_archs_rag.py\n```\n\n----------------------------------------\n\nTITLE: Installing PyG with Additional Libraries for PyTorch 2.5\nDESCRIPTION: This command installs PyG's additional extension libraries (pyg_lib, torch_scatter, torch_sparse, torch_cluster, torch_spline_conv) for PyTorch 2.5.0/2.5.1, using pre-built binaries from the specified wheel URL.  The `${CUDA}` placeholder must be replaced with the appropriate CUDA version (cpu, cu118, cu121, or cu124) corresponding to your PyTorch installation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+${CUDA}.html\n```\n\n----------------------------------------\n\nTITLE: Using DynamicEdgeConv Layer in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to initialize and use the DynamicEdgeConv layer. It creates a layer with 3 input channels, 128 output channels, and 6 nearest neighbors.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_gnn.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nconv = DynamicEdgeConv(3, 128, k=6)\nx = conv(x, batch)\n```\n\n----------------------------------------\n\nTITLE: Using SparseTensor with Existing GNN Layers in PyTorch Geometric\nDESCRIPTION: This code snippet shows how to use SparseTensor with existing GNN layers in PyTorch Geometric. It demonstrates that both edge_index and SparseTensor formats are supported, but the SparseTensor needs to be transposed when used.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nconv = GCNConv(16, 32)\nout1 = conv(x, edge_index)\nout2 = conv(x, adj.t())\nassert torch.allclose(out1, out2)\n\nconv = GINConv(nn=Sequential(Linear(16, 32), ReLU(), Linear(32, 32)))\nout1 = conv(x, edge_index)\nout2 = conv(x, adj.t())\nassert torch.allclose(out1, out2)\n```\n\n----------------------------------------\n\nTITLE: Dataset Splitting and Shuffling in PyTorch Geometric\nDESCRIPTION: Shows how to split datasets into training and testing sets using slicing operations, and how to shuffle datasets before splitting.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_dataset = dataset[:540]\n>>> ENZYMES(540)\n\ntest_dataset = dataset[540:]\n>>> ENZYMES(60)\n\ndataset = dataset.shuffle()\n>>> ENZYMES(600)\n\nperm = torch.randperm(len(dataset))\ndataset = dataset[perm]\n>> ENZYMES(600)\n```\n\n----------------------------------------\n\nTITLE: Importing Node2Vec and Loading Data in Python\nDESCRIPTION: This snippet shows how to import the Node2Vec module from PyTorch Geometric and load the Cora dataset using the Planetoid class.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/shallow_node_embeddings.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.nn import Node2Vec\n\ndata = Planetoid('./data/Planetoid', name='Cora')[0]\n```\n\n----------------------------------------\n\nTITLE: Running PyTorch Geometric Example in Singularity Container\nDESCRIPTION: Commands for downloading a PyTorch Geometric example (GAT) and running it in a Singularity container, with options for CPU and GPU execution.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docker/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nwget https://raw.githubusercontent.com/pyg-team/pytorch_geometric/master/examples/gat.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nsingularity exec geometric.sif python3 gat.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nsingularity exec --nv geometric.sif python3 gat.py\n```\n\n----------------------------------------\n\nTITLE: Combining Local and Global Outputs in GPS Layer (Python)\nDESCRIPTION: This snippet shows how to combine the outputs from local MPNN and global attention in the GPS layer. It sums the outputs, applies an MLP, and performs normalization if specified.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nout = sum(hs)\n\nout = out + self.mlp(out)\nif self.norm3 is not None:\n    if self.norm_with_batch:\n        out = self.norm3(out, batch=batch)\n    else:\n        out = self.norm3(out)\n```\n\n----------------------------------------\n\nTITLE: Loading TUDataset in PyTorch Geometric\nDESCRIPTION: Shows how to initialize and explore the ENZYMES dataset from TUDataset, which contains 600 graphs within 6 classes, and demonstrates how to access individual graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import TUDataset\n\ndataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n>>> ENZYMES(600)\n\nlen(dataset)\n>>> 600\n\ndataset.num_classes\n>>> 6\n\ndataset.num_node_features\n>>> 3\n```\n\n----------------------------------------\n\nTITLE: Testing PairData Batching Behavior with DataLoader\nDESCRIPTION: Complete example demonstrating how to batch PairData objects using DataLoader and verify the correct batching behavior. The example creates two identical PairData objects with different numbers of nodes in source and target graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.loader import DataLoader\n\nx_s = torch.randn(5, 16)  # 5 nodes.\nedge_index_s = torch.tensor([\n    [0, 0, 0, 0],\n    [1, 2, 3, 4],\n])\n\nx_t = torch.randn(4, 16)  # 4 nodes.\nedge_index_t = torch.tensor([\n    [0, 0, 0],\n    [1, 2, 3],\n])\n\ndata = PairData(x_s=x_s, edge_index_s=edge_index_s,\n                x_t=x_t, edge_index_t=edge_index_t)\n\ndata_list = [data, data]\nloader = DataLoader(data_list, batch_size=2)\nbatch = next(iter(loader))\n\nprint(batch)\n>>> PairDataBatch(x_s=[10, 16], edge_index_s=[2, 8],\n                  x_t=[8, 16], edge_index_t=[2, 6])\n\nprint(batch.edge_index_s)\n>>> tensor([[0, 0, 0, 0, 5, 5, 5, 5],\n            [1, 2, 3, 4, 6, 7, 8, 9]])\n\nprint(batch.edge_index_t)\n>>> tensor([[0, 0, 0, 4, 4, 4],\n            [1, 2, 3, 5, 6, 7]])\n```\n\n----------------------------------------\n\nTITLE: Simple Data Loading Example in PyTorch Geometric\nDESCRIPTION: Example showing how to create a DataLoader from a list of Data objects without using Dataset classes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/create_dataset.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\n\ndata_list = [Data(...), ..., Data(...)]\nloader = DataLoader(data_list, batch_size=32)\n```\n\n----------------------------------------\n\nTITLE: Using SAGEConv with Lazy Initialization\nDESCRIPTION: Example of lazy initialization of message passing layers\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/cheatsheet.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nSAGEConv(in_channels=-1, out_channels=64)\n```\n\n----------------------------------------\n\nTITLE: Running Distributed Training on Node 1\nDESCRIPTION: This Bash command runs the distributed training example on the second node (rank 1). It uses the same parameters as node 0 but with a different node rank.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/pyg/README.md#2025-04-21_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\npython node_obg_cpu.py \\\n  --dataset=ogbn-products \\\n  --dataset_root_dir=<partition folder directory> \\\n  --num_nodes=2 \\\n  --node_rank=1 \\\n  --master_addr=<master ip>\n```\n\n----------------------------------------\n\nTITLE: Importing GCN in PyTorch Geometric\nDESCRIPTION: Example of importing and using the GCNConv layer from PyTorch Geometric. GCNConv implements the Graph Convolutional Network model as described by Kipf and Welling.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nfrom torch_geometric.nn import GCNConv\n\n# Usage example (pseudo-code)\nself.conv1 = GCNConv(in_channels, hidden_channels)\nself.conv2 = GCNConv(hidden_channels, out_channels)\n```\n\n----------------------------------------\n\nTITLE: Setting up device, model, optimizer, and scheduler in PyTorch\nDESCRIPTION: This snippet initializes the device (CUDA if available, otherwise CPU), defines a GPS model with specified parameters, creates an Adam optimizer with learning rate and weight decay, and sets up a ReduceLROnPlateau scheduler for dynamic learning rate adjustment based on validation performance. This is a common setup for training PyTorch models, particularly for graph neural networks where GPU acceleration is often beneficial.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    attn_kwargs = {'dropout': 0.5}\n    model = GPS(channels=64, pe_dim=8, num_layers=10, attn_type=args.attn_type,\n                attn_kwargs=attn_kwargs).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20,\n                                min_lr=0.00001)\n```\n\n----------------------------------------\n\nTITLE: Using String-Based Aggregation Resolution in PyTorch Geometric\nDESCRIPTION: Shows how to resolve aggregation functions from strings using PyG's lookup table functionality in a MessagePassing module.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MyConv(MessagePassing):\n    def __init__(self, ...):\n        super().__init__(aggr=\"median\")\n```\n\n----------------------------------------\n\nTITLE: Creating Jittable GNN Operator with Type Comment\nDESCRIPTION: This snippet shows an alternative way to create a jittable GNN operator by declaring the types of propagation arguments as a comment inside the module. This method also ensures compatibility with torch.jit.script.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/jit.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\nfrom torch import Tensor\nfrom torch_geometric.nn import MessagePassing\n\nclass MyConv(MessagePassing):\n    def forward(\n        self,\n        x: Tensor,\n        edge_index: Tensor,\n        edge_weight: Optional[Tensor] = None,\n    ) -> Tensor:\n        # propagate_type: (x: Tensor, edge_weight: Optional[Tensor])\n        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n```\n\n----------------------------------------\n\nTITLE: Profiling WebQSP Dataset with NVTX (Python)\nDESCRIPTION: This Python script shows how to use NVTX for profiling the WebQSP (Web Questions Semantic Parsing) dataset. It demonstrates performance analysis techniques specific to this dataset in the context of LLM and GNN co-training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/nvtx_examples/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nnvtx_webqsp_example.py\n```\n\n----------------------------------------\n\nTITLE: Training Loop for PointNet Model in PyTorch Geometric\nDESCRIPTION: This snippet defines the training loop for the PointNet model. It iterates through the training data loader, performs a forward pass, calculates the loss using CrossEntropyLoss, performs backpropagation, and updates the model parameters using the Adam optimizer.  The function returns the average loss over the training dataset.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/point_cloud.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef train():\n    model.train()\n\n    total_loss = 0\n    for data in train_loader:\n        optimizer.zero_grad()\n        logits = model(data.pos, data.edge_index, data.batch)\n        loss = criterion(logits, data.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += float(loss) * data.num_graphs\n\n    return total_loss / len(train_loader.dataset)\n```\n\n----------------------------------------\n\nTITLE: Using SAGEConv with Bipartite Graphs\nDESCRIPTION: Example of message passing in bipartite graphs with different feature dimensionalities\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/cheatsheet.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nSAGEConv(in_channels=(16, 32), out_channels=64)\n```\n\n----------------------------------------\n\nTITLE: Loading User Data in PyTorch Geometric\nDESCRIPTION: This code loads user data from the ratings CSV file, creating a mapping for user IDs without any additional features.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n_, user_mapping = load_node_csv(rating_path, index_col='userId')\n```\n\n----------------------------------------\n\nTITLE: Partitioning Graph Data for Distributed Training\nDESCRIPTION: This Python command partitions the ogbn-products dataset into two parts using the partition_graph.py script. It prepares the data for distributed training across multiple nodes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/pyg/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\npython partition_graph.py --dataset=ogbn-products --root_dir=../../../data --num_partitions=2\n```\n\n----------------------------------------\n\nTITLE: Using GCNConv with Static Graphs\nDESCRIPTION: Example of message passing in static graphs with batched input\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/cheatsheet.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nGCNConv(...).forward(x, edge_index)\n```\n\n----------------------------------------\n\nTITLE: Isolating Main Process from DataLoader Workers with numactl\nDESCRIPTION: Command to run a Python script with the main process bound to specific CPU cores that don't overlap with DataLoader worker cores. The example also uses local memory allocation for better performance.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nnumactl -C 4-(N-1) --localalloc python …\n```\n\n----------------------------------------\n\nTITLE: Interacting with a Custom GraphStore in Python\nDESCRIPTION: Shows how to add and access edge indices in a custom GraphStore implementation. It demonstrates putting edges into the store and then retrieving them as row and column tensors.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/remote.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngraph_store = CustomGraphStore()\n\nedge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])\n\n# Put edges:\ngraph_store['edge', 'coo'] = coo\n\n# Access edges:\nrow, col = graph_store['edge', 'coo']\nassert torch.equal(row, edge_index[0])\nassert torch.equal(col, edge_index[1])\n```\n\n----------------------------------------\n\nTITLE: Loading ZINC Dataset with Random Walk Positional Encoding (Python)\nDESCRIPTION: This code snippet demonstrates how to load the ZINC dataset with random walk positional encoding using PyTorch Geometric's DataLoader.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/graph_transformer.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntransform = T.AddRandomWalkPE(walk_length=20, attr_name='pe')\ntrain_dataset = ZINC(path, subset=True, split='train', pre_transform=transform)\nval_dataset = ZINC(path, subset=True, split='val', pre_transform=transform)\ntest_dataset = ZINC(path, subset=True, split='test', pre_transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64)\ntest_loader = DataLoader(test_dataset, batch_size=64)\n```\n\n----------------------------------------\n\nTITLE: Examining Node Masks in Cora Dataset\nDESCRIPTION: Shows how to access the single graph in the Cora dataset and examine its train, validation, and test masks which define node splits for semi-supervised learning.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndata = dataset[0]\n>>> Data(edge_index=[2, 10556], test_mask=[2708],\n         train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n\ndata.is_undirected()\n>>> True\n\ndata.train_mask.sum().item()\n>>> 140\n\ndata.val_mask.sum().item()\n>>> 500\n\ndata.test_mask.sum().item()\n>>> 1000\n```\n\n----------------------------------------\n\nTITLE: Initializing PyTorch Distributed Process Group\nDESCRIPTION: This function initializes the PyTorch distributed process group using the NCCL backend. It uses the world size and rank obtained from the environment.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef run(world_size: int, rank: int, local_rank: int):\n    dist.init_process_group('nccl', world_size=world_size, rank=rank)\n```\n\n----------------------------------------\n\nTITLE: Installing TorchScatter dependency using CMake and Make\nDESCRIPTION: This snippet demonstrates the process of cloning, configuring, and installing the TorchScatter library, which is a prerequisite for using PyG in C++. It uses CMake for configuration and Make for building and installation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cpp/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/rusty1s/pytorch_scatter.git\ncd pytorch_scatter\nmkdir build && cd build\ncmake -DWITH_CUDA=on -DCMAKE_PREFIX_PATH=\"...\" ..\nmake\n(sudo) make install\n```\n\n----------------------------------------\n\nTITLE: Implementing Node2Vec Training Function in Python\nDESCRIPTION: This function defines the training loop for the Node2Vec model, using the contrastive loss function provided by the model.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/shallow_node_embeddings.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef train():\n    model.train()\n    total_loss = 0\n    for pos_rw, neg_rw in loader:\n        optimizer.zero_grad()\n        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n```\n\n----------------------------------------\n\nTITLE: Implementing Sequence Encoder for NLP Features in PyTorch\nDESCRIPTION: This class implements a sequence encoder using the sentence-transformers library to convert text data into numerical embeddings. It's used to encode movie titles into feature vectors.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass SequenceEncoder:\n    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n        self.device = device\n        self.model = SentenceTransformer(model_name, device=device)\n\n    @torch.no_grad()\n    def __call__(self, df):\n        x = self.model.encode(df.values, show_progress_bar=True,\n                              convert_to_tensor=True, device=self.device)\n        return x.cpu()\n```\n\n----------------------------------------\n\nTITLE: Defining MetaPath for MetaPath2Vec in Python\nDESCRIPTION: This snippet demonstrates how to define a metapath for use with the MetaPath2Vec model, specifying the sequence of node and edge types for random walk sampling in heterogeneous graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/shallow_node_embeddings.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmetapath = [\n    ('author', 'writes', 'paper'),\n    ('paper', 'published_in', 'venue'),\n    ('venue', 'publishes', 'paper'),\n    ('paper', 'written_by', 'author'),\n]\n```\n\n----------------------------------------\n\nTITLE: Running Distributed Training on Multiple Nodes with CUDA in Bash\nDESCRIPTION: These commands show how to run the distributed training script on two separate nodes, each using two GPUs. It specifies the number of nodes, node rank, master address, dataset, and model parameters.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/graphlearn_for_pytorch/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Node 0:\nCUDA_VISIBLE_DEVICES=0,1 python dist_train_sage_supervised.py \\\n  --num_nodes=2 --node_rank=0 --master_addr=localhost \\\n  --dataset=ogbn-products --dataset_root_dir=../../../data/ogbn-products \\\n  --in_channel=100 --out_channel=47\n\n# Node 1:\nCUDA_VISIBLE_DEVICES=2,3 python dist_train_sage_supervised.py \\\n  --num_nodes=2 --node_rank=1 --master_addr=localhost \\\n  --dataset=ogbn-products --dataset_root_dir=../../../data/ogbn-products \\\n  --in_channel=100 --out_channel=47\n```\n\n----------------------------------------\n\nTITLE: Setting Up Edge Indices and Labels in PyTorch Geometric\nDESCRIPTION: This snippet defines the edge indices and labels for a heterogeneous graph using the HeteroData structure from PyTorch Geometric. It initializes the 'rates' relationships between 'user' and 'movie', ensuring the correct data types are maintained throughout, particularly for indexing with long integers.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndata['user', 'rates', 'movie'].edge_index = edge_index\n    data['user', 'rates', 'movie'].edge_label = edge_label\n```\n\n----------------------------------------\n\nTITLE: Executing Training Script with SLURM (Bash)\nDESCRIPTION: This command executes the Python training script using the srun command, which will start the specified number of task replicas.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsrun python distributed_sampling_multinode.py\n```\n\n----------------------------------------\n\nTITLE: Installing PyG Extensions for PyTorch 2.6 with CUDA 12.6\nDESCRIPTION: Specific pip command for installing PyG extension libraries for PyTorch 2.6.* with CUDA 12.6 support.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu126.html\n```\n\n----------------------------------------\n\nTITLE: Captum-based Explainer Example for Node Classification in PyTorch Geometric\nDESCRIPTION: This example demonstrates a Captum-based explainer for node classification tasks. Captum is a model interpretability library, and this example shows how to integrate it with PyG to explain node classification predictions.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/explain/README.md#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n\"./captum_explainer.py\"\n```\n\n----------------------------------------\n\nTITLE: Launching Distributed Training with Python Script\nDESCRIPTION: This Python command uses a launch script to run distributed training across multiple nodes. It specifies various parameters including workspace, dataset, and node configuration.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/pyg/README.md#2025-04-21_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\npython launch.py \\\n  --workspace {workspace}/pytorch_geometric \\\n  --num_nodes 2 \\\n  --dataset_root_dir {dataset_dir}/mag/2-parts \\\n  --dataset ogbn-mag \\\n  --batch_size 1024 \\\n  --learning_rate 0.0004 \\\n  --part_config {dataset_dir}/mag/2-parts/ogbn-mag-partitions/META.json \\\n  --ip_config {workspace}/pytorch_geometric/ip_config.yaml \\\n'cd /home/user_xxx; source {conda_envs}/bin/activate; cd {workspace}/pytorch_geometric; {conda_envs}/bin/python \\\n{workspace}/pytorch_geometric/examples/pyg/node_ogb_cpu.py --dataset=ogbn-mag --logging --progress_bar --ddp_port=11111'\n```\n\n----------------------------------------\n\nTITLE: Converting SparseTensor back to edge_index format in PyTorch Geometric\nDESCRIPTION: This code snippet demonstrates how to convert a SparseTensor back to the edge_index format in PyTorch Geometric. This can be useful when certain operations still require the edge_index format.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/sparse_tensor.rst#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nrow, col, edge_attr = adj_t.t().coo()\nedge_index = torch.stack([row, col], dim=0)\n```\n\n----------------------------------------\n\nTITLE: Using numactl for CPU Binding\nDESCRIPTION: Shows the numactl command syntax for binding processes to specific physical CPUs. This allows for controlling which CPU cores the process can run on.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\n--physcpubind=<cpus>, -C <cpus>  or --cpunodebind=<nodes>, -N <nodes>\n```\n\n----------------------------------------\n\nTITLE: Evaluating Explanations with Unfaithfulness Metric\nDESCRIPTION: Demonstrates how to evaluate the quality of an explanation using the unfaithfulness metric from PyG's explain.metric module. This metric assesses how accurate the explanation is compared to the model's true behavior.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/explain.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.explain import unfaithfulness\n\nmetric = unfaithfulness(explainer, explanation)\nprint(metric)\n```\n\n----------------------------------------\n\nTITLE: Installing PyG Extensions for PyTorch 2.5 with CUDA 11.8\nDESCRIPTION: Specific pip command for installing PyG extension libraries for PyTorch 2.5.* with CUDA 11.8 support.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.5.0+cu118.html\n```\n\n----------------------------------------\n\nTITLE: Partitioning OGBN Dataset for Distributed Training in Python\nDESCRIPTION: This code snippet demonstrates how to partition the ogbn-products dataset into two partitions using a Python script. It's a preparatory step for distributed training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/graphlearn_for_pytorch/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython partition_ogbn_dataset.py --dataset=ogbn-products --root_dir=../../../data/ogbn-products --num_partitions=2\n```\n\n----------------------------------------\n\nTITLE: Installing PyG via pip\nDESCRIPTION: Basic installation command for PyTorch Geometric using pip. This installs the core package without additional dependencies.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install torch_geometric\n```\n\n----------------------------------------\n\nTITLE: Accessing Node Split Masks in PyTorch Geometric\nDESCRIPTION: Shows how to access the train, validation, and test masks after applying the RandomNodeSplit transformation. These masks can be used to filter nodes for their respective purposes in the model training pipeline.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/dataset_splitting.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nnode_splits.train_mask\n>>> tensor([ True, False, False, False, True, True, False, False])\nnode_splits.val_mask\n>>> tensor([False, False, False, False, False, False, True, True])\nnode_splits.test_mask\n>>> tensor([False, True, True, True, False, False, False, False])\n```\n\n----------------------------------------\n\nTITLE: Setting Intel OMP Environment Variables for CPU Affinity\nDESCRIPTION: Shows how to set the KMP_AFFINITY environment variable to bind Intel OpenMP threads to specific physical cores. This affects applications using Intel's libiomp5 library.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nexport KMP_AFFINITY=granularity=fine,proclist=[0-<physical_cores_num-1>],explicit\n```\n\n----------------------------------------\n\nTITLE: Printing HeteroData Object to Console in PyTorch Geometric\nDESCRIPTION: This snippet creates a new HeteroData object with specified node counts for users and movies and prints the structure to the console. It provides insights into the dimensions of the underlying tensors for the graph structure, enhancing understanding of how the graph data is organized.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprint(data)\n    HeteroData(\n      user={ num_nodes=610 },\n      movie={ x=[9742, 404] },\n      (user, rates, movie)={\n        edge_index=[2, 100836],\n        edge_label=[100836, 1]\n      }\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset and GNN Hyperparameters for Grid Search\nDESCRIPTION: This configuration specifies the search space for dataset and GNN hyperparameters. It includes dataset format, name, task type, and transductive settings. For GNN architecture, it defines ranges for pre-message passing layers, message passing layers, post-message passing layers, stage type, and aggregation method.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/graphgym/grids/example.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# Format for each row: name in config.py; alias; range to search\n# No spaces, except between these 3 fields\n# Line breaks are used to union different grid search spaces\n# Feel free to add '#' to add comments\n\n\n# (1) dataset configurations\ndataset.format format ['PyG']\ndataset.name dataset ['TU_ENZYMES','TU_PROTEINS']\ndataset.task task ['graph']\ndataset.transductive trans [False]\n# (2) The recommended GNN design space, 96 models in total\ngnn.layers_pre_mp l_pre [1,2]\ngnn.layers_mp l_mp [2,4,6,8]\ngnn.layers_post_mp l_post [2,3]\ngnn.stage_type stage ['skipsum','skipconcat']\ngnn.agg agg ['add','mean','max']\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch Geometric with pip\nDESCRIPTION: This code snippet demonstrates the basic installation of the PyTorch Geometric library using pip. It installs the core PyG package without any additional or optional dependencies, making it a lightweight and straightforward installation for basic GNN functionalities.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install torch_geometric\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Node Feature Retrieval in PyTorch Geometric\nDESCRIPTION: This code snippet demonstrates how to asynchronously retrieve node features using a LocalFeatureStore in PyTorch Geometric. It creates a LocalFeatureStore instance, defines an async function to lookup features for specific node IDs, and uses the to_asyncio_future function to handle the asynchronous operation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/distributed_pyg.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.distributed import LocalFeatureStore\nfrom torch_geometric.distributed.event_loop import to_asyncio_future\n\nfeature_store = LocalFeatureStore(...)\n\nasync def get_node_features():\n    # Create a `LocalFeatureStore` instance:\n\n    # Retrieve node features for specific node IDs:\n    node_id = torch.tensor([1])\n    future = feature_store.lookup_features(node_id)\n\n    return await to_asyncio_future(future)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for PyG Benchmark Execution\nDESCRIPTION: Configures environment variables necessary for optimal performance during PyG benchmark execution, including DNNL, KMP, and jemalloc settings.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/inference/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsource activate env_name\nexport DNNL_PRIMITIVE_CACHE_CAPACITY=1024\nexport KMP_BLOCKTIME=1\nexport KMP_AFFINITY=granularity=fine,compact,1,0\n\njemalloc_lib=${workspace}/jemalloc-bin/lib/libjemalloc.so\nexport LD_PRELOAD=\"$jemalloc_lib\"\nexport MALLOC_CONF=\"oversize_threshold:1,background_thread:true,metadata_thp:auto,dirty_decay_ms:9000000000,muzzy_decay_ms:9000000000\"\n```\n\n----------------------------------------\n\nTITLE: Initializing DDP for Distributed Training in PyTorch\nDESCRIPTION: This code snippet shows how to initialize the Distributed Data Parallel (DDP) group for distributed training in PyTorch. It uses the torch.distributed.init_process_group function to set up the communication backend, rank, world size, and initialization method.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/distributed_pyg.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ntorch.distributed.init_process_group(\n    backend='gloo',\n    rank=current_ctx.rank,\n    world_size=current_ctx.world_size,\n    init_method=f'tcp://{master_addr}:{ddp_port}',\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Identity Encoder for Numeric Data in PyTorch\nDESCRIPTION: This class implements a simple encoder that converts numeric data from a pandas DataFrame to a PyTorch tensor. It's used to encode rating values as edge attributes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass IdentityEncoder:\n    def __init__(self, dtype=None):\n        self.dtype = dtype\n\n    def __call__(self, df):\n        return torch.from_numpy(df.values).view(-1, 1).to(self.dtype)\n```\n\n----------------------------------------\n\nTITLE: Using GCNConv with SparseTensor in PyTorch Geometric\nDESCRIPTION: Example of using GCNConv with SparseTensor for message passing in PyTorch Geometric. This demonstrates the usage of the SparseTensor feature.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/gnn_cheatsheet.rst#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nGCNConv(...).forward(x, adj_t)\n```\n\n----------------------------------------\n\nTITLE: Installing PyG with Additional Libraries for PyTorch 2.6\nDESCRIPTION: This command installs PyG's additional extension libraries (pyg_lib, torch_scatter, torch_sparse, torch_cluster, torch_spline_conv) for PyTorch 2.6.0, using pre-built binaries from the specified wheel URL. The `${CUDA}` placeholder must be replaced with the appropriate CUDA version (cpu, cu118, cu124, or cu126) corresponding to your PyTorch installation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+${CUDA}.html\n```\n\n----------------------------------------\n\nTITLE: Generating Subgraphs for Multihop Dataset using GRetriever in Python\nDESCRIPTION: This Python script uses the sample remote backend in 'g_retriever_utils' to generate subgraphs for the multihop dataset. It demonstrates how to integrate the GRetriever functionality with the preprocessed multihop data for LLM and GNN co-training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/multihop_rag/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nrag_generate_multihop.py\n```\n\n----------------------------------------\n\nTITLE: Building Singularity Container for PyTorch Geometric\nDESCRIPTION: Command for building a Singularity container for PyTorch Geometric. This setup allows for running PyG in environments where Singularity is preferred over Docker.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docker/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo singularity build geometric.sif singularity\n```\n\n----------------------------------------\n\nTITLE: Running Containerized PyG with SLURM and Pyxis (Bash)\nDESCRIPTION: This command demonstrates how to run a PyG container using SLURM with the pyxis plugin. It specifies partition, nodes, tasks, GPUs, container name, image, and mounts.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsrun --partition=<partitionname> -N<num_nodes> --ntasks=<number of GPUS in total> --gpus-per-task=1 --gpu-bind=none --container-name=pyg-test --container-image=<image_url> --container-mounts='.:/workspace' python3 distributed_sampling_multinode.py\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU Quiver Example in Bash\nDESCRIPTION: This command runs a Python script for multi-GPU training with Quiver. It showcases distributed sampling, feature aggregation across multiple GPUs, and multi-GPU memory utilization for caching and replicating hot GNN data.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/quiver/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython multi_gpu_quiver.py\n```\n\n----------------------------------------\n\nTITLE: Generating Unique Subgraphs from WebQSP Dataset - Python\nDESCRIPTION: This script generates a unique set of subgraphs from the WebQSP dataset using a custom retrieval algorithm, which defaults to the provided FeatureStore and GraphStore.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/g_retriever_utils/README.md#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nrag_generate.py\n```\n\n----------------------------------------\n\nTITLE: Installing PyG with Specific CUDA Version via Anaconda\nDESCRIPTION: Conda command to enforce a specific CUDA version when installing PyG, useful when conda doesn't pick up the correct CUDA version.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nconda install pyg=*=*cu* -c pyg\n```\n\n----------------------------------------\n\nTITLE: Basic GraphSAGE Model Compilation with PyTorch\nDESCRIPTION: Shows how to define and compile a GraphSAGE model using torch.compile. The model is moved to the specified device before compilation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/compile.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.nn import GraphSAGE\n\nmodel = GraphSAGE(in_channels, hidden_channels, num_layers, out_channels)\nmodel = model.to(device)\n\nmodel = torch.compile(model)\n```\n\n----------------------------------------\n\nTITLE: Downloading MovieLens Dataset in Python\nDESCRIPTION: This snippet downloads the MovieLens dataset and extracts it to the current directory. It uses PyTorch Geometric's utility functions for downloading and extracting zip files.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.data import download_url, extract_zip\n\nurl = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\nextract_zip(download_url(url, '.'), '.')\n\nmovie_path = './ml-latest-small/movies.csv'\nrating_path = './ml-latest-small/ratings.csv'\n```\n\n----------------------------------------\n\nTITLE: Running Single-GPU Quiver Example in Bash\nDESCRIPTION: This command executes a Python script for single-GPU training using Quiver. It demonstrates GPU-based graph sampling, feature aggregation, and GNN data caching.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/quiver/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython single_gpu_quiver.py\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Benchmark\nDESCRIPTION: Configures environment variables including DNNL settings, KMP parameters, and jemalloc configuration for optimal performance.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/training/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsource activate env_name\nexport DNNL_PRIMITIVE_CACHE_CAPACITY=1024\nexport KMP_BLOCKTIME=1\nexport KMP_AFFINITY=granularity=fine,compact,1,0\n\njemalloc_lib=${workspace}/jemalloc-bin/lib/libjemalloc.so\nexport LD_PRELOAD=\"$jemalloc_lib\"\nexport MALLOC_CONF=\"oversize_threshold:1,background_thread:true,metadata_thp:auto,dirty_decay_ms:9000000000,muzzy_decay_ms:9000000000\"\n```\n\n----------------------------------------\n\nTITLE: Implementing a RAG Enabled FeatureStore - Python\nDESCRIPTION: This script serves as a starting point for building a custom RAG enabled FeatureStore, which manages features retrieved using a retrieval mechanism.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/g_retriever_utils/README.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nrag_feature_store.py\n```\n\n----------------------------------------\n\nTITLE: Checking CUDA Setup with PyTorch\nDESCRIPTION: Python command to verify if PyTorch can access CUDA. Returns True if CUDA is correctly set up with PyTorch.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\npython -c \"import torch; print(torch.cuda.is_available())\"\n>>> True\n```\n\n----------------------------------------\n\nTITLE: Alternate Method for Creating a Graph in PyTorch Geometric\nDESCRIPTION: Shows how to create the same graph using edge indices defined as a list of tuples that need to be transposed and made contiguous before passing to the Data constructor.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.data import Data\n\nedge_index = torch.tensor([[0, 1],\n                           [1, 0],\n                           [1, 2],\n                           [2, 1]], dtype=torch.long)\nx = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n\ndata = Data(x=x, edge_index=edge_index.t().contiguous())\n>>> Data(edge_index=[2, 4], x=[3, 1])\n```\n\n----------------------------------------\n\nTITLE: Model Execution with Planetoid Dataset\nDESCRIPTION: Demonstrates how to load a Planetoid dataset (Cora) and execute the compiled model on graph data.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/compile.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.datasets import Planetoid\n\ndataset = Planetoid(root, name=\"Cora\")\ndata = dataset[0].to(device)\n\nout = model(data.x, data.edge_index)\n```\n\n----------------------------------------\n\nTITLE: Applying Aggregation Operations to Sets of Elements\nDESCRIPTION: Shows how to apply aggregation operations to batches of sets with varying sizes using an index vector to map input elements to their output locations.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Feature matrix holding 1000 elements with 64 features each:\nx = torch.randn(1000, 64)\n\n# Randomly assign elements to 100 sets:\nindex = torch.randint(0, 100, (1000, ))\n\noutput = mean_aggr(x, index)  #  Output shape: [100, 64]\n```\n\n----------------------------------------\n\nTITLE: Running PyG Test Suite\nDESCRIPTION: Command to execute the main test suite for PyTorch Geometric (PyG).\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/runtime/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython main.py\n```\n\n----------------------------------------\n\nTITLE: Initializing GraphSAGE Model with DistributedDataParallel in PyG\nDESCRIPTION: Sets up the GraphSAGE model and wraps it with DistributedDataParallel for multi-GPU training. This enables automatic gradient synchronization across GPUs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_gpu_vanilla.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom torch.nn.parallel import DistributedDataParallel\nfrom torch_geometric.nn import GraphSAGE\n\ndef run(rank: int, world_size: int, dataset: Reddit):\n    ...\n\n    torch.manual_seed(12345)\n    model = GraphSAGE(\n        in_channels=dataset.num_features,\n        hidden_channels=256,\n        num_layers=2,\n        out_channels=dataset.num_classes,\n    ).to(rank)\n    model = DistributedDataParallel(model, device_ids=[rank])\n```\n\n----------------------------------------\n\nTITLE: Dual Socket CPU Separation with numactl\nDESCRIPTION: Shows how to run a Python process on cores of the second CPU socket while also prioritizing memory allocation on the same NUMA node. This reduces remote memory calls and improves performance for dual-socket systems.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nnumactl -C M-(N-1) -m 1 python …\n```\n\n----------------------------------------\n\nTITLE: Full Graph Compilation Configuration\nDESCRIPTION: Demonstrates how to enforce full graph compilation to detect potential graph breaks during optimization.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/compile.rst#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntorch.compile(model, fullgraph=True)\n```\n\n----------------------------------------\n\nTITLE: Installing Quiver for PyG in Bash\nDESCRIPTION: This command installs Quiver version 0.1.1 or higher using pip. It assumes that PyTorch and PyG are already installed.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/quiver/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install torch-quiver>=0.1.1\n```\n\n----------------------------------------\n\nTITLE: Documenting Model Summary in PyTorch Geometric\nDESCRIPTION: This snippet generates documentation for the summary module in PyTorch Geometric, including all its members.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_10\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: torch_geometric.nn.summary\n   :members:\n```\n\n----------------------------------------\n\nTITLE: Running Performance Benchmarks - PyTorch Command\nDESCRIPTION: Command to execute detailed performance benchmarks that include time measurements and memory usage information for graph classification methods.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ python main_performance.py\n```\n\n----------------------------------------\n\nTITLE: Installing PyG Extensions from Source\nDESCRIPTION: Pip commands to install PyG extension libraries from source code repositories when pre-built wheels are not available for specific versions.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npip install --verbose git+https://github.com/pyg-team/pyg-lib.git\npip install --verbose torch_scatter\npip install --verbose torch_sparse\npip install --verbose torch_cluster\npip install --verbose torch_spline_conv\n```\n\n----------------------------------------\n\nTITLE: Setting GNU OpenMP Environment Variables for CPU Affinity\nDESCRIPTION: Shows how to set the GOMP_CPU_AFFINITY environment variable to bind GNU OpenMP threads to specific physical cores. This affects applications using the libgomp library.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nexport GOMP_CPU_AFFINITY=\"0-<physical_cores_num-1>\"\n```\n\n----------------------------------------\n\nTITLE: Running Intel GPU Benchmark for PyTorch Geometric\nDESCRIPTION: Command to run a training benchmark on Intel XPUs using PyTorch Geometric with MPI. It specifies the number of XPUs, dataset, model, and number of epochs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/multi_gpu/training/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <n> python training_benchmark_xpu.py --dataset ogbn-products --model edge_cnn --num-epochs 3\n```\n\n----------------------------------------\n\nTITLE: Creating Jittable GNN Operator with Propagate Type Dictionary\nDESCRIPTION: This example demonstrates how to create a jittable GNN operator by declaring the types of propagation arguments using a propagate_type dictionary. This ensures compatibility with torch.jit.script.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/jit.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\nfrom torch import Tensor\nfrom torch_geometric.nn import MessagePassing\n\nclass MyConv(MessagePassing):\n    propagate_type = {'x': Tensor, 'edge_weight': Optional[Tensor] }\n\n    def forward(\n        self,\n        x: Tensor,\n        edge_index: Tensor,\n        edge_weight: Optional[Tensor] = None,\n    ) -> Tensor:\n        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n```\n\n----------------------------------------\n\nTITLE: Running the Compiled PyG C++ Executable\nDESCRIPTION: This command demonstrates how to run the compiled PyG C++ executable named 'hello-world'. It takes a PyTorch model file as an argument, which is expected to be in the parent directory.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cpp/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./hello-world ../model.pt\n```\n\n----------------------------------------\n\nTITLE: Averaging Node Features Using Scatter in PyTorch Geometric\nDESCRIPTION: This snippet demonstrates how to use the scatter function from PyG to average node features for each graph in a batch. It loads the ENZYMES dataset, creates a DataLoader, and performs the averaging operation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/get_started/introduction.rst#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom torch_geometric.utils import scatter\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.loader import DataLoader\n\ndataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nfor data in loader:\n    data\n    >>> DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32])\n\n    data.num_graphs\n    >>> 32\n\n    x = scatter(data.x, data.batch, dim=0, reduce='mean')\n    x.size()\n    >>> torch.Size([32, 21])\n```\n\n----------------------------------------\n\nTITLE: Installing OGB Dataset Package\nDESCRIPTION: Installs the Open Graph Benchmark (OGB) dataset package required for running the benchmarks.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/training/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install ogb\n```\n\n----------------------------------------\n\nTITLE: Profiling RAG Backend with NVTX (Python)\nDESCRIPTION: This Python script demonstrates how to use NVTX for profiling a RAG (Retrieval-Augmented Generation) Backend. It's an example of how to analyze performance in the context of the rag_generate.py script used in the project.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/nvtx_examples/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nnvtx_rag_backend_example.py\n```\n\n----------------------------------------\n\nTITLE: Running Graph Classification Benchmarks - PyTorch Command\nDESCRIPTION: Command to execute the main benchmark suite that evaluates various graph classification methods through 10-fold cross validation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/kernel/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ python main.py\n```\n\n----------------------------------------\n\nTITLE: Configuring and Building PyG C++ Project with CMake\nDESCRIPTION: These commands show how to configure and build the PyG C++ project using CMake. It includes setting the CMAKE_PREFIX_PATH to point to the required libraries (LibTorch, TorchScatter, and TorchSparse) and then building the project.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cpp/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncmake -DCMAKE_PREFIX_PATH=\"<PATH_TO_LIBTORCH>;<PATH_TO_TORCHSCATTER>;<PATH_TO_TORCH_SPARSE>\" ..\ncmake --build .\n```\n\n----------------------------------------\n\nTITLE: Running SplineCNN Classification\nDESCRIPTION: Command to execute the SplineCNN implementation for point cloud classification\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/points/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython spline_cnn.py\n```\n\n----------------------------------------\n\nTITLE: Running EdgeCNN Classification\nDESCRIPTION: Command to execute the EdgeCNN implementation for point cloud classification\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/points/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython edge_cnn.py\n```\n\n----------------------------------------\n\nTITLE: Importing ChebConv in PyTorch Geometric\nDESCRIPTION: Example of importing and using the ChebConv layer from PyTorch Geometric. ChebConv implements the Chebyshev Spectral Graph Convolutional Network as described by Defferrard et al.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nfrom torch_geometric.nn import ChebConv\n\n# Usage example (pseudo-code)\nself.conv1 = ChebConv(in_channels, hidden_channels, K=2)\nself.conv2 = ChebConv(hidden_channels, out_channels, K=2)\n```\n\n----------------------------------------\n\nTITLE: Installing PyG via Anaconda\nDESCRIPTION: Conda command for installing PyTorch Geometric from the PyG channel. Note that this is only available for PyTorch versions ≤2.5.0.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nconda install pyg -c pyg\n```\n\n----------------------------------------\n\nTITLE: Installing PyG Extensions with CUDA Support\nDESCRIPTION: Generic pip command to install PyG extension libraries with CUDA support. The command uses a URL template that needs to be configured with the specific PyTorch and CUDA versions.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\n```\n\n----------------------------------------\n\nTITLE: Benchmark Execution Command\nDESCRIPTION: Command to run benchmarks comparing eager mode vs compiled mode performance for basic GNN models.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/compile.rst#2025-04-21_snippet_4\n\nLANGUAGE: console\nCODE:\n```\npython test/nn/models/test_basic_gnn.py\n```\n\n----------------------------------------\n\nTITLE: Using Transforms with PyTorch Geometric Datasets\nDESCRIPTION: Example showing how to apply transforms to PyTorch Geometric data, demonstrating both implicit application via dataset initialization and explicit application to individual data objects. This example creates a composite transform that converts graphs to undirected and adds self-loops.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/transforms.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import TUDataset\n\ntransform = T.Compose([T.ToUndirected(), T.AddSelfLoops()])\n\ndataset = TUDataset(path, name='MUTAG', transform=transform)\ndata = dataset[0]  # Implicitly transform data on every access.\n\ndata = TUDataset(path, name='MUTAG')[0]\ndata = transform(data)  # Explicitly transform data.\n```\n\n----------------------------------------\n\nTITLE: Running MPNN Classification\nDESCRIPTION: Command to execute the MPNN (Message Passing Neural Network) implementation for point cloud classification\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/points/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython mpnn.py\n```\n\n----------------------------------------\n\nTITLE: Launching Distributed Training with Configuration File in Bash\nDESCRIPTION: This command demonstrates how to launch distributed training using a configuration file and the launch.py script. It specifies the config file, master address, and port for process group initialization.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/graphlearn_for_pytorch/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install paramiko\npip install click\napt install tmux\npython launch.py --config=dist_train_sage_sup_config.yml --master_addr=0.0.0.0 --master_port=11234\n```\n\n----------------------------------------\n\nTITLE: Configuring CPU Affinity with Socket Separation for PyTorch Geometric\nDESCRIPTION: This snippet shows a configuration that separates the data loader process and main process onto different CPU sockets. It uses similar environment variables as the previous configuration but adds socket-specific memory allocation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/cpu_affinity.rst#2025-04-21_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nLD_PRELOAD=(path)/libjemalloc.so (path)/libiomp5.so MALLOC_CONF=oversize_threshold:1,background_thread:true,metadata_thp:auto OMP_NUM_THREADS=(N-M) KMP_AFFINITY=granularity=fine,compact,1,0 KMP_BLOCKTIME=0 numactl -C <M-(N-1)> -m 1 python training_benchmark.py --cpu-affinity --num-workers ...\n```\n\n----------------------------------------\n\nTITLE: Checking CUDA Version for PyTorch\nDESCRIPTION: Python code snippet to check the CUDA version that PyTorch was installed with, necessary for selecting the correct extension wheels.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npython -c \"import torch; print(torch.version.cuda)\"\n>>> 12.6\n```\n\n----------------------------------------\n\nTITLE: Using GCNConv with SparseTensor\nDESCRIPTION: Example of using GCNConv with SparseTensor for message passing\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/cheatsheet.rst#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nGCNConv(...).forward(x, adj_t)\n```\n\n----------------------------------------\n\nTITLE: Reading CSV Files with Pandas in Python\nDESCRIPTION: This code snippet demonstrates how to read the downloaded CSV files using pandas and display the first few rows of each file.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/load_csv.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nprint(pd.read_csv(movie_path).head())\nprint(pd.read_csv(rating_path).head())\n```\n\n----------------------------------------\n\nTITLE: Running Distributed Training with Shell Script\nDESCRIPTION: This Bash command runs a shell script that contains all parameter settings for distributed training, simplifying the execution process.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/pyg/README.md#2025-04-21_snippet_6\n\nLANGUAGE: Bash\nCODE:\n```\n./run_dist.sh\n```\n\n----------------------------------------\n\nTITLE: Installing PyG Benchmark Suite with pip\nDESCRIPTION: Command to install the PyG benchmark suite in development mode. This allows users to run the benchmarks while making changes to the codebase.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install -e .\n```\n\n----------------------------------------\n\nTITLE: Checking PyTorch Version\nDESCRIPTION: Python code snippet to check the installed PyTorch version, which is required before installing PyG extensions.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npython -c \"import torch; print(torch.__version__)\"\n>>> 2.6.0\n```\n\n----------------------------------------\n\nTITLE: Installing Intel oneAPI Base Toolkit Components for PyTorch Geometric\nDESCRIPTION: Bash commands to install necessary Intel oneAPI components including DPC++ Compiler, Math Kernel Library, and Collective Communications Library for running PyTorch Geometric on Intel GPUs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/multi_gpu/training/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install -y intel-oneapi-dpcpp-cpp-2024.1=2024.1.0-963 intel-oneapi-mkl-devel=2024.1.0-691 intel-oneapi-ccl-devel=2021.12.0-309\npip install oneccl_bind_pt==2.1.300+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\nsource /opt/intel/oneapi/setvars.sh\n```\n\n----------------------------------------\n\nTITLE: Implementing a RAG Enabled GraphStore - Python\nDESCRIPTION: This script provides a foundation for implementing a custom RAG enabled GraphStore to manage graph-related data for use with retrieval systems.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/g_retriever_utils/README.md#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nrag_graph_store.py\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch Geometric Nightly Build\nDESCRIPTION: This command installs the nightly version of the PyTorch Geometric library. Nightly builds provide access to the latest features and bug fixes but may be less stable than official releases. This installation is suitable for users who want to experiment with cutting-edge functionalities.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npip install pyg-nightly\n```\n\n----------------------------------------\n\nTITLE: Setting Network Interface for Multi-node Communication on Other Nodes\nDESCRIPTION: These Bash commands set the network interface for multi-node communication on non-master nodes using environment variables.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/pyg/README.md#2025-04-21_snippet_4\n\nLANGUAGE: Bash\nCODE:\n```\nexport TP_SOCKET_IFNAME=$(ip route get $MASTER_ADDR | grep -oP '(?<=dev )[^ ]+')\nexport GLOO_SOCKET_IFNAME=$TP_SOCKET_IFNAME\n```\n\n----------------------------------------\n\nTITLE: Documenting DataParallel Layers in PyTorch Geometric\nDESCRIPTION: This snippet generates documentation for the data_parallel module in PyTorch Geometric, including all its members.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_8\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: torch_geometric.nn.data_parallel\n   :members:\n```\n\n----------------------------------------\n\nTITLE: Verifying NVCC Availability\nDESCRIPTION: Command to check if the NVIDIA CUDA Compiler (nvcc) is accessible and to verify its version.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnvcc --version\n>>> 11.8\n```\n\n----------------------------------------\n\nTITLE: Documenting Model Transformation Classes in PyTorch Geometric\nDESCRIPTION: This section documents the Transformer class from torch_geometric.nn.fx module, excluding certain members. It also includes documentation for to_hetero and to_hetero_with_bases functions.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_7\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. autoclass:: torch_geometric.nn.fx.Transformer\n   :members:\n   :undoc-members:\n   :exclude-members: graph, find_by_target, find_by_name\n\n.. autofunction:: torch_geometric.nn.to_hetero_transformer.to_hetero\n\n.. autofunction:: torch_geometric.nn.to_hetero_with_bases_transformer.to_hetero_with_bases\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch Geometric from Master Branch\nDESCRIPTION: This command installs PyTorch Geometric directly from the master branch of its GitHub repository. This provides the absolute latest version of the code, including unreleased features and potentially unstable changes.  This is intended for developers or users who need the very latest updates and are comfortable with potential instability.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npip install git+https://github.com/pyg-team/pytorch_geometric.git\n```\n\n----------------------------------------\n\nTITLE: Utility Functions for Knowledge Graph Triplets - Python\nDESCRIPTION: This script includes utility functions for efficiently loading Knowledge Graph Triplets into defined backends such as FeatureStore and GraphStore.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/g_retriever_utils/README.md#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nrag_backend_utils.py\n```\n\n----------------------------------------\n\nTITLE: Downloading Multihop Dataset Components in Bash\nDESCRIPTION: This bash script downloads all the components of the multihop dataset. It's a crucial first step in the data preparation process for LLM and GNN co-training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/multihop_rag/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmultihop_download.sh\n```\n\n----------------------------------------\n\nTITLE: Generating Documentation for Helper Functions in PyTorch Geometric\nDESCRIPTION: This snippet uses Sphinx autosummary to create documentation for helper functions in the torch_geometric.data module.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/data.rst#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n\n   {% for name in torch_geometric.data.helper_functions %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Running Distributed Training on Node 0\nDESCRIPTION: This Bash command runs the distributed training example on the first node (rank 0). It specifies the dataset, partition directory, number of nodes, and master address for coordination.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/pyg/README.md#2025-04-21_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\npython node_ogb_cpu.py \\\n  --dataset=ogbn-products \\\n  --dataset_root_dir=<partition folder directory> \\\n  --num_nodes=2 \\\n  --node_rank=0 \\\n  --master_addr=<master ip>\n```\n\n----------------------------------------\n\nTITLE: Running the Complete Benchmark Suite in Bash\nDESCRIPTION: A bash command to execute the entire test suite of graph neural network benchmarks. This will run all the individual model evaluation scripts (GCN, GAT, Cheby, SGC, ARMA, APPNP) on citation network datasets.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/citation/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./run.sh\n```\n\n----------------------------------------\n\nTITLE: Preparing Data for Papers 100M Dataset in Python\nDESCRIPTION: This snippet provides instructions for downloading the ogbn-papers100M dataset, extracting it, and converting it to a format compatible with Kùzu. It then creates a Kùzu database instance and loads the data into it.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/kuzu/papers_100M/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npython prepare_data.py\n```\n\n----------------------------------------\n\nTITLE: Setting up CUDA Library Path Environment Variables\nDESCRIPTION: Bash commands to add CUDA to library path environment variables, specific to Linux (LD_LIBRARY_PATH) and macOS (DYLD_LIBRARY_PATH).\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\necho $LD_LIBRARY_PATH\n>>> /usr/local/cuda/lib64:...\n\nexport DYLD_LIBRARY_PATH=/usr/local/cuda/lib:$DYLD_LIBRARY_PATH\necho $DYLD_LIBRARY_PATH\n>>> /usr/local/cuda/lib:...\n```\n\n----------------------------------------\n\nTITLE: Running nsys Profiler on Python Files with NVTX Calls (Bash)\nDESCRIPTION: This bash script runs the nsys profiler on a given Python file that contains NVTX calls. It's used for performance analysis of Python scripts in the context of LLM and GNN co-training.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/llm/nvtx_examples/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnvtx_run.sh\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for PyTorch Geometric Sampler\nDESCRIPTION: ReStructuredText documentation template that defines the structure for PyTorch Geometric's sampler module documentation, including module references and class documentation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/sampler.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\ntorch_geometric.sampler\n=======================\n\n.. currentmodule:: torch_geometric.sampler\n\n.. autosummary::\n   :nosignatures:\n   {% for cls in torch_geometric.sampler.classes %}\n     {{ cls }}\n   {% endfor %}\n\n.. autoclass:: torch_geometric.sampler.BaseSampler\n   :members:\n\n.. automodule:: torch_geometric.sampler\n   :members:\n   :exclude-members: sample_from_nodes, sample_from_edges, edge_permutation, BaseSampler\n```\n\n----------------------------------------\n\nTITLE: Installing and Configuring Jemalloc\nDESCRIPTION: Clones, builds, and installs jemalloc memory allocator for performance benchmarking from version 5.2.1.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/training/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd ${workspace}\ngit clone https://github.com/jemalloc/jemalloc.git\ncd jemalloc\ngit checkout 5.2.1\n./autogen.sh\n./configure --prefix=${workspace}/jemalloc-bin\nmake\nmake install\n```\n\n----------------------------------------\n\nTITLE: Generating Dataset Documentation in reStructuredText\nDESCRIPTION: This snippet uses reStructuredText to generate documentation for different types of datasets and generators in PyTorch Geometric. It includes sections for homogeneous, heterogeneous, hypergraph, and synthetic datasets, as well as graph and motif generators.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/datasets.rst#2025-04-21_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\ntorch_geometric.datasets\n========================\n\n.. contents:: Contents\n    :local:\n\nHomogeneous Datasets\n--------------------\n\n.. currentmodule:: torch_geometric.datasets\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/only_class.rst\n\n   {% for name in torch_geometric.datasets.homo_datasets %}\n     {{ name }}\n   {% endfor %}\n\nHeterogeneous Datasets\n----------------------\n\n.. currentmodule:: torch_geometric.datasets\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/only_class.rst\n\n   {% for name in torch_geometric.datasets.hetero_datasets %}\n     {{ name }}\n   {% endfor %}\n\nHypergraph Datasets\n-------------------\n\n.. currentmodule:: torch_geometric.datasets\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/only_class.rst\n\n   {% for name in torch_geometric.datasets.hyper_datasets %}\n     {{ name }}\n   {% endfor %}\n\nSynthetic Datasets\n------------------\n\n.. currentmodule:: torch_geometric.datasets\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/only_class.rst\n\n   {% for name in torch_geometric.datasets.synthetic_datasets %}\n     {{ name }}\n   {% endfor %}\n\nGraph Generators\n----------------\n\n.. currentmodule:: torch_geometric.datasets.graph_generator\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/only_class.rst\n\n   {% for name in torch_geometric.datasets.graph_generator.classes %}\n     {{ name }}\n   {% endfor %}\n\nMotif Generators\n----------------\n\n.. currentmodule:: torch_geometric.datasets.motif_generator\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/only_class.rst\n\n   {% for name in torch_geometric.datasets.motif_generator.classes %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Generating Autosummary for torch_geometric.loader Classes in Python\nDESCRIPTION: This code snippet uses a Jinja2 template to generate an autosummary of all classes in the torch_geometric.loader module. It iterates through the classes and lists them without signatures.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/loader.rst#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n{% for cls in torch_geometric.loader.classes %}\n  {{ cls }}\n{% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Autogenerating PyTorch Geometric Distributed Module Documentation in reStructuredText\nDESCRIPTION: A reStructuredText template that configures autogeneration of documentation for the torch_geometric.distributed module. It uses autosummary to list all classes and automodule to generate detailed member documentation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/distributed.rst#2025-04-21_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\ntorch_geometric.distributed\n===========================\n\n.. currentmodule:: torch_geometric.distributed\n\n.. autosummary::\n   :nosignatures:\n   {% for cls in torch_geometric.distributed.classes %}\n     {{ cls }}\n   {% endfor %}\n\n.. automodule:: torch_geometric.distributed\n    :members:\n```\n\n----------------------------------------\n\nTITLE: Using GCNConv with Static Graphs in PyTorch Geometric\nDESCRIPTION: Example of using GCNConv for message passing in static graphs in PyTorch Geometric. This shows how to handle input tensors with a batch dimension for static graphs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/gnn_cheatsheet.rst#2025-04-21_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nGCNConv(...).forward(x, edge_index)\n```\n\n----------------------------------------\n\nTITLE: Installing Autoconf for Jemalloc Setup in PyG Benchmarks\nDESCRIPTION: Installs the autoconf tool, which is required for setting up jemalloc, a memory allocator used in performance benchmarking.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/inference/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install autoconf\n```\n\n----------------------------------------\n\nTITLE: Generating Documentation for Data Objects in PyTorch Geometric\nDESCRIPTION: This snippet uses Sphinx autosummary to generate documentation for data classes in torch_geometric.data. It uses a custom template for inherited classes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/data.rst#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/inherited_class.rst\n\n   {% for name in torch_geometric.data.data_classes %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Core Binding for PyG Benchmark Execution\nDESCRIPTION: Demonstrates how to bind the benchmark execution to specific CPU cores for controlled performance testing.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/inference/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nOMP_NUM_THREADS=${CORES} numactl -C 0-${LAST_CORE} -m 0 CMD......\n```\n\n----------------------------------------\n\nTITLE: Sphinx Documentation Template for PyTorch Geometric Metrics\nDESCRIPTION: A reStructuredText (rst) documentation template that sets up the structure for PyTorch Geometric metrics documentation. It uses sphinx autosummary to generate documentation for link prediction metrics by iterating through available metric functions.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/metrics.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\ntorch_geometric.metrics\n=======================\n\n.. contents:: Contents\n    :local:\n\nLink Prediction Metrics\n-----------------------\n\n.. currentmodule:: torch_geometric.metrics\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/metrics.rst\n\n   {% for name in torch_geometric.metrics.link_pred_metrics %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Generating Class Documentation for PyTorch Geometric in RST\nDESCRIPTION: This RST code snippet sets up the structure for documenting a PyTorch Geometric class. It includes the class name, shows inheritance, and specifically documents the 'update', 'compute', and 'reset' methods.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/_templates/autosummary/metrics.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n{{ fullname | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n   :show-inheritance:\n   :members: update, compute, reset\n```\n\n----------------------------------------\n\nTITLE: Running DGL Test Suite\nDESCRIPTION: Commands to change directory to DGL and execute its test suite. This requires DGL to be installed first.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/runtime/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncd dgl\npython main.py\n```\n\n----------------------------------------\n\nTITLE: Generating Documentation for Database Classes in PyTorch Geometric\nDESCRIPTION: This snippet uses Sphinx autosummary to create documentation for database classes in torch_geometric.data, using a custom template for inherited classes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/data.rst#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/inherited_class.rst\n\n   {% for name in torch_geometric.data.database_classes %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Documenting PyTorch Lightning Wrappers in PyTorch Geometric\nDESCRIPTION: This snippet generates documentation for PyTorch Lightning wrapper classes in torch_geometric.data.lightning using Sphinx autosummary with a custom template.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/data.rst#2025-04-21_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n   :template: autosummary/only_class.rst\n\n   {% for name in torch_geometric.data.lightning.classes %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: RST Navigation Structure for GNN Documentation\nDESCRIPTION: Defines a navigation gallery structure in reStructuredText format for organizing GNN documentation sections, specifically for create_gnn and heterogeneous network documentation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/gnn_design.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. nbgallery::\n    :name: rst-gallery\n\n    create_gnn\n    heterogeneous\n```\n\n----------------------------------------\n\nTITLE: Configuring Grid Search Spaces in PyTorch Geometric\nDESCRIPTION: This snippet defines the grid search spaces for PyTorch Geometric configurations, including model architecture parameters such as pre-, main-, and post-message passing layers (l_pre, l_mp, l_post) and other settings like inner dimensions and learning rates. The parameters facilitate efficient hyperparameter tuning in machine learning models.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/graphgym/grids/pyg/example.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# Format for each row: name in config.py; alias; range to search\n# No spaces, except between these 3 fields\n# Line breaks are used to union different grid search spaces\n# Feel free to add '#' to add comments\n\ngnn.layers_pre_mp l_pre [1,2]\ngnn.layers_mp l_mp [2,4,6]\ngnn.layers_post_mp l_post [1,2]\ngnn.stage_type stage ['stack','skipsum','skipconcat']\ngnn.dim_inner dim [64]\noptim.base_lr lr [0.01]\noptim.max_epoch epoch [200]\n```\n\n----------------------------------------\n\nTITLE: Generating Autosummary for Dense Operations in PyTorch Geometric\nDESCRIPTION: This snippet uses Sphinx autosummary to generate documentation for classes in the torch_geometric.nn.dense module. It dynamically includes all pool classes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_6\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. currentmodule:: torch_geometric.nn.dense\n\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n\n   {% for name in torch_geometric.nn.dense.pool_classes %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Synthetic Datasets Table Template in RST\nDESCRIPTION: ReStructuredText table template for displaying statistics of synthetic graph datasets, including dataset name, number of graphs, nodes, edges, features, and classes/tasks.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/data_cheatsheet.rst#2025-04-21_snippet_2\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. list-table::\n    :widths: 50 10 10 10 10 10\n    :header-rows: 1\n\n    * - Name\n      - #graphs\n      - #nodes\n      - #edges\n      - #features\n      - #classes/#tasks\n```\n\n----------------------------------------\n\nTITLE: Setting up Sphinx Documentation for torch_geometric.utils Module\nDESCRIPTION: This code defines the Sphinx documentation structure for the torch_geometric.utils module. It uses autosummary and automodule directives to generate documentation for all available classes, with a template loop to iterate through all classes in the module.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/utils.rst#2025-04-21_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\ntorch_geometric.utils\n=====================\n\n.. currentmodule:: torch_geometric.utils\n\n.. autosummary::\n    :nosignatures:\n    {% for cls in torch_geometric.utils.classes %}\n      {{ cls }}\n    {% endfor %}\n\n.. automodule:: torch_geometric.utils\n    :members:\n```\n\n----------------------------------------\n\nTITLE: RST Table Definition for Heterogeneous Datasets in PyTorch Geometric\nDESCRIPTION: Defines a reStructuredText table for heterogeneous datasets showing node/edge counts, feature counts, and class/task counts. Uses Jinja2 templating to dynamically populate dataset information, including child type specifications.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/data_cheatsheet.rst#2025-04-21_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. list-table::\n    :widths: 50 30 10 10\n    :header-rows: 1\n\n    * - Name\n      - #nodes/#edges\n      - #features\n      - #classes/#tasks\n{% for cls in torch_geometric.datasets.hetero_datasets %}\n    * - :class:`~torch_geometric.datasets.{{ cls }}` {% if torch_geometric.datasets.utils.paper_link(cls) %}(`Paper <{{ torch_geometric.datasets.utils.paper_link(cls) }}>`__){% endif %}\n      -\n      -\n      -\n    {% for child in torch_geometric.datasets.utils.get_children(cls) %}\n    * - └─ **{{torch_geometric.datasets.utils.get_type(child)}} Type**: {{ child }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#nodes/#edges', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#features', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#classes', child, default='') }}{{ torch_geometric.datasets.utils.get_stat(cls, '#tasks', child, default='') }}\n    {% endfor %}\n{% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Configuring nbgallery for Distributed Training Tutorials in reStructuredText\nDESCRIPTION: This code snippet sets up an nbgallery directive in reStructuredText to display a collection of distributed training tutorials. It specifies the gallery name and lists the tutorials to be included.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/distributed.rst#2025-04-21_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. nbgallery::\n    :name: rst-gallery\n\n    distributed_pyg\n    multi_gpu_vanilla\n    multi_node_multi_gpu_vanilla\n```\n\n----------------------------------------\n\nTITLE: Integrating Aggregation Operations in Custom GNN Implementations\nDESCRIPTION: Demonstrates how to use aggregation operations within custom MessagePassing and GNN implementations for both neighborhood and global pooling operations.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch_geometric.nn import MessagePassing\n\nclass MyConv(MessagePassing):\n    def __init__(self, ...):\n        # Use a learnable softmax neighborhood aggregation:\n        super().__init__(aggr=aggr.SoftmaxAggregation(learn=True))\n\n   def forward(self, x, edge_index):\n       ....\n\n\nclass MyGNN(torch.nn.Module)\n    def __init__(self, ...):\n        super().__init__()\n\n        self.conv = MyConv(...)\n        # Use a global sort aggregation:\n        self.global_pool = aggr.SortAggregation(k=4)\n        self.classifier = torch.nn.Linear(...)\n\n     def foward(self, x, edge_index, batch):\n         x = self.conv(x, edge_index).relu()\n         x = self.global_pool(x, batch)\n         x = self.classifier(x)\n         return x\n```\n\n----------------------------------------\n\nTITLE: Including RST Documentation File\nDESCRIPTION: RST include directive that imports the sparse tensor documentation from a relative path in the advanced directory.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/sparse_tensor.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../advanced/sparse_tensor.rst\n```\n\n----------------------------------------\n\nTITLE: Heterogeneous Datasets Table Template in RST\nDESCRIPTION: ReStructuredText table template for displaying statistics of heterogeneous graph datasets, showing dataset name, nodes/edges count, features, and classes/tasks.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/data_cheatsheet.rst#2025-04-21_snippet_1\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. list-table::\n    :widths: 50 30 10 10\n    :header-rows: 1\n\n    * - Name\n      - #nodes/#edges\n      - #features\n      - #classes/#tasks\n```\n\n----------------------------------------\n\nTITLE: Including External Batching Documentation in Sphinx\nDESCRIPTION: Sphinx directive to include the content from the batching.rst file located in the ../advanced/ directory. This is a common pattern in documentation systems to avoid duplication of content.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/batching.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. include:: ../advanced/batching.rst\n```\n\n----------------------------------------\n\nTITLE: Ensuring CUDA Versions Match Between PyTorch and System\nDESCRIPTION: Commands to verify that the CUDA version used by PyTorch matches the system CUDA version, which is essential for successful installation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython -c \"import torch; print(torch.version.cuda)\"\n>>> 11.8\n\nnvcc --version\n>>> 11.8\n```\n\n----------------------------------------\n\nTITLE: RST Table Definition for Homogeneous Datasets in PyTorch Geometric\nDESCRIPTION: Defines a reStructuredText table listing homogeneous datasets with their statistics including graph count, node count, edge count, feature count, and class/task count. Uses Jinja2 templating to dynamically populate dataset information.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/data_cheatsheet.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. list-table::\n    :widths: 50 10 10 10 10 10\n    :header-rows: 1\n\n    * - Name\n      - #graphs\n      - #nodes\n      - #edges\n      - #features\n      - #classes/#tasks\n{% for cls in torch_geometric.datasets.homo_datasets %}\n    * - :class:`~torch_geometric.datasets.{{ cls }}` {% if torch_geometric.datasets.utils.paper_link(cls) %}(`Paper <{{ torch_geometric.datasets.utils.paper_link(cls) }}>`__){% endif %}\n      - {%if torch_geometric.datasets.utils.has_stats(cls) %}{{ torch_geometric.datasets.utils.get_stat(cls, '#graphs', default=1) }}{% else %}{{ torch_geometric.datasets.utils.get_stat(cls, '#graphs', default='') }}{% endif %}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#nodes', default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#edges', default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#features', default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#classes', default='') }}{{ torch_geometric.datasets.utils.get_stat(cls, '#tasks', default='') }}\n    {% for child in torch_geometric.datasets.utils.get_children(cls) %}\n    * - └─ {{ child }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#graphs', child, default=1) }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#nodes', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#edges', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#features', child, default='') }}\n      - {{ torch_geometric.datasets.utils.get_stat(cls, '#classes', child, default='') }}{{ torch_geometric.datasets.utils.get_stat(cls, '#tasks', child, default='') }}\n    {% endfor %}\n{% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Installing PyG Sphinx Theme\nDESCRIPTION: Installs the custom Sphinx theme required for PyG documentation from the GitHub repository.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install git+https://github.com/pyg-team/pyg_sphinx_theme.git\n```\n\n----------------------------------------\n\nTITLE: Deep Learning Model Configuration Parameters\nDESCRIPTION: Abbreviated parameters representing key configuration elements for neural network training, including activation, batch normalization, dropout, aggregation, learning rate, optimization, and training epochs\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/graphgym/sample/dimensions.txt#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nact bn drop agg l_mp l_pre l_post stage batch lr optim epoch\n```\n\n----------------------------------------\n\nTITLE: Displaying PyTorch Lightning Examples Table in Markdown\nDESCRIPTION: This markdown snippet presents a table listing three example Python scripts. Each row includes the filename and a brief description of the script's functionality, demonstrating different applications of PyG with PyTorch Lightning.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pytorch_lightning/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Example                                    | Description                                                                          |\n| ------------------------------------------ | ------------------------------------------------------------------------------------ |\n| [`graph_sage.py`](./graph_sage.py)         | Combines PyG and PyTorch Lightning for node classification via the `GraphSAGE` model |\n| [`gin.py`](./gin.py)                       | Combines PyG and PyTorch Lightning for graph classification via the `GIN` model      |\n| [`relational_gnn.py`](./relational_gnn.py) | Combines PyG and PyTorch Lightning for heterogeneous node classification             |\n```\n\n----------------------------------------\n\nTITLE: Including RST Documentation\nDESCRIPTION: Sphinx documentation directive to include the CSV loading tutorial file.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/load_csv.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../tutorial/load_csv.rst\n```\n\n----------------------------------------\n\nTITLE: Including Installation Instructions in Sphinx Documentation\nDESCRIPTION: A Sphinx directive that includes the installation.rst file from the ../install/ directory into the current document. This is a common pattern in Sphinx documentation to avoid duplicating content.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/installation.rst#2025-04-21_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n:orphan:\n\n.. include:: ../install/installation.rst\n```\n\n----------------------------------------\n\nTITLE: Generating HTML Documentation\nDESCRIPTION: Commands to navigate to the docs directory and generate HTML documentation using Sphinx make command.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nmake html\n```\n\n----------------------------------------\n\nTITLE: Listing Distributed Graph Learning Example Directories in Markdown\nDESCRIPTION: This code snippet provides a structured list of subdirectories containing examples for distributed graph learning. It includes PyG's own package, GraphLearn-for-PyTorch, and Kùzu graph database integration.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n1. [`pyg`](./pyg): Distributed training via PyG's own `torch_geometric.distributed` package.\n2. [`graphlearn_for_pytorch`](./graphlearn_for_pytorch): Distributed training via the external [GraphLearn-for-PyTorch (GLT)](https://github.com/alibaba/graphlearn-for-pytorch) package.\n3. [`kuzu`](./kuzu): Remote backend via the [Kùzu](https://kuzudb.com/) graph database.\n```\n\n----------------------------------------\n\nTITLE: Setting up CUDA Path Environment Variables\nDESCRIPTION: Bash commands to add CUDA to PATH and CPATH environment variables, necessary for building PyG extensions from source.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/install/installation.rst#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nexport PATH=/usr/local/cuda/bin:$PATH\necho $PATH\n>>> /usr/local/cuda/bin:...\n\nexport CPATH=/usr/local/cuda/include:$CPATH\necho $CPATH\n>>> /usr/local/cuda/include:...\n```\n\n----------------------------------------\n\nTITLE: Specifying PyTorch Geometric Dependencies\nDESCRIPTION: This snippet lists the required dependencies for the PyTorch Geometric project. It includes a specific PyTorch wheel for CPU, a minimum NumPy version, and a Git repository for a custom Sphinx theme.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nhttps://download.pytorch.org/whl/cpu/torch-1.13.0%2Bcpu-cp39-cp39-linux_x86_64.whl\nnumpy>=1.19.5\ngit+https://github.com/pyg-team/pyg_sphinx_theme.git\n```\n\n----------------------------------------\n\nTITLE: Visualizing Sampled Heterogeneous Graph Batch Structure in PyG\nDESCRIPTION: Shows the structure of a sampled batch from a heterogeneous graph. The output demonstrates the node and edge features that are included in the mini-batch, with information about different node types (paper, author, institution, field_of_study) and their relationships.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/heterogeneous.rst#2025-04-21_snippet_11\n\nLANGUAGE: text\nCODE:\n```\nHeteroData(\n  paper={\n    x=[20799, 256],\n    y=[20799],\n    train_mask=[20799],\n    val_mask=[20799],\n    test_mask=[20799],\n    batch_size=128\n  },\n  author={ x=[4419, 128] },\n  institution={ x=[302, 128] },\n  field_of_study={ x=[2605, 128] },\n  (author, affiliated_with, institution)={ edge_index=[2, 0] },\n  (author, writes, paper)={ edge_index=[2, 5927] },\n  (paper, cites, paper)={ edge_index=[2, 11829] },\n  (paper, has_topic, field_of_study)={ edge_index=[2, 10573] },\n  (institution, rev_affiliated_with, author)={ edge_index=[2, 829] },\n  (paper, rev_writes, author)={ edge_index=[2, 5512] },\n  (field_of_study, rev_has_topic, paper)={ edge_index=[2, 10499] }\n)\n```\n\n----------------------------------------\n\nTITLE: Sphinx Documentation Template for PyTorch Geometric Classes\nDESCRIPTION: A Sphinx documentation template that generates documentation for a class in PyTorch Geometric. It includes directives to underline the full class name, set the current module context, and display the class with its inheritance structure.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/_templates/autosummary/only_class.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n{{ fullname | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Initializing Distributed Environment in Python Script\nDESCRIPTION: This Python code snippet retrieves the world size, rank, and local rank from environment variables set by SLURM or the pyxis container. It then calls the run function with these parameters.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Get the world size from the WORLD_SIZE variable or directly from SLURM:\nworld_size = int(os.environ.get('WORLD_SIZE', os.environ.get('SLURM_NTASKS')))\n# Likewise for RANK and LOCAL_RANK:\nrank = int(os.environ.get('RANK', os.environ.get('SLURM_PROCID')))\nlocal_rank = int(os.environ.get('LOCAL_RANK', os.environ.get('SLURM_LOCALID')))\nrun(world_size, rank, local_rank)\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Documentation\nDESCRIPTION: A structured changelog entry documenting updates to PyTorch Geometric version 2.7.0, including new features, changes, fixes and removals. Uses markdown formatting with headers and bullet points.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/CHANGELOG.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Changelog\n\nAll notable changes to this project will be documented in this file.\nThe format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).\n\n## [2.7.0] - 2025-MM-DD\n\n### Added\n\n- Added PyTorch 2.6 support ([#10170](https://github.com/pyg-team/pytorch_geometric/pull/10170))\n- Added support for heterogenous graphs in `PGExplainer` ([#10168](https://github.com/pyg-team/pytorch_geometric/pull/10168))\n- Added support for heterogenous graphs in `GNNExplainer` ([#10158](https://github.com/pyg-team/pytorch_geometric/pull/10158))\n- Added Graph Positional and Structural Encoder (GPSE) ([#9018](https://github.com/pyg-team/pytorch_geometric/pull/9018))\n[...additional entries omitted for brevity...]\n\n### Changed\n\n- Updated cuGraph examples to use buffered sampling which keeps data in memory and is significantly faster than the deprecated buffered sampling ([#10079](https://github.com/pyg-team/pytorch_geometric/pull/10079))\n[...additional entries omitted for brevity...]\n\n### Fixed\n\n- Fixed `_recursive_config()` for `torch.nn.ModuleList` and `torch.nn.ModuleDict` ([#10124](https://github.com/pyg-team/pytorch_geometric/pull/10124), [#10129](https://github.com/pyg-team/pytorch_geometric/pull/10129))\n[...additional entries omitted for brevity...]\n\n### Removed\n\n## [2.6.0] - 2024-09-13\n```\n\n----------------------------------------\n\nTITLE: Citing PyTorch Geometric in BibTeX Format\nDESCRIPTION: BibTeX citation entry for the PyTorch Geometric paper. Users should include this citation when using PyG in their academic work, along with citations for any specific methods used from the library.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/README.md#2025-04-21_snippet_11\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{Fey/Lenssen/2019,\n  title={Fast Graph Representation Learning with {PyTorch Geometric}},\n  author={Fey, Matthias and Lenssen, Jan E.},\n  booktitle={ICLR Workshop on Representation Learning on Graphs and Manifolds},\n  year={2019},\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring SLURM Job Submission Script (Bash)\nDESCRIPTION: This snippet shows the configuration for a SLURM job submission script. It specifies the job name, output file, partition, number of nodes, tasks, GPUs per task, and GPU binding settings.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/multi_node_multi_gpu_vanilla.rst#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n#SBATCH --job-name=pyg-multinode-tutorial # identifier for the job listings\n#SBATCH --output=pyg-multinode.log        # outputfile\n#SBATCH --partition=gpucloud              # ADJUST this to your system\n#SBATCH -N 2                              # number of nodes you want to use\n#SBATCH --ntasks=4                        # number of processes to be run\n#SBATCH --gpus-per-task=1                 # every process wants one GPU!\n#SBATCH --gpu-bind=none                   # NCCL can't deal with task-binding...\n```\n\n----------------------------------------\n\nTITLE: Setting Network Interface for Multi-node Communication on Master Node\nDESCRIPTION: These Bash commands set the network interface for multi-node communication on the master node (node 0) using environment variables.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/pyg/README.md#2025-04-21_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\nexport TP_SOCKET_IFNAME=$(ip addr | grep \"$MASTER_ADDR\" | awk '{print $NF}')\nexport GLOO_SOCKET_IFNAME=$TP_SOCKET_IFNAME\n```\n\n----------------------------------------\n\nTITLE: Training GraphSAGE Model on Papers 100M Dataset in Python\nDESCRIPTION: This snippet runs a Python script to train a three-layer GraphSAGE model on the prepared Papers 100M dataset using PyTorch Geometric.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/kuzu/papers_100M/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npython train.py\n```\n\n----------------------------------------\n\nTITLE: Including External Documentation with RST Include Directive\nDESCRIPTION: This snippet demonstrates how to include content from another RST file using the include directive. The file includes the explain.rst tutorial from the tutorial directory.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/explain.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../tutorial/explain.rst\n```\n\n----------------------------------------\n\nTITLE: Including GraphGym Documentation using reStructuredText Directive\nDESCRIPTION: This RST directive includes content from another file in the documentation. It references the GraphGym documentation from the advanced directory within the project structure.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/graphgym.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../advanced/graphgym.rst\n```\n\n----------------------------------------\n\nTITLE: Generating Class Summaries in RST for torch_geometric.graphgym.models\nDESCRIPTION: This RST code snippet creates an autosummary of classes in the torch_geometric.graphgym.models module. It uses a Jinja2 template to iterate through the classes and list them without signatures.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/graphgym.rst#2025-04-21_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n    :nosignatures:\n    {% for cls in torch_geometric.graphgym.models.classes %}\n      {{ cls }}\n    {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Markdown Table of PyTorch Geometric Contrib Examples\nDESCRIPTION: A markdown table listing the example files in the contrib package, including RBCD attacks and PGM explainers for node and graph classification. Each row contains the filename and a brief description of its functionality.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/contrib/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Example                                                                            | Description                                                                                 |\n| ---------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |\n| [`rbcd_attack.py`](./rbcd_attack.py)                                               | An example of the RBCD (Resource-based Critical Data) attack                                |\n| [`rbcd_attack_poisoning.py`](./rbcd_attack_poisoning.py)                           | An example of the RBCD (Resource-Based Critical Data) attack with data poisoning strategies |\n| [`pgm_explainer_node_classification.py`](./pgm_explainer_node_classification.py)   | An example of the PGM (Probabilistic Graphical Model) explainer for node classification     |\n| [`pgm_explainer_graph_classification.py`](./pgm_explainer_graph_classification.py) | An example of the PGM (Probabilistic Graphical Model) explainer for graph classification    |\n```\n\n----------------------------------------\n\nTITLE: Including Heterogeneous Graph Tutorial in RST Documentation\nDESCRIPTION: RST directive to include external heterogeneous graph tutorial content from a relative path. Uses the orphan directive to prevent warnings about documents not being included in any toctree.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/heterogeneous.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../tutorial/heterogeneous.rst\n```\n\n----------------------------------------\n\nTITLE: Demonstrating GIN Model Implementation using PyTorch Ignite - Python\nDESCRIPTION: This code snippet showcases the implementation of the Graph Isomorphism Network (GIN) model utilizing the PyTorch Ignite framework. It is intended for developers seeking to understand the specific use of Ignite for model training and evaluation in graph-based tasks. Key parameters include model architecture configurations and training settings which dictate how the model learns from the data.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pytorch_ignite/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Code for demonstrating GIN model would be included here.\n```\n\n----------------------------------------\n\nTITLE: Including External RST File in Sphinx Documentation\nDESCRIPTION: This snippet uses Sphinx's include directive to incorporate content from another RST file. The directive pulls in the content from '../advanced/jit.rst' to be displayed at this location in the documentation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/jit.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../advanced/jit.rst\n```\n\n----------------------------------------\n\nTITLE: Creating a Gallery of PyTorch Geometric Applications in RST\nDESCRIPTION: This RST (reStructuredText) code creates a gallery section that organizes PyTorch Geometric application examples into categories. It uses the nbgallery directive to display links to various implementation examples including neighbor loaders, point cloud processing, model explainability, node embeddings, and graph transformers.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/tutorial/application.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. nbgallery::\n    :name: rst-gallery\n\n    neighbor_loader\n    point_cloud\n    explain\n    shallow_node_embeddings\n    graph_transformer\n```\n\n----------------------------------------\n\nTITLE: Including PyTorch Geometric Introduction RST File\nDESCRIPTION: RST directive to include the introduction.rst file from the get_started directory located one level up in the documentation hierarchy. The :orphan: directive indicates this page should not be included in the documentation table of contents.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/introduction.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n:orphan:\n\n.. include:: ../get_started/introduction.rst\n```\n\n----------------------------------------\n\nTITLE: Documenting Remote Backend Interfaces in PyTorch Geometric\nDESCRIPTION: This snippet generates documentation for remote backend interface classes in torch_geometric.data using Sphinx autosummary.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/data.rst#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :nosignatures:\n   :toctree: ../generated\n\n   {% for name in torch_geometric.data.remote_backend_classes %}\n     {{ name }}\n   {% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Using Attention-Based MultiAggregation in PyTorch Geometric\nDESCRIPTION: Shows how to use attention-based combination of multiple aggregation functions by specifying the mode and additional parameters.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmulti_aggr = aggr.MultiAggregation(\n    aggrs=['mean', 'std'],\n    mode='attn',\n    mode_kwargs=dict(in_channels=64, out_channels=64, num_heads=4),\n)\n```\n\n----------------------------------------\n\nTITLE: Documenting Model Hub in PyTorch Geometric\nDESCRIPTION: This section documents the model_hub module in PyTorch Geometric, including all its members.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/nn.rst#2025-04-21_snippet_9\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: torch_geometric.nn.model_hub\n   :members:\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Increment for Bipartite Data in PyTorch Geometric\nDESCRIPTION: This snippet shows the implementation of a custom __inc__ method for a BipartiteData class. It handles the increment of edge indices for source and target nodes separately based on their respective sizes.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/advanced/batching.rst#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nreturn torch.tensor([[self.x_s.size(0)], [self.x_t.size(0)]])\nreturn super().__inc__(key, value, *args, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Configuring RST Documentation Template for PyTorch Geometric Profile Module\nDESCRIPTION: Sphinx documentation configuration using RST directives to generate API documentation. Sets up the current module context and creates class summaries and detailed member documentation.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/modules/profile.rst#2025-04-21_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: torch_geometric.profile\n\n.. autosummary::\n    :nosignatures:\n    {% for cls in torch_geometric.profile.classes %}\n      {{ cls }}\n    {% endfor %}\n\n.. automodule:: torch_geometric.profile\n    :members:\n    :undoc-members:\n```\n\n----------------------------------------\n\nTITLE: Homogeneous Datasets Table Template in RST\nDESCRIPTION: ReStructuredText table template for displaying statistics of homogeneous graph datasets, including dataset name, number of graphs, nodes, edges, features, and classes/tasks.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/cheatsheet/data_cheatsheet.rst#2025-04-21_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. list-table::\n    :widths: 50 10 10 10 10 10\n    :header-rows: 1\n\n    * - Name\n      - #graphs\n      - #nodes\n      - #edges\n      - #features\n      - #classes/#tasks\n```\n\n----------------------------------------\n\nTITLE: Installing Intel Extension for PyTorch and Compatible PyTorch Version\nDESCRIPTION: Pip command to install a specific version of PyTorch and the Intel Extension for PyTorch, necessary for running benchmarks on Intel GPUs.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/multi_gpu/training/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install torch==2.1.0.post2 intel-extension-for-pytorch==2.1.30+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\n```\n\n----------------------------------------\n\nTITLE: Using GINEConv with Edge Features\nDESCRIPTION: Example of message passing with multi-dimensional edge feature information\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/cheatsheet.rst#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nGINEConv(...).forward(x, edge_index, edge_attr)\n```\n\n----------------------------------------\n\nTITLE: Including Remote Execution Documentation in reStructuredText\nDESCRIPTION: This directive includes the content of the 'remote.rst' file from the '../advanced/' directory into the current document. It is used to incorporate remote execution documentation into the PyTorch Geometric documentation structure.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/notes/remote.rst#2025-04-21_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n:orphan:\n\n.. include:: ../advanced/remote.rst\n```\n\n----------------------------------------\n\nTITLE: Generating Sphinx Class Documentation Template\nDESCRIPTION: A Sphinx documentation template that uses Jinja variables to create class documentation. The template shows class inheritance and member details using the autoclass directive.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/_templates/autosummary/class.rst#2025-04-21_snippet_0\n\nLANGUAGE: sphinx\nCODE:\n```\n{{ fullname | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n   :show-inheritance:\n   :members:\n```\n\n----------------------------------------\n\nTITLE: Generating Class Documentation Template with Jinja2\nDESCRIPTION: Sphinx documentation template that generates class documentation with inheritance and method listings. Has special handling for MessagePassing class to show different member methods. Uses Jinja2 templating syntax for dynamic content.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/_templates/autosummary/nn.rst#2025-04-21_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ fullname | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n{% if objname != \"MessagePassing\" %}\n.. autoclass:: {{ objname }}\n   :show-inheritance:\n   :members:\n   :exclude-members: forward, reset_parameters, message, message_and_aggregate, edge_update, aggregate, update\n\n   .. automethod:: forward\n   .. automethod:: reset_parameters\n{% else %}\n.. autoclass:: {{ objname }}\n   :show-inheritance:\n   :members:\n{% endif %}\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure in reStructuredText\nDESCRIPTION: This snippet defines the structure of the PyG documentation using reStructuredText directives. It includes sections for installation, getting started, tutorials, advanced concepts, package reference, cheatsheets, and external resources.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docs/source/index.rst#2025-04-21_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :maxdepth: 1\n   :caption: Install PyG\n\n   install/installation\n\n.. toctree::\n   :maxdepth: 1\n   :caption: Get Started\n\n   get_started/introduction\n   get_started/colabs\n\n.. toctree::\n   :maxdepth: 1\n   :caption: Tutorials\n\n   tutorial/gnn_design\n   tutorial/dataset\n   tutorial/application\n   tutorial/distributed\n\n.. toctree::\n   :maxdepth: 1\n   :caption: Advanced Concepts\n\n   advanced/batching\n   advanced/sparse_tensor\n   advanced/hgam\n   advanced/compile\n   advanced/jit\n   advanced/remote\n   advanced/graphgym\n   advanced/cpu_affinity\n\n.. toctree::\n   :maxdepth: 1\n   :caption: Package Reference\n\n   modules/root\n   modules/nn\n   modules/data\n   modules/loader\n   modules/sampler\n   modules/datasets\n   modules/transforms\n   modules/utils\n   modules/explain\n   modules/metrics\n   modules/distributed\n   modules/contrib\n   modules/graphgym\n   modules/profile\n\n.. toctree::\n   :maxdepth: 1\n   :caption: Cheatsheets\n\n   cheatsheet/gnn_cheatsheet\n   cheatsheet/data_cheatsheet\n\n.. toctree::\n   :maxdepth: 1\n   :caption: External Resources\n\n   external/resources\n```\n\n----------------------------------------\n\nTITLE: Configuring CMake Project with TorchScatter and TorchSparse\nDESCRIPTION: This CMake script sets up a project that uses TorchScatter and TorchSparse libraries. It defines the project, finds required packages, and configures an executable with appropriate linking and compilation settings.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/cpp/CMakeLists.txt#2025-04-21_snippet_0\n\nLANGUAGE: CMake\nCODE:\n```\ncmake_minimum_required(VERSION 3.10)\nproject(hello-world)\n\n# The first thing do is to tell cmake to find the TorchScatter\n# and TorchSparse libraries. The package pulls in all the necessary\n# torch libraries, so there is no need to add `find_package(Torch)`.\nfind_package(TorchScatter REQUIRED)\nfind_package(TorchSparse REQUIRED)\n\nfind_package(Python3 COMPONENTS Development)\n\nadd_executable(hello-world main.cpp)\n\n# We now need to link the TorchScatter and TorchSparse libraries\n# to our executable. We can do that by using the\n# TorchScatter::TorchScatter and TorchSparse::TorchSparse targets,\n# which also adds all the necessary torch dependencies.\ntarget_compile_features(hello-world PUBLIC cxx_range_for)\ntarget_link_libraries(hello-world TorchScatter::TorchScatter)\ntarget_link_libraries(hello-world TorchSparse::TorchSparse)\ntarget_link_libraries(hello-world ${CUDA_cusparse_LIBRARY})\nset_property(TARGET hello-world PROPERTY CXX_STANDARD 14)\n```\n\n----------------------------------------\n\nTITLE: Building and Running Docker Container for PyG on Intel GPU\nDESCRIPTION: Commands for building a Docker image for PyTorch Geometric with Intel GPU support and running it. This setup uses Intel's Extension for PyTorch.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docker/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ docker build -f docker/Dockerfile.xpu -t \"custom image name\"\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run --rm -it --ipc=host -v /dev/dri:/dev/dri --volume=$PWD:/app \"custom image name\" /bin/bash\n```\n\n----------------------------------------\n\nTITLE: Building and Running Docker Container for PyG on NVIDIA GPU\nDESCRIPTION: Commands for building a Docker image for PyTorch Geometric with CUDA support and running it on an NVIDIA GPU. This method is deprecated in favor of official NVIDIA containers.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/docker/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ docker build -t \"custom image name\"\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run --rm -it --init --runtime=nvidia --ipc=host --network=host --volume=$PWD:/app -e NVIDIA_VISIBLE_DEVICES=0 \"custom image name\" /bin/bash\n```\n\n----------------------------------------\n\nTITLE: Installing Kùzu via pip\nDESCRIPTION: Command to install Kùzu using pip package manager. This is a prerequisite for using Kùzu as a remote backend for PyG.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/distributed/kuzu/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install kuzu\n```\n\n----------------------------------------\n\nTITLE: Running PointNet++ Classification\nDESCRIPTION: Command to execute the PointNet++ implementation for point cloud classification\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/points/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython point_net.py\n```\n\n----------------------------------------\n\nTITLE: Running PointCNN Classification\nDESCRIPTION: Command to execute the PointCNN implementation for point cloud classification\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/points/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython point_cnn.py\n```\n\n----------------------------------------\n\nTITLE: Installing and Configuring Jemalloc for PyG Benchmark Performance\nDESCRIPTION: Clones, builds, and installs jemalloc, a memory allocator used to enhance performance in PyG benchmarks.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/inference/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd ${workspace}\ngit clone https://github.com/jemalloc/jemalloc.git\ncd jemalloc\ngit checkout 5.2.1\n./autogen.sh\n./configure --prefix=${workspace}/jemalloc-bin\nmake\nmake install\n```\n\n----------------------------------------\n\nTITLE: Core Binding Configuration\nDESCRIPTION: Example command for binding the process to specific CPU cores using numactl.\nSOURCE: https://github.com/pyg-team/pytorch_geometric/blob/master/benchmark/training/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nOMP_NUM_THREADS=${CORES} numactl -C 0-${LAST_CORE} -m 0 CMD......\n```"
  }
]