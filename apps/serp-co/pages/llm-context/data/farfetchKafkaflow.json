[
  {
    "owner": "farfetch",
    "repo": "kafkaflow",
    "content": "TITLE: Initializing Consumer with Topic and Group - KafkaFlow C#\nDESCRIPTION: This snippet demonstrates how to configure a basic Kafka consumer using KafkaFlow, specifying the topic to listen to and the consumer group it belongs to.  It also configures the buffer size and worker count. It utilizes the Microsoft.Extensions.DependencyInjection package for service configuration.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/add-consumers.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithBufferSize(100)\n            .WithWorkersCount(10)\n            .AddMiddlewares(middlewares => middlewares\n                ...\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow Consumer\nDESCRIPTION: This C# code configures a KafkaFlow consumer to receive messages from a specified Kafka topic. It sets up dependency injection, configures the Kafka cluster with broker addresses, and adds a consumer that subscribes to the topic, specifies a group ID, buffer size, worker count, and uses JSON serialization and the `HelloMessageHandler` to process incoming messages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\nusing KafkaFlow.TypedHandler;\nusing Consumer;\n\nconst string topicName = \"sample-topic\";\nvar services = new ServiceCollection();\n\nservices.AddKafka(kafka => kafka\n    .UseConsoleLog()\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .CreateTopicIfNotExists(topicName, 1, 1)\n        .AddConsumer(consumer => consumer\n            .Topic(topicName)\n            .WithGroupId(\"sample-group\")\n            .WithBufferSize(100)\n            .WithWorkersCount(10)\n            .AddMiddlewares(middlewares => middlewares\n                .AddSerializer<JsonCoreSerializer>()\n                .AddTypedHandlers(h => h.AddHandler<HelloMessageHandler>())\n            )\n        )\n    )\n);\n\nvar serviceProvider = services.BuildServiceProvider();\n\nvar bus = serviceProvider.CreateKafkaBus();\n\nawait bus.StartAsync();\n\nConsole.ReadKey();\n\nawait bus.StopAsync();\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow using Dependency Injection in C#\nDESCRIPTION: This snippet demonstrates how to configure KafkaFlow using Dependency Injection in a .NET application's `ConfigureServices` method. It sets up a Kafka cluster with a consumer and a producer, including brokers, topics, group ID, buffer size, worker count, deserializers, handlers, and serializers. The example assumes the existence of a `SampleMessageHandler` and uses `JsonCoreDeserializer` and `JsonCoreSerializer`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/installation.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\npublic void ConfigureServices(IServiceCollection services)\n{\n    services.AddKafka(kafka => kafka\n        .UseConsoleLog()\n        .AddCluster(cluster => cluster\n            .WithBrokers(new[] { \"localhost:9092\" })\n            .AddConsumer(consumer => consumer\n                .Topic(\"sample-topic\")\n                .WithGroupId(\"sample-group\")\n                .WithBufferSize(100)\n                .WithWorkersCount(10)\n                .AddMiddlewares(middlewares => middlewares\n                    .AddDeserializer<JsonCoreDeserializer>()\n                    .AddTypedHandlers(handlers => handlers\n                        .AddHandler<SampleMessageHandler>()))\n            )\n            .AddProducer(\"producer-name\", producer => producer\n                .DefaultTopic(\"sample-topic\")\n                .AddMiddlewares(middlewares => middlewares\n                    .AddSerializer<JsonCoreSerializer>()))\n        )\n    );\n}\n\npublic void Configure(\n    IApplicationBuilder app,\n    IWebHostEnvironment env,\n    IHostApplicationLifetime lifetime)\n{\n    var kafkaBus = app.ApplicationServices.CreateKafkaBus();\n\n    lifetime.ApplicationStarted.Register(() => kafkaBus.StartAsync(lifetime.ApplicationStopped));\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow in ASP.NET Core (C#)\nDESCRIPTION: This C# code snippet illustrates how to configure KafkaFlow in a modern ASP.NET Core application (after .NET 6). It registers KafkaFlow services using the `AddKafka` extension method and configures a Kafka cluster. The Kafka Bus is then started asynchronously before the application runs, ensuring KafkaFlow is initialized and ready to process messages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/configuration.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        ...\n    )\n);\n\nvar app = builder.Build();\n\napp.MapGet(\"/\", () => \"Hello World!\");\n\nvar kafkaBus = app.Services.CreateKafkaBus();\nawait kafkaBus.StartAsync();\n\napp.Run();\n```\n\n----------------------------------------\n\nTITLE: Configuring Serializer Middleware in KafkaFlow Producer\nDESCRIPTION: This code snippet demonstrates how to configure the Serializer Middleware in a KafkaFlow producer using various options, including specifying the serializer and type resolver. It uses the `AddSerializer` and `AddSingleTypeSerializer` extension methods.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/serializer-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer<ProductEventsProducer>(producer => producer\n            ...\n            .AddMiddlewares(middlewares => middleware\n                ...\n                .AddSerializer<JsonMessageSerializer>() // Using the DefaultMessageTypeResolver\n                // or\n                .AddSerializer<JsonMessageSerializer, YourTypeResolver>()\n                // or\n                .AddSerializer(\n                    resolver => new JsonMessageSerializer(...),\n                    resolver => new YourTypeResolver(...))\n                // or\n                .AddSingleTypeSerializer<YourMessageType, JsonMessageSerializer>()\n                // or\n                .AddSingleTypeSerializer<YourMessageType>(resolver => new JsonMessageSerializer(...))\n                ...\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Typed Handlers in KafkaFlow Consumer - C#\nDESCRIPTION: This code snippet demonstrates how to configure typed handlers within a KafkaFlow consumer using the `AddTypedHandlers` extension. It shows how to add handlers individually (`AddHandler`), from a collection (`AddHandlers`), or from an assembly (`AddHandlersFromAssemblyOf`).  It also shows how to configure the handler lifetime.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/typed-handler-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            ...\n            .AddMiddlewares(middlewares => middlewares\n                ...\n                .AddTypedHandlers(handlers => handlers\n                    .WithHandlerLifetime(InstanceLifetime.Singleton)\n                    .AddHandler<ProductCreatedHandler>()\n                    // or\n                    .AddHandlers( ... )\n                    // or\n                    .AddHandlersFromAssemblyOf<ProductCreatedHandler>()\n                )\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Enable Gzip Compression on Producer - C#\nDESCRIPTION: This snippet demonstrates how to enable Gzip compression for a KafkaFlow producer. It uses the `.WithCompression()` method and specifies `CompressionType.Gzip`. This configuration is applied during the producer setup.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/compression.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n.WithCompression(CompressionType.Gzip)\n```\n\n----------------------------------------\n\nTITLE: Configure KafkaFlow in ASP.NET Core (C#)\nDESCRIPTION: Configures KafkaFlow within an ASP.NET Core application.  It adds KafkaFlow to the service collection, configures a Kafka cluster with broker addresses, and starts the Kafka bus before the application starts. It showcases how to use the `AddKafka` extension method and create and start the `KafkaBus` instance.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/configuration.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        ...\n    )\n);\n\nvar app = builder.Build();\n\napp.MapGet(\"/\", () => \"Hello World!\");\n\nvar kafkaBus = app.Services.CreateKafkaBus();\nawait kafkaBus.StartAsync();\n\napp.Run();\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Security Information in C#\nDESCRIPTION: This code snippet demonstrates how to configure security information for a Kafka cluster in KafkaFlow using C#. It configures SASL authentication with username, password, mechanism, and security protocol. The `AddKafka` extension method is used to configure the Kafka cluster with brokers and schema registry, and `WithSecurityInformation` is used to set the authentication details.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/authentication.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n  services.AddKafka(\n    kafka => kafka\n        .AddCluster(\n            cluster => cluster\n                .WithBrokers(new[] {\"localhost:9092\"})\n                .WithSchemaRegistry(config => config.Url = \"localhost:8081\")\n                .WithSecurityInformation(information =>\n                {\n                  information.SaslMechanism = SaslMechanism.Plain;\n                  information.SaslPassword = \"pwd\";\n                  information.SaslUsername = \"user\";\n                  information.SecurityProtocol = SecurityProtocol.SaslPlaintext;\n                  information.EnableSslCertificateVerification = true;\n                  ...\n                })\n                ...\n            ...\n\n```\n\n----------------------------------------\n\nTITLE: Capturing KafkaFlow Activity with Tracer Provider\nDESCRIPTION: This code shows how to capture KafkaFlow activity by adding the `KafkaFlowInstrumentation.ActivitySourceName` as a source to the tracer provider builder. This requires that the .NET application instrumentation is already configured. The activity source name allows the OpenTelemetry tracer to capture and track KafkaFlow related activities.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/open-telemetry.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\n using var tracerProvider = Sdk.CreateTracerProviderBuilder()\n     .AddSource(KafkaFlowInstrumentation.ActivitySourceName)\n     ...\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow with Dashboard (.NET 6)\nDESCRIPTION: This C# code demonstrates how to configure KafkaFlow and integrate the KafkaFlow Dashboard in a .NET 6 web application.  It initializes Kafka with a consumer, enables admin messages and telemetry, maps controllers, and configures the KafkaFlow Dashboard middleware. It requires Kafka brokers running.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/dashboard.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Admin.Dashboard;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services\n    .AddKafka(kafka => kafka\n        .AddCluster(cluster => cluster\n                .WithBrokers(new[] { \"localhost:9092\" })\n                .AddConsumer(consumer => consumer\n                    .Topic(\"mytopic\")\n                    .WithGroupId(\"g1\")\n                    .WithWorkersCount(1)\n                    .WithBufferSize(10)\n                )\n                .EnableAdminMessages(\"kafka-flow.admin\")\n                .EnableTelemetry(\"kafka-flow.admin\") // you can use the same topic used in EnableAdminMessages, if need it\n        ))\n    .AddControllers();\n\nvar app = builder.Build();\n\napp.MapControllers();\napp.UseKafkaFlowDashboard();\n\nvar kafkaBus = app.Services.CreateKafkaBus();\nawait kafkaBus.StartAsync();\n\nawait app.RunAsync();\n```\n\n----------------------------------------\n\nTITLE: Initializing Name-based Producer with KafkaFlow (C#)\nDESCRIPTION: This code snippet demonstrates how to configure a name-based Kafka producer in KafkaFlow. It registers a producer named 'product-events' with a Kafka cluster. The producer is then accessed via the IProducerAccessor to send messages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/producers.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer(\n            \"product-events\", //the producer name\n            producer => \n                producer\n        )\n    )\n);\n\npublic class ProductService : IProductService\n{\n    private readonly IProducerAccessor _producers;\n\n    public ProductService(IProducerAccessor producers)\n    {\n        _producers = producers;\n    }\n\n    public async Task CreateProduct(Product product) =>\n        await _producers[\"product-events\"]\n            .ProduceAsync(product.Id.ToString(), product);     \n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Cluster with Security Information in C#\nDESCRIPTION: This C# code snippet demonstrates how to configure a Kafka cluster within the KafkaFlow framework, specifically focusing on setting up security information for authentication. It configures the brokers, schema registry, and security protocol, including SASL mechanism, username, password, and SSL certificate verification.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/authentication.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n  services.AddKafka(\n    kafka => kafka\n        .AddCluster(\n            cluster => cluster\n                .WithBrokers(new[] {\"localhost:9092\"})\n                .WithSchemaRegistry(config => config.Url = \"localhost:8081\")\n                .WithSecurityInformation(information =>\n                {\n                  information.SaslMechanism = SaslMechanism.Plain;\n                  information.SaslPassword = \"pwd\";\n                  information.SaslUsername = \"user\";\n                  information.SecurityProtocol = SecurityProtocol.SaslPlaintext;\n                  information.EnableSslCertificateVerification = true;\n                  ...\n                })\n                ...\n            ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Dynamic Workers Count with KafkaFlow in C#\nDESCRIPTION: This C# code snippet demonstrates how to configure the dynamic worker count for a KafkaFlow consumer. It uses the `WithWorkersCount` method with a lambda expression that calculates the number of workers based on whether it's peak hour or not. The worker count is evaluated every 15 minutes.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/dynamic-workers-configuration.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n.AddConsumer(\n    consumer => consumer\n        ...\n        .WithWorkersCount(\n            (context, resolver) =>\n            {\n                // Implement a custom logic to calculate the number of workers\n                if (IsPeakHour(DateTime.UtcNow))\n                {\n                    return Task.FromResult(10); // High worker count during peak hours\n                }\n                else\n                {\n                    return Task.FromResult(2); // Lower worker count during off-peak hours\n                }\n            },\n            TimeSpan.FromMinutes(15)); // Evaluate the worker count every 15 minutes\n        ...\n        )\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Type-Based Producer in KafkaFlow (C#)\nDESCRIPTION: This snippet shows how to configure a type-based producer in KafkaFlow using `AddProducer<T>`. It binds the producer configuration to a specific class (`ProductEventsProducer`) and uses `IMessageProducer<T>` to produce messages.  This allows for decoupling the KafkaFlow framework from service classes.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/producers.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nvar services = new ServiceCollection();\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer<ProductEventsProducer>(\n            producer => \n                producer\n                ...\n            )\n    )\n);\n\npublic class ProductEventsProducer : IProductEventsProducer\n{\n    private readonly IMessageProducer<ProductEventsProducer> _producer;\n\n    public ProductEventsProducer(IMessageProducer<ProductEventsProducer> producer)\n    {\n        _producer = producer;\n    }\n\n    public Task ProduceAsync(Product product) =>\n        _producer\n            .ProduceAsync(product.Id.ToString(), product);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Kafka Message Handler (C#)\nDESCRIPTION: This C# code defines a message handler for HelloMessage using KafkaFlow's IMessageHandler interface. It receives messages from Kafka, extracts the partition, offset, and message content, and prints them to the console.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Producer;\n\nnamespace Consumer;\n\npublic class HelloMessageHandler : IMessageHandler<HelloMessage>\n{\n    public Task Handle(IMessageContext context, HelloMessage message)\n    {\n        Console.WriteLine(\n            \"Partition: {0} | Offset: {1} | Message: {2}\",\n            context.ConsumerContext.Partition,\n            context.ConsumerContext.Offset,\n            message.Text);\n\n        return Task.CompletedTask;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Type-based Producer with KafkaFlow (C#)\nDESCRIPTION: This code snippet illustrates how to configure a type-based Kafka producer in KafkaFlow. It registers a producer using a class ProductEventsProducer, allowing for decoupling of the producer configuration from service classes. This is commonly used when creating a dedicated producer class.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/producers.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nvar services = new ServiceCollection();\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer<ProductEventsProducer>(\n            producer => \n                producer\n                ...\n            )\n    )\n);\n\npublic class ProductEventsProducer : IProductEventsProducer\n{\n    private readonly IMessageProducer<ProductEventsProducer> _producer;\n\n    public ProductEventsProducer(IMessageProducer<ProductEventsProducer> producer)\n    {\n        _producer = producer;\n    }\n\n    public Task ProduceAsync(Product product) =>\n        _producer\n            .ProduceAsync(product.Id.ToString(), product);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow with Custom Logger in C#\nDESCRIPTION: This code snippet demonstrates how to configure KafkaFlow to use a custom logger. It requires implementing the `ILogHandler` interface with your custom logging logic and then using the `UseLogHandler<YourLogHandler>()` method within the KafkaFlow configuration. `YourLogHandler` should be replaced with the name of your custom log handler class.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/logging.md#_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .UseLogHandler<YourLogHandler>()\n        ...\n\n```\n\n----------------------------------------\n\nTITLE: Subscribing Message Consume Completed Event in KafkaFlow\nDESCRIPTION: This snippet demonstrates how to subscribe to the Message Consume Completed Event in KafkaFlow using C#. This event signals the successful completion of message consumption. By subscribing to this event, you can track when messages have been successfully processed. It requires the KafkaFlow library to be installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/global-events.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceCompleted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n)\n```\n\n----------------------------------------\n\nTITLE: Enabling Admin Messages in KafkaFlow Configuration (C#)\nDESCRIPTION: This C# code snippet shows how to configure KafkaFlow to enable admin messages. It configures a Kafka cluster with brokers, a consumer, and enables the admin messages feature, specifying the admin topic. This allows for administrative operations to be performed via KafkaFlow.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services\n    .AddKafka(kafka => kafka\n        .AddCluster(cluster => cluster\n            .WithBrokers(new[] { \"localhost:9092\" })\n            .AddConsumer(consumer => consumer\n                .Topic(\"mytopic\")\n                .WithGroupId(\"g1\")\n                .WithWorkersCount(1)\n                .WithBufferSize(10)\n            )\n            .EnableAdminMessages(\n                \"kafka-flow.admin\" // the admin topic\n            )\n        ))\n    .AddControllers();\n\nvar app = builder.Build();\n\napp.MapControllers();\n\nvar kafkaBus = app.Services.CreateKafkaBus();\nawait kafkaBus.StartAsync();\n\nawait app.RunAsync();\n```\n\n----------------------------------------\n\nTITLE: Resetting Offsets for a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet demonstrates how to reset the offsets for a Kafka consumer using the `IConsumerAdmin` interface. The method requires access to the IoC provider. It pauses the consumer, resets the offsets, and restarts the consumer.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_10\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ResetOffsetsAsync(consumerName, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Message Consume Started Event in KafkaFlow (C#)\nDESCRIPTION: This code snippet demonstrates how to subscribe to the Message Consume Started event in KafkaFlow. This event is triggered at the start of message consumption, providing an opportunity to execute logic or set up resources before processing.  It utilizes `services.AddKafka` to configure KafkaFlow and subscribes to the `MessageConsumeStarted` event via `SubscribeGlobalEvents`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/global-events.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageConsumeStarted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n```\n\n----------------------------------------\n\nTITLE: Adding Compressor Middleware to KafkaFlow Producer (C#)\nDESCRIPTION: This code snippet demonstrates how to add a compressor middleware to a KafkaFlow producer using the `AddCompressor` extension method. It uses the `GzipMessageCompressor` for GZIP compression, either directly or through a resolver/factory method. The snippet is placed within the `ConfigureServices` method of a `Startup` class, configuring Kafka services.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/compressor-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\npublic class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddKafka(kafka => kafka\n            .AddCluster(cluster => cluster\n                .WithBrokers(new[] { \"localhost:9092\" })\n                .AddProducer<ProductEventsProducer>(producer => producer\n                    ...\n                    .AddMiddlewares(middlewares => middlewares\n                        ...\n                        .AddCompressor<GzipMessageCompressor>()\n                        // or\n                        .AddCompressor(resolver => new GzipMessageCompressor(...))\n                        ...\n                    )\n                )\n            )\n        );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow Dashboard in .NET 6\nDESCRIPTION: This C# code snippet demonstrates how to configure the KafkaFlow Dashboard in a .NET 6 application. It involves adding Kafka to the service collection, configuring a consumer, enabling admin messages and telemetry, mapping controllers, using the KafkaFlowDashboard middleware, and starting the Kafka bus.  The dashboard UI will be available at `/kafka-flow`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/dashboard.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Admin.Dashboard;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services\n    .AddKafka(kafka => kafka\n        .AddCluster(cluster => cluster\n                .WithBrokers(new[] { \"localhost:9092\" })\n                .AddConsumer(consumer => consumer\n                    .Topic(\"mytopic\")\n                    .WithGroupId(\"g1\")\n                    .WithWorkersCount(1)\n                    .WithBufferSize(10)\n                )\n                .EnableAdminMessages(\"kafka-flow.admin\")\n                .EnableTelemetry(\"kafka-flow.admin\") // you can use the same topic used in EnableAdminMessages, if need it\n        ))\n    .AddControllers();\n\nvar app = builder.Build();\n\napp.MapControllers();\napp.UseKafkaFlowDashboard();\n\nvar kafkaBus = app.Services.CreateKafkaBus();\nawait kafkaBus.StartAsync();\n\nawait app.RunAsync();\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Producer (C#)\nDESCRIPTION: This C# code configures a Kafka producer using KafkaFlow. It defines the Kafka brokers, creates a topic if it doesn't exist, and configures the producer with a JSON serializer. It then sends a HelloMessage to the specified topic.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.Extensions.DependencyInjection;\nusing KafkaFlow.Producers;\nusing KafkaFlow.Serializer;\nusing KafkaFlow;\nusing Producer;\n\nvar services = new ServiceCollection();\n\nconst string topicName = \"sample-topic\";\nconst string producerName = \"say-hello\";\n\nservices.AddKafka(\n    kafka => kafka\n        .UseConsoleLog()\n        .AddCluster(\n            cluster => cluster\n                .WithBrokers(new[] { \"localhost:9092\" })\n                .CreateTopicIfNotExists(topicName, 1, 1)\n                .AddProducer(\n                    producerName,\n                    producer => producer\n                        .DefaultTopic(topicName)\n                        .AddMiddlewares(m =>\n                            m.AddSerializer<JsonCoreSerializer>()\n                            )\n                )\n        )\n);\n\nvar serviceProvider = services.BuildServiceProvider();\n\nvar producer = serviceProvider\n    .GetRequiredService<IProducerAccessor>()\n    .GetProducer(producerName);\n\nawait producer.ProduceAsync(\n                   topicName,\n                   Guid.NewGuid().ToString(),\n                   new HelloMessage { Text = \"Hello!\" });\n\n\nConsole.WriteLine(\"Message sent!\");\n```\n\n----------------------------------------\n\nTITLE: Configuring a KafkaFlow Consumer\nDESCRIPTION: This code snippet demonstrates how to configure a KafkaFlow consumer using the `AddKafka` extension method in C#. It sets up a Kafka cluster with brokers, defines a consumer that listens to a specific topic and belongs to a consumer group, and configures buffer size and worker count.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/consumers/add-consumers.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithBufferSize(100)\n            .WithWorkersCount(10)\n            .AddMiddlewares(middlewares => middlewares\n                ...\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Automatic Partition Assignment - KafkaFlow C#\nDESCRIPTION: This snippet showcases automatic partition assignment for a KafkaFlow consumer using the `Topic()` method. It requires KafkaFlow and Microsoft.Extensions.DependencyInjection. The consumer will distribute the topic partitions across application instances. KafkaFlow.Serializer is implicitly used for message serialization.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/add-consumers.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Changing Workers Count for a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet shows how to change the number of workers for a Kafka consumer using the `IConsumerAdmin` interface.  It requires access to the IoC provider. It adjusts the degree of parallelism for the consumer.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_12\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ChangeWorkersCountAsync(consumerName, 100);\n```\n\n----------------------------------------\n\nTITLE: Manual Partition Assignment - KafkaFlow C#\nDESCRIPTION: This snippet shows how to manually assign partitions to a KafkaFlow consumer using the `ManualAssignPartitions()` method. It also requires KafkaFlow and Microsoft.Extensions.DependencyInjection.  It avoids automatic partition distribution. KafkaFlow.Serializer is implicitly used for message serialization.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/add-consumers.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .ManualAssignPartitions(\"topic-name\", new[] { 1, 2, 3 })\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Typed Handlers in Kafka Consumer - C#\nDESCRIPTION: This snippet demonstrates how to configure typed handlers within a Kafka consumer using KafkaFlow. It shows the use of `AddHandler`, `AddHandlers`, and `AddHandlersFromAssemblyOf` methods to register message handlers. The snippet also shows how to configure the lifetime of the handler instances.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/typed-handler-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            ...\n            .AddMiddlewares(middlewares => middlewares\n                ...\n                .AddTypedHandlers(handlers => handlers\n                    .WithHandlerLifetime(InstanceLifetime.Singleton)\n                    .AddHandler<ProductCreatedHandler>()\n                    // or\n                    .AddHandlers( ... )\n                    // or\n                    .AddHandlersFromAssemblyOf<ProductCreatedHandler>()\n                )\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow in Hosted Service (C#)\nDESCRIPTION: This C# snippet demonstrates how to configure KafkaFlow within a .NET Hosted Service.  It registers `KafkaFlowHostedService` with the service collection and configures a Kafka cluster with specified brokers.  The `AddKafkaFlowHostedService` extension method is used to simplify the registration process.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/configuration.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.Hosting;\n\npublic static class Program\n{\n    private static async Task Main(string[] args)\n    {\n        await Host\n            .CreateDefaultBuilder(args)\n            .ConfigureServices((hostContext, services) =>\n            {\n                services.AddKafkaFlowHostedService(kafka => kafka\n                    .AddCluster(cluster => cluster\n                        .WithBrokers(new[] { \"localhost:9092\" })\n                        ...\n                    )\n                );\n            })\n            .Build()\n            .RunAsync();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configure Producer with Compression in KafkaFlow - C#\nDESCRIPTION: This snippet demonstrates how to configure a KafkaFlow producer with Gzip compression within the `services.AddKafka` configuration. It shows how to define brokers and specify compression settings for a specific producer (`ProductEventsProducer`) using the `.WithCompression()` method.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/compression.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer<ProductEventsProducer>(producer => producer\n            .WithCompression(CompressionType.Gzip)\n                ...\n            )\n        )\n    )\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow with Schema Registry and Avro Serializer\nDESCRIPTION: This snippet shows how to configure KafkaFlow to use a schema registry along with an Avro serializer and deserializer. It configures the schema registry URL and adds the `AddSchemaRegistryAvroSerializer` and `AddSchemaRegistryAvroDeserializer` middlewares to the producer and consumer, respectively. Requires `KafkaFlow.SchemaRegistry` package.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/serializer-middleware.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\npublic class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddKafka(\n            kafka => kafka\n                .AddCluster(\n                    cluster => cluster\n                        .WithBrokers(new[] { \"localhost:9092\" })\n                        .WithSchemaRegistry(config => config.Url = \"localhost:8081\")\n                        .AddProducer(\n                            ...\n                            .AddMiddlewares(middlewares => \n                                    middlewares.AddSchemaRegistryAvroSerializer(new AvroSerializerConfig{ SubjectNameStrategy = SubjectNameStrategy.TopicRecord })\n                        )\n                       .AddConsumer(\n                            ...\n                            .AddMiddlewares(middlewares => middlewares.AddSchemaRegistryAvroDeserializer()\n                        )\n                    )\n            );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow with Console Logger in C#\nDESCRIPTION: This code snippet demonstrates how to configure KafkaFlow to use the console logger. It involves installing the `KafkaFlow.LogHandler.Console` NuGet package and then using the `UseConsoleLog()` method within the KafkaFlow configuration. This will direct KafkaFlow's log messages to the console output.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/logging.md#_snippet_0\n\nLANGUAGE: C#\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .UseConsoleLog()\n        ...\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Serializer Middleware in KafkaFlow\nDESCRIPTION: This C# code snippet demonstrates how to configure the serializer middleware within a KafkaFlow consumer or producer. It shows several ways to add the serializer using different implementations of IMessageSerializer and IMessageTypeResolver, including using a factory method and AddSingleTypeSerializer for topics with only one message type.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/serializer-middleware.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer<ProductEventsProducer>(producer => producer\n            ...\n            .AddMiddlewares(middlewares => middleware\n                ...\n                .AddSerializer<JsonMessageSerializer>() // Using the DefaultMessageTypeResolver\n                // or\n                .AddSerializer<JsonMessageSerializer, YourTypeResolver>()\n                // or\n                .AddSerializer(\n                    resolver => new JsonMessageSerializer(...),\n                    resolver => new YourTypeResolver(...))\n                // or\n                .AddSingleTypeSerializer<JsonMessageSerializer, YourMessageType>()\n                // or\n                .AddSingleTypeSerializer<YourMessageType>(resolver => new JsonMessageSerializer(...))\n                ...\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Error Handling Middleware Implementation in C#\nDESCRIPTION: This middleware handles exceptions that occur during message processing. It wraps the next middleware in a try-catch block and logs any exceptions that are caught. The middleware requires an ILogger instance to be injected via its constructor.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/middlewares.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\npublic class ErrorHandlingMiddleware : IMessageMiddleware\n{\n    private readonly ILogger log;\n\n    public ErrorHandlingMiddleware(ILogger log)\n    {\n        this.log = log ?? throw new ArgumentNullException(nameof(log));\n    }\n\n    public async Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        try\n        {\n            await next(context).ConfigureAwait(false);\n        }\n        catch(Exception ex)\n        {\n            this.log.Error(\"Error processing message\", ex);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Enable Gzip Compression - KafkaFlow Producer - C#\nDESCRIPTION: This code snippet demonstrates how to enable Gzip compression for a KafkaFlow producer. It uses the `.WithCompression` method and specifies `CompressionType.Gzip` as the compression type. This configures the producer to compress messages using Gzip before sending them to the Kafka topic. No additional dependencies beyond KafkaFlow and the Confluent Kafka client are needed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/compression.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n.WithCompression(CompressionType.Gzip)\n```\n\n----------------------------------------\n\nTITLE: Configure KafkaFlow Hosted Service (C#)\nDESCRIPTION: Configures KafkaFlow as a hosted service within a .NET application. It uses `AddKafkaFlowHostedService` to register KafkaFlow with a cluster configuration. This configuration includes broker addresses.  The code snippet showcases how to use Microsoft's Hosting extensions to configure and run a KafkaFlow-based application.  It depends on the packages added in the previous step.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/configuration.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.Hosting;\n\npublic static class Program\n{\n    private static async Task Main(string[] args)\n    {\n        await Host\n            .CreateDefaultBuilder(args)\n            .ConfigureServices((hostContext, services) =>\n            {\n                services.AddKafkaFlowHostedService(kafka => kafka\n                    .AddCluster(cluster => cluster\n                        .WithBrokers(new[] { \"localhost:9092\" })\n                        ...\n                    )\n                );\n            })\n            .Build()\n            .RunAsync();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Consumer Lag-Based Worker Balancer in C#\nDESCRIPTION: This code snippet demonstrates how to configure the `WithConsumerLagWorkerBalancer` feature within a KafkaFlow consumer setup. It sets the total number of workers, minimum workers per instance, and maximum workers per instance. This configuration dynamically adjusts worker threads based on Kafka topic lag, optimizing resource allocation.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/built-in-workers-algorithms/consumer-lag-based-worker-balancer.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n.AddConsumer(\n    consumer => consumer\n        ...\n        .WithConsumerLagWorkerBalancer(\n            50, // The total number of workers to be distributed across all application instances.\n            3,  // The minimum number of workers for each application instance.\n            20) // The maximum number of workers for each application instance.\n        ...\n        )\n)\n```\n\n----------------------------------------\n\nTITLE: Rewinding Offsets for a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet shows how to rewind the offsets for a Kafka consumer using the `IConsumerAdmin` interface.  It needs to get an instance of IConsumerAdmin from IoC provider. It rewinds offsets to the specified date.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_11\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.RewindOffsetsAsync(consumerName, DateTime.Today.AddDays(-1), new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Setting Default Topic for Producer in KafkaFlow (C#)\nDESCRIPTION: This code snippet demonstrates how to set the default topic for a Kafka producer in KafkaFlow. When the default topic is set, messages sent via the producer will automatically be routed to this topic unless a specific topic is provided in the ProduceAsync method. This simplifies the message production when all messages should be sent to one topic.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/producers.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer(\n            \"product-events\",\n            producer => \n                producer\n                    .DefaultTopic(\"products-topic\")\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Subscribing Message Consume Error Event in KafkaFlow\nDESCRIPTION: This snippet demonstrates how to subscribe to the Message Consume Error Event in KafkaFlow using C#. This event is triggered if an error occurs during message consumption. Subscribing to this event allows you to manage and respond to consumption errors.  It requires the KafkaFlow library to be installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/global-events.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageConsumeError.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n)\n```\n\n----------------------------------------\n\nTITLE: Producing Message without Key in KafkaFlow (C#)\nDESCRIPTION: This code snippet illustrates how to produce a message without a key in KafkaFlow. This is achieved by passing `null` as the key argument to the ProduceAsync method. When the key is null, Kafka will use a default partitioning strategy based on the message content.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/producers.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nawait producer.ProduceAsync(null, product);\n```\n\n----------------------------------------\n\nTITLE: Producing Message with Specified Topic in KafkaFlow (C#)\nDESCRIPTION: This code snippet shows how to specify the topic when producing a message using KafkaFlow. The topic is passed as the first argument to the ProduceAsync method, overriding any default topic configuration. This allows for dynamic routing of messages to different topics.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/producers.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nawait _producers[\"product-events\"]\n    .ProduceAsync(\"products-topic\", product.Id.ToString(), product);\n```\n\n----------------------------------------\n\nTITLE: Adding OpenTelemetry Instrumentation to KafkaFlow\nDESCRIPTION: This code snippet demonstrates how to add OpenTelemetry instrumentation to your KafkaFlow configuration using the `AddOpenTelemetryInstrumentation` extension method. It requires the `KafkaFlow.OpenTelemetry` package to be installed. The code adds the instrumentation to a KafkaFlow cluster configuration within the .NET service collection.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/open-telemetry.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .AddCluster(...)\n        .AddOpenTelemetryInstrumentation()\n);\n```\n\n----------------------------------------\n\nTITLE: Enable Gzip Compression with Level - KafkaFlow Producer - C#\nDESCRIPTION: This code snippet demonstrates how to enable Gzip compression with a specific compression level for a KafkaFlow producer. It uses the `.WithCompression` method, specifying `CompressionType.Gzip` and an integer (in this case, `5`) as the compression level. Refer to the Confluent Kafka .NET documentation for valid compression level values.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/compression.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\n.WithCompression(CompressionType.Gzip, 5)\n```\n\n----------------------------------------\n\nTITLE: Configure KafkaFlow with Admin Messages - C#\nDESCRIPTION: This C# code configures KafkaFlow to enable Admin Messages using the EnableAdminMessages method. It sets up a basic KafkaFlow cluster with a consumer and specifies an admin topic for administrative operations. It also configures the web application to use KafkaFlow and map controllers.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services\n    .AddKafka(kafka => kafka\n        .AddCluster(cluster => cluster\n            .WithBrokers(new[] { \"localhost:9092\" })\n            .AddConsumer(consumer => consumer\n                .Topic(\"mytopic\")\n                .WithGroupId(\"g1\")\n                .WithWorkersCount(1)\n                .WithBufferSize(10)\n            )\n            .EnableAdminMessages(\n                \"kafka-flow.admin\" // the admin topic\n            )\n        ))\n    .AddControllers();\n\nvar app = builder.Build();\n\napp.MapControllers();\n\nvar kafkaBus = app.Services.CreateKafkaBus();\nawait kafkaBus.StartAsync();\n\nawait app.RunAsync();\n```\n\n----------------------------------------\n\nTITLE: Creating a Message Contract (C#)\nDESCRIPTION: This C# code defines a simple message contract named HelloMessage with a Text property. This class is used as the data structure for messages exchanged between the producer and consumer.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nnamespace Producer;\n\npublic class HelloMessage\n{\n    public string Text { get; set; } = default!;\n}\n```\n\n----------------------------------------\n\nTITLE: Logging Middleware Implementation in C#\nDESCRIPTION: This middleware logs the receipt and processing time of Kafka messages. It utilizes an ILogger for logging and a Stopwatch to measure processing time. The middleware requires an ILogger instance to be injected via its constructor.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/middlewares.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\npublic class LoggingMiddleware : IMessageMiddleware\n{\n    private readonly ILogger log;\n\n    public LoggingMiddleware(ILogger log)\n    {\n        this.log = log ?? throw new ArgumentNullException(nameof(log));\n    }\n\n    public async Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        this.log.Info(\"Kafka Message Received\");\n\n        var sw = Stopwatch.StartNew();\n\n        await next(context).ConfigureAwait(false);\n\n        sw.Stop();\n\n        this.log.Info(\n            \"Kafka Message processed\",\n            () => new\n            {\n                MessageType = context.Message?.GetType().FullName,\n                ProcessingTime = sw.ElapsedMilliseconds\n            });\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding OpenTelemetry Instrumentation to KafkaFlow in C#\nDESCRIPTION: This code snippet demonstrates how to add OpenTelemetry instrumentation to a KafkaFlow cluster configuration using the `AddOpenTelemetryInstrumentation` extension method. This enables tracing and baggage propagation for KafkaFlow operations. The KafkaFlow.OpenTelemetry NuGet package must be installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/open-telemetry.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .AddCluster(...)\n        .AddOpenTelemetryInstrumentation()\n);\n\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow with Microsoft Logging in C#\nDESCRIPTION: This code snippet demonstrates how to configure KafkaFlow to use the Microsoft Logging Framework. It involves installing the `KafkaFlow.LogHandler.Microsoft` NuGet package and then using the `UseMicrosoftLog()` method within the KafkaFlow configuration.  This allows KafkaFlow to integrate with the standard Microsoft logging infrastructure.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/logging.md#_snippet_1\n\nLANGUAGE: C#\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .UseMicrosoftLog()\n        ...\n\n```\n\n----------------------------------------\n\nTITLE: Start Docker Cluster\nDESCRIPTION: This command starts the Kafka cluster using Docker Compose. It uses the docker-compose.yml file located in the root directory of the repository to define and run the necessary Kafka containers. The `-d` flag runs the containers in detached mode.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Message Consume Error Event in KafkaFlow (C#)\nDESCRIPTION: This code snippet illustrates subscribing to the Message Consume Error event in KafkaFlow. This event triggers when an error occurs during message consumption, allowing for error management and response. It utilizes `services.AddKafka` to configure KafkaFlow and subscribes to the `MessageConsumeError` event via `SubscribeGlobalEvents`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/global-events.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageConsumeError.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry Instrumentation Enrichment\nDESCRIPTION: This code snippet shows how to configure the OpenTelemetry instrumentation to enrich the `Activity` with additional information from the `IMessageContext` object. It defines separate methods for producer and consumer enrichment using the `EnrichProducer` and `EnrichConsumer` options within the `KafkaFlowInstrumentationOptions`.  These enrichments add custom tags to the activities, providing more contextual information.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/open-telemetry.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .AddCluster(...)\n        .AddOpenTelemetryInstrumentation(options =>\n        {\n            options.EnrichProducer = (activity, messageContext) =>\n            {\n                activity.SetTag(\"messaging.destination.producername\", \"KafkaFlowOtel\");\n            };\n\n            options.EnrichConsumer = (activity, messageContext) =>\n            {\n                activity.SetTag(\"messaging.destination.group.id\", messageContext.ConsumerContext.GroupId);\n            };\n        })\n);\n```\n\n----------------------------------------\n\nTITLE: Configure Kafka with Custom Logger in C#\nDESCRIPTION: This code snippet shows how to configure KafkaFlow with a custom logger by implementing the `ILogHandler` interface. The `UseLogHandler<YourLogHandler>()` method is used during the Kafka configuration to register the custom logger for handling KafkaFlow log messages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/logging.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .UseLogHandler<YourLogHandler>()\n        ...\n\n```\n\n----------------------------------------\n\nTITLE: Adding KafkaFlow Packages for ASP.NET Core (Bash)\nDESCRIPTION: This bash snippet adds the necessary NuGet packages for KafkaFlow integration into an ASP.NET Core application. It adds the KafkaFlow core package and the Microsoft Dependency Injection extension. These packages are essential for configuring KafkaFlow within the ASP.NET Core dependency injection container.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/configuration.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\n```\n\n----------------------------------------\n\nTITLE: Enable Gzip Compression with Level - C#\nDESCRIPTION: This snippet shows how to enable Gzip compression and set the compression level for a KafkaFlow producer. The `.WithCompression()` method takes `CompressionType.Gzip` and an integer representing the compression level as arguments. Refer to Confluent Kafka documentation for valid compression level values.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/compression.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\n.WithCompression(CompressionType.Gzip, 5)\n```\n\n----------------------------------------\n\nTITLE: Configuring Acks for Producer in KafkaFlow (C#)\nDESCRIPTION: This code snippet shows how to configure acknowledgments (ACKS) for a Kafka producer in KafkaFlow. It uses the WithAcks method to set the desired acknowledgment level.  The example configures the producer to wait for acknowledgment from the leader only (Acks.Leader).\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/producers.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer(\n            \"product-events\",\n            producer => \n                producer\n                    .WithAcks(Acks.Leader)\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Consumer (C#)\nDESCRIPTION: This C# code configures a Kafka consumer using KafkaFlow. It defines the Kafka brokers, creates a topic if it doesn't exist, and configures the consumer with a JSON deserializer and a handler for HelloMessage. It starts and stops the Kafka bus, initiating and terminating the consumer.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\nusing Consumer;\n\nconst string topicName = \"sample-topic\";\nvar services = new ServiceCollection();\n\nservices.AddKafka(kafka => kafka\n    .UseConsoleLog()\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .CreateTopicIfNotExists(topicName, 1, 1)\n        .AddConsumer(consumer => consumer\n            .Topic(topicName)\n            .WithGroupId(\"sample-group\")\n            .WithBufferSize(100)\n            .WithWorkersCount(10)\n            .AddMiddlewares(middlewares => middlewares\n                .AddDeserializer<JsonCoreDeserializer>()\n                .AddTypedHandlers(h => h.AddHandler<HelloMessageHandler>())\n            )\n        )\n    )\n);\n\nvar serviceProvider = services.BuildServiceProvider();\n\nvar bus = serviceProvider.CreateKafkaBus();\n\nawait bus.StartAsync();\n\nConsole.ReadKey();\n\nawait bus.StopAsync();\n```\n\n----------------------------------------\n\nTITLE: Handling No Handler Found Event in KafkaFlow - C#\nDESCRIPTION: This code snippet demonstrates how to handle the event when no handler is found for a particular message type in KafkaFlow. It shows how to use the `WhenNoHandlerFound` method to execute custom logic when a message cannot be handled. This example logs the partition and offset of the unhandled message to the console.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/typed-handler-middleware.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            ...\n            .AddMiddlewares(middlewares => middlewares\n                ...\n                .AddTypedHandlers(handlers => handlers\n                    .AddHandler<ProductCreatedHandler>()\n                    .WhenNoHandlerFound(context => \n                        Console.WriteLine(\"Message not handled > Partition: {0} | Offset: {1}\",\n                            context.ConsumerContext.Partition,\n                            context.ConsumerContext.Offset)\n                        )\n                )\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Message Produce Completed Event in KafkaFlow (C#)\nDESCRIPTION: This code snippet demonstrates how to subscribe to the Message Produce Completed event in KafkaFlow. This event is triggered upon successful message production or when production errors occur. It allows for tracking successful message production. It utilizes `services.AddKafka` to configure KafkaFlow and subscribes to the `MessageProduceCompleted` event via `SubscribeGlobalEvents`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/global-events.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceCompleted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n```\n\n----------------------------------------\n\nTITLE: Subscribing Message Produce Completed Event in KafkaFlow\nDESCRIPTION: This snippet demonstrates how to subscribe to the Message Produce Completed Event in KafkaFlow using C#. This event is triggered when a message is successfully produced or when error messages occur during the production process. It enables you to track the successful completion of message production.  It requires the KafkaFlow library to be installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/global-events.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceCompleted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n)\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Message Consume Completed Event in KafkaFlow (C#)\nDESCRIPTION: This code snippet demonstrates how to subscribe to the Message Consume Completed event in KafkaFlow. It's triggered upon successful message consumption, enabling tracking of processed messages.  It utilizes `services.AddKafka` to configure KafkaFlow and subscribes to the `MessageProduceCompleted` event via `SubscribeGlobalEvents`. Note: The code snippet provided in the source document seems to be incorrect, subscribing to `MessageProduceCompleted` instead of `MessageConsumeCompleted`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/global-events.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceCompleted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n```\n\n----------------------------------------\n\nTITLE: Dynamic Worker Count Configuration - C#\nDESCRIPTION: This code snippet shows how to configure the worker count dynamically in KafkaFlow v3. It utilizes the `WithWorkersCount` method with a lambda expression to calculate the worker count based on the `WorkersCountContext` and `IDependencyResolver`. The worker count is re-evaluated every 15 minutes.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/migration/from-v2-to-v3.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\n.AddConsumer(\n    consumerBuilder => consumerBuilder\n        .Topic(\"test-topic\")\n        .WithGroupId(\"group1\")\n        .WithWorkersCount((context, resolver) => {\n          // Use whatever logic to determine the worker count\n          return GetWorkerCount(context, resolver);\n        }, TimeSpan.FromMinutes(15))\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Batching in KafkaFlow Consumer - C#\nDESCRIPTION: This code snippet demonstrates how to configure the Batch Consume Middleware within a KafkaFlow consumer using the `AddBatching` extension method. It sets the maximum batch size to 100 and the waiting time to 10 seconds. Dependencies: KafkaFlow library. The `HandlingMiddleware` is the next middleware that will process the batch.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/batch-consume-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(\n            consumerBuilder => consumerBuilder\n            ...\n            .AddMiddlewares(\n                middlewares => middlewares\n                    ...\n                    .AddBatching(100, TimeSpan.FromSeconds(10)) // Configuration of the BatchConsumeMiddleware\n                    .Add<HandlingMiddleware>() // Middleware to process the batch\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring ACKS for KafkaFlow Producer (C#)\nDESCRIPTION: This example shows how to configure the Acks (acknowledgments) setting for a KafkaFlow producer. It uses the `.WithAcks()` method during producer configuration to specify the required acknowledgment level. In this case, it's configured to `Acks.Leader`, which corresponds to `acks=1` in Kafka.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/producers.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer(\n            \"product-events\",\n            producer => \n                producer\n                    .WithAcks(Acks.Leader)\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Expose Swagger Documentation - Bash\nDESCRIPTION: This bash code snippet is used to expose generated Swagger documentation, allowing users to access the Swagger UI to explore and test Admin API operations. It configures middleware to serve Swagger and Swagger UI endpoints.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\napp.UseSwagger();\napp.UseSwaggerUI(c =>\n{\n    c.SwaggerEndpoint(\"/swagger/kafka-flow/swagger.json\", \"KafkaFlow Admin\");\n});\n```\n\n----------------------------------------\n\nTITLE: Subscribing Message Consume Started Event in KafkaFlow\nDESCRIPTION: This snippet demonstrates how to subscribe to the Message Consume Started Event in KafkaFlow using C#. This event is raised at the beginning of the message consumption process. It offers an opportunity to execute specific tasks or set up resources before message processing begins. It requires the KafkaFlow library to be installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/global-events.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageConsumeStarted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Project Reference (Bash)\nDESCRIPTION: This command adds a project reference from the Consumer project to the Producer project, enabling the Consumer to access classes and types defined in the Producer project (HelloMessage).\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add reference ../Producer\n```\n\n----------------------------------------\n\nTITLE: Configure Kafka with Console Logger in C#\nDESCRIPTION: This code snippet demonstrates how to configure KafkaFlow to use the console logger. It requires the `KafkaFlow.LogHandler.Console` package and uses the `UseConsoleLog` method within the Kafka configuration to direct log messages to the console output.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/logging.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .UseConsoleLog()\n        ...\n\n```\n\n----------------------------------------\n\nTITLE: Stopping a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet demonstrates how to stop a Kafka consumer using the `IConsumerAdmin` interface. It gets the `IConsumerAdmin` instance from IoC provider and calls the `StopConsumerAsync` method, passing the consumer name as a parameter. Requires access to the IoC provider.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.StopConsumerAsync(consumerName);\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Cluster with Docker Compose\nDESCRIPTION: This YAML file defines the configuration for an Apache Kafka cluster using Docker Compose. It includes services for Zookeeper, Kafka, and optionally, a UI for Kafka management.  It configures network settings, volumes for persistent data storage, and environment variables for Kafka broker settings.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nversion: '3.8'\n\nservices:\n  zookeeper:\n    image: confluentinc/cp-zookeeper:7.3.0\n    hostname: zookeeper\n    container_name: zookeeper\n    ports:\n      - \"2181:2181\"\n    environment:\n      ZOOKEEPER_CLIENT_PORT: 2181\n      ZOOKEEPER_TICK_TIME: 2000\n\n  kafka:\n    image: confluentinc/cp-kafka:7.3.0\n    hostname: kafka\n    container_name: kafka\n    depends_on:\n      - zookeeper\n    ports:\n      - \"9092:9092\"\n      - \"9999:9999\"\n    environment:\n      KAFKA_BROKER_ID: 1\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\n      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n      KAFKA_JMX_PORT: 9999\n      KAFKA_JMX_HOSTNAME: localhost\n    volumes:\n      - kafka_data:/var/lib/kafka/data\n\n  kafka-ui:\n    image: provectuslabs/kafka-ui:latest\n    container_name: kafka-ui\n    ports:\n      - \"8080:8080\"\n    depends_on:\n      - kafka\n    environment:\n      KAFKA_CLUSTERS_0_NAME: Local\n      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092\n\nvolumes:\n  kafka_data:\n```\n\n----------------------------------------\n\nTITLE: Updating KafkaFlow Package References to v3 - C#\nDESCRIPTION: This code snippet demonstrates how to update KafkaFlow package references from version 2.5.0 to version 3.0.0 in a .NET project's .csproj file. It involves modifying the `Version` attribute within the `<PackageReference>` elements for each KafkaFlow-related package. This is a crucial step in migrating to KafkaFlow v3.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/migration/from-v2-to-v3.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n<ItemGroup>\n-   <PackageReference Include=\"KafkaFlow\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Abstractions\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Admin\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Admin.Dashboard\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Admin.WebApi\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.BatchConsume\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Compressor\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Compressor.Gzip\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Extensions.Hosting\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.LogHandler.Console\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.LogHandler.Microsoft\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Microsoft.DependencyInjection\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.OpenTelemetry\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.SchemaRegistry\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.JsonCore\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.NewtonsoftJson\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.ProtobufNet\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentAvro\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentJson\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentProtobuf\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.TypedHandler\" Version=\"2.5.0\" />\n-   <PackageReference Include=\"KafkaFlow.Unity\" Version=\"2.5.0\" />\n\n+   <PackageReference Include=\"KafkaFlow\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Abstractions\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Admin\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Admin.Dashboard\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Admin.WebApi\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Compressor.Gzip\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Extensions.Hosting\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.LogHandler.Console\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.LogHandler.Microsoft\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Microsoft.DependencyInjection\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.OpenTelemetry\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.SchemaRegistry\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.JsonCore\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.NewtonsoftJson\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.ProtobufNet\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentAvro\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentJson\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentProtobuf\" Version=\"3.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Unity\" Version=\"3.0.0\" />\n</ItemGroup>\n```\n\n----------------------------------------\n\nTITLE: KafkaFlow Manual Offset Storage\nDESCRIPTION: This code demonstrates how to configure a KafkaFlow consumer to store offsets manually using the `WithManualStoreOffsets()` method. This gives the application control over when and how offsets are stored.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/consumers/add-consumers.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithManualStoreOffsets()\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Pausing a Consumer Group via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet demonstrates how to pause all Kafka consumers in a consumer group using the `IConsumerAdmin` interface. It gets the consumer admin and calls the `PauseConsumerGroupAsync` method, providing the groupId and the topic names. Requires access to the IoC provider.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_13\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.PauseConsumerGroupAsync(groupId, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Subscribing Message Produce Error Event in KafkaFlow\nDESCRIPTION: This snippet demonstrates how to subscribe to the Message Produce Error Event in KafkaFlow using C#. This event is triggered when an error occurs during message production. By subscribing to this event, you will be able to catch any exceptions that may occur while producing a message.  It requires the KafkaFlow library to be installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/global-events.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceError.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n)\n```\n\n----------------------------------------\n\nTITLE: JSON Deserialize Middleware Implementation in C#\nDESCRIPTION: This middleware deserializes a JSON message from a byte array. It retrieves the message type from the headers and uses JsonConvert to deserialize the message. It requires the `context.Message` to be a byte array and a \"Message-Type\" header to be present.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/middlewares.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\npublic class JsonDeserializeMiddleware : IMessageMiddleware\n{\n    public Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        if(!(context.Message is byte[] rawMessage))\n            throw new InvalidOperationException();\n\n        var type = Type.GetType(context.Headers.GetString(\"Message-Type\"));\n\n        var jsonMessage = Encoding.UTF8.GetString(rawMessage);\n\n        context.TransformMessage(JsonConvert.Deserialize(jsonMessage, MessageType));\n\n        return next(context);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating KafkaFlow Package References in .NET\nDESCRIPTION: This XML snippet demonstrates how to update KafkaFlow package references from version 3.1.0 to version 4.0.0 in a .NET project. It involves modifying the `Version` attribute of the `PackageReference` elements within the project's `.csproj` file. This change is essential for migrating to KafkaFlow v4.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/migration/from-v3-to-v4.md#_snippet_0\n\nLANGUAGE: XML\nCODE:\n```\n<ItemGroup>\n-   <PackageReference Include=\"KafkaFlow\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Abstractions\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Admin\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Admin.Dashboard\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Admin.WebApi\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Compressor.Gzip\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Extensions.Hosting\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.LogHandler.Console\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.LogHandler.Microsoft\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Microsoft.DependencyInjection\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.OpenTelemetry\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.SchemaRegistry\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.JsonCore\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.NewtonsoftJson\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.ProtobufNet\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentAvro\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentJson\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentProtobuf\" Version=\"3.1.0\" />\n-   <PackageReference Include=\"KafkaFlow.Unity\" Version=\"3.1.0\" />\n\n+   <PackageReference Include=\"KafkaFlow\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Abstractions\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Admin\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Admin.Dashboard\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Admin.WebApi\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Compressor.Gzip\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Extensions.Hosting\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.LogHandler.Console\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.LogHandler.Microsoft\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Microsoft.DependencyInjection\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.OpenTelemetry\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.SchemaRegistry\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.JsonCore\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.NewtonsoftJson\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.ProtobufNet\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentAvro\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentJson\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Serializer.SchemaRegistry.ConfluentProtobuf\" Version=\"4.0.0\" />\n+   <PackageReference Include=\"KafkaFlow.Unity\" Version=\"4.0.0\" />\n</ItemGroup>\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Compose Cluster (Bash)\nDESCRIPTION: This command starts the Docker Compose cluster in detached mode.  It uses the `docker-compose.yml` file located in the root of the repository to define and run the necessary services (e.g., Kafka, Zookeeper). The `-d` flag runs the containers in the background.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.BatchOperations/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Manual Message Completion - KafkaFlow C#\nDESCRIPTION: This snippet demonstrates how to enable manual message completion for a KafkaFlow consumer using `WithManualMessageCompletion()`.  This allows the application to control when offsets are stored. It requires KafkaFlow and Microsoft.Extensions.DependencyInjection.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/add-consumers.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithManualMessageCompletion()\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Configuring BatchConsume Middleware in KafkaFlow\nDESCRIPTION: Configures the BatchConsume middleware within the KafkaFlow consumer pipeline.  It defines the maximum batch size (100) and the time to wait for messages to form a batch (10 seconds). The HandlingMiddleware processes the resulting batch.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/batch-consume-middleware.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(\n            consumerBuilder => consumerBuilder\n            ...\n            .AddMiddlewares(\n                middlewares => middlewares\n                    ...\n                    .BatchConsume(100, TimeSpan.FromSeconds(10)) // Configuration of the BatchConsumeMiddleware\n                    .Add<HandlingMiddleware>() // Middleware to process the batch\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Ignore Message Middleware Implementation C#\nDESCRIPTION: This C# code snippet demonstrates a custom middleware for selectively ignoring Kafka messages based on a custom condition. It implements the `IMessageMiddleware` interface and calls an `UnwantedMessage` method to determine if a message should be ignored. If `UnwantedMessage` returns true, the middleware short-circuits the pipeline by not calling `next(context)`; otherwise, it proceeds to the next middleware.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/middlewares.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\npublic class IgnoreMessageMiddleware : IMessageMiddleware\n{\n    public Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        return UnwantedMessage(context) ?\n            Task.CompletedTask :\n            next(context);\n    }\n\n    private bool UnwantedMessage(IMessageContext context)\n    {\n        ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Start Docker Compose Cluster (Bash)\nDESCRIPTION: This command starts the Kafka cluster using Docker Compose in detached mode. It assumes a `docker-compose.yml` file is present in the current directory, defining the Kafka cluster setup. The `-d` flag runs the containers in the background.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.WebApi/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Configure KafkaFlow in Startup.cs (C#)\nDESCRIPTION: Configures KafkaFlow using the `Startup.cs` approach in ASP.NET Core. It registers KafkaFlow dependencies in `ConfigureServices` and starts the Kafka bus in the `Configure` method when the application starts. It uses the `AddKafka` extension method and registers an event to start the Kafka bus when the application starts.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/configuration.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\npublic void ConfigureServices(IServiceCollection services)\n{\n    services.AddKafka(kafka => kafka\n        .UseConsoleLog()\n        .AddCluster(cluster => cluster\n            .WithBrokers(new[] { \"localhost:9092\" })\n            ...\n        )\n    );\n}\n\npublic void Configure(\n    IApplicationBuilder app,\n    IWebHostEnvironment env,\n    IHostApplicationLifetime lifetime)\n{\n    var kafkaBus = app.ApplicationServices.CreateKafkaBus();\n\n    lifetime.ApplicationStarted.Register(() => kafkaBus.StartAsync(lifetime.ApplicationStopped));\n}\n```\n\n----------------------------------------\n\nTITLE: Ignore Message Middleware Implementation in C#\nDESCRIPTION: This middleware allows selectively ignoring messages based on a custom condition. It checks if a message is unwanted and skips processing if it is. The `UnwantedMessage` method contains the logic for determining if a message should be ignored.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/middlewares.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\npublic class IgnoreMessageMiddleware : IMessageMiddleware\n{\n    public Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        return UnwantedMessage(context) ?\n            Task.CompletedTask :\n            next(context);\n    }\n\n    private bool UnwantedMessage(IMessageContext context)\n    {\n        ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Compose for Kafka Cluster\nDESCRIPTION: This command starts the Kafka cluster defined in the docker-compose.yml file in detached mode. It requires Docker Desktop to be installed and running. The docker-compose file should be located at the root of the repository.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.OpenTelemetry/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Creating a Message Handler - C#\nDESCRIPTION: This snippet shows how to create a message handler by implementing the `IMessageHandler<MessageType>` interface. The handler's instance is created by the configured dependency injection container, allowing dependency injection through the constructor. The instance lifetime is configurable.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/typed-handler-middleware.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\npublic class ProductCreatedHandler : IMessageHandler<ProductCreatedEvent>\n{\n    public Task Handle(IMessageContext context, ProductCreatedEvent message)\n    {\n        ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Subscribing Message Produce Started Event in KafkaFlow\nDESCRIPTION: This snippet demonstrates how to subscribe to the Message Produce Started Event in KafkaFlow using C#. This event is triggered at the beginning of the message production process, allowing developers to execute tasks or gather information before middlewares execution.  It requires the KafkaFlow library to be installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/global-events.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceStarted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n)\n```\n\n----------------------------------------\n\nTITLE: Installing KafkaFlow Packages (Bash)\nDESCRIPTION: These commands add required KafkaFlow and related NuGet packages to the .NET projects. They include KafkaFlow core, dependency injection, console logging, JSON serialization, and Microsoft extensions for dependency injection.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\n```\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\n```\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.LogHandler.Console\n```\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.Serializer.JsonCore\n```\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Microsoft.Extensions.DependencyInjection\n```\n\n----------------------------------------\n\nTITLE: Setting Default Topic for a KafkaFlow Producer (C#)\nDESCRIPTION: This snippet demonstrates how to set a default topic for a KafkaFlow producer during its configuration.  When a default topic is set, you don't have to specify the topic when calling `ProduceAsync`. The producer will automatically send messages to the configured default topic.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/producers.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer(\n            \"product-events\",\n            producer => \n                producer\n                    .DefaultTopic(\"products-topic\")\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Install KafkaFlow.BatchConsume package\nDESCRIPTION: Installs the KafkaFlow.BatchConsume NuGet package, which is required to use the Batch Consume Middleware. This package provides the necessary components for batch processing of Kafka messages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/batch-consume-middleware.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.BatchConsume\n```\n\n----------------------------------------\n\nTITLE: Start Kafka Cluster using Docker Compose\nDESCRIPTION: This snippet demonstrates how to start a Kafka cluster using Docker Compose.  It requires Docker Desktop to be installed and the docker-compose.yml file to be present in the current directory. The command starts the services defined in the docker-compose.yml file in detached mode.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.FlowControl/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow in Startup.cs (C#)\nDESCRIPTION: This C# snippet demonstrates how to configure KafkaFlow within the `Startup.cs` class of an ASP.NET Core application. It configures KafkaFlow dependencies in the `ConfigureServices` method and registers an event in the `Configure` method to start the Kafka Bus upon application startup. The cluster brokers are configured using the fluent builder.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/configuration.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\npublic void ConfigureServices(IServiceCollection services)\n{\n    services.AddKafka(kafka => kafka\n        .UseConsoleLog()\n        .AddCluster(cluster => cluster\n            .WithBrokers(new[] { \"localhost:9092\" })\n            ...\n        )\n    );\n}\n\npublic void Configure(\n    IApplicationBuilder app,\n    IWebHostEnvironment env,\n    IHostApplicationLifetime lifetime)\n{\n    var kafkaBus = app.ApplicationServices.CreateKafkaBus();\n\n    lifetime.ApplicationStarted.Register(() => kafkaBus.StartAsync(lifetime.ApplicationStopped));\n}\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Message Produce Error Event in KafkaFlow (C#)\nDESCRIPTION: This code snippet shows how to subscribe to the Message Produce Error event in KafkaFlow. This event is triggered when an error occurs during message production.  Subscribing to this event provides a mechanism to catch and handle exceptions during the production process. It utilizes `services.AddKafka` to configure KafkaFlow and subscribes to the `MessageProduceError` event via `SubscribeGlobalEvents`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/global-events.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceError.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n```\n\n----------------------------------------\n\nTITLE: Configuring Offset Strategy - KafkaFlow C#\nDESCRIPTION: This snippet demonstrates how to configure the offset strategy for a KafkaFlow consumer using `WithAutoOffsetReset()`.  It requires KafkaFlow and Microsoft.Extensions.DependencyInjection. It sets the strategy to `AutoOffsetReset.Earliest` to read from the beginning of the topic if no offset is stored.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/add-consumers.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithAutoOffsetReset(AutoOffsetReset.Earliest)\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Starting Kafka Cluster with Docker Compose\nDESCRIPTION: This command starts the Apache Kafka cluster defined in the docker-compose.yml file in detached mode. This command uses Docker Compose to spin up the required Kafka infrastructure.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Exposing Swagger Documentation in .NET (C#)\nDESCRIPTION: This C# code snippet shows how to expose the generated Swagger documentation in a .NET application. It uses the `app.UseSwagger()` and `app.UseSwaggerUI()` methods to enable the Swagger UI, making the API documentation accessible via a specific endpoint (`/swagger/`).\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\napp.UseSwagger();\napp.UseSwaggerUI(c =>\n{\n    c.SwaggerEndpoint(\"/swagger/kafka-flow/swagger.json\", \"KafkaFlow Admin\");\n});\n```\n\n----------------------------------------\n\nTITLE: Logging Middleware Implementation C#\nDESCRIPTION: This C# code snippet demonstrates a custom middleware for logging Kafka messages and their processing time. It implements the `IMessageMiddleware` interface and uses an `ILogger` to record message receipt and processing duration, leveraging the `Stopwatch` class for precise timing. The middleware constructor requires an `ILogger` instance through dependency injection.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/middlewares.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\npublic class LoggingMiddleware : IMessageMiddleware\n{\n    private readonly ILogger log;\n\n    public LoggingMiddleware(ILogger log)\n    {\n        this.log = log ?? throw new ArgumentNullException(nameof(log));\n    }\n\n    public async Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        this.log.Info(\"Kafka Message Received\");\n\n        var sw = Stopwatch.StartNew();\n\n        await next(context).ConfigureAwait(false);\n\n        sw.Stop();\n\n        this.log.Info(\n            \"Kafka Message processed\",\n            () => new\n            {\n                MessageType = context.Message?.GetType().FullName,\n                ProcessingTime = sw.ElapsedMilliseconds\n            });\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Run .NET Application (Bash)\nDESCRIPTION: This command runs the .NET application. It assumes that you are in the directory containing the .csproj file. It builds and executes the application, and Swagger UI will be accessible on `/swagger/`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.WebApi/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Configure KafkaFlow with Unity DI (C#)\nDESCRIPTION: Configures KafkaFlow using the Unity dependency injection container.  It creates a Unity container, configures KafkaFlow using `KafkaFlowConfigurator`, and creates a Kafka bus.  It then starts and stops the bus when the application starts and stops. It depends on the `KafkaFlowConfigurator` and `UnityDependencyResolver` classes.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/configuration.md#_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow.Configuration;\nusing KafkaFlow.Unity;\nusing Unity;\n\n\nstatic class Program\n{\n    public static async Task Main(string[] args)\n    {\n        var container = new UnityContainer();\n\n        var configurator = new KafkaFlowConfigurator(\n            new UnityDependencyConfigurator(container),\n            kafka => kafka\n                .AddCluster(cluster => cluster\n                    .WithBrokers(new[] { \"localhost:9092\" })\n                    ...\n                )\n        );\n\n        var bus = configurator.CreateBus(new UnityDependencyResolver(container));\n\n        // Call when your app starts\n        await bus.StartAsync();\n\n        // Call when your app stops\n        await bus.StopAsync();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configure Kafka with Microsoft Logging in C#\nDESCRIPTION: This code snippet demonstrates how to configure KafkaFlow to use the Microsoft Logging Framework. It requires the `KafkaFlow.LogHandler.Microsoft` package and utilizes the `UseMicrosoftLog` method within the Kafka configuration to integrate with the standard Microsoft logging infrastructure.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/logging.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .UseMicrosoftLog()\n        ...\n\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Batch in Middleware - C#\nDESCRIPTION: This code snippet shows how to access the message batch within a KafkaFlow middleware using the `GetMessagesBatch` method of the `IMessageContext`. The `batch` variable then contains the collection of messages that were batched by the Batch Consume Middleware. Dependencies: KafkaFlow library.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/batch-consume-middleware.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\n\ninternal class HandlingMiddleware : IMessageMiddleware\n{\n    public Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        var batch = context.GetMessagesBatch();\n        \n        (...)\n\n        return Task.CompletedTask;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Start Kafka Cluster with Docker Compose\nDESCRIPTION: This command uses Docker Compose to start the Kafka cluster in detached mode. It assumes a docker-compose.yml file exists in the current directory that defines the Kafka cluster services and their configurations. Ensure Docker Desktop is running before executing this command.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.CooperativeSticky/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Installing KafkaFlow packages using .NET CLI\nDESCRIPTION: This snippet demonstrates how to install the required KafkaFlow packages using the .NET CLI. It installs KafkaFlow, KafkaFlow.Microsoft.DependencyInjection, and KafkaFlow.LogHandler.Console packages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/installation.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package KafkaFlow.LogHandler.Console\n```\n\n----------------------------------------\n\nTITLE: KafkaFlow Disabling Offset Storage\nDESCRIPTION: This snippet shows how to disable offset storage for a KafkaFlow consumer using the `WithoutStoringOffsets()` method. This is useful when offset management is not required.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/consumers/add-consumers.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\nusing KafkaFlow.TypedHandler;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithoutStoringOffsets()\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Running the .NET KafkaFlow Sample\nDESCRIPTION: This command executes the .NET application located in the sample folder. It requires the .NET 6.0 SDK to be installed. The command compiles and runs the application, which produces and consumes messages from the Kafka cluster.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.OpenTelemetry/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Pause Consumer On Exception Middleware in C#\nDESCRIPTION: This middleware pauses the consumer when an exception is raised during message processing. It catches exceptions, logs the error, sets `ShouldStoreOffset` to false to prevent offset commits, and then pauses the consumer. It requires an `IConsumerAccessor` and `ILogHandler`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/middlewares.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow.Consumers;\n\npublic class PauseConsumerOnExceptionMiddleware : IMessageMiddleware\n{\n    private readonly IConsumerAccessor consumerAccessor;\n    private readonly ILogHandler logHandler;\n\n    public PauseConsumerOnExceptionMiddleware(IConsumerAccessor consumerAccessor, ILogHandler logHandler)\n    {\n        this.consumerAccessor = consumerAccessor;\n        this.logHandler = logHandler;\n    }\n\n    public async Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        try\n        {\n            await next(context);\n        }\n        catch (Exception exception)\n        {\n            context.ConsumerContext.ShouldStoreOffset = false;\n            this.logHandler.Error(\"Error handling message\", exception,\n                new\n                {\n                    context.Message,\n                    context.ConsumerContext.Topic,\n                    MessageKey = context.Message.Key,\n                    context.ConsumerContext.ConsumerName,\n                });\n\n            var consumer = this.consumerAccessor[context.ConsumerContext.ConsumerName];\n            consumer.Pause(consumer.Assignment);\n\n            this.logHandler.Warning(\"Consumer stopped\", context.ConsumerContext.ConsumerName);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Run .NET Sample Application\nDESCRIPTION: This command executes the .NET sample application. It assumes that the terminal is positioned within the sample folder. It compiles and runs the .NET project located in the current directory.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Run .NET KafkaFlow Sample\nDESCRIPTION: This command runs the KafkaFlow sample application. It assumes that the terminal is positioned in the sample folder and that the .NET 6.0 SDK is installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.Dashboard/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Pause Consumer on Exception Middleware Implementation C#\nDESCRIPTION: This C# code snippet demonstrates a custom middleware for pausing a Kafka consumer upon encountering an exception during message processing. It implements the `IMessageMiddleware` interface, uses an `IConsumerAccessor` to get the consumer instance and `ILogHandler` to log errors. On exception, it stops offset storing, pauses the consumer and logs the event.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/middlewares.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow.Consumers;\n\npublic class PauseConsumerOnExceptionMiddleware : IMessageMiddleware\n{\n    private readonly IConsumerAccessor consumerAccessor;\n    private readonly ILogHandler logHandler;\n\n    public PauseConsumerOnExceptionMiddleware(IConsumerAccessor consumerAccessor, ILogHandler logHandler)\n    {\n        this.consumerAccessor = consumerAccessor;\n        this.logHandler = logHandler;\n    }\n\n    public async Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        try\n        {\n            await next(context);\n        }\n        catch (Exception exception)\n        {\n            context.ConsumerContext.ShouldStoreOffset = false;\n            this.logHandler.Error(\"Error handling message\", exception,\n                new\n                {\n                    context.Message,\n                    context.ConsumerContext.Topic,\n                    MessageKey = context.Message.Key,\n                    context.ConsumerContext.ConsumerName,\n                });\n\n            var consumer = this.consumerAccessor[context.ConsumerContext.ConsumerName];\n            consumer.Pause(consumer.Assignment);\n\n            this.logHandler.Warning(\"Consumer stopped\", context.ConsumerContext.ConsumerName);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Run .NET Sample\nDESCRIPTION: This command runs the KafkaFlow Schema Registry Sample application. It navigates to the sample folder and executes the `dotnet run` command, which compiles and runs the .NET project.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.SchemaRegistry/README.md#_snippet_1\n\nLANGUAGE: dotnet\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Resume Consumer - C#\nDESCRIPTION: This C# code snippet demonstrates how to resume a paused Kafka consumer using the IConsumerAdmin interface.  It retrieves the IConsumerAdmin service and then uses the ResumeConsumerAsync method with the consumer name and relevant topic names to restart consumer activity.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_8\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ResumeConsumerAsync(consumerName, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Accessing Message Batch in KafkaFlow Middleware\nDESCRIPTION: Demonstrates how to access the batch of messages within a KafkaFlow middleware. The `GetMessagesBatch` method on the `context` provides access to the batched messages for processing.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/batch-consume-middleware.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow.BatchConsume;\n\ninternal class HandlingMiddleware : IMessageMiddleware\n{\n    public Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        var batch = context.GetMessagesBatch();\n        \n        (...)\n\n        return Task.CompletedTask;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding KafkaFlow Packages for Unity DI (Bash)\nDESCRIPTION: This bash snippet adds the necessary NuGet packages when using the Unity DI container with KafkaFlow. It adds both the core KafkaFlow package and the KafkaFlow.Unity package, which provides the integration between KafkaFlow and the Unity dependency injection framework.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/configuration.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Unity\n```\n\n----------------------------------------\n\nTITLE: Adding KafkaFlow Admin Packages with Dotnet CLI\nDESCRIPTION: This snippet demonstrates how to add the necessary KafkaFlow Admin packages to a .NET project using the dotnet CLI. It includes the KafkaFlow.Microsoft.DependencyInjection, KafkaFlow.Admin, and KafkaFlow.Admin.WebApi packages, enabling administrative features for KafkaFlow.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package KafkaFlow.Admin\ndotnet add package KafkaFlow.Admin.WebApi\n```\n\n----------------------------------------\n\nTITLE: Restart Consumer - C#\nDESCRIPTION: This C# snippet restarts a Kafka consumer using the IConsumerAdmin interface. The consumer is restarted without changing offsets, which causes a partition rebalance.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_9\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.RestartConsumerAsync(consumerName);\n```\n\n----------------------------------------\n\nTITLE: Resuming a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet demonstrates how to resume a Kafka consumer using the `IConsumerAdmin` interface.  It retrieves `IConsumerAdmin` from IoC and calls `ResumeConsumerAsync` with the consumer name and topic names. Requires access to the IoC provider.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_8\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ResumeConsumerAsync(consumerName, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Install KafkaFlow Packages (Hosted Service)\nDESCRIPTION: Installs the necessary NuGet packages for using KafkaFlow as a hosted service in a .NET application.  This includes KafkaFlow core, the Hosting extension, Microsoft Dependency Injection integration, and the Microsoft Hosting package. This is required for console applications.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/configuration.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Extensions.Hosting\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package Microsoft.Extensions.Hosting\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Message Produce Started Event in KafkaFlow (C#)\nDESCRIPTION: This code snippet demonstrates how to subscribe to the Message Produce Started event in KafkaFlow. This event is triggered at the start of the message production process, allowing you to execute logic before the middlewares are invoked.  It utilizes `services.AddKafka` to configure KafkaFlow and subscribes to the `MessageProduceStarted` event via `SubscribeGlobalEvents`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/global-events.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .SubscribeGlobalEvents(observers =>\n        {\n            observers.MessageProduceStarted.Subscribe(eventContext =>\n            {\n                // Add your logic here\n            });\n        })\n```\n\n----------------------------------------\n\nTITLE: Consumer Configuration Before v3 - C#\nDESCRIPTION: This code snippet shows how to configure a KafkaFlow consumer before version 3, using `.AddSerializer()` and `.AddCompressor()` for message deserialization and decompression. It highlights the use of `JsonCoreSerializer` and `GzipMessageCompressor`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/migration/from-v2-to-v3.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\n.AddConsumer(\n    consumerBuilder => consumerBuilder\n        .Topic(\"test-topic\")\n        .WithGroupId(\"group1\")\n        .AddMiddlewares(\n            middlewares => middlewares\n                .AddCompressor<GzipMessageCompressor>()\n                .AddSerializer<JsonCoreSerializer>()\n        )\n)\n```\n\n----------------------------------------\n\nTITLE: Start Docker Compose Cluster\nDESCRIPTION: This command starts the Kafka cluster defined in the docker-compose file in detached mode. It requires Docker Desktop to be installed and running. The docker-compose file should be located in the root of the repository.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.Dashboard/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Defining a Message Contract\nDESCRIPTION: This C# code defines a simple message contract named `HelloMessage` with a `Text` property. This class represents the structure of the message that will be sent and received by the Kafka producer and consumer.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nnamespace Producer;\n\npublic class HelloMessage\n{\n    public string Text { get; set; } = default!;\n}\n```\n\n----------------------------------------\n\nTITLE: KafkaFlow Offset Strategy Configuration\nDESCRIPTION: This example shows how to configure the offset strategy for a KafkaFlow consumer using the `WithAutoOffsetReset()` method. It sets the offset reset policy to `AutoOffsetReset.Earliest`, which will read from the beginning of the topic if no offset is stored.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/consumers/add-consumers.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithAutoOffsetReset(AutoOffsetReset.Earliest)\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Running .NET Projects (Bash)\nDESCRIPTION: These commands run the Consumer and Producer .NET projects using the .NET CLI. The --project argument specifies the project file to execute.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run --project Consumer/Consumer.csproj \n```\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run --project Producer/Producer.csproj \n```\n\n----------------------------------------\n\nTITLE: Running the .NET Sample Application (Bash)\nDESCRIPTION: This command executes the .NET application. It assumes that the terminal is positioned in the sample folder. The `dotnet run` command builds and runs the application defined by the `csproj` file in that directory.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.BatchOperations/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Adding Compressor Middleware to KafkaFlow Producer in C#\nDESCRIPTION: This code snippet demonstrates how to add the compressor middleware to a KafkaFlow producer using the `AddCompressor` extension method. It shows how to use both a generic type parameter (e.g., `GzipMessageCompressor`) and a resolver factory method to provide an instance of the compressor. The `KafkaFlow.Compressor` and `KafkaFlow.Compressor.Gzip` packages are required. Replace `localhost:9092` with your Kafka brokers.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/compressor-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\npublic class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddKafka(kafka => kafka\n            .AddCluster(cluster => cluster\n                .WithBrokers(new[] { \"localhost:9092\" })\n                .AddProducer<ProductEventsProducer>(producer => producer\n                    ...\n                    .AddMiddlewares(middlewares => middlewares\n                        ...\n                        .AddCompressor<GzipMessageCompressor>()\n                        // or\n                        .AddCompressor(resolver => new GzipMessageCompressor(...))\n                        ...\n                    )\n                )\n            )\n        );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Pausing a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet shows how to pause a Kafka consumer using the `IConsumerAdmin` interface.  It gets the `IConsumerAdmin` instance from IoC and calls the `PauseConsumerAsync` method, providing consumer name and topic names. Requires access to the IoC provider.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.PauseConsumerAsync(consumerName, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Run the KafkaFlow Sample Application\nDESCRIPTION: This command executes the KafkaFlow sample application using the .NET CLI. It assumes that the terminal is positioned within the sample application's folder and that the .NET 6.0 SDK is installed. The application will produce and consume messages as defined in its code.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.CooperativeSticky/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: JSON Deserialization Middleware Implementation C#\nDESCRIPTION: This C# code snippet demonstrates a custom middleware for deserializing JSON messages in KafkaFlow. It implements the `IMessageMiddleware` interface, retrieves the message type from the headers, deserializes the JSON payload using `JsonConvert.Deserialize`, and transforms the message within the context. It assumes the message is a byte array and throws an exception if it isn't. This is a simplified sample, and the `Serializer Middleware` should be used instead.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/middlewares.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\npublic class JsonDeserializeMiddleware : IMessageMiddleware\n{\n    public Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        if(!(context.Message is byte[] rawMessage))\n            throw new InvalidoperationException();\n\n        var type = Type.GetType(context.Headers.GetString(\"Message-Type\"));\n\n        var jsonMessage = Encoding.UTF8.GetString(rawMessage);\n\n        context.TransformMessage(JsonConvert.Deserialize(jsonMessage, MessageType));\n\n        return next(context);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Resume Consumer Group - C#\nDESCRIPTION: This C# code resumes a paused consumer group using the IConsumerAdmin interface. The code obtains an IConsumerAdmin instance, and then calls the ResumeConsumerGroupAsync method, using the group ID and topic names.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_14\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ResumeConsumerGroupAsync(groupId, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow Producer\nDESCRIPTION: This C# code configures the KafkaFlow producer to send messages to a specified Kafka topic. It sets up dependency injection, configures the Kafka cluster with broker addresses, creates the topic if it doesn't exist, and adds a producer with JSON serialization. The producer sends a `HelloMessage` to the topic.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.Extensions.DependencyInjection;\nusing KafkaFlow.Producers;\nusing KafkaFlow.Serializer;\nusing KafkaFlow;\nusing Producer;\n\nvar services = new ServiceCollection();\n\nconst string topicName = \"sample-topic\";\nconst string producerName = \"say-hello\";\n\nservices.AddKafka(\n    kafka => kafka\n        .UseConsoleLog()\n        .AddCluster(\n            cluster => cluster\n                .WithBrokers(new[] { \"localhost:9092\" })\n                .CreateTopicIfNotExists(topicName, 1, 1)\n                .AddProducer(\n                    producerName,\n                    producer => producer\n                        .DefaultTopic(topicName)\n                        .AddMiddlewares(m =>\n                            m.AddSerializer<JsonCoreSerializer>()\n                            )\n                )\n        )\n);\n\nvar serviceProvider = services.BuildServiceProvider();\n\nvar producer = serviceProvider\n    .GetRequiredService<IProducerAccessor>()\n    .GetProducer(producerName);\n\nawait producer.ProduceAsync(\n                   topicName,\n                   Guid.NewGuid().ToString(),\n                   new HelloMessage { Text = \"Hello!\" });\n\n\nConsole.WriteLine(\"Message sent!\");\n\n```\n\n----------------------------------------\n\nTITLE: Pause Consumer - C#\nDESCRIPTION: This C# code demonstrates how to pause a Kafka consumer using the IConsumerAdmin interface.  It retrieves the IConsumerAdmin service and uses the PauseConsumerAsync method with the consumer name and topic names to temporarily halt the consumer's activity.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.PauseConsumerAsync(consumerName, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Start Consumer - C#\nDESCRIPTION: This C# code snippet shows how to start a Kafka consumer using the IConsumerAdmin interface. It retrieves the IConsumerAdmin service from the service provider and calls the StartConsumerAsync method with the consumer name.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.StartConsumerAsync(consumerName);\n```\n\n----------------------------------------\n\nTITLE: Configuring KafkaFlow with Unity DI (C#)\nDESCRIPTION: This C# snippet demonstrates configuring KafkaFlow using the Unity dependency injection container.  It initializes a Unity container, creates a `KafkaFlowConfigurator` with `UnityDependencyConfigurator`, and configures the Kafka cluster.  It then creates and starts the Kafka bus using a `UnityDependencyResolver`. This ensures that KafkaFlow's dependencies are managed and resolved through the Unity container.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/configuration.md#_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow.Configuration;\nusing KafkaFlow.Unity;\nusing Unity;\n\n\nstatic class Program\n{\n    public static async Task Main(string[] args)\n    {\n        var container = new UnityContainer();\n\n        var configurator = new KafkaFlowConfigurator(\n            new UnityDependencyConfigurator(container),\n            kafka => kafka\n                .AddCluster(cluster => cluster\n                    .WithBrokers(new[] { \"localhost:9092\" })\n                    ...\n                )\n        );\n\n        var bus = configurator.CreateBus(new UnityDependencyResolver(container));\n\n        // Call when your app starts\n        await bus.StartAsync();\n\n        // Call when your app stops\n        await bus.StopAsync();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Restarting a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet shows how to restart a Kafka consumer using the `IConsumerAdmin` interface. It retrieves the `IConsumerAdmin` instance and calls the `RestartConsumerAsync` method, providing the consumer name as a parameter. Requires access to the IoC provider.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_9\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.RestartConsumerAsync(consumerName);\n```\n\n----------------------------------------\n\nTITLE: Start Docker Cluster\nDESCRIPTION: This command starts the Kafka cluster using Docker Compose. It positions the terminal in the directory containing the docker-compose.yml file and executes the `docker-compose up -d` command to start the services in detached mode.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.SchemaRegistry/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Error Handling Middleware Implementation C#\nDESCRIPTION: This C# code snippet demonstrates a custom middleware for handling exceptions during Kafka message processing.  It implements the `IMessageMiddleware` interface and utilizes a try-catch block within the `Invoke` method to catch any exceptions that occur during the execution of the next middleware. If an exception is caught, it logs the error using the provided `ILogger`.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/middlewares.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\npublic class ErrorHandlingMiddleware : IMessageMiddleware\n{\n    private readonly ILogger log;\n\n    public ErrorHandlingMiddleware(ILogger log)\n    {\n        this.log = log ?? throw new ArgumentNullException(nameof(log));\n    }\n\n    public async Task Invoke(IMessageContext context, MiddlewareDelegate next)\n    {\n        try\n        {\n            await next(context).ConfigureAwait(false);\n        }\n        catch(Exception ex)\n        {\n            this.log.Error(\"Error processing message\", ex);\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Consumer Throttling with KafkaFlow Fluent Interface in C#\nDESCRIPTION: This code snippet demonstrates how to configure Consumer Throttling in KafkaFlow using its fluent interface. It configures throttling for a consumer listening to \"bulk-topic\" based on the lag of \"singleConsumer\". It specifies an interval of 5 seconds for checking metrics and adds actions to apply delays based on lag thresholds.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/consumer-throttling-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n.AddConsumer(\n    consumer => consumer\n        .Topic(\"bulk-topic\")\n        .WithName(\"bulkConsumer\")\n        .AddMiddlewares(\n            middlewares => middlewares\n                .ThrottleConsumer(\n                    t => t\n                        .ByOtherConsumersLag(\"singleConsumer\")\n                        .WithInterval(TimeSpan.FromSeconds(5))\n                        .AddAction(a => a.AboveThreshold(10).ApplyDelay(100))\n                        .AddAction(a => a.AboveThreshold(100).ApplyDelay(1_000))\n                        .AddAction(a => a.AboveThreshold(1_000).ApplyDelay(10_000)))\n                .AddDeserializer<JsonCoreDeserializer>()\n        )\n)\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration\nDESCRIPTION: This docker-compose.yml configuration sets up an Apache Kafka cluster using Zookeeper and Kafka. It defines the necessary services, ports, and environment variables for a basic Kafka setup, enabling communication between producer and consumer applications.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Rewind Offsets - C#\nDESCRIPTION: This C# code rewinds the offsets of a Kafka consumer to a specific date using the IConsumerAdmin interface. It stops the consumers, searches for the first offset before the DateTime, commits the new offsets, and restarts the consumers.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_11\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.RewindOffsetsAsync(consumerName, DateTime.Today.AddDays(-1), new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Running .NET Project\nDESCRIPTION: This command executes a .NET project specified by its project file.  It compiles and runs the application.  The `--project` argument specifies the path to the project file.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run --project Consumer/Consumer.csproj\n```\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run --project Producer/Producer.csproj\n```\n\n----------------------------------------\n\nTITLE: Creating .NET Console Project\nDESCRIPTION: This command creates a new .NET console application project. The `--name` parameter specifies the name of the project to be created.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet new console --name Producer\n```\n\n----------------------------------------\n\nTITLE: Configuring Name-Based Producer in KafkaFlow (C#)\nDESCRIPTION: This code demonstrates how to configure a name-based producer in KafkaFlow using the `AddKafka` extension method. It configures a Kafka cluster, adds a producer with the name \"product-events\", and shows how to access the producer via `IProducerAccessor` to produce messages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/producers.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing Microsoft.Extensions.DependencyInjection;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer(\n            \"product-events\", //the producer name\n            producer => \n                producer\n        )\n    )\n);\n\npublic class ProductService : IProductService\n{\n    private readonly IProducerAccessor _producers;\n\n    public ProductService(IProducerAccessor producers)\n    {\n        _producers = producers;\n    }\n\n    public async Task CreateProduct(Product product) =>\n        await _producers[\"product-events\"]\n            .ProduceAsync(product.Id.ToString(), product);     \n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Schema Registry with Avro Serializer\nDESCRIPTION: This C# code demonstrates how to configure KafkaFlow with schema registry and the Avro serializer. It includes configuring the schema registry URL and adding the `AddSchemaRegistryAvroSerializer` middleware to both producer and consumer pipelines.  The AvroSerializerConfig is used to specify the subject name strategy.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/serializer-middleware.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\npublic class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        services.AddKafka(\n            kafka => kafka\n                .AddCluster(\n                    cluster => cluster\n                        .WithBrokers(new[] { \"localhost:9092\" })\n                        .WithSchemaRegistry(config => config.Url = \"localhost:8081\")\n                        .AddProducer(\n                            ...\n                            .AddMiddlewares(middlewares => \n                                    middlewares.AddSchemaRegistryAvroSerializer(new AvroSerializerConfig{ SubjectNameStrategy = SubjectNameStrategy.TopicRecord })\n                        )\n                       .AddConsumer(\n                            ...\n                            .AddMiddlewares(middlewares => middlewares.AddSchemaRegistryAvroSerializer()\n                        )\n                    )\n            );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Yarn\nDESCRIPTION: This command installs all the necessary dependencies for the website project using Yarn package manager. It's a prerequisite for running the development server, building the project, or deploying it.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ yarn\n```\n\n----------------------------------------\n\nTITLE: Change Workers Count - C#\nDESCRIPTION: This C# code snippet changes the number of workers for a KafkaFlow consumer using the IConsumerAdmin interface. This causes a rebalance between the consumers.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_12\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ChangeWorkersCountAsync(consumerName, 100);\n```\n\n----------------------------------------\n\nTITLE: Starting Kafka Broker with Make\nDESCRIPTION: This command, using `make`, initializes and starts a Kafka cluster. It likely relies on Docker to manage the Kafka broker and its dependencies, as suggested in the documentation.  It expects a `Makefile` in the repository root directory.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/CONTRIBUTING.md#_snippet_3\n\nLANGUAGE: Makefile\nCODE:\n```\nmake init_broker\n```\n\n----------------------------------------\n\nTITLE: Subscribe to Global Events - C#\nDESCRIPTION: This code snippet demonstrates how to subscribe to global KafkaFlow events, such as `MessageConsumeStarted`, `MessageConsumeError`, and `MessageConsumeCompleted`. These events provide insights into the internal workings of KafkaFlow and can be used for monitoring or logging purposes.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/migration/from-v2-to-v3.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(\n    kafka => kafka\n        .UseConsoleLog()\n        .SubscribeGlobalEvents(hub =>\n        {\n            hub.MessageConsumeStarted.Subscribe(eventContext => Console.WriteLine(\"Message Consume Started\"));\n\n            hub.MessageConsumeError.Subscribe(eventContext => Console.WriteLine(\"Message Consume Error\"));\n\n            hub.MessageConsumeCompleted.Subscribe(eventContext => Console.WriteLine(\"Message Consume Completed\"));\n\n            hub.MessageProduceStarted.Subscribe(eventContext => Console.WriteLine(\"Message Produce Started\"));\n\n            hub.MessageProduceError.Subscribe(eventContext => Console.WriteLine(\"Message Produce Error\"));\n\n            hub.MessageProduceCompleted.Subscribe(eventContext => Console.WriteLine(\"Message Produce Completed\"));\n        })\n);\n```\n\n----------------------------------------\n\nTITLE: Building Static Content with Yarn\nDESCRIPTION: This command builds the website into static content that can be hosted on any static content hosting service. It uses Yarn to execute the build script, which typically generates an optimized production-ready version of the website.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ yarn build\n```\n\n----------------------------------------\n\nTITLE: Deploying with SSH using Yarn\nDESCRIPTION: This command deploys the website using SSH. The `USE_SSH=true` environment variable enables SSH-based deployment. This assumes the deployment script is configured to use SSH for pushing changes to the remote server.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ USE_SSH=true yarn deploy\n```\n\n----------------------------------------\n\nTITLE: Stop Consumer - C#\nDESCRIPTION: This C# code snippet demonstrates how to stop a Kafka consumer using the IConsumerAdmin interface.  It retrieves the IConsumerAdmin service and calls the StopConsumerAsync method with the consumer name to halt the consumer's operation.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.StopConsumerAsync(consumerName);\n```\n\n----------------------------------------\n\nTITLE: Reset Offsets - C#\nDESCRIPTION: This C# code snippet shows how to reset the offsets of a Kafka consumer using the IConsumerAdmin interface.  It retrieves the IConsumerAdmin service from the provider, and invokes ResetOffsetsAsync, passing in the consumer name and topic names.  This triggers a consumer stop, offset reset, and consumer restart, leading to reprocessing of messages.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_10\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ResetOffsetsAsync(consumerName, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Consumer Configuration After v3 - C#\nDESCRIPTION: This code snippet demonstrates the updated KafkaFlow consumer configuration in v3, using `.AddDeserializer()` and `.AddDecompressor()` for message deserialization and decompression. It showcases the use of `JsonCoreDeserializer` and `GzipMessageDecompressor` and highlights the renaming of the methods and concrete implementations on the consumer side.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/migration/from-v2-to-v3.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\n.AddConsumer(\n    consumerBuilder => consumerBuilder\n        .Topic(\"test-topic\")\n        .WithGroupId(\"group1\")\n        .AddMiddlewares(\n            middlewares => middlewares\n                .AddDecompressor<GzipMessageDecompressor>()\n                .AddDeserializer<JsonCoreDeserializer>()\n        )\n)\n```\n\n----------------------------------------\n\nTITLE: Configure Gzip Compression in KafkaFlow - C#\nDESCRIPTION: This code snippet demonstrates how to configure a KafkaFlow producer with Gzip compression within the `AddKafka` service configuration. It shows how to define a Kafka cluster, add a producer, and enable compression using the `.WithCompression` method.  The configuration occurs within the `AddKafka` method during service registration.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/compression.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddProducer<ProductEventsProducer>(producer => producer\n            .WithCompression(CompressionType.Gzip)\n                ...\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Resuming a Consumer Group via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet shows how to resume all Kafka consumers in a consumer group using the `IConsumerAdmin` interface. It retrieves `IConsumerAdmin` from IoC and calls the `ResumeConsumerGroupAsync` method, providing the group ID and topic names. Requires access to the IoC provider.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_14\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.ResumeConsumerGroupAsync(groupId, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: Starting a Consumer via IConsumerAdmin (C#)\nDESCRIPTION: This C# code snippet shows how to start a Kafka consumer using the `IConsumerAdmin` interface. It retrieves an instance of `IConsumerAdmin` from the service provider and calls the `StartConsumerAsync` method with the consumer name as a parameter. Requires access to the IoC provider.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.StartConsumerAsync(consumerName);\n```\n\n----------------------------------------\n\nTITLE: Stopping Kafka Broker with Make\nDESCRIPTION: This command, using `make`, shuts down the Kafka cluster.  It likely relies on Docker to manage the Kafka broker. It expects a `Makefile` in the repository root directory.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/CONTRIBUTING.md#_snippet_4\n\nLANGUAGE: Makefile\nCODE:\n```\nmake shutdown_broker\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Message Type Resolver in KafkaFlow\nDESCRIPTION: This code demonstrates how to implement a custom message type resolver for KafkaFlow by implementing the `IMessageTypeResolver` interface. The resolver extracts the message type from the message headers during consumption and sets it during production. It depends on the `IMessageContext` for accessing headers and message information.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/serializer-middleware.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\npublic class SampleMessageTypeResolver : IMessageTypeResolver\n{\n    private const string MessageType = \"MessageType\";\n\n    public Type OnConsume(IMessageContext context)\n    {\n        var typeName = context.Headers.GetString(MessageType);\n\n        return Type.GetType(typeName);\n    }\n\n    public void OnProduce(IMessageContext context)\n    {\n        context.Headers.SetString(\n            MessageType,\n            $\"{context.Message.GetType().FullName}, {context.Message.GetType().Assembly.GetName().Name}\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Pause Consumer Group - C#\nDESCRIPTION: This C# code demonstrates how to pause a consumer group using the IConsumerAdmin interface.  It retrieves the IConsumerAdmin service from the provider and then calls PauseConsumerGroupAsync, passing the groupId and an array of topic names. This suspends all consumers within the specified group.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_13\n\nLANGUAGE: csharp\nCODE:\n```\nvar consumerAdmin = provider.GetService<IConsumerAdmin>();\nawait consumerAdmin.PauseConsumerGroupAsync(groupId, new []{ topicName });\n```\n\n----------------------------------------\n\nTITLE: KafkaFlow Manual Partition Assignment\nDESCRIPTION: This code demonstrates how to manually assign partitions to a KafkaFlow consumer using the `ManualAssignPartitions()` method. This allows the application to have fine-grained control over which partitions the consumer processes.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/consumers/add-consumers.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\nusing KafkaFlow.TypedHandler;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .ManualAssignPartitions(\"topic-name\", new[] { 1, 2, 3 })\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Message Handler\nDESCRIPTION: This C# code defines a message handler class `HelloMessageHandler` that implements the `IMessageHandler<HelloMessage>` interface. This handler receives and processes `HelloMessage` instances, writing the partition, offset, and message text to the console.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.TypedHandler;\nusing Producer;\n\nnamespace Consumer;\n\npublic class HelloMessageHandler : IMessageHandler<HelloMessage>\n{\n    public Task Handle(IMessageContext context, HelloMessage message)\n    {\n        Console.WriteLine(\n            \"Partition: {0} | Offset: {1} | Message: {2}\",\n            context.ConsumerContext.Partition,\n            context.ConsumerContext.Offset,\n            message.Text);\n\n        return Task.CompletedTask;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Project Reference\nDESCRIPTION: This command adds a project reference to the specified project. This enables the consumer project to use classes and types defined in the producer project, specifically the `HelloMessage` class.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add reference ../Producer\n```\n\n----------------------------------------\n\nTITLE: Configuring Consumer Throttling using Fluent Interface in C#\nDESCRIPTION: This C# code snippet demonstrates how to configure Consumer Throttling in KafkaFlow using the fluent interface. It sets up throttling based on the lag of another consumer ('singleConsumer'), defines an interval for checking metrics, and adds actions to apply delays based on threshold values.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/consumer-throttling-middleware.md#_snippet_0\n\nLANGUAGE: csharp\nCODE:\n```\n.AddConsumer(\n    consumer => consumer\n        .Topic(\"bulk-topic\")\n        .WithName(\"bulkConsumer\")\n        .AddMiddlewares(\n            middlewares => middlewares\n                .ThrottleConsumer(\n                    t => t\n                        .ByOtherConsumersLag(\"singleConsumer\")\n                        .WithInterval(TimeSpan.FromSeconds(5))\n                        .AddAction(a => a.AboveThreshold(10).ApplyDelay(100))\n                        .AddAction(a => a.AboveThreshold(100).ApplyDelay(1_000))\n                        .AddAction(a => a.AboveThreshold(1_000).ApplyDelay(10_000)))\n                .AddSerializer<JsonCoreSerializer>()\n        )\n)\n```\n\n----------------------------------------\n\nTITLE: Adding KafkaFlow Dashboard packages\nDESCRIPTION: This snippet shows how to add the necessary NuGet packages for KafkaFlow Dashboard using the `dotnet add package` command. These packages include KafkaFlow.Microsoft.DependencyInjection, KafkaFlow.Admin, KafkaFlow.Admin.WebApi, and KafkaFlow.Admin.Dashboard. Ensure .NET SDK is installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/dashboard.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package KafkaFlow.Admin\ndotnet add package KafkaFlow.Admin.WebApi\ndotnet add package KafkaFlow.Admin.Dashboard\n```\n\n----------------------------------------\n\nTITLE: Specifying Topic in ProduceAsync Method (C#)\nDESCRIPTION: This code illustrates how to specify the topic when calling the `ProduceAsync` method directly. The first argument of `ProduceAsync` defines the topic to which the message will be sent. This approach offers flexibility by allowing the topic to be specified at runtime.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/producers.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nawait _producers[\"product-events\"]\n    .ProduceAsync(\"products-topic\", product.Id.ToString(), product);\n```\n\n----------------------------------------\n\nTITLE: Installing KafkaFlow Packages\nDESCRIPTION: These commands install the required KafkaFlow NuGet packages to the project. These packages provide the necessary components for integrating with Kafka, handling dependency injection, logging, message serialization, and typed message handling.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/getting-started/create-your-first-application.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package KafkaFlow.LogHandler.Console\ndotnet add package KafkaFlow.TypedHandler\ndotnet add package KafkaFlow.Serializer\ndotnet add package KafkaFlow.Serializer.JsonCore\ndotnet add package Microsoft.Extensions.DependencyInjection\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Message Type Resolver\nDESCRIPTION: This C# code shows how to implement a custom `IMessageTypeResolver` in KafkaFlow. It includes logic for retrieving the message type from headers during consumption (`OnConsume`) and setting the message type in headers during production (`OnProduce`).  The `MessageType` constant defines the header key used to store the type information.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/serializer-middleware.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\npublic class SampleMessageTypeResolver : IMessageTypeResolver\n{\n    private const string MessageType = \"MessageType\";\n\n    public Type OnConsume(IMessageContext context)\n    {\n        var typeName = context.Headers.GetString(MessageType);\n\n        return Type.GetType(typeName);\n    }\n\n    public void OnProduce(IMessageContext context)\n    {\n        context.Headers.SetString(\n            MessageType,\n            $\"{context.Message.GetType().FullName}, {context.Message.GetType().Assembly.GetName().Name}\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling No Handler Found Event - C#\nDESCRIPTION: This snippet demonstrates how to handle the event when no handler is defined for an arriving message. It shows how to use the `WhenNoHandlerFound` method to execute a custom action when a message cannot be handled.  The example writes to the console.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/typed-handler-middleware.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            ...\n            .AddMiddlewares(middlewares => middlewares\n                ...\n                .AddTypedHandlers(handlers => handlers\n                    .AddHandler<ProductCreatedHandler>()\n                    .WhenNoHandlerFound(context => \n                        Console.WriteLine(\"Message not handled > Partition: {0} | Offset: {1}\",\n                            context.ConsumerContext.Partition,\n                            context.ConsumerContext.Offset)\n                        )\n                )\n            )\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Creating a Message Handler in KafkaFlow - C#\nDESCRIPTION: This code snippet demonstrates how to create a message handler in KafkaFlow by implementing the `IMessageHandler<MessageType>` interface.  The handler's dependencies are resolved via constructor injection. The handler instance's lifetime is configured during setup.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/middlewares/typed-handler-middleware.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\npublic class ProductCreatedHandler : IMessageHandler<ProductCreatedEvent>\n{\n    public Task Handle(IMessageContext context, ProductCreatedEvent message)\n    {\n        ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Install KafkaFlow Admin Packages - Bash\nDESCRIPTION: These commands install the necessary KafkaFlow packages for enabling the Admin Web API using the .NET CLI. It installs KafkaFlow.Microsoft.DependencyInjection, KafkaFlow.Admin, and KafkaFlow.Admin.WebApi.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package KafkaFlow.Admin\ndotnet add package KafkaFlow.Admin.WebApi\n```\n\n----------------------------------------\n\nTITLE: Register Swagger Generator - C#\nDESCRIPTION: This C# code registers the Swagger Generator in the services configuration. It configures the Swagger document with title and version information for the KafkaFlow Admin API.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_3\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.OpenApi.Models;\n\nbuilder.Services\n    .AddSwaggerGen(\n        c =>\n        {\n            c.SwaggerDoc(\n                \"kafka-flow\",\n                new OpenApiInfo\n                {\n                    Title = \"KafkaFlow Admin\",\n                    Version = \"kafka-flow\",\n                });\n        });\n```\n\n----------------------------------------\n\nTITLE: Install KafkaFlow Packages (ASP.NET Core)\nDESCRIPTION: Installs the NuGet packages needed to integrate KafkaFlow into an ASP.NET Core application. It includes KafkaFlow core and Microsoft Dependency Injection integration. These packages provide the functionality required for Kafka interaction and dependency management within the ASP.NET Core environment.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/configuration.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\n```\n\n----------------------------------------\n\nTITLE: Producing a Message without a Key in KafkaFlow (C#)\nDESCRIPTION: This code snippet illustrates how to produce a message without a key in KafkaFlow. By passing `null` as the key argument to the `ProduceAsync` method, the message will be sent without a key.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/producers.md#_snippet_4\n\nLANGUAGE: csharp\nCODE:\n```\nawait producer.ProduceAsync(null, product);\n```\n\n----------------------------------------\n\nTITLE: Adding KafkaFlow Packages (Bash)\nDESCRIPTION: This bash snippet adds the required NuGet packages for KafkaFlow when using a Hosted Service.  It includes KafkaFlow core, extensions for hosting, dependency injection, and the Microsoft Hosting package. These packages provide the necessary components for integrating KafkaFlow into a .NET application using the Hosted Service model.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/configuration.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Extensions.Hosting\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package Microsoft.Extensions.Hosting\n```\n\n----------------------------------------\n\nTITLE: Install Swashbuckle Package - Bash\nDESCRIPTION: This command installs the Swashbuckle.AspNetCore package using the .NET CLI. Swashbuckle is used to generate Swagger/OpenAPI documentation for the Admin API.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/web-api.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Swashbuckle.AspNetCore\n```\n\n----------------------------------------\n\nTITLE: Adding Swagger Generator in .NET Service Configuration (C#)\nDESCRIPTION: This C# code snippet demonstrates how to register the Swagger Generator in the services configuration of a .NET application. It configures Swagger to generate documentation for the KafkaFlow Admin API, providing a UI for exploring and testing operations. This relies on the Microsoft.OpenApi.Models package.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\nusing Microsoft.OpenApi.Models;\n\nbuilder.Services\n    .AddSwaggerGen(\n        c =>\n        {\n            c.SwaggerDoc(\n                \"kafka-flow\",\n                new OpenApiInfo\n                {\n                    Title = \"KafkaFlow Admin\",\n                    Version = \"kafka-flow\",\n                });\n        });\n```\n\n----------------------------------------\n\nTITLE: Installing KafkaFlow Dashboard Packages\nDESCRIPTION: This snippet shows how to install the necessary NuGet packages for the KafkaFlow Dashboard using the .NET CLI. The packages include KafkaFlow.Admin, KafkaFlow.Admin.WebApi, and KafkaFlow.Admin.Dashboard, along with KafkaFlow.Microsoft.DependencyInjection.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/admin/dashboard.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.Microsoft.DependencyInjection\ndotnet add package KafkaFlow.Admin\ndotnet add package KafkaFlow.Admin.WebApi\ndotnet add package KafkaFlow.Admin.Dashboard\n```\n\n----------------------------------------\n\nTITLE: Installing KafkaFlow Serializer Package\nDESCRIPTION: This bash command installs the KafkaFlow.Serializer NuGet package, which provides the necessary components for using the serializer middleware.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/middlewares/serializer-middleware.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow.Serializer\n```\n\n----------------------------------------\n\nTITLE: Creating .NET Console Projects (Bash)\nDESCRIPTION: These commands create new .NET console applications named Producer and Consumer, respectively, using the .NET CLI.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/create-your-first-application.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndotnet new console --name Producer\n```\n\nLANGUAGE: bash\nCODE:\n```\ndotnet new console --name Consumer\n```\n\n----------------------------------------\n\nTITLE: Running Jaeger with Docker\nDESCRIPTION: This command starts a Jaeger instance using Docker, exposing various ports for receiving traces and accessing the Jaeger UI. The command configures Jaeger to collect Zipkin traces and maps necessary ports. It utilizes the all-in-one Jaeger image.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.OpenTelemetry/README.md#_snippet_1\n\nLANGUAGE: docker\nCODE:\n```\ndocker run --rm --name jaeger \\\n  -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n  -p 6831:6831/udp \\\n  -p 6832:6832/udp \\\n  -p 5778:5778 \\\n  -p 16686:16686 \\\n  -p 4317:4317 \\\n  -p 4318:4318 \\\n  -p 14250:14250 \\\n  -p 14268:14268 \\\n  -p 14269:14269 \\\n  -p 9411:9411 \\\n  jaegertracing/all-in-one:1.51\n```\n\n----------------------------------------\n\nTITLE: Disabling Offset Storage - KafkaFlow C#\nDESCRIPTION: This snippet shows how to disable offset storage for a KafkaFlow consumer using the `WithoutStoringOffsets()` method. It requires KafkaFlow, KafkaFlow.Serializer, KafkaFlow.TypedHandler, and Microsoft.Extensions.DependencyInjection. Disabling offset storage prevents the consumer from storing processed message offsets.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/consumers/add-consumers.md#_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\nusing KafkaFlow.TypedHandler;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            .WithoutStoringOffsets()\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: KafkaFlow Automatic Partition Assignment\nDESCRIPTION: This code snippet showcases how to configure a KafkaFlow consumer with automatic partition assignment using the `Topic()` method. The consumer will automatically be assigned partitions from the specified topic by Kafka.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/consumers/add-consumers.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Serializer;\nusing Microsoft.Extensions.DependencyInjection;\nusing KafkaFlow.TypedHandler;\n\nservices.AddKafka(kafka => kafka\n    .AddCluster(cluster => cluster\n        .WithBrokers(new[] { \"localhost:9092\" })\n        .AddConsumer(consumer => consumer\n            .Topic(\"topic-name\")\n            .WithGroupId(\"sample-group\")\n            ...\n        )\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Adding Swashbuckle Package using Dotnet CLI\nDESCRIPTION: This snippet demonstrates how to add the Swashbuckle.AspNetCore package to a .NET project using the dotnet CLI.  Swashbuckle is used to generate Swagger/OpenAPI documentation for the KafkaFlow Admin API.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/guides/admin/web-api.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Swashbuckle.AspNetCore\n```\n\n----------------------------------------\n\nTITLE: Run the .NET KafkaFlow Sample\nDESCRIPTION: This snippet shows how to run the .NET KafkaFlow sample application. It assumes the .NET 6.0 SDK is installed and that the terminal is positioned in the sample's project folder. The `dotnet run` command compiles and executes the application.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.FlowControl/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Starting Local Development Server with Yarn\nDESCRIPTION: This command starts a local development server for the website. It uses Yarn to execute the start script defined in the project's package.json file, enabling live reloading of changes without restarting the server.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ yarn start\n```\n\n----------------------------------------\n\nTITLE: Creating a Feature Branch\nDESCRIPTION: This command creates a new branch named `my-new-feature` based on the current branch. It's used to isolate changes and work on new features without affecting the main codebase.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: git\nCODE:\n```\ngit checkout -b my-new-feature\n```\n\n----------------------------------------\n\nTITLE: Build Angular Dashboard UI\nDESCRIPTION: This command builds the Angular-based KafkaFlow Admin Dashboard UI. It requires navigating to the `kafkaflow\\src\\KafkaFlow.Admin.Dashboard\\ClientApp` directory and having Angular CLI (`ng`) installed.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/samples/KafkaFlow.Sample.Dashboard/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nng build\n```\n\n----------------------------------------\n\nTITLE: Deploying with GitHub User using Yarn\nDESCRIPTION: This command deploys the website, specifying the GitHub username.  This is typically used when deploying to GitHub Pages. The `GIT_USER` environment variable specifies the GitHub username for deployment.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ GIT_USER=<Your GitHub username> yarn deploy\n```\n\n----------------------------------------\n\nTITLE: Pushing Branch to Remote\nDESCRIPTION: This command pushes the local branch `my-new-feature` to the remote repository `origin`. This allows others to see and review the changes.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/CONTRIBUTING.md#_snippet_2\n\nLANGUAGE: git\nCODE:\n```\ngit push origin my-new-feature\n```\n\n----------------------------------------\n\nTITLE: Committing Changes\nDESCRIPTION: This command commits the changes made in the working directory to the local repository with a descriptive message. The message should follow the conventional commits format.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: git\nCODE:\n```\ngit commit -am 'feat: Add some feature'\n```\n\n----------------------------------------\n\nTITLE: Importing KafkaFlow namespaces in C#\nDESCRIPTION: This code snippet shows the necessary KafkaFlow namespaces that need to be imported in C# to use the library's features such as configuring consumers, producers, and serializers.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/docs/getting-started/installation.md#_snippet_1\n\nLANGUAGE: csharp\nCODE:\n```\nusing KafkaFlow;\nusing KafkaFlow.Producers;\nusing KafkaFlow.Serializer;\n```\n\n----------------------------------------\n\nTITLE: Install KafkaFlow Packages (Unity DI)\nDESCRIPTION: Installs the NuGet packages required for using KafkaFlow with the Unity DI container.  This includes KafkaFlow core and the Unity integration package. It prepares the project for dependency injection using Unity.\nSOURCE: https://github.com/farfetch/kafkaflow/blob/master/website/versioned_docs/version-2.x/guides/configuration.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package KafkaFlow\ndotnet add package KafkaFlow.Unity\n```"
  }
]