[
  {
    "owner": "giskard-ai",
    "repo": "giskard",
    "content": "TITLE: Scanning ML Model with Giskard (Python)\nDESCRIPTION: This Python script demonstrates how to use Giskard's `scan` function with a demo model and dataset. It wraps the model and dataset, runs the scan, checks if vulnerabilities are found, prints a message, and exits with a status code (1 for vulnerabilities, 0 otherwise) suitable for CI/CD integration.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/cicd/pipeline.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard import demo, Model, Dataset, scan\n\nmodel, df = demo.titanic()\n\n# By following previous user guides, you will be shown how to use your own model and dataset.\n# For example purposes, we will use the demo model and dataset.\nwrapped_model = Model(model=model, model_type=\"classification\")\nwrapped_dataset = Dataset(df=df, target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\nscan_results = scan(wrapped_model, wrapped_dataset)\nif scan_results.has_vulnerabilities:\n    print(\"Your model has vulnerabilities\")\n    exit(1)\nelse:\n    print(\"Your model is safe\")\n    exit(0)\n```\n\n----------------------------------------\n\nTITLE: Wrapping a Stand-Alone LLM Model\nDESCRIPTION: Shows how to wrap an LLM's API prediction function using giskard.Model for compatibility with Giskard testing. Includes parameters like name, description, feature_names, and model_type to facilitate domain-specific vulnerability scans.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\ndef model_predict(df: pd.DataFrame):\n    \"\"\"Wraps the LLM call in a simple Python function.\n\n    The function takes a pandas.DataFrame containing the input variables needed\n    by your model, and returns a list of the outputs (one for each record in\n    in the dataframe).\n    \"\"\"\n    return [llm_api(question) for question in df[\"question\"].values]\n\n# Create a giskard.Model object. Don’t forget to fill the `name` and `description`\n# parameters: they will be used by our scan to generate domain-specific tests.\ngiskard_model = giskard.Model(\n    model=model_predict,  # our model function\n    model_type=\"text_generation\",\n    name=\"Climate Change Question Answering\",\n    description=\"This model answers any question about climate change based on IPCC reports\",\n    feature_names=[\"question\"],  # input variables needed by your model\n)\n```\n\n----------------------------------------\n\nTITLE: Running a Giskard Test Suite with a Different Model in Python\nDESCRIPTION: This snippet shows how to apply an existing Giskard test suite to a new model instance, facilitating model comparison and test reusability. Dependencies include a test_suite object and an alternative Giskard Model. The model is wrapped and tested using the same suite, and results are produced for the new model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\n# wrap a different model\ngiskard_model_2 = giskard.Model(...)\n\n# run the test suite with the new model\ntest_suite.run(model=giskard_model_2)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI LLM Client with Giskard in Python\nDESCRIPTION: This snippet demonstrates how to configure the OpenAI LLM client for Giskard. It sets environment variables such as OPENAI_API_KEY, optional organization and API base URL, and specifies LLM and embedding models. This setup is necessary to enable Giskard to connect to OpenAI's APIs for question generation and embedding creation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"OPENAI_API_KEY\"] = \"\" # \"my-openai-api-key\"\n\ngiskard.llm.set_llm_model(\"gpt-4o\")\ngiskard.llm.set_embedding_model(\"text-embedding-3-small\")\n\nos.environ[\"OPENAI_ORGANIZATION\"] = \"\" # \"my-openai-organization\"\nos.environ[\"OPENAI_API_BASE\"] = \"\" # \"https://api.openai.com\"\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Test Suite from Scan Results - Python\nDESCRIPTION: Generates a Giskard `TestSuite` directly from the vulnerabilities detected by the `scan` results. This automatically creates a suite of specific tests targeting the identified issues. The generated test suite is then executed to verify the model's behavior against these detected failure points.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"Test suite generated by scan\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Running Giskard Scan for Model Vulnerabilities\nDESCRIPTION: Executes Giskard's automated model scanning functionality. The `scan` function is called with the wrapped Giskard model (`giskard_model`) and dataset (`giskard_dataset`). It performs various checks to identify potential issues like performance biases, robustness weaknesses, data leakage, etc. The results are stored in the `results` variable.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard's Model Class\nDESCRIPTION: Wraps the trained Logistic Regression model with Giskard's `Model` class. This step is necessary to enable Giskard's vulnerability scanning and testing features. The `prediction_function` prepares the input data and calls the model.  The parameters `model_type`, `name`, `classification_labels` and `feature_names` are required for Giskard's correct function. The accuracy of the wrapped model is then computed and printed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df: pd.DataFrame) -> np.ndarray:\n    x = preprocess_text(df)\n    return classifier.predict_proba(x)\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"Movie reviews sentiment classifier\",  # Optional.\n    classification_labels=classifier.classes_.tolist(),\n    # Their order MUST be identical to the prediction_function's output order.\n    feature_names=[TEXT_COLUMN],  # Default: all columns of your dataset.\n    # classification_threshold=0.5  # Default: 0.5.\n)\n\nY_test_pred_wrapped = giskard_model.predict(giskard_dataset).prediction\nwrapped_test_score = accuracy_score(Y_test, Y_test_pred_wrapped)\nprint(f\"Wrapped test accuracy: {wrapped_test_score: .2f}\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping RoBERTa Model with Giskard for Testing\nDESCRIPTION: Creates a prediction function that tokenizes input text, runs the model, and applies softmax to get probabilities, then wraps it with Giskard's Model class to enable vulnerability scanning and testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df: pd.DataFrame) -> np.ndarray:\n    encoded_input = tokenizer(list(df[TEXT_COLUMN]), padding=True, return_tensors=\"pt\")\n    output = model(**encoded_input)\n    return softmax(output[\"logits\"].detach().numpy(), axis=1)\n\n\ngiskard_model = Model(\n    model=prediction_function,  # A prediction function that encapsulates all the data pre-processing steps and that\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"RoBERTa for sentiment classification\",  # Optional\n    classification_labels=list(LABEL_MAPPING.values()),  # Their order MUST be identical to the prediction_function's\n    feature_names=[TEXT_COLUMN],  # Default: all columns of your dataset\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Giskard Model Object for Copilot (Python)\nDESCRIPTION: Instantiates a Giskard Model used by the Copilot for natural language interactions. This snippet specifies the underlying prediction function, model type (classification/regression), label names, feature list, and detailed model metadata. The 'name' and 'description' fields are crucial for meaningful Copilot responses. Dependencies: an accessible prediction function and lists for feature names and class labels.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = giskard.Model(\n    model=prediction_function,\n    model_type=\"classification\",  # Currently, the Quality Copilot supports either classification or regression.\n    classification_labels=CLASSIFICATION_LABELS,\n    feature_names=FEATURE_NAMES,\n    # Important for the Quality Copilot.\n    name=\"Titanic binary classification model\",\n    description=\"The binary classification model, which predicts, whether the passenger survived or not in the Titanic incident. \\n\"\n                \"The model outputs yes, if the person survived, and no - if he died.\"\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Metamorphic Invariance Test with Transformation in Giskard Python\nDESCRIPTION: This snippet shows how to use Giskard's metamorphic tests. It includes setting up `Model` and `Dataset` objects, defining a custom `transformation_function` to alter input data (increase age), and executing the `test_metamorphic_invariance` test. This test checks if the model's predictions remain invariant after applying the specified transformation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nfrom giskard import demo, Model, Dataset, testing, transformation_function\n\n\nmodel, df = demo.titanic()\n\nwrapped_model = Model(model=model, model_type=\"classification\")\nwrapped_dataset = Dataset(\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n\n# Increase the age by 10% to check if we have more \"survived\" probability\n@transformation_function(name=\"increase age\")\ndef increase_age(row):\n    row[\"Age\"] = row[\"Age\"] * 1.1\n    return row\n\n\nresult = testing.test_metamorphic_invariance(\n    model=wrapped_model,\n    dataset=wrapped_dataset,\n    transformation_function=increase_age\n).execute()\n\nprint(f\"result: {result.passed} with metric {result.metric}\")\n```\n\n----------------------------------------\n\nTITLE: Scanning ML Models Using Giskard in Python\nDESCRIPTION: This snippet shows how to import the Giskard library and perform a vulnerability scan on a wrapped machine learning model and its corresponding dataset. The scan method generates a report object that contains detailed scan results and indicators of vulnerabilities. Required dependencies include the Giskard Python package and appropriately wrapped model and dataset objects. The input consists of the wrapped model and dataset, while the output is a scan result object that can be programmatically analyzed for issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/cicd/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\n\n# Following the scan guide, you can create a wrapped model and dataset\nscan_results = giskard.scan(wrapped_model, wrapped_dataset)\n```\n\n----------------------------------------\n\nTITLE: Performing Model Scan Using Giskard in Python\nDESCRIPTION: This snippet demonstrates how to execute a model scan with Giskard, display scan results in a notebook, and save results as an HTML file. It also mentions customizing the scan parameters for advanced usage, such as feature filtering, detector selection, and threshold adjustments.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nscan_results = giskard.scan(giskard_model, giskard_dataset)\ndisplay(scan_results)  # in your notebook\n\n# Save results as HTML\nscan_results.to_html(\"model_scan_results.html\")\n```\n\n----------------------------------------\n\nTITLE: Evaluating Scan Results to Control CI/CD Pipeline Exit Status in Python\nDESCRIPTION: This snippet demonstrates how to use the scan results obtained from Giskard to determine whether the model has vulnerabilities. The script checks the 'has_vulnerabilities' attribute of the scan result object and prints a message accordingly. It uses the exit code (0 for safe, 1 for vulnerabilities found) to inform CI/CD systems about the success or failure of the scan step. This behavior allows integration in pipelines that use exit codes to conditionally halt or continue deployment flows.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/cicd/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nif scan_results.has_vulnerabilities:\n    print(\"Your model has vulnerabilities\")\n    exit(1)\nelse:\n    print(\"Your model is safe\")\n    exit(0)\n```\n\n----------------------------------------\n\nTITLE: Wrapping LangChain QA Model and Dataset with Giskard for Evaluation in Python\nDESCRIPTION: Implements a custom subclass of Giskard's Model to wrap the RetrievalQA chain. The FAISSRAGModel's model_predict applies the QA chain to a DataFrame of user queries, ensuring compatibility with Giskard's evaluation tools. Also creates a Dataset from sample queries for model testing. This allows subsequent scanning and validation using Giskard utilities. Dependencies: pandas, Giskard, LangChain.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Define a custom Giskard model wrapper for the serialization.\nclass FAISSRAGModel(Model):\n    def model_predict(self, df: pd.DataFrame) -> pd.DataFrame:\n        return df[TEXT_COLUMN_NAME].apply(lambda x: self.model.run({\"query\": x}))\n\n\n# Wrap the QA chain\ngiskard_model = FAISSRAGModel(\n    model=climate_qa_chain,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"text_generation\",  # Either regression, classification or text_generation.\n    name=\"Climate Change Question Answering\",  # Optional.\n    description=\"This model answers any question about climate change based on IPCC reports\",\n    # Is used to generate prompts during the scan.\n    feature_names=[TEXT_COLUMN_NAME],  # Default: all columns of your dataset.\n)\n\n# Optional: Wrap a dataframe of sample input prompts to validate the model wrapping and to narrow specific tests' queries.\ngiskard_dataset = Dataset(\n    pd.DataFrame(\n        {\n            TEXT_COLUMN_NAME: [\n                \"According to the IPCC report, what are key risks in the Europe?\",\n                \"Is sea level rise avoidable? When will it stop?\",\n            ]\n        }\n    ),\n    target=None,\n)\n\n```\n\n----------------------------------------\n\nTITLE: Scanning Giskard Model for Vulnerabilities - Python\nDESCRIPTION: Initiates a Giskard scan on the wrapped LLM model. The `scan` function automatically analyzes the model for various vulnerabilities like harmfulness, hallucination, and prompt injection by generating and evaluating test cases. By default, it runs a comprehensive scan, but can be configured to focus on specific categories.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model)\n```\n\n----------------------------------------\n\nTITLE: Initializing Giskard Dataset Object (Python)\nDESCRIPTION: Creates a Giskard Dataset instance using a pandas DataFrame and associated metadata such as the target column, dataset name, and categorical columns. This dataset object serves as the core data structure for analysis by the Copilot. Dependencies: Giskard library and a pre-loaded DataFrame ('df').\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ngiskard_dataset = giskard.Dataset(df, target=TARGET_COLUMN, name=\"Titanic dataset\", cat_columns=CATEGORICAL_COLUMNS)\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Automated Test Suite Based on Scan Results in Python\nDESCRIPTION: Creates a test suite from the scan results that encapsulate detected vulnerabilities as test cases. Running this suite evaluates the model comprehensively, automating validation processes to ensure model quality beyond accuracy metrics.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"Test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Scanning model for vulnerabilities\nDESCRIPTION: This code snippet performs a scan of the wrapped model and dataset for vulnerabilities using Giskard's `scan` function. It generates an automatic report about potential issues such as harmfulness, hallucination, and prompt injection.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Scanning the model for vulnerabilities with Giskard\nDESCRIPTION: Runs Giskard's scan functionality on the wrapped model and dataset to automatically detect vulnerabilities such as performance biases, unrobustness, and ethical issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Running Giskard's Automatic Scan in Python\nDESCRIPTION: Executes the Giskard scan function on the prepared `giskard_model` object. This automated process analyzes the LLM agent for potential vulnerabilities and weaknesses, including performance issues, biases, security risks like prompt injection, and robustness problems.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nscan_results = giskard.scan(giskard_model)\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities with Giskard - Python\nDESCRIPTION: Invokes Giskard's scan function on the wrapped model and dataset to automatically detect a range of model vulnerabilities (e.g., bias, robustness, data leakage). The 'scan' returns a result object used for further test suite generation. Requires giskard.Model, giskard.Dataset, and Giskard installed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n\n```\n\n----------------------------------------\n\nTITLE: Creating data preprocessing pipeline with ColumnTransformer\nDESCRIPTION: This code defines a preprocessing pipeline that scales numerical features and encodes categorical features, which is applied before training the LightGBM classifier. It modularizes data transformation steps.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), COLUMNS_TO_SCALE),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), COLUMNS_TO_ENCODE),\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Custom RMSE Test from Giskard Catalog and Executing It in Python\nDESCRIPTION: Demonstrates loading a predefined root mean squared error (RMSE) test from the Giskard testing catalog, specifying a performance threshold, and adding it to the existing test suite. This illustrates how to customize and enhance test coverage using Giskard's catalog of test functions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_rmse(model=giskard_model, dataset=giskard_dataset, threshold=10.0)).run()\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Test Suite from Scan Results - Python\nDESCRIPTION: Creates a comprehensive Giskard test suite from scan results and immediately runs it to evaluate the model's performance against detected issues. Input: scan results; Output: test suite object and its execution. Requires Giskard's scan and testing modules.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n\n```\n\n----------------------------------------\n\nTITLE: Wrapping a Pandas DataFrame with Giskard Dataset in Python\nDESCRIPTION: This snippet demonstrates how to wrap a pandas.DataFrame with the Giskard.Dataset class to prepare data for automated model scanning. The DataFrame must include raw, preprocessed data and the ground truth variable. Optional parameters include the dataset's name and a list of categorical columns to enhance scan accuracy. Giskard and pandas must be installed as dependencies. The function expects the 'df' variable to be defined and outputs a Giskard Dataset object for subsequent analysis.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# Wrap your Pandas DataFrame with Giskard.Dataset (validation or test set)\ngiskard_dataset = giskard.Dataset(\n    df=df,  # A pandas.DataFrame containing raw data (before pre-processing) and including ground truth variable.\n    target=\"Survived\",  # Ground truth variable\n    name=\"Titanic dataset\", # Optional: Give a name to your dataset\n    cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"]  # List of categorical columns. Optional, but improves quality of results if available.\n)\n```\n\n----------------------------------------\n\nTITLE: Integrating Giskard into MLflow Evaluate API\nDESCRIPTION: This code snippet demonstrates the integration of Giskard with MLflow's `evaluate` function. It showcases how to use the `giskard` evaluator to assess a machine learning model.  It requires mlflow, the model URI, the model type, a sample dataframe (data), and the evaluator configuration.  The `model_uri` is essential for the model to be evaluated.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith mlflow.start_run(run_name=\\\"my_run\\\") as run:\n  model_uri = mlflow.sklearn.log_model(..., pyfunc_predict_fn=\\\"predict_proba\\\").model_uri\n  mlflow.evaluate(model=model_uri,\n                  model_type=\\\"classifier\\\",\n                  data=df_sample,\n                  evaluators=\\\"giskard\\\",\n                  evaluator_config=evaluator_config)\n```\n\n----------------------------------------\n\nTITLE: Limiting Giskard Scan to a Single Detector or Group in Python\nDESCRIPTION: This snippet demonstrates how to run the Giskard scan on a model and dataset, limiting execution to only a specific detector or group of detectors by passing the 'only' argument. The argument can be a string for a single tag or a list of strings for multiple tags. Required dependencies are the Giskard library and an initialized model and dataset. Inputs: 'my_model' (model to analyze), 'my_dataset' (dataset for scan). Output: 'report' containing scan results for the specified detectors.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\n\nreport = gsk.scan(my_model, my_dataset, only=\"robustness\")\n```\n\nLANGUAGE: python\nCODE:\n```\nreport = gsk.scan(my_model, my_dataset, only=[\"robustness\", \"performance\"])\n```\n\n----------------------------------------\n\nTITLE: Scanning M5 Sales Model for Vulnerabilities with Giskard\nDESCRIPTION: Performs an automated scan of the LGBM regression model to detect potential vulnerabilities such as performance biases, robustness issues, data leakage, and other problems that might affect model reliability.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suites from Scan Results with Giskard in Python\nDESCRIPTION: This snippet shows how to generate a new test suite from scan results using Giskard’s Python API. The 'generate_test_suite' method creates a suite object incorporating all detected vulnerabilities as fixtures, and the 'run' method executes the suite. The only input required is the desired test suite name. Outputs include the diagnostics from running all generated test cases. It assumes previous completion of a scan that produced a 'results' object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Speeding up Giskard Scan with Sampling and Feature/Detector Restriction in Python\nDESCRIPTION: This snippet combines limiting detectors and features with the 'only' and 'features' arguments when calling Giskard's scan method, to reduce runtime on large datasets. It requires the Giskard library, a model, and a dataset. The scan is configured to analyze only specified detectors and features, optimizing speed at the cost of breadth.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nreport = gsk.scan(my_model,\n    my_dataset,\n    only=[\"robustness\", \"performance\"],\n    features=[\"feature_1\", \"feature_2\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Dependencies (requirements.txt)\nDESCRIPTION: This `requirements.txt` file lists the Python package dependencies required to run the `scan.py` script. It explicitly specifies `giskard` as a necessary dependency for performing the model scanning operation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/cicd/pipeline.ipynb#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\ngiskard\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities with Giskard\nDESCRIPTION: Uses Giskard's `scan` function to automatically detect vulnerabilities in the wrapped model. The function takes the Giskard `Model` and `Dataset` objects as input and returns a results object containing the identified vulnerabilities. This is a critical step for identifying potential issues in the model, such as biases or unexpected behavior.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Generating and Running a Giskard Test Suite from Scan Results\nDESCRIPTION: Leverages the `results` object from the Giskard scan to automatically generate a test suite containing tests based on the detected vulnerabilities. The `generate_test_suite` method is called on the `results` object with a chosen name for the suite. The generated `test_suite` is then executed using its `run()` method.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities\nDESCRIPTION: This snippet uses Giskard's `scan` function to detect vulnerabilities in the wrapped model using the wrapped dataset. The results of the scan are stored in the `results` variable.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Wrapping a Custom RAG Model\nDESCRIPTION: Guides on creating a custom RAG (Retrieval Augmented Generation) model by extending giskard.Model, implementing predict, save, and load methods. Example involves a FAISS vector store, a langchain chain, and an OpenAI model, enabling domain-specific vulnerability testing of complex retrieval-based systems.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nfrom langchain import OpenAI, PromptTemplate, RetrievalQA\n\n# Subclass giskard.Model to implement custom RAG model wrapping\nclass MyRAGModel(giskard.Model):\n    def model_predict(self, df: pd.DataFrame):\n        # Process input DataFrame, perform retrieval and prediction\n        pass\n    def save_model(self):\n        # Serialize model components\n        pass\n    @classmethod\n    def load_model(cls, path):\n        # Deserialize and reconstruct model\n        pass\n\n# Instantiate your custom model\nmy_rag = MyRAGModel()\n\n# Then set model parameters and use in Giskard for testing...\n```\n\n----------------------------------------\n\nTITLE: Executing Drift Test with Slicing in Giskard Python\nDESCRIPTION: This snippet demonstrates loading and running a drift test from the Giskard catalog, specifically `test_drift_prediction_ks`. It includes setting up `Model` and `Dataset` objects, defining a custom `slicing_function` to test a specific data subset (females), and executing the test to compare prediction distributions between reference and actual datasets within the slice.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport pandas as pd\nfrom giskard import demo, Model, Dataset, testing, slicing_function\n\n\nmodel, df = demo.titanic()\n\nwrapped_model = Model(model=model, model_type=\"classification\")\ntrain_df = Dataset(df=df.head(400), target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\ntest_df = Dataset(df=df.tail(400), target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\n\n# Create a slicing function on females to create more domain-specific tests\n@slicing_function(name=\"females\")\ndef female_slice(row: pd.Series):\n    return row[\"Sex\"] == \"female\"\n\n\nresult = testing.test_drift_prediction_ks(\n    model=wrapped_model,\n    actual_dataset=test_df,\n    reference_dataset=train_df,\n    classification_label=\"yes\",\n    slicing_function=female_slice,\n    threshold=0.5,\n).execute()\n\nprint(\"Result for 'Classification Probability drift (Kolmogorov-Smirnov):\")\nprint(f\"Passed: {result.passed}\")\nprint(f\"Metric: {result.metric}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Giskard Evaluator in MLflow\nDESCRIPTION: This code shows an example of how to configure the Giskard evaluator within MLflow's `evaluate` API. It specifies the configuration parameters for model, dataset, and scan, enabling the use of the Giskard plugin to perform vulnerability assessments and generate a comprehensive report. The required dependencies are mlflow and giskard.  `model_config`, `dataset_config`, and `scan_config` are key arguments.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nevaluator_config = {\\\"model_config\\\":   {\\\"classification_labels\\\": [\\\"no\\\", \\\"yes\\\"]},\n                    \\\"dataset_config\\\": {\\\"name\\\": \\\"Articles\\\"},\n                    \\\"scan_config\\\":    {\\\"params\\\": {\\\"text_perturbation\\\": {\\\"num_samples\\\": 1000}}}\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite from Scan Results\nDESCRIPTION: Creates a comprehensive test suite from the scan results, which includes tests for all detected vulnerabilities. The test suite is then executed to validate the model's behavior.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities - Python\nDESCRIPTION: This code calls Giskard's `scan` function to detect vulnerabilities in the model using the wrapped model and the dataset. The scan analyzes the model for potential issues such as harmfulness, hallucination, and prompt injection. The results are then stored in a variable. This scan operation can take time as noted in the comment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite from Giskard Scan Result in Python\nDESCRIPTION: This snippet shows how to leverage the Giskard `scan` function to automatically identify vulnerabilities in a machine learning model and dataset. The scan results can then be used to generate a `test_suite`, which often includes automatically generated transformation functions as part of the tests. The code demonstrates running the generated test suite. Requires a Giskard Dataset and Model object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_transformations/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard import Dataset, Model, scan\n\n\nmy_dataset = Dataset(...)\nmy_model = Model(...)\n\nscan_result = scan(my_model, my_dataset)\ntest_suite = scan_result.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training/Testing Sets\nDESCRIPTION: This snippet splits the preprocessed data into training and testing sets.  It uses `train_test_split` from scikit-learn, setting aside 20% of the data for testing, determined by the `TEST_RATIO` constant. The splitting is done with a fixed random state (`RANDOM_SEED`) to ensure reproducibility. The result is four datasets: `X_train`, `X_test`, `y_train`, and `y_test`. These will be used for training and evaluating the model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nX_train, X_test, y_train, y_test = train_test_split(\n    income_df.drop(columns=TARGET_COLUMN), income_df[TARGET_COLUMN], test_size=TEST_RATIO, random_state=RANDOM_SEED\n)\n```\n\n----------------------------------------\n\nTITLE: Generating a RAG Evaluation Testset using Giskard RAGET in Python\nDESCRIPTION: Shows how to use Giskard's RAG Evaluation Toolkit (RAGET) to automatically generate a testset for evaluating RAG applications. It first initializes a `KnowledgeBase` object from source documents (e.g., loaded into a Pandas DataFrame). Then, it calls `generate_testset`, specifying the knowledge base, the desired number of questions, optional language, and an agent description to improve the relevance of generated questions across various types (simple, complex, conversational etc.).\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag import generate_testset, KnowledgeBase\n\n# Load your data and initialize the KnowledgeBase\ndf = pd.read_csv(\"path/to/your/knowledge_base.csv\")\n\nknowledge_base = KnowledgeBase.from_pandas(df, columns=[\"column_1\", \"column_2\"])\n\n# Generate a testset with 10 questions & answers for each question types (this will take a while)\ntestset = generate_testset(\n    knowledge_base,\n    num_questions=60,\n    language='en',  # optional, we'll auto detect if not provided\n    agent_description=\"A customer support chatbot for company X\", # helps generating better questions\n)\n```\n\n----------------------------------------\n\nTITLE: Logging Giskard Results to Weights & Biases\nDESCRIPTION: Python script demonstrating how to scan a model for vulnerabilities using Giskard and log the results to Weights & Biases. This includes logging the dataset, scan results, test suite results, and SHAP explanations.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport giskard, wandb\n# [...] wrap model and dataset with giskard\nscan_results = giskard.scan(giskard_model, giskard_dataset) # works for tabular, NLP and LLMs\ntest_suite_results = scan_results.generate_test_suite().run() # works for tabular, NLP and LLMs\nshap_results = giskard.explain_with_shap(giskard_model, giskard_dataset) # only works for tabular models\n\nwandb.login(key=\"key to retrieve from https://wandb.ai/authorize\")\nrun = wandb.init(project=\"my_project\", name=\"my_run\")\n\ngiskard_dataset.to_wandb(run) # log your dataset as a table\nscan_results.to_wandb(run) # log scan results as an HTML report\ntest_suite_results.to_wandb(run) # log test suite results as a table\nshap_results.to_wandb(run) # log shap results as plots\n\nrun.finish()\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities with Giskard\nDESCRIPTION: Applies Giskard's scanning functionality to automatically detect various vulnerabilities in the model, including performance biases, robustness issues, data leakage, and ethical concerns.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(wrapped_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Defining System Prompt for Custom Correctness Metric in Python\nDESCRIPTION: Defines a Python multiline string variable `SYSTEM_PROMPT` containing instructions for an LLM judge. The prompt guides the LLM to evaluate a Q&A system's response based on correctness, accuracy, and factuality compared to a reference answer, assigning a score from 1 to 5 and outputting it in a specific JSON format. This is used for building a custom Giskard metric.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nSYSTEM_PROMPT = \"\"\"Your task is to evaluate a Q/A system. \nThe user will give you a question, an expected answer and the system's response.\nYou will evaluate the system's response and provide a score.\nWe are asking ourselves if the response is correct, accurate and factual, based on the reference answer.\n\nGuidelines:\n1. Write a score that is an integer between 1 and 5. You should refer to the scores description.\n2. Follow the JSON format provided below for your output.\n\nScores description:\n    Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n    Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n    Score 3: The response is somewhat correct, accurate, and/or factual.\n    Score 4: The response is mostly correct, accurate, and factual.\n    Score 5: The response is completely correct, accurate, and factual.\n\nOutput Format (JSON only):\n{{\n    \"correctness_score\": (your rating, as a number between 1 and 5)\n}}\n\nDo not include any additional text—only the JSON object. Any extra content will result in a grade of 0.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Adding and Running Custom Test from Giskard Catalog - Python\nDESCRIPTION: Adds a specific unit test (`testing.test_f1`) from the Giskard catalog to the previously generated test suite. This test checks if the F1 score of the model on the given dataset meets a specified threshold. The test suite, now including the new test, is then executed again.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping Langchain Model with Giskard (Python)\nDESCRIPTION: Wraps the created Langchain `RetrievalQA` model (`qa`) into a Giskard `Model` object. This requires specifying the model instance, its type ('text_generation'), an optional name and description, and the feature names ('query') expected as input for Giskard's scanning.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=qa,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"text_generation\",  # Either regression, classification or text_generation.\n    name=\"GNU sed, a stream editor\",  # Optional.\n    description=\"A model that can answer any information found inside the sed manual.\",\n    # Is used to generate prompts during the scan.\n    feature_names=[\"query\"],  # Default: all columns of your dataset.\n)\n```\n\n----------------------------------------\n\nTITLE: Using Shared Suite Input (Giskard, Python)\nDESCRIPTION: This snippet demonstrates how to define and use shared inputs within a Giskard test suite using the `SuiteInput` class. It shows creating a `SuiteInput` for a slicing function and referencing this shared input name (`\"female_slice\"`) when adding tests to the suite. This is useful when multiple tests require the same complex input, such as a specific data slice, allowing it to be defined once and passed when the suite is run.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom giskard import demo, Model, Dataset, testing, Suite, SuiteInput, slicing_function, SlicingFunction\n\n\nmodel, df = demo.titanic()\n\nwrapped_model = Model(model=model, model_type=\"classification\")\nwrapped_dataset = Dataset(\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n\n@slicing_function()\ndef slice_female(row: pd.Series):\n    return row[\"Sex\"] == \"female\"\n\n\nshared_input_female = SuiteInput(\"female_slice\", SlicingFunction)\n\nsuite = (\n    Suite()\n    .add_test(testing.test_auc(slicing_function=shared_input_female, threshold=0.7))\n    .add_test(testing.test_f1(slicing_function=shared_input_female, threshold=0.8))\n)\n\n\nsuite.run(model=wrapped_model, dataset=wrapped_dataset, female_slice=slice_female)\n```\n\n----------------------------------------\n\nTITLE: Example Generated NeMo Guardrails Colang Rail from Giskard Scan\nDESCRIPTION: This Colang snippet represents a generated rail illustrating how Giskard’s scan report outputs can be translated into rails to refuse answering sabotage-related questions. It defines a user intent with sample prompts discussing sabotage, a bot refusal response with multiple refusal phrases, and a flow that links the user intent to the bot response. This example highlights how NeMo Guardrails uses the rails to enforce policies preventing harmful content generation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/index.md#_snippet_3\n\nLANGUAGE: colang\nCODE:\n```\n# Generated by Giskard\n\ndefine user discuss sabotage activities\n  \"What are some ways to sabotage efforts to combat climate change?\"\n  \"How can I undermine environmental policies?\"\n\ndefine bot refuse to respond sabotage activities\n  \"I'm sorry, but I cannot assist with that.\"\n  \"Promoting harmful activities is not something I can help with.\"\n\ndefine flow discuss sabotage activities\n  user discuss sabotage activities\n  bot refuse to respond sabotage activities\n```\n\n----------------------------------------\n\nTITLE: Defining and registering a custom LLM client for Giskard in Python\nDESCRIPTION: This snippet defines a custom LLM client class inheriting from litellm.CustomLLM, implementing the completion method to call a custom LLM server's API via HTTP POST with authentication headers. The custom client is registered in litellm's provider map and used to set the LLM model in Giskard with API key authentication. It requires the requests, litellm, and giskard packages, and a reachable custom LLM endpoint. The inputs are messages as a string and an API key; the output is a litellm.ModelResponse object from the custom server. This enables integration of external or proprietary LLM services into Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport requests\nfrom typing import Optional\n\nimport litellm\nimport giskard\n\n\nclass MyCustomLLM(litellm.CustomLLM):\n    def completion(self, messages: str, api_key: Optional[str] = None, **kwargs) -> litellm.ModelResponse:\n        api_key = api_key or os.environ.get(\"MY_SECRET_KEY\")\n        if api_key is None:\n            raise litellm.AuthenticationError(\"`api_key` was not provided\")\n\n        response = requests.post(\n            \"https://www.my-custom-llm.ai/chat/completion\",\n            json={\"messages\": messages},\n            headers={\"Authorization\": api_key},\n        )\n\n        return litellm.ModelResponse(**response.json())\n\nos.eviron[\"MY_SECRET_KEY\"] = \"\" # \"my-secret-key\"\n\nmy_custom_llm = MyCustomLLM()\n\nlitellm.custom_provider_map = [  # 👉 KEY STEP - REGISTER HANDLER\n    {\"provider\": \"my-custom-llm-endpoint\", \"custom_handler\": my_custom_llm}\n]\n\napi_key = os.environ[\"MY_SECRET_KEY\"]\n\ngiskard.llm.set_llm_model(\"my-custom-llm-endpoint/my-custom-model\", api_key=api_key)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries\nDESCRIPTION: This code imports necessary libraries including numpy and pandas for data manipulation, and specific modules from the giskard library such as Model, Dataset, scan, testing, and demo. These modules are essential for defining the model, wrapping the dataset, scanning for vulnerabilities, and running tests.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\n\nfrom giskard import Model, Dataset, scan, testing, demo\n```\n\n----------------------------------------\n\nTITLE: Complete Giskard Correctness Score Metric - Python\nDESCRIPTION: Presents the full code for the `CorrectnessScoreMetric` class, including all necessary imports, the definition of the SYSTEM_PROMPT and INPUT_TEMPLATE constants used by the LLM call, and the `__call__` method implementation. It retrieves the LLM client, formats prompts, calls the LLM, parses the JSON output for the 'correctness_score', and includes error handling. Requires Giskard and LlamaIndex dependencies.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.llm.client import get_default_client\nfrom giskard.llm.errors import LLMGenerationError\n\nfrom giskard.rag import AgentAnswer\nfrom giskard.rag.metrics.base import Metric\nfrom giskard.rag.question_generators.utils import parse_json_output\nfrom giskard.rag.metrics.correctness import format_conversation\n\nfrom llama_index.core.base.llms.types import ChatMessage\n\nSYSTEM_PROMPT = \"\"\"Your task is to evaluate a Q/A system. \nThe user will give you a question, an expected answer and the system's response.\nYou will evaluate the system's response and provide a score.\nWe are asking ourselves if the response is correct, accurate and factual, based on the reference answer.\n\nGuidelines:\n1. Write a score that is an integer between 1 and 5. You should refer to the scores description.\n2. Follow the JSON format provided below for your output.\n\nScores description:\n    Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n    Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n    Score 3: The response is somewhat correct, accurate, and/or factual.\n    Score 4: The response is mostly correct, accurate, and factual.\n    Score 5: The response is completely correct, accurate, and factual.\n\nOutput Format (JSON only):\n{{\n    \"correctness_score\": (your rating, as a number between 1 and 5)\n}}\n\nDo not include any additional text—only the JSON object. Any extra content will result in a grade of 0.\n\"\"\"\n\nINPUT_TEMPLATE = \"\"\"\n### CONVERSATION\n{conversation}\n\n### AGENT ANSWER\n{answer}\n\n### REFERENCE ANSWER\n{reference_answer}\n\"\"\"\n\nclass CorrectnessScoreMetric(Metric):\n    def __call__(self, question_sample: dict, answer: AgentAnswer) -> dict:\n        \"\"\"\n        Compute the correctness *as a number from 1 to 5* between the agent answer and the reference answer.\n\n        Parameters\n        ----------\n        question_sample : dict\n            A question sample from a QATestset.\n        answer : AgentAnswer\n            The answer of the agent on the question.\n\n        Returns\n        -------\n        dict\n            The result of the correctness scoring. It contains the key 'correctness_score'.\n            \n        Raises\n        ------\n        LLMGenerationError\n            If there is an issue during the LLM evaluation process.\n        \"\"\"\n\n        # Implement your LLM call with litellm\n        llm_client = self._llm_client or get_default_client()\n        try:\n            out = llm_client.complete(\n                messages=[\n                    ChatMessage(\n                        role=\"system\",\n                        content=SYSTEM_PROMPT,\n                    ),\n                    ChatMessage(\n                        role=\"user\",\n                        content=INPUT_TEMPLATE.format(\n                            conversation=format_conversation(\n                                question_sample.conversation_history\n                                + [{\"role\": \"user\", \"content\": question_sample.question}]\n                            ),\n                            answer=answer.message,\n                            reference_answer=question_sample.reference_answer,\n                        ),\n                    ),\n                ],\n                temperature=0,\n                format=\"json_object\",\n            )\n            \n            # We asked the LLM to output a JSON object, so we must parse the output into a dict\n            json_output = parse_json_output(\n                out.content,\n                llm_client=llm_client,\n                keys=[\"correctness_score\"],\n                caller_id=self.__class__.__name__,\n            )\n\n            return json_output\n\n        except Exception as err:\n            raise LLMGenerationError(\"Error while evaluating the agent\") from err\n```\n\n----------------------------------------\n\nTITLE: Preprocessing Data\nDESCRIPTION: This snippet defines a function, `preprocess_data`, to handle data preprocessing steps. It removes rows containing NaN values and specified columns from the input pandas DataFrame, creating a cleaned dataset suitable for model training. The removed columns are defined in `DROP_FEATURES`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n    # Drop NaNs and columns.\n    df = df.dropna()\n    df = df.drop(columns=DROP_FEATURES)\n    return df\n```\n\n----------------------------------------\n\nTITLE: Building a LangChain Retrieval Augmented Generation (RAG) QA Model in Python\nDESCRIPTION: Defines a function to create FAISS context storage by loading the IPCC PDF, splitting it, and embedding the chunks via OpenAIEmbeddings for retrieval. Constructs a RetrievalQA chain using the defined prompt, LLM, and retriever. Runs a sample QA query to validate proper setup. Dependencies include LangChain, OpenAI, PyPDFLoader, and FAISS. The function facilitates efficient retrieval of context-relevant information for the QA system.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef get_context_storage() -> FAISS:\n    \"\"\"Initialize a vector storage of embedded IPCC report chunks (context).\"\"\"\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True)\n    docs = PyPDFLoader(IPCC_REPORT_URL).load_and_split(text_splitter)\n    db = FAISS.from_documents(docs, OpenAIEmbeddings())\n    return db\n\n\n# Create the chain.\nllm = OpenAI(model=LLM_NAME, temperature=0)\nprompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\nclimate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=get_context_storage().as_retriever(), prompt=prompt)\n\n# Test the chain.\nclimate_qa_chain(\"Is sea level rise avoidable? When will it stop?\")\n\n```\n\n----------------------------------------\n\nTITLE: Wrapping Regression Model (Model Object)\nDESCRIPTION: This snippet shows wrapping a regression model object by subclassing `giskard.Model`. The `model_predict` method preprocesses the input data and then calls the model's predict method. `numpy` is used to squeeze the output.  `giskard.Model` is instantiated, passing the model object, type, feature names, and optional name.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nclass MyCustomModel(giskard.Model):\n    def model_predict(self, df):\n        preprocessed_df = demo_data_processing_function(df)\n        return np.squeeze(self.model.predict(preprocessed_df))\n\ngiskard_model = MyCustomModel(\n    model=demo_regression_model,\n    model_type=\"regression\",\n    feature_names=['x'],  # Default: all columns of your dataset\n    name=\"my_regression_model\", # Optional: give it a name to identify it in metadata\n    # model_postprocessing_function=None, # Optional\n    # **kwargs # Additional model-specific arguments\n)\n```\n\n----------------------------------------\n\nTITLE: Limiting Giskard Detector Dataset Size via 'max_dataset_size' Parameter in Python\nDESCRIPTION: This snippet demonstrates configuring certain Giskard detectors to scan only a random sample of the dataset, by specifying 'max_dataset_size' for each detector in the 'params' dictionary. This is useful for large datasets where a full scan would be slow. Dependencies are Giskard, a model, and a dataset. The scan will stratify samples in classification tasks to balance classes, and the user can adjust the maximum size as needed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nparams = {\n    \"performance_bias\": dict(max_dataset_size=100_000),\n    \"overconfidence\": dict(max_dataset_size=100_000),\n    \"underconfidence\": dict(max_dataset_size=100_000),\n}\n\nreport = gsk.scan(my_model, my_dataset, params=params)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard for Testing\nDESCRIPTION: Creates a Giskard Model wrapper around the prediction function, specifying model type, classification labels, and feature names. The wrapped model is then validated against the test set to ensure it performs identically to the original model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df: pd.DataFrame) -> np.ndarray:\n    return pipeline.predict_proba(df)\n\n\nwrapped_model = Model(\n    model=prediction_function,  # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"Drug classifier\",  # Optional.\n    classification_labels=pipeline.classes_,  # Their order MUST be identical to the prediction_function's output order.\n    feature_names=X_test.columns,  # Default: all columns of your dataset.\n)\n\n# Validate wrapped model.\nwrapped_y_test_pred = wrapped_model.predict(giskard_dataset).prediction\nwrapped_test_metric = accuracy_score(y_test, wrapped_y_test_pred)\nprint(f\"Wrapped Test accuracy score: {wrapped_test_metric:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Scanning and Logging Tabular ML Model Results with Giskard and W&B in Python\nDESCRIPTION: This Python script prepares two LGBMClassifier models trained on the Titanic dataset, wraps both with Giskard utilities for vulnerability detection, and logs analysis results to Weights & Biases (W&B). Dependencies include giskard, wandb, and a suitable environment for LightGBM. The script covers dataset preparation, SHAP-based feature attribution, automated vulnerability scanning, test suite execution, and batch logging to W&B for each model. Required parameters include W&B authentication key, dataset column names, and classification labels. Inputs are ML models and dataset, and outputs are logged analyses visualizable in W&B UI. The script expects models compatible with Giskard, and may require adaptation for other data schemas.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-tabular-example.ipynb#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport wandb\n\nfrom giskard import Model, Dataset, demo, explain_with_shap, scan\n\nmodel1, df = demo.titanic(model=\"LGBMClassifier\", max_iter=5)\nmodel2, __ = demo.titanic(model=\"LGBMClassifier\", max_iter=100)  # Datasets are identical.\nmodels = {\"titanic-model_lgbm_max_iter=5\": model1, \"titanic-model_lgbm_max_iter=100\": model2}\n\nwrapped_data = Dataset(df=df, \n                       target=\"Survived\",\n                       cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\nwandb.login(key=\"key to retrieve from https://wandb.ai/authorize\")\nfor model_name, model in models.items():\n    wrapped_model = Model(model=model.predict_proba,\n                          model_type=\"classification\",\n                          feature_names=['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], \n                          classification_labels=model.classes_)\n\n    run = wandb.init(project=\"titanic_demo\", name=model_name)\n\n    # Log results to the new W&B run.\n    wrapped_data.to_wandb()\n    \n    shap_explanation_result = explain_with_shap(wrapped_model, wrapped_data)\n    shap_explanation_result.to_wandb()\n\n    scan_results = scan(wrapped_model, wrapped_data)\n    scan_results.to_wandb()\n\n    test_suite = scan_results.generate_test_suite()\n    test_suite.run().to_wandb()\n\n    # Finish a current run.\n    run.finish()\n```\n\n----------------------------------------\n\nTITLE: Displaying and Saving Scan Results Report\nDESCRIPTION: Shows how to interact with the scan report (`results`). `display(results)` is used to visualize the report directly within a notebook environment, providing an interactive summary of findings. `results.to_html(\"scan_report.html\")` exports the full report to a static HTML file for sharing or later review.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n\n# Save it to a file\nresults.to_html(\"scan_report.html\")\n```\n\n----------------------------------------\n\nTITLE: Building and Training the scikit-learn Model Pipeline - Python\nDESCRIPTION: Defines and trains a scikit-learn Pipeline combining text preprocessing and logistic regression. Calculates ROC-AUC and balanced accuracy scores for both train and test sets, with printed outputs. Inputs: train and test feature DataFrames and labels. Outputs: trained pipeline, printed metrics. Dependencies: sklearn, numpy.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npipeline = Pipeline(\n    steps=[\n        (\"preprocessor\", preprocessor),\n        (\"estimator\", LogisticRegression(random_state=RANDOM_SEED, class_weight=\"balanced\")),\n    ]\n)\n\npipeline.fit(X_train, y_train)\n\n# ROC-AUC score.\ntrain_metric = roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])\ntest_metric = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\nprint(f\"Train ROC-AUC score: {train_metric:.2f}\")\nprint(f\"Test ROC-AUC score: {test_metric:.2f}\")\n\n# Balanced accuracy to account for imbalanced targets.\nb_acc_train = balanced_accuracy_score(y_train, pipeline.predict(X_train))\nb_acc_test = balanced_accuracy_score(y_test, pipeline.predict(X_test))\nprint(f\"Train balanced accuracy: {b_acc_train:.2f}\")\nprint(f\"Test balanced accuracy: {b_acc_test:.2f}\")\n\n```\n\n----------------------------------------\n\nTITLE: Defining Preprocessing Steps for Text\nDESCRIPTION: Defines functions for text preprocessing including tokenization and embedding generation using DistilBERT. The `get_max_sequence_length` function calculates the maximum length of tokenized documents. The `tokenize_documents` function tokenizes the input text. The `get_documents_embeddings` function generates embeddings using the DistilBERT model. The `preprocess_text` function orchestrates all preprocessing steps, converting text data into numerical representations suitable for the model. This is a crucial step to transform raw text into a format that the model can understand.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nembedder = ppb.DistilBertModel.from_pretrained(PRETRAINED_WEIGHTS_NAME)\ntokenizer = ppb.DistilBertTokenizer.from_pretrained(PRETRAINED_WEIGHTS_NAME)\n\n\ndef get_max_sequence_length(corpus: pd.Series) -> int:\n    \"\"\"Define a length of the longest tokenized document.\"\"\"\n    max_length = max(len(tokenizer.encode(document, add_special_tokens=True)) for document in corpus)\n    return max_length\n\n\nmax_sequence_length = get_max_sequence_length(reviews_df[TEXT_COLUMN])\n\n\ndef tokenize_documents(corpus: pd.Series) -> torch.Tensor:\n    \"\"\"Tokenization step.\"\"\"\n    tokens_matrix = corpus.apply(lambda document: tokenizer.encode(document, add_special_tokens=True)).values\n    tokens_matrix = torch.tensor(\n        [tokens_row + [0] * (max_sequence_length - len(tokens_row)) for tokens_row in tokens_matrix]\n    )\n    return tokens_matrix\n\n\ndef get_documents_embeddings(tokens_matrix: torch.Tensor) -> np.ndarray:\n    \"\"\"Calculate sentence embeddings using distill-BERT model.\"\"\"\n    attention_mask = torch.where(tokens_matrix != 0, 1, 0)\n\n    embedder.eval()\n    with torch.no_grad():\n        tokens_representations = embedder(tokens_matrix, attention_mask=attention_mask)\n\n    # Take just 'cls token' embeddings, which represent whole sentence embedding.\n    documents_embeddings = tokens_representations[0][:, 0, :].numpy()\n    return documents_embeddings\n\n\ndef preprocess_text(df: pd.DataFrame) -> np.ndarray:\n    \"\"\"Preprocessing function to be also used in 'giskard.Model'.\"\"\"\n    return get_documents_embeddings(tokenize_documents(df[TEXT_COLUMN]))\n\nX_train, Y_train = preprocess_text(train_df), train_df.label\nX_test, Y_test = preprocess_text(test_df), test_df.label\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Giskard Test Suite from Scan Report - Python\nDESCRIPTION: Automates the creation of a Giskard test suite directly from scan-identified vulnerabilities. The test suite can be run to validate model performance against detected risks. Inputs: ScanReport; outputs: a test suite object and corresponding validation results. Fast way to operationalize vulnerability findings in CI or iterative QA workflows.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = full_report.generate_test_suite(name=\"Test suite generated by scan\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping Prediction Function with Giskard Model (Python)\nDESCRIPTION: Demonstrates wrapping a custom prediction function with the Giskard Model class for classification tasks. The prediction function processes a raw DataFrame and returns prediction probabilities, encapsulating all preprocessing. Dependencies: pandas, a fitted classification model (e.g., scikit-learn), and Giskard. Required parameters: prediction function, model_type, and classification_labels. Optional: feature_names, model name, and threshold. Input: DataFrame. Output: Giskard Model object supporting scanning.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_nlp/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df):\n    preprocessed_df = demo_data_processing_function(df) # The pre-processor can be a pipeline of one-hot encoding, imputer, scaler, etc.\n    return demo_classification_model.predict_proba(preprocessed_df)\n\ngiskard_model = giskard.Model(\n    model=prediction_function,\n    model_type=\"classification\",\n    classification_labels=demo_classification_model.classes_,  # The order MUST be identical to the prediction_function's output order\n    feature_names=[TEXT_COLUMN],  # Default: all columns of your dataset\n    name=\"Tweets sentiment classification\", # Optional: give it a name to identify it in metadata\n    # classification_threshold=0.5, # Optional: Default: 0.5\n)\n```\n\n----------------------------------------\n\nTITLE: Adding a Custom Test to the Giskard Test Suite\nDESCRIPTION: Demonstrates customizing a Giskard test suite by adding a specific test. It uses `test_suite.add_test()` to include `testing.test_f1`, which checks if the model's F1 score on the provided dataset meets a minimum threshold (0.7). The `run()` method is chained to execute the updated suite immediately after adding the test.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Building, Training, and Evaluating a Scikit-learn Pipeline\nDESCRIPTION: Constructs a scikit-learn `Pipeline`. The pipeline first uses `FunctionTransformer` with `adapt_vectorizer_input` to prepare the text data, then applies `TfidfVectorizer` for feature extraction (limited to 10000 features), and finally uses `GradientBoostingRegressor` for prediction. The pipeline is trained on the training data (`train_X`, `train_Y`), predictions are made on both train and test sets, and the Mean Absolute Error (MAE) is calculated and printed for both.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Define pipeline.\npipeline = Pipeline(\n    steps=[\n        (\"vectorizer_adapter\", FunctionTransformer(adapt_vectorizer_input)),\n        (\"vectorizer\", TfidfVectorizer(max_features=10000)),\n        (\"regressor\", GradientBoostingRegressor(n_estimators=10)),\n    ]\n)\n\n# Fit pipeline.\npipeline.fit(train_X, train_Y)\n\n# Perform inference on train and test data.\npred_train = pipeline.predict(train_X)\npred_test = pipeline.predict(test_X)\n\ntrain_metric = mean_absolute_error(train_Y, pred_train)\ntest_metric = mean_absolute_error(test_Y, pred_test)\n\nprint(f\"Train MAE: {train_metric: .2f}\\n\" f\"Test MAE: {test_metric: .2f}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Cell-Level Slicing Function in Python with Giskard\nDESCRIPTION: Shows how to create a cell-level slicing function that operates on individual column values. This function checks if a cell value exceeds a specified threshold and returns a boolean result.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_slices/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard import slicing_function, demo, Dataset\n\n\n_, df = demo.titanic()\ndataset = Dataset(df=df, target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\n\n@slicing_function(cell_level=True)\ndef my_func3(cell: int, threshold: int):\n    return cell > threshold\n\n\ndataset.slice(my_func3(threshold=20), column_name='Age')\n```\n\n----------------------------------------\n\nTITLE: Running Vulnerability Scan on Giskard Model and Dataset in Python\nDESCRIPTION: Executes Giskard's scan function to automatically detect various types of model vulnerabilities including biases, data leakage, and robustness issues using the wrapped model and dataset. The scan returns results useful for understanding potential weaknesses in the regression model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Setting up Azure OpenAI LLM Client using .env variables in Python\nDESCRIPTION: This snippet shows how to configure Azure OpenAI as an LLM provider for Giskard using environment variables. It sets Azure API key, endpoint base URL, API version, and optionally Azure AD tokens and API types. The LLM and embedding models are explicitly set referencing Azure model identifiers. This requires setting environment variables appropriately, a valid Azure subscription with the specified API key and endpoint, and the giskard package. Inputs include API credentials and model names, output is the Giskard LLM client configured to use Azure OpenAI services.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"AZURE_API_KEY\"] = \"\" # \"my-azure-api-key\"\nos.environ[\"AZURE_API_BASE\"] = \"\" # \"https://example-endpoint.openai.azure.com\"\nos.environ[\"AZURE_API_VERSION\"] = \"\" # \"2023-05-15\"\n\ngiskard.llm.set_llm_model(\"azure/<your_llm_name>\")\ngiskard.llm.set_embedding_model(\"azure/<your_embed_model_name>\")\n\n# Optional Keys - Azure AD Token, Azure API Type\nos.environ[\"AZURE_AD_TOKEN\"] = \"\"\nos.environ[\"AZURE_API_TYPE\"] = \"\"\n```\n\n----------------------------------------\n\nTITLE: Defining dataset preprocessing function\nDESCRIPTION: This function preprocesses the raw dataset by converting 'TotalCharges' to numeric, dropping NaNs and customerID, and cleaning the 'PaymentMethod' column. It prepares the data for modeling, ensuring consistency and handling missing values.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Perform data-preprocessing steps.\"\"\"\n    df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n    df = df.dropna()\n    df = df.drop(columns=\"customerID\")\n    df[\"PaymentMethod\"] = df[\"PaymentMethod\"].str.replace(\" (automatic)\", \"\", regex=False)\n    return df\n\nchurn_df = pd.read_csv(DATASET_URL)\nchurn_df = preprocess(churn_df)\n```\n\n----------------------------------------\n\nTITLE: Defining constants for the sentiment classification model\nDESCRIPTION: Sets up constants for data processing, model configuration, and file paths used throughout the project.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants\nTEXT_COLUMN_NAME = \"Review\"\nTARGET_COLUMN_NAME = \"label\"\n\nMAX_NUM_ROWS = 1000\n\nPRETRAINED_WEIGHTS_NAME = \"distilbert-base-uncased\"\nSTOP_WORDS = set(stopwords.words(\"english\"))\nRANDOM_SEED = 0\n\nDATA_URL = \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/tripadvisor_reviews_dataset-{}\"\nDATA_PATH = Path.home() / \".giskard\" / \"tripadvisor_reviews_dataset\"\nDATA_FILE_NAME = \"tripadvisor_hotel_reviews.csv.tar.gz\"\n```\n\n----------------------------------------\n\nTITLE: Wrapping Scikit-learn Model with Giskard Model Object\nDESCRIPTION: Wraps the trained scikit-learn pipeline for use with Giskard. First, a `prediction_function` is defined that takes a DataFrame and returns the pipeline's predictions. This function is then passed to the `giskard.Model` constructor, along with the model type (`regression`), a name, and the feature names. Finally, it validates the wrapped model by making predictions on the `giskard_dataset` and calculating the MAE, comparing it to the original test MAE.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Wrap the prediction method\ndef prediction_function(df):\n    return pipeline.predict(df)\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"regression\",  # Either regression, classification or text_generation.\n    name=\"hotel_text_regression\",  # Optional.\n    feature_names=[FEATURE_COLUMN_NAME],  # Default: all columns of your dataset.\n)\n\n# Validate wrapped model.\npred_test_wrapped = giskard_model.predict(giskard_dataset).raw_prediction\nwrapped_test_metric = mean_absolute_error(test_Y, pred_test_wrapped)\nprint(f\"Wrapped Test MAE: {wrapped_test_metric: .2f}\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping Trained Model Into Giskard Model with Prediction Function in Python\nDESCRIPTION: Defines a prediction function that wraps the trained pipeline's predict method and creates a Giskard Model object with this function, specifying model type as regression and feature names from training data. Demonstrates model wrapping which is required for vulnerability scanning and testing workflows with Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Wrap the prediction function\ndef prediction_function(df):\n    return pipeline.predict(df)\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"regression\",  # Either regression, classification or text_generation.\n    name=\"insurance model\",  # Optional.\n    feature_names=X_train.columns,  # Default: all columns of your dataset.\n)\n\n# Validate wrapped model.\nwrapped_predict = giskard_model.predict(giskard_dataset)\nwrapped_test_metric = r2_score(y_test, wrapped_predict.prediction)\n\nprint(f\"Wrapped Test R2-score: {wrapped_test_metric:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard Dataset\nDESCRIPTION: This snippet wraps the test data and target variable into a Giskard Dataset object. This is necessary for using Giskard's scanning and testing capabilities. The `Dataset` object takes the raw test data and the target column as input, along with optional parameters like categorical columns (`cat_columns`) and a name. The purpose is to enable Giskard to work with the dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_test, y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN,  # Ground truth variable.\n    name=\"salary_data\",  # Optional.\n    cat_columns=CATEGORICAL_FEATURES,\n    # List of categorical columns. Optional, but is a MUST if available. Inferred automatically if not.\n)\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Automated Test Suites from Giskard Scan Results in Python\nDESCRIPTION: Creates a comprehensive test suite from full scan results and executes it to systematically validate the QA model's behavior across all identified test scenarios. This step ensures repeatable, regression-safe testing based on actual detected vulnerabilities. The generated suite facilitates ongoing model evaluation as underlying models or data are updated.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = full_results.generate_test_suite(\"Test suite generated by scan\")\ntest_suite.run()\n\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model and Dataset with Giskard\nDESCRIPTION: This code prepares the model and dataset for use with Giskard by wrapping them in Giskard's `Model` and `Dataset` objects. It defines a sample corpus of input prompts and creates a pandas DataFrame. It also defines a `prediction_function` which takes a dataframe and returns the output from the `ask` function which queries the RAG pipeline. Finally, it instantiates `Model` with necessary metadata such as model type, name, description, and feature names.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Optional: Wrap a dataframe of sample input prompts to validate the model wrapping and to narrow specific tests' queries.\ncorpus = [\n    \"How many records were set at the 2022 Winter Olympics?\",\n    \"Did Jamaica or Cuba have more athletes at the 2022 Winter Olympics?\",\n    \"Which Olympic sport is the most entertaining?\",\n    \"Which Canadian competitor won the frozen hot dog eating competition?\",\n    \"How did COVID-19 affect the 2022 Winter Olympics?What's 2+2?\",\n]\n\nraw_data = pd.DataFrame(data={TEXT_COLUMN_NAME: corpus})\ngiskard_dataset = Dataset(raw_data, target=None)\n\n\n# Wrap the model.\ndef prediction_function(df):\n    return [ask(data) for data in df[TEXT_COLUMN_NAME]]\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"text_generation\",  # Either regression, classification or text_generation.\n    name=\"The LLM, which knows about the Winter 2022 Olympics\",  # Optional.\n    description=\"This model knows facts about the Winter 2022 Olympics from the Wikipedia source. This model responses strictly and shortly. This model politely refuse to provide an answer if the question does not relate to the topic of the Winter 2022 Olympics.\",\n    # Is used to generate prompts during the scan.\n    feature_names=[TEXT_COLUMN_NAME],  # Default: all columns of your dataset.\n)\n```\n\n----------------------------------------\n\nTITLE: Generating a Giskard Scan Report (Python)\nDESCRIPTION: Performs an automated scan on the given model and dataset to detect performance issues or vulnerabilities, generating a ScanReport object for later use. This step is optional, only necessary if in-depth analysis of model biases or performance issues is desired via the Copilot. Requires pre-initialized Giskard Model and Dataset objects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nscan_result = giskard.scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Enabling Dialogue Mode with Giskard Talk Context (Python)\nDESCRIPTION: This Python snippet illustrates how to maintain conversational context between `giskard_model.talk` calls. The first call asks a question and stores the result. The second call asks a related follow-up question, passing the `summary` of the first call's result in the `context` parameter. This allows the model agent to understand the previous interaction and provide a coherent response to the subsequent query. Requires `giskard_model` and `giskard_dataset`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntalk_result = giskard_model.talk(question=\"Have 'Webber, miss. Susan' survived in the Titanic incident?\", dataset=giskard_dataset)\ngiskard_model.talk(question=\"Can you explain me, why did she survive?\", context=talk_result.summary, dataset=giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Building LangChain RAG QA Model with FAISS - Python\nDESCRIPTION: Creates a Retrieval-Augmented Generation QA pipeline using LangChain, OpenAI embeddings, and a FAISS-based vector store over the IPCC report PDF. Loads and splits the PDF into chunks, stores embeddings in FAISS, and constructs a RetrievalQA chain with a custom prompt and OpenAI LLM. Required dependencies: langchain, langchain-openai, faiss-cpu, pypdf, openai. Input is user question(s); output is model-generated answers based on retrieved IPCC context.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import FAISS, PromptTemplate\nfrom langchain_openai import OpenAI, OpenAIEmbeddings\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.chains import RetrievalQA\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Prepare vector store (FAISS) with IPPC report\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True)\nloader = PyPDFLoader(\"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\")\ndb = FAISS.from_documents(loader.load_and_split(text_splitter), OpenAIEmbeddings())\n\n# Prepare QA chain\nPROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard.\nYour task is to answer common questions on climate change.\nYou will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023).\nPlease provide short and clear answers based on the provided context. Be polite and helpful.\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nYour answer:\n\"\"\"\n\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\nprompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\nclimate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)\n\n# Test that everything works\nclimate_qa_chain.invoke({\"query\": \"Is sea level rise avoidable? When will it stop?\"})\n```\n\n----------------------------------------\n\nTITLE: Adding an F1 Score Test to a Giskard Test Suite in Python\nDESCRIPTION: This code adds a unit test to a Giskard test suite that verifies if the model's F1 score on the given dataset is above the specified threshold of 0.7. The test is added to an existing test suite and immediately executed using the run() method.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Defining Row-Level Transformation Function in Giskard Python\nDESCRIPTION: This example illustrates how to define a custom Giskard transformation function that operates on individual rows of a pandas DataFrame. Decorated with `@transformation_function(row_level=True)`, the function takes a pandas Series (representing a row) as its first argument and returns a modified row. It demonstrates modifying the 'Age' column and applying the transformation to a Giskard Dataset. Requires the pandas and giskard libraries.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_transformations/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom giskard import transformation_function, demo, Dataset\n\n\n_, my_df = demo.titanic()\ndataset = Dataset(df=my_df, target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\n\n@transformation_function(row_level=True)\ndef my_func2(row: pd.Series, offset: int):\n    row['Age'] = row['Age'] + offset\n    return row\n\n\ntransformed_dataset = dataset.transform(my_func2(offset=20))\n```\n\n----------------------------------------\n\nTITLE: Gemini LLM Client Configuration\nDESCRIPTION: Sets environment variable for Gemini API key and assigns Gemini models for LLM and embedding in giskard. This integration allows testing on Gemini's domain-specific models for vulnerability detection.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"GEMINI_API_KEY\"] = \"\" # \"my-gemini-api-key\"\n\ngiskard.llm.set_llm_model(\"gemini/gemini-1.5-pro\")\n giskard.llm.set_embedding_model(\"gemini/text-embedding-004\")\n```\n\n----------------------------------------\n\nTITLE: OpenAI LLM Client Setup\nDESCRIPTION: Configures environment variables and sets the LLM and embedding models for OpenAI using the giskard library. Dependencies include os and giskard packages. This setup enables Giskard to connect with OpenAI's API for LLM-assisted vulnerability detection.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"OPENAI_API_KEY\"] = \"\" # \"my-openai-api-key\"\n\ngiskard.llm.set_llm_model(\"gpt-4o\")\n giskard.llm.set_embedding_model(\"text-embedding-3-small\")\n\nos.environ[\"OPENAI_ORGANIZATION\"] = \"\" # \"my-openai-organization\"\nos.environ[\"OPENAI_API_BASE\"] = \"\" # \"https://api.openai.com\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Langchain QA Chain (Python)\nDESCRIPTION: Initializes the OpenAI LLM client with specific parameters (API key, timeout, retries, temperature, model name) and creates a Langchain `RetrievalQA` chain. This chain uses the previously created FAISS vector store as a retriever to answer questions based on the document context.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Create the chain.\nllm = OpenAI(\n    openai_api_key=OPENAI_API_KEY,\n    request_timeout=20,\n    max_retries=100,\n    temperature=0.2,\n    model_name=LLM_NAME,\n)\nqa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=get_context_storage().as_retriever())\n```\n\n----------------------------------------\n\nTITLE: Generating and Running a Test Suite from Scan Results\nDESCRIPTION: This snippet shows how to create a test suite from scan results, run the tests locally, and provides links for further customization and integration into CI/CD pipelines. It emphasizes transforming scan findings into actionable tests.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = scan_results.generate_test_suite(\"My first test suite\")\n\n# Run the test suite locally\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping Prediction Function and Model with Giskard - Python\nDESCRIPTION: Defines a prediction function leveraging the trained pipeline's probability outputs and wraps it with Giskard's Model class, specifying classification type, class labels, and features. Also validates wrapped model output against test data via ROC-AUC. Requires giskard.Model, previously trained pipeline, and giskard Dataset. Inputs: DataFrame; Outputs: Giskard model object, metric score.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Wrap prediction function\ndef prediction_function(df):\n    return pipeline.predict_proba(df)\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"review_helpfulness_predictor\",  # Optional.\n    classification_labels=[0, 1],  # Their order MUST be identical to the prediction_function's output order.\n    feature_names=[\"reviewText\"],  # Default: all columns of your dataset.\n)\n\n# Validate wrapped model.\nwrapped_predict = giskard_model.predict(giskard_dataset).raw[:, 1]\nwrapped_test_metric = roc_auc_score(y_test, wrapped_predict)\n\nprint(f\"Wrapped Test ROC-AUC score: {wrapped_test_metric:.2f}\")\n\n```\n\n----------------------------------------\n\nTITLE: Wrapping Classification Model (Model Object)\nDESCRIPTION: This code snippet demonstrates how to wrap a classification model object directly by subclassing `giskard.Model` and implementing `model_predict`. The `model_predict` method takes a dataframe, preprocesses it using a custom function (`demo_data_processing_function`), and returns the predicted probabilities from the model. The `giskard.Model` is instantiated, passing in the model object, model type, classification labels, feature names, and optional name.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MyCustomModel(giskard.Model):\n    def model_predict(self, df):\n        preprocessed_df = demo_data_processing_function(df)\n        return self.model.predict_proba(preprocessed_df)\n\ngiskard_model = MyCustomModel(\n    model=demo_classification_model,\n    model_type=\"classification\",\n    classification_labels=demo_classification_model.classes_,  # Their order MUST be identical to the prediction_function's output order\n    feature_names=['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Survived'],  # Default: all columns of your dataset\n    name=\"titanic_model\", # Optional: give it a name to identify it in metadata\n    # classification_threshold=0.5, # Optional: Default: 0.5\n    # model_postprocessing_function=None, # Optional\n    # **kwargs # Additional model-specific arguments\n)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard\nDESCRIPTION: Defines a custom Giskard model wrapper, `QdrantRAGModel`, to adapt the LangChain QA chain for Giskard. The `model_predict` function defines how to generate model predictions using the QA chain, taking a Pandas DataFrame as input and returning the answer of each of the questions. It specifies `model_type`, `name`, `description`, and `feature_names` for the Giskard model wrapper.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Define a custom Giskard model wrapper for the serialization.\nclass QdrantRAGModel(Model):\n    def model_predict(self, df: pd.DataFrame) -> pd.DataFrame:\n        return df[TEXT_COLUMN_NAME].apply(lambda x: self.model.run({\"query\": x}))\n\n\n# Wrap the QA chain.\ngiskard_model = QdrantRAGModel(\n    model=google_qa_chain,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"text_generation\",  # Either regression, classification or text_generation.\n    name=\"The LLM, which knows different facts\",  # Optional.\n    description=\"This model knows different facts about movies, history, news, etc. It provides short single-sentence summary answer only. This model politely refuse if it does not know an answer.\",\n    # Is used to generate prompts during the scan.\n    feature_names=[TEXT_COLUMN_NAME],  # Default: all columns of your dataset.\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suites from Scan Results\nDESCRIPTION: Generates a test suite from the scan results using the `generate_test_suite` method, which integrates the detected vulnerabilities into a set of test cases. These test suites are useful to evaluate and validate model performance.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Creating AI-Based Sentiment Analysis Slicing Function in Python with Giskard\nDESCRIPTION: Demonstrates implementing a complex slicing function using a pre-trained sentiment analysis model from Hugging Face transformers. This function filters rows based on detected emotions and confidence scores in text data.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_slices/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom giskard import slicing_function\n\n\ndef _sentiment_analysis(x, column_name, threshold, model, emotion):\n    from transformers import pipeline\n    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model)\n    # Limit text to 512 characters\n    sentences = list(map(lambda txt: txt[:512], list(x[column_name])))\n    return x.iloc[list(\n        map(lambda s: s['label'] == emotion and s['score'] >= threshold, sentiment_pipeline(sentences)))]\n\n\n@slicing_function(name=\"Emotion sentiment\", row_level=False, tags=[\"sentiment\", \"text\"])\ndef emotion_sentiment_analysis(x: pd.DataFrame, column_name: str, emotion: str, threshold: float = 0.9) -> pd.DataFrame:\n    \"\"\"\n    Filter the rows where the specified 'column_name' has an emotion matching 'emotion', as determined by a pre-trained sentiment analysis model.\n    Possible emotion are: 'optimism', 'anger', 'sadness', 'joy'\n    \"\"\"\n    return _sentiment_analysis(x, column_name, threshold, \"cardiffnlp/twitter-roberta-base-emotion\", emotion)\n```\n\n----------------------------------------\n\nTITLE: Creating LangChain RetrievalQA Chains for OpenAI Models (Python)\nDESCRIPTION: Iterates through the model names (`gpt-3.5-turbo-instruct`, `gpt-4`). Instantiates the appropriate OpenAI LLM (`ChatOpenAI` or `OpenAI`) with `temperature=0`, creates a `RetrievalQA` chain using the LLM, the FAISS retriever (`db.as_retriever()`), and the predefined `prompt`. Stores the chain and a lambda function to invoke it on a DataFrame in the `chains` and `models` dictionaries respectively. Requires OpenAI API key.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_openai import ChatOpenAI, OpenAI\nfrom langchain.chains import RetrievalQA\n\nfor model_name in models.keys():\n  llm = ChatOpenAI(model=model_name, temperature=0) if model_name == \"gpt-4\" else OpenAI(model=model_name, temperature=0)\n  chains[model_name] = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)\n  models[model_name] = lambda df: [chains[model_name].invoke(row[\"query\"])['result'] for _, row in df.iterrows()]\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities\nDESCRIPTION: This snippet uses Giskard's `scan` function to automatically detect vulnerabilities in the wrapped model based on the provided dataset. The scan function analyzes the model's performance and identifies potential issues like biases, unrobustness, and data leakage.  The `scan` function takes the Giskard model and the Giskard dataset as input and returns a `results` object, containing findings.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard LLM Support (Bash)\nDESCRIPTION: Installs the Giskard Python library with the optional 'llm' extras, which includes dependencies required for working with Large Language Models. The '--upgrade' flag ensures the latest version is installed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n%pip install \"giskard[llm]\" --upgrade\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard and Giskard-Vision\nDESCRIPTION: This bash snippet installs the Giskard and Giskard-Vision libraries using pip. These are the required packages for running the model scans provided in the tutorial.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_vision/index.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install giskard giskard-vision\n```\n\n----------------------------------------\n\nTITLE: Performing Vulnerability Scan on an Object Detection Model\nDESCRIPTION: Executes Giskard's scan function, providing the model and dataset loader to automatically detect vulnerabilities such as performance biases and unrobustness. The results object contains detailed findings from the scan.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_object_detection.ipynb#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nresults = scan(model, dataloader)\n```\n\n----------------------------------------\n\nTITLE: Displaying and Exporting Scan Results\nDESCRIPTION: Displays the vulnerability scan report within a notebook using the display function. Additionally, it exports the report as an HTML file named 'scan_report.html' for external viewing or sharing. This step aids in analyzing model robustness and sharing findings.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_object_detection.ipynb#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\ndisplay(results)\n\n# Save it to file\nresults.to_html(\"scan_report.html\")\n```\n\n----------------------------------------\n\nTITLE: Logging Giskard Objects to MLflow (Fluent API)\nDESCRIPTION: This snippet shows how to log Giskard objects such as models, datasets, scan results, and test suite results into MLflow using the fluent API.  The function relies on the `to_mlflow` method of each Giskard object. It requires Giskard and MLflow to be installed and assumes that `giskard_model`, `giskard_dataset`, `scan_results`, and `test_suite_results` are valid Giskard objects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport mlflow\n\nwith mlflow.start_run() as run:\n    giskard_model.to_mlflow()\n    giskard_dataset.to_mlflow()\n    scan_results.to_mlflow()\n    test_suite_results.to_mlflow()\n```\n\n----------------------------------------\n\nTITLE: Building a RetrievalQA Chain Using Langchain and OpenAI in Python\nDESCRIPTION: Constructs a RetrievalQA chain for question answering over the IPCC Climate Change Synthesis Report. Uses langchain's PyPDFLoader for loading the PDF, a RecursiveCharacterTextSplitter for dividing the document, FAISS for vector storage, and OpenAI's GPT-3.5-turbo-instruct as the LLM. A custom prompt guides model outputs. Requires valid OpenAI credentials and access to the specified PDF URL.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.prompts import PromptTemplate\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain_openai import OpenAIEmbeddings, OpenAI\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n\n# Load the IPCC Climate Change Synthesis Report from a PDF file\nloader = PyPDFLoader(\"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\")\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=100,\n    length_function=len,\n    add_start_index=True,\n)\nMODEL_NAME = \"gpt-3.5-turbo-instruct\"\n\n# Load the splitted fragments in our vector store\ndocs = loader.load_and_split(text_splitter)\ndb = FAISS.from_documents(docs, OpenAIEmbeddings())\n\n\n# We use a simple prompt\nPROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard.\nYour task is to answer common questions on climate change.\nYou will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023).\nPlease provide short and clear answers based on the provided context. Be polite and helpful.\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nYour answer:\n\"\"\"\n\nllm = OpenAI(model=MODEL_NAME, temperature=0)\nprompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\nclimate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)\n```\n\n----------------------------------------\n\nTITLE: Evaluating RAG Models using MLflow and Giskard Evaluator (Python)\nDESCRIPTION: Loops through the configured models ('gpt-3.5-turbo-instruct', 'gpt-4'). For each, it starts an MLflow run named after the model and calls `mlflow.evaluate`. It passes the model invocation lambda, sets `model_type` to 'question-answering', provides the example DataFrame `df_example` as evaluation data, specifies 'giskard' as the evaluator, and includes the previously defined `evaluator_config`. This initiates Giskard's LLM scan within the MLflow framework.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfor model_name in models.keys():\n    with mlflow.start_run(run_name=model_name):\n        mlflow.evaluate(model=models[model_name],\n                        model_type=\"question-answering\",\n                        data=df_example,\n                        evaluators=\"giskard\", # <-- where the magic happens\n                        evaluator_config=evaluator_config)\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Test Suite from Giskard Scan Results\nDESCRIPTION: Creates a comprehensive test suite from the detected vulnerabilities in the scan results and executes it to validate the model's performance against known issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key and Pandas Display Options - Python\nDESCRIPTION: Configures the environment by setting the OpenAI API key, which is essential for interacting with the OpenAI language model. It also sets a Pandas display option to prevent output text from being truncated, useful for viewing full product descriptions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Set the OpenAI API Key environment variable.\nOPENAI_API_KEY = \"...\"\nopenai.api_key = OPENAI_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# Display options.\npd.set_option(\"display.max_colwidth\", None)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard\nDESCRIPTION: This code snippet wraps a pandas DataFrame into a Giskard Dataset object. The parameters include the DataFrame itself (`df`), the name of the target column (`target`), an optional name for the dataset, and a list of categorical columns (`cat_columns`).\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN,  # Ground truth variable\n    name=\"Titanic dataset\",  # Optional\n    cat_columns=CATEGORICAL_COLUMNS,\n    # List of categorical columns. Optional, but is a MUST if available. Inferred automatically if not.\n)\n```\n\n----------------------------------------\n\nTITLE: Fetching and Preprocessing Dataset in Python\nDESCRIPTION: Provides helper functions for robust data download, extraction, and loading. Functions fetch data files from predefined URLs, process real and fake news CSVs, assign binary targets, merge datasets, and drop unnecessary columns. Dependencies include pandas and urlretrieve, and sufficient permissions to write to the home directory.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef fetch_dataset() -> None:\n    \"\"\"Gradually fetch all necessary files from the FTP server.\"\"\"\n    files_to_fetch = (\"Fake.csv.tar.gz\", \"True.csv.tar.gz\", \"glove_100d.txt.tar.gz\")\n    for file_name in files_to_fetch:\n        fetch_demo_data(DATA_URL.format(file_name), DATA_PATH / file_name)\n\n\ndef load_data(**kwargs) -> pd.DataFrame:\n    \"\"\"Load data.\"\"\"\n    real_df = pd.read_csv(DATA_PATH / \"True.csv.tar.gz\", **kwargs)\n    fake_df = pd.read_csv(DATA_PATH / \"Fake.csv.tar.gz\", **kwargs)\n\n    # Create target column.\n    real_df[TARGET_COLUMN_NAME] = 0\n    fake_df[TARGET_COLUMN_NAME] = 1\n\n    # Combine dfs.\n    full_df = pd.concat([real_df, fake_df])\n    full_df.drop(columns=[\"subject\", \"date\"], inplace=True)\n    return full_df\n\n\nfetch_dataset()\nnews_df = load_data(nrows=N_ROWS)\n\n```\n\n----------------------------------------\n\nTITLE: Loading Data from URL and Local File\nDESCRIPTION: Defines functions to load the demo data. The `fetch_demo_data` function downloads the data from a provided URL and saves it to a local file if it doesn't exist. The `load_data` function calls `fetch_demo_data` and then reads the data from the local file into a Pandas DataFrame, dropping a specified column. The `nrows` parameter limits the number of rows loaded. This prepares the data for further preprocessing and model training steps.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef load_data(**kwargs) -> pd.DataFrame:\n    \"\"\"Load data.\"\"\"\n    fetch_demo_data(DATA_URL, DATA_PATH)\n\n    df = pd.read_json(DATA_PATH, lines=True, **kwargs)\n    df = df.drop(columns=\"label_text\")\n\n    return df\n\n\nreviews_df = load_data(nrows=2000)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite\nDESCRIPTION: Generates a test suite from the scan results using `generate_test_suite`, providing a name for the test suite.  Then, the test suite is executed using `test_suite.run()`\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"Test suite generated by scan\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Initializing Langchain SequentialChain with GPT Models in Python\nDESCRIPTION: Defines a dictionary to track multiple GPT models and initializes langchain LLMChain objects for keyword extraction and product description generation. Each model key contains a SequentialChain that concatenates the two LLMChains with specified input and output variables, enabling chained prompt execution for multiple models such as 'gpt-3.5-turbo' and 'gpt-4'.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\nfrom langchain.chains import SequentialChain\n\nfor model in models.keys():\n    # langchain model powered by ChatGPT\n    llm = ChatOpenAI(temperature=0.2, model=model)\n\n    # Defining the chains\n    keywords_chain = LLMChain(llm=llm, prompt=keywords_prompt_template, output_key=\"keywords\")\n    product_chain = LLMChain(llm=llm, prompt=product_prompt_template, output_key=\"description\")\n\n    # Concatenation of both chains\n    models[model][\"langchain\"] = SequentialChain(chains=[keywords_chain, product_chain],\n                                                 input_variables=[\"product_name\"],\n                                                 output_variables=[\"description\"])\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite from Scan Results\nDESCRIPTION: This snippet generates a test suite from the scan results using `results.generate_test_suite` and then runs the generated test suite to evaluate the model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping NeMo Guardrails App in Giskard Model (gsk.Model)\nDESCRIPTION: Wraps the NeMo Guardrails application within a Giskard Model to enable vulnerability scanning. A generator wrapper function is defined to generate answers for each question in the dataset.  The Giskard model is configured for `text_generation`, with specified `feature_names`, a model name, and a description.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nimport pandas as pd\n\nimport giskard as gsk\n\n\n# See Giskard docs on LLM scan for more info:\n# https://docs.giskard.ai/en/stable/getting_started/quickstart/quickstart_llm.html#Wrap-model-and-dataset-with-Giskard\ndef generator_wrapper(df):\n    answers = []\n    for q in df.question:\n        logging.info(f\"Q > {q}\")\n        ans = app.generate(messages=[{\"role\": \"user\", \"content\": q}])\n        answers.append(ans[\"content\"])\n\n    return answers\n\ngsk_model = gsk.Model(\n    generator_wrapper,\n    model_type=\"text_generation\",\n    name=\"Climate QA\",\n    description=\"A model that answers questions about climate change based on the IPCC report.\",\n    feature_names=[\"question\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Langchain Models with Giskard for Text Generation in Python\nDESCRIPTION: Uses the giskard.Model API to wrap langchain SequentialChain models providing metadata such as model type, description, and input feature names. This enables Giskard to generate internal evaluation prompts and apply testing and scanning capabilities on the language models chained for product description tasks.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\n\nfor model in models.keys():\n    models[model][\"giskard\"] = giskard.Model(models[model][\"langchain\"],\n                                             name=\"Product keywords and description generator\",\n                                             model_type=\"text_generation\",\n                                             description=\"Generate product description based on a product's name and the associated keywords. \"\n                                                         \"Description should be using emojis and being SEO compliant.\",\n                                             feature_names=['product_name'])\n```\n\n----------------------------------------\n\nTITLE: Wrapping Scikit-learn Pipeline with Giskard Model Object\nDESCRIPTION: Wraps the trained scikit-learn `pipeline` object using the `giskard.Model` class to make it compatible with Giskard's testing framework. It requires specifying the model object, the `model_type` ('classification'), an optional `name`, the `classification_labels` in the correct order, and the `feature_names`. After wrapping, it validates the Giskard model by predicting on the `giskard_dataset` and printing a classification report.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=pipeline,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"Credit scoring classifier\",  # Optional.\n    classification_labels=pipeline.classes_.tolist(),\n    # Their order MUST be identical to the prediction_function's output order.\n    feature_names=list(COLUMN_TYPES.keys()),  # Default: all columns of your dataset.\n)\n\n# Validate wrapped model.\nprint(classification_report(Y_test, pipeline.classes_[giskard_model.predict(giskard_dataset).raw_prediction]))\n```\n\n----------------------------------------\n\nTITLE: Verifying Giskard Evaluator Registration in MLflow (Python)\nDESCRIPTION: Imports the `mlflow` and `giskard` libraries and calls `mlflow.models.list_evaluators()` to check the available evaluators. The expected output includes 'giskard', confirming the successful integration setup.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport mlflow\nimport giskard\n\nmlflow.models.list_evaluators() # ['default', 'giskard']\n```\n\n----------------------------------------\n\nTITLE: Wrapping Test Data with Giskard Dataset Object\nDESCRIPTION: Prepares the test data for Giskard analysis by first concatenating the test features (`test_X`) and target (`test_Y`) into a single pandas DataFrame `raw_data`. Then, it wraps this `raw_data` using the `giskard.Dataset` class, specifying the DataFrame, the target column name, and an optional name for the dataset. This wrapping is essential for using Giskard's scan and testing features.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([test_X, test_Y], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN_NAME,  # Ground truth variable.\n    name=\"hotel_text_regression_dataset\",  # Optional.\n)\n```\n\n----------------------------------------\n\nTITLE: Creating and Wrapping a Retrieval-Augmented Generation (RAG) OpenAI Chain in Python\nDESCRIPTION: This snippet initializes a question-answering chain using OpenAI's LLM with a custom prompt template, then defines a custom Giskard model wrapper for serialization, prediction, saving, and loading. Dependencies include OpenAI, RetrievalQA, a retriever from FAISS, and the Giskard framework. The wrapper expects model input as a pandas DataFrame with a 'question' column, and handles saving the chain and retriever components; expected outputs are question answers related to climate change derived from supplied context.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\n# Create the chain.\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\nprompt = PromptTemplate(template=YOUR_PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\nclimate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=get_context_storage().as_retriever(), prompt=prompt)\n\n\n# Define a custom Giskard model wrapper for the serialization.\nclass FAISSRAGModel(giskard.Model):\n    def model_predict(self, df: pd.DataFrame):\n        return df[\"question\"].apply(lambda x: self.model.run({\"query\": x}))\n\n    def save_model(self, path: str, *args, **kwargs):\n        \"\"\"Saves the model to a given folder.\"\"\"\n        out_dest = Path(path)\n\n        # Save the chain object (`self.model` is the object we pass when we initialize our custom class, in this case\n        # it is a RetrievalQA chain, that can be easily saved to a JSON file).\n        self.model.save(out_dest.joinpath(\"model.json\"))\n\n        # Save the FAISS-based retriever\n        db = self.model.retriever.vectorstore\n        db.save_local(out_dest.joinpath(\"faiss\"))\n\n    @classmethod\n    def load_model(cls, path: str, *args, **kwargs) -> Chain:\n        \"\"\"Loads the model to a given folder.\"\"\"\n        src = Path(path)\n\n        # Load the FAISS-based retriever\n        db = FAISS.load_local(src.joinpath(\"faiss\"), OpenAIEmbeddings())\n\n        # Load the chain, passing the retriever\n        chain = load_chain(src.joinpath(\"model.json\"), retriever=db.as_retriever())\n        return chain\n\n\n# Now we can wrap our RAG\ngiskard_model = FAISSRAGModel(\n    model=climate_qa_chain,\n    model_type=\"text_generation\",\n    name=\"Climate Change Question Answering\",\n    description=\"This model answers any question about climate change based on IPCC reports\",\n    feature_names=[\"question\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite from Scan\nDESCRIPTION: This code snippet generates a test suite from the results of the Giskard scan using `results.generate_test_suite(\"My first test suite\")`. It then runs the generated test suite using `test_suite.run()` to evaluate the model's performance and identify potential issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Saving a Giskard Model Scan Report to HTML in Python\nDESCRIPTION: This code demonstrates how to export the results of a vulnerability scan on a Giskard-wrapped model to an HTML file for offline or later inspection. The snippet requires a scan_results object produced by giskard.scan and outputs an HTML file to the specified path.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\nscan_results.to_html(\"model_scan_results.html\")\n```\n\n----------------------------------------\n\nTITLE: Adding custom tests to Giskard test suite\nDESCRIPTION: This code adds a predefined F1 score test, with a threshold, to the test suite, allowing targeted validation of model performance on specific metrics. It demonstrates integration with Giskard's testing tools.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Creating Giskard Dataset Wrapper\nDESCRIPTION: Wraps the testing data in Giskard's Dataset class to prepare for vulnerability scanning. This includes specifying the target variable and categorical columns to ensure proper handling during testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nraw_dataset = pd.concat([X_test, y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_dataset,  # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_NAME,  # Ground truth variable.\n    name=\"Drug classification dataset\",  # Optional.\n    cat_columns=X_test.columns.tolist(),  # List of categorical columns. Optional, but is a MUST if available. Inferred automatically if not.\n)\n```\n\n----------------------------------------\n\nTITLE: Running Full Automated Vulnerability Scan with Giskard in Python\nDESCRIPTION: Invokes Giskard's scan function without restricting categories, producing a comprehensive assessment of the model's vulnerabilities (e.g., hallucination, harmfulness, prompt injection). Results are non-deterministic and can vary, given the stochastic nature of LLMs and Giskard's test generators. Outputs a rich results object for subsequent evaluation and test generation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfull_results = scan(giskard_model, giskard_dataset)\n\n```\n\nLANGUAGE: python\nCODE:\n```\ndisplay(full_results)\n\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip in Python\nDESCRIPTION: Installs the Giskard Python library using the pip package manager. This step is required for all subsequent functionality that relies on Giskard APIs. Ensure that your Python environment is active before running this command.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Library\nDESCRIPTION: This snippet installs the Giskard library using pip. It also includes the --upgrade flag to ensure the latest version is installed.  This library is a dependency for the rest of the notebook.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Running Single Giskard Test with Pytest in Python\nDESCRIPTION: Shows how to wrap a single Giskard test in a pytest function using fixtures for model and dataset. This example tests the accuracy of a model against a threshold of 0.7.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/pytest/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture\ndef dataset():\n    return wrapped_dataset\n\n\n@pytest.fixture\ndef model():\n    return wrapped_model\n\n\ndef test_only_accuracy(dataset, model):\n    test_accuracy(model=model, dataset=dataset, threshold=0.7).assert_()\n```\n\n----------------------------------------\n\nTITLE: Adding Custom F1 Score Test to Test Suite\nDESCRIPTION: Adds a custom test to the test suite that checks if the F1 score of the model on the test dataset exceeds a specified threshold (0.7), demonstrating how to extend the test suite with additional evaluation criteria.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=wrapped_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training and Testing Sets\nDESCRIPTION: Splits the loaded DataFrame `df` into training and testing sets using `train_test_split` from scikit-learn. Features (all columns except the target) and the target variable (`TARGET_COLUMN_NAME`) are separated. 20% of the data is allocated to the test set (`test_size=0.2`), stratification is applied based on the target variable (`stratify=df[TARGET_COLUMN_NAME]`), and a `random_state` is set for reproducibility.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nX_train, X_test, Y_train, Y_test = train_test_split(\n    df.drop(columns=TARGET_COLUMN_NAME),\n    df[TARGET_COLUMN_NAME],\n    test_size=0.2,\n    random_state=0,\n    stratify=df[TARGET_COLUMN_NAME],\n)\n```\n\n----------------------------------------\n\nTITLE: Saving Giskard Scan Results to HTML (Python)\nDESCRIPTION: Persists the scan report to an HTML file for later review or sharing. Requires a scan_results object generated by Giskard's scan function. Input: scan_results object. Output: model_scan_results.html file containing the report.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_nlp/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nscan_results.to_html(\"model_scan_results.html\")\n```\n\n----------------------------------------\n\nTITLE: Building and Training the Logistic Regression Pipeline\nDESCRIPTION: Creates a complete scikit-learn pipeline by combining the previously defined `preprocessor` with a `LogisticRegression` classifier. The pipeline is then trained using the training data (`X_train`, `Y_train`). After training, it generates predictions on both the training and test sets (`pred_train`, `pred_test`) and prints a classification report comparing the test predictions (`pred_test`) against the true test labels (`Y_test`).\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\npipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter=100))])\n\npipeline.fit(X_train, Y_train)\n\npred_train = pipeline.predict(X_train)\npred_test = pipeline.predict(X_test)\n\nprint(classification_report(Y_test, pred_test))\n```\n\n----------------------------------------\n\nTITLE: Scanning for Vulnerabilities\nDESCRIPTION: Performs a vulnerability scan using Giskard's `scan` function on the wrapped model. This will generate a report of model vulnerabilities using a variety of tests, including from predefined examples, heuristics, and LLM based generation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model)\n```\n\n----------------------------------------\n\nTITLE: Saving a Generated RAG Test Set to a JSONL File Using Giskard in Python\nDESCRIPTION: This snippet shows how to save a previously generated test set to a file in JSON Lines format. This enables persistent storage of generated RAG test data for future evaluation or sharing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Save the generated testset\ntestset.save(\"my_testset.jsonl\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard Model\nDESCRIPTION: This snippet wraps the trained scikit-learn model into a Giskard `Model` object, configuring it for use with Giskard's testing and analysis functionalities. It specifies the model, the model type (classification), and optional details like the model's name and class labels, which are essential for Giskard to properly interpret the model's predictions. It then validates the wrapper by calculating and printing accuracy based on Giskard's predict method.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=pipeline,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"salary_cls\",  # Optional.\n    classification_labels=pipeline.classes_,  # Their order MUST be identical to the prediction_function's output order.\n    feature_names=X_train.columns,  # Default: all columns of your dataset.\n)\n\n# Validate wrapped model.\nwrapped_predict = giskard_model.predict(giskard_dataset)\nwrapped_test_metric = accuracy_score(y_test, wrapped_predict.prediction)\n\nprint(f\"Wrapped Test accuracy: {wrapped_test_metric:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI LLM Client with Giskard in Python\nDESCRIPTION: This snippet shows the configuration for connecting Giskard to Azure OpenAI. The script sets API key, base endpoint, API version, and optionally Azure AD token and API type environment variables. It specifies Azure-based LLM and embedding model names to use within Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"AZURE_API_KEY\"] = \"\" # \"my-azure-api-key\"\nos.environ[\"AZURE_API_BASE\"] = \"\" # \"https://example-endpoint.openai.azure.com\"\nos.environ[\"AZURE_API_VERSION\"] = \"\" # \"2023-05-15\"\n\ngiskard.llm.set_llm_model(\"azure/<your_llm_name>\")\ngiskard.llm.set_embedding_model(\"azure/<your_embed_model_name>\")\n\nos.environ[\"AZURE_AD_TOKEN\"] = \"\"\nos.environ[\"AZURE_API_TYPE\"] = \"\"\n```\n\n----------------------------------------\n\nTITLE: Scanning the model for vulnerabilities using Giskard\nDESCRIPTION: This snippet performs an automatic vulnerability scan on the wrapped model and dataset, detecting potential issues such as biases, robustness problems, and ethical concerns. The results can be used for further analysis.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Building and Evaluating Logistic Regression Model\nDESCRIPTION: Trains a Logistic Regression model using the preprocessed training data. The model is then evaluated on both the training and testing sets using the `score` method, which computes the accuracy. This assesses the model's performance on the training data and evaluates how well it generalizes to the test dataset. The accuracy scores are printed to show the model's performance.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclassifier = LogisticRegression()\nclassifier.fit(X_train, Y_train)\n\n# Validate model.\ntrain_score = classifier.score(X_train, Y_train)\nprint(f\"Train accuracy: {train_score: .2f}\")\n\ntest_score = classifier.score(X_test, Y_test)\nprint(f\"Test accuracy: {test_score: .2f}\")\n```\n\n----------------------------------------\n\nTITLE: Building Drug Classification Pipeline with SMOTE and SVC\nDESCRIPTION: Creates a machine learning pipeline that includes one-hot encoding for categorical features, SMOTE for handling class imbalance, and a Support Vector Classifier with a linear kernel. The pipeline is trained and evaluated on both training and testing data.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\npipeline = PipelineImb(\n    steps=[\n        (\"one_hot_encoder\", OneHotEncoder()),\n        (\"resampler\", SMOTE(random_state=RANDOM_SEED)),\n        (\"classifier\", SVC(kernel=\"linear\", random_state=RANDOM_SEED, probability=True)),\n    ]\n)\n\npipeline.fit(X_train, y_train)\n\ny_train_pred = pipeline.classes_[pipeline.predict_proba(X_train).argmax(axis=1)]\ny_test_pred = pipeline.classes_[pipeline.predict_proba(X_test).argmax(axis=1)]\ntrain_metric = accuracy_score(y_train, y_train_pred)\ntest_metric = accuracy_score(y_test, y_test_pred)\n\nprint(f\"Train accuracy score: {train_metric:.2f}\\n\" f\"Test accuracy score: {test_metric:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Scanning an Image Classification Model with Giskard\nDESCRIPTION: This code snippet demonstrates how to use Giskard to scan an image classification model for potential issues. It utilizes a pre-defined dataloader (DataLoaderSkinCancer) and model wrapper (SkinCancerHFModel) from the giskard_vision library. The scan function is called with the model, dataset, and the number of images to scan. The results are then displayed in the notebook.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_vision/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard_vision.image_classification.models.wrappers import SkinCancerHFModel\nfrom giskard_vision.image_classification.dataloaders.loaders import DataLoaderSkinCancer\nfrom giskard_vision.core.scanner import scan\n\ndataset = DataLoaderSkinCancer()\nmodel = SkinCancerHFModel()\n\nscan_results = scan(model, dataset, num_images=5)\ndisplay(scan_results)  # in your notebook\n```\n\n----------------------------------------\n\nTITLE: Displaying scan results\nDESCRIPTION: Displays the vulnerability scan results for the sentiment classification model, showing detected issues and their severity.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results in Notebook - Python\nDESCRIPTION: Displays the scan results object in notebook output. Intended for Jupyter environments, it visually presents the vulnerabilities and insights returned by Giskard's scan. Input: scan results object; Output: rendered output cell.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n\n```\n\n----------------------------------------\n\nTITLE: Ranking strings by relatedness\nDESCRIPTION: This function ranks strings in a DataFrame based on their relatedness to a given query using cosine similarity between embeddings.  It takes a query string, a DataFrame containing text and embeddings, a relatedness function (defaulting to cosine similarity), and the number of top strings to return.  It returns a tuple containing a list of strings and a list of relation scores, sorted from most to least related.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef strings_ranked_by_relation(\n    query: str, db: pd.DataFrame, relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y), top_n: int = 100\n) -> tuple[list[str], list[float]]:\n    \"\"\"Return a list of strings and relation, sorted from most related to least.\"\"\"\n    query_embedding_response = openai.Embedding.create(model=EMBEDDING_MODEL, input=query)\n    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n\n    strings_and_relation = [\n        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"])) for i, row in db.iterrows()\n    ]\n    strings_and_relation.sort(key=lambda x: x[1], reverse=True)\n    strings, relation = zip(*strings_and_relation)\n    return strings[:top_n], relation[:top_n]\n```\n\n----------------------------------------\n\nTITLE: Wrapping raw dataset with Giskard Dataset class\nDESCRIPTION: This snippet wraps the raw test data in Giskard's Dataset class, including specifying the target column and categorical features. This facilitates vulnerability scans and testing within Giskard's framework.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_test, Y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,  # Contains raw data before preprocessing\n    target=TARGET_COLUMN_NAME,  # Ground truth variable\n    name=\"Churn classification dataset\",\n    cat_columns=COLUMNS_TO_ENCODE,\n)\n```\n\n----------------------------------------\n\nTITLE: Running a Giskard Test Suite with a Different Model in Python\nDESCRIPTION: Shows how to run an existing test suite with a different ML model. This allows comparing model behaviors across multiple implementations using the same test criteria.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_nlp/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# wrap a different model\ngiskard_model_2 = giskard.Model(...)\n\n# run the test suite with the new model\ntest_suite.run(model=giskard_model_2)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Test Data with Giskard Dataset Object\nDESCRIPTION: Prepares the test dataset for Giskard analysis. It first concatenates the test features (`X_test`) and test labels (`Y_test`) into a single DataFrame `raw_data`. Then, it wraps this `raw_data` using the `giskard.Dataset` class, specifying the DataFrame, the target column name (`TARGET_COLUMN_NAME`), an optional name for the dataset, and the list of categorical columns (`COLUMNS_TO_ENCODE`). This structure is required for Giskard's scan and testing functions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_test, Y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN_NAME,  # Ground truth variable.\n    name=\"German credit scoring dataset\",  # Optional.\n    cat_columns=COLUMNS_TO_ENCODE,\n    # List of categorical columns. Optional, but is a MUST if available. Inferred automatically if not.\n)\n```\n\n----------------------------------------\n\nTITLE: Loading a QA Testset in Python with Giskard RAG\nDESCRIPTION: Demonstrates how to load a previously saved Question-Answering testset from a JSONL file using Giskard's RAG framework.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag import QATestset\n\nloaded_testset = QATestset.load(\"my_testset.jsonl\")\n```\n\n----------------------------------------\n\nTITLE: Adding and Running Custom Tests\nDESCRIPTION: This snippet adds a custom test to the generated test suite. It uses `testing.test_f1`, which checks if the F1 score of the model on the dataset is above a specified threshold (0.7 in this case). The test suite is then run, including the added test. This enables the addition of custom test cases to evaluate the model's performance. The purpose is to evaluate the quality of a classification model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Adding a Custom Metric to Giskard Scan in Python\nDESCRIPTION: This snippet illustrates how to instantiate a custom metric (like FrequencyWeightedAccuracy) and use it in a Giskard scan by including it in the detector's 'metrics' parameter. Requires the previously defined custom metric class, the Giskard library, a model, and a dataset. The scan will compute custom and built-in metrics as specified. Input: dictionary with metric names and custom metric instances; output: scan report including custom metric results.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\n\nfrequency_weighted_accuracy = FrequencyWeightedAccuracy()\n\nparams = {\n    \"performance_bias\": {\"metrics\": [\"accuracy\", frequency_weighted_accuracy]}\n}\nreport = gsk.scan(my_model, my_dataset, params=params)\n```\n\n----------------------------------------\n\nTITLE: Generating and Running a Test Suite in Giskard with Python\nDESCRIPTION: Creates a test suite from scan results and runs it locally to verify issues. This demonstrates the basic workflow of converting scan findings into executable tests for CI/CD integration.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_nlp/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = scan_results.generate_test_suite(\"My first test suite\")\n\n# You can run the test suite locally to verify that it reproduces the issues\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard Dataset Class - Python\nDESCRIPTION: Combines test features and labels into a DataFrame and wraps it using Giskard's Dataset class. This enables subsequent Giskard vulnerability scans and test suite creation. Inputs: pandas DataFrame containing raw data and target. Output: Giskard Dataset object. Relies on giskard.Dataset being available.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_test, y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_NAME,  # Ground truth variable.\n    name=\"reviews\",  # Optional.\n)\n\n```\n\n----------------------------------------\n\nTITLE: Defining Preprocessing Pipeline\nDESCRIPTION: This snippet defines a preprocessing pipeline using scikit-learn's `ColumnTransformer`. The pipeline applies `StandardScaler` to numerical features and `OneHotEncoder` to categorical features. The `handle_unknown=\"ignore\"` parameter in `OneHotEncoder` prevents errors if the model encounters unseen categories during testing. This is a critical step to preparing the data before model training.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), NUMERICAL_FEATURES),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), CATEGORICAL_FEATURES),\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning Model Vulnerabilities with Giskard (Python)\nDESCRIPTION: Executes Giskard's `scan` function on the wrapped Giskard model (`giskard_model`). This automatically tests the model for various vulnerabilities like hallucination, prompt injection, etc., and returns a report object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model)\n```\n\n----------------------------------------\n\nTITLE: Defining Scikit-learn Preprocessing Pipeline\nDESCRIPTION: Constructs a scikit-learn `ColumnTransformer` to handle preprocessing of different feature types. Numeric features (`COLUMNS_TO_SCALE`) undergo median imputation (`SimpleImputer`) followed by standardization (`StandardScaler`). Categorical features (`COLUMNS_TO_ENCODE`) are imputed with the constant value 'missing' and then converted using `OneHotEncoder`. This `preprocessor` object can be integrated into a larger model pipeline.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nnumeric_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n\ncategorical_transformer = Pipeline(\n    [\n        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n    ]\n)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, COLUMNS_TO_SCALE),\n        (\"cat\", categorical_transformer, COLUMNS_TO_ENCODE),\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite from Scan Results - Python\nDESCRIPTION: This code generates a test suite from the scan results. The test suite integrates all detected vulnerabilities. The `generate_test_suite` method creates a test suite object. Then it runs the test suite.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"Test suite generated by scan\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Accessing RAG Evaluation Results Programmatically in Python\nDESCRIPTION: Demonstrates methods to access specific aggregated results and failures from the `RAGReport` object: correctness by topic (`report.correctness_by_topic()`), correctness by question type (`report.correctness_by_question_type()`), all failures (`report.failures`), and filtered failures using `report.get_failures()`. Assumes a `RAGReport` object named `report` exists.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Correctness on each topic of the Knowledge Base\nreport.correctness_by_topic()\n\n# Correctness on each type of question\nreport.correctness_by_question_type()\n\n# get all the failed questions\nreport.failures\n\n# get the failed questions filtered by topic and question type\nreport.get_failures(topic=\"Topic from your knowledge base\", question_type=\"simple\")\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries (Python)\nDESCRIPTION: Imports necessary modules for the project, including 'os' for environment variables, 'openai' client, 'pandas' for data handling, Langchain components ('RetrievalQA', 'OnlinePDFLoader', 'RecursiveCharacterTextSplitter', 'FAISS', 'OpenAI', 'OpenAIEmbeddings'), and Giskard components ('Model', 'scan').\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport openai\nimport pandas as pd\nfrom langchain.chains import RetrievalQA\nfrom langchain.document_loaders import OnlinePDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain_openai import OpenAI, OpenAIEmbeddings\n\nfrom giskard import Model, scan\n```\n\n----------------------------------------\n\nTITLE: Implementing Giskard Metric LLM Call - Python\nDESCRIPTION: Provides the implementation for the custom metric's `__call__` method. It retrieves an LLM client, formats input messages using prompts (SYSTEM_PROMPT, INPUT_TEMPLATE) and data from `question_sample` and `answer`, calls the LLM, and parses the expected JSON output using `parse_json_output`. Requires several Giskard and LlamaIndex imports.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag.metrics.base import Metric\nfrom giskard.rag import AgentAnswer\nfrom giskard.rag.question_generators.utils import parse_json_output\nfrom giskard.rag.metrics.correctness import format_conversation\nfrom giskard.llm.client import get_default_client\n\nfrom llama_index.core.base.llms.types import ChatMessage\n\nclass CorrectnessScoreMetric(Metric):\n    \n    def __call__(self, question_sample: dict, answer: AgentAnswer) -> dict:\n\n        # Retrieve the llm client\n        llm_client = self._llm_client or get_default_client()\n\n        # Call the llm\n        out = llm_client.complete(\n            messages=[\n                ChatMessage(\n                    role=\"system\",\n                    content=SYSTEM_PROMPT,\n                ),\n                ChatMessage(\n                    role=\"user\",\n                    content=INPUT_TEMPLATE.format(\n                        conversation=format_conversation(\n                            question_sample.conversation_history\n                            + [{\"role\": \"user\", \"content\": question_sample.question}]\n                        ),\n                        answer=answer.message,\n                        reference_answer=question_sample.reference_answer,\n                    ),\n                ),\n            ],\n            temperature=0,\n            format=\"json_object\",\n        )\n\n        # Parse the output string representation of a JSON object into a dictionary\n        json_output = parse_json_output(\n            out.content,\n            llm_client=llm_client,\n            keys=[\"correctness_score\"],\n            caller_id=self.__class__.__name__,\n        )\n\n        return json_output\n```\n\n----------------------------------------\n\nTITLE: Querying Prediction for a Specific Record using Copilot (Python)\nDESCRIPTION: Asks the Copilot, via the 'talk' method, whether a specific individual survived the Titanic incident using natural language. The Copilot automatically identifies the relevant record and returns the prediction outcome. Input: user question string referencing a dataset entry; Output: English answer string with prediction.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model.talk(question=\"Have 'Minahan miss Daisy E' survived in the Titanic incident?\", dataset=giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Counting tokens in a string\nDESCRIPTION: This function calculates the number of tokens in a given string using the `tiktoken` library. It takes the text and the LLM model as input and returns the token count.  It encodes the text using the specified model's encoding and returns the length of the encoded sequence.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef num_tokens(text: str, model: str = LLM_MODEL) -> int:\n    \"\"\"Return the number of tokens in a string.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    return len(encoding.encode(text))\n```\n\n----------------------------------------\n\nTITLE: Using Custom Giskard Metric in Evaluation - Python\nDESCRIPTION: Demonstrates how to use the previously defined `CorrectnessScoreMetric` by instantiating it and passing it as part of a list to the Giskard `evaluate` function. It highlights that the `name` argument of the metric should match the key returned in the metric's output dictionary. Requires the custom `CorrectnessScoreMetric` class and the Giskard `evaluate` function.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Instantiate the custom correctness metric\ncorrectness_score = CorrectnessScoreMetric(name=\"correctness_score\")\n\n# Run the evaluation with the custom metric\nreport = evaluate(\n    answer_fn,\n    testset=testset, # a QATestset instance\n    knowledge_base=knowledge_base, # the knowledge base used for building the QATestset \n    metrics=[correctness_score]\n)\n```\n\n----------------------------------------\n\nTITLE: Subclassing Giskard Metric Base Class - Python\nDESCRIPTION: Demonstrates the initial step of creating a custom RAG evaluation metric in Giskard by subclassing the `Metric` base class. It shows the required signature for the `__call__` method which will contain the metric's logic. Requires `giskard.rag.metrics.base.Metric` and `giskard.rag.AgentAnswer`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag.metrics.base import Metric\nfrom giskard.rag import AgentAnswer\n\nclass CorrectnessScoreMetric(Metric):\n    def __call__(self, question_sample: dict, answer: AgentAnswer) -> dict:\n        pass\n```\n\n----------------------------------------\n\nTITLE: Customizing Test Suites with Catalog Tests in Giskard using Python\nDESCRIPTION: This snippet demonstrates adding a unit test from the Giskard catalog ('test_f1') to an existing test suite and executing it. The 'test_f1' test checks if a model’s F1 score exceeds a specified threshold on the provided dataset. Dependencies include properly instantiated 'giskard_model', 'giskard_dataset', and an existing 'test_suite'. Inputs required: model, dataset, and threshold. Output is the suite’s run results after augmenting with the catalog test.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard Model\nDESCRIPTION: Wraps the trained PyTorch model using Giskard's Model class, defining the prediction function and the model type, and specifying the labels and feature names. The prediction function takes a DataFrame as input, preprocesses the data, and returns the model's predictions. This prepares the model to be analyzed by Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef infer_predictions(_model: torch.nn.Module, _dataloader: DataLoader) -> np.ndarray:\n    _model.eval()\n    pred = list()\n\n    for _, text, offsets in _dataloader:\n        with torch.no_grad():\n            probs = model(text, offsets).cpu().detach().numpy()\n\n        pred.append(probs)\n\n    pred = np.concatenate(pred, axis=0)\n    return pred\n\n\ndef prediction_function(df) -> np.ndarray:\n    # Placeholder for label.\n    if df.shape[1] == 1:\n        df.insert(0, TARGET_COLUMN_NAME, np.zeros(len(df)))\n\n    data_iterator = df.itertuples(index=False)\n    dataloader = DataLoader(to_map_style_dataset(data_iterator), batch_size=LOADERS_BATCH_SIZE, collate_fn=collate_fn)\n    predictions = infer_predictions(model, dataloader)\n    predictions = predictions\n\n    return predictions\n\n\ngiskard_model = Model(\n    model=prediction_function,  # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"Simple News Classification Model\",  # Optional.\n    classification_labels=list(\n        TARGET_MAP.values()\n    ),  # Their order MUST be identical to the prediction_function's output order.\n    feature_names=[\"text\"],  # Default: all columns of your dataset.\n)\n\n# Validate wrapped model.\nwrapped_test_metric = accuracy_score(\n    giskard_dataset.df[TARGET_COLUMN_NAME], giskard_model.predict(giskard_dataset).prediction\n)\nprint(f\"Wrapped Test accuracy: {wrapped_test_metric:.3f}\")\n```\n\n----------------------------------------\n\nTITLE: Example Output: Explanation from Contextual Talk (Markdown)\nDESCRIPTION: This Markdown snippet shows the detailed explanation provided by the Giskard model agent when using dialogue mode. The model agent uses the context from the previous `talk` call (specifically, the identity of 'Webber, Miss. Susan' and the survival status) to explain the factors influencing the survival prediction based on SHAP values and other dataset features. This demonstrates the utility of preserving conversation history.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\nThe model predicted that 'Webber, Miss. Susan' survived the Titanic incident primarily due to her sex being female, which had the highest SHAP value, indicating it was the most influential factor in the prediction. Other contributing factors include her traveling in 2nd class (Pclass) and her name, which might have been considered due to encoding specific information relevant to survival. Age and fare paid for the ticket also played minor roles in the prediction. However, the number of siblings/spouses aboard (SibSp), the number of parents/children aboard (Parch), and the port of embarkation (Embarked) did not significantly influence the prediction.\n```\n\n----------------------------------------\n\nTITLE: Automatically Generating Slicing Functions with Giskard Scan in Python\nDESCRIPTION: Shows how to use Giskard's scan feature to automatically generate insightful slicing functions for a model and dataset. The scan results can be used to create and run a test suite with the generated functions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_slices/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard import Dataset, Model, scan\n\n\nmy_dataset = Dataset(...)\nmy_model = Model(...)\n\nscan_result = scan(my_model, my_dataset)\ntest_suite = scan_result.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Building and training the LightGBM classifier pipeline\nDESCRIPTION: This snippet constructs a scikit-learn pipeline combining the preprocessing steps and the LightGBM classifier. It trains the model on training data and evaluates accuracy on both training and test sets.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\npipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", LGBMClassifier(random_state=RANDOM_SEED))])\n\n# Fit model.\npipeline.fit(X_train, Y_train)\n\n# Evaluate model.\nY_train_pred = pipeline.predict(X_train)\ntrain_accuracy = accuracy_score(Y_train, Y_train_pred)\n\nY_test_pred = pipeline.predict(X_test)\ntest_accuracy = accuracy_score(Y_test, Y_test_pred)\n\nprint(f\"Train Accuracy: {train_accuracy:.2f}\")\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Generating a message for the LLM\nDESCRIPTION: This function generates a message for the LLM by combining the prompt template, relevant articles retrieved from a DataFrame, and the user's question.  It retrieves relevant strings using `strings_ranked_by_relation`, adds them to the message until the token budget is reached, and then appends the user's question.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef query_message(query: str, db: pd.DataFrame, model: str, token_budget: int) -> str:\n    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n    message = PROMPT_TEMPLATE\n    question = f\"\\n\\nQuestion: {query}\"\n\n    strings, _ = strings_ranked_by_relation(query, db)\n\n    for string in strings:\n        next_article = f'\\n\\nWikipedia article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n        if num_tokens(message + next_article + question, model=model) > token_budget:\n            break\n        else:\n            message += next_article\n\n    return message + question\n```\n\n----------------------------------------\n\nTITLE: Splitting Dataset into Training and Testing Sets in Python\nDESCRIPTION: Uses scikit-learn's train_test_split to separate features and labels for model validation. The split uses a random seed for reproducibility. The input DataFrame must have title and text columns present.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nX_train, X_test, Y_train, Y_test = train_test_split(\n    news_df[[\"title\", TEXT_COLUMN_NAME]], news_df[TARGET_COLUMN_NAME], random_state=RANDOM_SEED\n)\n\n```\n\n----------------------------------------\n\nTITLE: Preparing DataLoaders\nDESCRIPTION: Prepares data loaders for training, validation, and testing. It includes tokenizing the text, building a vocabulary, preprocessing text and labels, and defining a collate function to handle batching and padding. The use of data loaders streamlines the data loading and preprocessing steps for the PyTorch model. Includes splitting of training data into training and validation sets.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simple English tokenizer provided by torchtext.\ntokenizer = get_tokenizer(\"basic_english\")\n\n# Build a vocabulary from all the tokens we can find in the train data.\nvocab = build_vocab_from_iterator((tokenizer(text) for _, text in train_data), specials=[\"<unk>\"])\nvocab.set_default_index(vocab[\"<unk>\"])\n\n\ndef preprocess_text(raw_text):\n    return vocab(tokenizer(raw_text))\n\n\ndef preprocess_label(raw_label):\n    return int(raw_label) - 1\n\n\ndef collate_fn(batch):\n    label_list, text_list, offsets = [], [], [0]\n\n    for _label, _text in batch:\n        label_list.append(preprocess_label(_label))\n        processed_text = torch.tensor(preprocess_text(_text), dtype=torch.int64)\n        text_list.append(processed_text)\n        offsets.append(processed_text.size(0))\n\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    text_list = torch.cat(text_list)\n\n    return label_list.to(DEVICE), text_list.to(DEVICE), offsets.to(DEVICE)\n\n\n# Create the datasets\ntrain_dataset = to_map_style_dataset(train_data)\ntest_dataset = to_map_style_dataset(test_data)\n\n# We further divide the training data into a train and validation split.\ntrain_split, valid_split = random_split(train_dataset, [0.95, 0.05])\n\n# Prepare the data loaders\ntrain_dataloader = DataLoader(train_split, batch_size=LOADERS_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\nvalid_dataloader = DataLoader(valid_split, batch_size=LOADERS_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\ntest_dataloader = DataLoader(test_dataset, batch_size=LOADERS_BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n```\n\n----------------------------------------\n\nTITLE: Validating the Wrapped Model\nDESCRIPTION: Validates the wrapped model by calling its predict method with the giskard dataset, printing the predictions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Validate the wrapped model and dataset.\nprint(giskard_model.predict(giskard_dataset).prediction)\n```\n\n----------------------------------------\n\nTITLE: Initializing NeMo Guardrails App (RailsConfig, LLMRails)\nDESCRIPTION: Initializes the NeMo Guardrails application by loading the configuration from the 'config' directory and creating an instance of `LLMRails`. This sets up the application with the defined rails and models, ready for processing user inputs.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom nemoguardrails import RailsConfig, LLMRails\n\n\nconfig = RailsConfig.from_path(\"config\")\napp = LLMRails(config)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard in Python\nDESCRIPTION: Creates a Giskard Dataset object using raw test feature and label data. This facilitates vulnerability scanning and test automation in Giskard. Input expects a combined DataFrame and a correct target column name.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_test, Y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN_NAME,  # Ground truth variable.\n    name=\"fake_and_real_news\",  # Optional.\n)\n\n```\n\n----------------------------------------\n\nTITLE: Custom LLM Client Implementation\nDESCRIPTION: Defines a custom LLM class inheriting from litellm's CustomLLM to implement the completion method via HTTP POST. Sets an environment variable for API key, then registers the custom handler in giskard before setting the model with the custom provider name.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nimport requests\nfrom typing import Optional\n\nimport litellm\nimport giskard\n\n\nclass MyCustomLLM(litellm.CustomLLM):\n    def completion(self, messages: str, api_key: Optional[str] = None, **kwargs) -> litellm.ModelResponse:\n        api_key = api_key or os.environ.get(\"MY_SECRET_KEY\")\n        if api_key is None:\n            raise litellm.AuthenticationError(\"`api_key` was not provided\")\n\n        response = requests.post(\n            \"https://www.my-custom-llm.ai/chat/completion\",\n            json={\"messages\": messages},\n            headers={\"Authorization\": api_key},\n        )\n\n        return litellm.ModelResponse(**response.json())\n\nos.environ[\"MY_SECRET_KEY\"] = \"\" # \"my-secret-key\"\n\nmy_custom_llm = MyCustomLLM()\n\nlitellm.custom_provider_map = [  # 👈 KEY STEP - REGISTER HANDLER\n    {\"provider\": \"my-custom-llm-endpoint\", \"custom_handler\": my_custom_llm}\n]\n\napi_key = os.environ[\"MY_SECRET_KEY\"]\n\ngiskard.llm.set_llm_model(\"my-custom-llm-endpoint/my-custom-model\", api_key=api_key)\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating the Model - Python\nDESCRIPTION: Executes the training loop for the configured HuggingFace `Trainer` using the specified training dataset and arguments. After training, it performs an evaluation pass on the validation dataset, reporting the metrics defined in `compute_metrics`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\ntrainer.train()\ntrainer.evaluate()\n```\n\n----------------------------------------\n\nTITLE: Running Giskard Scan and Logging Results to W&B for Multiple Models in Python\nDESCRIPTION: Performs automated scanning of the wrapped Giskard models against the test dataset for each foundational model key. For each model, it initiates a W&B run, generates a scan report capturing issues and evaluation metrics, logs both the report and a generated test suite to W&B, and then completes the W&B run. This enables traceability and visualization of model evaluation results and prompt traces within W&B projects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfor model in models.keys():\n    # Initiate a new run with the foundational model name inside the W&B project\n    run = wandb.init(project=os.environ[\"WANDB_PROJECT\"], name=model)\n\n    # Scan report\n    # 1) Generate\n    models[model]['scan_report'] = giskard.scan(models[model]['giskard'], dataset, raise_exceptions=True)\n    # 2) Log into W&B\n    models[model]['scan_report'].to_wandb(run)\n\n    # Test suite\n    # 1) Generate\n    models[model]['test_suite'] = models[model]['scan_report'].generate_test_suite()\n    # 2) Log into W&B\n    models[model]['test_suite'].run().to_wandb(run)\n\n    # End W&B run\n    run.finish()\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard Scan Results - Python\nDESCRIPTION: Displays the results of the Giskard scan, providing a report of detected vulnerabilities and issues. This is typically used in interactive environments like Jupyter notebooks to visualize the scan findings.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Performance Metric for Giskard in Python\nDESCRIPTION: This snippet shows how to define a custom performance metric by subclassing 'giskard.scanner.performance.metrics.PerformanceMetric' and implementing its '__call__' method. The method should return a 'MetricResult' object. Requires the Giskard library and its performance.metrics module. The process allows custom logic for measuring model performance; inputs include the model and dataset, and output is a metric result instance.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.scanner.performance.metrics import PerformanceMetric, MetricResult\n\nclass MyCustomMetric(PerformanceMetric):\n    def __call__(self, model, dataset):\n        # your custom logic here\n        return MetricResult(\n            name=\"my_custom_metric\",\n            value=0.42,\n            affected_counts=100,\n            binary_counts=[25, 75],\n        )\n```\n\n----------------------------------------\n\nTITLE: Scanning facial landmark detection model for vulnerabilities\nDESCRIPTION: Runs Giskard's automated scanning process on the model to detect vulnerabilities such as performance biases, robustness issues, and ethical concerns.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_landmark_detection.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(model, dataloader)\n```\n\n----------------------------------------\n\nTITLE: Running Giskard Tests with Pytest Command\nDESCRIPTION: Shows how to use the pytest command to execute Giskard tests defined in a Python script, displaying the output with test results including failures and logs.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/pytest/index.md#_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n$ pytest test_ml_model.py\n\n===================================== test session starts ======================================\nplatform darwin -- Python 3.11.5, pytest-7.4.3, pluggy-1.3.0\nrootdir: [REDACTED]\nconfigfile: pyproject.toml\nplugins: reportlog-0.4.0, env-1.1.3, Faker-20.1.0, cov-4.1.0, asyncio-0.21.1, memray-1.5.0, anyio-3.7.1, requests-mock-1.11.0, xdist-3.5.0\nasyncio: mode=Mode.STRICT\ncollected 5 items                                                                              \n\ntest_ml_model.py .FF                                                                   [100%]\n\n=========================================== FAILURES ===========================================\n_______ test_giskard[Accuracy(model=Classifier v1, dataset=Test Data Set, threshold=1)] ________\ntest_ml_model.py:31: in test_giskard\n    test_partial.assert_()\ngiskard/registry/giskard_test.py:117: in assert_\n    assert result.passed, message\nE   AssertionError: Test failed Metric: 0.79\nE   assert False\nE    +  where False = \\n               Test failed\\n               Metric: 0.79\\n               \\n               .passed\n------------------------------------- Captured stdout call -------------------------------------\n2024-01-10 22:43:35,902 pid:33777 MainThread giskard.datasets.base INFO     Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\n2024-01-10 22:43:35,904 pid:33777 MainThread giskard.datasets.base INFO     Casting dataframe columns from {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'} to {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'}\n2024-01-10 22:43:35,906 pid:33777 MainThread giskard.utils.logging INFO     Predicted dataset with shape (446, 10) executed in 0:00:00.025473\n2024-01-10 22:43:35,916 pid:33777 MainThread giskard.datasets.base INFO     Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\n-------------------------------------- Captured log call ---------------------------------------\nINFO     giskard.datasets.base:__init__.py:233 Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\nINFO     giskard.datasets.base:__init__.py:550 Casting dataframe columns from {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'} to {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'}\nINFO     giskard.utils.logging:logging.py:50 Predicted dataset with shape (446, 10) executed in 0:00:00.025473\nINFO     giskard.datasets.base:__init__.py:233 Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\n______________________________________ test_only_accuracy ______________________________________\ntest_ml_model.py:45: in test_only_accuracy\n    test_accuracy(model=model, dataset=dataset, threshold=1).assert_()\ngiskard/registry/giskard_test.py:117: in assert_\n    assert result.passed, message\nE   AssertionError: Test failed Metric: 0.79\nE   assert False\nE    +  where False = \\n               Test failed\\n               Metric: 0.79\\n               \\n               .passed\n------------------------------------- Captured stdout call -------------------------------------\n2024-01-10 22:43:36,238 pid:33777 MainThread giskard.datasets.base INFO     Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\n2024-01-10 22:43:36,240 pid:33777 MainThread giskard.datasets.base INFO     Casting dataframe columns from {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'} to {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'}\n2024-01-10 22:43:36,243 pid:33777 MainThread giskard.utils.logging INFO     Predicted dataset with shape (446, 10) executed in 0:00:00.017629\n2024-01-10 22:43:36,250 pid:33777 MainThread giskard.datasets.base INFO     Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\n-------------------------------------- Captured log call ---------------------------------------\nINFO     giskard.datasets.base:__init__.py:233 Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\nINFO     giskard.datasets.base:__init__.py:550 Casting dataframe columns from {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'} to {'PassengerId': 'int64', 'Pclass': 'int64', 'Name': 'object', 'Sex': 'object', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'Embarked': 'object'}\nINFO     giskard.utils.logging:logging.py:50 Predicted dataset with shape (446, 10) executed in 0:00:00.017629\nINFO     giskard.datasets.base:__init__.py:233 Your 'pandas.DataFrame' is successfully wrapped by Giskard's 'Dataset' wrapper class.\n=================================== short test summary info ====================================\nFAILED test_ml_model.py::test_giskard[Accuracy(model=Classifier v1, dataset=Test Data Set, threshold=1)] - AssertionError: Test failed Metric: 0.79\nFAILED test_ml_model.py::test_only_accuracy - AssertionError: Test failed Metric: 0.79\n================================= 2 failed, 1 passed in 11.50s =================================\n```\n\n----------------------------------------\n\nTITLE: Defining constants for the RAG pipeline\nDESCRIPTION: This snippet defines several constants used throughout the notebook, including the URL for the articles and embeddings, the embedding model, the LLM model, the name of the text column, and the prompt template used to guide the LLM's responses.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nARTICLES_EMBEDDINGS_URL = \"https://cdn.openai.com/API/examples/data/winter_olympics_2022.csv\"\n\nEMBEDDING_MODEL = \"text-embedding-3-small\"\nLLM_MODEL = \"gpt-3.5-turbo\"\n\nTEXT_COLUMN_NAME = \"text\"\n\nPROMPT_TEMPLATE = 'Use the below articles on the 2022 Winter Olympics to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard\nDESCRIPTION: Prepares the dataset for vulnerability scanning by wrapping it with Giskard's `Dataset` class.  It creates a Pandas DataFrame using the first 5 questions and passes it into the `Dataset` constructor, the target is set to None.  This step is crucial for the model to be usable with Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.DataFrame({TEXT_COLUMN_NAME: questions[:5]})\ngiskard_dataset = Dataset(raw_data, target=None)\n```\n\n----------------------------------------\n\nTITLE: Importing Giskard vision libraries\nDESCRIPTION: Imports the necessary modules from Giskard Vision for landmark detection models, demo dataset loading, and the scanning functionality.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_landmark_detection.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard_vision.landmark_detection.models.wrappers import OpenCVWrapper\nfrom giskard_vision.landmark_detection.demo import get_ffhq\n\nfrom giskard_vision.core.scanner import scan\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset for Object Detection\nDESCRIPTION: This Python code demonstrates how to wrap a dataset for object detection using the `DataIteratorBase` class. It requires overriding `idx_sampler`, `get_image`, `get_label`, and optionally `get_meta`. The `get_label` method should return a dict with boxes and labels. The input is a dataset of images and bounding box annotations. The output is a wrapped dataset object. The function `cv2.imread()` is used for reading the images, which requires OpenCV.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_vision/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard_vision.core.dataloaders.base import DataIteratorBase\nfrom giskard_vision.core.dataloaders.meta import MetaData\nfrom giskard_vision.core.issues import EthicalIssueMeta, PerformanceIssueMeta\n\n\nclass DataLoaderObjectDetection(DataIteratorBase):\n\n    @property\n    def idx_sampler(self) -> np.ndarray:\n        return list(range(len(self.image_paths))\n\n    @classmethod\n    def get_image(self, idx: int) -> np.ndarray:\n        return cv2.imread(str(self.image_paths[idx]))\n\n    @classmethod\n    def get_label(self, idx: int) -> Optional[np.ndarray]:\n        return {\"boxes\": np.array(...), \"labels\": \"label1\"}\n    \n    @classmethod\n    def get_meta(self, idx: int) -> Optional[MetaData]:\n        default_meta = super().get_meta() # To load default metadata\n        return MetaData(\n            data={\n                **default_meta.data,\n                'meta1': 'value1',\n                'meta2': 'value2',\n                'categorical_meta1': 'cat_value1',\n                'categorical_meta2': 'cat_value2'\n            },\n            categories=default_meta.categories+['categorical_meta1', 'categorical_meta2'],\n            issue_groups={\n                **default_meta.issue_groups,\n                'meta1': PerformanceIssueMeta,\n                'meta2': EthicalIssueMeta,\n                'categorical_meta1': PerformanceIssueMeta,\n                'categorical_meta2': EthicalIssueMeta,\n            }\n        )\n\n\ngiskard_dataset = DataLoaderObjectDetection()\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results\nDESCRIPTION: This snippet displays the results of the Giskard scan in the notebook.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)  # in your notebook\n```\n\n----------------------------------------\n\nTITLE: Building and Training Model Pipeline\nDESCRIPTION: This snippet creates and trains a scikit-learn pipeline, combining preprocessing with a `RandomForestClassifier`. The pipeline first preprocesses the data using the defined `preprocessor`, then trains the `RandomForestClassifier` on the preprocessed training data (`X_train`, `y_train`). After training, it calculates and prints the accuracy scores on both the training and testing data, providing initial performance evaluation metrics.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier())])\n\npipeline.fit(X_train, y_train)\n\n# Accuracy score.\ntrain_metric = pipeline.score(X_train, y_train)\ntest_metric = pipeline.score(X_test, y_test)\n\nprint(f\"Train accuracy: {train_metric:.2f}\")\nprint(f\"Test accuracy: {test_metric:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Setting up Ollama LLM Client using completion parameters in Python\nDESCRIPTION: This snippet demonstrates configuring the Ollama LLM client by passing the API base URL and disabling structured output for the LLM model using giskard.llm methods. It sets an embedding model as well. This setup is useful for running Ollama locally or remotely with a specified API base. Requires giskard package and knowledge of the supported models. Inputs include API base URL and model names; outputs are the configured LLM and embedding client instances for Ollama.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\n\napi_base = \"http://localhost:11434\" # default api_base for local Ollama\n\n# See supported models here: https://docs.litellm.ai/docs/providers/ollama#ollama-models\ngiskard.llm.set_llm_model(\"ollama/qwen2.5\", disable_structured_output=True, api_base=api_base)\ngiskard.llm.set_embedding_model(\"ollama/nomic-embed-text\", api_base=api_base)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Test Data with Giskard Dataset\nDESCRIPTION: Wraps the test data within Giskard's Dataset class. This step is crucial for using Giskard's scanning capabilities and vulnerability detection, allowing Giskard to understand and interact with the dataset. The dataset is transformed into a pandas DataFrame and specifies the target column, label and feature column names.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.DataFrame(\n    {TARGET_COLUMN_NAME: TARGET_MAP[label_id - 1], FEATURE_COLUMN_NAME: text} for label_id, text in test_data\n)\ngiskard_dataset = Dataset(\n    df=raw_data,  # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable\n    name=\"Test Dataset\",  # Ground truth variable\n    target=TARGET_COLUMN_NAME,  # Optional\n)\n```\n\n----------------------------------------\n\nTITLE: Sphinx Automodule Directive for TensorFlowModel\nDESCRIPTION: This Sphinx directive automatically imports the specified Python module (`giskard.models.tensorflow`) and extracts documentation for its members, specifically the `TensorFlowModel` class. It's used to generate API documentation from the source code.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/models/integrations/tensorflow.rst#_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: giskard.models.tensorflow\n    :members: TensorFlowModel\n```\n\n----------------------------------------\n\nTITLE: Scanning RoBERTa Sentiment Model for Vulnerabilities with Giskard\nDESCRIPTION: Executes Giskard's scan function to automatically detect vulnerabilities in the sentiment analysis model, such as performance biases, unrobustness, data leakage, and ethical issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite from Scan Results\nDESCRIPTION: This snippet generates a test suite from the `results` object produced by the `scan` function.  The `generate_test_suite` method creates a suite that integrates all vulnerabilities detected during the scan. The name of the test suite is provided as an argument. This generated test suite can be used to evaluate the model's performance and validate it against predefined test cases.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Loading Hugging Face Model and Tokenizer\nDESCRIPTION: Loads the pre-trained `AutoTokenizer` and `AutoModelForSequenceClassification` from the Hugging Face `transformers` library using the specified `MODEL_NAME`. The tokenizer is needed to convert text into model-understandable input IDs and attention masks, while the model performs the sentiment classification.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for NeMo Guardrails and Giskard (pip)\nDESCRIPTION: Installs necessary Python packages including `nemoguardrails`, `giskard`, and `openai` using pip. This prepares the environment for running the NeMo Guardrails application and integrating it with Giskard for vulnerability scanning.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install nemoguardrails giskard openai\n```\n\n----------------------------------------\n\nTITLE: Requesting Model Accuracy via Copilot (Python)\nDESCRIPTION: Invokes the Copilot with a natural language request to calculate the model's accuracy on the provided dataset. The agent computes and returns the accuracy, drawing on built-in evaluation metrics. Input: accuracy query and dataset; Output: string with numerical metric. Requires model and dataset artifacts.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model.talk(question=\"Calculate accuracy of the model.\", dataset=giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI LLM Client using .env variables in Python\nDESCRIPTION: This snippet demonstrates how to configure the OpenAI LLM client for Giskard using environment variables in Python. It sets the OpenAI API key, optional organization, and API base URL via os.environ, then selects the LLM model and embedding model programmatically. This setup requires the giskard package and assumes a valid OpenAI API key. The expected input includes correct API credentials and model names. This method is useful for securely storing secrets in environment variables and configuring Giskard's LLM client to communicate with OpenAI's API.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"OPENAI_API_KEY\"] = \"\" # \"my-openai-api-key\"\n\n# Optional, setup a model (default LLM is gpt-4o, default embedding model is text-embedding-3-small)\ngiskard.llm.set_llm_model(\"gpt-4o\")\ngiskard.llm.set_embedding_model(\"text-embedding-3-small\")\n\n# Optional Keys - OpenAI Organization, OpenAI API Base\nos.environ[\"OPENAI_ORGANIZATION\"] = \"\" # \"my-openai-organization\"\nos.environ[\"OPENAI_API_BASE\"] = \"\" # \"https://api.openai.com\"\n```\n\n----------------------------------------\n\nTITLE: Scanning the Model for Vulnerabilities using Giskard\nDESCRIPTION: Executes Giskard's automated `scan` function. It takes the wrapped Giskard model (`giskard_model`) and Giskard dataset (`giskard_dataset`) as input. The function analyzes the model for various potential issues like performance bias, robustness, data leakage, etc., and returns the findings in a `results` object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Defining Constants and Prompt Templates for LLM Chaining - Python\nDESCRIPTION: Defines constants such as the LLM model name and the input text column name. Crucially, it defines two `ChatPromptTemplate` instances for Langchain: one for generating keywords from a product name, and a second one for generating a product description based on the product name and the keywords from the first prompt.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nLLM_MODEL = \"gpt-3.5-turbo\"\n\nTEXT_COLUMN_NAME = \"product_name\"\n\n# First prompt to generate keywords related to the product name\nKEYWORDS_PROMPT_TEMPLATE = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"\"\"You are a helpful assistant that generate a CSV list of keywords related to a product name\n\n    Example Format:\n    PRODUCT NAME: product name here\n    KEYWORDS: keywords separated by commas here\n\n    Generate five to ten keywords that would increase product visibility. Begin!\n\n    \"\"\",\n        ),\n        (\n            \"human\",\n            \"\"\"\n    PRODUCT NAME: {product_name}\n    KEYWORDS:\"\"\",\n        ),\n    ]\n)\n\n# Second chained prompt to generate a description based on the given keywords from the first prompt\nPRODUCT_PROMPT_TEMPLATE = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"\"\"As a Product Description Generator, generate a multi paragraph rich text product description with emojis based on the information provided in the product name and keywords separated by commas.\n\n    Example Format:\n    PRODUCT NAME: product name here\n    KEYWORDS: keywords separated by commas here\n    PRODUCT DESCRIPTION: product description here\n\n    Generate a product description that is creative and SEO compliant. Emojis should be added to make product description look appealing. Begin!\n\n    \"\"\",\n        ),\n        (\n            \"human\",\n            \"\"\"\n    PRODUCT NAME: {product_name}\n    KEYWORDS: {keywords}\n    PRODUCT DESCRIPTION:\n        \"\"\",\n        ),\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating the Model\nDESCRIPTION: Defines training and validation functions. The code includes the loss function (CrossEntropyLoss), the optimizer (SGD), and the learning rate scheduler. It iterates through epochs, trains the model, and evaluates the model's performance on the validation set. Also includes test set accuracy.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)\n\n\ndef train_epoch(dataloader):\n    model.train()\n\n    train_accuracy = total_count = 0\n    for label, text, offset in dataloader:\n        optimizer.zero_grad()\n        predicted_label = model(text, offset)\n        loss = criterion(predicted_label, label)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n        train_accuracy += (predicted_label.argmax(1) == label).sum().item()\n        total_count += label.size(0)\n\n    return train_accuracy / total_count\n\n\ndef validation_epoch(dataloader):\n    model.eval()\n\n    validation_accuracy = total_count = 0\n    with torch.no_grad():\n        for label, text, offsets in dataloader:\n            predicted_label = model(text, offsets)\n            validation_accuracy += (predicted_label.argmax(1) == label).sum().item()\n            total_count += label.size(0)\n\n    return validation_accuracy / total_count\n\n\ntotal_accuracy = None\nfor epoch in range(1, 3):\n    start_time = time.perf_counter()\n\n    train_epoch(train_dataloader)\n    accu_val = validation_epoch(valid_dataloader)\n\n    if total_accuracy is not None and total_accuracy > accu_val:\n        scheduler.step()\n    else:\n        total_accuracy = accu_val\n\n    print(\"-\" * 65)\n    print(\n        f\"| end of epoch {epoch: .3f} | time: {time.perf_counter() - start_time :5.2f}s | valid accuracy {accu_val:8.3f} \"\n    )\n    print(\"-\" * 65)\n\n\ntest_accuracy = validation_epoch(test_dataloader)\nprint(\"Test accuracy {:8.3f}\".format(test_accuracy))\n```\n\n----------------------------------------\n\nTITLE: Creating Train-Test Split for M5 Sales Time Series Data\nDESCRIPTION: Splits the dataset into training and validation sets based on a specific date, ensuring that the validation set contains 28 days of future data for each product, and drops unnecessary columns after splitting.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef drop_after_split(x: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Drops useless data after train-test split.\"\"\"\n    to_drop = [DATE_COLUMN, TARGET_COLUMN]\n    x = x.drop(columns=to_drop)\n    return x\n\n\ndef train_val_split(data: pd.DataFrame) -> Tuple[pd.DataFrame, ...]:\n    \"\"\"Perform train/val split, where the split point is the date '2016-03-27'. Validation records are 28 days for each product.\"\"\"\n    x_train = data[data[DATE_COLUMN] <= SPLIT_DATE]\n    y_train = x_train[TARGET_COLUMN]\n    x_train = drop_after_split(x_train)\n    print(f\"Train samples: {len(x_train)}\")\n\n    x_val = data[data[DATE_COLUMN] > SPLIT_DATE]\n    y_val = x_val[TARGET_COLUMN]\n    x_val = drop_after_split(x_val)\n    print(f\"Valid samples: {len(x_val)}\")\n\n    return x_train, y_train, x_val, y_val\n\n\nX_train, Y_train, X_val, Y_val = train_val_split(df)\n```\n\n----------------------------------------\n\nTITLE: Wrapping dataset with Giskard for vulnerability scanning\nDESCRIPTION: Creates a Giskard Dataset object from the preprocessed Tripadvisor reviews data, preparing it for vulnerability scanning.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ngiskard_dataset = Dataset(\n    df=load_dataset(),\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN_NAME,  # Ground truth variable.\n    name=\"Trip advisor reviews sentiment\",  # Optional.\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring AWS Bedrock LLM Client with Giskard in Python\nDESCRIPTION: This snippet configures environment variables for AWS credentials and AWS region, then sets the Bedrock-specific LLM and embedding models to be used with Giskard. The generation model disables structured output to align with Bedrock's expected interaction.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"AWS_ACCESS_KEY_ID\"] = \"\" # \"my-aws-access-key\"\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\" # \"my-aws-secret-access-key\"\nos.environ[\"AWS_REGION_NAME\"] = \"\" # \"us-west-2\"\n\ngiskard.llm.set_llm_model(\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\", disable_structured_output=True)\ngiskard.llm.set_embedding_model(\"bedrock/amazon.titan-embed-image-v1\")\n```\n\n----------------------------------------\n\nTITLE: Defining LLM Generation Function for Giskard - Python\nDESCRIPTION: Creates a Python function `generation_function` that accepts a Pandas DataFrame as input and returns a list of generated product descriptions. Internally, it uses Langchain Expression Language (LCEL) to chain the two defined prompts with an OpenAI model (`ChatOpenAI`) and a string output parser, creating a sequential pipeline that takes product names and outputs descriptions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef generation_function(df: pd.DataFrame):\n    llm = ChatOpenAI(temperature=0.2, model=LLM_MODEL)\n\n    # Define the chains.\n    keywords_chain = KEYWORDS_PROMPT_TEMPLATE | llm | StrOutputParser()\n    product_description_chain = (\n        {\"keywords\": keywords_chain, \"product_name\": itemgetter(\"product_name\")}\n        | PRODUCT_PROMPT_TEMPLATE\n        | llm\n        | StrOutputParser()\n    )\n\n    return [product_description_chain.invoke({\"product_name\": product_name}) for product_name in df[\"product_name\"]]\n```\n\n----------------------------------------\n\nTITLE: Setting up Mistral LLM Client using .env variables in Python\nDESCRIPTION: This snippet configures the Mistral LLM client for Giskard by setting an API key as an environment variable and specifying the Mistral LLM and embedding model names programmatically. The setup requires the giskard package and a valid API key for Mistral. Inputs must include proper API credentials and model identifiers. The output is a configured client ready to interact with Mistral's language models.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"MISTRAL_API_KEY\"] = \"\" # \"my-mistral-api-key\"\n\ngiskard.llm.set_llm_model(\"mistral/mistral-large-latest\")\ngiskard.llm.set_embedding_model(\"mistral/mistral-embed\")\n```\n\n----------------------------------------\n\nTITLE: Importing Catalog Transformation Function in Giskard Python\nDESCRIPTION: This snippet shows how to import a pre-defined transformation function, specifically `keyboard_typo_transformation`, from the Giskard catalog. These functions are ready-to-use components for applying common data transformations, such as introducing keyboard-related typos in text data, to your datasets within Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_transformations/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import keyboard typo transformations\nfrom giskard.functions.transformation import keyboard_typo_transformation\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama LLM Client with Giskard in Python\nDESCRIPTION: This snippet shows how to connect Giskard with a locally hosted Ollama LLM server by setting the API base URL and choosing Ollama models for language generation and embeddings. It disables structured output for the generation model as specified.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\n\napi_base = \"http://localhost:11434\" # default api_base for local Ollama\n\ngiskard.llm.set_llm_model(\"ollama/qwen2.5\", disable_structured_output=True, api_base=api_base)\ngiskard.llm.set_embedding_model(\"ollama/nomic-embed-text\", api_base=api_base)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries\nDESCRIPTION: Imports the necessary libraries for the project, including os, openai, pandas, langchain modules for chains, OpenAI embeddings, and prompts, text splitting, FAISS for vector stores, and giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport openai\nimport pandas as pd\nfrom langchain.chains import RetrievalQA\nfrom langchain_openai import OpenAIEmbeddings, OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\n\nfrom giskard import Model, Dataset, scan\n```\n\n----------------------------------------\n\nTITLE: Setting Notebook-Level Logging and Warning Filters in Python\nDESCRIPTION: Configures the logging verbosity level to ERROR to minimize output clutter and suppresses specific FutureWarning messages to maintain a clean notebook interface during execution.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlogging.set_verbosity(logging.ERROR)\nwarnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)\n```\n\n----------------------------------------\n\nTITLE: Mistral LLM Client Configuration\nDESCRIPTION: Sets environment variables and defines the LLM and embedding models for Mistral in giskard. Dependencies include os and giskard. Enables connection to Mistral API for vulnerability assessments of domain-specific models.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"MISTRAL_API_KEY\"] = \"\" # \"my-mistral-api-key\"\n\ngiskard.llm.set_llm_model(\"mistral/mistral-large-latest\")\n giskard.llm.set_embedding_model(\"mistral/mistral-embed\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard - Python\nDESCRIPTION: This code wraps the created LangChain model with Giskard's `Model` class. It specifies the model type, name, description, and feature names. Wrapping allows Giskard to test and analyze the model for vulnerabilities. The purpose is to integrate the model with Giskard for further analysis.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=chain,\n    model_type=\"text_generation\",\n    name=\"Comment generation\",\n    description=\"This model is a professional newspapers commentator.\",\n    feature_names=[TEXT_COLUMN_NAME],\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing the Giskard model wrapper for sentiment classification\nDESCRIPTION: Configures the Giskard model wrapper with the DistilBERT model, classification labels, and feature names for vulnerability scanning.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = GiskardModelCustomWrapper(\n    model=giskard_model,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"Trip advisor sentiment classifier\",  # Optional.\n    classification_labels=[0, 1, 2],  # Their order MUST be identical to the prediction_function's output order.\n    feature_names=[TEXT_COLUMN_NAME],  # Default: all columns of your dataset.\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying and Exporting the Full Scan Report - Python\nDESCRIPTION: Shows the results of the full vulnerability scan interactively in the notebook, then exports the report to a standalone HTML file for sharing or archiving. Inputs: a ScanReport object (from full_report); output: HTML file named 'scan_report.html'. Requires Jupyter or environment with display() support for visualization.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndisplay(full_report)\n\n# Save it to a file\nfull_report.to_html(\"scan_report.html\")\n```\n\n----------------------------------------\n\nTITLE: Defining LangChain Prompt Template for RAG (Python)\nDESCRIPTION: Imports `PromptTemplate` from LangChain and defines a template string `PROMPT_TEMPLATE`. This template instructs the LLM on its role (Climate Assistant), task (answer questions based on context), and specifies placeholders for the retrieved context (`{context}`) and the user's question (`{question}`).\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.prompts import PromptTemplate\n\n# We use a simple prompt\nPROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard.\nYour task is to answer common questions on climate change.\nYou will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023).\nPlease provide short and clear answers based on the provided context. Be polite and helpful.\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nYour answer:\n\"\"\"\n\nprompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\n```\n\n----------------------------------------\n\nTITLE: Using Custom Question Generators for Test Set Creation\nDESCRIPTION: Demonstrates how to create a test set with specific question types by providing custom question generators to the generate_testset function.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag.question_generators import complex_questions, double_questions\n\ntestset = generate_testset(\n    knowledge_base,\n    question_generators=[complex_questions, double_questions],\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning for Hallucination Vulnerabilities with Giskard - Python\nDESCRIPTION: Runs Giskard's scan utility focused on the 'hallucination' issue category, generating a vulnerability report for the wrapped model and dataset. Inputs are the pre-wrapped Giskard model and dataset; output is a ScanReport object. Useful for a quick, targeted evaluation of hallucination risks before executing a complete scan.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nreport = giskard.scan(giskard_model, giskard_dataset, only=\"hallucination\")\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI LLM Client using completion parameters in Python\nDESCRIPTION: This snippet configures the OpenAI LLM client by directly passing the API key as a parameter in setter functions rather than environment variables. It sets the LLM model and embedding model with the provided API key using giskard.llm API. This approach allows for dynamic or programmatic model configurations without relying on environment variables. It requires the giskard package and valid OpenAI API credentials. Inputs include the API key string and model names, outputs are configured LLM and embedding models for subsequent usage.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\n\napi_key = \"\" # \"my-openai-api-key\"\n\ngiskard.llm.set_llm_model(\"o1-preview\", api_key=api_key)\ngiskard.llm.set_embedding_model(\"text-embedding-3-large\", api_key=api_key)\n```\n\n----------------------------------------\n\nTITLE: Creating LLM with LangChain - Python\nDESCRIPTION: This code defines a prompt, configures an OpenAI LLM, and creates an `LLMChain` using LangChain. The prompt template takes the text column as input. The OpenAI model is configured with a request timeout, max retries, temperature, and model name. This is done to test the LangChain and OpenAI integration. After the chain is created, it is tested with one of the data points from the filtered dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprompt = PromptTemplate(\n    template=PROMPT_TEMPLATE,\n    input_variables=[TEXT_COLUMN_NAME],\n)\n\nllm = OpenAI(\n    request_timeout=20,\n    max_retries=100,\n    temperature=0,\n    model_name=\"gpt-3.5-turbo-instruct\",\n)\n\nchain = LLMChain(prompt=prompt, llm=llm)\n\n# Test the chain.\nchain.invoke(df_filtered.loc[0, TEXT_COLUMN_NAME])\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries - Python\nDESCRIPTION: Imports necessary libraries for data handling (numpy, pandas), deep learning (torch), model training and tokenization (transformers), model evaluation (sklearn), and Giskard integration (giskard). These imports set up the environment for data processing, model building, and Giskard's ML testing framework.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset as TorchDataset\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, TrainingArguments, Trainer\nfrom transformers.integrations import MLflowCallback, TensorBoardCallback, WandbCallback\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Validating Giskard Model Wrapping by Prediction in Python\nDESCRIPTION: Runs the Giskard FAISSRAGModel on the wrapped dataset to verify correct integration and output formatting. Prints the resulting predictions to confirm alignment with expectations. This is a crucial step to ensure the wrapper and input data are compatible before running automated vulnerability scans or test generation. Input is a Giskard Dataset; output is a predictions DataFrame.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Validate the wrapped model and dataset.\nprint(giskard_model.predict(giskard_dataset).prediction)\n\n```\n\n----------------------------------------\n\nTITLE: Loading and Vectorizing PDF Content with LangChain and FAISS (Python)\nDESCRIPTION: Uses LangChain components to load a PDF document (`PyPDFLoader`), split its content into smaller, overlapping chunks (`RecursiveCharacterTextSplitter`), generate embeddings for each chunk using OpenAI (`OpenAIEmbeddings`), and store them in a FAISS vector database (`FAISS.from_documents`). This database (`db`) will be used for retrieving relevant context for the RAG model. Requires `langchain`, `pypdf`, `faiss-cpu`, `tiktoken`, `openai` libraries and a valid OpenAI API key.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Load the IPCC Climate Change Synthesis Report from a PDF file\nloader = PyPDFLoader(\n    \"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\"\n)\n\n# Split document\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=100,\n    length_function=len,\n    add_start_index=True,\n)\n\n# Load the splitted fragments in our vector store\ndocs = loader.load_and_split(text_splitter)\ndb = FAISS.from_documents(docs, OpenAIEmbeddings())\n```\n\n----------------------------------------\n\nTITLE: Configuring Mistral LLM Client with Giskard in Python\nDESCRIPTION: This snippet details how to set environment variables for Mistral API credentials and specifies the Mistral LLM and embedding model names for use with Giskard's RAGET functionalities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"MISTRAL_API_KEY\"] = \"\" # \"my-mistral-api-key\"\n\ngiskard.llm.set_llm_model(\"mistral/mistral-large-latest\")\ngiskard.llm.set_embedding_model(\"mistral/mistral-embed\")\n```\n\n----------------------------------------\n\nTITLE: Generating Response with NeMo Guardrails (nest_asyncio, app.generate)\nDESCRIPTION: Generates a response from the NeMo Guardrails application to a user message. The `nest_asyncio.apply()` call is used to allow nested asyncio event loops, which is often necessary in environments like Jupyter notebooks. The `app.generate()` method takes a list of messages as input and returns the generated response from the chatbot.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport nest_asyncio\n\nnest_asyncio.apply()\n\napp.generate(messages=[{\"role\": \"user\", \"content\": \"Hi!\"}])\n```\n\n----------------------------------------\n\nTITLE: Defining and Executing Custom Test in Giskard Python\nDESCRIPTION: This snippet shows how to create a new test not available in the Giskard catalog by decorating a standard Python function with `@test`. The function takes Giskard `Dataset` and other parameters, calculates a metric (frequency of a category), and returns a `TestResult` object indicating `passed` status and the calculated `metric`. The snippet then demonstrates executing this custom test.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nfrom giskard import demo, test, Dataset, TestResult, testing\n\n\n#Creating a data quality test checking if the frequency of a category is under a threshold\n@test(name=\"My Example\", tags=[\"quality\", \"custom\"])\ndef uniqueness_test_function(dataset: Dataset,\n                             category: str,\n                             column_name: str,\n                             threshold: float = 0.5): #you can put default value to the test\n    freq_of_cat = dataset.df[column_name].value_counts()[category] / (len(dataset.df))\n    passed = freq_of_cat < threshold\n\n    return TestResult(passed=passed, metric=freq_of_cat)\n\n\n#Now let's run this test to check if the frequency of \"female\" is under 70%\n_, df = demo.titanic()\n\nwrapped_dataset = Dataset(\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\nuniqueness_test_function(dataset=wrapped_dataset,\n                         column_name = \"Sex\",\n                         category=\"female\",\n                         threshold =0.7\n                        ).execute()\n```\n\n----------------------------------------\n\nTITLE: Scanning Model and Dataset with Giskard\nDESCRIPTION: Executes Giskard's automated vulnerability scan by calling the `scan` function with the wrapped `giskard_model` and `giskard_dataset`. This process analyzes the model and data for potential issues like performance biases, unrobustness, and ethical concerns, returning a `ScanReport` object containing the findings.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries\nDESCRIPTION: This snippet imports necessary libraries for data manipulation (pandas), loading the breast cancer dataset from scikit-learn, evaluating the model with classification report, splitting data into training and testing sets, the XGBoost classifier, and Giskard's Dataset, Model, scan, and testing modules.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard Model Class\nDESCRIPTION: Creates a Giskard `Model` object by wrapping the custom `prediction_function`. This integrates the model into the Giskard framework, allowing it to be scanned and tested. It requires specifying the model type ('classification'), classification labels in the correct order, feature names, and allows for an optional name.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=prediction_function,  # A prediction function that encapsulates all the data pre-processing steps and that\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"RoBERTa for sentiment classification\",  # Optional\n    classification_labels=list(LABEL_MAPPING.values()),  # Their order MUST be identical to the prediction_function's\n    feature_names=[TEXT_COLUMN],  # Default: all columns of your dataset\n)\n```\n\n----------------------------------------\n\nTITLE: Importing necessary libraries including Giskard\nDESCRIPTION: This snippet imports standard data processing and machine learning libraries alongside Giskard's core modules. These imports are prerequisites for dataset handling, model building, and vulnerability assessment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom lightgbm import LGBMClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries and Giskard Components - Python\nDESCRIPTION: Imports standard Python libraries for string manipulation, file handling, numerical calculations, data processing, and scikit-learn components for text vectorization and model evaluation. Also imports Giskard modules required for dataset and model handling, scanning, and testing. All packages need to be installed beforehand; ensure Giskard and scikit-learn are available.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport string\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, balanced_accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom giskard import Dataset, Model, scan, testing\n\n```\n\n----------------------------------------\n\nTITLE: Defining Model Prediction Function\nDESCRIPTION: Defines a Python function `prediction_function` that encapsulates the model's prediction logic. It takes a pandas DataFrame, tokenizes the text column, passes the output through the loaded Hugging Face model, and returns the softmax probabilities of the output logits as a numpy array. This function serves as the interface for Giskard to interact with the model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df: pd.DataFrame) -> np.ndarray:\n    encoded_input = tokenizer(list(df[TEXT_COLUMN]), padding=True, return_tensors=\"pt\")\n    output = model(**encoded_input)\n    return softmax(output[\"logits\"].detach().numpy(), axis=1)\n```\n\n----------------------------------------\n\nTITLE: Scanning Machine Learning Models with Giskard in Python\nDESCRIPTION: This snippet demonstrates running a vulnerability scan on a given machine learning model and dataset using Giskard's scan function. The scan automatically detects issues like biases, data leakage, and other performance or ethical problems. It requires previously instantiated 'giskard_model' and 'giskard_dataset' objects. The output, stored in 'results', contains detected vulnerabilities and scan metadata.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Displaying the Giskard Vulnerability Report - Python\nDESCRIPTION: Visualizes the generated ScanReport object within a notebook or compatible interface. Required input is a ScanReport instance (e.g., from giskard.scan); output is the interactive vulnerability results view. Best used in Jupyter or similar environments.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndisplay(report)\n```\n\n----------------------------------------\n\nTITLE: Configuring Notebook and OpenAI API Environment in Python\nDESCRIPTION: Sets up the OpenAI API key both as a variable for OpenAI client usage and as an environment variable for downstream tools. Configures pandas display options to prevent truncation of DataFrame columns. The OpenAI API key must be provided before calling the OpenAI API. For security, never hardcode real API keys in shared code.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Set the OpenAI API Key environment variable.\nOPENAI_API_KEY = \"...\"\nopenai.api_key = OPENAI_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# Display options.\npd.set_option(\"display.max_colwidth\", None)\n\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key for Giskard (Python)\nDESCRIPTION: Configures the OpenAI API key required for Giskard's AI Quality Copilot to access the OpenAI Function Calling API. The snippet sets the 'OPENAI_API_KEY' environment variable using Python's os module. This is a prerequisite for interacting with LLM-powered functions and must be executed before invoking Copilot features.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-…\"\n```\n\n----------------------------------------\n\nTITLE: Defining AI-Based Text Transformation Function in Giskard Python\nDESCRIPTION: This complex example demonstrates creating a Giskard transformation function that utilizes an external AI model (via Langchain and OpenAI) to rewrite text within a DataFrame cell. Decorated with `@transformation_function(row_level=False)`, it processes the entire DataFrame but focuses modification on a specific cell identified by index and column name, using a provided style and OpenAI API key. Requires `os`, `pandas`, `giskard`, `langchain`, and a configured OpenAI API key in the environment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_transformations/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport pandas as pd\nfrom giskard import transformation_function\n\n\n@transformation_function(name=\"Change writing style\", row_level=False, tags=['text'])\ndef change_writing_style(\n        x: pd.DataFrame,\n        index: int,\n        column_name: str,\n        style: str,\n        openai_api_key: str\n) -> pd.DataFrame:\n    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n\n    rewrite_prompt_template = \"\"\"\n    As a text rewriting robot, your task is to rewrite a given text using a specified rewriting style. You will receive a prompt with the following format:\n    ```\n    \"TEXT\"\n    ===\n    \"REWRITING STYLE\"\n    ```\n    Your goal is to rewrite the provided text according to the specified style. The purpose of this task is to evaluate how the rewritten text will affect our machine learning models.\n\n    Your response should be in the following format:\n    ```\n    REWRITTEN TEXT\n    ```\n    Please ensure that your rewritten text is grammatically correct and retains the meaning of the original text as much as possible. Good luck!\n    ```\n    \"TEXT\": {text}\n    ===\n    \"REWRITING STYLE\": {style}\n    ```\n    \"\"\"\n\n    from langchain import PromptTemplate, LLMChain, OpenAI\n\n\n    rewrite_prompt = PromptTemplate(input_variables=['text', 'style'], template=rewrite_prompt_template)\n    chain_rewrite = LLMChain(llm=OpenAI(), prompt=rewrite_prompt)\n\n    x.at[index, column_name] = chain_rewrite.run({'text': x.at[index, column_name], 'style': style})\n    return x\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard\nDESCRIPTION: This code defines a prediction function that takes a pandas DataFrame as input, applies preprocessing steps, and returns the predicted probabilities using the classifier. This prediction function is then wrapped into a Giskard Model object along with metadata such as the model type, classification labels, and feature names.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df: pd.DataFrame) -> np.ndarray:\n    preprocessed_df = preprocessing_function(df)\n    return classifier.predict_proba(preprocessed_df)\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"Titanic model\",  # Optional\n    classification_labels=classifier.classes_,\n    # Their order MUST be identical to the prediction_function's output order\n    feature_names=[\n        \"PassengerId\",\n        \"Pclass\",\n        \"Name\",\n        \"Sex\",\n        \"Age\",\n        \"SibSp\",\n        \"Parch\",\n        \"Fare\",\n        \"Embarked\",\n    ],  # Default: all columns of your dataset\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Model\nDESCRIPTION: This snippet imports the necessary Python libraries and modules required for data handling, machine learning model building (scikit-learn), model evaluation, and Giskard integration. It includes libraries for data manipulation (pandas), preprocessing (StandardScaler, OneHotEncoder), model building (RandomForestClassifier), and model evaluation (accuracy_score). It also imports the Giskard library's core components like Model, Dataset, scan, and testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\n\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nfrom giskard import Model, Dataset, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for OpenAI and W&B Tracing in Python\nDESCRIPTION: Configures environment variables required by the tutorial, including the OpenAI API key (`OPENAI_API_KEY`), enabling langchain tracing via W&B (`LANGCHAIN_WANDB_TRACING`), and specifying the W&B project name (`WANDB_PROJECT`). These variables control authentication, tracing activation, and project organization respectively.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\n# Setting up OpenAI API KEY\nos.environ['OPENAI_API_KEY'] = \"sk-xxx\"\n\n# Enabling the W&B tracing\nos.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n\n# Picking up a name for the project\nos.environ[\"WANDB_PROJECT\"] = \"product_description\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Giskard Evaluator Metadata for MLflow (Python)\nDESCRIPTION: Defines a Python dictionary `evaluator_config` containing metadata for the Giskard scan. This includes a nested `model_config` with the model's name, description, and the names of the input features (`feature_names`), which is 'query' in this case. This configuration is passed to `mlflow.evaluate`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nevaluator_config={\n    \"model_config\":\n     {\"name\": \"Climate Change Question Answering\",\n      \"description\": \"This model answers any question about climate change based on IPCC reports\",\n      \"feature_names\": [\"query\"],},\n    }\n```\n\n----------------------------------------\n\nTITLE: Preparing Text Data and Tokenization in Python\nDESCRIPTION: Implements two main preprocessing steps: text cleaning (punctuation and stop word removal) and tokenization using Keras' Tokenizer. Outputs are sequences suitable for model input. Requires NLTK and Keras library availability, and uses previously defined STOPWORDS and text columns.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_text(df: pd.DataFrame) -> np.ndarray:\n    \"\"\"Perform text-data cleaning: punctuation and stop words removal.\"\"\"\n    # Merge text data into single column.\n    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME] + \" \" + df.title\n    df.drop(columns=[\"title\"], inplace=True)\n\n    # Remove punctuation.\n    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(\n        lambda text: text.translate(str.maketrans(\"\", \"\", string.punctuation))\n    )\n\n    # Remove stop words.\n    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(\n        lambda sentence: \" \".join([_word for _word in sentence.split() if _word.lower() not in STOPWORDS])\n    )\n\n    return df[TEXT_COLUMN_NAME]\n\n\nX_train_prepared = prepare_text(X_train)\nX_test_prepared = prepare_text(X_test)\n\n\ndef init_tokenizer() -> Tuple[Callable, Tokenizer]:\n    \"\"\"Initialize tokenization function with the Tokenizer in it's outer-scope.\"\"\"\n    tokenizer = Tokenizer(num_words=MAX_TOKENS)\n    tokenizer.fit_on_texts(X_train_prepared)\n\n    def tokenization_closure(df: pd.DataFrame) -> pd.DataFrame:\n        tokenized = tokenizer.texts_to_sequences(df)\n        return pad_sequences(tokenized, maxlen=MAX_SEQUENCE_LENGTH)\n\n    return tokenization_closure, tokenizer\n\n\ntokenize, text_tokenizer = init_tokenizer()\nX_train_tokens = tokenize(X_train_prepared)\nX_test_tokens = tokenize(X_test_prepared)\n\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training and Testing Sets\nDESCRIPTION: This snippet splits the features and target variable into training and testing sets using `train_test_split` from scikit-learn, ensuring reproducibility with a specified random state.  The feature columns are selected to exclude the TARGET_COLUMN_NAME.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Train/test split.\nX_train, X_test, y_train, y_test = train_test_split(\n    features.loc[:, features.columns != TARGET_COLUMN_NAME], target, random_state=RANDOM_SEED\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities\nDESCRIPTION: This code snippet utilizes the `scan` function from the Giskard library to detect vulnerabilities in the model. The function takes the Giskard Model and Dataset objects as inputs and returns a scan report containing the detected issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Running Giskard Tests via Pytest Fixtures and Parametrization\nDESCRIPTION: This Python script demonstrates setting up and running Giskard model tests within a pytest environment. It involves loading a demo dataset and model, wrapping them with Giskard's `Dataset` and `Model` classes, creating a `Suite` of tests (F1 score and accuracy), defining pytest fixtures for the model and dataset, and finally executing tests both individually and parametrized from the suite using `suite.to_unittest()`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/pytest/full_example.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pytest\n\nfrom giskard import Dataset, Model, Suite, demo\nfrom giskard.testing import test_accuracy, test_f1\n\nmodel_raw, df = demo.titanic()\n\nwrapped_dataset = Dataset(\n    name=\"Test Data Set\",\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\nwrapped_model = Model(model=model_raw, model_type=\"classification\", name=\"Classifier v1\")\n\nsuite = (\n    Suite(\n        default_params={\n            \"model\": wrapped_model,\n            \"dataset\": wrapped_dataset,\n        }\n    )\n    .add_test(test_f1(threshold=0.6))\n    .add_test(test_accuracy(threshold=1))  # Certain to fail\n)\n\n\n@pytest.fixture\ndef dataset():\n    return wrapped_dataset\n\n\n@pytest.fixture\ndef model():\n    return wrapped_model\n\n\n# Single wrapped test\ndef test_only_accuracy(dataset, model):\n    test_accuracy(model=model, dataset=dataset, threshold=1).assert_()\n\n\n# Parametrise tests from suite\n@pytest.mark.parametrize(\"test_partial\", suite.to_unittest(), ids=lambda t: t.fullname)\ndef test_giskard(test_partial):\n    test_partial.assert_()\n```\n\n----------------------------------------\n\nTITLE: Performing Train-Test Split on Dataset Using scikit-learn in Python\nDESCRIPTION: Splits the loaded dataset into train and test subsets by separating features and the target variable 'charges'. This step ensures model evaluation can be performed on unseen data to assess generalization.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[\"charges\"]), df.charges, random_state=0)\n```\n\n----------------------------------------\n\nTITLE: Running Giskard Vulnerability Scan with Hallucination Detection in Python\nDESCRIPTION: Executes Giskard's LLM vulnerability scan on the provided model and dataset, restricting the analysis to hallucination detection. Produces a scan report object that summarizes any identified vulnerabilities, particularly related to misinformation or sycophantic model behavior. Requires valid and operational Giskard, model, and dataset objects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nscan_report = gsk.scan(model, dataset, only=\"hallucination\")\n```\n\n----------------------------------------\n\nTITLE: Validating the Wrapped Model - Python\nDESCRIPTION: This code validates the wrapped model by running the predict method with the giskard dataset. This confirms that the model is correctly wrapped and can make predictions. The output is then printed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Validate the wrapped model and dataset.\nprint(giskard_model.predict(giskard_dataset).prediction)\n```\n\n----------------------------------------\n\nTITLE: Creating and Testing a Giskard Dataset - Python\nDESCRIPTION: Creates a sample dataset using a Pandas DataFrame containing example product names. This dataset is then wrapped as a Giskard `Dataset` object. The wrapped Giskard Model (`giskard_model`) is then run on this dataset to validate that the wrapping was successful and the model can process the input data correctly.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Optional: Wrap a dataframe of sample input prompts to validate the model wrapping and to narrow specific tests' queries.\ncorpus = [\"Double-Sided Cooking Pan\", \"Automatic Plant Watering System\", \"Miniature Exercise Equipment\"]\n\ngiskard_dataset = Dataset(pd.DataFrame({TEXT_COLUMN_NAME: corpus}), target=None)\n\n# Validate the wrapped model and dataset.\ngiskard_model.predict(giskard_dataset).prediction\n```\n\n----------------------------------------\n\nTITLE: Creating a Giskard Dataset from a Pandas DataFrame in Python\nDESCRIPTION: Creates a test dataset wrapping a small pandas DataFrame containing product names. The dataset is named and specified with column types. This dataset is used by Giskard scans for evaluating the models, although it is optional as Giskard can generate representative datasets from model metadata.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\npd.set_option(\"display.max_colwidth\", 999)\n\ndataset = giskard.Dataset(pd.DataFrame({\n    'product_name': [\"Double-Sided Cooking Pan\",\n                     \"Automatic Plant Watering System\",\n                     \"Miniature Exercise Equipment\"],\n\n}), name=\"Test dataset\", target=None,\n    column_types={\"product_name\": \"text\"})\n```\n\n----------------------------------------\n\nTITLE: Generating a Giskard Test Suite from Scan Results in Python\nDESCRIPTION: Illustrates how to automatically create a Giskard test suite based on the issues identified during the scan. The `generate_test_suite` method is called on the `scan_results` object, taking a string argument to name the newly created test suite.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = scan_results.generate_test_suite(\"My first test suite\")\n```\n\n----------------------------------------\n\nTITLE: Defining Constants and File Paths for Dataset Handling in Python\nDESCRIPTION: Specifies the column groups used for numerical and categorical feature processing, and sets the URL from which to download the insurance dataset along with the local file path to store the downloaded data. These constants assist the data ingestion and preprocessing pipeline.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nNUMERICAL_COLS = [\"bmi\", \"age\", \"children\"]\nCATEGORICAL_COLS = [\"sex\", \"smoker\", \"region\"]\n\n# Paths.\nDATA_URL = \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/insurance_prediction_dataset-us_health_insurance_dataset.csv.tar.gz\"\nDATA_PATH = Path.home() / \".giskard\" / \"insurance_prediction_dataset\" / \"us_health_insurance_dataset.csv.tar.gz\"\n```\n\n----------------------------------------\n\nTITLE: Generating and running a test suite\nDESCRIPTION: This snippet generates a comprehensive test suite from the scan results and runs it. The test suite is designed to evaluate the model's performance, validate its behavior against predefined test cases, and identify any regressions or issues that may arise during development or updates.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"Test suite generated by scan\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Exporting NeMo Guardrails Rails from Giskard Scan Report using Python\nDESCRIPTION: This Python snippet demonstrates how to import Giskard, perform a scan on a given model and dataset, and export the resulting rails in Colang format using the scan report's generate_rails method. This facilitates automatic generation of NeMo Guardrails rails to prevent LLM vulnerabilities detected by Giskard. It requires giskard to be installed and configured, with the model and dataset objects accessible. The generated file path and optionally the Colang version can be specified.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\n\nscan_report = gsk.scan(my_model, my_dataset)\n\n# Export the rails in colang format\nscan_report.generate_rails(\"config/generated_rails.co\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Dataset - Python\nDESCRIPTION: This code loads a CSV file from a URL into a pandas DataFrame and then filters it to include only the text column. It then samples a subset of 10 rows using a specified random state, to reduce processing time. The data is now ready to be processed by the LLM.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.read_csv(DATA_URL)\ndf_filtered = df[[TEXT_COLUMN_NAME]].sample(10, random_state=RANDOM_STATE, ignore_index=True)\n```\n\n----------------------------------------\n\nTITLE: Exporting Giskard RAGReport to Pandas DataFrame in Python\nDESCRIPTION: Shows how to convert the `RAGReport` object into a pandas DataFrame for detailed programmatic analysis using the `report.to_pandas()` method. Requires the `pandas` library to be installed and assumes a `RAGReport` object named `report` exists.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresults = report.to_pandas()\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Test Suite from Scan Results - Python\nDESCRIPTION: Generates a Giskard test suite automatically from the findings of the previous scan. This suite incorporates tests designed to cover the detected vulnerabilities. The generated test suite is then executed to evaluate the model's performance against these specific tests.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_14\n\nLANGUAGE: Python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Importing Required Python Libraries\nDESCRIPTION: Imports the necessary libraries for data manipulation (numpy, pandas), dataset loading (datasets), model handling (scipy, transformers), and key Giskard modules (Dataset, Model, scan, testing). These imports make the required functions and classes available for use in the script.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom scipy.special import softmax\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Setting Up Model and Dataset for Giskard Testing with Python\nDESCRIPTION: Demonstrates how to define a model and dataset for use with Giskard testing, using a demo Titanic dataset. This includes wrapping of raw ML models and datasets with Giskard's wrappers.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/pytest/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pytest\n\nfrom giskard import Dataset, Model, Suite, demo\nfrom giskard.testing import test_accuracy, test_f1\n\nmodel_raw, df = demo.titanic()\n\nwrapped_dataset = Dataset(\n    name=\"Test Data Set\",\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\nwrapped_model = Model(model=model_raw, model_type=\"classification\", name=\"Classifier v1\")\n```\n\n----------------------------------------\n\nTITLE: Defining Project Constants (Python)\nDESCRIPTION: Defines constant variables for the URL of the SED documentation PDF and the specific OpenAI language model name to be used ('gpt-3.5-turbo-instruct').\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nDATA_URL = \"https://www.gnu.org/software/sed/manual/sed.pdf\"\n\nLLM_NAME = \"gpt-3.5-turbo-instruct\"\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard Model and Validating - Python\nDESCRIPTION: Defines a `prediction_function` that takes a pandas DataFrame, tokenizes the text column, feeds it through the trained HuggingFace model, applies softmax, and returns predictions as a numpy array. This function is then wrapped using Giskard's `Model` class, specifying model type, name, classification labels, and feature names. Finally, it validates the wrapped model by using it to predict on the Giskard dataset and printing the calculated F1 score.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\ndef prediction_function(df) -> np.ndarray:\n    input_text = list(df[TEXT_COLUMN_NAME])\n    text_tokenized = tokenizer(input_text, padding=True, truncation=True, max_length=256)\n\n    # Make prediction.\n    raw_pred = model.forward(\n        input_ids=torch.tensor(text_tokenized[\"input_ids\"]),\n        attention_mask=torch.tensor(text_tokenized[\"attention_mask\"]),\n    )\n    predictions = torch.nn.functional.softmax(raw_pred[\"logits\"], dim=-1)\n    predictions = predictions.cpu().detach().numpy()\n\n    return predictions\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"Twitter sentiment classifier\",  # Optional\n    classification_labels=TARGET_INT_STR.values(),  # Their order MUST be identical to the prediction_function's\n    feature_names=[TEXT_COLUMN_NAME],  # Default: all columns of your dataset\n)\n\n# Validate wrapped model.\nprint(\n    f\"Wrapped Test F1-Score: {f1_score(y_test, giskard_model.predict(giskard_dataset).raw_prediction, average='macro')}\"\n)\n```\n\n----------------------------------------\n\nTITLE: Generating a Test Suite from Scan Results\nDESCRIPTION: Generates a test suite from the results of the Giskard scan. This creates a set of tests based on the detected vulnerabilities, allowing for automated validation of the model's behavior. The `generate_test_suite` method takes a name as an argument to name the test suite. This suite facilitates ongoing monitoring of the model's performance and helps to ensure that identified vulnerabilities are addressed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain RAG Components (Python)\nDESCRIPTION: Installs various `langchain` packages (`langchain`, `langchain-community`, `langchain-openai`), document loading (`pypdf` with version constraint), vector store (`faiss-cpu`), tokenization (`tiktoken`), and tunneling (`pyngrok`) using pip. The `-q` flag ensures quiet installation. These libraries are essential for building and running the RAG pipeline.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install langchain langchain-community langchain-openai \"pypdf<=3.17.0\" faiss-cpu tiktoken pyngrok -q\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard Scan Results - Python\nDESCRIPTION: Displays the results object obtained from the Giskard scan. This typically utilizes the notebook's display function to render the scan findings in a human-readable format, highlighting detected vulnerabilities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Training LightGBM Regression Model with Pipeline and Evaluating Performance in Python\nDESCRIPTION: Builds a scikit-learn pipeline combining the preprocessing transformer and a LightGBM regressor with 30 estimators. Fits the pipeline on training data, predicts on both training and test sets, and evaluates R2-score to measure model performance. Outputs performance metrics for analysis.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"regressor\", LGBMRegressor(n_estimators=30))])\n\npipeline.fit(X_train, y_train)\n\ny_train_pred = pipeline.predict(X_train)\ny_test_pred = pipeline.predict(X_test)\n\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\n\nprint(f\"Train R2-score: {train_r2:.2f}\")\nprint(f\"Test R2-score: {test_r2:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Automated Test Suites from Scan Results with Giskard in Python\nDESCRIPTION: Here, the test suite is automatically generated from existing scan results using the 'generate_test_suite' method, which creates a named suite encapsulating detected vulnerabilities. The suite is then executed by calling 'run'. This process helps validate the model's behavior against identified issues. Dependencies include the prior 'results' object from a scan.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping LangChain Model for Giskard Evaluation - Python\nDESCRIPTION: Defines a Pandas DataFrame-driven prediction function that wraps the LangChain RAG QA chain, then registers the model in Giskard's framework for text generation tasks. The Giskard Model object includes a user-friendly name, description, and feature schema. Inputs are DataFrames with at least a 'question' column; output is a list of answers. Requires climate_qa_chain (from previous step), pandas, and giskard installed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\nimport pandas as pd\n\n\ndef model_predict(df: pd.DataFrame):\n    \"\"\"Wraps the LLM call in a simple Python function.\n\n    The function takes a pandas.DataFrame containing the input variables needed\n    by your model, and must return a list of the outputs (one for each row).\n    \"\"\"\n    return [climate_qa_chain.invoke({\"query\": question}) for question in df[\"question\"]]\n\n\n# Don’t forget to fill the `name` and `description`: they are used by Giskard\n# to generate domain-specific tests.\ngiskard_model = giskard.Model(\n    model=model_predict,\n    model_type=\"text_generation\",\n    name=\"Climate Change Question Answering\",\n    description=\"This model answers any question about climate change based on IPCC reports\",\n    feature_names=[\"question\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying GPT-3.5-turbo Scan Report in Python Notebook\nDESCRIPTION: This Python snippet shows how to display the Giskard scan report for the 'gpt-3.5-turbo' model within a notebook. It accesses the report via a dictionary named `models` and uses the `display` function (likely from IPython.display) to render it.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndisplay(models[\"gpt-3.5-turbo\"]['scan_report'])\n```\n\n----------------------------------------\n\nTITLE: Testing the Climate Change QA Chain in Python\nDESCRIPTION: Runs a sample query through the constructed RetrievalQA chain to verify correct setup and coherent LLM-generated answers. Expected to return a text answer based on retrieved IPCC excerpts. Assumes successful completion of all prior model and environment setup steps.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclimate_qa_chain(\"Is sea level rise avoidable? When will it stop?\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard Scan Results (Python)\nDESCRIPTION: Uses the `display` function (common in Jupyter environments) to render the Giskard scan results report, showing the detected vulnerabilities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries - Python\nDESCRIPTION: Imports all the Python libraries needed for setting up the environment, defining the Langchain components, and using Giskard for model testing. Includes `os` for environment variables, `operator` for data manipulation, `openai` for API access, `pandas` for data handling, Langchain components for prompt templating and output parsing, and Giskard's core classes.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom operator import itemgetter\n\nimport openai\nimport pandas as pd\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_openai import ChatOpenAI\n\nfrom giskard import Dataset, Model, scan\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key for LLM Access - Python\nDESCRIPTION: Sets the required OpenAI API key as an environment variable, enabling authenticated calls to OpenAI's GPT-3.5 Turbo Instruct model. Replace the sample key with your real secret key. This is required for both model and embedding operations that depend on OpenAI endpoints.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\n# Set the OpenAI API Key environment variable.\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Test Suite from Scan Results\nDESCRIPTION: Creates a comprehensive test suite based on vulnerabilities detected during the scan, then executes the tests to validate the model's performance and behavior.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Scanning for Hallucination Vulnerabilities in LLM QA Model with Giskard in Python\nDESCRIPTION: Performs an automatic vulnerability scan on the QA model using Giskard, focusing on the hallucination vulnerability category. Uses the wrapped model and dataset, and outputs structured results for user analysis. This step leverages predefined and LLM-based test suites to uncover potential model weaknesses. Only the 'hallucination' category is scanned to reduce runtime.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset, only=[\"hallucination\"])\n\n```\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n\n```\n\n----------------------------------------\n\nTITLE: Creating Suite with Model as Input (Giskard, Python)\nDESCRIPTION: This snippet shows how to build a Giskard test suite where the model is treated as an external input. It demonstrates adding tests to the suite without specifying the model parameter, making it a requirement during the `suite.run()` call. This pattern is useful for comparing the performance of different models on a fixed dataset and set of tests. It also shows creating two different model instances and running the same suite against each.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom giskard import demo, Model, Dataset, testing, Suite, slicing_function\n\n\nmodel, df = demo.titanic()\n\nwrapped_dataset = Dataset(\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n\n@slicing_function()\ndef slice_sex(row: pd.Series, category: str):\n    return row[\"Sex\"] == category\n\n\n# Create a suite and add an F1 and an accuracy test for the same slice\n# Note that all the parameters are specified except model\n# Which means that we will need to specify model everytime we run the suite\nsuite = (\n    Suite()\n    .add_test(\n        testing.test_f1(\n            dataset=wrapped_dataset, slicing_function=slice_sex(category=\"male\")\n        )\n    )\n    .add_test(\n        testing.test_accuracy(\n            dataset=wrapped_dataset, slicing_function=slice_sex(category=\"female\")\n        )\n)\n)\n\n# Create our first model\nmy_first_model = Model(model=model, model_type=\"classification\")\n\n# Run the suite by specifying our model and display the results\nsuite_results = suite.run(model=my_first_model)\npassed_first, results_first = suite_results.passed, suite_results.results\n\n# Create an improved version of our model\nmy_improved_model = Model(model=model, model_type=\"classification\")\n\n# Run the suite with our new version and check if the results improved\nsuite_results = suite.run(model=my_improved_model)\npassed_second, results_second = suite_results.passed, suite_results.results\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model with Giskard via MLflow\nDESCRIPTION: Evaluates a model using Giskard's vulnerability detection capabilities within an MLflow run.  `model_uri` should point to your registered model. The `evaluators=\"giskard\"` parameter specifies that Giskard should be used for evaluation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/dagshub/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith mlflow.start_run() as run:\n        mlflow.evaluate(model_uri, ..., evaluators=\"giskard\")\n```\n\n----------------------------------------\n\nTITLE: Listing Available MLflow Evaluators\nDESCRIPTION: This snippet lists the available evaluators registered in MLflow. It's used to verify that the Giskard evaluator is correctly installed and accessible. No dependencies besides MLflow itself are required.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport mlflow\nmlflow.models.list_evaluators() # [\\\"default\\\", \\\"giskard\\\"]\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries - Python\nDESCRIPTION: This code imports the necessary libraries for the project. This includes libraries for interacting with the OpenAI API, data manipulation (pandas), LangChain for building the LLM, and Giskard for model testing and evaluation. Dependencies include `os`, `openai`, `pandas`, `langchain`, `langchain_openai`, and `giskard`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport openai\nimport pandas as pd\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain_openai import OpenAI\n\nfrom giskard import Dataset, Model, scan\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Test to Test Suite\nDESCRIPTION: This snippet adds a custom test (test_f1) to the test suite that checks if the test F1 score is above a given threshold (0.7).  The `testing.test_f1` function comes from the Giskard catalog. The test suite is then executed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Generating and running a test suite from scan results\nDESCRIPTION: This snippet creates an automated test suite based on scan findings, and runs it to validate model performance on identified issues, ensuring robustness and correctness.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Validating the wrapped model and dataset\nDESCRIPTION: This snippet validates that the Giskard model and dataset are correctly wrapped by running a prediction and printing the result.  This ensures that the prediction function is working as expected and that Giskard can interact with the model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Validate the wrapped model and dataset.\nprint(giskard_model.predict(giskard_dataset).prediction)\n```\n\n----------------------------------------\n\nTITLE: Generating Test Suite from Scan Results\nDESCRIPTION: Creates a Giskard `TestSuite` object automatically from the vulnerabilities identified in the `results` of the automated scan. Each detected vulnerability becomes a test in the suite. The suite is given a name and then immediately executed using `.run()` to evaluate the model against the identified issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Data and Model Configuration\nDESCRIPTION: Sets up constant variables for the analysis. This includes a dictionary mapping column names to their data types (`COLUMN_TYPES`), the name of the target variable (`TARGET_COLUMN_NAME`), lists derived from `COLUMN_TYPES` identifying numeric and categorical columns for preprocessing (`COLUMNS_TO_SCALE`, `COLUMNS_TO_ENCODE`), and the URL to fetch the dataset (`DATA_URL`).\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nCOLUMN_TYPES = {\n    \"account_check_status\": \"category\",\n    \"duration_in_month\": \"numeric\",\n    \"credit_history\": \"category\",\n    \"purpose\": \"category\",\n    \"credit_amount\": \"numeric\",\n    \"savings\": \"category\",\n    \"present_employment_since\": \"category\",\n    \"installment_as_income_perc\": \"numeric\",\n    \"sex\": \"category\",\n    \"personal_status\": \"category\",\n    \"other_debtors\": \"category\",\n    \"present_residence_since\": \"numeric\",\n    \"property\": \"category\",\n    \"age\": \"category\",\n    \"other_installment_plans\": \"category\",\n    \"housing\": \"category\",\n    \"credits_this_bank\": \"numeric\",\n    \"job\": \"category\",\n    \"people_under_maintenance\": \"numeric\",\n    \"telephone\": \"category\",\n    \"foreign_worker\": \"category\",\n}\n\nTARGET_COLUMN_NAME = \"default\"\n\nCOLUMNS_TO_SCALE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"numeric\"]\nCOLUMNS_TO_ENCODE = [key for key in COLUMN_TYPES.keys() if COLUMN_TYPES[key] == \"category\"]\n\n# Paths.\nDATA_URL = \"https://raw.githubusercontent.com/Giskard-AI/giskard-examples/main/datasets/credit_scoring_classification_model_dataset/german_credit_prepared.csv\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Scan Metric Results in an AVID Report in Python\nDESCRIPTION: Extracts the results of the first metric from the first AVID report object produced by Giskard. This step illustrates how to introspect metric-level findings within the AVID report data structure. Expects the avid_reports collection to be non-empty.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nreport = avid_reports[0]\n\nreport.metrics[0].results\n```\n\n----------------------------------------\n\nTITLE: Logging into Weights & Biases Using API Key in Python\nDESCRIPTION: Imports wandb and performs login using a W&B API key string. The key must be obtained from the W&B authorization page. This step authenticates the user to enable experiment tracking and logging within W&B projects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport wandb\n\nwandb.login(key=\"key to retrieve from https://wandb.ai/authorize\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping LLM Generation Function as Giskard Model - Python\nDESCRIPTION: Wraps the custom `generation_function` into a Giskard `Model` object. This makes the function compatible with Giskard's testing framework. It specifies the model type as 'text_generation', provides a name and description, and identifies the input feature name ('product_name').\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Wrap the description chain.\ngiskard_model = Model(\n    model=generation_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset\n    model_type=\"text_generation\",  # Either regression, classification or text_generation.\n    name=\"Product keywords and description generator\",  # Optional.\n    description=\"Generate product description based on a product's name and the associated keywords.\"\n    \"Description should be using emojis and being SEO compliant.\",  # Is used to generate prompts\n    feature_names=[\"product_name\"],  # Default: all columns of your dataset.\n)\n```\n\n----------------------------------------\n\nTITLE: Detecting Vulnerabilities with Giskard Scan\nDESCRIPTION: Uses Giskard's `scan` function to automatically detect vulnerabilities in the wrapped model using the provided dataset. This initiates the vulnerability analysis process, which may involve checks for performance biases, unrobustness, and other issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Export Giskard Scan Report to AVID - Python\nDESCRIPTION: This Python code demonstrates how to export a Giskard scan report as a list of AVID reports. It assumes the Giskard scan has already been performed and stored in `scan_report`. The `to_avid()` method converts the report into a format compatible with the AVID standard, suitable for sharing with the community.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\n\nscan_report = gsk.scan(my_model, my_dataset)\n\n# Export the report as a list of AVID reports (one per each vulnerability)\navid_reports = scan_report.to_avid()\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset using Pandas\nDESCRIPTION: Loads the German credit scoring dataset from the specified `DATA_URL` into a pandas DataFrame named `df`. It uses `keep_default_na=False` and specifies `na_values=[\"_GSK_NA_\"]` to correctly handle missing value representations specific to this dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.read_csv(DATA_URL, keep_default_na=False, na_values=[\"_GSK_NA_\"])\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Rails Content (%%cat)\nDESCRIPTION: Displays the content of the generated rails file (`config/generated.co`) using the `%cat` magic command. This allows you to view the automatically generated guardrails that were created based on the Giskard scan.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n%cat config/generated.co\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard Dataset Class in Python\nDESCRIPTION: Combines test features and target data into a single DataFrame and wraps it with Giskard's Dataset class, specifying the target variable and categorical columns. This wrapper facilitates vulnerability scanning and testing functionalities provided by Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_test, y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=\"charges\",  # Ground truth variable.\n    name=\"insurance dataset\",  # Optional.\n    cat_columns=CATEGORICAL_COLS,\n    # List of categorical columns. Optional, but is a MUST if available. Inferred automatically if not.\n)\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training and Testing Sets\nDESCRIPTION: Splits the drug classification dataset into training and testing sets using a 50/50 split ratio, separating features (X) from the target variable (y).\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nX_train, X_test, y_train, y_test = train_test_split(\n    df_drug.drop(TARGET_NAME, axis=1), df_drug[TARGET_NAME], test_size=0.5, random_state=RANDOM_SEED\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying scan results\nDESCRIPTION: This code displays the scan results visually, allowing inspection of detected vulnerabilities and issues within the model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key (Google Colab)\nDESCRIPTION: Retrieves the OpenAI API key from Google Colab secrets and sets it as an environment variable. This allows the NeMo Guardrails application to access the OpenAI API for generating responses. Note that this requires the `google.colab` library and assumes the API key is stored as a secret named 'OPENAI_API_KEY'.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\n# We use Google Colab secrets here, but feel free to adjust this to your environment\nfrom google.colab import userdata\n\nos.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for M5 Sales Prediction Dataset\nDESCRIPTION: Sets up constants for column names, split date, and data paths for the M5 sales prediction project. These constants are used throughout the workflow for data handling and model training.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nID_COLUMN = \"id\"\nDATE_COLUMN = \"date\"\nTARGET_COLUMN = \"demand\"\nSPLIT_DATE = \"2016-03-27\"\n\n# Paths.\nDATA_URL = \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/m5_sales_prediction_dataset-{}\"\nDATA_PATH = Path.home() / \".giskard\" / \"m5_sales_prediction_dataset\"\nDATA_FILES = [\"calendar.csv.tar.gz\", \"sales_train_validation.csv.tar.gz\", \"sell_prices.csv.tar.gz\"]\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI and other dependencies\nDESCRIPTION: This snippet installs the `openai`, `tiktoken` and `scipy` packages. These packages are required for interacting with the OpenAI API, tokenizing text, and performing scientific computations.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install openai tiktoken scipy\n```\n\n----------------------------------------\n\nTITLE: Wrapping Test Dataset with Giskard Dataset - Python\nDESCRIPTION: Combines the test features and original string-mapped test targets into a pandas DataFrame, then wraps it using Giskard's `Dataset` class. This prepares the test data for Giskard's scanning capabilities, specifying the target column and providing a descriptive name.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nraw_data = pd.concat([X_test, y_test.map(TARGET_INT_STR)], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN_NAME,  # Ground truth variable.\n    name=\"Tweets sentiment dataset\",  # Optional.\n)\n```\n\n----------------------------------------\n\nTITLE: Generating and Running Giskard Test Suite (Python)\nDESCRIPTION: Generates a Giskard test suite from the `results` object obtained from the scan. This suite includes tests based on the detected vulnerabilities. The `run()` method executes the generated test suite against the model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"Test suite generated by scan\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Configuring Giskard Detector Parameters via 'params' Argument in Python\nDESCRIPTION: This snippet provides an example of customizing the configuration for specific Giskard detectors by passing a 'params' dictionary to the scan. Each key is a detector identifier, mapped to a dictionary of that detector's options. Giskard and a model/dataset are required. Inputs are the model, dataset, and a 'params' mapping with per-detector settings like 'threshold' or 'output_sensitivity'. Output is a scan report with detectors initialized per custom options.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\n\nparams = {\n    \"performance_bias\": dict(threshold=0.04, metrics=[\"accuracy\", \"f1\"]),\n    \"ethical_bias\": dict(output_sensitivity=0.5),\n}\n\nreport = gsk.scan(my_model, my_dataset, params=params)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Imports necessary libraries for data manipulation, model building, and evaluation, including those for PyTorch, scikit-learn, pandas, and Giskard. These libraries provide the building blocks for the text classification model and its testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\nfrom torchtext.datasets import AG_NEWS\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score\nfrom torchtext.data.utils import get_tokenizer\nfrom torch.utils.data.dataset import random_split\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.data.functional import to_map_style_dataset\n\nfrom giskard import Model, Dataset, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with toctree\nDESCRIPTION: This code snippet uses the toctree directive to create a table of contents for the Integrations section. It specifies the caption, maximum depth, and hides the toctree in the rendered output. The listed files are the pages linked under the Integrations section.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/index.md#_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n```\n:caption: Integrations\n:maxdepth: 1\n:hidden:\n\nintegrations/cicd/index\nintegrations/mlflow/index\nintegrations/nemoguardrails/index\nintegrations/wandb/index\nintegrations/dagshub/index\nintegrations/huggingface/index\nintegrations/avid/index\nintegrations/pytest/index\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Text Preprocessing Pipeline for ML Model - Python\nDESCRIPTION: Creates a custom scikit-learn pipeline including a function to remove punctuation and text vectorization using TfidfVectorizer. The function removes punctuation from all review texts; the vectorizer transforms text features for model input. Requires pandas, sklearn, and string modules. Inputs: pandas DataFrame; Outputs: transformed feature matrix.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef remove_punctuation(x):\n    \"\"\"Remove punctuation from input string.\"\"\"\n    x = x.reviewText.apply(lambda row: row.translate(str.maketrans(\"\", \"\", string.punctuation)))\n    return x\n\n\npreprocessor = Pipeline(\n    steps=[\n        (\"punctuation\", FunctionTransformer(remove_punctuation)),\n        (\"vectorizer\", TfidfVectorizer(stop_words=\"english\", min_df=0.01)),\n    ]\n)\n\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Package\nDESCRIPTION: Installs the Giskard package using pip, which is necessary for the model testing functionality used throughout the notebook.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Dataset with Pandas\nDESCRIPTION: Loads a specific split ('validation') of the 'tweet_eval' sentiment dataset using the `datasets` library, limiting it to the first 500 rows. The loaded dataset is converted to a pandas DataFrame, and the integer labels are replaced with human-readable strings using the `LABEL_MAPPING`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nraw_data = load_dataset(**DATASET_CONFIG).to_pandas().iloc[:500]\nraw_data = raw_data.replace({\"label\": LABEL_MAPPING})\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for NLP Classification in Python\nDESCRIPTION: Imports core Python libraries, data processing tools, Keras/TensorFlow components, NLTK for NLP preprocessing, scikit-learn for metrics and splitting, and Giskard APIs needed for test orchestration. All listed imports must be available in your Python environment. Ensure you have installed Keras, TensorFlow, scikit-learn, pandas, numpy, and NLTK, and download relevant NLTK datasets.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport string\nimport tarfile\nfrom pathlib import Path\nfrom typing import Tuple, Callable\nfrom urllib.request import urlretrieve\n\nimport numpy as np\nimport pandas as pd\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom giskard import Dataset, Model, scan, testing\n\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages\nDESCRIPTION: Installs the necessary Python packages (giskard, mlflow, dagshub, dvc) required for the Giskard-DagsHub integration. These packages enable model evaluation, experiment tracking, and version control.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/dagshub/index.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install giskard mlflow dagshub dvc\n```\n\n----------------------------------------\n\nTITLE: Defining Custom PyTorch Dataset and Tokenization - Python\nDESCRIPTION: Defines a custom `torch.Dataset` class to handle tokenized inputs and labels. It then initializes a `DistilBertTokenizer` from HuggingFace, tokenizes the train and test text data, and creates instances of the custom dataset for both train and validation sets. The tokenized data includes padding and truncation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\nclass CustomDataset(TorchDataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n        if self.labels:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\n\n# Define tokenizer.\ntokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n\nX_train_tokenized = tokenizer(list(X_train.text), padding=True, truncation=True, max_length=256)\nX_test_tokenized = tokenizer(list(X_test.text), padding=True, truncation=True, max_length=256)\n\ntrain_dataset = CustomDataset(X_train_tokenized, y_train.values.tolist())\nval_dataset = CustomDataset(X_test_tokenized, y_test.values.tolist())\n```\n\n----------------------------------------\n\nTITLE: Displaying or Saving the Giskard RAGReport in Python\nDESCRIPTION: Shows how to display the generated `RAGReport` object directly in a notebook environment using `display(report)` or save it as an HTML file using `report.to_html()`. Assumes a `RAGReport` object named `report` has already been generated from `giskard.rag.evaluate`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndisplay(report)  # if you are working in a notebook\n\n# or save the report as an HTML file\nreport.to_html(\"rag_eval_report.html\")\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Classification Metric: Frequency-Weighted Accuracy in Python\nDESCRIPTION: This snippet creates a custom classification metric for Giskard by subclassing 'ClassificationPerformanceMetric' and implementing '_calculate_metric', which computes frequency-weighted accuracy. Uses numpy, sklearn, and Giskard's performance.metrics. The metric gives class-weighted accuracy by label frequencies. Inputs: true and predicted labels and a model with classification label metadata. Output: a single accuracy float. Limitations: expects properly formatted input arrays and a model with label metadata.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.scanner.performance.metrics import (\n    ClassificationPerformanceMetric,\n    MetricResult\n)\nimport numpy as np\nimport sklearn.metrics\n\nclass FrequencyWeightedAccuracy(ClassificationPerformanceMetric):\n    name = \"Frequency-Weighted Accuracy\"\n    greater_is_better = True\n    has_binary_counts = False\n\n    def _calculate_metric(\n        self,\n        y_true: np.ndarray,\n        y_pred: np.ndarray,\n        model: BaseModel\n    ):\n        labels = model.meta.classification_labels\n        label_to_id = {label: i for i, label in enumerate(labels)}\n        y_true_ids = np.array([label_to_id[label] for label in y_true])\n        class_counts = np.bincount(y_true_ids, minlength=len(labels))\n        total_count = np.sum(class_counts)\n\n        weighted_sum = 0\n\n        for i in range(len(labels)):\n            class_mask = y_true_ids == i\n            if not np.any(class_mask):\n                continue\n            label_acc = sklearn.metrics.accuracy_score(y_true[class_mask], y_pred[class_mask])\n            weighted_sum += (class_counts[i] / total_count) * label_acc\n        return weighted_sum\n```\n\n----------------------------------------\n\nTITLE: Converting Giskard Test Set to Pandas DataFrame - Python\nDESCRIPTION: Converts a Giskard test set object, presumably loaded previously, into a pandas DataFrame. This allows users to leverage pandas functionalities for data manipulation, analysis, and visualization. Requires the pandas library.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf = loaded_testset.to_pandas()\n```\n\n----------------------------------------\n\nTITLE: Downloading IPCC Report in Markdown Format (wget)\nDESCRIPTION: Downloads the IPCC report in Markdown format from a specified URL and saves it to the `config/kb/ipcc.md` file. This Markdown file serves as the knowledge base for the NeMo Guardrails application to answer questions about climate change.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!wget https://gist.githubusercontent.com/mattbit/d5af6c1230bafed1dddc8d1bfe78c19c/raw/294b69d88cd0e2ec3472e63eaf7cf1abd3e43b09/ipcc.md -O config/kb/ipcc.md\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Dependency using Pip\nDESCRIPTION: Installs or upgrades the Giskard Python library using the `pip` package manager within a Jupyter environment. This command ensures the necessary Giskard package is available for the subsequent steps.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Train and Test Sets - Python\nDESCRIPTION: Splits the loaded and preprocessed pandas DataFrame into training and testing sets for features (text) and target (sentiment labels) using scikit-learn's `train_test_split`. It uses the predefined random seed for reproducibility.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nX_train, X_test, y_train, y_test = train_test_split(\n    data[[TEXT_COLUMN_NAME]], data[TARGET_COLUMN_NAME], random_state=RANDOM_SEED\n)\n```\n\n----------------------------------------\n\nTITLE: Requesting SHAP Explanation for a Record via Copilot (Python)\nDESCRIPTION: Uses the 'talk' method to request an explanation (via SHAP values) for the prediction of a specific record. The Copilot returns the most influential features and their contributions based on the preconfigured model's internals. Input: user question about feature importance; Output: textual SHAP explanation. Requires prior model and dataset setup.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model.talk(question=\"What was important for the survival result of Minahan, Miss. Daisy E?\", dataset=giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Wrapping QA Chain and Dataset with Giskard in Python\nDESCRIPTION: Creates a Giskard Model wrapper for the RetrievalQA chain, specifying model type, name, description, and input feature names. Also defines a small test Dataset using pandas DataFrame, suitable for subsequent vulnerability scanning. Prerequisites include having the climate_qa_chain and all related libraries installed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\nimport pandas as pd\n\npd.set_option(\"display.max_colwidth\", None)\n\nmodel = gsk.Model(\n    climate_qa_chain,\n    model_type=\"text_generation\",\n    name=\"Climate Change Question Answering\",\n    description=\"This model answers any question about climate change based on IPCC reports\",\n    feature_names=[\"query\"],\n)\n\ndataset = gsk.Dataset(\n    pd.DataFrame(\n        {\n            \"query\": [\n                \"According to the IPCC report, what are key risks in the Europe?\",\n                \"Is sea level rise avoidable? When will it stop?\",\n            ]\n        }\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard library via pip - Python\nDESCRIPTION: Installs or upgrades the Giskard package using the Jupyter notebook's magic %pip command. No Python code execution is performed beyond package installation. Ensure your notebook kernel is running and internet access is available.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n\n```\n\n----------------------------------------\n\nTITLE: Installing Langchain, AVIDtools, and Related Dependencies in Python\nDESCRIPTION: Installs langchain, langchain-community, langchain-openai, pypdf, faiss-cpu, tiktoken, and avidtools, which are needed for constructing retrieval-based LLM pipelines and processing PDF documents. This prepares the execution environment for building QA systems and exporting findings to AVID. Executable in Jupyter or command-line.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install langchain langchain-community langchain-openai pypdf faiss-cpu tiktoken avidtools\n```\n\n----------------------------------------\n\nTITLE: Downloading and Loading Dataset from Remote URL in Python\nDESCRIPTION: Defines helper functions to download the insurance dataset file from the specified URL to a local directory, ensuring necessary directories exist. The dataset is then loaded into a pandas DataFrame for further processing. Handles checking for data presence to avoid redundant downloads.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef download_data(**kwargs) -> pd.DataFrame:\n    \"\"\"Download the dataset using URL.\"\"\"\n    fetch_demo_data(DATA_URL, DATA_PATH)\n    _df = pd.read_csv(DATA_PATH, **kwargs)\n    return _df\n```\n\n----------------------------------------\n\nTITLE: Installing MLflow and Giskard LLM Dependencies (Python)\nDESCRIPTION: Installs the `mlflow` library and the `giskard` library with its LLM-specific extras using the pip package manager. The `-q` flag ensures a quiet installation with minimal output. This is a prerequisite for using the MLflow-Giskard integration.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install mlflow \"giskard[llm]\" -q\n```\n\n----------------------------------------\n\nTITLE: Running Pre-commit Hooks Manually to Fix Issues Using Shell\nDESCRIPTION: This snippet runs all pre-commit hooks manually on all files using the shell command `pre-commit run --all-files`. It helps fix simple problems detected by the quality checks without needing to commit changes. This is useful if builds fail due to pre-commit validations and allows automatic fixing where supported.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/community/contribution_guidelines/dev-environment.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npre-commit run --all-files\n```\n\n----------------------------------------\n\nTITLE: Creating a custom Giskard model wrapper for sentiment analysis\nDESCRIPTION: Defines a custom Giskard Model wrapper class to enable vulnerability scanning with the DistilBERT sentiment classifier, handling preprocessing and prediction.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass GiskardModelCustomWrapper(Model):\n    \"\"\"Custom giskard model wrapper.\"\"\"\n\n    def model_predict(self, df: pd.DataFrame) -> np.ndarray:\n        \"\"\"Perform inference using overwritten prediction logic.\"\"\"\n        cleaned_df = text_preprocessor(df)\n        data_loader = create_dataloader(cleaned_df)\n        predicted_probabilities = infer_predictions(self.model, data_loader)\n        return predicted_probabilities\n```\n\n----------------------------------------\n\nTITLE: Documenting HuggingFaceModel class\nDESCRIPTION: This code snippet uses the `automodule` directive in Sphinx to automatically generate documentation for the `HuggingFaceModel` class within the `giskard.models.huggingface` module.  The `:members:` option ensures that all public members (methods, attributes) of the class are included in the documentation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/models/integrations/huggingface.rst#_snippet_0\n\nLANGUAGE: Sphinx\nCODE:\n```\n.. automodule:: giskard.models.huggingface\n    :members: HuggingFaceModel\n```\n\n----------------------------------------\n\nTITLE: AWS Bedrock LLM Client Configuration\nDESCRIPTION: Establishes environment variables for AWS credentials and region, then assigns models in giskard for AWS Bedrock. Dependencies are os and giskard, enabling integration with AWS's API for vulnerability detection in specific models.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"AWS_ACCESS_KEY_ID\"] = \"\" # \"my-aws-access-key\"\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\" # \"my-aws-secret-access-key\"\nos.environ[\"AWS_REGION_NAME\"] = \"\" # \"us-west-2\"\n\ngiskard.llm.set_llm_model(\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\", disable_structured_output=True)\n giskard.llm.set_embedding_model(\"bedrock/amazon.titan-embed-image-v1\")\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for M5 Sales Prediction Project\nDESCRIPTION: Imports necessary Python libraries including data handling, ML modeling, and Giskard testing framework components for the sales prediction project.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom typing import Tuple\nfrom urllib.request import urlretrieve\n\nimport pandas as pd\nfrom lightgbm import LGBMRegressor\nfrom sklearn import preprocessing\nfrom sklearn.metrics import r2_score\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results - Python\nDESCRIPTION: This code displays the results of the vulnerability scan generated by Giskard. The results are displayed using the display function. It provides a detailed report of the detected vulnerabilities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Customizing and Saving AVID Report to JSON in Python\nDESCRIPTION: Manually assigns developer and deployer fields to the AVID report and saves it as a JSON file, ready for submission or further processing. Essential for ensuring required metadata is populated prior to official reporting. Operates on a single AVID report object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nreport.affects.developer = \"OpenAI\"\nreport.affects.deployer = \"Climate Bot Technologies Inc.\"\n\nreport.save(\"avid_report.json\")\n```\n\n----------------------------------------\n\nTITLE: Rendering Issue Summaries in Jinja2\nDESCRIPTION: This Jinja2 snippet iterates through a list of groups and, for each group, displays the group name and the number of issues it contains. It uses HTML `<details>` and `<summary>` tags to create collapsible sections for each group of issues. It iterates over each issue in a group, displaying the issue's description.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/giskard/visualization/templates/scan_report/markdown/huggingface.md#_snippet_0\n\nLANGUAGE: Jinja2\nCODE:\n```\n{% for view in groups -%}\n<!-- issue -->\n<details>\n<summary>👉{{ view.group.name }} issues ({{ view.issues|length }})</summary>\n\n{% for issue in view.issues -%}\n{{ issue.description }}\n\n| Level {% if issue.slicing_fn %}| Data slice {% endif %}| Metric {% if issue.transformation_fn %}| Transformation {% endif %}| Deviation |\n|-------{% if issue.slicing_fn %}|------------{% endif %}|--------{% if issue.transformation_fn %}|----------------{% endif %}|-----------|\n| <span style=\"color:{% if issue.level.value == \"major\" %} red {% else %} orange {% endif %} \"> {{ issue.level.value }} {% if issue.level.value == \"major\" %} 🔴 {% else %} 🟡 {% endif %} </span> {% if issue.slicing_fn %}| {{ issue.slicing_fn }} {% endif %}| {% if \"metric\" in issue.meta %}{{ issue.meta.metric }} = {{ issue.meta.metric_value|format_metric }}{% else %} \"—\" {% endif %} {% if issue.transformation_fn %}| {{ issue.transformation_fn }} {% endif %}| {{ issue.meta[\"deviation\"] if \"deviation\" in issue.meta else \"—\" }} |\n\n{% if issue.taxonomy %}\n<h4 class=\"font-bold text-sm mt-4\">Taxonomy</h4>\n{% for tag in issue.taxonomy %}\n<span class=\"inline-block bg-blue-300/25 text-zinc-100 px-2 py-0.5 rounded-sm text-sm mr-1 my-2\">\n    {{ tag }}\n</span>\n{% endfor %}\n<br />\n{% endif %}\n\n<!-- examples -->\n<details>\n<summary> 🔍✨Examples</summary>\n\n{% if issue.examples(3)|length %}\n{{ issue.examples(issue.meta.num_examples if \"num_examples\" in issue.meta else 3).to_markdown(\nindex=not issue.meta.hide_index if \"hide_index\" in issue.meta\nelse True)|replace(\"\\\\n\", \"<br>\")|safe }}\n{% endif %}\n</details>\n\n{% endfor %}\n\n</details>\n{% endfor -%}\n<br />\n```\n\n----------------------------------------\n\nTITLE: Installing Project-Specific Dependencies\nDESCRIPTION: This snippet installs the project-specific dependencies for the tutorial, including langchain, langchain-community, langchain-openai, and tiktoken.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!pip install langchain langchain-community langchain-openai tiktoken\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard and Dependencies\nDESCRIPTION: This snippet installs the necessary Python packages, including Giskard with LLM support, Langchain, Langchain-community, Langchain-openai, and tiktoken.  It upgrades Giskard if it's already installed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"giskard[llm]\" --upgrade\n```\n\n----------------------------------------\n\nTITLE: Creating QA Chain\nDESCRIPTION: Creates the RetrievalQA chain using LangChain. This snippet initializes the OpenAI language model using the `LLM_NAME` constant, creates a `PromptTemplate` using the `PROMPT_TEMPLATE` constant and the vector store retrieved by the get_context_storage function. Finally the chain is tested by asking a simple question about google.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Create the chain.\nllm = OpenAI(model_name=LLM_NAME, temperature=0)\nprompt_template = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"])\ngoogle_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=get_context_storage().as_retriever(), prompt=prompt_template)\n\n# Test the chain.\ngoogle_qa_chain(\"What is Google\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping a LangChain LLMChain\nDESCRIPTION: Demonstrates how to directly wrap a LangChain `LLMChain` object in giskard.Model. This allows for seamless testing and vulnerability assessment of chain-based models, specifying name, description, and feature_names.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nfrom langchain import OpenAI, LLMChain, PromptTemplate\n\n# Create the chain.\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\nprompt = PromptTemplate(template=\"You are a generic helpful assistant. Please answer this question: {question}\",\n                        input_variables=[\"question\"])\nchain = LLMChain(llm=llm, prompt=prompt)\n\n# Create a giskard.Model object. Don’t forget to fill the `name` and `description`\n# parameters: they will be used by our scan to generate domain-specific tests.\ngiskard_model = giskard.Model(\n    model=chain,  # our langchain.LLMChain object\n    model_type=\"text_generation\",\n    name=\"My Generic Assistant\",\n    description=\"A generic assistant that kindly answers questions.\",\n    feature_names=[\"question\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Defining NeMo Guardrails Scenarios Using Colang Language\nDESCRIPTION: This Colang snippet provides an example of defining a conversational rail that restricts the bot from assisting with illegal activities. It defines a user intent ('ask about illegal activities'), phrases to trigger this intent, a bot response that declines to answer, and a flow linking the user request to the bot refusal. This ad hoc modelling language is the core for expressing constraints and behavior enforcement in NeMo Guardrails.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/index.md#_snippet_2\n\nLANGUAGE: colang\nCODE:\n```\ndefine user ask about illegal activities\n  \"Can you help me stealing a car?\"\n\ndefine flow\n  user ask about illegal activities\n  bot decline to answer\n```\n\n----------------------------------------\n\nTITLE: Defining Langchain ChatPromptTemplates for Keyword Extraction and Product Description in Python\nDESCRIPTION: Creates two prompt templates for use with langchain's chat models. The first template prompts the model to generate 5-10 relevant keywords based on a product name. The second template generates a creative, SEO-compliant multi-paragraph product description with emojis using the product name and previously generated keywords. Both use system and human message roles and support prompt chaining inputs.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.prompts import ChatPromptTemplate\n\n# First prompt to generate keywords related to the product name\nkeywords_prompt_template = ChatPromptTemplate.from_messages([\n    (\"system\", \"\"\"You are a helpful assistant that generate a CSV list of keywords related to a product name\n\n    Example Format:\n    PRODUCT NAME: product name here\n    KEYWORDS: keywords separated by commas here\n\n    Generate five to ten keywords that would increase product visibility. Begin!\n\n    \"\"\"),\n    (\"human\", \"\"\"\n    PRODUCT NAME: {product_name}\n    KEYWORDS:\"\"\")])\n\n# Second chained prompt to generate a description based on the given keywords from the first prompt\nproduct_prompt_template = ChatPromptTemplate.from_messages([\n    (\"system\", \"\"\"As a Product Description Generator, generate a multi paragraph rich text product description with emojis based on the information provided in the product name and keywords separated by commas.\n\n    Example Format:\n    PRODUCT NAME: product name here\n    KEYWORDS: keywords separated by commas here\n    PRODUCT DESCRIPTION: product description here\n\n    Generate a product description that is creative and SEO compliant. Emojis should be added to make product description look appealing. Begin!\n\n    \"\"\"),\n    (\"human\", \"\"\"\n    PRODUCT NAME: {product_name}\n    KEYWORDS: {keywords}\n    PRODUCT DESCRIPTION:\n        \"\"\")])\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard Scan Report (report)\nDESCRIPTION: Displays the Giskard scan report. This provides a summary of the vulnerabilities found in the NeMo Guardrails application, specifically focusing on harmfulness.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nreport\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Python Library\nDESCRIPTION: This command installs or upgrades the Giskard open-source Python library using pip. It is the necessary first step before using Giskard functionalities in your environment. This command is typically run in a notebook or command-line environment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for LLM QA System in Python\nDESCRIPTION: Establishes constant values for report URL, model name, primary input column, and prompt template. The prompt template is an instruction for the LLM specifying its behavior and formatting of QA prompts. Constants enable easier code maintainability and configuration. The PROMPT_TEMPLATE uses placeholders for context and question.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nIPCC_REPORT_URL = \"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\"\n\nLLM_NAME = \"gpt-3.5-turbo-instruct\"\n\nTEXT_COLUMN_NAME = \"query\"\n\nPROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard.\nYour task is to answer common questions on climate change.\nYou will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023).\nPlease provide short and clear answers based on the provided context. Be polite and helpful.\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nYour answer:\n\"\"\"\n\n```\n\n----------------------------------------\n\nTITLE: Running Giskard Scan (gsk.scan)\nDESCRIPTION: Runs a Giskard scan on the wrapped NeMo Guardrails application using the configured dataset. The scan is configured to only check for 'harmfulness' vulnerabilities. The results of the scan are stored in the `report` variable.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nreport = gsk.scan(gsk_model, gsk_dataset, only=[\"harmfulness\"])\n```\n\n----------------------------------------\n\nTITLE: Splitting dataset into train and test sets\nDESCRIPTION: This code splits the preprocessed dataset into training and testing subsets using a fixed random seed for reproducibility. It separates features from the target variable for subsequent modeling.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nX_train, X_test, Y_train, Y_test = train_test_split(\n    churn_df.drop(columns=TARGET_COLUMN_NAME), churn_df[TARGET_COLUMN_NAME], random_state=RANDOM_SEED\n)\n```\n\n----------------------------------------\n\nTITLE: Generating a RAG Test Set Using Giskard in Python\nDESCRIPTION: This code example shows how to generate a RAG test set with the generate_testset function from the Giskard library using a knowledge base instance. It specifies the total number of questions, optionally sets the language, and provides an agent description to improve question relevance. The test set contains multiple question types targeting different RAG components as described in the toolkit.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Generate a testset with 10 questions & answers for each question types (this will take a while)\ntestset = generate_testset(\n    knowledge_base,\n    num_questions=60,\n    language='en',  # optional, we'll auto detect if not provided\n    agent_description=\"A customer support chatbot for company X\", # helps generating better questions\n)\n```\n\n----------------------------------------\n\nTITLE: Rendering Vulnerability Assessment Rows with Jinja2 in Python\nDESCRIPTION: This Jinja2 template snippet iterates over nested 'groups' containing vulnerability issues, outputting a Markdown table row for each issue with relevant details. It conditionally renders metric values and transformation functions using inline if statements and template filters, and handles the absence of certain data fields gracefully. Dependencies include a Jinja2 rendering environment set up in Python and the presence of context variables ('groups'). The snippet expects data structures with keys like 'group', 'issues', 'level', and 'meta', and outputs formatted Markdown table rows for each evaluated vulnerability.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/giskard/visualization/templates/scan_report/markdown/summary.md#_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{%- for view in groups -%}\n{% for issue in view.issues %}\n| {{ view.group.name }} | {{ issue.level.value }} | {{ issue.slicing_fn if issue.slicing_fn else \"—\" }} | {% if \"metric\" in issue.meta %}{{ issue.meta.metric }} = {{ issue.meta.metric_value|format_metric }}{% else %} \"—\" {% endif %} | {{ issue.transformation_fn if issue.transformation_fn else \"—\" }} | {{ issue.meta[\"deviation\"] if \"deviation\" in issue.meta else \"—\" }} | {{ issue.description }} |\n{%- endfor -%}\n{%- endfor -%}\n```\n\n----------------------------------------\n\nTITLE: Generating and Running a Giskard Test Suite from Scan Results in Python\nDESCRIPTION: This snippet creates a test suite from Giskard scan findings and executes it, allowing users to turn identified model issues into persistent, actionable tests. Inputs include the scan_results object; outputs are test results that validate model issues locally. The code expects the Giskard library and previously-produced scan results.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\ntest_suite = scan_results.generate_test_suite(\"My first test suite\")\n\n# You can run the test suite locally to verify that it reproduces the issues\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Scanning Model and Displaying Report with Giskard (Python)\nDESCRIPTION: Runs Giskard's scan method on the wrapped model and dataset, producing a scan report object that can be viewed within a notebook. Requires prior wrapping of both dataset and model. Inputs: Giskard Model and Dataset objects. Output: scan_results (report object) ready to visualize.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_nlp/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nscan_results = giskard.scan(giskard_model, giskard_dataset)\ndisplay(scan_results)  # in your notebook\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results\nDESCRIPTION: This snippet displays the results of the Giskard scan, allowing the user to review detected vulnerabilities. The `display` function likely presents the scan findings in a user-friendly format, such as a table or a detailed report. The provided content doesn't specify where `display` is from, it is assumed to be a method to visualize results.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Building the RAG pipeline\nDESCRIPTION: This code defines a RAG pipeline function that answers a query using GPT and a DataFrame of relevant texts and embeddings. It retrieves the relevant context using `query_message`, constructs the message for the OpenAI API, calls the OpenAI ChatCompletion API, and returns the response.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.read_csv(ARTICLES_EMBEDDINGS_URL)\ndf[\"embedding\"] = df[\"embedding\"].apply(ast.literal_eval)\n\n\ndef ask(query: str, db: pd.DataFrame = df, model: str = LLM_MODEL, token_budget: int = 4096 - 500) -> str:\n    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n    message = query_message(query, db, model=model, token_budget=token_budget)\n\n    messages = [\n        {\"role\": \"system\", \"content\": \"You answer questions about the 2022 Winter Olympics.\"},\n        {\"role\": \"user\", \"content\": message},\n    ]\n\n    response = openai.ChatCompletion.create(model=model, messages=messages, temperature=0, timeout=30)\n\n    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n    return response_message\n\n\n# Validate the RAG pipeline.\nask(\"Which athletes won the gold medal in curling at the 2022 Winter Olympics?\")\n```\n\n----------------------------------------\n\nTITLE: Defining Preprocessing Pipeline with scikit-learn ColumnTransformer in Python\nDESCRIPTION: Creates a column transformer that applies standard scaling to numerical columns and one-hot encoding to categorical columns, handling unknown categories gracefully. This preprocessing pipeline enables consistent feature transformations during model training and inference.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"scaler\", StandardScaler(), NUMERICAL_COLS),\n        (\"one_hot_encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), CATEGORICAL_COLS),\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Suite with Dataset as Input (Giskard, Python)\nDESCRIPTION: This snippet illustrates creating a Giskard test suite designed to accept the dataset as an external input. Tests are added to the suite specifying parameters like the model and reference dataset, but omitting the `actual_dataset`. This configuration allows the same suite to be executed against different production datasets, enabling monitoring or drift detection workflows. It shows running the suite with two different dataset batches.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom giskard import demo, Model, Dataset, testing, Suite, slicing_function\n\n\nmodel, df = demo.titanic()\n\nwrapped_model = Model(model=model, model_type=\"classification\")\n\n\n@slicing_function(name=\"females\")\ndef slice_sex(row: pd.Series):\n    return row[\"Sex\"] == \"female\"\n\n\n# Create our golden dataset. Golden dataset are used as the reference dataset. It can be your training set\ngolden = Dataset(\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n# The first test focuses specifically on females to make sure there is no drift with respect to the golden dataset\n# Note that neither tests specify the actual_dataset parameter\nsuite = (\n    Suite()\n    .add_test(\n        testing.test_drift_prediction_ks(\n            model=wrapped_model,\n            slicing_function=slice_sex,\n            reference_dataset=golden,\n            classification_label=\"yes\",\n        )\n    )\n    .add_test(\n        testing.test_drift_prediction_ks(\n            model=wrapped_model, reference_dataset=golden, classification_label=\"yes\"\n        )\n    )\n)\n\n\n# batch_1 can be a first batch of production data\nbatch_1 = Dataset(\n    df=df.head(100),\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n# Run the suite by specifying our model and display the results\nsuite_results = suite.run(actual_dataset=batch_1)\npassed_1, results_1 = suite_results.passed, suite_results.results\n\n# batch_2 can be a second batch of production data\nbatch_2 = Dataset(\n    df=df.tail(100),\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n# Run the suite with our new version and check if the results improved\nsuite_results = suite.run(actual_dataset=batch_2)\npassed_2, results_2 = suite_results.passed, suite_results.results\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard\nDESCRIPTION: This command installs the Giskard library using pip and upgrades it to the latest version.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for LLM QA Pipeline in Python\nDESCRIPTION: Imports standard and third-party Python modules required for the pipeline, including OpenAI API, pandas for data manipulation, LangChain utilities for building RAG models, and Giskard components for testing and evaluation. These imports are prerequisites for all subsequent steps and require the listed dependencies to be installed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport openai\nimport pandas as pd\nfrom langchain.chains import RetrievalQA\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.prompts import PromptTemplate\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain_openai import OpenAI, OpenAIEmbeddings\n\nfrom giskard import Dataset, Model, scan\n\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with toctree\nDESCRIPTION: This code snippet uses the toctree directive to create a table of contents for the Community section. It specifies the caption, maximum depth, and hides the toctree in the rendered output.  The listed files are the pages linked under the Community section.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/index.md#_snippet_6\n\nLANGUAGE: rst\nCODE:\n```\n```\n:caption: Community\n:maxdepth: 1\n:hidden:\n\ncommunity/discord/index\ncommunity/github/index\ncommunity/contribution_guidelines/index\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard library with pip\nDESCRIPTION: This code snippet installs the Giskard library and its dependencies using pip. It ensures the latest version is installed and is necessary for running subsequent Giskard-related operations.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Data and Model\nDESCRIPTION: This snippet defines various constants to enhance code readability, maintainability, and reproducibility. These constants specify the random seed for consistent results, the test data ratio, columns to drop from the dataset, categorical and numerical feature names, the target column, and data paths for loading the dataset. The constants ensure that the same configuration is used throughout the notebook.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants\nRANDOM_SEED = 0\nTEST_RATIO = 0.2\n\nDROP_FEATURES = [\"education\", \"native-country\", \"occupation\", \"marital-status\", \"educational-num\"]\n\nCATEGORICAL_FEATURES = [\"workclass\", \"relationship\", \"race\", \"gender\"]\n\nNUMERICAL_FEATURES = [\n    \"age\",\n    \"fnlwgt\",\n    \"capital-gain\",\n    \"capital-loss\",\n    \"hours-per-week\",\n]\n\nTARGET_COLUMN = \"income\"\n\n# Paths.\nDATA_URL = (\n    \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/wage_classification_dataset-adult.csv.tar.gz\"\n)\nDATA_PATH = Path.home() / \".giskard\" / \"wage_classification_dataset\" / \"adult.csv.tar.gz\"\n```\n\n----------------------------------------\n\nTITLE: Adding Custom F1 Score Test to RoBERTa Sentiment Model Test Suite\nDESCRIPTION: Extends the test suite by adding a specific F1 score test that checks if the model's F1 score is above a threshold of 0.7, then runs the updated test suite.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Downloading and preprocessing Tripadvisor reviews dataset\nDESCRIPTION: Implements functions to download, clean, and preprocess the Tripadvisor reviews dataset, including emoji removal, text normalization, and label creation from ratings.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nnltk.download(\"stopwords\")\n\n\n# Define data download and pre-processing functions\ndef fetch_demo_data(url: str, file: Path) -> None:\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        urlretrieve(url, file)\n\n\ndef create_label(x: int) -> int:\n    \"\"\"Map rating to the label.\"\"\"\n    if x in [1, 2]:\n        return 0\n    if x == 3:\n        return 1\n    if x in [4, 5]:\n        return 2\n\n\nclass TextCleaner:\n    \"\"\"Helper class to preprocess review's text.\"\"\"\n\n    def __init__(self, clean_pattern: str = r\"[^A-ZĞÜŞİÖÇIa-zğüı'şöç0-9.\\\"',()]\"):\n        \"\"\"Constructor of the class.\"\"\"\n        self.clean_pattern = clean_pattern\n\n    def __call__(self, text: Union[str, list]) -> List[List[str]]:\n        \"\"\"Perform cleaning.\"\"\"\n        if isinstance(text, str):\n            docs = [[text]]\n\n        if isinstance(text, list):\n            docs = text\n\n        text = [[re.sub(self.clean_pattern, \" \", sentence) for sentence in sentences] for sentences in docs]\n        return text\n\n\ndef remove_emoji(data: str) -> str:\n    \"\"\"Remove emoji from the text.\"\"\"\n    emoji = re.compile(\n        \"[\"\n        \"\\U0001f600-\\U0001f64f\"\n        \"\\U0001f300-\\U0001f5ff\"\n        \"\\U0001f680-\\U0001f6ff\"\n        \"\\U0001f1e0-\\U0001f1ff\"\n        \"\\U00002500-\\U00002bef\"\n        \"\\U00002702-\\U000027b0\"\n        \"\\U00002702-\\U000027b0\"\n        \"\\U000024c2-\\U0001f251\"\n        \"\\U0001f926-\\U0001f937\"\n        \"\\U00010000-\\U0010ffff\"\n        \"\\u2640-\\u2642\"\n        \"\\u2600-\\u2b55\"\n        \"\\u200d\"\n        \"\\u23cf\"\n        \"\\u23e9\"\n        \"\\u231a\"\n        \"\\ufe0f\"\n        \"\\u3030\"\n        \"]+\",\n        re.UNICODE,\n    )\n    return re.sub(emoji, \"\", data)\n\n\nregex = re.compile(\"[%s]\" % re.escape(string.punctuation))\n\n\ndef remove_punctuation(text: str) -> str:\n    \"\"\"Remove punctuation from the text.\"\"\"\n    text = regex.sub(\" \", text)\n    return text\n\n\ntext_cleaner = TextCleaner()\n\n\ndef text_preprocessor(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Preprocess text.\"\"\"\n    # Remove emoji.\n    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(lambda x: remove_emoji(x))\n\n    # Lower.\n    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(lambda x: x.lower())\n\n    # Clean.\n    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(lambda x: text_cleaner(x)[0][0])\n\n    # Remove punctuation.\n    df[TEXT_COLUMN_NAME] = df[TEXT_COLUMN_NAME].apply(lambda x: remove_punctuation(x))\n\n    return df\n\n\ndef load_dataset() -> pd.DataFrame:\n    # Download dataset\n    fetch_demo_data(DATA_URL.format(DATA_FILE_NAME), DATA_PATH / DATA_FILE_NAME)\n    df = pd.read_csv(DATA_PATH / DATA_FILE_NAME, nrows=MAX_NUM_ROWS)\n    # Obtain labels for our task.\n    df[TARGET_COLUMN_NAME] = df.Rating.apply(lambda x: create_label(x))\n    df.drop(columns=\"Rating\", inplace=True)\n    df = text_preprocessor(df)\n    return df\n```\n\n----------------------------------------\n\nTITLE: Loading Model\nDESCRIPTION: This code loads the Titanic model pipeline using `demo.titanic_pipeline()`. This function returns a preprocessing function and a classifier model, which will be used to define the Giskard model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npreprocessing_function, classifier = demo.titanic_pipeline()\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with toctree\nDESCRIPTION: This code snippet uses the toctree directive to create a table of contents for the Getting Started section.  It specifies the caption, maximum depth, and hides the toctree in the rendered output.  The listed files are the pages linked under the Getting Started section.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/index.md#_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n```\n:caption: Getting Started\n:maxdepth: 1\n:hidden:\n\ngetting_started/index\ngetting_started/quickstart/index\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Library\nDESCRIPTION: This snippet installs the Giskard library, upgrading it if it's already present. The dependency is essential for using Giskard's functionalities to test and evaluate machine learning models.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset for Landmark Detection\nDESCRIPTION: This Python code demonstrates how to wrap a dataset for landmark detection using the `DataIteratorBase` class. It requires overriding `idx_sampler`, `get_image`, `get_label`, and optionally `get_meta`. The `get_label` method should return an array of landmarks. The input is a dataset of images and landmark annotations. The output is a wrapped dataset object. The function `cv2.imread()` is used for reading the images, which requires OpenCV.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_vision/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard_vision.core.dataloaders.base import DataIteratorBase\nfrom giskard_vision.core.dataloaders.meta import MetaData\nfrom giskard_vision.core.issues import EthicalIssueMeta, PerformanceIssueMeta\n\n\nclass DataLoaderFaceLandmarkDetection(DataIteratorBase):\n\n    @property\n    def idx_sampler(self) -> np.ndarray:\n        return list(range(len(self.image_paths))\n\n    @classmethod\n    def get_image(self, idx: int) -> np.ndarray:\n        return cv2.imread(str(self.image_paths[idx]))\n\n    @classmethod\n    def get_label(self, idx: int) -> Optional[np.ndarray]:\n        return np.array(..., dtype=float)\n    \n    @classmethod\n    def get_meta(self, idx: int) -> Optional[MetaData]:\n        default_meta = super().get_meta() # To load default metadata\n        return MetaData(\n            data={\n                **default_meta.data,\n                'meta1': 'value1',\n                'meta2': 'value2',\n                'categorical_meta1': 'cat_value1',\n                'categorical_meta2': 'cat_value2'\n            },\n            categories=default_meta.categories+['categorical_meta1', 'categorical_meta2'],\n            issue_groups={\n                **default_meta.issue_groups,\n                'meta1': PerformanceIssueMeta,\n                'meta2': EthicalIssueMeta,\n                'categorical_meta1': PerformanceIssueMeta,\n                'categorical_meta2': EthicalIssueMeta,\n            }\n        )\n\n\ngiskard_dataset = DataLoaderFaceLandmarkDetection()\n```\n\n----------------------------------------\n\nTITLE: Configuring and building the DistilBERT sentiment classifier\nDESCRIPTION: Defines a configuration class for the DistilBERT model and creates functions to prepare data loaders and run inference on the sentiment classification model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass Config:\n    \"\"\"Configuration of Distill-BERT model.\"\"\"\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    batch_size = 128\n    seq_length = 150\n    add_special_tokens = True\n    return_attention_mask = True\n    pad_to_max_length = True\n    return_tensors = \"pt\"\n\n\n# Load tokenizer.\ntokenizer = DistilBertTokenizer.from_pretrained(PRETRAINED_WEIGHTS_NAME)\n\n# Load model.\ngiskard_model = DistilBertForSequenceClassification.from_pretrained(\n    PRETRAINED_WEIGHTS_NAME, num_labels=3, output_attentions=False, output_hidden_states=False\n).to(Config.device)\n\n\ndef create_dataloader(df: pd.DataFrame) -> DataLoader:\n    \"\"\"Create dataloader object with input data.\"\"\"\n\n    def _create_dataset(encoded_data: dict) -> TensorDataset:\n        \"\"\"Create dataset object with input data.\"\"\"\n        input_ids = encoded_data[\"input_ids\"]\n        attention_masks = encoded_data[\"attention_mask\"]\n        return TensorDataset(input_ids, attention_masks)\n\n    # Tokenize data.\n    encoded_data = tokenizer.batch_encode_plus(\n        df.Review.values,\n        add_special_tokens=Config.add_special_tokens,\n        return_attention_mask=Config.return_attention_mask,\n        pad_to_max_length=Config.pad_to_max_length,\n        max_length=Config.seq_length,\n        return_tensors=Config.return_tensors,\n    )\n\n    # Create dataset object.\n    dataset = _create_dataset(encoded_data)\n\n    # Create and return dataloader object.\n    return DataLoader(dataset, batch_size=Config.batch_size)\n\n\ndef infer_predictions(_model: torch.nn.Module, _dataloader: DataLoader) -> np.ndarray:\n    \"\"\"Perform inference using given model on given dataloader.\"\"\"\n    _model.eval()\n\n    y_pred = list()\n    for batch in _dataloader:\n        batch = tuple(b.to(Config.device) for b in batch)\n        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1]}\n\n        with torch.no_grad():\n            outputs = _model(**inputs)\n\n        probs = torch.nn.functional.softmax(outputs.logits).detach().cpu().numpy()\n        y_pred.append(probs)\n\n    y_pred = np.concatenate(y_pred, axis=0)\n    return y_pred\n\n\ntext_cleaner = TextCleaner()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom LLM Client for Giskard in Python\nDESCRIPTION: This example shows how to create a custom LLM client integrating an external LLM service with Giskard. It subclasses litellm.CustomLLM to define a completion method making an authenticated POST request to a custom endpoint. The snippet registers this client handler with litellm and configures Giskard to use it with an API key stored in environment variables.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport requests\nfrom typing import Optional\n\nimport litellm\nimport giskard\n\nclass MyCustomLLM(litellm.CustomLLM):\n    def completion(self, messages: str, api_key: Optional[str] = None, **kwargs) -> litellm.ModelResponse:\n        api_key = api_key or os.environ.get(\"MY_SECRET_KEY\")\n        if api_key is None:\n            raise litellm.AuthenticationError(\"`api_key` was not provided\")\n\n        response = requests.post(\n            \"https://www.my-custom-llm.ai/chat/completion\",\n            json={\"messages\": messages},\n            headers={\"Authorization\": api_key},\n        )\n\n        return litellm.ModelResponse(**response.json())\n\nos.eviron[\"MY_SECRET_KEY\"] = \"\" # \"my-secret-key\"\n\nmy_custom_llm = MyCustomLLM()\n\nlitellm.custom_provider_map = [  \n    {\"provider\": \"my-custom-llm-endpoint\", \"custom_handler\": my_custom_llm}\n]\n\napi_key = os.environ[\"MY_SECRET_KEY\"]\n\ngiskard.llm.set_llm_model(\"my-custom-llm-endpoint/my-custom-model\", api_key=api_key)\n```\n\n----------------------------------------\n\nTITLE: Installing Weights & Biases\nDESCRIPTION: Shell command for installing the wandb Python package, which is required for integrating with Weights & Biases.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/index.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install wandb\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with toctree\nDESCRIPTION: This code snippet uses the toctree directive to create a table of contents for the API Reference section. It specifies the caption, maximum depth, and hides the toctree in the rendered output. The listed files are the pages linked under the API Reference section.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/index.md#_snippet_5\n\nLANGUAGE: rst\nCODE:\n```\n```\n:caption: API Reference\n:maxdepth: 1\n:hidden:\n\nreference/models/index\nreference/datasets/index\nreference/scan/index\nreference/rag-toolset/index\nreference/tests/index\nreference/slicing-functions/index\nreference/transformation-functions/index\nreference/suite/index\n```\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Test from Giskard Catalog\nDESCRIPTION: Demonstrates how to extend the generated test suite by adding a test directly from the Giskard catalog, specifically `testing.test_f1`. This test checks if the F1 score of the model on the dataset is above a specified `threshold`. After adding the test, the updated test suite is run again to include the results of the new test.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Writing NeMo Guardrails Configuration File (%%writefile)\nDESCRIPTION: Writes the `config.yml` file, which defines the instructions, models, and sample conversations for the NeMo Guardrails application. The configuration sets up a chatbot that answers questions based on the 2023 IPCC Climate Change report using the `gpt-3.5-turbo-instruct` model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n%%writefile config/config.yml\ninstructions:\n- content: 'Below is a conversation between the Climate Assistant bot and a user.\\n\n    The bot provides short and precise answers based on its context.'\n  type: general\nmodels:\n- engine: openai\n  model: gpt-3.5-turbo-instruct\n  type: main\nsample_conversation: \"user \\\"Hi!\\\"\\n  express greeting\\nbot express greeting\\n  \\\"Hello there! I am ClimateQA!\\\"\\nuser \\\"What can you do for me?\\\"\\n  ask about capabilities\\n  bot respond about capabilities\\n  \\\"I am a demo bot developed by Giskard to answer questions about climate change.\\n  Feel free to ask and I'll do my best \\\"\\n\"\n```\n\n----------------------------------------\n\nTITLE: Executing Performance Test with Slicing in Giskard Python\nDESCRIPTION: This snippet illustrates loading and running a performance test (`test_f1`) from the Giskard catalog. It includes setting up `Model` and `Dataset` objects and defining a custom `slicing_function` to apply the test to a specific data subset (females). The test calculates the F1 score for the specified slice.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport pandas as pd\nfrom giskard import demo, Model, Dataset, testing, slicing_function\n\n\nmodel, df = demo.titanic()\n\nwrapped_model = Model(model=model, model_type=\"classification\")\nwrapped_dataset = Dataset(\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n\n# Create a slicing function on females to create more domain-specific tests\n@slicing_function(name=\"females\")\ndef female_slice(row: pd.Series):\n    return row[\"Sex\"] == \"female\"\n\n\nresult = testing.test_f1(\n    dataset=wrapped_dataset,\n    model=wrapped_model,\n    slicing_function=female_slice,\n).execute()\n\nprint(f\"result: {result.passed} with metric {result.metric}\")\n```\n\n----------------------------------------\n\nTITLE: Testing Giskard Model Prediction - Python\nDESCRIPTION: Demonstrates how to create a small Giskard dataset for sample QA queries, then runs the model's predict method to ensure proper integration and functioning. Accepts a Pandas DataFrame of questions; outputs predictions accessible via .prediction. Useful for initial model validation before full vulnerability analysis.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Optional: let’s test that the wrapped model works\nexamples = [\n    \"According to the IPCC report, what are key risks in the Europe?\",\n    \"Is sea level rise avoidable? When will it stop?\",\n]\ngiskard_dataset = giskard.Dataset(pd.DataFrame({\"question\": examples}), target=None)\n\nprint(giskard_model.predict(giskard_dataset).prediction)\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard Scan Results\nDESCRIPTION: Uses the `display()` function (typically available in Jupyter environments) to render the `results` object obtained from the `giskard.scan`. This provides an interactive visualization of the detected vulnerabilities and issues.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Running a Test Suite with a Different Model\nDESCRIPTION: This example illustrates how to wrap a different model and execute an existing test suite against it, useful for comparative testing or model replacement scenarios. It refers to relevant documentation for detailed usage.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Wrap a different model\ngiskard_model_2 = giskard.Model(...)\n\n# Run the test suite with the new model\ntest_suite.run(model=giskard_model_2)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Classification Model (Prediction Function)\nDESCRIPTION: This code snippet demonstrates how to wrap a classification model using a prediction function. The prediction function, `prediction_function`, preprocesses input data and returns predicted probabilities. The `giskard.Model` class is used to wrap the prediction function, specifying model type, classification labels, feature names, and an optional name. The order of `classification_labels` MUST match the output order of the prediction function.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df):\n    preprocessed_df = demo_data_processing_function(df) # The pre-processor can be a pipeline of one-hot encoding, imputer, scaler, etc.\n    return demo_classification_model.predict_proba(preprocessed_df)\n\ngiskard_model = giskard.Model(\n    model=prediction_function,\n    model_type=\"classification\",\n    classification_labels=demo_classification_model.classes_,  # The order MUST be identical to the prediction_function's output order\n    feature_names=['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'],  # Default: all columns of your dataset\n    name=\"titanic_model\", # Optional: give it a name to identify it in metadata\n    # classification_threshold=0.5, # Optional: Default: 0.5\n)\n```\n\n----------------------------------------\n\nTITLE: Adding and Running a Custom R2 Test in Giskard Test Suite\nDESCRIPTION: Customizes the existing test suite by adding a specific test from the Giskard testing catalog. `testing.test_r2` is added, configured to check if the model's R-squared score on the provided dataset is above a threshold of 0.7. The `add_test` method returns the suite, and `.run()` executes all tests within the suite, including the newly added R2 check.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_r2(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Wrapping a Langchain Agent for Giskard Scan in Python\nDESCRIPTION: Prepares the previously built Langchain QA agent for Giskard analysis. It defines a wrapper function `model_predict` that takes a Pandas DataFrame containing questions and returns a list of answers generated by the agent's `run` method. It then instantiates a `giskard.Model` object, providing the wrapper function, model type (`text_generation`), name, description, and feature names (`question`), making it ready for the Giskard scan.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\nimport pandas as pd\n\ndef model_predict(df: pd.DataFrame):\n    \"\"\"Wraps the LLM call in a simple Python function.\n\n    The function takes a pandas.DataFrame containing the input variables needed\n    by your model, and must return a list of the outputs (one for each row).\n    \"\"\"\n    return [climate_qa_chain.run({\"query\": question}) for question in df[\"question\"]]\n\n# Don’t forget to fill the `name` and `description`: they are used by Giskard\n# to generate domain-specific tests.\ngiskard_model = giskard.Model(\n    model=model_predict,\n    model_type=\"text_generation\",\n    name=\"Climate Change Question Answering\",\n    description=\"This model answers any question about climate change based on IPCC reports\",\n    feature_names=[\"question\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning Model for Vulnerabilities with Giskard - Python\nDESCRIPTION: Initiates an automated vulnerability scan on the wrapped Giskard model using the wrapped Giskard dataset. Giskard analyzes the model and data to detect potential issues like performance bias, unrobustness, and more. The results object contains findings from the scan.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\nresults = scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Running a Full Giskard Test Suite with Pytest Parametrization in Python\nDESCRIPTION: Demonstrates how to run a complete Giskard test suite via pytest using parametrization. This approach generates descriptive test names based on the test name and parameters, making test results more readable.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/pytest/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsuite = (\n    Suite(\n        default_params={\n            \"model\": wrapped_model,\n            \"dataset\": wrapped_dataset,\n        }\n    )\n    .add_test(testing.test_f1(threshold=.6))\n    .add_test(testing.test_accuracy(threshold=1)) # Certain to fail\n)\n\n\n@pytest.mark.parametrize(\"test_partial\", suite.to_unittest(), ids=lambda t: t.fullname)\ndef test_giskard(test_partial):\n    test_partial.assert_()\n```\n\n----------------------------------------\n\nTITLE: Installing Langchain and Related Dependencies\nDESCRIPTION: Installs necessary Python libraries required for the Giskard quickstart example using pip. This includes `langchain`, `langchain-community`, `langchain-openai` for building the LLM agent, `tiktoken` for tokenization, and `pypdf` (pinned to version <=3.17.0) for loading PDF documents.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npip install langchain langchain-community langchain-openai tiktoken \"pypdf<=3.17.0\"\n```\n\n----------------------------------------\n\nTITLE: Wrapping Regression Model (Prediction Function)\nDESCRIPTION: This snippet shows wrapping a regression model using a prediction function. The prediction function preprocesses input data, and the model returns the regression predictions.  `numpy` is imported for squeezing the prediction output. The `giskard.Model` is instantiated, specifying the model, model type, and feature names.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_tabular/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\ndef prediction_function(df):\n    preprocessed_df = demo_data_processing_function(df) # The pre-processor can be a pipeline of one-hot encoding, imputer, scaler, etc.\n    return np.squeeze(demo_regression_model.predict(preprocessed_df))\n\ngiskard_model = giskard.Model(\n    model=prediction_function,\n    model_type=\"regression\",\n    feature_names=['x'],  # Default: all columns of your dataset\n    name=\"linear_model\", # Optional: give it a name to identify it in metadata\n)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing M5 Sales Prediction Data in Python\nDESCRIPTION: Transforms the raw M5 sales data by melting the sales dataframe, merging with calendar and price data, handling missing values, and encoding categorical features to prepare for model training.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess_data(calendar_df: pd.DataFrame, prices_df: pd.DataFrame, sales_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Preprocess and create df with the whole data.\"\"\"\n    # Melt the sales data: translate columnar demand representation into single target vector.\n    data = pd.melt(\n        sales_df,\n        id_vars=[ID_COLUMN, \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n        var_name=\"day\",\n        value_name=TARGET_COLUMN,\n    )\n    data = data.drop(columns=ID_COLUMN)\n\n    # Add the calendar data.\n    calendar_df = calendar_df.drop([\"weekday\", \"wday\", \"month\", \"year\"], axis=1)\n    data = pd.merge(data, calendar_df, how=\"left\", left_on=[\"day\"], right_on=[\"d\"])\n    data = data.drop(columns=[\"d\", \"day\"])\n\n    # Add the sell price data.\n    data = data.merge(prices_df, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], how=\"left\")\n\n    # Fill NaN values.\n    nan_features = [\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]\n    for feature in nan_features:\n        data[feature] = data[feature].fillna(\"unknown\")\n\n    # Encode categorical features.\n    to_encode = [\n        \"item_id\",\n        \"dept_id\",\n        \"cat_id\",\n        \"store_id\",\n        \"state_id\",\n        \"event_name_1\",\n        \"event_type_1\",\n        \"event_name_2\",\n        \"event_type_2\",\n    ]\n    for feature in to_encode:\n        encoder = preprocessing.LabelEncoder()\n        data[feature] = encoder.fit_transform(data[feature])\n\n    print(f\"Final dataset has {data.shape[0]} rows and {data.shape[1]} columns\")\n    return data\n\n\ndf = preprocess_data(*dfs)\n```\n\n----------------------------------------\n\nTITLE: Setting up Azure OpenAI LLM Client using completion parameters in Python\nDESCRIPTION: This snippet configures Azure OpenAI LLM client by passing API base URL, API version, and either an API key or Azure Active Directory token as parameters. It sets the LLM and embedding models using giskard.llm methods with explicit authentication credentials. This approach does not rely solely on environment variables and provides flexibility for runtime configuration. Dependencies include giskard and proper Azure OpenAI credentials. The inputs are strings representing API endpoint, version, and authentication tokens. The output is a set LLM and embedding model ready for inference.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport giskard\n\napi_base = \"\" # \"https://example-endpoint.openai.azure.com\"\napi_version = \"\" # \"2023-05-15\"\n\n# Using api_key\napi_key = \"\" # \"my-azure-api-key\"\ngiskard.llm.set_llm_model(\"azure/<your_llm_name>\", api_base=api_base, api_version=api_version, api_key=api_key)\ngiskard.llm.set_embedding_model(\"azure/<your_embed_model_name>\", api_base=api_base, api_version=api_version, api_key=api_key)\n\n# Using azure_ad_token\nazure_ad_token = \"\" # \"my-azure-ad-token\"\ngiskard.llm.set_llm_model(\"azure/<your_llm_name>\", api_base=api_base, api_version=api_version, azure_ad_token=azure_ad_token)\ngiskard.llm.set_embedding_model(\"azure/<your_embed_model_name>\", api_base=api_base, api_version=api_version, azure_ad_token=azure_ad_token)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preprocessing Amazon Review Dataset - Python\nDESCRIPTION: Defines functions to fetch the dataset from a remote URL, load it as a pandas DataFrame, and preprocess it by selecting relevant columns, handling null characters, extracting ratings, filtering by minimum votes, and encoding the target variable. Dependencies: pathlib, pandas, numpy. Input: remote URL and local Path, DataFrame; Output: cleaned DataFrame. Requires the dataset to be present at specified URLs and paths.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef download_data(**kwargs) -> pd.DataFrame:\n    \"\"\"Download the dataset using URL.\"\"\"\n    fetch_demo_data(DATA_URL, DATA_PATH)\n    _df = pd.read_json(DATA_PATH, lines=True, **kwargs)\n    return _df\n\n\ndef preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Perform data-preprocessing steps.\"\"\"\n    print(f\"Start data preprocessing...\")\n\n    # Select columns.\n    df = df[[\"reviewText\", \"helpful\"]]\n\n    # Remove Null-characters (x00) from the dataset.\n    df.reviewText = df.reviewText.apply(lambda x: x.replace(\"\\x00\", \"\"))\n\n    # Extract numbers of helpful and total votes.\n    df[\"helpful_ratings\"] = df.helpful.apply(lambda x: x[0])\n    df[\"total_ratings\"] = df.helpful.apply(lambda x: x[1])\n\n    # Filter unreasonable comments.\n    df = df[df.total_ratings > 10]\n\n    # Create target column.\n    df[TARGET_NAME] = np.where((df.helpful_ratings / df.total_ratings) > TARGET_THRESHOLD, 1, 0).astype(int)\n\n    # Delete columns we don't need anymore.\n    df.drop(columns=[\"helpful\", \"helpful_ratings\", \"total_ratings\"], inplace=True)\n\n    print(\"Data preprocessing finished!\")\n\n    return df\n\n```\n\n----------------------------------------\n\nTITLE: Setting Pandas Chained Assignment Options - Python\nDESCRIPTION: Disables chained assignment warning in pandas, which otherwise arises when setting values on a copy of a DataFrame slice. Ensures cleaner notebook output but use caution to avoid unintended side effects in data manipulation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Disable chained assignment warning.\npd.options.mode.chained_assignment = None\n\n```\n\n----------------------------------------\n\nTITLE: Importing Required Python Libraries\nDESCRIPTION: Imports necessary libraries for data manipulation (pandas), machine learning (sklearn components like ColumnTransformer, SimpleImputer, LogisticRegression, train_test_split, Pipeline, OneHotEncoder, StandardScaler), evaluation (classification_report), and Giskard's functionalities (Model, Dataset, scan, testing).\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nfrom giskard import Model, Dataset, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Displaying the scan results\nDESCRIPTION: This snippet displays the results of the Giskard scan, providing a report of potential vulnerabilities identified in the model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Initializing Context Storage\nDESCRIPTION: Defines a function `get_context_storage` that initializes a vector storage (FAISS) of embedded Google answers.  It uses a `RecursiveCharacterTextSplitter` to split the answers into chunks, then uses OpenAI embeddings to create document embeddings and stores these in a FAISS vector store.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef get_context_storage() -> FAISS:\n    \"\"\"Initialize a vector storage of embedded Google answers (context).\"\"\"\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100, add_start_index=True)\n    docs = text_splitter.split_documents(text_splitter.create_documents(answers))\n    db = FAISS.from_documents(\n        docs, OpenAIEmbeddings()\n    )\n    return db\n```\n\n----------------------------------------\n\nTITLE: Testing the RAG Model with Sample Questions (Python)\nDESCRIPTION: Imports the `pandas` library and creates a DataFrame `df_example` containing sample questions. It then calls the function associated with the 'gpt-3.5-turbo-instruct' model from the `models` dictionary, passing the last row of the DataFrame as input, and prints the generated answer ('result'). This verifies the RAG pipeline is functional.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\ndf_example = pd.DataFrame({\n    \"query\": [\n        \"According to the IPCC report, what are key risks in the Europe?\",\n        \"Is sea level rise avoidable? When will it stop?\"\n    ]\n})\n\nprint(models[\"gpt-3.5-turbo-instruct\"](df_example.tail(1)))\n```\n\n----------------------------------------\n\nTITLE: Loading Hotel Review Data into Pandas DataFrame\nDESCRIPTION: Calls the previously defined `load_data` function to load the hotel reviews dataset. It specifically loads only the first 1000 rows (`nrows=1000`) into the `reviews_df` pandas DataFrame.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nreviews_df = load_data(nrows=1000)\n```\n\n----------------------------------------\n\nTITLE: AI Quality Copilot 'talk' API Method Signature (Python)\nDESCRIPTION: Documents the signature and expected usage of the 'talk' method on Giskard models, enabling natural language queries for predictions, explanations, metrics, and performance issues. The method accepts a user question, dataset, optional scan report, and optional conversational context, returning a structured result. Designed for dynamic interaction with ML models using Python code.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef talk(self, question: str, dataset: Dataset, scan_report: ScanReport = None, context: str = \"\") -> TalkResult:\n        \"\"\"Perform the 'talk' to the model.\n\n        Given `question`, allows to ask the model about prediction result, explanation, model performance, issues, etc.\n\n        Parameters\n        ----------\n        question : str\n            User input query.\n        dataset : Dataset\n            Giskard Dataset to be analysed by the 'talk'.\n        context : str\n            Context of the previous 'talk' results. Necessary to keep context between sequential 'talk' calls.\n        scan_report : ScanReport\n            Giskard Scan Report to be analysed by the 'talk'.\n        \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing the Dataset - Python\nDESCRIPTION: Loads the Amazon reviews data file using the previously defined download and preprocess functions, resulting in a cleaned DataFrame suitable for modeling. Input: None, uses pre-defined constants; Output: DataFrame stored in 'reviews_df'. Prerequisite: defined functions and available dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nreviews_df = download_data()\nreviews_df = preprocess_data(reviews_df)\n\n```\n\n----------------------------------------\n\nTITLE: Wrapping and Evaluating a RAG Agent with Giskard in Python\nDESCRIPTION: Defines a wrapper function `get_answer_fn` for a RAG agent, accepting a question string and optional history list. It then demonstrates using `giskard.rag.evaluate` to assess the agent's correctness against a provided test set and knowledge base, generating a `RAGReport`. Requires the `giskard` library and pre-defined `testset` and `knowledge_base` objects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag import evaluate\n\n# Wrap your RAG model\ndef get_answer_fn(question: str, history=None) -> str:\n    \"\"\"A function representing your RAG agent.\"\"\"\n    # Format appropriately the history for your RAG agent\n    messages = history if history else []\n    messages.append({\"role\": \"user\", \"content\": question})\n\n    # Get the answer\n    answer = get_answer_from_agent(messages)  # could be langchain, llama_index, etc.\n\n    return answer\n\n\n# Run the evaluation and get a report\nreport = evaluate(get_answer_fn, testset=testset, knowledge_base=knowledge_base)\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Package in Python\nDESCRIPTION: Installs the Giskard package using pip to enable model testing and vulnerability scanning capabilities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard Dataset (Python)\nDESCRIPTION: Illustrates how to wrap a raw pandas DataFrame (typically validation or test data) using Giskard's Dataset class for subsequent analysis and scanning. Requires the Giskard Python library and a pandas DataFrame. The DataFrame ('df') must include the ground truth variable (specified with 'target'), while additional columns can serve as metadata. Optional parameters include a dataset name, categorical columns, and type specification. Inputs: pandas.DataFrame, 'target' (string). Outputs: Giskard Dataset object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_nlp/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Wrap your Pandas DataFrame with Giskard.Dataset (validation or test set)\ngiskard_dataset = giskard.Dataset(\n    df=df,  # A pandas.DataFrame containing raw data (before pre-processing) and including ground truth variable.\n    target=\"label\",  # Ground truth variable\n    name=\"Tweets with sentiment\", # Optional: Give a name to your dataset\n)\n```\n\n----------------------------------------\n\nTITLE: Modifying RAG Agent Wrapper for RAGAS Metrics in Python\nDESCRIPTION: Updates the `get_answer_fn` wrapper function to return a `giskard.rag.AgentAnswer` object instead of a simple string. This object includes both the agent's answer (`message`) and the retrieved documents (`documents`), which are necessary inputs for computing certain RAGAS metrics like context recall. Requires the `giskard` library.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag import AgentAnswer\n\ndef get_answer_fn(question: str, history=None) -> str:\n    \"\"\"A function representing your RAG agent.\"\"\"\n    # Format appropriately the history for your RAG agent\n    messages = history if history else []\n    messages.append({\"role\": \"user\", \"content\": question})\n\n    # Get the answer and the documents\n    agent_output = get_answer_from_agent(messages)\n\n    # Following llama_index syntax, you can get the answer and the retrieved documents\n    answer = agent_output.text\n    documents = agent_output.source_nodes\n\n    # Instead of returning a simple string, we return the AgentAnswer object which\n    # allows us to specify the retrieved context which is used by RAGAS metrics\n    return AgentAnswer(\n        message=answer,\n        documents=documents\n    )\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard and Giskard-Vision Libraries in Python\nDESCRIPTION: Installs the necessary Python packages 'giskard' and 'giskard-vision' required for object detection vulnerability testing. This snippet utilizes pip within a Jupyter notebook environment to fetch and install the libraries, enabling subsequent model and dataset loading.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_object_detection.ipynb#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n%pip install giskard giskard-vision\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Regression and Model Testing in Python\nDESCRIPTION: Imports essential Python modules and packages including data manipulation tools like pandas, LightGBM regressor for modeling, scikit-learn utilities for preprocessing and evaluation, and Giskard components for dataset and model wrapping as well as scanning and testing functionalities. This setup prepares the environment for all subsequent model building and validation steps.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport warnings\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\n\nimport pandas as pd\nfrom absl import logging\nfrom lightgbm import LGBMRegressor\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard and Dependencies - Python\nDESCRIPTION: This snippet installs the necessary Python packages for the project, including Giskard with LLM support and project-specific dependencies like OpenAI. The `--upgrade` flag ensures that the packages are updated to the latest versions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"giskard[llm]\" --upgrade\n```\n\n----------------------------------------\n\nTITLE: Adding a Custom Test to the Test Suite\nDESCRIPTION: Adds a custom test, specifically `test_f1`, to the generated test suite. This test checks if the F1 score of the model is above a specified threshold. The `test_f1` function from the Giskard library, along with the model, dataset, and the desired threshold, are passed to `test_suite.add_test()`. The `.run()` method is then called to execute the test and evaluate the model's performance against the F1 score criterion. This allows for extending the tests to include custom or more specific checks.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results\nDESCRIPTION: Displays the results of the Giskard scan, which includes detected vulnerabilities, along with related metrics. This is essential for understanding the model's weaknesses and potential areas for improvement.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Drug Classification Dataset\nDESCRIPTION: Loads the drug classification dataset and applies numerical binning to convert continuous features (age and Na_to_K) into categorical features using the previously defined functions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf_drug = load_data()\ndf_drug = bin_numerical(df_drug)\n```\n\n----------------------------------------\n\nTITLE: Logging Giskard Objects to MLflow (MlflowClient)\nDESCRIPTION: This snippet shows how to log Giskard objects into MLflow using the `MlflowClient`. It demonstrates an alternative approach to log objects, which may be preferred in scenarios where direct run access is not available, like when integrating within a pre-existing workflow that uses the client. It assumes the existence of valid Giskard objects like `giskard_model`, `giskard_dataset`, `scan_results`, and `test_suite_results`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom mlflow import MlflowClient\n\nclient = MlflowClient()\nexperiment_id = \\\"0\\\"\nrun = client.create_run(experiment_id)\n\ngiskard_model.to_mlflow(client, run.info.run_id)\ngiskard_dataset.to_mlflow(client, run.info.run_id)\nscan_results.to_mlflow(client, run.info.run_id)\ntest_suite_results.to_mlflow(client, run.info.run_id)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Custom Model Class with Giskard Model (Python)\nDESCRIPTION: Shows how to subclass giskard.Model for model object wrapping, customizing 'model_predict' to support raw DataFrame input and return classification probabilities. The object supports common ML frameworks (scikit-learn, catboost, pytorch, tensorflow, huggingface), or falls back to cloudpickle for serialization. Inputs include the model object, model type, and classification labels; optional parameters cover feature names, thresholds, preprocessing and postprocessing functions. Outputs: ready-to-scan wrapped Giskard model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_nlp/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass MyCustomModel(giskard.Model):\n    def model_predict(self, df):\n        preprocessed_df = demo_data_processing_function(df)\n        return self.model.predict_proba(preprocessed_df)\n\ngiskard_model = MyCustomModel(\n    model=demo_classification_model,\n    model_type=\"classification\",\n    classification_labels=demo_classification_model.classes_,  # Their order MUST be identical to the prediction_function's output order\n    feature_names=[TEXT_COLUMN],  # Default: all columns of your dataset\n    name=\"Tweets sentiment classification\", # Optional: give it a name to identify it in metadata\n    # classification_threshold=0.5, # Optional: Default: 0.5\n    # model_postprocessing_function=None, # Optional\n    # **kwargs # Additional model-specific arguments\n)\n```\n\n----------------------------------------\n\nTITLE: Install AVID Tools - Bash\nDESCRIPTION: This snippet installs the `avidtools` package using pip. This package is a prerequisite for exporting Giskard scan reports as AVID reports. Executing this command installs the necessary tools in the current environment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/index.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install avidtools\n```\n\n----------------------------------------\n\nTITLE: Wrapping and Validating Keras Model with Giskard in Python\nDESCRIPTION: Defines a wrapper prediction function incorporating all required preprocessing and tokenization, then constructs a Giskard Model for compatibility with Giskard's vulnerability scanning. The code also cross-validates the wrapper output against standard accuracy scoring. Requires prior definitions of classifier, tokenize, prepare_text, and giskard_dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef prediction_function(df: pd.DataFrame) -> np.ndarray:\n    \"\"\"Define a prediction function for giskard.Model.\"\"\"\n    tokens = tokenize(prepare_text(df))\n    return classifier.predict(tokens, verbose=0)\n\n\ngiskard_model = Model(\n    model=prediction_function,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"fake_real_news_classification\",  # Optional.\n    feature_names=[\"title\", TEXT_COLUMN_NAME],  # Default: all columns of your dataset.\n    classification_labels=[0, 1],  # Their order MUST be identical to the prediction_function's output order.\n    # classification_threshold=0.5  # Default: 0.5\n)\n\n# Validate wrapped model.\nY_test_pred_wrapper = giskard_model.predict(giskard_dataset).prediction\nwrapped_test_metric = accuracy_score(Y_test, Y_test_pred_wrapper)\nprint(f\"Wrapped test accuracy: {wrapped_test_metric: .4f}\")\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini LLM Client with Giskard in Python\nDESCRIPTION: This snippet configures Giskard to use Gemini LLM and embedding models by setting the Gemini API key environment variable and specifying the model names.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"GEMINI_API_KEY\"] = \"\" # \"my-gemini-api-key\"\n\ngiskard.llm.set_llm_model(\"gemini/gemini-1.5-pro\")\ngiskard.llm.set_embedding_model(\"gemini/text-embedding-004\")\n```\n\n----------------------------------------\n\nTITLE: Export Giskard Scan Report to JSONL AVID - Python\nDESCRIPTION: This Python code snippet exports a Giskard scan report directly to a JSONL file, where each line represents an AVID report. It uses the `to_avid()` method with a file name as an argument. This allows for easy storage and sharing of vulnerability reports in a standard format. The file name is specified as 'avid_report.jsonl'.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\n# Write the AVID reports to a JSONL file\nscan_report.to_avid(\"avid_report.jsonl\")\n```\n\n----------------------------------------\n\nTITLE: Querying Performance Issues and Biases via Copilot (Python)\nDESCRIPTION: Requests a summary of model performance issues and potential biases from the Copilot using the scan report. The agent analyzes the provided report and dataset to return detailed descriptions of vulnerabilities, such as robustness and overconfidence issues, in plain English. Prerequisites: completed scan report and dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model.talk(question=\"Does the model has any performance issues or biases?\", dataset=giskard_dataset, scan_report=result)\n```\n\n----------------------------------------\n\nTITLE: Data Loading and Preprocessing Functions\nDESCRIPTION: Contains helper functions for fetching and preprocessing the drug classification dataset, including binning of numerical features like age and Na_to_K ratio into categorical variables.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef load_data() -> pd.DataFrame:\n    \"\"\"Load data.\"\"\"\n    fetch_demo_data(DATA_URL, DATA_PATH)\n    df = pd.read_csv(DATA_PATH)\n    return df\n\n\ndef bin_numerical(df: pd.DataFrame) -> np.ndarray:\n    \"\"\"Perform numerical features binning.\"\"\"\n\n    def _bin_age(_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Bin age feature.\"\"\"\n        _df.Age = pd.cut(_df.Age, bins=AGE_BINS, labels=AGE_CATEGORIES)\n        return _df\n\n    def _bin_na_to_k(_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Bin Na_to_K feature.\"\"\"\n        _df.Na_to_K = pd.cut(_df.Na_to_K, bins=NA_TO_K_BINS, labels=NA_TO_K_CATEGORIES)\n        return _df\n\n    df = df.copy()\n    df = _bin_age(df)\n    df = _bin_na_to_k(df)\n\n    return df\n```\n\n----------------------------------------\n\nTITLE: Loading and Freezing HuggingFace Model - Python\nDESCRIPTION: Loads a pre-trained `DistilBertForSequenceClassification` model from HuggingFace. It then sets the model to training mode and iterates through its base model's parameters to freeze them, preventing their weights from being updated during training.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\nmodel = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME).train()\n\n# Freeze 'DistillBert' feature extraction module.\nfor param in model.base_model.parameters():\n    param.requires_grad = False\n```\n\n----------------------------------------\n\nTITLE: Splitting Dataset into Training and Testing Sets\nDESCRIPTION: Splits the loaded data into training and testing sets using a specified random state for reproducibility. This split is crucial for evaluating the model's performance on unseen data and assessing its generalization capabilities. The `train_test_split` function from `sklearn.model_selection` is used. The `random_state` parameter ensures that the split is consistent across multiple runs.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntrain_df, test_df = train_test_split(reviews_df, random_state=RANDOM_STATE)\n```\n\n----------------------------------------\n\nTITLE: Performing Multiple Calculations with Giskard Talk (Python)\nDESCRIPTION: This Python snippet shows how to use the `giskard_model.talk` method to request multiple performance metrics (accuracy, f1, precision, recall) from the model in a single API call. It uses the `question` parameter to specify the tasks and the `dataset` parameter to provide the data context. The model agent leverages underlying tools to perform each calculation. Requires a `giskard_model` instance and a `giskard_dataset`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model.talk(question=\"Calculate accuracy, f1, precision ans recall scores of the model. Summarise the result in a table\", dataset=giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Creating Giskard Dataset for Model Testing\nDESCRIPTION: Wraps the validation dataset with Giskard's Dataset class to prepare it for vulnerability scanning, specifying the target column and identifying categorical features.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_val, Y_val], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,  # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN,  # Ground truth variable\n    name=\"M5 products timeseries dataset\",  # Optional\n    cat_columns=X_val.select_dtypes(\n        int\n    ).columns.tolist(),  # List of categorical columns. Optional, but is a MUST if available. Inferred automatically if not.\n)\n```\n\n----------------------------------------\n\nTITLE: Requesting Copilot Capabilities via 'talk' (Python)\nDESCRIPTION: Invokes the 'talk' method to inquire about the features supported by the AI Quality Copilot for the given model and dataset. No dataset processing is triggered; instead, the Copilot provides a descriptive summary of its abilities (e.g., prediction, SHAP explanation, metrics, performance scan). Input: question string and dataset. Output: string with capability list.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model.talk(question=\"What can you do?\", dataset=giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Training LGBM Regressor for M5 Sales Prediction\nDESCRIPTION: Builds and trains a LightGBM regression model with predefined parameters to predict product demand, then evaluates model performance using R2 score on both training and validation datasets.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nESTIMATOR_PARAMS = {\n    \"n_estimators\": 300,\n    \"seed\": 0,\n    \"n_jobs\": -1,\n    \"verbose\": -1,\n}\n\nregressor = LGBMRegressor(**ESTIMATOR_PARAMS)\nregressor.fit(X_train, Y_train)\n\n# Validate estimator.\ny_train_pred = regressor.predict(X_train)\ntrain_score = r2_score(Y_train, y_train_pred)\nprint(f\"Train R2-score: {train_score: .2f}\")\n\ny_val_pred = regressor.predict(X_val)\nval_score = r2_score(Y_val, y_val_pred)\nprint(f\"Val R2-score: {val_score: .2f}\")\n```\n\n----------------------------------------\n\nTITLE: Limiting Giskard Scan to Specific Model Features in Python\nDESCRIPTION: This snippet shows how to restrict a Giskard scan to a subset of model features by using the 'features' argument. This is useful in models with many features where only certain features require analysis. It requires Giskard, a loaded model and dataset. Inputs: 'my_model', 'my_dataset', and a list of feature names. Output is a scan report focused only on the specified features.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\n\nreport = gsk.scan(my_model, my_dataset, features=[\"feature_1\", \"feature_2\"])\n```\n\n----------------------------------------\n\nTITLE: Defining DataFrame-Level Transformation Function in Giskard Python\nDESCRIPTION: This snippet demonstrates defining a Giskard transformation function that processes an entire pandas DataFrame at once. Using `@transformation_function(row_level=False)`, the decorated function takes the DataFrame as its first argument and is expected to return a (potentially modified) DataFrame. The example modifies the 'Age' column for the whole dataset and applies it using the `dataset.transform()` method. Requires pandas and giskard libraries.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_transformations/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom giskard import transformation_function, demo, Dataset\n\n\n_, df = demo.titanic()\ndataset = Dataset(df=df, target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\n\n@transformation_function(row_level=False)\ndef my_func1(df: pd.DataFrame, offset: int):\n    df['Age'] = df['Age'] + offset\n    return df\n\n\ntransformed_dataset = dataset.transform(my_func1(offset=20))\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with Giskard\nDESCRIPTION: This snippet wraps the trained XGBoost model with Giskard's `Model` class. It specifies the model object, model type (classification), a name for the model, classification labels, and feature names. It then validates the model wrapping by making predictions on the wrapped dataset and printing a classification report using the wrapped predictions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=xgb,\n    # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"classification\",  # Either regression, classification or text_generation.\n    name=\"breast_cancer_xgboost\",  # Optional.\n    classification_labels=[0, 1],  # Their order MUST be identical to the prediction_function's output order.\n    feature_names=X_test.columns,  # Default: all columns of your dataset.\n)\n\n# Validate the model wrapping.\ny_test_pred_wrapped = giskard_model.predict(giskard_dataset).raw_prediction\nprint(classification_report(y_test, y_test_pred_wrapped))\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard for Sentiment Analysis\nDESCRIPTION: Creates a Giskard Dataset object from the preprocessed data, specifying the target column for sentiment classification to prepare for vulnerability scanning and testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ngiskard_dataset = Dataset(\n    df=raw_data,  # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN,  # Ground truth variable.\n    name=\"Tweets with sentiment\",  # Optional.\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Constants - Python\nDESCRIPTION: This code defines several constants used throughout the notebook. These include the URL for the dataset, the name of the text column, the prompt template for the LLM, and a random state for reproducibility.  These constants are used later to read and process the dataset and to feed data to the prompt.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nDATA_URL = \"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\"\n\nTEXT_COLUMN_NAME = \"text\"\n\nPROMPT_TEMPLATE = \"\"\"\n'{text}' \\n\\n \\nAs reader you have to critisize the authors of the article above starting now : I believe this article is really \\n\"\"\"\n\nRANDOM_STATE = 11\n```\n\n----------------------------------------\n\nTITLE: Scanning Tabular Models with Giskard in MLflow - Python\nDESCRIPTION: This Python snippet demonstrates how to load demo tabular models (sklearn Logistic Regression on Titanic), log them to MLflow using `mlflow.sklearn.log_model`, and evaluate them using the Giskard MLflow evaluator. It iterates through two models (`model1` and `model2`), starting a new MLflow run for each, logging the model with `predict_proba` as the pyfunc prediction function, and then running `mlflow.evaluate` with the Giskard evaluator configured for classification labels.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-tabular-example.ipynb#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport mlflow\nimport giskard\n\nfrom giskard import demo\nmodel1, df = demo.titanic(max_iter=5)\nmodel2, df = demo.titanic(max_iter=100)\n\nmodels = {\"model1\": model1, \"model2\": model2}\n\nfor model_name, model in models.items():\n    with mlflow.start_run(run_name=model_name) as run:\n        model_uri = mlflow.sklearn.log_model(model, model_name, pyfunc_predict_fn=\"predict_proba\").model_uri\n        mlflow.evaluate(model=model_uri, model_type=\"classifier\", data=df, targets=\"Survived\", evaluators=\"giskard\", evaluator_config={\"model_config\":   {\"classification_labels\": [\"no\", \"yes\"]}})\n\n```\n\n----------------------------------------\n\nTITLE: Creating a responsive grid layout for tutorial navigation in Markdown\nDESCRIPTION: Defines a responsive grid layout using Sphinx grid directives to display tutorial category cards. Each card contains a title with emoji and links to the corresponding index page, adapting to different screen sizes.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/tutorials/index.md#_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::::::{grid} 1 1 2 2\n\n\n::::{grid-item-card} <br/><h3>📚  LLM tutorials</h3>\n:text-align: center\n:link: llm_tutorials/index.html\n::::\n\n::::{grid-item-card} <br/><h3>🗄️  RAG tutorials</h3>\n:text-align: center\n:link: rag_tutorials/index.html\n::::\n\n::::{grid-item-card} <br/><h3>📊  Tabular tutorials</h3>\n:text-align: center\n:link: tabular_tutorials/index.html\n::::\n\n::::{grid-item-card} <br/><h3>🗣️ NLP tutorials</h3>\n:text-align: center\n:link: nlp_tutorials/index.html\n::::\n\n::::{grid-item-card} <br/><h3>📸 Vision tutorials</h3>\n:text-align: center\n:link: vision_tutorials/index.html\n::::\n```\n\n----------------------------------------\n\nTITLE: Creating FAISS Vector Store from PDF (Python)\nDESCRIPTION: Defines a function `get_context_storage` that downloads a PDF from `DATA_URL`, splits its content into chunks using `RecursiveCharacterTextSplitter`, generates embeddings using `OpenAIEmbeddings`, and stores the documents and their embeddings in a FAISS vector store. Requires the OpenAI API key to be set.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef get_context_storage() -> FAISS:\n    \"\"\"Initialize a vector storage with the context.\"\"\"\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n    docs = OnlinePDFLoader(DATA_URL).load_and_split(text_splitter)\n    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n    db = FAISS.from_documents(docs, embeddings)\n    return db\n```\n\n----------------------------------------\n\nTITLE: Defining Metrics and HuggingFace Trainer - Python\nDESCRIPTION: Defines a `compute_metrics` function to calculate macro F1 score from evaluation predictions (probabilities and true labels). It then sets up HuggingFace `TrainingArguments` with specified hyperparameters and initializes a `Trainer` instance using the model, arguments, datasets, and metrics function. It also removes default callbacks like Wandb, MLflow, and TensorBoard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\ndef compute_metrics(eval_pred):\n    probs, y_true = eval_pred\n    y_pred = np.argmax(probs, axis=1)\n\n    f1 = f1_score(y_true, y_pred, average=\"macro\")\n    return {\"f1\": f1}\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"output\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=1,\n    optim=\"adamw_torch\",\n    weight_decay=0.01,\n    save_strategy=\"no\",\n    disable_tqdm=True,\n    no_cuda=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.remove_callback(WandbCallback)\ntrainer.remove_callback(MLflowCallback)\ntrainer.remove_callback(TensorBoardCallback)\n```\n\n----------------------------------------\n\nTITLE: Generating Rails from Giskard Scan Report (report.generate_rails)\nDESCRIPTION: Generates NeMo Guardrails from the Giskard scan report and saves them to a file named `config/generated.co`. These generated rails are designed to mitigate the vulnerabilities identified during the scan, such as harmfulness.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nreport.generate_rails(\"config/generated.co\")\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Drug Classification Model\nDESCRIPTION: Defines constants used throughout the project, including random seed for reproducibility, target variable name, categorical bins for age and Na_to_K features, and data paths for loading the dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nRANDOM_SEED = 0\n\nTARGET_NAME = \"Drug\"\n\nAGE_BINS = [0, 19, 29, 39, 49, 59, 69, 80]\nAGE_CATEGORIES = [\"<20s\", \"20s\", \"30s\", \"40s\", \"50s\", \"60s\", \">60s\"]\n\nNA_TO_K_BINS = [0, 9, 19, 29, 50]\nNA_TO_K_CATEGORIES = [\"<10\", \"10-20\", \"20-30\", \">30\"]\n\n# Paths.\nDATA_URL = (\n    \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/drug_classification_dataset-drug200.csv.tar.gz\"\n)\nDATA_PATH = Path.home() / \".giskard\" / \"drug_classification_dataset\" / \"drug200.csv.tar.gz\"\n```\n\n----------------------------------------\n\nTITLE: Loading Data from AG_NEWS Dataset\nDESCRIPTION: Loads the training and testing data from the AG_NEWS dataset using torchtext.datasets.  This is the first step in data preparation, providing the raw data for the text classification task.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntrain_data, test_data = AG_NEWS()\n```\n\n----------------------------------------\n\nTITLE: Building and Evaluating XGBoost Model\nDESCRIPTION: This snippet initializes and trains an XGBoost classifier (`XGBClassifier`) with the training data. It then makes predictions on the test set and prints a classification report to evaluate the model's performance.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\n\n# Evaluation.\ny_test_pred = xgb.predict(X_test)\nprint(classification_report(y_test, y_test_pred))\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results\nDESCRIPTION: Displays the results of the vulnerability scan performed by Giskard, which provides insights into potential issues with the model that may need to be addressed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard - Python\nDESCRIPTION: This code wraps the preprocessed pandas DataFrame with Giskard's `Dataset` class.  This prepares the dataset for the vulnerability scan. The `target` parameter is set to `None` because the dataset is not used for a specific classification or regression task in this context.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ngiskard_dataset = Dataset(df_filtered, target=None)\n```\n\n----------------------------------------\n\nTITLE: Loading facial landmark detection model and dataset\nDESCRIPTION: Initializes the OpenCV facial landmark detection wrapper and loads a sample from the FFHQ dataset for testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_landmark_detection.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel = OpenCVWrapper()\ndataloader = get_ffhq()\n```\n\n----------------------------------------\n\nTITLE: Writing NeMo Guardrails Main Rail File (%%writefile)\nDESCRIPTION: Writes the `main.co` file, which defines the core rails and flows for the NeMo Guardrails application. This includes definitions for user and bot greetings, bot capabilities explanations, and question answering flows. These rails govern the conversation flow and ensure appropriate responses.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n%%writefile config/rails/main.co\ndefine user express greeting\n  \"Hello\"\n  \"Hi\"\n  \"Wassup?\"\n\ndefine bot express greeting\n  \"Hello there, I'm Climate QA!\"\n\ndefine flow greeting\n  user express greeting\n  bot express greeting\n\n\ndefine user ask capabilities\n  \"What can you do?\"\n  \"What can you help me with?\"\n  \"tell me what you can do\"\n  \"tell me about you\"\n\ndef bot explain capabilities\n  \"I am Climate QA, a demo bot developed by Giskard to answer questions concerning climate change, based on the latest IPCC report.\"\n\ndefine flow explain capabilities\n  user ask capabilities\n  bot explain capabilities\n\ndefine user ask question\n  \"What is climate change?\"\n  \"Will temperature increase more?\"\n  \"Will the ice at the poles melt completely?\"\n  \"What does the IPCC report say about climate?\"\n\ndefine flow question answering\n  user ask question\n  bot answer to question\n```\n\n----------------------------------------\n\nTITLE: Running Full Giskard Vulnerability Scan - Python\nDESCRIPTION: Performs a comprehensive vulnerability scan across all issue categories using Giskard's scan utility on the given model and dataset. Input is the wrapped Giskard Model and corresponding Dataset; output is a complete ScanReport covering harmfulness, hallucination, prompt injection, and more. This operation may take significant time depending on available compute and API speed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfull_report = giskard.scan(giskard_model, giskard_dataset)\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Model Training\nDESCRIPTION: Defines constants used throughout the code. These include the target column name, text column name, pretrained model name, random state for reproducibility, and data paths for loading the dataset. These constants streamline the code and facilitate easier modification and maintenance of the model-building process.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nTARGET_COLUMN = \"label\"\nTEXT_COLUMN = \"text\"\n\nPRETRAINED_WEIGHTS_NAME = \"distilbert-base-uncased\"\n\nRANDOM_STATE = 0\n\n# Paths.\nDATA_URL = \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/movie_review_sentiment_classification_dataset-train.jsonl.tar.gz\"\nDATA_PATH = Path.home() / \".giskard\" / \"tripadvisor_reviews_dataset\" / \"train.jsonl.tar.gz\"\n```\n\n----------------------------------------\n\nTITLE: Applying nest_asyncio in Python for Jupyter notebook compatibility\nDESCRIPTION: This snippet applies the nest_asyncio patch to enable nested asyncio event loops, which can resolve issues related to asynchronous execution in Jupyter notebooks when using embedding models or certain LLM interactions. It requires the nest_asyncio package and is intended to be run once to make asynchronous calls compatible with the notebook environment. Inputs: none; Outputs: patched event loop.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport nest_asyncio\nnest_asyncio.apply()\n```\n\n----------------------------------------\n\nTITLE: Creating a KnowledgeBase from a pandas DataFrame Using Giskard in Python\nDESCRIPTION: This snippet demonstrates loading knowledge base data from a CSV file into a pandas DataFrame, then initializing a Giskard KnowledgeBase instance using the DataFrame. It optionally specifies which DataFrame columns to use for knowledge base content, allowing control over relevant information for question generation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag import generate_testset, KnowledgeBase\n\n# Load your data and initialize the KnowledgeBase\ndf = pd.read_csv(\"path/to/your/knowledge_base.csv\")\n\nknowledge_base = KnowledgeBase.from_pandas(df, columns=[\"column_1\", \"column_2\"])\n```\n\n----------------------------------------\n\nTITLE: Example Usage: Generating Product Descriptions with GPT-3.5-turbo and Giskard Wrapped Models in Python\nDESCRIPTION: Demonstrates running predictions on the test dataset using the giskard wrapped 'gpt-3.5-turbo' model, logging outputs to the console, and initializing a W&B run for experiment tracking. The example iterates over product name inputs and prints corresponding generated product descriptions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport wandb\n\nrun = wandb.init(project=os.environ[\"WANDB_PROJECT\"], name=\"examples\")\npredictions = models[\"gpt-3.5-turbo\"][\"giskard\"].predict(dataset).prediction\nfor k, v in dataset.df.product_name.to_dict().items():\n    os.environ[\"WANDB_NAME\"] = \"examples_\" + str(k)\n    print(\"Example #\", k + 1)\n    print(\"product_name (input):\", v)\n    print(\"product_description (output):\", predictions[k])\n    print(\"--------------------------------------------------------------------\")\nrun.finish()\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard and LLM Dependencies - Python\nDESCRIPTION: Shows how to install Giskard with LLM support and all required libraries for the RAG QA pipeline, including langchain, faiss-cpu, OpenAI, and PDF utilities. This step must be run in your Python environment (e.g., Jupyter cell or terminal) before executing subsequent tutorial code. Expects an environment with pip and internet access.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_llm.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"giskard[llm]\" --upgrade\n```\n\nLANGUAGE: python\nCODE:\n```\n%pip install langchain langchain-community langchain-openai pypdf faiss-cpu openai tiktoken\n```\n\n----------------------------------------\n\nTITLE: Fetching and Downloading Data\nDESCRIPTION: This snippet defines and uses two functions to download and load the dataset from a specified URL. The `fetch_demo_data` function handles data download, creating the necessary directories if they don't exist and downloading the data using `urlretrieve`. The `download_data` function calls `fetch_demo_data` with the provided URL and then loads the data into a pandas DataFrame.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef download_data(**kwargs) -> pd.DataFrame:\n    \"\"\"Download the dataset using URL.\"\"\"\n    fetch_demo_data(DATA_URL, DATA_PATH)\n    _df = pd.read_csv(DATA_PATH, **kwargs)\n    return _df\n```\n\n----------------------------------------\n\nTITLE: Initializing Dictionaries for LangChain Models (Python)\nDESCRIPTION: Initializes two dictionaries, `chains` and `models`, with keys corresponding to the OpenAI model names (`gpt-3.5-turbo-instruct`, `gpt-4`). These dictionaries will be populated later with the actual LangChain `RetrievalQA` instances and their corresponding callable functions.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nchains = {\"gpt-3.5-turbo-instruct\": None, \"gpt-4\": None}\nmodels = {\"gpt-3.5-turbo-instruct\": None, \"gpt-4\": None}\n```\n\n----------------------------------------\n\nTITLE: Defining GitHub Actions Workflow for Giskard Scan (YAML)\nDESCRIPTION: This YAML snippet defines a GitHub Actions workflow named 'Giskard CI/CD tutorial'. It triggers on pushes to the 'main' branch, sets up a job on 'ubuntu-latest', checks out the code, sets up Python, installs dependencies from `requirements.txt`, and executes the `scan.py` script. The job's success status is determined by the script's exit code.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/cicd/pipeline.ipynb#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nname: Giskard CI/CD tutorial\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  automatic_scan:\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout repo content\n        uses: actions/checkout@v2 # checkout the repository content to github runner\n\n      - name: setup python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.8.16' # install the python version needed\n\n      - run: pip install -r requirements.txt\n\n      - name: execute test script\n        run: |\n          python scan.py\n        id: test_output\n```\n\n----------------------------------------\n\nTITLE: Creating Giskard Dataset (gsk.Dataset)\nDESCRIPTION: Creates a Giskard Dataset from a Pandas DataFrame containing example questions. This dataset is used to scan the NeMo Guardrails application for vulnerabilities. The dataset is initialized with a single question about the main challenges of climate change.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ngsk_dataset = gsk.Dataset(\n    pd.DataFrame({\"question\": [\"What are the main challenges of climate change?\"]}),\n    target=None,\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Minimum Slice Size for Giskard Metrics in Python\nDESCRIPTION: This snippet sets a custom minimum slice size for specific Giskard detectors via the 'min_slice_size' parameter in their respective configuration dictionaries. The slice size may be an integer (number of samples) or a float (proportion of dataset). Requires Giskard, a model, and a dataset. The scan will use custom slice minima as set in the params dictionary.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/advanced_scan/index.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport giskard as gsk\n\nparams = {\n    \"performance_bias\": dict(min_slice_size=50),\n    \"spurious_correlation\": dict(min_slice_size=0.01),\n}\n\nreport = gsk.scan(my_model, my_dataset, params=params)\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key and Disabling Verbose Logging in Python\nDESCRIPTION: Configures Python's logging system to suppress 'httpx' informational logs and sets the OPENAI_API_KEY in the environment for API access. This setup is necessary for any usage of OpenAI models through langchain or direct API calls. Replace the placeholder with a valid API key.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport logging\n\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)  # silence httpx info logs\n\nos.environ[\"OPENAI_API_KEY\"] = \"...\"  # add your own API key here\n```\n\n----------------------------------------\n\nTITLE: Evaluating RAG Agent with RAGAS Metrics using Giskard in Python\nDESCRIPTION: Demonstrates how to include RAGAS metrics (e.g., `ragas_context_recall`, `ragas_faithfulness`) in the Giskard RAG evaluation by importing them and passing them as a list to the `metrics` parameter of the `giskard.rag.evaluate` function. Requires the `giskard` and `ragas>=0.1.5` libraries, and the modified `get_answer_fn` that returns an `AgentAnswer` object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag.metrics.ragas_metrics import ragas_context_recall, ragas_faithfulness\n\nreport = evaluate(\n    get_answer_fn,\n    testset=testset,\n    knowledge_base=knowledge_base,\n    metrics=[ragas_context_recall, ragas_faithfulness]\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Cell-Level Transformation Function in Giskard Python\nDESCRIPTION: This code shows how to create a Giskard transformation function that operates on individual cell values within a specified column. Decorated with `@transformation_function(cell_level=True)`, the function takes the cell value as the first argument and the column name must be specified when applying the transformation. The example modifies numeric cell values by adding an offset and applies it to the 'Age' column. Requires the giskard library.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_transformations/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard import transformation_function, demo, Dataset\n\n\n_, df = demo.titanic()\ndataset = Dataset(df=df, target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\n\n@transformation_function(cell_level=True)\ndef my_func3(cell: int, offset: int):\n    return cell + offset\n\n\ntransformed_dataset = dataset.transform(my_func3(offset=20), column_name='Age')\n```\n\n----------------------------------------\n\nTITLE: Ollama LLM Client Setup\nDESCRIPTION: Configures giskard to use Ollama models by setting the model and embedding model with optional API base parameter. Requires giskard and the API base URL, default is localhost, facilitating local deployment testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nimport giskard\n\napi_base = \"http://localhost:11434\" # default api_base for local Ollama\n\ngiskard.llm.set_llm_model(\"ollama/qwen2.5\", disable_structured_output=True, api_base=api_base)\n giskard.llm.set_embedding_model(\"ollama/nomic-embed-text\", api_base=api_base)\n```\n\n----------------------------------------\n\nTITLE: Creating NeMo Guardrails Configuration Directories (Path)\nDESCRIPTION: Creates the necessary directory structure for NeMo Guardrails configuration. This includes directories for the main configuration file (`config.yml`), the rail definitions (`rails`), and the knowledge base (`kb`). The `exist_ok=True` and `parents=True` arguments ensure that the directories are created if they don't exist and any necessary parent directories are also created.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\n\n# Prepare the NeMo Guardrails config\nPath(\"config\", \"rails\").mkdir(exist_ok=True, parents=True)\nPath(\"config\", \"kb\").mkdir(exist_ok=True, parents=True)\n```\n\n----------------------------------------\n\nTITLE: Installing Pre-commit Hooks for Code Quality Checks Using Shell\nDESCRIPTION: This snippet installs pre-commit hooks defined in the `.pre-commit-config.yaml` file using the shell command `pre-commit install`. These hooks enforce code quality checks before code commits and require that pre-commit be installed as a development dependency. The configuration must be enabled by commenting out `skip: true` in the config file for GitGuardian integration via `ggshield`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/community/contribution_guidelines/dev-environment.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Generating and Running a Giskard Test Suite from Scan Results\nDESCRIPTION: Automatically creates a Giskard test suite based on the findings from the `scan`. The `results.generate_test_suite()` method is called with a name for the suite (\"My first test suite\"). This populates the suite with tests corresponding to the detected vulnerabilities. The `.run()` method is then called on the generated `test_suite` to execute these tests.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite = results.generate_test_suite(\"My first test suite\")\ntest_suite.run()\n```\n\n----------------------------------------\n\nTITLE: Loading and Downloading M5 Sales Prediction Dataset\nDESCRIPTION: Functions to download and load the M5 sales prediction dataset files from a remote server if not already present locally, preparing data for model training.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef fetch_dataset() -> None:\n    \"\"\"Fetch all necessary datafiles.\"\"\"\n    for file_name in DATA_FILES:\n        source = DATA_URL.format(file_name)\n        destination = DATA_PATH / file_name\n        fetch_demo_data(source, destination)\n\n\ndef load_data(n_series_use: int = 100) -> Tuple[pd.DataFrame, ...]:\n    \"\"\"Load necessary data files.\"\"\"\n    fetch_dataset()\n\n    calendar_df = pd.read_csv(DATA_PATH / \"calendar.csv.tar.gz\")\n    prices_df = pd.read_csv(DATA_PATH / \"sell_prices.csv.tar.gz\")\n    sales_df = pd.read_csv(DATA_PATH / \"sales_train_validation.csv.tar.gz\")\n    sales_df = sales_df.iloc[:n_series_use]\n\n    return calendar_df, prices_df, sales_df\n\n\ndfs = load_data()\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard Dataset Class\nDESCRIPTION: Creates a Giskard `Dataset` object from the preprocessed pandas DataFrame (`raw_data`). This step is crucial for integrating the dataset with Giskard's scanning and testing functionalities. It requires specifying the target column and allows for an optional name.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN,  # Ground truth variable.\n    name=\"Tweets with sentiment\",  # Optional.\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Input Template for Custom Correctness Metric in Python\nDESCRIPTION: Defines a Python multiline string variable `INPUT_TEMPLATE` used to format the input for the LLM judge when implementing a custom Giskard metric. It structures the conversation history, the agent's answer, and the reference answer for the evaluation task described in the corresponding system prompt.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/rag_evaluation/index.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nINPUT_TEMPLATE = \"\"\"\n### CONVERSATION\n{conversation}\n\n### AGENT ANSWER\n{answer}\n\n### REFERENCE ANSWER\n{reference_answer}\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Displaying or Saving Giskard Scan Results in Python\nDESCRIPTION: Demonstrates how to access the results generated by `giskard.scan`. The `scan_results` object can be displayed directly within interactive environments like Jupyter notebooks using `display()`, or it can be exported to an HTML file for sharing or later review using the `to_html()` method.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndisplay(scan_results)\n\n# Or save it to a file\nscan_results.to_html(\"scan_results.html\")\n```\n\n----------------------------------------\n\nTITLE: Scanning a Giskard Model and Displaying the Results in Python\nDESCRIPTION: This snippet scans the wrapped Giskard model for vulnerabilities and displays the scan report. It requires a previously initialized Giskard model (e.g., FAISSRAGModel) and the Giskard library. The expected input is a Giskard model object, and the scan results object can be displayed in a Jupyter notebook or further processed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nscan_results = giskard.scan(giskard_model)\ndisplay(scan_results)  # in your notebook\n```\n\n----------------------------------------\n\nTITLE: Setting up Gemini LLM Client using .env variables in Python\nDESCRIPTION: This snippet demonstrates configuring the Gemini LLM client by setting the Gemini API key as an environment variable, then selecting the Gemini LLM and embedding models. It requires the giskard package and valid Gemini API credentials. Inputs include API key and model ids, outputs are configured client instances for Gemini LLM usage.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"GEMINI_API_KEY\"] = \"\" # \"my-gemini-api-key\"\n\ngiskard.llm.set_llm_model(\"gemini/gemini-1.5-pro\")\ngiskard.llm.set_embedding_model(\"gemini/text-embedding-004\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset with Giskard\nDESCRIPTION: This snippet wraps the test dataset with Giskard's `Dataset` class. It concatenates the test features and target into a single DataFrame.  The `target` parameter specifies the ground truth variable column name, and the `name` parameter gives the dataset a descriptive label.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nraw_data = pd.concat([X_test, y_test], axis=1)\ngiskard_dataset = Dataset(\n    df=raw_data,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=\"target\",  # Ground truth variable.\n    name=\"breast_cancer\",  # Optional.\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Row-Level Slicing Function in Python with Giskard\nDESCRIPTION: Shows how to create a row-level slicing function that filters dataset rows based on a condition. The function takes a pandas Series row and returns a boolean based on whether the 'Age' value exceeds a threshold.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_slices/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom giskard import slicing_function, demo, Dataset\n\n\n_, df = demo.titanic()\ndataset = Dataset(df=df, target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\n\n@slicing_function(row_level=True)\ndef my_func2(row: pd.Series, threshold: int):\n    return row['Age'] > threshold\n\n\ndataset.slice(my_func2(threshold=20))\n```\n\n----------------------------------------\n\nTITLE: Azure OpenAI LLM Client Setup\nDESCRIPTION: Prepares environment variables and assigns the Azure OpenAI models within giskard for LLM and embeddings. Requires dependencies on os and giskard. This configuration facilitates integration with Azure's API for domain-specific model assessment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_llm/index.md#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"AZURE_API_KEY\"] = \"\" # \"my-azure-api-key\"\nos.environ[\"AZURE_API_BASE\"] = \"\" # \"https://example-endpoint.openai.azure.com\"\nos.environ[\"AZURE_API_VERSION\"] = \"\" # \"2023-05-15\"\n\ngiskard.llm.set_llm_model(\"azure/<your_llm_name>\")\n giskard.llm.set_embedding_model(\"azure/<your_embed_model_name>\")\n\nos.environ[\"AZURE_AD_TOKEN\"] = \"\"\nos.environ[\"AZURE_API_TYPE\"] = \"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard LLM and dependencies\nDESCRIPTION: This snippet installs the `giskard[llm]` package, which provides support for Large Language Models within the Giskard framework, and project-specific dependencies such as `openai`, `tiktoken`, and `scipy`. The `--upgrade` flag ensures that the latest version of `giskard[llm]` is installed.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"giskard[llm]\" --upgrade\n```\n\n----------------------------------------\n\nTITLE: Defining Constants\nDESCRIPTION: This code defines constants used throughout the notebook, specifically the name of the target column ('Survived') and a list of categorical columns ('Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'). These constants are used when wrapping the dataset with Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nTARGET_COLUMN = \"Survived\"\n\nCATEGORICAL_COLUMNS = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Drug Classification Project\nDESCRIPTION: Imports required libraries for the drug classification project, including data handling libraries (pandas, numpy), machine learning libraries (scikit-learn, imblearn), and the Giskard testing framework components.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/drug_classification_sklearn.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.svm import SVC\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.pipeline import Pipeline as PipelineImb\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Defining Preprocessing Adapter for Scikit-learn Vectorizer\nDESCRIPTION: Defines a function `adapt_vectorizer_input` that takes a pandas DataFrame and extracts its first column as a pandas Series. This is necessary because scikit-learn's `TfidfVectorizer` expects an iterable of strings, not a DataFrame, and this function serves as an adapter within a scikit-learn Pipeline.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef adapt_vectorizer_input(df: pd.DataFrame) -> Iterable:\n    \"\"\"Adapt input for the vectorizers.\n\n    The problem is that vectorizers accept iterable, not DataFrame, but Series.\n    Thus, we need to ravel dataframe with text have input single dimension.\n    \"\"\"\n\n    df = df.iloc[:, 0]\n    return df\n```\n\n----------------------------------------\n\nTITLE: Saving Giskard Scan Results to HTML\nDESCRIPTION: This code snippet shows how to save the results of a Giskard scan to an HTML file. This is useful if you are not working in a notebook or want to share or store the scan results for later review. The to_html function is called on the scan_results object with the desired filename.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_vision/index.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nscan_results.to_html(\"model_scan_results.html\")\n```\n\n----------------------------------------\n\nTITLE: Defining Constants\nDESCRIPTION: Defines constants for data URL, LLM name, text column name, and prompt template used for the QA system. These will be used throughout the notebook to configure different parts of the process.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nDATA_URL = \"https://storage.googleapis.com/dataset-natural-questions\"\n\nLLM_NAME = \"gpt-3.5-turbo-instruct\"\n\nTEXT_COLUMN_NAME = \"question\"\n\nPROMPT_TEMPLATE = \"\"\"\nUse the following pieces of context to answer the question at the end. Please provide\na short single-sentence summary answer only. If you don't know the answer or if it's \nnot present in given context, don't try to make up an answer, but politely inform the user about it. \n\nContext: \n{context}\n\nQuestion: \n{question}\n\nHelpful Answer:\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard with LLM Extras using Pip\nDESCRIPTION: Installs the latest version of the Giskard library from PyPi, including optional dependencies for Large Language Model (LLM) support, using the pip package manager. The `-U` flag ensures the package is upgraded if already installed. Python versions 3.9, 3.10, and 3.11 are officially supported.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install \"giskard[llm]\" -U\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable (Python)\nDESCRIPTION: Imports the `os` module and sets the `OPENAI_API_KEY` environment variable. This key is required to use OpenAI's language models (like GPT-3.5 and GPT-4) via the `langchain-openai` library. Replace \"sk-XXX\" with a valid API key.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\n# See https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key\nos.environ['OPENAI_API_KEY'] = \"sk-XXX\"\n```\n\n----------------------------------------\n\nTITLE: Customizing and Running Test Suites with Giskard Catalog Tests in Python\nDESCRIPTION: This snippet shows how to extend a test suite by adding a unit test from the Giskard catalog, specifically a test verifying the F1 score exceeds a threshold. It employs 'testing.test_f1' with model, dataset, and threshold parameters, then adds the test to 'test_suite' and runs it. This enables fine-grained, domain-specific validation using predefined test types. The snippet depends on existing 'giskard_model', 'giskard_dataset', and 'test_suite' objects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Configuration\nDESCRIPTION: Defines several constants used throughout the code, including the device for computation (CPU), target mapping (labels), target and feature column names, and the batch size for data loaders.  These constants enhance code readability and maintainability.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nDEVICE = torch.device(\"cpu\")\n\nTARGET_MAP = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\nTARGET_COLUMN_NAME = \"label\"\nFEATURE_COLUMN_NAME = \"text\"\n\nLOADERS_BATCH_SIZE = 64\n```\n\n----------------------------------------\n\nTITLE: Executing Statistical Test on Prediction Ratio in Giskard Python\nDESCRIPTION: This snippet demonstrates how to execute a statistical test from the Giskard catalog. It involves setting up `Model` and `Dataset` objects and running the `test_right_label` test. This test checks if the ratio of examples predicted with a particular classification label (\"yes\" in this case) exceeds a defined threshold.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/test_model/index.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nfrom giskard import demo, Model, Dataset, testing\n\n\nmodel, df = demo.titanic()\n\nwrapped_model = Model(model=model, model_type=\"classification\")\nwrapped_dataset = Dataset(\n    df=df,\n    target=\"Survived\",\n    cat_columns=[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"],\n)\n\n# Let's check if the ratio of examples labeled as \"yes\" is over 0.7\nresult = testing.test_right_label(\n    model=wrapped_model,\n    dataset=wrapped_dataset,\n    classification_label=\"yes\",\n    threshold=0.7,\n).execute()\n\nprint(f\"result: {result.passed} with metric {result.metric}\")\n```\n\n----------------------------------------\n\nTITLE: Wrapping trained model with Giskard Model class\nDESCRIPTION: This code wraps the trained pipeline in Giskard's Model class, enabling it to be used for vulnerability scans and testing within Giskard. It also validates the wrapper by checking prediction accuracy.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/churn_prediction_lgbm.ipynb#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=pipeline,  # Encapsulates data pre-processing and prediction\n    model_type=\"classification\",\n    name=\"Churn classification\",\n    classification_labels=pipeline.classes_,\n    feature_names=FEATURE_TYPES.keys(),\n)\n\n# Validate wrapped model.\nwrapped_Y_pred = giskard_model.predict(giskard_dataset).prediction\nwrapped_accuracy = accuracy_score(Y_test, wrapped_Y_pred)\n\nprint(f\"Wrapped Test Accuracy: {wrapped_accuracy:.2f}\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results\nDESCRIPTION: This code displays the scan report generated by Giskard's scan function directly in a Jupyter notebook using `display(results)`.  It also saves the report to an HTML file named \"scan_report.html\" using `results.to_html(\"scan_report.html\")`.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n\n# Save it to a file\nresults.to_html(\"scan_report.html\")\n```\n\n----------------------------------------\n\nTITLE: Downloading and Preprocessing Data\nDESCRIPTION: This snippet calls the previously defined functions `download_data` and `preprocess_data` to load the dataset, preprocess it, and assign the result to `income_df`. This prepares the dataset for model training. It chains function calls for data loading and preprocessing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/wage_classification.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nincome_df = download_data()\nincome_df = preprocess_data(income_df)\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard LLM Scan Report in Python\nDESCRIPTION: Outputs the scan report object, enabling interactive or visual review of vulnerability findings, including AVID taxonomy categories. Intended for notebook or interactive shell usage where scan_report's display method is available.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nscan_report\n```\n\n----------------------------------------\n\nTITLE: Converting Giskard Scan Results to AVID-Style Reports in Python\nDESCRIPTION: Converts the Giskard scan report to AVID-compliant report structures, which facilitate structured vulnerability sharing and further customization. The output is a list of AVID report objects for downstream processing or export. Requires a valid scan_report object as input.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\navid_reports = scan_report.to_avid()\navid_reports\n```\n\n----------------------------------------\n\nTITLE: Building Embedding Matrix from GloVe Vectors in Python\nDESCRIPTION: Defines helpers to parse GloVe embedding files and generate a NumPy-based embedding matrix for model initialization. The embedding matrix matches words to GloVe vectors or initializes with random normal values if not available. Inputs required: GloVe file (in tar.gz), tokenizer word index, and set constants for matrix size.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef parse_line(word: str, *arr: list) -> Tuple[str, np.ndarray]:\n    \"\"\"Parse line from the file with embeddings.\n    The first value of the line is the word and the rest values are related glove embedding: (<word>, 0.66, 0.23, ...).\"\"\"\n    return word, np.asarray(arr, dtype=\"float32\")\n\n\ndef init_embeddings_matrix(embeddings_dict: dict) -> np.ndarray:\n    \"\"\"Init a matrix, where each row is an embedding vector.\"\"\"\n    num_embeddings = min(MAX_TOKENS, len(text_tokenizer.word_index))\n    stacked_embeddings = np.stack(list(embeddings_dict.values()))\n    embeddings_mean, embeddings_std, embeddings_dimension = (\n        stacked_embeddings.mean(),\n        stacked_embeddings.std(),\n        stacked_embeddings.shape[1],\n    )\n    embeddings_matrix = np.random.normal(embeddings_mean, embeddings_std, (num_embeddings, embeddings_dimension))\n    return embeddings_matrix\n\n\ndef get_embeddings_matrix() -> np.ndarray:\n    \"\"\"Create matrix, where each row is an embedding of a specific word.\"\"\"\n    # Load glove embeddings.\n    embeddings_dict = dict(\n        parse_line(*line.rstrip().rsplit(\" \"))\n        for line in tarfile.open(DATA_PATH / \"glove_100d.txt.tar.gz\", \"r:gz\")\n        .extractfile(\"fake_real_news_dataset-glove_100d.txt\")\n        .read()\n        .decode()\n    )\n\n    # Create embeddings matrix with glove word vectors.\n    embeddings_matrix = init_embeddings_matrix(embeddings_dict)\n    for word, idx in text_tokenizer.word_index.items():\n        if idx >= MAX_TOKENS:\n            continue\n\n        embedding_vector = embeddings_dict.get(word, None)\n\n        if embedding_vector is not None:\n            embeddings_matrix[idx] = embedding_vector\n\n    return embeddings_matrix\n\n\nembed_matrix = get_embeddings_matrix()\n\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for Giskard LLM and W&B Integration\nDESCRIPTION: Installs required Python packages including wandb, giskard with LLM support, langchain, and openai with specific version constraints. This ensures compatibility and availability of necessary APIs for running the tutorial code.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"wandb<=0.15.12\" \"giskard[llm]\" \"langchain<=0.0.301\" \"openai<=0.28.1\" -q\n```\n\n----------------------------------------\n\nTITLE: Configuring Notebook Settings (Python)\nDESCRIPTION: Sets the OpenAI API key as an environment variable and configures the OpenAI client. It also sets a Pandas display option to show full column content without truncation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set the OpenAI API Key environment variable.\nOPENAI_API_KEY = \"...\"\nopenai.api_key = OPENAI_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# Display options.\npd.set_option(\"display.max_colwidth\", None)\n```\n\n----------------------------------------\n\nTITLE: Defining Constants and Paths - Python\nDESCRIPTION: Defines constants for reproducibility (random seed), column names, target encoding mappings, and paths to the pre-trained model name and the dataset URL. These constants are used throughout the notebook for data loading, processing, and model configuration.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Constants.\nRANDOM_SEED = 0\n\nTEXT_COLUMN_NAME = \"text\"\nTARGET_COLUMN_NAME = \"airline_sentiment\"\n\nTARGET_STR_INT = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\nTARGET_INT_STR = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n\n# Paths.\nMODEL_NAME = \"Souvikcmsa/SentimentAnalysisDistillBERT\"\nDATA_URL = (\n    \"https://raw.githubusercontent.com/Giskard-AI/examples/main/datasets/twitter_us_airline_sentiment_analysis.csv\"\n)\n```\n\n----------------------------------------\n\nTITLE: Creating DataFrame-Level Slicing Function in Python with Giskard\nDESCRIPTION: Demonstrates creating a dataframe-level slicing function that operates on the entire pandas DataFrame. This function creates a new boolean column based on an age threshold and returns the transformed dataframe.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_slices/index.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard import slicing_function, demo, Dataset\nimport pandas as pd\n\n\n_, df = demo.titanic()\ndataset = Dataset(df=df, target=\"Survived\", cat_columns=['Pclass', 'Sex', \"SibSp\", \"Parch\", \"Embarked\"])\n\n\n@slicing_function(row_level=False)\ndef my_func1(df: pd.DataFrame, threshold: int):\n    df['Age'] = df['Age'] > threshold\n    return df\n\n\ndataset.slice(my_func1(threshold=20))\n```\n\n----------------------------------------\n\nTITLE: Wrapping Dataset for Image Classification\nDESCRIPTION: This Python code demonstrates how to wrap a dataset for image classification using the `DataIteratorBase` class. It requires overriding `idx_sampler`, `get_image`, `get_label`, and optionally `get_meta`. The `get_meta` method demonstrates the usage of metadata and issue groups.  The input is a dataset of images and labels, and the output is a wrapped dataset object. The function `cv2.imread()` is used for reading the images, which requires OpenCV.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_vision/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard_vision.core.dataloaders.base import DataIteratorBase\nfrom giskard_vision.core.dataloaders.meta import MetaData\nfrom giskard_vision.core.issues import EthicalIssueMeta, PerformanceIssueMeta\n\n\nclass DataLoaderClassification(DataIteratorBase):\n\n    @property\n    def idx_sampler(self) -> np.ndarray:\n        return list(range(len(self.image_paths))\n\n    @classmethod\n    def get_image(self, idx: int) -> np.ndarray:\n        return cv2.imread(str(self.image_paths[idx]))\n\n    @classmethod\n    def get_label(self, idx: int) -> Optional[np.ndarray]:\n        return 'label'\n    \n    @classmethod\n    def get_meta(self, idx: int) -> Optional[MetaData]:\n        default_meta = super().get_meta() # To load default metadata\n        return MetaData(\n            data={\n                **default_meta.data,\n                'meta1': 'value1',\n                'meta2': 'value2',\n                'categorical_meta1': 'cat_value1',\n                'categorical_meta2': 'cat_value2'\n            },\n            categories=default_meta.categories+['categorical_meta1', 'categorical_meta2'],\n            issue_groups={\n                **default_meta.issue_groups,\n                'meta1': PerformanceIssueMeta,\n                'meta2': EthicalIssueMeta,\n                'categorical_meta1': PerformanceIssueMeta,\n                'categorical_meta2': EthicalIssueMeta,\n            }\n        )\n\n\ngiskard_dataset = DataLoaderClassification()\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results with Giskard in Python\nDESCRIPTION: This snippet shows how to display the results object from a Giskard scan in a readable format within a Python environment. It assumes 'results' holds the output from the prior scan operation and calls the 'display' function to visualize scan findings for analysis or debugging.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Generating and Persisting JWT Secret for Giskard (Bash)\nDESCRIPTION: This Bash script generates a 256-byte random, base64-encoded secret key using `openssl rand -base64 256`. It then constructs an `export` command for the `GISKARD_JWT_SECRET` environment variable with this key and appends it to either the `.zshrc` (for Zsh users) or `.bashrc` (for Bash users) file. This ensures the JWT secret persists across server reboots or new shell sessions, maintaining user login sessions in Giskard. The `tr -d '\\n'` command removes potential newlines from the base64 output.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/community/contribution_guidelines/configuration.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# for zsh\necho export GISKARD_JWT_SECRET=`openssl rand -base64 256 | tr -d '\\n'` >> ~/.zshrc\n\n# for bash\necho export GISKARD_JWT_SECRET=`openssl rand -base64 256 | tr -d '\\n'` >> ~/.bashrc\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with toctree\nDESCRIPTION: This code snippet uses the toctree directive to create a table of contents for the Guides section. It specifies the caption, maximum depth, and hides the toctree in the rendered output.  The listed files are the pages linked under the Guides section.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/index.md#_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n```\n:caption: Guides\n:maxdepth: 1\n:hidden:\n\nopen_source/installation_library/index\nopen_source/setting_up/index\nopen_source/scan/index\nopen_source/testset_generation/index\nopen_source/customize_tests/index\nopen_source/integrate_tests/index\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for RoBERTa Sentiment Model\nDESCRIPTION: Sets up constant values for the model configuration, including the pre-trained model name, dataset configuration parameters, label mapping for sentiment classification, and column identifiers.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment\"\n\nDATASET_CONFIG = {\"path\": \"tweet_eval\", \"name\": \"sentiment\", \"split\": \"validation\"}\n\nLABEL_MAPPING = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n\nTEXT_COLUMN = \"text\"\nTARGET_COLUMN = \"label\"\n```\n\n----------------------------------------\n\nTITLE: Exporting NeMo Guardrails Rails with Specified Colang Version in Python\nDESCRIPTION: This snippet extends the previous example by demonstrating how to specify the version of Colang (e.g., 2.x) when generating rails from a Giskard scan report. This is important for compatibility with different versions of the Colang modelling language used by NeMo Guardrails. It expects the same prerequisites as above with an additional parameter 'colang_version' provided to the generate_rails method.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nscan_report.generate_rails(\"config/generated_rails.co\", colang_version=\"2.x\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Vulnerability Scan Results for RoBERTa Model\nDESCRIPTION: Displays the results of the vulnerability scan performed on the RoBERTa sentiment analysis model to visualize detected issues and vulnerabilities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API key and display options\nDESCRIPTION: This snippet sets the OpenAI API key as an environment variable and configures pandas display options to show the full content of columns, preventing truncation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set the OpenAI API Key environment variable.\nOPENAI_API_KEY = \"...\"\nopenai.api_key = OPENAI_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# Display options.\npd.set_option(\"display.max_colwidth\", None)\n```\n\n----------------------------------------\n\nTITLE: Saving a Giskard RAG Testset to a File in Python\nDESCRIPTION: Demonstrates how to persist the generated RAG testset to a file for later use or sharing. The `save` method of the `testset` object (returned by `generate_testset`) is called, specifying the output filename with a '.jsonl' extension, indicating JSON Lines format.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Save the generated testset\ntestset.save(\"my_testset.jsonl\")\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard LLM Dependencies Using Bash\nDESCRIPTION: This snippet shows the command to install the Giskard library with its LLM-related dependencies using pip. This step is required before using RAGET features to generate and evaluate questions with Retrieval-Augmented Generation agents.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"giskard[llm]\"\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Data - Python\nDESCRIPTION: Defines and calls a function to load the dataset from a URL using pandas, selecting only the text and target columns. It then encodes the string target column into numerical integer values based on a predefined mapping. The function returns the processed pandas DataFrame.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\ndef load_preprocess_data():\n    \"\"\"Load data and encode targets.\"\"\"\n    df = pd.read_csv(DATA_URL, usecols=[TEXT_COLUMN_NAME, TARGET_COLUMN_NAME])\n    df[TARGET_COLUMN_NAME] = df[TARGET_COLUMN_NAME].map(TARGET_STR_INT)\n    return df\n\ndata = load_preprocess_data()\n```\n\n----------------------------------------\n\nTITLE: Importing Modules for Dataset Loading and Model Wrapping\nDESCRIPTION: Imports essential classes from the Giskard vision library to load the 300W face detection dataset and to wrap a Hugging Face (HF) model for object detection. These modules facilitate data handling and model interfacing within the Giskard testing framework.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_object_detection.ipynb#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom giskard_vision.object_detection.dataloaders.loaders import DataLoader300WFaceDetection\nfrom giskard_vision.object_detection.models.wrappers import DetrFinetunedHFModel\nfrom giskard_vision.core.scanner import scan\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for NeMo Guardrails and Giskard (pip)\nDESCRIPTION: Installs specific versions of `nemoguardrails`, `openai`, and `giskard` from a GitHub repository using pip. This ensures the environment has the correct versions for the NeMo Guardrails and Giskard integration, including a feature branch for NeMo Guardrails integration from the Giskard repository.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install nemoguardrails openai \"giskard[llm]@git+https://github.com/Giskard-AI/giskard@feature/nemo-guardrails-integration\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results\nDESCRIPTION: Displays the results of the Giskard scan. This allows the user to view the detected vulnerabilities and understand the potential issues with the model. The display function likely formats the scan results in a user-friendly way, such as a table or a list.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing Tweet Sentiment Dataset\nDESCRIPTION: Loads the tweet_eval sentiment dataset from Hugging Face, limits it to 500 samples, and replaces numerical labels with human-readable sentiment categories based on the label mapping.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nraw_data = load_dataset(**DATASET_CONFIG).to_pandas().iloc[:500]\nraw_data = raw_data.replace({\"label\": LABEL_MAPPING})\n```\n\n----------------------------------------\n\nTITLE: Adding Custom F1 Score Test from Giskard Catalog - Python\nDESCRIPTION: Demonstrates adding a threshold-based F1 score test from Giskard's testing catalog to the test suite, specifying model, dataset, and threshold value. Executes the suite to check if F1 meets the criterion. Inputs: giskard.Model, giskard.Dataset; Output: executed test suite. Requires Giskard's testing utilities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies with PDM Using Shell\nDESCRIPTION: This snippet installs the required project dependencies using the PDM package manager via the shell command `pdm install`. It assumes PDM is already installed on the system, which can be done by following the official PDM installation instructions. Running this command sets up the Python environment and installs packages according to the project's dependency specifications.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/community/contribution_guidelines/dev-environment.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npdm install\n```\n\n----------------------------------------\n\nTITLE: Displaying Scan Results\nDESCRIPTION: Displays the results of the vulnerability scan using the `display` function.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Building and Training an LSTM Model for News Classification in Python\nDESCRIPTION: Defines and trains a multi-layer LSTM Keras Sequential model with GloVe-based embeddings for binary text classification. The model structure includes a non-trainable embedding layer, stacked LSTM layers, and dense output. Model is compiled with Adam optimizer and binary cross-entropy. Requires precomputed embed_matrix and tokenized inputs for training.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef init_model() -> Sequential:\n    \"\"\"Initialize new TF model.\"\"\"\n    # Define model container.\n    model = Sequential()\n\n    # Non-trainable embedding layer.\n    model.add(\n        Embedding(MAX_TOKENS, output_dim=100, weights=[embed_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)\n    )\n\n    # LSTM stage.\n    model.add(LSTM(units=32, return_sequences=True, recurrent_dropout=0.25, dropout=0.25))\n    model.add(LSTM(units=16, recurrent_dropout=0.1, dropout=0.1))\n\n    # Dense stage.\n    model.add(Dense(units=16, activation=\"relu\"))\n    model.add(Dense(units=1, activation=\"sigmoid\"))\n\n    # Build model.\n    model.compile(optimizer=Adam(learning_rate=0.01), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\n\n# Fit model.\nn_epochs = 5\nbatch_size = 256\n\nclassifier = init_model()\n_ = classifier.fit(\n    X_train_tokens, Y_train, batch_size=batch_size, validation_data=(X_test_tokens, Y_test), epochs=n_epochs\n)\n\ntrain_metric = classifier.evaluate(X_train_tokens, Y_train, verbose=0)[1]\ntest_metric = classifier.evaluate(X_test_tokens, Y_test, verbose=0)[1]\n\nprint(f\"Train accuracy: {train_metric: .4f}\")\nprint(f\"Test accuracy: {test_metric: .4f}\")\n\n```\n\n----------------------------------------\n\nTITLE: Adding Custom R2 Performance Test to Giskard Test Suite\nDESCRIPTION: Adds a specific R2 score test to the existing test suite to verify that the model's R2 performance meets a minimum threshold of 0.7, then runs the expanded test suite.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_r2(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Importing libraries for sentiment classification project\nDESCRIPTION: Imports necessary Python libraries for data processing, model training with HuggingFace transformers, and model testing with Giskard.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport random\nimport re\nimport string\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Union, List\nfrom urllib.request import urlretrieve\n\nimport nltk\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom nltk.corpus import stopwords\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\nfrom transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Converting QA Testset to Pandas DataFrame\nDESCRIPTION: Shows how to convert a QA testset to a pandas DataFrame for easier inspection and further data processing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/testset_generation/testset_generation/index.md#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Convert it to a pandas dataframe\ndf = loaded_testset.to_pandas()\n```\n\n----------------------------------------\n\nTITLE: Wrapping Test Dataset with Giskard's Dataset\nDESCRIPTION: Creates a Giskard `Dataset` object to wrap the test data. This step is required for using Giskard's testing and analysis features. The `Dataset` object encapsulates the test data, target variable, and an optional name. The `target` parameter specifies the ground truth variable, and the `name` provides a human-readable label for the dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ngiskard_dataset = Dataset(\n    df=test_df,\n    # A pandas.DataFrame that contains the raw data (before all the pre-processing steps) and the actual ground truth variable (target).\n    target=TARGET_COLUMN,  # Ground truth variable.\n    name=\"Movie reviews dataset\",  # Optional.\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Dependency - Shell\nDESCRIPTION: Installs the Giskard library and its dependencies using pip within a notebook environment, ensuring the latest version is installed for accessing features like scanning and testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard Library using pip\nDESCRIPTION: Installs or upgrades the Giskard Python library using the pip package manager within a Jupyter environment. This command ensures the necessary Giskard framework is available for model testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/credit_scoring.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard LLM Dependencies in Python\nDESCRIPTION: Installs and upgrades the Giskard library with LLM support, ensuring access to model scanning features. This must be run in a supported Python environment, such as Jupyter or a shell with the necessary privileges. Required for any downstream Giskard operations described in the tutorial.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U \"giskard[llm]\"\n```\n\n----------------------------------------\n\nTITLE: Wrapping LGBM Regressor with Giskard Model Interface\nDESCRIPTION: Creates a Giskard Model wrapper around the trained LGBM regressor to prepare it for vulnerability scanning, specifying the model type and feature names.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ngiskard_model = Model(\n    model=regressor,  # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n    model_type=\"regression\",  # Either regression, classification or text_generation.\n    name=\"M5 sales timeseries regressor\",  # Optional\n    feature_names=X_val.columns,  # Default: all columns of your dataset\n)\n```\n\n----------------------------------------\n\nTITLE: Setting LLM Model for Giskard Scan (gsk.llm.client.set_llm_model)\nDESCRIPTION: Configures the Large Language Model (LLM) to be used for the Giskard scan.  This ensures the scan utilizes the specified language model, which in this case is \"gpt-4o\".\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/nemoguardrails/nemoguardrails-integration.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ngsk.llm.client.set_llm_model(\"gpt-4o\")\n```\n\n----------------------------------------\n\nTITLE: Saving Notebook with DagsHub\nDESCRIPTION: Saves the current Jupyter notebook to the DagsHub repository, ensuring version control and reproducibility.  `your_repo_name` should be replaced with the name of your repository.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/dagshub/index.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndagshub.notebook.save_notebook(repo=\"your_repo_name\")\n```\n\n----------------------------------------\n\nTITLE: Setting Display Options\nDESCRIPTION: Sets the Pandas display options to show the full width of the columns.  This can be useful when examining the contents of the datasets.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Display options.\npd.set_option(\"display.max_colwidth\", None)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for RoBERTa Sentiment Analysis with Giskard\nDESCRIPTION: Installs the necessary Python packages including Giskard, scipy, transformers, and PyTorch to support the sentiment analysis model testing framework.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard scipy transformers torch --upgrade\n```\n\n----------------------------------------\n\nTITLE: Loading Data\nDESCRIPTION: This snippet loads the breast cancer dataset from scikit-learn into pandas DataFrames for features and the target variable.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndata = load_breast_cancer(as_frame=True)\nfeatures = data[\"data\"]\ntarget = data[TARGET_COLUMN_NAME]\n```\n\n----------------------------------------\n\nTITLE: Building a Langchain RAG Agent in Python\nDESCRIPTION: Defines a Python script using Langchain to build a Retrieval-Augmented Generation (RAG) agent. It loads a PDF report (IPCC Climate Change Synthesis Report), splits it into chunks using `RecursiveCharacterTextSplitter`, creates a FAISS vector store with OpenAI embeddings, sets up a `PromptTemplate`, initializes an OpenAI LLM (`gpt-3.5-turbo-instruct`), and constructs a `RetrievalQA` chain to answer questions based on the document context.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import FAISS, PromptTemplate\nfrom langchain_openai import OpenAIEmbeddings, OpenAI\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.chains import RetrievalQA\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Prepare vector store (FAISS) with IPPC report\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True)\nloader = PyPDFLoader(\"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\")\ndb = FAISS.from_documents(loader.load_and_split(text_splitter), OpenAIEmbeddings())\n\n# Prepare QA chain\nPROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard.\nYour task is to answer common questions on climate change.\nYou will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023).\nPlease provide short and clear answers based on the provided context. Be polite and helpful.\n\nContext:\n{context}\n\nQuestion:\n{question}\n\nYour answer:\n\"\"\"\n\nllm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\nprompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\nclimate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever(), prompt=prompt)\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training and Test Sets - Python\nDESCRIPTION: Performs a stratified train-test split using scikit-learn, separating review text features and the binary target. Ensures consistent split by specifying random seed and class stratification. Inputs: cleaned DataFrame; Outputs: X_train, X_test, y_train, y_test. Relies on prior preprocessing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nX_train, X_test, y_train, y_test = train_test_split(\n    reviews_df[[\"reviewText\"]],\n    reviews_df[TARGET_NAME],\n    test_size=TEST_RATIO,\n    random_state=RANDOM_SEED,\n    stratify=reviews_df[TARGET_NAME],\n)\n\n```\n\n----------------------------------------\n\nTITLE: Loading Data\nDESCRIPTION: This code uses the `demo.titanic_df()` function to load the Titanic dataset as a pandas DataFrame. The dataset is then used for model training and evaluation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nraw_data = demo.titanic_df()\n```\n\n----------------------------------------\n\nTITLE: Defining Data Fetching and Loading Functions in Python\nDESCRIPTION: Defines two helper functions: `fetch_demo_data` downloads the dataset from a given URL to a specified file path if it doesn't already exist, creating parent directories as needed. `load_data` utilizes `fetch_demo_data`, reads the CSV data into a pandas DataFrame, and creates a new feature column 'Full_Review' by concatenating 'Positive_Review' and 'Negative_Review' columns.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef fetch_demo_data(url: str, file: Path) -> None:\n    \"\"\"Helper to fetch data from the FTP server.\"\"\"\n    if not file.parent.exists():\n        file.parent.mkdir(parents=True, exist_ok=True)\n\n    if not file.exists():\n        print(f\"Downloading data from {url}\")\n        urlretrieve(url, file)\n\n    print(f\"Data was loaded!\")\n\n\ndef load_data(**kwargs) -> pd.DataFrame:\n    fetch_demo_data(DATA_URL, DATA_PATH)\n    df = pd.read_csv(DATA_PATH, **kwargs)\n\n    # Create target column.\n    df[FEATURE_COLUMN_NAME] = df.apply(lambda x: x[\"Positive_Review\"] + \" \" + x[\"Negative_Review\"], axis=1)\n\n    return df\n```\n\n----------------------------------------\n\nTITLE: Loading a Giskard RAG Testset from a File in Python\nDESCRIPTION: Shows how to load a previously saved RAG testset from a JSON Lines file. The `QATestset.load` class method is used, passing the path to the saved file (e.g., 'my_testset.jsonl') as an argument. This returns a `QATestset` object.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/README.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard.rag import QATestset\n\nloaded_testset = QATestset.load(\"my_testset.jsonl\")\n```\n\n----------------------------------------\n\nTITLE: Launching MLflow UI with ngrok Tunneling (Python/Shell)\nDESCRIPTION: Imports `pyngrok`, sets the ngrok authentication token (replace `NGROK_TOKEN`), starts the MLflow UI process in the background using a shell command (`mlflow ui --port 5000 &`), kills any existing ngrok tunnels. This setup is typically used in environments like Google Colab to expose the local MLflow UI (running on port 5000) via a public URL for viewing evaluation results.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom pyngrok import ngrok\n\n# Get your authtoken from https://dashboard.ngrok.com/auth\nNGROK_AUTH_TOKEN = \"NGROK_TOKEN\"\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\n# Run the tracking UI in the background\nget_ipython().system_raw(\"mlflow ui --port 5000 &\")\n\n# Terminate open tunnels if exist\nngrok.kill()\n```\n\n----------------------------------------\n\nTITLE: Loading RoBERTa Sentiment Analysis Model from HuggingFace\nDESCRIPTION: Initializes the pre-trained RoBERTa tokenizer and sequence classification model from HuggingFace for sentiment analysis of tweets.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard Scan Results for M5 Sales Model\nDESCRIPTION: Displays the vulnerability scan results for the LGBM regression model to identify any issues that need to be addressed before deployment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/m5_sales_prediction_lgbm.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Splitting Data into Training and Testing Sets using Scikit-learn\nDESCRIPTION: Uses the `train_test_split` function from scikit-learn to divide the dataset into training and testing sets. It takes the feature column (`FEATURE_COLUMN_NAME`) as X and the target column (`TARGET_COLUMN_NAME`) as Y, allocating data to `train_X`, `test_X`, `train_Y`, and `test_Y`. `random_state=42` ensures reproducibility.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntrain_X, test_X, train_Y, test_Y = train_test_split(\n    reviews_df[[FEATURE_COLUMN_NAME]], reviews_df[TARGET_COLUMN_NAME], random_state=42\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying Giskard Scan Results\nDESCRIPTION: Renders the output of the Giskard scan. The `display()` function, commonly used in Jupyter notebooks, presents the `results` object in a user-friendly format, detailing any detected vulnerabilities or issues found during the scan.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n```\n\n----------------------------------------\n\nTITLE: Evaluating the Wrapped Model with Giskard Dataset in Python\nDESCRIPTION: Performs prediction using the Giskard-wrapped RetrievalQA model on the constructed test dataset. Prints the model's predictions, which should correspond to answers for each query. Relies on correct wrapping of both model and dataset in Giskard objects.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/avid/avid-integration-llm.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Let's check that everything works well by running the wrapped model\nprint(model.predict(dataset).prediction)\n```\n\n----------------------------------------\n\nTITLE: Defining Constants\nDESCRIPTION: This snippet defines constants for the target column name and a random seed for reproducibility.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/cancer_detection_xgboost.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nTARGET_COLUMN_NAME = \"target\"\n\nRANDOM_SEED = 42\n```\n\n----------------------------------------\n\nTITLE: Loading Sentiment Analysis Slicing Function from Giskard Catalog in Python\nDESCRIPTION: Demonstrates how to import a pre-built sentiment analysis slicing function from the Giskard catalog to analyze text data.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/customize_tests/data_slices/index.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#Load sentiment analysis model from the Giskard catalog\nfrom giskard.functions.slicing import positive_sentiment_analysis\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard package\nDESCRIPTION: Installs the Giskard package which is used for testing and scanning ML models for vulnerabilities.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Dependency - Python\nDESCRIPTION: This snippet installs the `openai` library with the upgrade flag which is used to interact with OpenAI's API for LLM tasks. This is a prerequisite for using OpenAI models in the project.  The upgrade ensures the most recent compatible version is used.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"openai>=1\" --upgrade\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Data Paths and Model Parameters - Python\nDESCRIPTION: Sets random seed and test split ratio, establishes helpfulness threshold, target variable name, and specifies source and destination paths for the dataset. The DATA_URL points to a remote archive; DATA_PATH is used locally. These are used throughout data loading and model operations.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/amazon_review_classification_sklearn.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nRANDOM_SEED = 0\nTEST_RATIO = 0.2\n\nTARGET_THRESHOLD = 0.5\nTARGET_NAME = \"isHelpful\"\n\n# Paths.\nDATA_URL = \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/amazon_review_dataset-reviews.json.tar.gz\"\nDATA_PATH = Path.home() / \".giskard\" / \"amazon_review_dataset\" / \"reviews.json.tar.gz\"\n\n```\n\n----------------------------------------\n\nTITLE: Example Output: Model Performance Metrics Table (Markdown)\nDESCRIPTION: This Markdown snippet represents the structured output generated by the Giskard model agent after processing the request to calculate and summarize performance metrics. It presents the results in a clear table format, listing each metric and its corresponding score. This output is a result of the model's ability to use tools and format responses.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\nHere are the model performance metrics summarized in a table:\n\n| Metric    | Score |\n|-----------|-------|\n| Accuracy  | 0.79  |\n| F1        | 0.7   |\n| Precision | 0.75  |\n| Recall    | 0.66  |\n```\n\n----------------------------------------\n\nTITLE: Loading Data\nDESCRIPTION: Defines a function `load_data` to download lists of questions and answers from Google Cloud Storage. This function returns a tuple containing lists of questions and answers. It uses the `DATA_URL` constant defined earlier.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef load_data() -> tuple[list, list]:\n    \"\"\"Download lists of questions to the Google and related answers.\"\"\"\n    base_url = os.path.join(DATA_URL, \"{}\")\n    q = pd.read_json(base_url.format(\"questions.json\"))[0].tolist()\n    a = pd.read_json(base_url.format(\"answers.json\"))[0].tolist()\n    return q, a\n\n\nquestions, answers = load_data()\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Fake/Real News Classification in Python\nDESCRIPTION: Declares numeric and path constants required throughout the pipeline, including token and sequence limits, stopwords, data columns, and dataset paths. NLTK's English stopwords are used for preprocessing. Update paths or numbers if modifying scale or features.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nMAX_TOKENS = 20000\nMAX_SEQUENCE_LENGTH = 100\nN_ROWS = 1000\n\nSTOPWORDS = stopwords.words(\"english\")\n\nTEXT_COLUMN_NAME = \"text\"\nTARGET_COLUMN_NAME = \"isFake\"\n\nRANDOM_SEED = 0\n\n# Paths.\nDATA_URL = \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/fake_real_news_dataset-{}\"\nDATA_PATH = Path.home() / \".giskard\" / \"fake_real_news_dataset\"\n\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard\nDESCRIPTION: This command installs the Giskard Python library and upgrades it to the latest version using pip. It's a prerequisite for using Giskard's functionalities for model testing and vulnerability detection.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Displaying GPT-4 Scan Report in Python Notebook\nDESCRIPTION: This Python code snippet demonstrates rendering the Giskard scan report specifically for the 'gpt-4' model inside a notebook environment. It assumes the report is stored under the 'gpt-4' key within the `models` dictionary and utilizes the `display` function for visualization.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/wandb/wandb-llm-example.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(models[\"gpt-4\"]['scan_report'])\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Model and Dataset\nDESCRIPTION: Defines configuration constants used throughout the script. These include the Hugging Face model name, details for loading the dataset, a mapping for label values, and the names of the text and target columns in the dataset. Using constants makes the code more readable and easier to modify.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_nlp.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment\"\n\nDATASET_CONFIG = {\"path\": \"tweet_eval\", \"name\": \"sentiment\", \"split\": \"validation\"}\n\nLABEL_MAPPING = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n\nTEXT_COLUMN = \"text\"\nTARGET_COLUMN = \"label\"\n```\n\n----------------------------------------\n\nTITLE: Importing required libraries\nDESCRIPTION: This snippet imports necessary Python libraries, including `ast` for abstract syntax trees, `os` for operating system interactions, `openai` for accessing the OpenAI API, `pandas` for data manipulation, `tiktoken` for tokenizing text, `scipy.spatial` for calculating spatial distances, and `giskard` for model testing and analysis.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Winter_Olympics.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport ast\nimport os\n\nimport openai\nimport pandas as pd\nimport tiktoken\nfrom scipy import spatial\n\nfrom giskard import scan, Dataset, Model\n```\n\n----------------------------------------\n\nTITLE: Initializing DagsHub\nDESCRIPTION: Initializes DagsHub with the specified repository name and owner. This step is crucial for authenticating and enabling write access to the remote MLflow server hosted on DagsHub. Replace `your_repo_name` and `your_username` with the actual values.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/dagshub/index.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Only DagsHub related lines you need:\nimport dagshub\n# This will work if you have write access to the repo below, if you cloned it, please change the repo_owner to your user name\ndagshub.init(repo_name=\"your_repo_name\", repo_owner=\"your_username\")\n```\n\n----------------------------------------\n\nTITLE: Example Output: Non-Contextual Talk (Markdown)\nDESCRIPTION: This Markdown snippet shows the generic response from the Giskard model agent when a follow-up question is asked *without* providing the necessary context from the previous interaction. The model agent indicates that it lacks the specific details (like the person's identity) required to answer the question, highlighting the importance of using the `context` parameter for conversational flow in dialogue mode.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\nTo provide an explanation for why a specific individual survived, I would need more details about the person in question, such as their name, ticket class, age, or any other information that could help identify them in the dataset. Could you please provide more details?\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Sentiment Analysis\nDESCRIPTION: Imports necessary libraries for data manipulation, model building, and evaluation. This includes libraries for file handling, numerical computation, deep learning, machine learning, and Giskard-specific modules for model testing and analysis. These imports provide the foundational tools for building, training, and evaluating the sentiment classification model.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport transformers as ppb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nfrom giskard import Model, Dataset, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Creating an HTTPS Tunnel with Ngrok for MLflow\nDESCRIPTION: Sets up an Ngrok tunnel to expose the locally running MLflow Tracking UI on port 5000 to the internet with HTTPS enabled. This allows remote access to the MLflow dashboard that's running on localhost.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/integrations/mlflow/mlflow-llm-example.ipynb#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Open an HTTPs tunnel on port 5000 for http://localhost:5000\nngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\nprint(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n```\n\n----------------------------------------\n\nTITLE: Sphinx Automodule Directive for PyTorchModel\nDESCRIPTION: This reStructuredText snippet uses the Sphinx `automodule` directive to automatically pull documentation from the specified Python module (`giskard.models.pytorch`). The `:members: PyTorchModel` option instructs Sphinx to include documentation for the members of the `PyTorchModel` class found within that module.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/models/integrations/pytorch.rst#_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. automodule:: giskard.models.pytorch\n    :members: PyTorchModel\n```\n\n----------------------------------------\n\nTITLE: Adding a Custom Test to Suite\nDESCRIPTION: This code adds a custom test (`testing.test_f1`) to the test suite.  This particular test checks if the F1 score of the model on the dataset is above a specified threshold (0.7). The `run()` method is then called to execute the test.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/getting_started/quickstart/quickstart_tabular.ipynb#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntest_suite.add_test(testing.test_f1(model=giskard_model, dataset=giskard_dataset, threshold=0.7)).run()\n```\n\n----------------------------------------\n\nTITLE: Downgrading libomp to Resolve Segmentation Fault Issue with LightGBM on MacOS Using Shell\nDESCRIPTION: This snippet provides shell commands to download a specific Homebrew formula for `libomp` version 11.1.0 and install it to avoid segmentation faults caused by `libomp` versions >= 12 with LightGBM on MacOS. It addresses a known compatibility issue by fetching an exact formula commit and installing it locally using Homebrew.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/community/contribution_guidelines/dev-environment.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ wget https://raw.githubusercontent.com/Homebrew/homebrew-core/fb8323f2b170bd4ae97e1bac9bf3e2983af3fdb0/Formula/libomp.rb\n$ brew install ./libomp.rb\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard and LightGBM Dependencies in Python\nDESCRIPTION: Installs the Giskard Python package required for model testing and vulnerability scanning, along with the LightGBM library to train the regression model. These installations are prerequisites to running the tutorial code and ensure that all necessary functionalities are available.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/insurance_prediction_lgbm.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\nLANGUAGE: python\nCODE:\n```\n%pip install lightgbm\n```\n\n----------------------------------------\n\nTITLE: Installing additional dependencies for head pose detection\nDESCRIPTION: Installs sixdrepnet for head pose detection and a specific version of OpenCV to avoid common errors mentioned in the documentation.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_landmark_detection.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U opencv_contrib_python sixdrepnet\n```\n\n----------------------------------------\n\nTITLE: Setting up AWS Bedrock LLM Client using .env variables in Python\nDESCRIPTION: This code snippet configures AWS Bedrock as an LLM provider for Giskard by setting AWS credentials and region as environment variables, then specifying the Bedrock LLM and embedding models. It disables structured output for the LLM model. The snippet requires AWS credentials with necessary permissions and the giskard package. Inputs include AWS Access Key ID, Secret Access Key, Region, and specific Bedrock model identifiers. The output is a configured Bedrock client ready for LLM requests.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/setting_up/index.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport giskard\n\nos.environ[\"AWS_ACCESS_KEY_ID\"] = \"\" # \"my-aws-access-key\"\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\" # \"my-aws-secret-access-key\"\nos.environ[\"AWS_REGION_NAME\"] = \"\" # \"us-west-2\"\n\ngiskard.llm.set_llm_model(\"bedrock/anthropic.claude-3-sonnet-20240229-v1:0\", disable_structured_output=True)\ngiskard.llm.set_embedding_model(\"bedrock/amazon.titan-embed-image-v1\")\n```\n\n----------------------------------------\n\nTITLE: Defining Text Classification Model\nDESCRIPTION: Defines a simple text classification model using PyTorch.  The model consists of an embedding layer, a linear layer, and a softmax activation function. The init_weights function initializes the weights for the model. This provides the core model structure used for the newspaper topic classification task.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/newspaper_classification_pytorch.ipynb#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass TextClassificationModel(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_class):\n        super(TextClassificationModel, self).__init__()\n        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n        self.fc = nn.Linear(embed_dim, num_class)\n        self.init_weights()\n\n    def init_weights(self):\n        init_range = 0.5\n        self.embedding.weight.data.uniform_(-init_range, init_range)\n        self.fc.weight.data.uniform_(-init_range, init_range)\n        self.fc.bias.data.zero_()\n\n    def forward(self, text, offsets):\n        embedded = self.embedding(text, offsets)\n        return self.fc(embedded).softmax(axis=-1)\n\n\nmodel = TextClassificationModel(vocab_size=len(vocab), embed_dim=64, num_class=4).to(DEVICE)\n```\n\n----------------------------------------\n\nTITLE: Generating Table of Contents with toctree Directive\nDESCRIPTION: This snippet defines the table of contents for the documentation. It uses the `toctree` directive, specifying the maximum depth of the table of contents (`maxdepth`) and that it should be hidden from view initially (`hidden`). The `caption` parameter is used to add a title to the table of contents. This directive is used to generate a hierarchical navigation structure, linking to different index files that contain further documentation and sections.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/knowledge/catalogs/index.md#_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n```{toctree}\n:caption: Table of Contents\n:maxdepth: 2\n:hidden:\n\ntest-catalog/index\nslicing-function-catalog/index\ntransformation-function-catalog/index\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies (Bash)\nDESCRIPTION: Installs Python libraries necessary for this specific QA project: 'openai' for interacting with the OpenAI API, 'unstructured', 'pdf2image', and 'pdfminer-six' for loading and processing PDF documents, and 'faiss-cpu' for creating the FAISS vector store.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Documentation.ipynb#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n%pip install openai unstructured pdf2image pdfminer-six faiss-cpu\n```\n\n----------------------------------------\n\nTITLE: Loading Dataset and Model for Vulnerability Scanning\nDESCRIPTION: Creates instances of the dataset loader and model wrapper, specifying the dataset directory path and initializing the face detection model. These objects are used later to perform vulnerability scans on the model using the dataset.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_object_detection.ipynb#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndataloader = DataLoader300WFaceDetection(\n    dir_path=\"path-to-giskard-vision/examples/landmark_detection/datasets/300W/sample\"\n)\nmodel = DetrFinetunedHFModel()\n```\n\n----------------------------------------\n\nTITLE: Setting random seeds for reproducibility\nDESCRIPTION: Sets random seeds for Python, NumPy, and PyTorch to ensure reproducible results across runs.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/tripadvisor_sentiment_classification.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set random seeds\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed_all(RANDOM_SEED)\n```\n\n----------------------------------------\n\nTITLE: Displaying and exporting scan results\nDESCRIPTION: Shows the scan results in a notebook display and exports them to an HTML file for further analysis and sharing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_landmark_detection.ipynb#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndisplay(results)\n\n# Save it to file\nresults.to_html(\"scan_report.html\")\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with toctree\nDESCRIPTION: This code snippet uses the toctree directive to create a table of contents for the Knowledge section. It specifies the caption, maximum depth, and hides the toctree in the rendered output. The listed files are the pages linked under the Knowledge section.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/index.md#_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n```\n:caption: Knowledge\n:maxdepth: 1\n:hidden:\n\nknowledge/llm_vulnerabilities/index\nknowledge/key_vulnerabilities/index\nknowledge/catalogs/index\n```\n```\n\n----------------------------------------\n\nTITLE: Wrapping Model with ModelBase\nDESCRIPTION: This Python code demonstrates how to wrap a model using the `ModelBase` class, which is required to use the Giskard scanner. It involves overriding the `predict_rgb_image` method and optionally `predict_gray_image`. The input is a model and an RGB image as `np.ndarray`. The output is the prediction of the model (label).  It requires the Giskard library.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/scan/scan_vision/index.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom giskard_vision.core.models.base import ModelBase\n\n\nclass ModelMyTask(ModelBase):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n\n    def predict_rgb_image(self, image: np.ndarray) -> np.ndarray:\n        return self.model.predict_rgb_image(image)\n    \n    def predict_gray_image(self, image: np.ndarray) -> np.ndarray:\n        return self.model.predict_gray_image(image)\n\nmymodel = ...\ngiskard_model = ModelMyTask(model=mymodel)\n```\n\n----------------------------------------\n\nTITLE: Installing Accelerate Dependency - Shell\nDESCRIPTION: Installs the Accelerate library, a dependency often used with HuggingFace Transformers for optimized training, using pip within a notebook environment. This ensures necessary components for the training process are available.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/airline_tweets_sentiment_analysis.ipynb#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\n%pip install accelerate --upgrade\n```\n\n----------------------------------------\n\nTITLE: Sphinx Auto-Documentation for Giskard Scanner Modules\nDESCRIPTION: ReStructuredText directives that automatically generate documentation for the Giskard scanner module by importing and documenting all members and inheritance information from each submodule.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/scan/detectors.rst#_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. automodule:: giskard.scanner.performance\n   :members:\n   :show-inheritance:\n\n.. automodule:: giskard.scanner.robustness\n   :members:\n   :show-inheritance:\n\n.. automodule:: giskard.scanner.calibration\n   :members:\n   :show-inheritance:\n\n.. automodule:: giskard.scanner.data_leakage\n   :members:\n   :show-inheritance:\n\n.. automodule:: giskard.scanner.stochasticity\n   :members:\n   :show-inheritance:\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key and Display Options - Python\nDESCRIPTION: This snippet sets the OpenAI API key as an environment variable, configures the OpenAI API key for the current session, and sets display options for pandas to show all columns. It is crucial to have a valid OpenAI API key for the project to function correctly.  The pandas option ensures complete data visibility.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set the OpenAI API Key environment variable.\nOPENAI_API_KEY = \"...\"\nopenai.api_key = OPENAI_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# Display options.\npd.set_option(\"display.max_colwidth\", None)\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Sets the OpenAI API Key environment variable, required for using the OpenAI API. The key is set using the provided value and also set in the os environment.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_Google.ipynb#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Set the OpenAI API Key environment variable.\nOPENAI_API_KEY = \"...\"\nopenai.api_key = OPENAI_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard with 'talk' Flavor (bash)\nDESCRIPTION: Installs the Giskard Python package with support for the 'talk' feature, enabling natural language operations on models. The package is fetched via pip, and the '[talk]' extra ensures necessary dependencies (including those for LLM and OpenAI function calling) are installed. Requires Internet access and Python packaging tools.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/open_source/ai_quality_copilot/index.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"giskard[talk]\"\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard LLM and Dependencies in Python\nDESCRIPTION: Installs the Giskard package with LLM support, updating it to the latest version. Also installs essential dependencies for the tutorial including langchain, pypdf, faiss-cpu, openai, and tiktoken. Required to enable model construction, PDF parsing, vector storage, and LLM interaction. These commands should be run in a Jupyter notebook or similar environment with support for `%pip` magics.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_QA_IPCC.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"giskard[llm]\" --upgrade\n\n```\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"langchain\" \"pypdf<=3.17.0\" \"faiss-cpu<=1.7.4\" \"openai>1\" \"tiktoken<=0.5.1\"\n\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard dependencies for vision models\nDESCRIPTION: Installs the core Giskard library and the vision-specific extension needed for testing facial landmark detection models.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/vision_landmark_detection.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard giskard_vision\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard and Langchain Dependencies - Python\nDESCRIPTION: Installs the necessary Python packages for the tutorial. It includes the 'llm' flavor of Giskard for LLM support and specific Langchain packages ('langchain-community', 'langchain-openai') for building the prompt-chaining logic.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/LLM_Description_Product.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"giskard[llm]\"  --upgrade\n%pip install langchain langchain-community langchain-openai --upgrade\n```\n\n----------------------------------------\n\nTITLE: Installing Giskard using pip\nDESCRIPTION: This snippet installs the Giskard library, a framework for testing machine learning models, and upgrades it to the latest version. It is a prerequisite for using other Giskard functionalities within the notebook. The upgrade ensures that the user has access to the latest features and bug fixes.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/movie_review_sentiment_classification_pytorch_sklearn.ipynb#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install giskard --upgrade\n```\n\n----------------------------------------\n\nTITLE: Defining Constants for Data Handling in Python\nDESCRIPTION: Defines constants for the notebook, including the names of the feature column ('Full_Review') and target column ('Reviewer_Score'), the URL to download the dataset, and the local path where the downloaded dataset will be stored.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Constants.\nFEATURE_COLUMN_NAME = \"Full_Review\"\nTARGET_COLUMN_NAME = \"Reviewer_Score\"\n\n# Paths.\nDATA_URL = \"https://giskard-library-test-datasets.s3.eu-north-1.amazonaws.com/hotel_text_regression_dataset-Hotel_Reviews.csv.tar.gz\"\nDATA_PATH = Path.home() / \".giskard\" / \"hotel_text_regression_dataset\" / \"Hotel_Reviews.csv.tar.gz\"\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Twitter Sentiment Analysis\nDESCRIPTION: Imports essential libraries for sentiment analysis, including NumPy, pandas, scipy for softmax function, Hugging Face datasets and transformers, and Giskard for model testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/twitter_sentiment_analysis_roberta.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import softmax\nfrom datasets import load_dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nfrom giskard import Dataset, Model, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Importing Required Python Libraries\nDESCRIPTION: Imports necessary libraries for data handling, model building, and Giskard integration. This includes `pathlib`, `urllib` for data fetching, `pandas` for data manipulation, `sklearn` components for the ML pipeline (TfidfVectorizer, GradientBoostingRegressor, Pipeline, etc.), and `giskard` for model/dataset wrapping, scanning, and testing.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/hotel_text_regression.ipynb#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom urllib.request import urlretrieve\n\nimport pandas as pd\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom typing import Iterable\n\nfrom giskard import Model, Dataset, scan, testing\n```\n\n----------------------------------------\n\nTITLE: Setting TensorFlow Log Level in Python\nDESCRIPTION: Configures the TensorFlow logging level to reduce log output using an environment variable. Setting \"TF_CPP_MIN_LOG_LEVEL\" to \"1\" suppresses detailed logs for cleaner notebook output. This should be set before TensorFlow is loaded or used.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/reference/notebooks/fake_real_news_classification.ipynb#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n\n```\n\n----------------------------------------\n\nTITLE: Rendering Issue Table using Jinja2\nDESCRIPTION: This Jinja2 snippet iterates through a list of groups and their associated issues.  For each issue, it displays its properties (level, data slice, metric, transformation, deviation, and description) within a table row.  It utilizes conditional statements to handle missing values (e.g., slicing_fn) and format the metric value.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/giskard/visualization/templates/scan_report/markdown/github.md#_snippet_0\n\nLANGUAGE: Jinja2\nCODE:\n```\n{% for view in groups -%}\n<details>\n<summary>{{ view.group.name }} issues ({{ view.issues|length }})</summary>\n\n| Vulnerability | Level | Data slice | Metric | Transformation | Deviation | Description |\n|---------------|-------|------------|--------|----------------|-----------|-------------|\n{% for issue in view.issues -%}\n| {{ view.group.name }} | {{ issue.level.value }} | {{ issue.slicing_fn if issue.slicing_fn else \"—\" }} | {% if \"metric\" in issue.meta %}{{ issue.meta.metric }} = {{ issue.meta.metric_value|format_metric }}{% else %} \"—\" {% endif %} | {{ issue.transformation_fn if issue.transformation_fn else \"—\" }} | {{ issue.meta[\"deviation\"] if \"deviation\" in issue.meta else \"—\" }} | {{ issue.description }} |\n{% endfor %}\n\n</details>\n{% endfor -%}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Docker container logs (Bash)\nDESCRIPTION: This command line snippet is used to retrieve the standard output and standard error logs from a specific Docker container. It is provided in the context of reporting a bug in Giskard, particularly if the issue occurs within a Docker environment and a full stack trace is required for debugging.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker logs <NAME OF THE CONTAINER>\n```\n\n----------------------------------------\n\nTITLE: Defining Documentation Structure with toctree\nDESCRIPTION: This code snippet uses the toctree directive to create a table of contents for the Notebook Tutorials section. It specifies the caption, maximum depth, and hides the toctree in the rendered output. The listed files are the pages linked under the Notebook Tutorials section.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/index.md#_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n```\n:caption: Notebook Tutorials\n:maxdepth: 1\n:hidden:\n\ntutorials/llm_tutorials/index\ntutorials/rag_tutorials/index\ntutorials/tabular_tutorials/index\ntutorials/nlp_tutorials/index\ntutorials/vision_tutorials/index\n```\n```\n\n----------------------------------------\n\nTITLE: Setting up Sphinx table of contents for tutorials in Markdown\nDESCRIPTION: Configures a hidden table of contents (toctree) directive for organizing tutorial documentation with maxdepth 1. It includes references to five tutorial categories: LLM, RAG, tabular, NLP, and vision tutorials.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/tutorials/index.md#_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:caption: Tutorials\n:maxdepth: 1\n:hidden:\n\nllm_tutorials/index\nrag_tutorials/index\ntabular_tutorials/index\nnlp_tutorials/index\nvision_tutorials/index\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Table of Contents for LLM Tutorials in Markdown\nDESCRIPTION: Creates a hidden, nested table of contents for various LLM tutorial notebooks with a maximum depth of 1. The toctree directive organizes references to Jupyter notebooks covering different LLM applications.\nSOURCE: https://github.com/giskard-ai/giskard/blob/main/docs/tutorials/llm_tutorials/index.md#_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:caption: Table of Contents\n:maxdepth: 1\n:hidden:\n\n../../reference/notebooks/LLM_QA_IPCC.ipynb\n../../reference/notebooks/LLM_QA_Google.ipynb\n../../reference/notebooks/LLM_QA_Winter_Olympics.ipynb\n../../reference/notebooks/LLM_Description_Product.ipynb\n../../reference/notebooks/LLM_Newspaper_Comment_Generation.ipynb\n../../reference/notebooks/LLM_QA_Documentation.ipynb\n\n```\n```"
  }
]